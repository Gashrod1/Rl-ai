Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.78662
Policy Entropy: 0.95183
Value Function Loss: 0.07391

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 9606.10671
Overall Steps per Second: 2180.96111

Timestep Collection Time: 5.20877
Timestep Consumption Time: 17.73341
PPO Batch Consumption Time: 0.19492
Total Iteration Time: 22.94218

Cumulative Model Updates: 43526
Cumulative Timesteps: 363378911

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.86554
Policy Entropy: 0.98756
Value Function Loss: 0.06307

Mean KL Divergence: 0.08945
SB3 Clip Fraction: 0.32753
Policy Update Magnitude: 0.11021
Value Function Update Magnitude: 0.16562

Collected Steps per Second: 9998.30836
Overall Steps per Second: 1944.93059

Timestep Collection Time: 5.00175
Timestep Consumption Time: 20.71074
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 25.71249

Cumulative Model Updates: 43530
Cumulative Timesteps: 363428920

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.07949
Policy Entropy: 1.01400
Value Function Loss: 0.05877

Mean KL Divergence: 0.14567
SB3 Clip Fraction: 0.36632
Policy Update Magnitude: 0.16007
Value Function Update Magnitude: 0.20461

Collected Steps per Second: 10700.09866
Overall Steps per Second: 7421.55856

Timestep Collection Time: 4.67538
Timestep Consumption Time: 2.06539
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.74077

Cumulative Model Updates: 43536
Cumulative Timesteps: 363478947

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.18294
Policy Entropy: 1.03318
Value Function Loss: 0.04898

Mean KL Divergence: 0.11021
SB3 Clip Fraction: 0.33242
Policy Update Magnitude: 0.14455
Value Function Update Magnitude: 0.17527

Collected Steps per Second: 9762.08719
Overall Steps per Second: 7021.91478

Timestep Collection Time: 5.12534
Timestep Consumption Time: 2.00007
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 7.12541

Cumulative Model Updates: 43542
Cumulative Timesteps: 363528981

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.12326
Policy Entropy: 1.03117
Value Function Loss: 0.04525

Mean KL Divergence: 0.06095
SB3 Clip Fraction: 0.27094
Policy Update Magnitude: 0.13473
Value Function Update Magnitude: 0.17500

Collected Steps per Second: 10135.11386
Overall Steps per Second: 7331.47999

Timestep Collection Time: 4.93433
Timestep Consumption Time: 1.88694
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 6.82127

Cumulative Model Updates: 43548
Cumulative Timesteps: 363578991

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.16685
Policy Entropy: 1.04053
Value Function Loss: 0.04050

Mean KL Divergence: 0.04800
SB3 Clip Fraction: 0.25613
Policy Update Magnitude: 0.12755
Value Function Update Magnitude: 0.16578

Collected Steps per Second: 10914.43452
Overall Steps per Second: 7496.00428

Timestep Collection Time: 4.58320
Timestep Consumption Time: 2.09009
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 6.67329

Cumulative Model Updates: 43554
Cumulative Timesteps: 363629014

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.33870
Policy Entropy: 1.05018
Value Function Loss: 0.03905

Mean KL Divergence: 0.03971
SB3 Clip Fraction: 0.23202
Policy Update Magnitude: 0.12207
Value Function Update Magnitude: 0.15199

Collected Steps per Second: 9891.25682
Overall Steps per Second: 7155.93898

Timestep Collection Time: 5.05942
Timestep Consumption Time: 1.93393
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 6.99335

Cumulative Model Updates: 43560
Cumulative Timesteps: 363679058

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.92399
Policy Entropy: 1.05705
Value Function Loss: 0.03645

Mean KL Divergence: 0.02976
SB3 Clip Fraction: 0.18811
Policy Update Magnitude: 0.11730
Value Function Update Magnitude: 0.14903

Collected Steps per Second: 9744.12002
Overall Steps per Second: 6933.07596

Timestep Collection Time: 5.13140
Timestep Consumption Time: 2.08055
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.21195

Cumulative Model Updates: 43566
Cumulative Timesteps: 363729059

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.14955
Policy Entropy: 1.06469
Value Function Loss: 0.03476

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.11562
Value Function Update Magnitude: 0.15532

Collected Steps per Second: 10439.36075
Overall Steps per Second: 7294.71773

Timestep Collection Time: 4.79206
Timestep Consumption Time: 2.06578
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 6.85784

Cumulative Model Updates: 43572
Cumulative Timesteps: 363779085

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.24839
Policy Entropy: 1.06215
Value Function Loss: 0.03434

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.11361
Value Function Update Magnitude: 0.16691

Collected Steps per Second: 9856.23671
Overall Steps per Second: 7070.89838

Timestep Collection Time: 5.07364
Timestep Consumption Time: 1.99859
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 7.07223

Cumulative Model Updates: 43578
Cumulative Timesteps: 363829092

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 363829092...
Checkpoint 363829092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.96647
Policy Entropy: 1.06907
Value Function Loss: 0.03437

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.11395
Value Function Update Magnitude: 0.16515

Collected Steps per Second: 9676.39411
Overall Steps per Second: 6970.84314

Timestep Collection Time: 5.17114
Timestep Consumption Time: 2.00704
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.17818

Cumulative Model Updates: 43584
Cumulative Timesteps: 363879130

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.30346
Policy Entropy: 1.07263
Value Function Loss: 0.03276

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.11360
Value Function Update Magnitude: 0.15822

Collected Steps per Second: 10222.69328
Overall Steps per Second: 7226.30578

Timestep Collection Time: 4.89470
Timestep Consumption Time: 2.02959
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.92428

Cumulative Model Updates: 43590
Cumulative Timesteps: 363929167

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.07688
Policy Entropy: 1.07908
Value Function Loss: 0.03244

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.11021
Value Function Update Magnitude: 0.14873

Collected Steps per Second: 10009.45699
Overall Steps per Second: 7159.19109

Timestep Collection Time: 4.99687
Timestep Consumption Time: 1.98939
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.98626

Cumulative Model Updates: 43596
Cumulative Timesteps: 363979183

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.47225
Policy Entropy: 1.07833
Value Function Loss: 0.03117

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.10441
Value Function Update Magnitude: 0.16096

Collected Steps per Second: 9808.27429
Overall Steps per Second: 7042.12827

Timestep Collection Time: 5.09876
Timestep Consumption Time: 2.00279
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.10155

Cumulative Model Updates: 43602
Cumulative Timesteps: 364029193

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.79120
Policy Entropy: 1.08279
Value Function Loss: 0.03154

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.10322
Value Function Update Magnitude: 0.15181

Collected Steps per Second: 10319.96492
Overall Steps per Second: 7222.02508

Timestep Collection Time: 4.84847
Timestep Consumption Time: 2.07978
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 6.92825

Cumulative Model Updates: 43608
Cumulative Timesteps: 364079229

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.58843
Policy Entropy: 1.09155
Value Function Loss: 0.03105

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.10561
Value Function Update Magnitude: 0.13404

Collected Steps per Second: 9945.45721
Overall Steps per Second: 7090.73744

Timestep Collection Time: 5.02853
Timestep Consumption Time: 2.02448
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.05300

Cumulative Model Updates: 43614
Cumulative Timesteps: 364129240

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.85607
Policy Entropy: 1.09498
Value Function Loss: 0.03067

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.10805
Value Function Update Magnitude: 0.12627

Collected Steps per Second: 9972.30810
Overall Steps per Second: 7137.89675

Timestep Collection Time: 5.01449
Timestep Consumption Time: 1.99122
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.00571

Cumulative Model Updates: 43620
Cumulative Timesteps: 364179246

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.82382
Policy Entropy: 1.09729
Value Function Loss: 0.03038

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.10493
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 10593.98203
Overall Steps per Second: 7383.60321

Timestep Collection Time: 4.72278
Timestep Consumption Time: 2.05346
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 6.77623

Cumulative Model Updates: 43626
Cumulative Timesteps: 364229279

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.09617
Policy Entropy: 1.09572
Value Function Loss: 0.03036

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.10018
Value Function Update Magnitude: 0.12368

Collected Steps per Second: 9796.03507
Overall Steps per Second: 7044.21755

Timestep Collection Time: 5.10615
Timestep Consumption Time: 1.99471
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.10086

Cumulative Model Updates: 43632
Cumulative Timesteps: 364279299

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.96297
Policy Entropy: 1.10150
Value Function Loss: 0.03065

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.10006
Value Function Update Magnitude: 0.12500

Collected Steps per Second: 9727.95897
Overall Steps per Second: 6990.98454

Timestep Collection Time: 5.14209
Timestep Consumption Time: 2.01313
PPO Batch Consumption Time: 0.02931
Total Iteration Time: 7.15522

Cumulative Model Updates: 43638
Cumulative Timesteps: 364329321

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 364329321...
Checkpoint 364329321 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.22117
Policy Entropy: 1.09799
Value Function Loss: 0.02963

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.09847
Value Function Update Magnitude: 0.12822

Collected Steps per Second: 10401.78912
Overall Steps per Second: 7135.92616

Timestep Collection Time: 4.81033
Timestep Consumption Time: 2.20152
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.01184

Cumulative Model Updates: 43644
Cumulative Timesteps: 364379357

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.23468
Policy Entropy: 1.09385
Value Function Loss: 0.02883

Mean KL Divergence: 0.02537
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.08942
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 9939.99166
Overall Steps per Second: 7115.38061

Timestep Collection Time: 5.03381
Timestep Consumption Time: 1.99828
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.03209

Cumulative Model Updates: 43650
Cumulative Timesteps: 364429393

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.67240
Policy Entropy: 1.08940
Value Function Loss: 0.02779

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.08909
Value Function Update Magnitude: 0.12387

Collected Steps per Second: 9984.44763
Overall Steps per Second: 7134.77293

Timestep Collection Time: 5.00909
Timestep Consumption Time: 2.00066
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.00975

Cumulative Model Updates: 43656
Cumulative Timesteps: 364479406

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.86854
Policy Entropy: 1.08143
Value Function Loss: 0.02970

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.09931
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 10637.47715
Overall Steps per Second: 7353.91672

Timestep Collection Time: 4.70215
Timestep Consumption Time: 2.09953
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 6.80168

Cumulative Model Updates: 43662
Cumulative Timesteps: 364529425

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.16089
Policy Entropy: 1.07368
Value Function Loss: 0.02961

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.09948
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 9850.01797
Overall Steps per Second: 7065.75664

Timestep Collection Time: 5.07857
Timestep Consumption Time: 2.00121
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.07978

Cumulative Model Updates: 43668
Cumulative Timesteps: 364579449

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.68579
Policy Entropy: 1.07608
Value Function Loss: 0.03072

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.10215
Value Function Update Magnitude: 0.12294

Collected Steps per Second: 9817.43212
Overall Steps per Second: 6995.54541

Timestep Collection Time: 5.09706
Timestep Consumption Time: 2.05607
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.15312

Cumulative Model Updates: 43674
Cumulative Timesteps: 364629489

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.84147
Policy Entropy: 1.07645
Value Function Loss: 0.03024

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.10330
Value Function Update Magnitude: 0.12397

Collected Steps per Second: 10350.64586
Overall Steps per Second: 7171.38855

Timestep Collection Time: 4.83120
Timestep Consumption Time: 2.14179
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 6.97299

Cumulative Model Updates: 43680
Cumulative Timesteps: 364679495

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.48742
Policy Entropy: 1.07327
Value Function Loss: 0.03017

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.17149
Policy Update Magnitude: 0.09569
Value Function Update Magnitude: 0.12167

Collected Steps per Second: 9719.79687
Overall Steps per Second: 7028.07883

Timestep Collection Time: 5.14496
Timestep Consumption Time: 1.97049
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.11546

Cumulative Model Updates: 43686
Cumulative Timesteps: 364729503

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.71159
Policy Entropy: 1.06529
Value Function Loss: 0.03074

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.15440
Policy Update Magnitude: 0.09040
Value Function Update Magnitude: 0.12280

Collected Steps per Second: 9654.78143
Overall Steps per Second: 6915.87772

Timestep Collection Time: 5.18303
Timestep Consumption Time: 2.05264
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 7.23567

Cumulative Model Updates: 43692
Cumulative Timesteps: 364779544

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.93426
Policy Entropy: 1.05358
Value Function Loss: 0.03048

Mean KL Divergence: 0.02777
SB3 Clip Fraction: 0.16868
Policy Update Magnitude: 0.09491
Value Function Update Magnitude: 0.12843

Collected Steps per Second: 10336.50280
Overall Steps per Second: 7234.26652

Timestep Collection Time: 4.83955
Timestep Consumption Time: 2.07532
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 6.91487

Cumulative Model Updates: 43698
Cumulative Timesteps: 364829568

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 364829568...
Checkpoint 364829568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.49688
Policy Entropy: 1.05842
Value Function Loss: 0.03080

Mean KL Divergence: 0.03551
SB3 Clip Fraction: 0.20101
Policy Update Magnitude: 0.09661
Value Function Update Magnitude: 0.13038

Collected Steps per Second: 9866.91566
Overall Steps per Second: 7054.38563

Timestep Collection Time: 5.06815
Timestep Consumption Time: 2.02063
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.08878

Cumulative Model Updates: 43704
Cumulative Timesteps: 364879575

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.79118
Policy Entropy: 1.05023
Value Function Loss: 0.03028

Mean KL Divergence: 0.03585
SB3 Clip Fraction: 0.20183
Policy Update Magnitude: 0.09096
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 9841.44226
Overall Steps per Second: 7047.08473

Timestep Collection Time: 5.08421
Timestep Consumption Time: 2.01603
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.10024

Cumulative Model Updates: 43710
Cumulative Timesteps: 364929611

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.37400
Policy Entropy: 1.05372
Value Function Loss: 0.03001

Mean KL Divergence: 0.03481
SB3 Clip Fraction: 0.20485
Policy Update Magnitude: 0.09081
Value Function Update Magnitude: 0.13164

Collected Steps per Second: 10335.11332
Overall Steps per Second: 7248.84103

Timestep Collection Time: 4.84136
Timestep Consumption Time: 2.06126
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.90262

Cumulative Model Updates: 43716
Cumulative Timesteps: 364979647

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.30729
Policy Entropy: 1.05038
Value Function Loss: 0.02897

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.09454
Value Function Update Magnitude: 0.12414

Collected Steps per Second: 9948.23137
Overall Steps per Second: 7041.37645

Timestep Collection Time: 5.02924
Timestep Consumption Time: 2.07619
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.10543

Cumulative Model Updates: 43722
Cumulative Timesteps: 365029679

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.67827
Policy Entropy: 1.05448
Value Function Loss: 0.02941

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.10222
Value Function Update Magnitude: 0.12092

Collected Steps per Second: 9820.79224
Overall Steps per Second: 7016.12505

Timestep Collection Time: 5.09338
Timestep Consumption Time: 2.03606
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.12943

Cumulative Model Updates: 43728
Cumulative Timesteps: 365079700

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.72455
Policy Entropy: 1.04269
Value Function Loss: 0.02847

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.09441
Value Function Update Magnitude: 0.12797

Collected Steps per Second: 10351.76848
Overall Steps per Second: 7227.93813

Timestep Collection Time: 4.83425
Timestep Consumption Time: 2.08930
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.92355

Cumulative Model Updates: 43734
Cumulative Timesteps: 365129743

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.45091
Policy Entropy: 1.05786
Value Function Loss: 0.02993

Mean KL Divergence: 0.02800
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.09994
Value Function Update Magnitude: 0.14079

Collected Steps per Second: 9919.14736
Overall Steps per Second: 7086.15749

Timestep Collection Time: 5.04318
Timestep Consumption Time: 2.01622
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.05940

Cumulative Model Updates: 43740
Cumulative Timesteps: 365179767

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.70505
Policy Entropy: 1.06114
Value Function Loss: 0.02958

Mean KL Divergence: 0.02410
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.10343
Value Function Update Magnitude: 0.14204

Collected Steps per Second: 9776.70903
Overall Steps per Second: 6975.23913

Timestep Collection Time: 5.11563
Timestep Consumption Time: 2.05459
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 7.17022

Cumulative Model Updates: 43746
Cumulative Timesteps: 365229781

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.31477
Policy Entropy: 1.07091
Value Function Loss: 0.02932

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.14908
Policy Update Magnitude: 0.10410
Value Function Update Magnitude: 0.16016

Collected Steps per Second: 10446.82485
Overall Steps per Second: 7292.47391

Timestep Collection Time: 4.78911
Timestep Consumption Time: 2.07152
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 6.86063

Cumulative Model Updates: 43752
Cumulative Timesteps: 365279812

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.65017
Policy Entropy: 1.06920
Value Function Loss: 0.02918

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.10447
Value Function Update Magnitude: 0.15206

Collected Steps per Second: 10069.40160
Overall Steps per Second: 7126.45023

Timestep Collection Time: 4.96772
Timestep Consumption Time: 2.05148
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.01920

Cumulative Model Updates: 43758
Cumulative Timesteps: 365329834

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 365329834...
Checkpoint 365329834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.55520
Policy Entropy: 1.06558
Value Function Loss: 0.02887

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.10787
Value Function Update Magnitude: 0.15574

Collected Steps per Second: 10170.38078
Overall Steps per Second: 7219.87690

Timestep Collection Time: 4.91751
Timestep Consumption Time: 2.00961
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 6.92713

Cumulative Model Updates: 43764
Cumulative Timesteps: 365379847

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.08963
Policy Entropy: 1.06492
Value Function Loss: 0.02974

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.10202
Value Function Update Magnitude: 0.17841

Collected Steps per Second: 10392.00265
Overall Steps per Second: 7275.90559

Timestep Collection Time: 4.81351
Timestep Consumption Time: 2.06151
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 6.87502

Cumulative Model Updates: 43770
Cumulative Timesteps: 365429869

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.32041
Policy Entropy: 1.06079
Value Function Loss: 0.03027

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.10163
Value Function Update Magnitude: 0.17076

Collected Steps per Second: 9891.25778
Overall Steps per Second: 7089.05450

Timestep Collection Time: 5.05820
Timestep Consumption Time: 1.99944
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.05764

Cumulative Model Updates: 43776
Cumulative Timesteps: 365479901

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.18758
Policy Entropy: 1.06131
Value Function Loss: 0.03150

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.10833
Value Function Update Magnitude: 0.15590

Collected Steps per Second: 9751.38731
Overall Steps per Second: 7014.95075

Timestep Collection Time: 5.12881
Timestep Consumption Time: 2.00068
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.12949

Cumulative Model Updates: 43782
Cumulative Timesteps: 365529914

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.86647
Policy Entropy: 1.05000
Value Function Loss: 0.03168

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.10733
Value Function Update Magnitude: 0.15120

Collected Steps per Second: 10330.77635
Overall Steps per Second: 7256.70378

Timestep Collection Time: 4.83991
Timestep Consumption Time: 2.05027
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.89018

Cumulative Model Updates: 43788
Cumulative Timesteps: 365579914

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.48665
Policy Entropy: 1.04316
Value Function Loss: 0.03243

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.10873
Value Function Update Magnitude: 0.15793

Collected Steps per Second: 9874.49298
Overall Steps per Second: 7038.14256

Timestep Collection Time: 5.06720
Timestep Consumption Time: 2.04207
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.10926

Cumulative Model Updates: 43794
Cumulative Timesteps: 365629950

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.49392
Policy Entropy: 1.04513
Value Function Loss: 0.03140

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.17777
Policy Update Magnitude: 0.09991
Value Function Update Magnitude: 0.18292

Collected Steps per Second: 9780.92249
Overall Steps per Second: 7018.84616

Timestep Collection Time: 5.11261
Timestep Consumption Time: 2.01193
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 7.12453

Cumulative Model Updates: 43800
Cumulative Timesteps: 365679956

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.10356
Policy Entropy: 1.05625
Value Function Loss: 0.03312

Mean KL Divergence: 0.02548
SB3 Clip Fraction: 0.16021
Policy Update Magnitude: 0.09627
Value Function Update Magnitude: 0.18172

Collected Steps per Second: 10288.04147
Overall Steps per Second: 7241.26709

Timestep Collection Time: 4.86254
Timestep Consumption Time: 2.04592
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 6.90846

Cumulative Model Updates: 43806
Cumulative Timesteps: 365729982

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.58474
Policy Entropy: 1.05867
Value Function Loss: 0.03092

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.16368
Policy Update Magnitude: 0.10317
Value Function Update Magnitude: 0.17556

Collected Steps per Second: 10002.40154
Overall Steps per Second: 7128.45352

Timestep Collection Time: 5.00310
Timestep Consumption Time: 2.01708
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.02018

Cumulative Model Updates: 43812
Cumulative Timesteps: 365780025

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.46206
Policy Entropy: 1.05297
Value Function Loss: 0.03206

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.10502
Value Function Update Magnitude: 0.17186

Collected Steps per Second: 9732.26700
Overall Steps per Second: 6995.53817

Timestep Collection Time: 5.14217
Timestep Consumption Time: 2.01167
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.15385

Cumulative Model Updates: 43818
Cumulative Timesteps: 365830070

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 365830070...
Checkpoint 365830070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.96032
Policy Entropy: 1.05020
Value Function Loss: 0.03067

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.10884
Value Function Update Magnitude: 0.16940

Collected Steps per Second: 10463.16512
Overall Steps per Second: 7305.42970

Timestep Collection Time: 4.78125
Timestep Consumption Time: 2.06667
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.84792

Cumulative Model Updates: 43824
Cumulative Timesteps: 365880097

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.86510
Policy Entropy: 1.04419
Value Function Loss: 0.03150

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.10555
Value Function Update Magnitude: 0.15850

Collected Steps per Second: 9875.29094
Overall Steps per Second: 7091.29750

Timestep Collection Time: 5.06537
Timestep Consumption Time: 1.98863
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.05400

Cumulative Model Updates: 43830
Cumulative Timesteps: 365930119

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.83496
Policy Entropy: 1.04365
Value Function Loss: 0.03067

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.10493
Value Function Update Magnitude: 0.15668

Collected Steps per Second: 9744.42626
Overall Steps per Second: 6969.44027

Timestep Collection Time: 5.13258
Timestep Consumption Time: 2.04361
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.17619

Cumulative Model Updates: 43836
Cumulative Timesteps: 365980133

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.70494
Policy Entropy: 1.04120
Value Function Loss: 0.03114

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.11083
Value Function Update Magnitude: 0.15023

Collected Steps per Second: 10424.66235
Overall Steps per Second: 7269.88000

Timestep Collection Time: 4.79689
Timestep Consumption Time: 2.08162
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 6.87852

Cumulative Model Updates: 43842
Cumulative Timesteps: 366030139

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.12075
Policy Entropy: 1.05218
Value Function Loss: 0.03195

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.10931
Value Function Update Magnitude: 0.14299

Collected Steps per Second: 9849.50039
Overall Steps per Second: 7075.39881

Timestep Collection Time: 5.07924
Timestep Consumption Time: 1.99145
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.07070

Cumulative Model Updates: 43848
Cumulative Timesteps: 366080167

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.95211
Policy Entropy: 1.05951
Value Function Loss: 0.03151

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.10525
Value Function Update Magnitude: 0.15033

Collected Steps per Second: 9814.29727
Overall Steps per Second: 7002.78637

Timestep Collection Time: 5.09705
Timestep Consumption Time: 2.04639
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.14344

Cumulative Model Updates: 43854
Cumulative Timesteps: 366130191

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.46907
Policy Entropy: 1.06212
Value Function Loss: 0.03104

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.10765
Value Function Update Magnitude: 0.15282

Collected Steps per Second: 10430.72107
Overall Steps per Second: 7291.51106

Timestep Collection Time: 4.79641
Timestep Consumption Time: 2.06499
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 6.86140

Cumulative Model Updates: 43860
Cumulative Timesteps: 366180221

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.59453
Policy Entropy: 1.06354
Value Function Loss: 0.03159

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.10302
Value Function Update Magnitude: 0.15429

Collected Steps per Second: 10113.57675
Overall Steps per Second: 7083.70403

Timestep Collection Time: 4.94771
Timestep Consumption Time: 2.11625
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.06396

Cumulative Model Updates: 43866
Cumulative Timesteps: 366230260

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.99825
Policy Entropy: 1.06850
Value Function Loss: 0.03081

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.10612
Value Function Update Magnitude: 0.16558

Collected Steps per Second: 9758.26780
Overall Steps per Second: 6909.63136

Timestep Collection Time: 5.12499
Timestep Consumption Time: 2.11288
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.23787

Cumulative Model Updates: 43872
Cumulative Timesteps: 366280271

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.53534
Policy Entropy: 1.06899
Value Function Loss: 0.03112

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.10203
Value Function Update Magnitude: 0.16695

Collected Steps per Second: 10287.53695
Overall Steps per Second: 7248.60139

Timestep Collection Time: 4.86336
Timestep Consumption Time: 2.03894
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.90230

Cumulative Model Updates: 43878
Cumulative Timesteps: 366330303

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 366330303...
Checkpoint 366330303 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.66045
Policy Entropy: 1.07452
Value Function Loss: 0.02970

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.09819
Value Function Update Magnitude: 0.17161

Collected Steps per Second: 9782.86012
Overall Steps per Second: 7023.51905

Timestep Collection Time: 5.11190
Timestep Consumption Time: 2.00832
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.12022

Cumulative Model Updates: 43884
Cumulative Timesteps: 366380312

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.90856
Policy Entropy: 1.07267
Value Function Loss: 0.02968

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.09681
Value Function Update Magnitude: 0.18593

Collected Steps per Second: 9680.27645
Overall Steps per Second: 6958.23156

Timestep Collection Time: 5.16969
Timestep Consumption Time: 2.02237
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.19206

Cumulative Model Updates: 43890
Cumulative Timesteps: 366430356

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.18400
Policy Entropy: 1.07946
Value Function Loss: 0.02918

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.09441
Value Function Update Magnitude: 0.17165

Collected Steps per Second: 10434.62642
Overall Steps per Second: 7317.23973

Timestep Collection Time: 4.79404
Timestep Consumption Time: 2.04242
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 6.83646

Cumulative Model Updates: 43896
Cumulative Timesteps: 366480380

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.52277
Policy Entropy: 1.05756
Value Function Loss: 0.02890

Mean KL Divergence: 0.03658
SB3 Clip Fraction: 0.20205
Policy Update Magnitude: 0.08975
Value Function Update Magnitude: 0.16697

Collected Steps per Second: 9967.05276
Overall Steps per Second: 7068.97020

Timestep Collection Time: 5.02004
Timestep Consumption Time: 2.05808
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.07812

Cumulative Model Updates: 43902
Cumulative Timesteps: 366530415

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.71883
Policy Entropy: 1.06695
Value Function Loss: 0.03052

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.17079
Policy Update Magnitude: 0.09580
Value Function Update Magnitude: 0.17603

Collected Steps per Second: 9845.26750
Overall Steps per Second: 7087.14327

Timestep Collection Time: 5.07879
Timestep Consumption Time: 1.97653
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.05531

Cumulative Model Updates: 43908
Cumulative Timesteps: 366580417

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.44087
Policy Entropy: 1.05919
Value Function Loss: 0.03150

Mean KL Divergence: 0.03368
SB3 Clip Fraction: 0.17869
Policy Update Magnitude: 0.09713
Value Function Update Magnitude: 0.20126

Collected Steps per Second: 10635.52354
Overall Steps per Second: 7338.12376

Timestep Collection Time: 4.70489
Timestep Consumption Time: 2.11415
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 6.81905

Cumulative Model Updates: 43914
Cumulative Timesteps: 366630456

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.78298
Policy Entropy: 1.06218
Value Function Loss: 0.03255

Mean KL Divergence: 0.02608
SB3 Clip Fraction: 0.16194
Policy Update Magnitude: 0.10579
Value Function Update Magnitude: 0.17996

Collected Steps per Second: 9959.02428
Overall Steps per Second: 7147.16352

Timestep Collection Time: 5.02228
Timestep Consumption Time: 1.97588
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 6.99816

Cumulative Model Updates: 43920
Cumulative Timesteps: 366680473

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.13428
Policy Entropy: 1.05457
Value Function Loss: 0.02938

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.10547
Value Function Update Magnitude: 0.18212

Collected Steps per Second: 9752.59860
Overall Steps per Second: 6989.06207

Timestep Collection Time: 5.12868
Timestep Consumption Time: 2.02793
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.15661

Cumulative Model Updates: 43926
Cumulative Timesteps: 366730491

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.81886
Policy Entropy: 1.05740
Value Function Loss: 0.02875

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.10746
Value Function Update Magnitude: 0.17699

Collected Steps per Second: 10583.55648
Overall Steps per Second: 7361.41370

Timestep Collection Time: 4.72752
Timestep Consumption Time: 2.06927
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 6.79679

Cumulative Model Updates: 43932
Cumulative Timesteps: 366780525

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.27561
Policy Entropy: 1.05054
Value Function Loss: 0.02879

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.10582
Value Function Update Magnitude: 0.16613

Collected Steps per Second: 9924.07738
Overall Steps per Second: 7066.81233

Timestep Collection Time: 5.03865
Timestep Consumption Time: 2.03724
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 7.07589

Cumulative Model Updates: 43938
Cumulative Timesteps: 366830529

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 366830529...
Checkpoint 366830529 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.03534
Policy Entropy: 1.03984
Value Function Loss: 0.03102

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.10686
Value Function Update Magnitude: 0.15761

Collected Steps per Second: 9936.17597
Overall Steps per Second: 6945.82905

Timestep Collection Time: 5.03413
Timestep Consumption Time: 2.16731
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.20144

Cumulative Model Updates: 43944
Cumulative Timesteps: 366880549

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.06387
Policy Entropy: 1.04199
Value Function Loss: 0.03147

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.10577
Value Function Update Magnitude: 0.16207

Collected Steps per Second: 10333.95525
Overall Steps per Second: 3648.32436

Timestep Collection Time: 4.84093
Timestep Consumption Time: 8.87111
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 13.71205

Cumulative Model Updates: 43950
Cumulative Timesteps: 366930575

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.57027
Policy Entropy: 1.03510
Value Function Loss: 0.03086

Mean KL Divergence: 0.02662
SB3 Clip Fraction: 0.17094
Policy Update Magnitude: 0.09912
Value Function Update Magnitude: 0.14497

Collected Steps per Second: 9854.74768
Overall Steps per Second: 5527.36207

Timestep Collection Time: 5.07380
Timestep Consumption Time: 3.97229
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 9.04609

Cumulative Model Updates: 43956
Cumulative Timesteps: 366980576

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.06582
Policy Entropy: 1.04917
Value Function Loss: 0.03074

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.09418
Value Function Update Magnitude: 0.15614

Collected Steps per Second: 9796.38202
Overall Steps per Second: 7002.57366

Timestep Collection Time: 5.10689
Timestep Consumption Time: 2.03749
PPO Batch Consumption Time: 0.02870
Total Iteration Time: 7.14437

Cumulative Model Updates: 43962
Cumulative Timesteps: 367030605

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.94166
Policy Entropy: 1.05053
Value Function Loss: 0.03005

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.17358
Policy Update Magnitude: 0.10071
Value Function Update Magnitude: 0.16419

Collected Steps per Second: 10333.03174
Overall Steps per Second: 7228.21643

Timestep Collection Time: 4.84021
Timestep Consumption Time: 2.07907
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 6.91927

Cumulative Model Updates: 43968
Cumulative Timesteps: 367080619

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.10086
Policy Entropy: 1.05982
Value Function Loss: 0.03099

Mean KL Divergence: 0.03229
SB3 Clip Fraction: 0.19356
Policy Update Magnitude: 0.09650
Value Function Update Magnitude: 0.16557

Collected Steps per Second: 9700.04467
Overall Steps per Second: 6910.31746

Timestep Collection Time: 5.15668
Timestep Consumption Time: 2.08177
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.23845

Cumulative Model Updates: 43974
Cumulative Timesteps: 367130639

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.10016
Policy Entropy: 1.06343
Value Function Loss: 0.03063

Mean KL Divergence: 0.03545
SB3 Clip Fraction: 0.20425
Policy Update Magnitude: 0.08687
Value Function Update Magnitude: 0.16794

Collected Steps per Second: 10224.22775
Overall Steps per Second: 7285.65626

Timestep Collection Time: 4.89171
Timestep Consumption Time: 1.97301
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.86472

Cumulative Model Updates: 43980
Cumulative Timesteps: 367180653

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.93564
Policy Entropy: 1.06931
Value Function Loss: 0.03120

Mean KL Divergence: 0.03355
SB3 Clip Fraction: 0.20247
Policy Update Magnitude: 0.09049
Value Function Update Magnitude: 0.16159

Collected Steps per Second: 10350.59509
Overall Steps per Second: 7228.19357

Timestep Collection Time: 4.83209
Timestep Consumption Time: 2.08734
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 6.91943

Cumulative Model Updates: 43986
Cumulative Timesteps: 367230668

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.30283
Policy Entropy: 1.05942
Value Function Loss: 0.02898

Mean KL Divergence: 0.03874
SB3 Clip Fraction: 0.20787
Policy Update Magnitude: 0.09217
Value Function Update Magnitude: 0.16139

Collected Steps per Second: 9896.88998
Overall Steps per Second: 7047.27224

Timestep Collection Time: 5.05381
Timestep Consumption Time: 2.04355
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.09736

Cumulative Model Updates: 43992
Cumulative Timesteps: 367280685

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.48576
Policy Entropy: 1.05494
Value Function Loss: 0.02919

Mean KL Divergence: 0.03255
SB3 Clip Fraction: 0.19688
Policy Update Magnitude: 0.08744
Value Function Update Magnitude: 0.15367

Collected Steps per Second: 9564.63430
Overall Steps per Second: 6831.80455

Timestep Collection Time: 5.22832
Timestep Consumption Time: 2.09141
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.31974

Cumulative Model Updates: 43998
Cumulative Timesteps: 367330692

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 367330692...
Checkpoint 367330692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.94656
Policy Entropy: 1.05678
Value Function Loss: 0.02825

Mean KL Divergence: 0.03531
SB3 Clip Fraction: 0.20120
Policy Update Magnitude: 0.08424
Value Function Update Magnitude: 0.14668

Collected Steps per Second: 11706.60271
Overall Steps per Second: 8056.22382

Timestep Collection Time: 4.27272
Timestep Consumption Time: 1.93602
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.20874

Cumulative Model Updates: 44004
Cumulative Timesteps: 367380711

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.57259
Policy Entropy: 1.05721
Value Function Loss: 0.02821

Mean KL Divergence: 0.02339
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.08964
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 10422.27041
Overall Steps per Second: 7318.60065

Timestep Collection Time: 4.79895
Timestep Consumption Time: 2.03514
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 6.83409

Cumulative Model Updates: 44010
Cumulative Timesteps: 367430727

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.77656
Policy Entropy: 1.05676
Value Function Loss: 0.02745

Mean KL Divergence: 0.02050
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.09877
Value Function Update Magnitude: 0.14303

Collected Steps per Second: 9851.22048
Overall Steps per Second: 7046.78680

Timestep Collection Time: 5.07907
Timestep Consumption Time: 2.02133
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.10040

Cumulative Model Updates: 44016
Cumulative Timesteps: 367480762

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.77584
Policy Entropy: 1.05201
Value Function Loss: 0.02851

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.10180
Value Function Update Magnitude: 0.14124

Collected Steps per Second: 10345.86784
Overall Steps per Second: 7210.98116

Timestep Collection Time: 4.83304
Timestep Consumption Time: 2.10111
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 6.93415

Cumulative Model Updates: 44022
Cumulative Timesteps: 367530764

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.96865
Policy Entropy: 1.04869
Value Function Loss: 0.02961

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.10543
Value Function Update Magnitude: 0.14074

Collected Steps per Second: 10005.62018
Overall Steps per Second: 7074.37461

Timestep Collection Time: 4.99949
Timestep Consumption Time: 2.07152
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 7.07101

Cumulative Model Updates: 44028
Cumulative Timesteps: 367580787

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.91684
Policy Entropy: 1.04435
Value Function Loss: 0.03042

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.15823
Policy Update Magnitude: 0.10036
Value Function Update Magnitude: 0.14427

Collected Steps per Second: 9641.85098
Overall Steps per Second: 6918.75549

Timestep Collection Time: 5.19050
Timestep Consumption Time: 2.04288
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.23338

Cumulative Model Updates: 44034
Cumulative Timesteps: 367630833

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.17406
Policy Entropy: 1.04447
Value Function Loss: 0.02998

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.09949
Value Function Update Magnitude: 0.15048

Collected Steps per Second: 10384.68540
Overall Steps per Second: 7274.37936

Timestep Collection Time: 4.81652
Timestep Consumption Time: 2.05940
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 6.87591

Cumulative Model Updates: 44040
Cumulative Timesteps: 367680851

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.57299
Policy Entropy: 1.03619
Value Function Loss: 0.03095

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.10735
Value Function Update Magnitude: 0.14787

Collected Steps per Second: 10070.74537
Overall Steps per Second: 7159.87158

Timestep Collection Time: 4.96756
Timestep Consumption Time: 2.01958
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 6.98714

Cumulative Model Updates: 44046
Cumulative Timesteps: 367730878

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.69015
Policy Entropy: 1.03120
Value Function Loss: 0.03264

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.11046
Value Function Update Magnitude: 0.14803

Collected Steps per Second: 9777.67791
Overall Steps per Second: 7020.19396

Timestep Collection Time: 5.11635
Timestep Consumption Time: 2.00967
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.12601

Cumulative Model Updates: 44052
Cumulative Timesteps: 367780904

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.96316
Policy Entropy: 1.02865
Value Function Loss: 0.03358

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.10853
Value Function Update Magnitude: 0.14801

Collected Steps per Second: 10327.67434
Overall Steps per Second: 7219.67034

Timestep Collection Time: 4.84136
Timestep Consumption Time: 2.08416
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 6.92552

Cumulative Model Updates: 44058
Cumulative Timesteps: 367830904

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 367830904...
Checkpoint 367830904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.89129
Policy Entropy: 1.02761
Value Function Loss: 0.03257

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.17466
Policy Update Magnitude: 0.09811
Value Function Update Magnitude: 0.15287

Collected Steps per Second: 9808.35083
Overall Steps per Second: 7014.27324

Timestep Collection Time: 5.09841
Timestep Consumption Time: 2.03091
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.12932

Cumulative Model Updates: 44064
Cumulative Timesteps: 367880911

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.29941
Policy Entropy: 1.03142
Value Function Loss: 0.03152

Mean KL Divergence: 0.03054
SB3 Clip Fraction: 0.18728
Policy Update Magnitude: 0.09133
Value Function Update Magnitude: 0.15942

Collected Steps per Second: 9761.57390
Overall Steps per Second: 7000.69002

Timestep Collection Time: 5.12325
Timestep Consumption Time: 2.02047
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 7.14372

Cumulative Model Updates: 44070
Cumulative Timesteps: 367930922

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.02515
Policy Entropy: 1.02782
Value Function Loss: 0.03028

Mean KL Divergence: 0.02979
SB3 Clip Fraction: 0.17927
Policy Update Magnitude: 0.08845
Value Function Update Magnitude: 0.15254

Collected Steps per Second: 10386.17745
Overall Steps per Second: 7240.56446

Timestep Collection Time: 4.81457
Timestep Consumption Time: 2.09166
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 6.90623

Cumulative Model Updates: 44076
Cumulative Timesteps: 367980927

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.08565
Policy Entropy: 1.04774
Value Function Loss: 0.03031

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.17275
Policy Update Magnitude: 0.09141
Value Function Update Magnitude: 0.15965

Collected Steps per Second: 9873.18221
Overall Steps per Second: 6973.34963

Timestep Collection Time: 5.06463
Timestep Consumption Time: 2.10610
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.17073

Cumulative Model Updates: 44082
Cumulative Timesteps: 368030931

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.12416
Policy Entropy: 1.05557
Value Function Loss: 0.03027

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.10717
Value Function Update Magnitude: 0.15742

Collected Steps per Second: 9788.65308
Overall Steps per Second: 6985.17148

Timestep Collection Time: 5.10857
Timestep Consumption Time: 2.05031
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.15888

Cumulative Model Updates: 44088
Cumulative Timesteps: 368080937

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.53914
Policy Entropy: 1.06672
Value Function Loss: 0.03006

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.10586
Value Function Update Magnitude: 0.14830

Collected Steps per Second: 10263.68202
Overall Steps per Second: 7201.60754

Timestep Collection Time: 4.87515
Timestep Consumption Time: 2.07288
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 6.94803

Cumulative Model Updates: 44094
Cumulative Timesteps: 368130974

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.17321
Policy Entropy: 1.06804
Value Function Loss: 0.02931

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.10574
Value Function Update Magnitude: 0.14398

Collected Steps per Second: 10109.38930
Overall Steps per Second: 7205.41074

Timestep Collection Time: 4.95035
Timestep Consumption Time: 1.99513
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 6.94547

Cumulative Model Updates: 44100
Cumulative Timesteps: 368181019

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.34075
Policy Entropy: 1.06729
Value Function Loss: 0.02869

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.10405
Value Function Update Magnitude: 0.14473

Collected Steps per Second: 9761.32718
Overall Steps per Second: 7030.34435

Timestep Collection Time: 5.12410
Timestep Consumption Time: 1.99049
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.11459

Cumulative Model Updates: 44106
Cumulative Timesteps: 368231037

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.90444
Policy Entropy: 1.07171
Value Function Loss: 0.02870

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.10296
Value Function Update Magnitude: 0.15108

Collected Steps per Second: 10472.46161
Overall Steps per Second: 7282.43244

Timestep Collection Time: 4.77710
Timestep Consumption Time: 2.09258
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 6.86968

Cumulative Model Updates: 44112
Cumulative Timesteps: 368281065

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.71693
Policy Entropy: 1.06788
Value Function Loss: 0.02998

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.16661
Policy Update Magnitude: 0.10174
Value Function Update Magnitude: 0.14777

Collected Steps per Second: 9767.36865
Overall Steps per Second: 7005.23122

Timestep Collection Time: 5.12257
Timestep Consumption Time: 2.01981
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.14238

Cumulative Model Updates: 44118
Cumulative Timesteps: 368331099

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 368331099...
Checkpoint 368331099 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.91654
Policy Entropy: 1.06683
Value Function Loss: 0.02994

Mean KL Divergence: 0.03799
SB3 Clip Fraction: 0.20384
Policy Update Magnitude: 0.09003
Value Function Update Magnitude: 0.14536

Collected Steps per Second: 9692.12946
Overall Steps per Second: 6938.44154

Timestep Collection Time: 5.16037
Timestep Consumption Time: 2.04802
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.20839

Cumulative Model Updates: 44124
Cumulative Timesteps: 368381114

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.54747
Policy Entropy: 1.05347
Value Function Loss: 0.02985

Mean KL Divergence: 0.04611
SB3 Clip Fraction: 0.21894
Policy Update Magnitude: 0.08612
Value Function Update Magnitude: 0.14576

Collected Steps per Second: 10413.55604
Overall Steps per Second: 7281.94009

Timestep Collection Time: 4.80211
Timestep Consumption Time: 2.06516
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 6.86726

Cumulative Model Updates: 44130
Cumulative Timesteps: 368431121

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.53248
Policy Entropy: 1.07097
Value Function Loss: 0.02913

Mean KL Divergence: 0.02952
SB3 Clip Fraction: 0.18382
Policy Update Magnitude: 0.09393
Value Function Update Magnitude: 0.14882

Collected Steps per Second: 9844.59795
Overall Steps per Second: 7072.22884

Timestep Collection Time: 5.08157
Timestep Consumption Time: 1.99201
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.07358

Cumulative Model Updates: 44136
Cumulative Timesteps: 368481147

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.68889
Policy Entropy: 1.07740
Value Function Loss: 0.02991

Mean KL Divergence: 0.03002
SB3 Clip Fraction: 0.17838
Policy Update Magnitude: 0.10419
Value Function Update Magnitude: 0.14683

Collected Steps per Second: 9788.08274
Overall Steps per Second: 7024.57434

Timestep Collection Time: 5.10887
Timestep Consumption Time: 2.00986
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.11872

Cumulative Model Updates: 44142
Cumulative Timesteps: 368531153

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.82361
Policy Entropy: 1.08480
Value Function Loss: 0.02996

Mean KL Divergence: 0.02276
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.09976
Value Function Update Magnitude: 0.14785

Collected Steps per Second: 10434.32647
Overall Steps per Second: 7270.68844

Timestep Collection Time: 4.79571
Timestep Consumption Time: 2.08672
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 6.88243

Cumulative Model Updates: 44148
Cumulative Timesteps: 368581193

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.35674
Policy Entropy: 1.07993
Value Function Loss: 0.03065

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.10370
Value Function Update Magnitude: 0.15314

Collected Steps per Second: 9979.88335
Overall Steps per Second: 7039.06857

Timestep Collection Time: 5.01318
Timestep Consumption Time: 2.09443
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.10762

Cumulative Model Updates: 44154
Cumulative Timesteps: 368631224

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.73593
Policy Entropy: 1.07842
Value Function Loss: 0.03204

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.10893
Value Function Update Magnitude: 0.16959

Collected Steps per Second: 9844.14513
Overall Steps per Second: 7019.67669

Timestep Collection Time: 5.08292
Timestep Consumption Time: 2.04519
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.12811

Cumulative Model Updates: 44160
Cumulative Timesteps: 368681261

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.28195
Policy Entropy: 1.07392
Value Function Loss: 0.03311

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.11237
Value Function Update Magnitude: 0.17800

Collected Steps per Second: 10384.42535
Overall Steps per Second: 7316.03666

Timestep Collection Time: 4.81702
Timestep Consumption Time: 2.02029
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 6.83731

Cumulative Model Updates: 44166
Cumulative Timesteps: 368731283

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.25063
Policy Entropy: 1.06937
Value Function Loss: 0.03177

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.11053
Value Function Update Magnitude: 0.17280

Collected Steps per Second: 9870.52829
Overall Steps per Second: 7014.01582

Timestep Collection Time: 5.06994
Timestep Consumption Time: 2.06477
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.13471

Cumulative Model Updates: 44172
Cumulative Timesteps: 368781326

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.33099
Policy Entropy: 1.06887
Value Function Loss: 0.03127

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.10683
Value Function Update Magnitude: 0.17539

Collected Steps per Second: 9943.01272
Overall Steps per Second: 7144.88916

Timestep Collection Time: 5.02996
Timestep Consumption Time: 1.96986
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 6.99983

Cumulative Model Updates: 44178
Cumulative Timesteps: 368831339

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 368831339...
Checkpoint 368831339 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.41299
Policy Entropy: 1.09012
Value Function Loss: 0.03010

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.09973
Value Function Update Magnitude: 0.17864

Collected Steps per Second: 10442.82260
Overall Steps per Second: 7277.80913

Timestep Collection Time: 4.78922
Timestep Consumption Time: 2.08276
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 6.87199

Cumulative Model Updates: 44184
Cumulative Timesteps: 368881352

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.80986
Policy Entropy: 1.09283
Value Function Loss: 0.02929

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.10270
Value Function Update Magnitude: 0.16766

Collected Steps per Second: 9763.36733
Overall Steps per Second: 6933.39450

Timestep Collection Time: 5.12139
Timestep Consumption Time: 2.09037
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.21176

Cumulative Model Updates: 44190
Cumulative Timesteps: 368931354

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.85194
Policy Entropy: 1.09743
Value Function Loss: 0.02874

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.10180
Value Function Update Magnitude: 0.15297

Collected Steps per Second: 9768.53115
Overall Steps per Second: 6960.96374

Timestep Collection Time: 5.12257
Timestep Consumption Time: 2.06609
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.18866

Cumulative Model Updates: 44196
Cumulative Timesteps: 368981394

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.17517
Policy Entropy: 1.09417
Value Function Loss: 0.02995

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.10372
Value Function Update Magnitude: 0.14804

Collected Steps per Second: 10368.00228
Overall Steps per Second: 7289.07148

Timestep Collection Time: 4.82446
Timestep Consumption Time: 2.03787
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 6.86233

Cumulative Model Updates: 44202
Cumulative Timesteps: 369031414

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.71875
Policy Entropy: 1.10701
Value Function Loss: 0.03197

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.10354
Value Function Update Magnitude: 0.14942

Collected Steps per Second: 9857.59472
Overall Steps per Second: 7017.37249

Timestep Collection Time: 5.07477
Timestep Consumption Time: 2.05397
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.12874

Cumulative Model Updates: 44208
Cumulative Timesteps: 369081439

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.29731
Policy Entropy: 1.10702
Value Function Loss: 0.03256

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.10391
Value Function Update Magnitude: 0.14812

Collected Steps per Second: 9780.47758
Overall Steps per Second: 1674.13207

Timestep Collection Time: 5.11304
Timestep Consumption Time: 24.75796
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 29.87100

Cumulative Model Updates: 44214
Cumulative Timesteps: 369131447

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.51804
Policy Entropy: 1.09987
Value Function Loss: 0.03160

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.14954
Policy Update Magnitude: 0.10552
Value Function Update Magnitude: 0.14287

Collected Steps per Second: 10483.44502
Overall Steps per Second: 7365.93746

Timestep Collection Time: 4.77362
Timestep Consumption Time: 2.02035
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 6.79398

Cumulative Model Updates: 44220
Cumulative Timesteps: 369181491

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.63081
Policy Entropy: 1.09573
Value Function Loss: 0.03148

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.10124
Value Function Update Magnitude: 0.13964

Collected Steps per Second: 9990.40114
Overall Steps per Second: 7114.03926

Timestep Collection Time: 5.00701
Timestep Consumption Time: 2.02444
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.03145

Cumulative Model Updates: 44226
Cumulative Timesteps: 369231513

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.79550
Policy Entropy: 1.10573
Value Function Loss: 0.03045

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.09839
Value Function Update Magnitude: 0.14463

Collected Steps per Second: 9663.20803
Overall Steps per Second: 6955.19168

Timestep Collection Time: 5.17768
Timestep Consumption Time: 2.01594
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.19362

Cumulative Model Updates: 44232
Cumulative Timesteps: 369281546

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.21079
Policy Entropy: 1.10829
Value Function Loss: 0.03037

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.10392
Value Function Update Magnitude: 0.15440

Collected Steps per Second: 10314.12840
Overall Steps per Second: 7163.38005

Timestep Collection Time: 4.84956
Timestep Consumption Time: 2.13304
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.98260

Cumulative Model Updates: 44238
Cumulative Timesteps: 369331565

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 369331565...
Checkpoint 369331565 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.41876
Policy Entropy: 1.10674
Value Function Loss: 0.03132

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.10515
Value Function Update Magnitude: 0.15651

Collected Steps per Second: 9911.98808
Overall Steps per Second: 7073.40943

Timestep Collection Time: 5.04712
Timestep Consumption Time: 2.02542
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 7.07254

Cumulative Model Updates: 44244
Cumulative Timesteps: 369381592

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.60516
Policy Entropy: 1.10196
Value Function Loss: 0.03158

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.09981
Value Function Update Magnitude: 0.16688

Collected Steps per Second: 9695.64405
Overall Steps per Second: 6976.90903

Timestep Collection Time: 5.15871
Timestep Consumption Time: 2.01023
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.16893

Cumulative Model Updates: 44250
Cumulative Timesteps: 369431609

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.04655
Policy Entropy: 1.10960
Value Function Loss: 0.03132

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.10412
Value Function Update Magnitude: 0.18316

Collected Steps per Second: 10257.19111
Overall Steps per Second: 7190.42418

Timestep Collection Time: 4.87804
Timestep Consumption Time: 2.08052
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.95856

Cumulative Model Updates: 44256
Cumulative Timesteps: 369481644

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.17393
Policy Entropy: 1.11415
Value Function Loss: 0.03128

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.10017
Value Function Update Magnitude: 0.18771

Collected Steps per Second: 9803.00474
Overall Steps per Second: 7004.26606

Timestep Collection Time: 5.10333
Timestep Consumption Time: 2.03917
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.14250

Cumulative Model Updates: 44262
Cumulative Timesteps: 369531672

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.08303
Policy Entropy: 1.12480
Value Function Loss: 0.03108

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.10297
Value Function Update Magnitude: 0.18375

Collected Steps per Second: 9933.31847
Overall Steps per Second: 7223.47605

Timestep Collection Time: 5.03457
Timestep Consumption Time: 1.88869
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 6.92326

Cumulative Model Updates: 44268
Cumulative Timesteps: 369581682

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.33891
Policy Entropy: 1.11903
Value Function Loss: 0.02966

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.10307
Value Function Update Magnitude: 0.17958

Collected Steps per Second: 10544.08317
Overall Steps per Second: 7325.06564

Timestep Collection Time: 4.74380
Timestep Consumption Time: 2.08467
PPO Batch Consumption Time: 0.03208
Total Iteration Time: 6.82847

Cumulative Model Updates: 44274
Cumulative Timesteps: 369631701

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.87406
Policy Entropy: 1.14271
Value Function Loss: 0.03050

Mean KL Divergence: 0.03496
SB3 Clip Fraction: 0.18184
Policy Update Magnitude: 0.10038
Value Function Update Magnitude: 0.16595

Collected Steps per Second: 9979.84922
Overall Steps per Second: 7118.50244

Timestep Collection Time: 5.01070
Timestep Consumption Time: 2.01410
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.02479

Cumulative Model Updates: 44280
Cumulative Timesteps: 369681707

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.64088
Policy Entropy: 1.13789
Value Function Loss: 0.02952

Mean KL Divergence: 0.04949
SB3 Clip Fraction: 0.19614
Policy Update Magnitude: 0.10044
Value Function Update Magnitude: 0.15542

Collected Steps per Second: 9677.28029
Overall Steps per Second: 6964.92684

Timestep Collection Time: 5.16963
Timestep Consumption Time: 2.01321
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.18285

Cumulative Model Updates: 44286
Cumulative Timesteps: 369731735

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.51832
Policy Entropy: 1.14488
Value Function Loss: 0.03100

Mean KL Divergence: 0.02704
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.10233
Value Function Update Magnitude: 0.16142

Collected Steps per Second: 10316.36880
Overall Steps per Second: 7248.56409

Timestep Collection Time: 4.84909
Timestep Consumption Time: 2.05228
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 6.90137

Cumulative Model Updates: 44292
Cumulative Timesteps: 369781760

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.03289
Policy Entropy: 1.13616
Value Function Loss: 0.02931

Mean KL Divergence: 0.02391
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.10421
Value Function Update Magnitude: 0.15906

Collected Steps per Second: 10220.78050
Overall Steps per Second: 7201.02211

Timestep Collection Time: 4.89336
Timestep Consumption Time: 2.05204
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 6.94540

Cumulative Model Updates: 44298
Cumulative Timesteps: 369831774

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 369831774...
Checkpoint 369831774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.03795
Policy Entropy: 1.14387
Value Function Loss: 0.03123

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.10485
Value Function Update Magnitude: 0.15518

Collected Steps per Second: 9782.06332
Overall Steps per Second: 7018.56509

Timestep Collection Time: 5.11232
Timestep Consumption Time: 2.01293
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.12525

Cumulative Model Updates: 44304
Cumulative Timesteps: 369881783

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.33911
Policy Entropy: 1.13657
Value Function Loss: 0.03068

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.10083
Value Function Update Magnitude: 0.15125

Collected Steps per Second: 10267.24669
Overall Steps per Second: 7198.60845

Timestep Collection Time: 4.87054
Timestep Consumption Time: 2.07622
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 6.94676

Cumulative Model Updates: 44310
Cumulative Timesteps: 369931790

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.33425
Policy Entropy: 1.13869
Value Function Loss: 0.03136

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.09220
Value Function Update Magnitude: 0.15129

Collected Steps per Second: 10100.75798
Overall Steps per Second: 7145.61031

Timestep Collection Time: 4.95329
Timestep Consumption Time: 2.04849
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.00178

Cumulative Model Updates: 44316
Cumulative Timesteps: 369981822

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.09096
Policy Entropy: 1.13837
Value Function Loss: 0.03230

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.16378
Policy Update Magnitude: 0.08259
Value Function Update Magnitude: 0.14959

Collected Steps per Second: 10060.71277
Overall Steps per Second: 7206.48912

Timestep Collection Time: 4.97321
Timestep Consumption Time: 1.96970
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 6.94291

Cumulative Model Updates: 44322
Cumulative Timesteps: 370031856

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.03778
Policy Entropy: 1.13450
Value Function Loss: 0.03123

Mean KL Divergence: 0.02845
SB3 Clip Fraction: 0.17162
Policy Update Magnitude: 0.08049
Value Function Update Magnitude: 0.14636

Collected Steps per Second: 10598.81886
Overall Steps per Second: 7364.54554

Timestep Collection Time: 4.71949
Timestep Consumption Time: 2.07265
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.79214

Cumulative Model Updates: 44328
Cumulative Timesteps: 370081877

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.49103
Policy Entropy: 1.13518
Value Function Loss: 0.03119

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.09374
Value Function Update Magnitude: 0.14045

Collected Steps per Second: 9857.55626
Overall Steps per Second: 7013.43932

Timestep Collection Time: 5.07519
Timestep Consumption Time: 2.05811
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.13330

Cumulative Model Updates: 44334
Cumulative Timesteps: 370131906

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.98809
Policy Entropy: 1.13750
Value Function Loss: 0.03078

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.10787
Value Function Update Magnitude: 0.14681

Collected Steps per Second: 9667.41161
Overall Steps per Second: 6992.30315

Timestep Collection Time: 5.17377
Timestep Consumption Time: 1.97938
PPO Batch Consumption Time: 0.02401
Total Iteration Time: 7.15315

Cumulative Model Updates: 44340
Cumulative Timesteps: 370181923

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.54869
Policy Entropy: 1.13456
Value Function Loss: 0.03201

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.09993
Value Function Update Magnitude: 0.14429

Collected Steps per Second: 10459.28597
Overall Steps per Second: 7268.34464

Timestep Collection Time: 4.78073
Timestep Consumption Time: 2.09883
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 6.87956

Cumulative Model Updates: 44346
Cumulative Timesteps: 370231926

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.62904
Policy Entropy: 1.13423
Value Function Loss: 0.03319

Mean KL Divergence: 0.02655
SB3 Clip Fraction: 0.16048
Policy Update Magnitude: 0.08389
Value Function Update Magnitude: 0.14717

Collected Steps per Second: 10281.01857
Overall Steps per Second: 7335.63412

Timestep Collection Time: 4.86596
Timestep Consumption Time: 1.95377
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 6.81972

Cumulative Model Updates: 44352
Cumulative Timesteps: 370281953

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.66355
Policy Entropy: 1.13396
Value Function Loss: 0.03193

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.17265
Policy Update Magnitude: 0.08460
Value Function Update Magnitude: 0.15607

Collected Steps per Second: 9818.28404
Overall Steps per Second: 7033.50218

Timestep Collection Time: 5.09386
Timestep Consumption Time: 2.01682
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.11068

Cumulative Model Updates: 44358
Cumulative Timesteps: 370331966

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 370331966...
Checkpoint 370331966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.90136
Policy Entropy: 1.12537
Value Function Loss: 0.03009

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.09317
Value Function Update Magnitude: 0.15986

Collected Steps per Second: 10371.16167
Overall Steps per Second: 7197.42676

Timestep Collection Time: 4.82492
Timestep Consumption Time: 2.12757
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 6.95248

Cumulative Model Updates: 44364
Cumulative Timesteps: 370382006

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.43517
Policy Entropy: 1.11962
Value Function Loss: 0.02831

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.10602
Value Function Update Magnitude: 0.15615

Collected Steps per Second: 9880.36332
Overall Steps per Second: 7020.18399

Timestep Collection Time: 5.06317
Timestep Consumption Time: 2.06285
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.12602

Cumulative Model Updates: 44370
Cumulative Timesteps: 370432032

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.08160
Policy Entropy: 1.12411
Value Function Loss: 0.02920

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.09685
Value Function Update Magnitude: 0.15173

Collected Steps per Second: 9851.25318
Overall Steps per Second: 7008.63394

Timestep Collection Time: 5.07885
Timestep Consumption Time: 2.05992
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.13877

Cumulative Model Updates: 44376
Cumulative Timesteps: 370482065

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.81359
Policy Entropy: 1.12445
Value Function Loss: 0.02993

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.09157
Value Function Update Magnitude: 0.14655

Collected Steps per Second: 10333.71566
Overall Steps per Second: 7272.29272

Timestep Collection Time: 4.83853
Timestep Consumption Time: 2.03688
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 6.87541

Cumulative Model Updates: 44382
Cumulative Timesteps: 370532065

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.38809
Policy Entropy: 1.11394
Value Function Loss: 0.03072

Mean KL Divergence: 0.03153
SB3 Clip Fraction: 0.17092
Policy Update Magnitude: 0.09394
Value Function Update Magnitude: 0.16302

Collected Steps per Second: 9844.04855
Overall Steps per Second: 7090.78856

Timestep Collection Time: 5.08013
Timestep Consumption Time: 1.97255
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.05267

Cumulative Model Updates: 44388
Cumulative Timesteps: 370582074

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.74347
Policy Entropy: 1.10674
Value Function Loss: 0.02825

Mean KL Divergence: 0.03283
SB3 Clip Fraction: 0.18308
Policy Update Magnitude: 0.09059
Value Function Update Magnitude: 0.16563

Collected Steps per Second: 9769.99450
Overall Steps per Second: 7003.25658

Timestep Collection Time: 5.12119
Timestep Consumption Time: 2.02320
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.14439

Cumulative Model Updates: 44394
Cumulative Timesteps: 370632108

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.89680
Policy Entropy: 1.10169
Value Function Loss: 0.02711

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.15821
Policy Update Magnitude: 0.09187
Value Function Update Magnitude: 0.16034

Collected Steps per Second: 10545.35967
Overall Steps per Second: 7336.05869

Timestep Collection Time: 4.74218
Timestep Consumption Time: 2.07456
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 6.81674

Cumulative Model Updates: 44400
Cumulative Timesteps: 370682116

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.81216
Policy Entropy: 1.09049
Value Function Loss: 0.02759

Mean KL Divergence: 0.02487
SB3 Clip Fraction: 0.15586
Policy Update Magnitude: 0.09598
Value Function Update Magnitude: 0.15339

Collected Steps per Second: 10040.99819
Overall Steps per Second: 7170.12754

Timestep Collection Time: 4.98088
Timestep Consumption Time: 1.99431
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.97519

Cumulative Model Updates: 44406
Cumulative Timesteps: 370732129

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.94985
Policy Entropy: 1.08965
Value Function Loss: 0.02826

Mean KL Divergence: 0.03250
SB3 Clip Fraction: 0.18920
Policy Update Magnitude: 0.09117
Value Function Update Magnitude: 0.14712

Collected Steps per Second: 9848.86648
Overall Steps per Second: 7063.84358

Timestep Collection Time: 5.07957
Timestep Consumption Time: 2.00269
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.08226

Cumulative Model Updates: 44412
Cumulative Timesteps: 370782157

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.68038
Policy Entropy: 1.08592
Value Function Loss: 0.02935

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.18051
Policy Update Magnitude: 0.08931
Value Function Update Magnitude: 0.14826

Collected Steps per Second: 10609.47901
Overall Steps per Second: 7375.65554

Timestep Collection Time: 4.71607
Timestep Consumption Time: 2.06774
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.78380

Cumulative Model Updates: 44418
Cumulative Timesteps: 370832192

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 370832192...
Checkpoint 370832192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.05990
Policy Entropy: 1.10305
Value Function Loss: 0.02999

Mean KL Divergence: 0.03488
SB3 Clip Fraction: 0.19804
Policy Update Magnitude: 0.09120
Value Function Update Magnitude: 0.15589

Collected Steps per Second: 9827.86270
Overall Steps per Second: 6891.56428

Timestep Collection Time: 5.08981
Timestep Consumption Time: 2.16862
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.25844

Cumulative Model Updates: 44424
Cumulative Timesteps: 370882214

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.21605
Policy Entropy: 1.09360
Value Function Loss: 0.03067

Mean KL Divergence: 0.03985
SB3 Clip Fraction: 0.20682
Policy Update Magnitude: 0.09307
Value Function Update Magnitude: 0.16611

Collected Steps per Second: 9872.56405
Overall Steps per Second: 6999.68458

Timestep Collection Time: 5.06495
Timestep Consumption Time: 2.07880
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.14375

Cumulative Model Updates: 44430
Cumulative Timesteps: 370932218

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.44139
Policy Entropy: 1.10084
Value Function Loss: 0.03213

Mean KL Divergence: 0.03520
SB3 Clip Fraction: 0.18739
Policy Update Magnitude: 0.09887
Value Function Update Magnitude: 0.15858

Collected Steps per Second: 10322.65691
Overall Steps per Second: 7236.05531

Timestep Collection Time: 4.84691
Timestep Consumption Time: 2.06749
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 6.91440

Cumulative Model Updates: 44436
Cumulative Timesteps: 370982251

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.77396
Policy Entropy: 1.10335
Value Function Loss: 0.03290

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.10699
Value Function Update Magnitude: 0.16418

Collected Steps per Second: 9863.05910
Overall Steps per Second: 7048.16509

Timestep Collection Time: 5.07155
Timestep Consumption Time: 2.02547
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.09702

Cumulative Model Updates: 44442
Cumulative Timesteps: 371032272

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.07136
Policy Entropy: 1.10401
Value Function Loss: 0.03231

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.11362
Value Function Update Magnitude: 0.16726

Collected Steps per Second: 9754.90650
Overall Steps per Second: 7065.57756

Timestep Collection Time: 5.12655
Timestep Consumption Time: 1.95129
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.07784

Cumulative Model Updates: 44448
Cumulative Timesteps: 371082281

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.55623
Policy Entropy: 1.10571
Value Function Loss: 0.03102

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.11019
Value Function Update Magnitude: 0.16278

Collected Steps per Second: 10596.25786
Overall Steps per Second: 7376.50287

Timestep Collection Time: 4.72176
Timestep Consumption Time: 2.06099
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.78275

Cumulative Model Updates: 44454
Cumulative Timesteps: 371132314

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.91802
Policy Entropy: 1.09186
Value Function Loss: 0.02878

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.10526
Value Function Update Magnitude: 0.17289

Collected Steps per Second: 9996.99317
Overall Steps per Second: 7089.75433

Timestep Collection Time: 5.00310
Timestep Consumption Time: 2.05158
PPO Batch Consumption Time: 0.02454
Total Iteration Time: 7.05469

Cumulative Model Updates: 44460
Cumulative Timesteps: 371182330

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.98734
Policy Entropy: 1.08942
Value Function Loss: 0.02741

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.10357
Value Function Update Magnitude: 0.17310

Collected Steps per Second: 9570.44959
Overall Steps per Second: 6939.77514

Timestep Collection Time: 5.22598
Timestep Consumption Time: 1.98102
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.20701

Cumulative Model Updates: 44466
Cumulative Timesteps: 371232345

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.42593
Policy Entropy: 1.07959
Value Function Loss: 0.02745

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.10376
Value Function Update Magnitude: 0.18070

Collected Steps per Second: 10252.10772
Overall Steps per Second: 7176.93962

Timestep Collection Time: 4.87870
Timestep Consumption Time: 2.09042
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 6.96913

Cumulative Model Updates: 44472
Cumulative Timesteps: 371282362

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.29073
Policy Entropy: 1.07626
Value Function Loss: 0.02980

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.10777
Value Function Update Magnitude: 0.19746

Collected Steps per Second: 9841.37368
Overall Steps per Second: 7055.44787

Timestep Collection Time: 5.08181
Timestep Consumption Time: 2.00661
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.08842

Cumulative Model Updates: 44478
Cumulative Timesteps: 371332374

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 371332374...
Checkpoint 371332374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.55788
Policy Entropy: 1.07080
Value Function Loss: 0.03053

Mean KL Divergence: 0.03253
SB3 Clip Fraction: 0.19070
Policy Update Magnitude: 0.09910
Value Function Update Magnitude: 0.20173

Collected Steps per Second: 9741.84830
Overall Steps per Second: 7020.08460

Timestep Collection Time: 5.13506
Timestep Consumption Time: 1.99092
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.12598

Cumulative Model Updates: 44484
Cumulative Timesteps: 371382399

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.65418
Policy Entropy: 1.05342
Value Function Loss: 0.03072

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.18625
Policy Update Magnitude: 0.08383
Value Function Update Magnitude: 0.19306

Collected Steps per Second: 10428.69653
Overall Steps per Second: 7191.95840

Timestep Collection Time: 4.79475
Timestep Consumption Time: 2.15788
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 6.95263

Cumulative Model Updates: 44490
Cumulative Timesteps: 371432402

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.21825
Policy Entropy: 1.06112
Value Function Loss: 0.03013

Mean KL Divergence: 0.03731
SB3 Clip Fraction: 0.20459
Policy Update Magnitude: 0.08391
Value Function Update Magnitude: 0.17925

Collected Steps per Second: 9812.47093
Overall Steps per Second: 7060.86970

Timestep Collection Time: 5.09698
Timestep Consumption Time: 1.98628
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.08326

Cumulative Model Updates: 44496
Cumulative Timesteps: 371482416

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.05335
Policy Entropy: 1.06513
Value Function Loss: 0.03155

Mean KL Divergence: 0.02318
SB3 Clip Fraction: 0.15266
Policy Update Magnitude: 0.09571
Value Function Update Magnitude: 0.16846

Collected Steps per Second: 9793.38320
Overall Steps per Second: 7014.92707

Timestep Collection Time: 5.10549
Timestep Consumption Time: 2.02217
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.12766

Cumulative Model Updates: 44502
Cumulative Timesteps: 371532416

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.45144
Policy Entropy: 1.07495
Value Function Loss: 0.03448

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.15453
Policy Update Magnitude: 0.09667
Value Function Update Magnitude: 0.17003

Collected Steps per Second: 10652.41615
Overall Steps per Second: 7371.97861

Timestep Collection Time: 4.69574
Timestep Consumption Time: 2.08955
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 6.78529

Cumulative Model Updates: 44508
Cumulative Timesteps: 371582437

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.58086
Policy Entropy: 1.05502
Value Function Loss: 0.03404

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.10122
Value Function Update Magnitude: 0.17095

Collected Steps per Second: 9901.51419
Overall Steps per Second: 7014.06850

Timestep Collection Time: 5.05418
Timestep Consumption Time: 2.08063
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 7.13480

Cumulative Model Updates: 44514
Cumulative Timesteps: 371632481

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.80683
Policy Entropy: 1.05608
Value Function Loss: 0.03262

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.10835
Value Function Update Magnitude: 0.16681

Collected Steps per Second: 9763.38794
Overall Steps per Second: 7025.60988

Timestep Collection Time: 5.12363
Timestep Consumption Time: 1.99660
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.12024

Cumulative Model Updates: 44520
Cumulative Timesteps: 371682505

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.00915
Policy Entropy: 1.06744
Value Function Loss: 0.02951

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 0.09188
Value Function Update Magnitude: 0.16100

Collected Steps per Second: 10355.19267
Overall Steps per Second: 7229.66964

Timestep Collection Time: 4.83120
Timestep Consumption Time: 2.08862
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 6.91982

Cumulative Model Updates: 44526
Cumulative Timesteps: 371732533

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.97165
Policy Entropy: 1.07407
Value Function Loss: 0.03124

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.10751
Value Function Update Magnitude: 0.16083

Collected Steps per Second: 10295.25095
Overall Steps per Second: 7280.01658

Timestep Collection Time: 4.85836
Timestep Consumption Time: 2.01223
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 6.87059

Cumulative Model Updates: 44532
Cumulative Timesteps: 371782551

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.18295
Policy Entropy: 1.06498
Value Function Loss: 0.02998

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.11453
Value Function Update Magnitude: 0.16196

Collected Steps per Second: 9744.91747
Overall Steps per Second: 6985.20383

Timestep Collection Time: 5.13088
Timestep Consumption Time: 2.02711
PPO Batch Consumption Time: 0.02462
Total Iteration Time: 7.15799

Cumulative Model Updates: 44538
Cumulative Timesteps: 371832551

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 371832551...
Checkpoint 371832551 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.28818
Policy Entropy: 1.05314
Value Function Loss: 0.03020

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.15152
Policy Update Magnitude: 0.10880
Value Function Update Magnitude: 0.16701

Collected Steps per Second: 10281.26510
Overall Steps per Second: 7188.61778

Timestep Collection Time: 4.86604
Timestep Consumption Time: 2.09344
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 6.95947

Cumulative Model Updates: 44544
Cumulative Timesteps: 371882580

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.38932
Policy Entropy: 1.05326
Value Function Loss: 0.02965

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.16186
Policy Update Magnitude: 0.10339
Value Function Update Magnitude: 0.17123

Collected Steps per Second: 9892.01811
Overall Steps per Second: 6987.32624

Timestep Collection Time: 5.05498
Timestep Consumption Time: 2.10140
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.15639

Cumulative Model Updates: 44550
Cumulative Timesteps: 371932584

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.61680
Policy Entropy: 1.05335
Value Function Loss: 0.03082

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.09610
Value Function Update Magnitude: 0.17780

Collected Steps per Second: 10057.57677
Overall Steps per Second: 7158.77159

Timestep Collection Time: 4.97525
Timestep Consumption Time: 2.01463
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 6.98989

Cumulative Model Updates: 44556
Cumulative Timesteps: 371982623

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.22833
Policy Entropy: 1.05633
Value Function Loss: 0.03235

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.15088
Policy Update Magnitude: 0.09834
Value Function Update Magnitude: 0.17599

Collected Steps per Second: 10334.86049
Overall Steps per Second: 7107.81293

Timestep Collection Time: 4.84148
Timestep Consumption Time: 2.19810
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.03958

Cumulative Model Updates: 44562
Cumulative Timesteps: 372032659

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.23867
Policy Entropy: 1.04478
Value Function Loss: 0.03137

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.11306
Value Function Update Magnitude: 0.17210

Collected Steps per Second: 10028.38899
Overall Steps per Second: 7194.26950

Timestep Collection Time: 4.98724
Timestep Consumption Time: 1.96468
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 6.95192

Cumulative Model Updates: 44568
Cumulative Timesteps: 372082673

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.68320
Policy Entropy: 1.05147
Value Function Loss: 0.03126

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.11574
Value Function Update Magnitude: 0.17035

Collected Steps per Second: 9737.07076
Overall Steps per Second: 7019.05987

Timestep Collection Time: 5.13810
Timestep Consumption Time: 1.98964
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.12774

Cumulative Model Updates: 44574
Cumulative Timesteps: 372132703

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.15695
Policy Entropy: 1.04833
Value Function Loss: 0.03006

Mean KL Divergence: 0.04505
SB3 Clip Fraction: 0.22045
Policy Update Magnitude: 0.10159
Value Function Update Magnitude: 0.17541

Collected Steps per Second: 10398.68869
Overall Steps per Second: 7254.49054

Timestep Collection Time: 4.80897
Timestep Consumption Time: 2.08428
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 6.89325

Cumulative Model Updates: 44580
Cumulative Timesteps: 372182710

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.83522
Policy Entropy: 1.05741
Value Function Loss: 0.02985

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.15536
Policy Update Magnitude: 0.09800
Value Function Update Magnitude: 0.17208

Collected Steps per Second: 9842.54137
Overall Steps per Second: 7054.07917

Timestep Collection Time: 5.08415
Timestep Consumption Time: 2.00976
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.09391

Cumulative Model Updates: 44586
Cumulative Timesteps: 372232751

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.42874
Policy Entropy: 1.04885
Value Function Loss: 0.03087

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.10912
Value Function Update Magnitude: 0.16908

Collected Steps per Second: 9685.43284
Overall Steps per Second: 6946.96256

Timestep Collection Time: 5.16250
Timestep Consumption Time: 2.03504
PPO Batch Consumption Time: 0.02926
Total Iteration Time: 7.19753

Cumulative Model Updates: 44592
Cumulative Timesteps: 372282752

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.13204
Policy Entropy: 1.03901
Value Function Loss: 0.02913

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.10427
Value Function Update Magnitude: 0.17522

Collected Steps per Second: 10417.10355
Overall Steps per Second: 7262.22527

Timestep Collection Time: 4.79989
Timestep Consumption Time: 2.08519
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.88508

Cumulative Model Updates: 44598
Cumulative Timesteps: 372332753

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 372332753...
Checkpoint 372332753 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.73823
Policy Entropy: 1.03605
Value Function Loss: 0.03093

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.10664
Value Function Update Magnitude: 0.17107

Collected Steps per Second: 9930.47031
Overall Steps per Second: 7034.76126

Timestep Collection Time: 5.03843
Timestep Consumption Time: 2.07396
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 7.11239

Cumulative Model Updates: 44604
Cumulative Timesteps: 372382787

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.70292
Policy Entropy: 1.03412
Value Function Loss: 0.03094

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.11185
Value Function Update Magnitude: 0.17675

Collected Steps per Second: 9996.04113
Overall Steps per Second: 7122.87195

Timestep Collection Time: 5.00548
Timestep Consumption Time: 2.01907
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.02455

Cumulative Model Updates: 44610
Cumulative Timesteps: 372432822

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.87006
Policy Entropy: 1.02699
Value Function Loss: 0.03235

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.10835
Value Function Update Magnitude: 0.17572

Collected Steps per Second: 10644.23797
Overall Steps per Second: 7375.05229

Timestep Collection Time: 4.69822
Timestep Consumption Time: 2.08261
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 6.78083

Cumulative Model Updates: 44616
Cumulative Timesteps: 372482831

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.02726
Policy Entropy: 1.02481
Value Function Loss: 0.03152

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.10812
Value Function Update Magnitude: 0.17267

Collected Steps per Second: 9961.85105
Overall Steps per Second: 7061.77399

Timestep Collection Time: 5.01945
Timestep Consumption Time: 2.06135
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.08080

Cumulative Model Updates: 44622
Cumulative Timesteps: 372532834

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.60908
Policy Entropy: 1.03579
Value Function Loss: 0.03221

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.11149
Value Function Update Magnitude: 0.17385

Collected Steps per Second: 9641.55445
Overall Steps per Second: 6953.93796

Timestep Collection Time: 5.18817
Timestep Consumption Time: 2.00517
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 7.19333

Cumulative Model Updates: 44628
Cumulative Timesteps: 372582856

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.37134
Policy Entropy: 1.03960
Value Function Loss: 0.03258

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.15437
Policy Update Magnitude: 0.10727
Value Function Update Magnitude: 0.18178

Collected Steps per Second: 10376.52971
Overall Steps per Second: 7272.01827

Timestep Collection Time: 4.82001
Timestep Consumption Time: 2.05772
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 6.87773

Cumulative Model Updates: 44634
Cumulative Timesteps: 372632871

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.35810
Policy Entropy: 1.03572
Value Function Loss: 0.03373

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.09772
Value Function Update Magnitude: 0.18572

Collected Steps per Second: 9834.88744
Overall Steps per Second: 7008.72978

Timestep Collection Time: 5.08801
Timestep Consumption Time: 2.05166
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.13967

Cumulative Model Updates: 44640
Cumulative Timesteps: 372682911

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.30752
Policy Entropy: 1.02137
Value Function Loss: 0.03196

Mean KL Divergence: 0.02525
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.09920
Value Function Update Magnitude: 0.18264

Collected Steps per Second: 9745.78092
Overall Steps per Second: 6978.88550

Timestep Collection Time: 5.13350
Timestep Consumption Time: 2.03526
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.16877

Cumulative Model Updates: 44646
Cumulative Timesteps: 372732941

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.73589
Policy Entropy: 1.02458
Value Function Loss: 0.03176

Mean KL Divergence: 0.02838
SB3 Clip Fraction: 0.18001
Policy Update Magnitude: 0.10449
Value Function Update Magnitude: 0.17434

Collected Steps per Second: 10379.24372
Overall Steps per Second: 7220.29560

Timestep Collection Time: 4.81731
Timestep Consumption Time: 2.10762
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 6.92492

Cumulative Model Updates: 44652
Cumulative Timesteps: 372782941

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.07271
Policy Entropy: 1.02553
Value Function Loss: 0.03062

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.17905
Policy Update Magnitude: 0.10486
Value Function Update Magnitude: 0.17133

Collected Steps per Second: 10015.77239
Overall Steps per Second: 7115.90770

Timestep Collection Time: 4.99432
Timestep Consumption Time: 2.03528
PPO Batch Consumption Time: 0.02927
Total Iteration Time: 7.02960

Cumulative Model Updates: 44658
Cumulative Timesteps: 372832963

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 372832963...
Checkpoint 372832963 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.75071
Policy Entropy: 1.03924
Value Function Loss: 0.02993

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.10148
Value Function Update Magnitude: 0.16725

Collected Steps per Second: 9610.63777
Overall Steps per Second: 6914.27235

Timestep Collection Time: 5.20725
Timestep Consumption Time: 2.03068
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.23793

Cumulative Model Updates: 44664
Cumulative Timesteps: 372883008

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.67193
Policy Entropy: 1.04794
Value Function Loss: 0.03072

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.09805
Value Function Update Magnitude: 0.17064

Collected Steps per Second: 10825.36078
Overall Steps per Second: 7476.69867

Timestep Collection Time: 4.62045
Timestep Consumption Time: 2.06940
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 6.68985

Cumulative Model Updates: 44670
Cumulative Timesteps: 372933026

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.32884
Policy Entropy: 1.05532
Value Function Loss: 0.03031

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.10593
Value Function Update Magnitude: 0.17294

Collected Steps per Second: 9901.93585
Overall Steps per Second: 7110.52089

Timestep Collection Time: 5.04952
Timestep Consumption Time: 1.98232
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.03183

Cumulative Model Updates: 44676
Cumulative Timesteps: 372983026

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.88353
Policy Entropy: 1.05000
Value Function Loss: 0.03115

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.11373
Value Function Update Magnitude: 0.17467

Collected Steps per Second: 9783.23965
Overall Steps per Second: 7200.94101

Timestep Collection Time: 5.11446
Timestep Consumption Time: 1.83408
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.94854

Cumulative Model Updates: 44682
Cumulative Timesteps: 373033062

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.74665
Policy Entropy: 1.04237
Value Function Loss: 0.02827

Mean KL Divergence: 0.02177
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.12138
Value Function Update Magnitude: 0.17561

Collected Steps per Second: 10272.20021
Overall Steps per Second: 7257.28028

Timestep Collection Time: 4.87013
Timestep Consumption Time: 2.02322
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 6.89335

Cumulative Model Updates: 44688
Cumulative Timesteps: 373083089

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.58289
Policy Entropy: 1.03379
Value Function Loss: 0.02900

Mean KL Divergence: 0.02993
SB3 Clip Fraction: 0.17195
Policy Update Magnitude: 0.10590
Value Function Update Magnitude: 0.16579

Collected Steps per Second: 9843.84097
Overall Steps per Second: 7065.45920

Timestep Collection Time: 5.08125
Timestep Consumption Time: 1.99812
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.07937

Cumulative Model Updates: 44694
Cumulative Timesteps: 373133108

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.44148
Policy Entropy: 1.02244
Value Function Loss: 0.03037

Mean KL Divergence: 0.04738
SB3 Clip Fraction: 0.23440
Policy Update Magnitude: 0.09289
Value Function Update Magnitude: 0.16123

Collected Steps per Second: 9740.24114
Overall Steps per Second: 7020.10833

Timestep Collection Time: 5.13694
Timestep Consumption Time: 1.99045
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.12738

Cumulative Model Updates: 44700
Cumulative Timesteps: 373183143

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.63484
Policy Entropy: 1.01930
Value Function Loss: 0.03196

Mean KL Divergence: 0.03315
SB3 Clip Fraction: 0.20301
Policy Update Magnitude: 0.09080
Value Function Update Magnitude: 0.16538

Collected Steps per Second: 10370.35916
Overall Steps per Second: 7256.37665

Timestep Collection Time: 4.82327
Timestep Consumption Time: 2.06984
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 6.89311

Cumulative Model Updates: 44706
Cumulative Timesteps: 373233162

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.31106
Policy Entropy: 1.03173
Value Function Loss: 0.03182

Mean KL Divergence: 0.04920
SB3 Clip Fraction: 0.23834
Policy Update Magnitude: 0.09293
Value Function Update Magnitude: 0.17412

Collected Steps per Second: 9792.86773
Overall Steps per Second: 7029.83713

Timestep Collection Time: 5.10596
Timestep Consumption Time: 2.00686
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.11282

Cumulative Model Updates: 44712
Cumulative Timesteps: 373283164

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.27066
Policy Entropy: 1.04278
Value Function Loss: 0.03277

Mean KL Divergence: 0.02907
SB3 Clip Fraction: 0.18300
Policy Update Magnitude: 0.10976
Value Function Update Magnitude: 0.17368

Collected Steps per Second: 9617.45167
Overall Steps per Second: 6903.13754

Timestep Collection Time: 5.20044
Timestep Consumption Time: 2.04481
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 7.24526

Cumulative Model Updates: 44718
Cumulative Timesteps: 373333179

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 373333179...
Checkpoint 373333179 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.10376
Policy Entropy: 1.04966
Value Function Loss: 0.03354

Mean KL Divergence: 0.03616
SB3 Clip Fraction: 0.20009
Policy Update Magnitude: 0.11008
Value Function Update Magnitude: 0.18211

Collected Steps per Second: 10499.41931
Overall Steps per Second: 7287.56351

Timestep Collection Time: 4.76655
Timestep Consumption Time: 2.10077
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 6.86732

Cumulative Model Updates: 44724
Cumulative Timesteps: 373383225

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.66956
Policy Entropy: 1.05251
Value Function Loss: 0.03461

Mean KL Divergence: 0.04142
SB3 Clip Fraction: 0.22806
Policy Update Magnitude: 0.09049
Value Function Update Magnitude: 0.17849

Collected Steps per Second: 9789.88735
Overall Steps per Second: 6899.89333

Timestep Collection Time: 5.10782
Timestep Consumption Time: 2.13939
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.24721

Cumulative Model Updates: 44730
Cumulative Timesteps: 373433230

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.08003
Policy Entropy: 1.05723
Value Function Loss: 0.03328

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.17300
Policy Update Magnitude: 0.10190
Value Function Update Magnitude: 0.18307

Collected Steps per Second: 9663.94636
Overall Steps per Second: 6948.67542

Timestep Collection Time: 5.17542
Timestep Consumption Time: 2.02235
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 7.19777

Cumulative Model Updates: 44736
Cumulative Timesteps: 373483245

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.71492
Policy Entropy: 1.04748
Value Function Loss: 0.03288

Mean KL Divergence: 0.03041
SB3 Clip Fraction: 0.18110
Policy Update Magnitude: 0.10830
Value Function Update Magnitude: 0.19307

Collected Steps per Second: 10178.31721
Overall Steps per Second: 7195.68663

Timestep Collection Time: 4.91309
Timestep Consumption Time: 2.03649
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 6.94958

Cumulative Model Updates: 44742
Cumulative Timesteps: 373533252

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.52960
Policy Entropy: 1.03703
Value Function Loss: 0.03330

Mean KL Divergence: 0.02876
SB3 Clip Fraction: 0.17748
Policy Update Magnitude: 0.11683
Value Function Update Magnitude: 0.19918

Collected Steps per Second: 9680.30868
Overall Steps per Second: 6849.91778

Timestep Collection Time: 5.16719
Timestep Consumption Time: 2.13509
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.30228

Cumulative Model Updates: 44748
Cumulative Timesteps: 373583272

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.32587
Policy Entropy: 1.02919
Value Function Loss: 0.03442

Mean KL Divergence: 0.03772
SB3 Clip Fraction: 0.22371
Policy Update Magnitude: 0.11189
Value Function Update Magnitude: 0.19730

Collected Steps per Second: 9640.98711
Overall Steps per Second: 6962.06035

Timestep Collection Time: 5.18629
Timestep Consumption Time: 1.99563
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.18193

Cumulative Model Updates: 44754
Cumulative Timesteps: 373633273

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.64164
Policy Entropy: 1.03134
Value Function Loss: 0.03289

Mean KL Divergence: 0.03253
SB3 Clip Fraction: 0.19897
Policy Update Magnitude: 0.10108
Value Function Update Magnitude: 0.20924

Collected Steps per Second: 10394.12270
Overall Steps per Second: 7302.03435

Timestep Collection Time: 4.81368
Timestep Consumption Time: 2.03838
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 6.85206

Cumulative Model Updates: 44760
Cumulative Timesteps: 373683307

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.53328
Policy Entropy: 1.03785
Value Function Loss: 0.03209

Mean KL Divergence: 0.03663
SB3 Clip Fraction: 0.21621
Policy Update Magnitude: 0.08781
Value Function Update Magnitude: 0.21046

Collected Steps per Second: 9767.40639
Overall Steps per Second: 6947.71121

Timestep Collection Time: 5.12009
Timestep Consumption Time: 2.07796
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.19805

Cumulative Model Updates: 44766
Cumulative Timesteps: 373733317

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.22830
Policy Entropy: 1.02667
Value Function Loss: 0.03125

Mean KL Divergence: 0.03698
SB3 Clip Fraction: 0.21407
Policy Update Magnitude: 0.08814
Value Function Update Magnitude: 0.19264

Collected Steps per Second: 9964.34751
Overall Steps per Second: 7127.46999

Timestep Collection Time: 5.02020
Timestep Consumption Time: 1.99814
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.01834

Cumulative Model Updates: 44772
Cumulative Timesteps: 373783340

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.90971
Policy Entropy: 1.02623
Value Function Loss: 0.03237

Mean KL Divergence: 0.03903
SB3 Clip Fraction: 0.22173
Policy Update Magnitude: 0.08454
Value Function Update Magnitude: 0.18228

Collected Steps per Second: 10380.74546
Overall Steps per Second: 7230.24662

Timestep Collection Time: 4.81921
Timestep Consumption Time: 2.09992
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.91913

Cumulative Model Updates: 44778
Cumulative Timesteps: 373833367

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 373833367...
Checkpoint 373833367 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.38628
Policy Entropy: 1.01890
Value Function Loss: 0.03072

Mean KL Divergence: 0.03082
SB3 Clip Fraction: 0.19745
Policy Update Magnitude: 0.09054
Value Function Update Magnitude: 0.17610

Collected Steps per Second: 10138.50305
Overall Steps per Second: 3137.22860

Timestep Collection Time: 4.93377
Timestep Consumption Time: 11.01056
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 15.94433

Cumulative Model Updates: 44784
Cumulative Timesteps: 373883388

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.35000
Policy Entropy: 1.02201
Value Function Loss: 0.03035

Mean KL Divergence: 0.04290
SB3 Clip Fraction: 0.22610
Policy Update Magnitude: 0.08631
Value Function Update Magnitude: 0.16910

Collected Steps per Second: 9836.51350
Overall Steps per Second: 2431.52762

Timestep Collection Time: 5.08331
Timestep Consumption Time: 15.48072
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 20.56403

Cumulative Model Updates: 44790
Cumulative Timesteps: 373933390

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.85820
Policy Entropy: 1.02637
Value Function Loss: 0.02875

Mean KL Divergence: 0.02902
SB3 Clip Fraction: 0.18602
Policy Update Magnitude: 0.09052
Value Function Update Magnitude: 0.16808

Collected Steps per Second: 10290.70908
Overall Steps per Second: 3134.17617

Timestep Collection Time: 4.86079
Timestep Consumption Time: 11.09906
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 15.95986

Cumulative Model Updates: 44796
Cumulative Timesteps: 373983411

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.17130
Policy Entropy: 1.03245
Value Function Loss: 0.02883

Mean KL Divergence: 0.03871
SB3 Clip Fraction: 0.21737
Policy Update Magnitude: 0.08852
Value Function Update Magnitude: 0.16956

Collected Steps per Second: 10169.02299
Overall Steps per Second: 7216.95532

Timestep Collection Time: 4.91856
Timestep Consumption Time: 2.01192
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 6.93048

Cumulative Model Updates: 44802
Cumulative Timesteps: 374033428

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.95422
Policy Entropy: 1.02614
Value Function Loss: 0.02958

Mean KL Divergence: 0.03260
SB3 Clip Fraction: 0.19873
Policy Update Magnitude: 0.09052
Value Function Update Magnitude: 0.16604

Collected Steps per Second: 9787.94873
Overall Steps per Second: 7011.63341

Timestep Collection Time: 5.11077
Timestep Consumption Time: 2.02365
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 7.13443

Cumulative Model Updates: 44808
Cumulative Timesteps: 374083452

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.55745
Policy Entropy: 1.04425
Value Function Loss: 0.03206

Mean KL Divergence: 0.04354
SB3 Clip Fraction: 0.23007
Policy Update Magnitude: 0.08559
Value Function Update Magnitude: 0.17029

Collected Steps per Second: 10265.94105
Overall Steps per Second: 7179.54961

Timestep Collection Time: 4.87369
Timestep Consumption Time: 2.09513
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 6.96882

Cumulative Model Updates: 44814
Cumulative Timesteps: 374133485

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.62570
Policy Entropy: 1.03451
Value Function Loss: 0.03129

Mean KL Divergence: 0.03640
SB3 Clip Fraction: 0.20192
Policy Update Magnitude: 0.09287
Value Function Update Magnitude: 0.17365

Collected Steps per Second: 9899.24159
Overall Steps per Second: 7030.30456

Timestep Collection Time: 5.05483
Timestep Consumption Time: 2.06278
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 7.11761

Cumulative Model Updates: 44820
Cumulative Timesteps: 374183524

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.78360
Policy Entropy: 1.03027
Value Function Loss: 0.02987

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.16915
Policy Update Magnitude: 0.09923
Value Function Update Magnitude: 0.17278

Collected Steps per Second: 9787.95204
Overall Steps per Second: 7043.33188

Timestep Collection Time: 5.11220
Timestep Consumption Time: 1.99210
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.10431

Cumulative Model Updates: 44826
Cumulative Timesteps: 374233562

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.89983
Policy Entropy: 1.03695
Value Function Loss: 0.02940

Mean KL Divergence: 0.03693
SB3 Clip Fraction: 0.21635
Policy Update Magnitude: 0.09788
Value Function Update Magnitude: 0.16444

Collected Steps per Second: 10436.26599
Overall Steps per Second: 7330.14691

Timestep Collection Time: 4.79300
Timestep Consumption Time: 2.03101
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 6.82401

Cumulative Model Updates: 44832
Cumulative Timesteps: 374283583

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.72036
Policy Entropy: 1.02813
Value Function Loss: 0.03164

Mean KL Divergence: 0.03544
SB3 Clip Fraction: 0.21741
Policy Update Magnitude: 0.09398
Value Function Update Magnitude: 0.17202

Collected Steps per Second: 9964.66904
Overall Steps per Second: 7015.26265

Timestep Collection Time: 5.01923
Timestep Consumption Time: 2.11022
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.12946

Cumulative Model Updates: 44838
Cumulative Timesteps: 374333598

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 374333598...
Checkpoint 374333598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.28942
Policy Entropy: 1.02241
Value Function Loss: 0.03207

Mean KL Divergence: 0.04477
SB3 Clip Fraction: 0.23410
Policy Update Magnitude: 0.09678
Value Function Update Magnitude: 0.17711

Collected Steps per Second: 9681.85646
Overall Steps per Second: 6947.24336

Timestep Collection Time: 5.16440
Timestep Consumption Time: 2.03284
PPO Batch Consumption Time: 0.02842
Total Iteration Time: 7.19724

Cumulative Model Updates: 44844
Cumulative Timesteps: 374383599

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.82918
Policy Entropy: 1.01116
Value Function Loss: 0.03167

Mean KL Divergence: 0.02511
SB3 Clip Fraction: 0.16577
Policy Update Magnitude: 0.10451
Value Function Update Magnitude: 0.17334

Collected Steps per Second: 10315.14894
Overall Steps per Second: 7255.79993

Timestep Collection Time: 4.84811
Timestep Consumption Time: 2.04417
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 6.89228

Cumulative Model Updates: 44850
Cumulative Timesteps: 374433608

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.69846
Policy Entropy: 1.02468
Value Function Loss: 0.03069

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.11041
Value Function Update Magnitude: 0.16806

Collected Steps per Second: 9891.94885
Overall Steps per Second: 7091.17358

Timestep Collection Time: 5.05613
Timestep Consumption Time: 1.99700
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.05313

Cumulative Model Updates: 44856
Cumulative Timesteps: 374483623

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.35112
Policy Entropy: 1.02323
Value Function Loss: 0.03082

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.11155
Value Function Update Magnitude: 0.17190

Collected Steps per Second: 9722.44707
Overall Steps per Second: 6989.44940

Timestep Collection Time: 5.14654
Timestep Consumption Time: 2.01239
PPO Batch Consumption Time: 0.02398
Total Iteration Time: 7.15893

Cumulative Model Updates: 44862
Cumulative Timesteps: 374533660

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.31085
Policy Entropy: 1.03546
Value Function Loss: 0.03077

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.10628
Value Function Update Magnitude: 0.17881

Collected Steps per Second: 10412.92794
Overall Steps per Second: 7239.41726

Timestep Collection Time: 4.80364
Timestep Consumption Time: 2.10575
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 6.90940

Cumulative Model Updates: 44868
Cumulative Timesteps: 374583680

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.41354
Policy Entropy: 1.03107
Value Function Loss: 0.02990

Mean KL Divergence: 0.02996
SB3 Clip Fraction: 0.18151
Policy Update Magnitude: 0.10057
Value Function Update Magnitude: 0.17663

Collected Steps per Second: 9823.86022
Overall Steps per Second: 6918.51126

Timestep Collection Time: 5.09230
Timestep Consumption Time: 2.13845
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.23075

Cumulative Model Updates: 44874
Cumulative Timesteps: 374633706

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.20011
Policy Entropy: 1.03716
Value Function Loss: 0.03039

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.09159
Value Function Update Magnitude: 0.17281

Collected Steps per Second: 9635.54479
Overall Steps per Second: 6941.00110

Timestep Collection Time: 5.19203
Timestep Consumption Time: 2.01558
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.20761

Cumulative Model Updates: 44880
Cumulative Timesteps: 374683734

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.07979
Policy Entropy: 1.03866
Value Function Loss: 0.02961

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.10090
Value Function Update Magnitude: 0.18254

Collected Steps per Second: 10691.73957
Overall Steps per Second: 7440.79373

Timestep Collection Time: 4.67847
Timestep Consumption Time: 2.04406
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 6.72254

Cumulative Model Updates: 44886
Cumulative Timesteps: 374733755

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.38741
Policy Entropy: 1.04854
Value Function Loss: 0.03063

Mean KL Divergence: 0.03852
SB3 Clip Fraction: 0.21291
Policy Update Magnitude: 0.09110
Value Function Update Magnitude: 0.18885

Collected Steps per Second: 10129.32715
Overall Steps per Second: 7160.68726

Timestep Collection Time: 4.93715
Timestep Consumption Time: 2.04682
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 6.98397

Cumulative Model Updates: 44892
Cumulative Timesteps: 374783765

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.53988
Policy Entropy: 1.06671
Value Function Loss: 0.02973

Mean KL Divergence: 0.04486
SB3 Clip Fraction: 0.23659
Policy Update Magnitude: 0.08910
Value Function Update Magnitude: 0.19655

Collected Steps per Second: 9762.64663
Overall Steps per Second: 7037.80175

Timestep Collection Time: 5.12597
Timestep Consumption Time: 1.98463
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.11060

Cumulative Model Updates: 44898
Cumulative Timesteps: 374833808

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 374833808...
Checkpoint 374833808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.85218
Policy Entropy: 1.06414
Value Function Loss: 0.03028

Mean KL Divergence: 0.04595
SB3 Clip Fraction: 0.23288
Policy Update Magnitude: 0.09491
Value Function Update Magnitude: 0.19129

Collected Steps per Second: 10406.25424
Overall Steps per Second: 7226.76525

Timestep Collection Time: 4.80865
Timestep Consumption Time: 2.11561
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 6.92426

Cumulative Model Updates: 44904
Cumulative Timesteps: 374883848

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.53393
Policy Entropy: 1.07931
Value Function Loss: 0.02985

Mean KL Divergence: 0.04036
SB3 Clip Fraction: 0.22078
Policy Update Magnitude: 0.09355
Value Function Update Magnitude: 0.19065

Collected Steps per Second: 9895.37619
Overall Steps per Second: 7049.73844

Timestep Collection Time: 5.05418
Timestep Consumption Time: 2.04013
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.09431

Cumulative Model Updates: 44910
Cumulative Timesteps: 374933861

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.98309
Policy Entropy: 1.07983
Value Function Loss: 0.03177

Mean KL Divergence: 0.04206
SB3 Clip Fraction: 0.21995
Policy Update Magnitude: 0.09514
Value Function Update Magnitude: 0.19002

Collected Steps per Second: 9823.23485
Overall Steps per Second: 7117.68906

Timestep Collection Time: 5.09058
Timestep Consumption Time: 1.93501
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.02559

Cumulative Model Updates: 44916
Cumulative Timesteps: 374983867

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.08470
Policy Entropy: 1.09095
Value Function Loss: 0.03095

Mean KL Divergence: 0.02604
SB3 Clip Fraction: 0.16977
Policy Update Magnitude: 0.10102
Value Function Update Magnitude: 0.18006

Collected Steps per Second: 10047.06913
Overall Steps per Second: 7064.04943

Timestep Collection Time: 4.97797
Timestep Consumption Time: 2.10211
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.08008

Cumulative Model Updates: 44922
Cumulative Timesteps: 375033881

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.80530
Policy Entropy: 1.09694
Value Function Loss: 0.03103

Mean KL Divergence: 0.03953
SB3 Clip Fraction: 0.21303
Policy Update Magnitude: 0.10023
Value Function Update Magnitude: 0.18061

Collected Steps per Second: 9492.88428
Overall Steps per Second: 6843.63682

Timestep Collection Time: 5.27111
Timestep Consumption Time: 2.04050
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 7.31161

Cumulative Model Updates: 44928
Cumulative Timesteps: 375083919

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.94948
Policy Entropy: 1.09217
Value Function Loss: 0.02836

Mean KL Divergence: 0.03749
SB3 Clip Fraction: 0.19611
Policy Update Magnitude: 0.08885
Value Function Update Magnitude: 0.17906

Collected Steps per Second: 9408.07187
Overall Steps per Second: 6831.13829

Timestep Collection Time: 5.31544
Timestep Consumption Time: 2.00516
PPO Batch Consumption Time: 0.02499
Total Iteration Time: 7.32060

Cumulative Model Updates: 44934
Cumulative Timesteps: 375133927

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.91920
Policy Entropy: 1.10683
Value Function Loss: 0.02805

Mean KL Divergence: 0.02724
SB3 Clip Fraction: 0.17705
Policy Update Magnitude: 0.09551
Value Function Update Magnitude: 0.17391

Collected Steps per Second: 10020.01037
Overall Steps per Second: 7036.27123

Timestep Collection Time: 4.99201
Timestep Consumption Time: 2.11687
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.10888

Cumulative Model Updates: 44940
Cumulative Timesteps: 375183947

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.61312
Policy Entropy: 1.10146
Value Function Loss: 0.02936

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.10278
Value Function Update Magnitude: 0.17359

Collected Steps per Second: 9718.39778
Overall Steps per Second: 5833.08821

Timestep Collection Time: 5.14900
Timestep Consumption Time: 3.42965
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 8.57865

Cumulative Model Updates: 44946
Cumulative Timesteps: 375233987

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.82400
Policy Entropy: 1.09933
Value Function Loss: 0.02953

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.10288
Value Function Update Magnitude: 0.16457

Collected Steps per Second: 9482.79992
Overall Steps per Second: 6845.49023

Timestep Collection Time: 5.27376
Timestep Consumption Time: 2.03178
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.30554

Cumulative Model Updates: 44952
Cumulative Timesteps: 375283997

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.62519
Policy Entropy: 1.08240
Value Function Loss: 0.03012

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.10146
Value Function Update Magnitude: 0.16833

Collected Steps per Second: 10126.05086
Overall Steps per Second: 7132.27750

Timestep Collection Time: 4.94151
Timestep Consumption Time: 2.07420
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.01571

Cumulative Model Updates: 44958
Cumulative Timesteps: 375334035

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 375334035...
Checkpoint 375334035 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.55395
Policy Entropy: 1.10486
Value Function Loss: 0.02929

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.08870
Value Function Update Magnitude: 0.17530

Collected Steps per Second: 10231.14222
Overall Steps per Second: 7296.45070

Timestep Collection Time: 4.89154
Timestep Consumption Time: 1.96742
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.85895

Cumulative Model Updates: 44964
Cumulative Timesteps: 375384081

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.91300
Policy Entropy: 1.08437
Value Function Loss: 0.03011

Mean KL Divergence: 0.03589
SB3 Clip Fraction: 0.19221
Policy Update Magnitude: 0.08640
Value Function Update Magnitude: 0.17992

Collected Steps per Second: 10027.27423
Overall Steps per Second: 7139.54336

Timestep Collection Time: 4.99049
Timestep Consumption Time: 2.01850
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 7.00899

Cumulative Model Updates: 44970
Cumulative Timesteps: 375434122

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.85956
Policy Entropy: 1.10104
Value Function Loss: 0.02938

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.17472
Policy Update Magnitude: 0.08932
Value Function Update Magnitude: 0.18044

Collected Steps per Second: 10370.03512
Overall Steps per Second: 7251.57884

Timestep Collection Time: 4.82351
Timestep Consumption Time: 2.07430
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.89781

Cumulative Model Updates: 44976
Cumulative Timesteps: 375484142

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.28714
Policy Entropy: 1.08976
Value Function Loss: 0.03077

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.09996
Value Function Update Magnitude: 0.18714

Collected Steps per Second: 10142.92375
Overall Steps per Second: 7226.40614

Timestep Collection Time: 4.93181
Timestep Consumption Time: 1.99044
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 6.92225

Cumulative Model Updates: 44982
Cumulative Timesteps: 375534165

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.79357
Policy Entropy: 1.08447
Value Function Loss: 0.03114

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.10874
Value Function Update Magnitude: 0.20195

Collected Steps per Second: 9973.63207
Overall Steps per Second: 7164.76782

Timestep Collection Time: 5.01593
Timestep Consumption Time: 1.96644
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 6.98236

Cumulative Model Updates: 44988
Cumulative Timesteps: 375584192

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.28097
Policy Entropy: 1.08545
Value Function Loss: 0.03091

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.10988
Value Function Update Magnitude: 0.19399

Collected Steps per Second: 10478.86736
Overall Steps per Second: 7364.38562

Timestep Collection Time: 4.77323
Timestep Consumption Time: 2.01865
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.79188

Cumulative Model Updates: 44994
Cumulative Timesteps: 375634210

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.21079
Policy Entropy: 1.08819
Value Function Loss: 0.03073

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.11136
Value Function Update Magnitude: 0.19045

Collected Steps per Second: 9765.79227
Overall Steps per Second: 6998.81266

Timestep Collection Time: 5.12155
Timestep Consumption Time: 2.02480
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 7.14636

Cumulative Model Updates: 45000
Cumulative Timesteps: 375684226

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.41221
Policy Entropy: 1.09963
Value Function Loss: 0.02951

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.10643
Value Function Update Magnitude: 0.18567

Collected Steps per Second: 9727.22010
Overall Steps per Second: 6924.47822

Timestep Collection Time: 5.14155
Timestep Consumption Time: 2.08109
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 7.22264

Cumulative Model Updates: 45006
Cumulative Timesteps: 375734239

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.98673
Policy Entropy: 1.09834
Value Function Loss: 0.03036

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.10785
Value Function Update Magnitude: 0.18638

Collected Steps per Second: 10315.62415
Overall Steps per Second: 7221.12447

Timestep Collection Time: 4.84702
Timestep Consumption Time: 2.07711
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 6.92413

Cumulative Model Updates: 45012
Cumulative Timesteps: 375784239

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.86424
Policy Entropy: 1.09869
Value Function Loss: 0.03001

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.10425
Value Function Update Magnitude: 0.18623

Collected Steps per Second: 9821.90509
Overall Steps per Second: 6954.62810

Timestep Collection Time: 5.09524
Timestep Consumption Time: 2.10068
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 7.19593

Cumulative Model Updates: 45018
Cumulative Timesteps: 375834284

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 375834284...
Checkpoint 375834284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.33221
Policy Entropy: 1.09279
Value Function Loss: 0.02942

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.10307
Value Function Update Magnitude: 0.18147

Collected Steps per Second: 9741.51933
Overall Steps per Second: 6998.47759

Timestep Collection Time: 5.13637
Timestep Consumption Time: 2.01319
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.14955

Cumulative Model Updates: 45024
Cumulative Timesteps: 375884320

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.48571
Policy Entropy: 1.09587
Value Function Loss: 0.03165

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.10320
Value Function Update Magnitude: 0.17703

Collected Steps per Second: 10388.56928
Overall Steps per Second: 7258.72945

Timestep Collection Time: 4.81337
Timestep Consumption Time: 2.07544
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.88881

Cumulative Model Updates: 45030
Cumulative Timesteps: 375934324

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.78243
Policy Entropy: 1.08838
Value Function Loss: 0.03166

Mean KL Divergence: 0.02442
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.10847
Value Function Update Magnitude: 0.17975

Collected Steps per Second: 9859.03134
Overall Steps per Second: 7102.17925

Timestep Collection Time: 5.07535
Timestep Consumption Time: 1.97010
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 7.04544

Cumulative Model Updates: 45036
Cumulative Timesteps: 375984362

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.47466
Policy Entropy: 1.08983
Value Function Loss: 0.03295

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.10792
Value Function Update Magnitude: 0.18813

Collected Steps per Second: 10031.03246
Overall Steps per Second: 7126.79426

Timestep Collection Time: 4.98453
Timestep Consumption Time: 2.03125
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.01578

Cumulative Model Updates: 45042
Cumulative Timesteps: 376034362

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.33898
Policy Entropy: 1.07995
Value Function Loss: 0.03089

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.10207
Value Function Update Magnitude: 0.18443

Collected Steps per Second: 10309.62328
Overall Steps per Second: 7215.92060

Timestep Collection Time: 4.85207
Timestep Consumption Time: 2.08024
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 6.93231

Cumulative Model Updates: 45048
Cumulative Timesteps: 376084385

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.22172
Policy Entropy: 1.08417
Value Function Loss: 0.03099

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.10240
Value Function Update Magnitude: 0.18381

Collected Steps per Second: 9910.64185
Overall Steps per Second: 7149.40137

Timestep Collection Time: 5.04589
Timestep Consumption Time: 1.94882
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.99471

Cumulative Model Updates: 45054
Cumulative Timesteps: 376134393

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.79378
Policy Entropy: 1.08661
Value Function Loss: 0.03194

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.10430
Value Function Update Magnitude: 0.18968

Collected Steps per Second: 9681.77554
Overall Steps per Second: 6982.10694

Timestep Collection Time: 5.16796
Timestep Consumption Time: 1.99822
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.16617

Cumulative Model Updates: 45060
Cumulative Timesteps: 376184428

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.35359
Policy Entropy: 1.08596
Value Function Loss: 0.03179

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.10714
Value Function Update Magnitude: 0.18887

Collected Steps per Second: 10498.44811
Overall Steps per Second: 7304.88061

Timestep Collection Time: 4.76413
Timestep Consumption Time: 2.08280
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.84693

Cumulative Model Updates: 45066
Cumulative Timesteps: 376234444

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.69178
Policy Entropy: 1.08239
Value Function Loss: 0.03177

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.10944
Value Function Update Magnitude: 0.18255

Collected Steps per Second: 9873.28355
Overall Steps per Second: 7074.12338

Timestep Collection Time: 5.06731
Timestep Consumption Time: 2.00508
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.07240

Cumulative Model Updates: 45072
Cumulative Timesteps: 376284475

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.49662
Policy Entropy: 1.07482
Value Function Loss: 0.02915

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.11386
Value Function Update Magnitude: 0.18113

Collected Steps per Second: 9666.83642
Overall Steps per Second: 6969.08031

Timestep Collection Time: 5.17522
Timestep Consumption Time: 2.00335
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.17857

Cumulative Model Updates: 45078
Cumulative Timesteps: 376334503

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 376334503...
Checkpoint 376334503 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.68717
Policy Entropy: 1.08381
Value Function Loss: 0.03075

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.10720
Value Function Update Magnitude: 0.18413

Collected Steps per Second: 10424.34999
Overall Steps per Second: 7286.29542

Timestep Collection Time: 4.79800
Timestep Consumption Time: 2.06640
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 6.86439

Cumulative Model Updates: 45084
Cumulative Timesteps: 376384519

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.22784
Policy Entropy: 1.08493
Value Function Loss: 0.03019

Mean KL Divergence: 0.03633
SB3 Clip Fraction: 0.19495
Policy Update Magnitude: 0.08897
Value Function Update Magnitude: 0.18489

Collected Steps per Second: 9932.72680
Overall Steps per Second: 7084.96300

Timestep Collection Time: 5.03558
Timestep Consumption Time: 2.02402
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 7.05960

Cumulative Model Updates: 45090
Cumulative Timesteps: 376434536

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.15329
Policy Entropy: 1.07840
Value Function Loss: 0.03166

Mean KL Divergence: 0.03438
SB3 Clip Fraction: 0.18870
Policy Update Magnitude: 0.08163
Value Function Update Magnitude: 0.18564

Collected Steps per Second: 9824.22540
Overall Steps per Second: 7031.30339

Timestep Collection Time: 5.09302
Timestep Consumption Time: 2.02301
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.11603

Cumulative Model Updates: 45096
Cumulative Timesteps: 376484571

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.87561
Policy Entropy: 1.08401
Value Function Loss: 0.03049

Mean KL Divergence: 0.03179
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.08025
Value Function Update Magnitude: 0.18226

Collected Steps per Second: 10435.08894
Overall Steps per Second: 7267.37480

Timestep Collection Time: 4.79306
Timestep Consumption Time: 2.08921
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 6.88227

Cumulative Model Updates: 45102
Cumulative Timesteps: 376534587

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.33453
Policy Entropy: 1.07305
Value Function Loss: 0.03294

Mean KL Divergence: 0.03251
SB3 Clip Fraction: 0.18785
Policy Update Magnitude: 0.08387
Value Function Update Magnitude: 0.18624

Collected Steps per Second: 9907.06482
Overall Steps per Second: 7021.60099

Timestep Collection Time: 5.04731
Timestep Consumption Time: 2.07415
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.12145

Cumulative Model Updates: 45108
Cumulative Timesteps: 376584591

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.91369
Policy Entropy: 1.07840
Value Function Loss: 0.03197

Mean KL Divergence: 0.03786
SB3 Clip Fraction: 0.20005
Policy Update Magnitude: 0.08426
Value Function Update Magnitude: 0.18574

Collected Steps per Second: 9798.32988
Overall Steps per Second: 7009.29896

Timestep Collection Time: 5.10536
Timestep Consumption Time: 2.03145
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.13681

Cumulative Model Updates: 45114
Cumulative Timesteps: 376634615

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.81956
Policy Entropy: 1.07136
Value Function Loss: 0.03228

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.17035
Policy Update Magnitude: 0.09501
Value Function Update Magnitude: 0.17910

Collected Steps per Second: 10398.62966
Overall Steps per Second: 7200.22292

Timestep Collection Time: 4.80986
Timestep Consumption Time: 2.13659
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 6.94645

Cumulative Model Updates: 45120
Cumulative Timesteps: 376684631

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.05682
Policy Entropy: 1.07361
Value Function Loss: 0.02956

Mean KL Divergence: 0.02652
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.09926
Value Function Update Magnitude: 0.17769

Collected Steps per Second: 9826.04509
Overall Steps per Second: 6962.12664

Timestep Collection Time: 5.08974
Timestep Consumption Time: 2.09370
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.18344

Cumulative Model Updates: 45126
Cumulative Timesteps: 376734643

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.39083
Policy Entropy: 1.07404
Value Function Loss: 0.02927

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.15077
Policy Update Magnitude: 0.09944
Value Function Update Magnitude: 0.17701

Collected Steps per Second: 9667.53400
Overall Steps per Second: 6937.77579

Timestep Collection Time: 5.17660
Timestep Consumption Time: 2.03680
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.21341

Cumulative Model Updates: 45132
Cumulative Timesteps: 376784688

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.39801
Policy Entropy: 1.07526
Value Function Loss: 0.02770

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.16852
Policy Update Magnitude: 0.09677
Value Function Update Magnitude: 0.18689

Collected Steps per Second: 10280.45172
Overall Steps per Second: 7206.95058

Timestep Collection Time: 4.86739
Timestep Consumption Time: 2.07577
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 6.94316

Cumulative Model Updates: 45138
Cumulative Timesteps: 376834727

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 376834727...
Checkpoint 376834727 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.48299
Policy Entropy: 1.08299
Value Function Loss: 0.02893

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.15311
Policy Update Magnitude: 0.09252
Value Function Update Magnitude: 0.19598

Collected Steps per Second: 10178.20512
Overall Steps per Second: 7267.25254

Timestep Collection Time: 4.91668
Timestep Consumption Time: 1.96941
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 6.88610

Cumulative Model Updates: 45144
Cumulative Timesteps: 376884770

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.30376
Policy Entropy: 1.06836
Value Function Loss: 0.03082

Mean KL Divergence: 0.03173
SB3 Clip Fraction: 0.17248
Policy Update Magnitude: 0.09647
Value Function Update Magnitude: 0.18650

Collected Steps per Second: 9888.30486
Overall Steps per Second: 7033.86875

Timestep Collection Time: 5.05800
Timestep Consumption Time: 2.05260
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 7.11060

Cumulative Model Updates: 45150
Cumulative Timesteps: 376934785

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.61465
Policy Entropy: 1.06845
Value Function Loss: 0.03170

Mean KL Divergence: 0.04089
SB3 Clip Fraction: 0.20388
Policy Update Magnitude: 0.09013
Value Function Update Magnitude: 0.18013

Collected Steps per Second: 10838.23818
Overall Steps per Second: 7498.37693

Timestep Collection Time: 4.61477
Timestep Consumption Time: 2.05547
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.67024

Cumulative Model Updates: 45156
Cumulative Timesteps: 376984801

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.19663
Policy Entropy: 1.04984
Value Function Loss: 0.03123

Mean KL Divergence: 0.03627
SB3 Clip Fraction: 0.20021
Policy Update Magnitude: 0.08486
Value Function Update Magnitude: 0.19013

Collected Steps per Second: 10001.30299
Overall Steps per Second: 7025.16806

Timestep Collection Time: 5.00195
Timestep Consumption Time: 2.11902
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.12097

Cumulative Model Updates: 45162
Cumulative Timesteps: 377034827

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.55238
Policy Entropy: 1.06223
Value Function Loss: 0.03204

Mean KL Divergence: 0.04209
SB3 Clip Fraction: 0.21866
Policy Update Magnitude: 0.08791
Value Function Update Magnitude: 0.20623

Collected Steps per Second: 9779.72780
Overall Steps per Second: 7003.15953

Timestep Collection Time: 5.11446
Timestep Consumption Time: 2.02775
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 7.14220

Cumulative Model Updates: 45168
Cumulative Timesteps: 377084845

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.09272
Policy Entropy: 1.05149
Value Function Loss: 0.03218

Mean KL Divergence: 0.03744
SB3 Clip Fraction: 0.20348
Policy Update Magnitude: 0.08743
Value Function Update Magnitude: 0.20190

Collected Steps per Second: 10432.06087
Overall Steps per Second: 7309.68514

Timestep Collection Time: 4.79397
Timestep Consumption Time: 2.04777
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 6.84174

Cumulative Model Updates: 45174
Cumulative Timesteps: 377134856

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.61392
Policy Entropy: 1.06454
Value Function Loss: 0.03405

Mean KL Divergence: 0.04363
SB3 Clip Fraction: 0.21362
Policy Update Magnitude: 0.09235
Value Function Update Magnitude: 0.18870

Collected Steps per Second: 9879.64719
Overall Steps per Second: 7077.93678

Timestep Collection Time: 5.06243
Timestep Consumption Time: 2.00390
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.06632

Cumulative Model Updates: 45180
Cumulative Timesteps: 377184871

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.20821
Policy Entropy: 1.05326
Value Function Loss: 0.03185

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.16581
Policy Update Magnitude: 0.10656
Value Function Update Magnitude: 0.18663

Collected Steps per Second: 9945.22984
Overall Steps per Second: 3398.80181

Timestep Collection Time: 5.02985
Timestep Consumption Time: 9.68799
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 14.71783

Cumulative Model Updates: 45186
Cumulative Timesteps: 377234894

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.42656
Policy Entropy: 1.06110
Value Function Loss: 0.03061

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.15781
Policy Update Magnitude: 0.11050
Value Function Update Magnitude: 0.18246

Collected Steps per Second: 10372.60990
Overall Steps per Second: 3288.48886

Timestep Collection Time: 4.82299
Timestep Consumption Time: 10.38977
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 15.21276

Cumulative Model Updates: 45192
Cumulative Timesteps: 377284921

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.04197
Policy Entropy: 1.06465
Value Function Loss: 0.02859

Mean KL Divergence: 0.02723
SB3 Clip Fraction: 0.16434
Policy Update Magnitude: 0.10406
Value Function Update Magnitude: 0.18164

Collected Steps per Second: 9871.28117
Overall Steps per Second: 7060.00831

Timestep Collection Time: 5.06520
Timestep Consumption Time: 2.01695
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.08214

Cumulative Model Updates: 45198
Cumulative Timesteps: 377334921

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 377334921...
Checkpoint 377334921 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.38445
Policy Entropy: 1.07084
Value Function Loss: 0.02763

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.10591
Value Function Update Magnitude: 0.17073

Collected Steps per Second: 9798.07705
Overall Steps per Second: 6953.77379

Timestep Collection Time: 5.10468
Timestep Consumption Time: 2.08797
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.19264

Cumulative Model Updates: 45204
Cumulative Timesteps: 377384937

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.05321
Policy Entropy: 1.07529
Value Function Loss: 0.02890

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.10855
Value Function Update Magnitude: 0.16681

Collected Steps per Second: 10378.64249
Overall Steps per Second: 7220.78572

Timestep Collection Time: 4.81980
Timestep Consumption Time: 2.10784
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 6.92764

Cumulative Model Updates: 45210
Cumulative Timesteps: 377434960

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.20205
Policy Entropy: 1.07495
Value Function Loss: 0.02926

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.10839
Value Function Update Magnitude: 0.17363

Collected Steps per Second: 9880.24205
Overall Steps per Second: 7056.08876

Timestep Collection Time: 5.06202
Timestep Consumption Time: 2.02604
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.08806

Cumulative Model Updates: 45216
Cumulative Timesteps: 377484974

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.16639
Policy Entropy: 1.07683
Value Function Loss: 0.03016

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.10414
Value Function Update Magnitude: 0.18067

Collected Steps per Second: 9701.37985
Overall Steps per Second: 6961.67672

Timestep Collection Time: 5.15700
Timestep Consumption Time: 2.02949
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.18649

Cumulative Model Updates: 45222
Cumulative Timesteps: 377535004

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.83680
Policy Entropy: 1.07779
Value Function Loss: 0.03111

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.15212
Policy Update Magnitude: 0.10302
Value Function Update Magnitude: 0.19311

Collected Steps per Second: 10481.71122
Overall Steps per Second: 7305.29500

Timestep Collection Time: 4.77355
Timestep Consumption Time: 2.07559
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 6.84914

Cumulative Model Updates: 45228
Cumulative Timesteps: 377585039

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.44878
Policy Entropy: 1.07154
Value Function Loss: 0.03321

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.10967
Value Function Update Magnitude: 0.19220

Collected Steps per Second: 9849.02224
Overall Steps per Second: 7000.50817

Timestep Collection Time: 5.07715
Timestep Consumption Time: 2.06590
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.14305

Cumulative Model Updates: 45234
Cumulative Timesteps: 377635044

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.37415
Policy Entropy: 1.07272
Value Function Loss: 0.03317

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.11010
Value Function Update Magnitude: 0.20672

Collected Steps per Second: 9733.78647
Overall Steps per Second: 7041.39236

Timestep Collection Time: 5.13736
Timestep Consumption Time: 1.96436
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.10172

Cumulative Model Updates: 45240
Cumulative Timesteps: 377685050

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.80175
Policy Entropy: 1.07479
Value Function Loss: 0.03230

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.11145
Value Function Update Magnitude: 0.18929

Collected Steps per Second: 10321.30235
Overall Steps per Second: 7240.72268

Timestep Collection Time: 4.84832
Timestep Consumption Time: 2.06273
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 6.91105

Cumulative Model Updates: 45246
Cumulative Timesteps: 377735091

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.05969
Policy Entropy: 1.07283
Value Function Loss: 0.03034

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.11321
Value Function Update Magnitude: 0.18358

Collected Steps per Second: 9790.39409
Overall Steps per Second: 6980.61827

Timestep Collection Time: 5.11021
Timestep Consumption Time: 2.05692
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.16713

Cumulative Model Updates: 45252
Cumulative Timesteps: 377785122

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.01622
Policy Entropy: 1.07190
Value Function Loss: 0.03033

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.15329
Policy Update Magnitude: 0.11205
Value Function Update Magnitude: 0.18271

Collected Steps per Second: 9778.17676
Overall Steps per Second: 7043.83337

Timestep Collection Time: 5.11353
Timestep Consumption Time: 1.98502
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.09855

Cumulative Model Updates: 45258
Cumulative Timesteps: 377835123

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 377835123...
Checkpoint 377835123 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.28950
Policy Entropy: 1.06617
Value Function Loss: 0.03108

Mean KL Divergence: 0.03568
SB3 Clip Fraction: 0.19470
Policy Update Magnitude: 0.10174
Value Function Update Magnitude: 0.19661

Collected Steps per Second: 10355.34549
Overall Steps per Second: 7264.32536

Timestep Collection Time: 4.83007
Timestep Consumption Time: 2.05523
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 6.88529

Cumulative Model Updates: 45264
Cumulative Timesteps: 377885140

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.08565
Policy Entropy: 1.06371
Value Function Loss: 0.03069

Mean KL Divergence: 0.03245
SB3 Clip Fraction: 0.18413
Policy Update Magnitude: 0.09209
Value Function Update Magnitude: 0.21168

Collected Steps per Second: 10011.00100
Overall Steps per Second: 7155.58972

Timestep Collection Time: 4.99481
Timestep Consumption Time: 1.99316
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.98796

Cumulative Model Updates: 45270
Cumulative Timesteps: 377935143

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.92502
Policy Entropy: 1.05585
Value Function Loss: 0.03103

Mean KL Divergence: 0.04480
SB3 Clip Fraction: 0.22051
Policy Update Magnitude: 0.09223
Value Function Update Magnitude: 0.21306

Collected Steps per Second: 10307.25285
Overall Steps per Second: 7237.25688

Timestep Collection Time: 4.85454
Timestep Consumption Time: 2.05926
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 6.91381

Cumulative Model Updates: 45276
Cumulative Timesteps: 377985180

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.61988
Policy Entropy: 1.03570
Value Function Loss: 0.03111

Mean KL Divergence: 0.03722
SB3 Clip Fraction: 0.20109
Policy Update Magnitude: 0.09081
Value Function Update Magnitude: 0.22463

Collected Steps per Second: 10220.62352
Overall Steps per Second: 7159.27070

Timestep Collection Time: 4.89236
Timestep Consumption Time: 2.09201
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.98437

Cumulative Model Updates: 45282
Cumulative Timesteps: 378035183

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.05125
Policy Entropy: 1.04800
Value Function Loss: 0.03113

Mean KL Divergence: 0.03182
SB3 Clip Fraction: 0.19343
Policy Update Magnitude: 0.09101
Value Function Update Magnitude: 0.22281

Collected Steps per Second: 9871.75353
Overall Steps per Second: 7070.80345

Timestep Collection Time: 5.06800
Timestep Consumption Time: 2.00758
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.07557

Cumulative Model Updates: 45288
Cumulative Timesteps: 378085213

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.62802
Policy Entropy: 1.05011
Value Function Loss: 0.03066

Mean KL Divergence: 0.03240
SB3 Clip Fraction: 0.18845
Policy Update Magnitude: 0.09106
Value Function Update Magnitude: 0.20566

Collected Steps per Second: 10432.28505
Overall Steps per Second: 7285.00658

Timestep Collection Time: 4.79368
Timestep Consumption Time: 2.07097
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 6.86465

Cumulative Model Updates: 45294
Cumulative Timesteps: 378135222

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.31265
Policy Entropy: 1.05272
Value Function Loss: 0.03077

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.16319
Policy Update Magnitude: 0.09208
Value Function Update Magnitude: 0.20130

Collected Steps per Second: 9913.14955
Overall Steps per Second: 6978.17247

Timestep Collection Time: 5.04562
Timestep Consumption Time: 2.12216
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.16778

Cumulative Model Updates: 45300
Cumulative Timesteps: 378185240

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.05932
Policy Entropy: 1.05569
Value Function Loss: 0.03132

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.10360
Value Function Update Magnitude: 0.20178

Collected Steps per Second: 9735.46120
Overall Steps per Second: 7003.94135

Timestep Collection Time: 5.13761
Timestep Consumption Time: 2.00366
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.14126

Cumulative Model Updates: 45306
Cumulative Timesteps: 378235257

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.47679
Policy Entropy: 1.05461
Value Function Loss: 0.03159

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.11264
Value Function Update Magnitude: 0.20110

Collected Steps per Second: 10434.38410
Overall Steps per Second: 7281.92248

Timestep Collection Time: 4.79348
Timestep Consumption Time: 2.07517
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 6.86865

Cumulative Model Updates: 45312
Cumulative Timesteps: 378285274

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.71585
Policy Entropy: 1.05746
Value Function Loss: 0.03263

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.11489
Value Function Update Magnitude: 0.19622

Collected Steps per Second: 9822.48703
Overall Steps per Second: 6982.74694

Timestep Collection Time: 5.09219
Timestep Consumption Time: 2.07089
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.16308

Cumulative Model Updates: 45318
Cumulative Timesteps: 378335292

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 378335292...
Checkpoint 378335292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.45257
Policy Entropy: 1.03981
Value Function Loss: 0.03071

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.16214
Policy Update Magnitude: 0.11143
Value Function Update Magnitude: 0.19314

Collected Steps per Second: 9761.24278
Overall Steps per Second: 6950.99783

Timestep Collection Time: 5.12414
Timestep Consumption Time: 2.07166
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.19580

Cumulative Model Updates: 45324
Cumulative Timesteps: 378385310

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.81380
Policy Entropy: 1.03436
Value Function Loss: 0.03103

Mean KL Divergence: 0.02669
SB3 Clip Fraction: 0.16428
Policy Update Magnitude: 0.10488
Value Function Update Magnitude: 0.20094

Collected Steps per Second: 10341.12930
Overall Steps per Second: 7235.40786

Timestep Collection Time: 4.83719
Timestep Consumption Time: 2.07631
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.91350

Cumulative Model Updates: 45330
Cumulative Timesteps: 378435332

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.47292
Policy Entropy: 1.04140
Value Function Loss: 0.02894

Mean KL Divergence: 0.03710
SB3 Clip Fraction: 0.20663
Policy Update Magnitude: 0.09573
Value Function Update Magnitude: 0.20378

Collected Steps per Second: 9772.65033
Overall Steps per Second: 7023.31998

Timestep Collection Time: 5.12062
Timestep Consumption Time: 2.00450
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.12512

Cumulative Model Updates: 45336
Cumulative Timesteps: 378485374

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.95847
Policy Entropy: 1.03551
Value Function Loss: 0.03081

Mean KL Divergence: 0.03962
SB3 Clip Fraction: 0.20937
Policy Update Magnitude: 0.09238
Value Function Update Magnitude: 0.19369

Collected Steps per Second: 9779.15384
Overall Steps per Second: 7000.35068

Timestep Collection Time: 5.11650
Timestep Consumption Time: 2.03100
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.14750

Cumulative Model Updates: 45342
Cumulative Timesteps: 378535409

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.97889
Policy Entropy: 1.05391
Value Function Loss: 0.02984

Mean KL Divergence: 0.04471
SB3 Clip Fraction: 0.21963
Policy Update Magnitude: 0.09027
Value Function Update Magnitude: 0.18846

Collected Steps per Second: 10563.62062
Overall Steps per Second: 7542.77408

Timestep Collection Time: 4.73493
Timestep Consumption Time: 1.89632
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.63125

Cumulative Model Updates: 45348
Cumulative Timesteps: 378585427

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.54042
Policy Entropy: 1.03004
Value Function Loss: 0.03031

Mean KL Divergence: 0.03930
SB3 Clip Fraction: 0.21185
Policy Update Magnitude: 0.09167
Value Function Update Magnitude: 0.18762

Collected Steps per Second: 9804.04265
Overall Steps per Second: 6952.31232

Timestep Collection Time: 5.10391
Timestep Consumption Time: 2.09355
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.19746

Cumulative Model Updates: 45354
Cumulative Timesteps: 378635466

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.07471
Policy Entropy: 1.05469
Value Function Loss: 0.03127

Mean KL Divergence: 0.02944
SB3 Clip Fraction: 0.17923
Policy Update Magnitude: 0.10394
Value Function Update Magnitude: 0.18734

Collected Steps per Second: 9805.84857
Overall Steps per Second: 7022.39810

Timestep Collection Time: 5.09910
Timestep Consumption Time: 2.02112
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.12022

Cumulative Model Updates: 45360
Cumulative Timesteps: 378685467

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.90734
Policy Entropy: 1.05060
Value Function Loss: 0.03184

Mean KL Divergence: 0.02735
SB3 Clip Fraction: 0.17124
Policy Update Magnitude: 0.11728
Value Function Update Magnitude: 0.18939

Collected Steps per Second: 10393.45214
Overall Steps per Second: 7271.30505

Timestep Collection Time: 4.81226
Timestep Consumption Time: 2.06628
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 6.87855

Cumulative Model Updates: 45366
Cumulative Timesteps: 378735483

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.81940
Policy Entropy: 1.06094
Value Function Loss: 0.03119

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.11615
Value Function Update Magnitude: 0.18769

Collected Steps per Second: 9896.04013
Overall Steps per Second: 7093.39221

Timestep Collection Time: 5.05616
Timestep Consumption Time: 1.99773
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.05389

Cumulative Model Updates: 45372
Cumulative Timesteps: 378785519

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.40254
Policy Entropy: 1.06621
Value Function Loss: 0.02914

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.10619
Value Function Update Magnitude: 0.18246

Collected Steps per Second: 9721.55823
Overall Steps per Second: 6964.90539

Timestep Collection Time: 5.14660
Timestep Consumption Time: 2.03698
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.18359

Cumulative Model Updates: 45378
Cumulative Timesteps: 378835552

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 378835552...
Checkpoint 378835552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.33438
Policy Entropy: 1.06693
Value Function Loss: 0.02855

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.10069
Value Function Update Magnitude: 0.17667

Collected Steps per Second: 10634.22025
Overall Steps per Second: 7385.09875

Timestep Collection Time: 4.70199
Timestep Consumption Time: 2.06867
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 6.77066

Cumulative Model Updates: 45384
Cumulative Timesteps: 378885554

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.60477
Policy Entropy: 1.06726
Value Function Loss: 0.02995

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.09989
Value Function Update Magnitude: 0.17634

Collected Steps per Second: 9996.88381
Overall Steps per Second: 7026.06845

Timestep Collection Time: 5.00406
Timestep Consumption Time: 2.11585
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.11991

Cumulative Model Updates: 45390
Cumulative Timesteps: 378935579

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.08103
Policy Entropy: 1.06119
Value Function Loss: 0.03028

Mean KL Divergence: 0.02509
SB3 Clip Fraction: 0.16042
Policy Update Magnitude: 0.10525
Value Function Update Magnitude: 0.17538

Collected Steps per Second: 9839.51024
Overall Steps per Second: 7037.73834

Timestep Collection Time: 5.08399
Timestep Consumption Time: 2.02397
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.10797

Cumulative Model Updates: 45396
Cumulative Timesteps: 378985603

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.15413
Policy Entropy: 1.06847
Value Function Loss: 0.03103

Mean KL Divergence: 0.03569
SB3 Clip Fraction: 0.20490
Policy Update Magnitude: 0.09829
Value Function Update Magnitude: 0.17357

Collected Steps per Second: 10883.39874
Overall Steps per Second: 7518.87023

Timestep Collection Time: 4.59452
Timestep Consumption Time: 2.05595
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.65047

Cumulative Model Updates: 45402
Cumulative Timesteps: 379035607

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.27669
Policy Entropy: 1.05635
Value Function Loss: 0.03014

Mean KL Divergence: 0.02246
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.10243
Value Function Update Magnitude: 0.17257

Collected Steps per Second: 9919.18462
Overall Steps per Second: 6998.16645

Timestep Collection Time: 5.04467
Timestep Consumption Time: 2.10563
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.15030

Cumulative Model Updates: 45408
Cumulative Timesteps: 379085646

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.68572
Policy Entropy: 1.06201
Value Function Loss: 0.03058

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.11233
Value Function Update Magnitude: 0.17789

Collected Steps per Second: 9673.26513
Overall Steps per Second: 6956.02318

Timestep Collection Time: 5.17261
Timestep Consumption Time: 2.02058
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.19319

Cumulative Model Updates: 45414
Cumulative Timesteps: 379135682

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.12239
Policy Entropy: 1.04438
Value Function Loss: 0.02939

Mean KL Divergence: 0.02757
SB3 Clip Fraction: 0.16166
Policy Update Magnitude: 0.10921
Value Function Update Magnitude: 0.18398

Collected Steps per Second: 10370.35516
Overall Steps per Second: 7251.86646

Timestep Collection Time: 4.82568
Timestep Consumption Time: 2.07517
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 6.90084

Cumulative Model Updates: 45420
Cumulative Timesteps: 379185726

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.94501
Policy Entropy: 1.04152
Value Function Loss: 0.03146

Mean KL Divergence: 0.04572
SB3 Clip Fraction: 0.20164
Policy Update Magnitude: 0.11025
Value Function Update Magnitude: 0.18338

Collected Steps per Second: 9969.69185
Overall Steps per Second: 7147.99239

Timestep Collection Time: 5.01921
Timestep Consumption Time: 1.98135
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.00057

Cumulative Model Updates: 45426
Cumulative Timesteps: 379235766

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.47203
Policy Entropy: 1.05355
Value Function Loss: 0.03067

Mean KL Divergence: 0.04024
SB3 Clip Fraction: 0.20507
Policy Update Magnitude: 0.09612
Value Function Update Magnitude: 0.18229

Collected Steps per Second: 9721.67764
Overall Steps per Second: 6917.61782

Timestep Collection Time: 5.14417
Timestep Consumption Time: 2.08519
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 7.22937

Cumulative Model Updates: 45432
Cumulative Timesteps: 379285776

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.30620
Policy Entropy: 1.05473
Value Function Loss: 0.03130

Mean KL Divergence: 0.03852
SB3 Clip Fraction: 0.21019
Policy Update Magnitude: 0.09077
Value Function Update Magnitude: 0.18159

Collected Steps per Second: 10415.95627
Overall Steps per Second: 7249.46080

Timestep Collection Time: 4.80446
Timestep Consumption Time: 2.09854
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.90300

Cumulative Model Updates: 45438
Cumulative Timesteps: 379335819

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 379335819...
Checkpoint 379335819 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.61856
Policy Entropy: 1.05258
Value Function Loss: 0.03055

Mean KL Divergence: 0.03372
SB3 Clip Fraction: 0.19389
Policy Update Magnitude: 0.08691
Value Function Update Magnitude: 0.18126

Collected Steps per Second: 9771.11720
Overall Steps per Second: 6998.82472

Timestep Collection Time: 5.11886
Timestep Consumption Time: 2.02762
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.14649

Cumulative Model Updates: 45444
Cumulative Timesteps: 379385836

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.10295
Policy Entropy: 1.04523
Value Function Loss: 0.02998

Mean KL Divergence: 0.04670
SB3 Clip Fraction: 0.22461
Policy Update Magnitude: 0.08835
Value Function Update Magnitude: 0.18704

Collected Steps per Second: 9673.44086
Overall Steps per Second: 6983.76513

Timestep Collection Time: 5.16921
Timestep Consumption Time: 1.99083
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.16003

Cumulative Model Updates: 45450
Cumulative Timesteps: 379435840

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.48891
Policy Entropy: 1.04089
Value Function Loss: 0.02926

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.15681
Policy Update Magnitude: 0.09941
Value Function Update Magnitude: 0.18421

Collected Steps per Second: 10401.82062
Overall Steps per Second: 7275.74570

Timestep Collection Time: 4.80973
Timestep Consumption Time: 2.06654
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 6.87627

Cumulative Model Updates: 45456
Cumulative Timesteps: 379485870

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.09577
Policy Entropy: 1.04773
Value Function Loss: 0.02963

Mean KL Divergence: 0.02661
SB3 Clip Fraction: 0.16076
Policy Update Magnitude: 0.10127
Value Function Update Magnitude: 0.18196

Collected Steps per Second: 9667.34706
Overall Steps per Second: 6936.89915

Timestep Collection Time: 5.17577
Timestep Consumption Time: 2.03725
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.21302

Cumulative Model Updates: 45462
Cumulative Timesteps: 379535906

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.90817
Policy Entropy: 1.04602
Value Function Loss: 0.03234

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.16316
Policy Update Magnitude: 0.10460
Value Function Update Magnitude: 0.18410

Collected Steps per Second: 9585.05298
Overall Steps per Second: 6895.52882

Timestep Collection Time: 5.21750
Timestep Consumption Time: 2.03503
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 7.25253

Cumulative Model Updates: 45468
Cumulative Timesteps: 379585916

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.37545
Policy Entropy: 1.05569
Value Function Loss: 0.03280

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.14848
Policy Update Magnitude: 0.11617
Value Function Update Magnitude: 0.19016

Collected Steps per Second: 10250.02694
Overall Steps per Second: 7180.27738

Timestep Collection Time: 4.88038
Timestep Consumption Time: 2.08648
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 6.96686

Cumulative Model Updates: 45474
Cumulative Timesteps: 379635940

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.64129
Policy Entropy: 1.06098
Value Function Loss: 0.03251

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.11363
Value Function Update Magnitude: 0.19428

Collected Steps per Second: 9860.04124
Overall Steps per Second: 7060.30741

Timestep Collection Time: 5.07432
Timestep Consumption Time: 2.01220
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.08652

Cumulative Model Updates: 45480
Cumulative Timesteps: 379685973

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.61263
Policy Entropy: 1.07261
Value Function Loss: 0.03090

Mean KL Divergence: 0.02978
SB3 Clip Fraction: 0.17879
Policy Update Magnitude: 0.10849
Value Function Update Magnitude: 0.18953

Collected Steps per Second: 9938.76354
Overall Steps per Second: 7105.08939

Timestep Collection Time: 5.03533
Timestep Consumption Time: 2.00821
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.04354

Cumulative Model Updates: 45486
Cumulative Timesteps: 379736018

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.36039
Policy Entropy: 1.07130
Value Function Loss: 0.03117

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.17016
Policy Update Magnitude: 0.10217
Value Function Update Magnitude: 0.18714

Collected Steps per Second: 10284.75795
Overall Steps per Second: 7215.09455

Timestep Collection Time: 4.86234
Timestep Consumption Time: 2.06868
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 6.93102

Cumulative Model Updates: 45492
Cumulative Timesteps: 379786026

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.10771
Policy Entropy: 1.06792
Value Function Loss: 0.03120

Mean KL Divergence: 0.02927
SB3 Clip Fraction: 0.16797
Policy Update Magnitude: 0.10674
Value Function Update Magnitude: 0.19392

Collected Steps per Second: 9759.21150
Overall Steps per Second: 7017.21025

Timestep Collection Time: 5.12521
Timestep Consumption Time: 2.00269
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 7.12790

Cumulative Model Updates: 45498
Cumulative Timesteps: 379836044

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 379836044...
Checkpoint 379836044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.58466
Policy Entropy: 1.06731
Value Function Loss: 0.03223

Mean KL Divergence: 0.02428
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.10291
Value Function Update Magnitude: 0.19470

Collected Steps per Second: 9714.01241
Overall Steps per Second: 6979.48034

Timestep Collection Time: 5.14978
Timestep Consumption Time: 2.01766
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.16744

Cumulative Model Updates: 45504
Cumulative Timesteps: 379886069

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.98850
Policy Entropy: 1.07059
Value Function Loss: 0.03307

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.10162
Value Function Update Magnitude: 0.19914

Collected Steps per Second: 10515.56086
Overall Steps per Second: 7324.66984

Timestep Collection Time: 4.75809
Timestep Consumption Time: 2.07280
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 6.83089

Cumulative Model Updates: 45510
Cumulative Timesteps: 379936103

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.69188
Policy Entropy: 1.06572
Value Function Loss: 0.03212

Mean KL Divergence: 0.03173
SB3 Clip Fraction: 0.17844
Policy Update Magnitude: 0.10242
Value Function Update Magnitude: 0.19809

Collected Steps per Second: 9868.62411
Overall Steps per Second: 7102.71244

Timestep Collection Time: 5.06829
Timestep Consumption Time: 1.97367
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.04196

Cumulative Model Updates: 45516
Cumulative Timesteps: 379986120

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.77207
Policy Entropy: 1.06610
Value Function Loss: 0.03226

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.15744
Policy Update Magnitude: 0.09464
Value Function Update Magnitude: 0.19283

Collected Steps per Second: 9712.06548
Overall Steps per Second: 6955.22508

Timestep Collection Time: 5.14947
Timestep Consumption Time: 2.04109
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.19057

Cumulative Model Updates: 45522
Cumulative Timesteps: 380036132

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.06797
Policy Entropy: 1.09326
Value Function Loss: 0.03045

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.18083
Policy Update Magnitude: 0.09933
Value Function Update Magnitude: 0.18714

Collected Steps per Second: 10478.60059
Overall Steps per Second: 7309.44865

Timestep Collection Time: 4.77239
Timestep Consumption Time: 2.06916
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 6.84156

Cumulative Model Updates: 45528
Cumulative Timesteps: 380086140

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.07435
Policy Entropy: 1.09070
Value Function Loss: 0.03121

Mean KL Divergence: 0.03041
SB3 Clip Fraction: 0.17670
Policy Update Magnitude: 0.10333
Value Function Update Magnitude: 0.18625

Collected Steps per Second: 9853.13119
Overall Steps per Second: 6984.41079

Timestep Collection Time: 5.07808
Timestep Consumption Time: 2.08573
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.16381

Cumulative Model Updates: 45534
Cumulative Timesteps: 380136175

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.91030
Policy Entropy: 1.09659
Value Function Loss: 0.03151

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.15864
Policy Update Magnitude: 0.09566
Value Function Update Magnitude: 0.18883

Collected Steps per Second: 9842.86256
Overall Steps per Second: 6974.08322

Timestep Collection Time: 5.08013
Timestep Consumption Time: 2.08970
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 7.16983

Cumulative Model Updates: 45540
Cumulative Timesteps: 380186178

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.81522
Policy Entropy: 1.09692
Value Function Loss: 0.03180

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.16274
Policy Update Magnitude: 0.09984
Value Function Update Magnitude: 0.19646

Collected Steps per Second: 10380.57037
Overall Steps per Second: 7281.23890

Timestep Collection Time: 4.81833
Timestep Consumption Time: 2.05097
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 6.86930

Cumulative Model Updates: 45546
Cumulative Timesteps: 380236195

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.42570
Policy Entropy: 1.10054
Value Function Loss: 0.03174

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.10573
Value Function Update Magnitude: 0.19504

Collected Steps per Second: 9866.73639
Overall Steps per Second: 7059.82604

Timestep Collection Time: 5.07047
Timestep Consumption Time: 2.01596
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.08644

Cumulative Model Updates: 45552
Cumulative Timesteps: 380286224

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.49650
Policy Entropy: 1.09731
Value Function Loss: 0.03052

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.10599
Value Function Update Magnitude: 0.19175

Collected Steps per Second: 9937.24876
Overall Steps per Second: 7089.74971

Timestep Collection Time: 5.03469
Timestep Consumption Time: 2.02211
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.05681

Cumulative Model Updates: 45558
Cumulative Timesteps: 380336255

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 380336255...
Checkpoint 380336255 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.31344
Policy Entropy: 1.09295
Value Function Loss: 0.02962

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.10364
Value Function Update Magnitude: 0.20291

Collected Steps per Second: 10893.12029
Overall Steps per Second: 7526.68898

Timestep Collection Time: 4.59070
Timestep Consumption Time: 2.05326
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.64396

Cumulative Model Updates: 45564
Cumulative Timesteps: 380386262

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.59328
Policy Entropy: 1.10812
Value Function Loss: 0.03039

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.09905
Value Function Update Magnitude: 0.20437

Collected Steps per Second: 9838.63659
Overall Steps per Second: 7052.71089

Timestep Collection Time: 5.08627
Timestep Consumption Time: 2.00915
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.09543

Cumulative Model Updates: 45570
Cumulative Timesteps: 380436304

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.79915
Policy Entropy: 1.11814
Value Function Loss: 0.03073

Mean KL Divergence: 0.02254
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.10096
Value Function Update Magnitude: 0.20687

Collected Steps per Second: 9756.79376
Overall Steps per Second: 6969.78216

Timestep Collection Time: 5.12556
Timestep Consumption Time: 2.04956
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.17512

Cumulative Model Updates: 45576
Cumulative Timesteps: 380486313

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.36374
Policy Entropy: 1.11904
Value Function Loss: 0.03139

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.10348
Value Function Update Magnitude: 0.20516

Collected Steps per Second: 10177.45442
Overall Steps per Second: 7150.80420

Timestep Collection Time: 4.91410
Timestep Consumption Time: 2.07994
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 6.99404

Cumulative Model Updates: 45582
Cumulative Timesteps: 380536326

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.14009
Policy Entropy: 1.10701
Value Function Loss: 0.03048

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.10523
Value Function Update Magnitude: 0.20020

Collected Steps per Second: 10075.28940
Overall Steps per Second: 7300.84962

Timestep Collection Time: 4.96561
Timestep Consumption Time: 1.88701
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.85263

Cumulative Model Updates: 45588
Cumulative Timesteps: 380586356

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.83167
Policy Entropy: 1.12442
Value Function Loss: 0.03103

Mean KL Divergence: 0.02735
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.09519
Value Function Update Magnitude: 0.19657

Collected Steps per Second: 9908.68440
Overall Steps per Second: 7104.40971

Timestep Collection Time: 5.04880
Timestep Consumption Time: 1.99288
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.04168

Cumulative Model Updates: 45594
Cumulative Timesteps: 380636383

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.51462
Policy Entropy: 1.11358
Value Function Loss: 0.03183

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.15867
Policy Update Magnitude: 0.10200
Value Function Update Magnitude: 0.20354

Collected Steps per Second: 10461.60966
Overall Steps per Second: 7272.02766

Timestep Collection Time: 4.78292
Timestep Consumption Time: 2.09783
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 6.88075

Cumulative Model Updates: 45600
Cumulative Timesteps: 380686420

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.91217
Policy Entropy: 1.12305
Value Function Loss: 0.03197

Mean KL Divergence: 0.02705
SB3 Clip Fraction: 0.16091
Policy Update Magnitude: 0.10288
Value Function Update Magnitude: 0.20434

Collected Steps per Second: 9907.91979
Overall Steps per Second: 2681.91672

Timestep Collection Time: 5.04677
Timestep Consumption Time: 13.59773
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 18.64450

Cumulative Model Updates: 45606
Cumulative Timesteps: 380736423

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.53753
Policy Entropy: 1.11851
Value Function Loss: 0.03164

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.10438
Value Function Update Magnitude: 0.20185

Collected Steps per Second: 9844.42328
Overall Steps per Second: 2982.54643

Timestep Collection Time: 5.07942
Timestep Consumption Time: 11.68612
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 16.76554

Cumulative Model Updates: 45612
Cumulative Timesteps: 380786427

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.17921
Policy Entropy: 1.12519
Value Function Loss: 0.03004

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.10827
Value Function Update Magnitude: 0.20054

Collected Steps per Second: 10305.54932
Overall Steps per Second: 7291.99727

Timestep Collection Time: 4.85583
Timestep Consumption Time: 2.00676
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.86259

Cumulative Model Updates: 45618
Cumulative Timesteps: 380836469

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 380836469...
Checkpoint 380836469 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.31550
Policy Entropy: 1.12204
Value Function Loss: 0.03048

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.10917
Value Function Update Magnitude: 0.19671

Collected Steps per Second: 10334.60132
Overall Steps per Second: 7318.39907

Timestep Collection Time: 4.83918
Timestep Consumption Time: 1.99442
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 6.83360

Cumulative Model Updates: 45624
Cumulative Timesteps: 380886480

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.56934
Policy Entropy: 1.11460
Value Function Loss: 0.03087

Mean KL Divergence: 0.02257
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.10341
Value Function Update Magnitude: 0.20152

Collected Steps per Second: 9753.02272
Overall Steps per Second: 6988.97651

Timestep Collection Time: 5.13051
Timestep Consumption Time: 2.02905
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.15956

Cumulative Model Updates: 45630
Cumulative Timesteps: 380936518

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.37696
Policy Entropy: 1.11859
Value Function Loss: 0.03208

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.09304
Value Function Update Magnitude: 0.20520

Collected Steps per Second: 10876.21114
Overall Steps per Second: 7498.88663

Timestep Collection Time: 4.59903
Timestep Consumption Time: 2.07130
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 6.67032

Cumulative Model Updates: 45636
Cumulative Timesteps: 380986538

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.33765
Policy Entropy: 1.13142
Value Function Loss: 0.03335

Mean KL Divergence: 0.03034
SB3 Clip Fraction: 0.16784
Policy Update Magnitude: 0.09817
Value Function Update Magnitude: 0.20152

Collected Steps per Second: 9777.45634
Overall Steps per Second: 6912.21434

Timestep Collection Time: 5.11790
Timestep Consumption Time: 2.12146
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.23936

Cumulative Model Updates: 45642
Cumulative Timesteps: 381036578

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.86002
Policy Entropy: 1.12597
Value Function Loss: 0.03413

Mean KL Divergence: 0.02878
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.09307
Value Function Update Magnitude: 0.20675

Collected Steps per Second: 9648.46634
Overall Steps per Second: 6948.10920

Timestep Collection Time: 5.18580
Timestep Consumption Time: 2.01544
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.20124

Cumulative Model Updates: 45648
Cumulative Timesteps: 381086613

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.41561
Policy Entropy: 1.13941
Value Function Loss: 0.03249

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.16109
Policy Update Magnitude: 0.09924
Value Function Update Magnitude: 0.21605

Collected Steps per Second: 10366.09053
Overall Steps per Second: 7241.23504

Timestep Collection Time: 4.82419
Timestep Consumption Time: 2.08181
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 6.90600

Cumulative Model Updates: 45654
Cumulative Timesteps: 381136621

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.09987
Policy Entropy: 1.12247
Value Function Loss: 0.03040

Mean KL Divergence: 0.03017
SB3 Clip Fraction: 0.17113
Policy Update Magnitude: 0.09824
Value Function Update Magnitude: 0.21176

Collected Steps per Second: 9752.37904
Overall Steps per Second: 7004.02857

Timestep Collection Time: 5.12972
Timestep Consumption Time: 2.01288
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 7.14260

Cumulative Model Updates: 45660
Cumulative Timesteps: 381186648

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.33870
Policy Entropy: 1.13473
Value Function Loss: 0.03093

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.09541
Value Function Update Magnitude: 0.21746

Collected Steps per Second: 9799.22051
Overall Steps per Second: 7039.52138

Timestep Collection Time: 5.10326
Timestep Consumption Time: 2.00063
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.10389

Cumulative Model Updates: 45666
Cumulative Timesteps: 381236656

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.90394
Policy Entropy: 1.13198
Value Function Loss: 0.03175

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.10843
Value Function Update Magnitude: 0.22219

Collected Steps per Second: 10470.25314
Overall Steps per Second: 7297.84066

Timestep Collection Time: 4.77687
Timestep Consumption Time: 2.07653
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 6.85340

Cumulative Model Updates: 45672
Cumulative Timesteps: 381286671

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.98583
Policy Entropy: 1.13218
Value Function Loss: 0.03238

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.11188
Value Function Update Magnitude: 0.21826

Collected Steps per Second: 9822.57920
Overall Steps per Second: 6965.83484

Timestep Collection Time: 5.09337
Timestep Consumption Time: 2.08883
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.18220

Cumulative Model Updates: 45678
Cumulative Timesteps: 381336701

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 381336701...
Checkpoint 381336701 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.17959
Policy Entropy: 1.12990
Value Function Loss: 0.03223

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.11057
Value Function Update Magnitude: 0.21501

Collected Steps per Second: 10015.56597
Overall Steps per Second: 7133.94039

Timestep Collection Time: 4.99353
Timestep Consumption Time: 2.01704
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.01057

Cumulative Model Updates: 45684
Cumulative Timesteps: 381386714

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.24458
Policy Entropy: 1.13197
Value Function Loss: 0.03091

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.10861
Value Function Update Magnitude: 0.21456

Collected Steps per Second: 10395.29952
Overall Steps per Second: 7332.51354

Timestep Collection Time: 4.81044
Timestep Consumption Time: 2.00932
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.81976

Cumulative Model Updates: 45690
Cumulative Timesteps: 381436720

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.05640
Policy Entropy: 1.13772
Value Function Loss: 0.02999

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.10366
Value Function Update Magnitude: 0.20124

Collected Steps per Second: 9808.06913
Overall Steps per Second: 6948.17606

Timestep Collection Time: 5.10253
Timestep Consumption Time: 2.10022
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.20275

Cumulative Model Updates: 45696
Cumulative Timesteps: 381486766

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.13965
Policy Entropy: 1.13078
Value Function Loss: 0.03068

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.09935
Value Function Update Magnitude: 0.19636

Collected Steps per Second: 9767.33298
Overall Steps per Second: 7059.25002

Timestep Collection Time: 5.12074
Timestep Consumption Time: 1.96443
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.08517

Cumulative Model Updates: 45702
Cumulative Timesteps: 381536782

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.78885
Policy Entropy: 1.13089
Value Function Loss: 0.03107

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.09756
Value Function Update Magnitude: 0.19485

Collected Steps per Second: 10429.68947
Overall Steps per Second: 7228.14158

Timestep Collection Time: 4.79592
Timestep Consumption Time: 2.12425
PPO Batch Consumption Time: 0.02884
Total Iteration Time: 6.92017

Cumulative Model Updates: 45708
Cumulative Timesteps: 381586802

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.07547
Policy Entropy: 1.13316
Value Function Loss: 0.03254

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.10650
Value Function Update Magnitude: 0.19939

Collected Steps per Second: 9780.94848
Overall Steps per Second: 7021.67514

Timestep Collection Time: 5.11433
Timestep Consumption Time: 2.00975
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.12408

Cumulative Model Updates: 45714
Cumulative Timesteps: 381636825

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.84092
Policy Entropy: 1.13879
Value Function Loss: 0.03244

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.10910
Value Function Update Magnitude: 0.20381

Collected Steps per Second: 9748.21516
Overall Steps per Second: 548.90356

Timestep Collection Time: 5.13232
Timestep Consumption Time: 86.01483
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 91.14716

Cumulative Model Updates: 45720
Cumulative Timesteps: 381686856

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.57032
Policy Entropy: 1.13131
Value Function Loss: 0.03325

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.10799
Value Function Update Magnitude: 0.20493

Collected Steps per Second: 10381.11248
Overall Steps per Second: 7237.50755

Timestep Collection Time: 4.81731
Timestep Consumption Time: 2.09239
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 6.90970

Cumulative Model Updates: 45726
Cumulative Timesteps: 381736865

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.66355
Policy Entropy: 1.14912
Value Function Loss: 0.03248

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.10453
Value Function Update Magnitude: 0.19845

Collected Steps per Second: 9860.78347
Overall Steps per Second: 7067.46839

Timestep Collection Time: 5.07313
Timestep Consumption Time: 2.00508
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.07821

Cumulative Model Updates: 45732
Cumulative Timesteps: 381786890

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.76027
Policy Entropy: 1.15394
Value Function Loss: 0.03251

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.10696
Value Function Update Magnitude: 0.19740

Collected Steps per Second: 9808.43015
Overall Steps per Second: 7041.31872

Timestep Collection Time: 5.09929
Timestep Consumption Time: 2.00393
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.10321

Cumulative Model Updates: 45738
Cumulative Timesteps: 381836906

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 381836906...
Checkpoint 381836906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.41033
Policy Entropy: 1.16241
Value Function Loss: 0.03160

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.10656
Value Function Update Magnitude: 0.19426

Collected Steps per Second: 10513.33405
Overall Steps per Second: 7254.46936

Timestep Collection Time: 4.75625
Timestep Consumption Time: 2.13661
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 6.89285

Cumulative Model Updates: 45744
Cumulative Timesteps: 381886910

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.78988
Policy Entropy: 1.15642
Value Function Loss: 0.03077

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.09274
Value Function Update Magnitude: 0.19351

Collected Steps per Second: 9849.65008
Overall Steps per Second: 7046.17663

Timestep Collection Time: 5.07825
Timestep Consumption Time: 2.02049
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.09874

Cumulative Model Updates: 45750
Cumulative Timesteps: 381936929

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.58134
Policy Entropy: 1.15596
Value Function Loss: 0.03062

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.14881
Policy Update Magnitude: 0.08420
Value Function Update Magnitude: 0.19325

Collected Steps per Second: 10020.76410
Overall Steps per Second: 7118.69794

Timestep Collection Time: 4.99094
Timestep Consumption Time: 2.03465
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.02558

Cumulative Model Updates: 45756
Cumulative Timesteps: 381986942

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.51708
Policy Entropy: 1.15031
Value Function Loss: 0.03367

Mean KL Divergence: 0.02742
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.09101
Value Function Update Magnitude: 0.19106

Collected Steps per Second: 10530.65638
Overall Steps per Second: 7250.02097

Timestep Collection Time: 4.74861
Timestep Consumption Time: 2.14875
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 6.89736

Cumulative Model Updates: 45762
Cumulative Timesteps: 382036948

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.44382
Policy Entropy: 1.16718
Value Function Loss: 0.03506

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.10310
Value Function Update Magnitude: 0.20384

Collected Steps per Second: 10105.27073
Overall Steps per Second: 7184.68210

Timestep Collection Time: 4.94910
Timestep Consumption Time: 2.01182
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 6.96092

Cumulative Model Updates: 45768
Cumulative Timesteps: 382086960

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.12957
Policy Entropy: 1.17190
Value Function Loss: 0.03424

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.10658
Value Function Update Magnitude: 0.21067

Collected Steps per Second: 9815.78866
Overall Steps per Second: 6953.46351

Timestep Collection Time: 5.09658
Timestep Consumption Time: 2.09796
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.19454

Cumulative Model Updates: 45774
Cumulative Timesteps: 382136987

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.59951
Policy Entropy: 1.17592
Value Function Loss: 0.03264

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.10827
Value Function Update Magnitude: 0.20298

Collected Steps per Second: 10366.80955
Overall Steps per Second: 7258.30718

Timestep Collection Time: 4.82733
Timestep Consumption Time: 2.06739
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 6.89472

Cumulative Model Updates: 45780
Cumulative Timesteps: 382187031

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.17124
Policy Entropy: 1.17905
Value Function Loss: 0.03206

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.10794
Value Function Update Magnitude: 0.22470

Collected Steps per Second: 9889.55759
Overall Steps per Second: 7042.90109

Timestep Collection Time: 5.05907
Timestep Consumption Time: 2.04482
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 7.10389

Cumulative Model Updates: 45786
Cumulative Timesteps: 382237063

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.88587
Policy Entropy: 1.17804
Value Function Loss: 0.03228

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.10702
Value Function Update Magnitude: 0.21963

Collected Steps per Second: 9687.60524
Overall Steps per Second: 6984.24786

Timestep Collection Time: 5.16206
Timestep Consumption Time: 1.99805
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.16011

Cumulative Model Updates: 45792
Cumulative Timesteps: 382287071

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.97852
Policy Entropy: 1.18588
Value Function Loss: 0.03173

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.10654
Value Function Update Magnitude: 0.20953

Collected Steps per Second: 10381.41327
Overall Steps per Second: 7256.28592

Timestep Collection Time: 4.81938
Timestep Consumption Time: 2.07561
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 6.89499

Cumulative Model Updates: 45798
Cumulative Timesteps: 382337103

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 382337103...
Checkpoint 382337103 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.78718
Policy Entropy: 1.17998
Value Function Loss: 0.03285

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.10698
Value Function Update Magnitude: 0.21460

Collected Steps per Second: 9773.28877
Overall Steps per Second: 7030.60546

Timestep Collection Time: 5.11639
Timestep Consumption Time: 1.99594
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.11233

Cumulative Model Updates: 45804
Cumulative Timesteps: 382387107

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.23327
Policy Entropy: 1.18451
Value Function Loss: 0.03167

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.10540
Value Function Update Magnitude: 0.22423

Collected Steps per Second: 9888.94187
Overall Steps per Second: 7076.41968

Timestep Collection Time: 5.05706
Timestep Consumption Time: 2.00993
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.06699

Cumulative Model Updates: 45810
Cumulative Timesteps: 382437116

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.93735
Policy Entropy: 1.18189
Value Function Loss: 0.03228

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.10486
Value Function Update Magnitude: 0.22280

Collected Steps per Second: 10263.81118
Overall Steps per Second: 7203.44452

Timestep Collection Time: 4.87519
Timestep Consumption Time: 2.07121
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 6.94640

Cumulative Model Updates: 45816
Cumulative Timesteps: 382487154

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.47294
Policy Entropy: 1.18293
Value Function Loss: 0.03162

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.10310
Value Function Update Magnitude: 0.21775

Collected Steps per Second: 10114.52484
Overall Steps per Second: 7176.57262

Timestep Collection Time: 4.94467
Timestep Consumption Time: 2.02425
PPO Batch Consumption Time: 0.02925
Total Iteration Time: 6.96893

Cumulative Model Updates: 45822
Cumulative Timesteps: 382537167

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.75605
Policy Entropy: 1.18118
Value Function Loss: 0.03282

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.09888
Value Function Update Magnitude: 0.21695

Collected Steps per Second: 9674.95499
Overall Steps per Second: 6955.38429

Timestep Collection Time: 5.16809
Timestep Consumption Time: 2.02073
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.18882

Cumulative Model Updates: 45828
Cumulative Timesteps: 382587168

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.11141
Policy Entropy: 1.17808
Value Function Loss: 0.03253

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.10334
Policy Update Magnitude: 0.10441
Value Function Update Magnitude: 0.22030

Collected Steps per Second: 10395.15569
Overall Steps per Second: 7305.88123

Timestep Collection Time: 4.81089
Timestep Consumption Time: 2.03428
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 6.84517

Cumulative Model Updates: 45834
Cumulative Timesteps: 382637178

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.36174
Policy Entropy: 1.17760
Value Function Loss: 0.03227

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.10658
Value Function Update Magnitude: 0.21496

Collected Steps per Second: 9871.22326
Overall Steps per Second: 7080.80031

Timestep Collection Time: 5.06695
Timestep Consumption Time: 1.99680
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.06375

Cumulative Model Updates: 45840
Cumulative Timesteps: 382687195

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.43038
Policy Entropy: 1.16744
Value Function Loss: 0.03343

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.10401
Value Function Update Magnitude: 0.20822

Collected Steps per Second: 9804.73558
Overall Steps per Second: 7019.31414

Timestep Collection Time: 5.10366
Timestep Consumption Time: 2.02525
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 7.12890

Cumulative Model Updates: 45846
Cumulative Timesteps: 382737235

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.01610
Policy Entropy: 1.18434
Value Function Loss: 0.03281

Mean KL Divergence: 0.02467
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.10081
Value Function Update Magnitude: 0.21105

Collected Steps per Second: 10416.56446
Overall Steps per Second: 7242.20171

Timestep Collection Time: 4.80456
Timestep Consumption Time: 2.10591
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.91047

Cumulative Model Updates: 45852
Cumulative Timesteps: 382787282

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.53024
Policy Entropy: 1.18227
Value Function Loss: 0.03118

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.09761
Value Function Update Magnitude: 0.20861

Collected Steps per Second: 9891.34940
Overall Steps per Second: 7081.03789

Timestep Collection Time: 5.05553
Timestep Consumption Time: 2.00643
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.06196

Cumulative Model Updates: 45858
Cumulative Timesteps: 382837288

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 382837288...
Checkpoint 382837288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.26984
Policy Entropy: 1.18386
Value Function Loss: 0.03190

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.10457
Value Function Update Magnitude: 0.20666

Collected Steps per Second: 9842.46909
Overall Steps per Second: 7006.71902

Timestep Collection Time: 5.08216
Timestep Consumption Time: 2.05684
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 7.13900

Cumulative Model Updates: 45864
Cumulative Timesteps: 382887309

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.89909
Policy Entropy: 1.17600
Value Function Loss: 0.03093

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.10277
Value Function Update Magnitude: 0.20609

Collected Steps per Second: 10390.69021
Overall Steps per Second: 7284.04818

Timestep Collection Time: 4.81469
Timestep Consumption Time: 2.05346
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 6.86816

Cumulative Model Updates: 45870
Cumulative Timesteps: 382937337

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.21661
Policy Entropy: 1.17093
Value Function Loss: 0.03251

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.08732
Value Function Update Magnitude: 0.20124

Collected Steps per Second: 9981.74400
Overall Steps per Second: 7117.95274

Timestep Collection Time: 5.01105
Timestep Consumption Time: 2.01611
PPO Batch Consumption Time: 0.02854
Total Iteration Time: 7.02716

Cumulative Model Updates: 45876
Cumulative Timesteps: 382987356

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.10589
Policy Entropy: 1.17489
Value Function Loss: 0.03141

Mean KL Divergence: 0.03275
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.08583
Value Function Update Magnitude: 0.19703

Collected Steps per Second: 9662.50524
Overall Steps per Second: 6960.44030

Timestep Collection Time: 5.17857
Timestep Consumption Time: 2.01034
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.18891

Cumulative Model Updates: 45882
Cumulative Timesteps: 383037394

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.77999
Policy Entropy: 1.18356
Value Function Loss: 0.03181

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.09677
Value Function Update Magnitude: 0.20262

Collected Steps per Second: 10413.88052
Overall Steps per Second: 7234.68122

Timestep Collection Time: 4.80224
Timestep Consumption Time: 2.11029
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 6.91254

Cumulative Model Updates: 45888
Cumulative Timesteps: 383087404

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.40562
Policy Entropy: 1.18016
Value Function Loss: 0.03148

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.10074
Value Function Update Magnitude: 0.20241

Collected Steps per Second: 9908.64781
Overall Steps per Second: 6998.82325

Timestep Collection Time: 5.04711
Timestep Consumption Time: 2.09838
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.14549

Cumulative Model Updates: 45894
Cumulative Timesteps: 383137414

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.91699
Policy Entropy: 1.18114
Value Function Loss: 0.03219

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.09924
Value Function Update Magnitude: 0.20991

Collected Steps per Second: 9892.03650
Overall Steps per Second: 7070.89038

Timestep Collection Time: 5.05781
Timestep Consumption Time: 2.01797
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.07577

Cumulative Model Updates: 45900
Cumulative Timesteps: 383187446

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.92103
Policy Entropy: 1.18500
Value Function Loss: 0.03306

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.10742
Value Function Update Magnitude: 0.20615

Collected Steps per Second: 10319.15433
Overall Steps per Second: 7215.65541

Timestep Collection Time: 4.84604
Timestep Consumption Time: 2.08431
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 6.93035

Cumulative Model Updates: 45906
Cumulative Timesteps: 383237453

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.18377
Policy Entropy: 1.19018
Value Function Loss: 0.03231

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.10767
Value Function Update Magnitude: 0.21172

Collected Steps per Second: 9910.11180
Overall Steps per Second: 7025.99098

Timestep Collection Time: 5.04909
Timestep Consumption Time: 2.07261
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.12170

Cumulative Model Updates: 45912
Cumulative Timesteps: 383287490

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.49730
Policy Entropy: 1.18483
Value Function Loss: 0.03177

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.10318
Value Function Update Magnitude: 0.21630

Collected Steps per Second: 9655.97047
Overall Steps per Second: 6871.58003

Timestep Collection Time: 5.18177
Timestep Consumption Time: 2.09967
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.28144

Cumulative Model Updates: 45918
Cumulative Timesteps: 383337525

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 383337525...
Checkpoint 383337525 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.03401
Policy Entropy: 1.18015
Value Function Loss: 0.03179

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.14881
Policy Update Magnitude: 0.09463
Value Function Update Magnitude: 0.20618

Collected Steps per Second: 10473.10017
Overall Steps per Second: 7281.05699

Timestep Collection Time: 4.77509
Timestep Consumption Time: 2.09342
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.86851

Cumulative Model Updates: 45924
Cumulative Timesteps: 383387535

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.80860
Policy Entropy: 1.17691
Value Function Loss: 0.03126

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.09523
Value Function Update Magnitude: 0.20560

Collected Steps per Second: 9878.17840
Overall Steps per Second: 7065.20706

Timestep Collection Time: 5.06318
Timestep Consumption Time: 2.01588
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.07906

Cumulative Model Updates: 45930
Cumulative Timesteps: 383437550

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.62091
Policy Entropy: 1.16708
Value Function Loss: 0.03129

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.10759
Value Function Update Magnitude: 0.21190

Collected Steps per Second: 9727.42168
Overall Steps per Second: 6997.96276

Timestep Collection Time: 5.14134
Timestep Consumption Time: 2.00531
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.14665

Cumulative Model Updates: 45936
Cumulative Timesteps: 383487562

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.31516
Policy Entropy: 1.16609
Value Function Loss: 0.03063

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.11035
Value Function Update Magnitude: 0.20506

Collected Steps per Second: 10311.72844
Overall Steps per Second: 7198.03401

Timestep Collection Time: 4.84894
Timestep Consumption Time: 2.09754
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.94648

Cumulative Model Updates: 45942
Cumulative Timesteps: 383537563

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.14885
Policy Entropy: 1.16387
Value Function Loss: 0.03107

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.10669
Value Function Update Magnitude: 0.19340

Collected Steps per Second: 9874.48080
Overall Steps per Second: 5357.91888

Timestep Collection Time: 5.06477
Timestep Consumption Time: 4.26945
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 9.33422

Cumulative Model Updates: 45948
Cumulative Timesteps: 383587575

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.82662
Policy Entropy: 1.16527
Value Function Loss: 0.03119

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.10744
Value Function Update Magnitude: 0.19027

Collected Steps per Second: 9649.12398
Overall Steps per Second: 6960.33545

Timestep Collection Time: 5.18627
Timestep Consumption Time: 2.00347
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.18974

Cumulative Model Updates: 45954
Cumulative Timesteps: 383637618

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.27707
Policy Entropy: 1.16102
Value Function Loss: 0.03100

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.10544
Value Function Update Magnitude: 0.19461

Collected Steps per Second: 10489.52227
Overall Steps per Second: 4228.93341

Timestep Collection Time: 4.76685
Timestep Consumption Time: 7.05693
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 11.82379

Cumulative Model Updates: 45960
Cumulative Timesteps: 383687620

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.38380
Policy Entropy: 1.16234
Value Function Loss: 0.03297

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.11215
Value Function Update Magnitude: 0.20576

Collected Steps per Second: 9788.74958
Overall Steps per Second: 6946.98745

Timestep Collection Time: 5.10872
Timestep Consumption Time: 2.08979
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.19852

Cumulative Model Updates: 45966
Cumulative Timesteps: 383737628

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.22749
Policy Entropy: 1.15786
Value Function Loss: 0.03386

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.10609
Value Function Update Magnitude: 0.20627

Collected Steps per Second: 9818.45563
Overall Steps per Second: 7026.58648

Timestep Collection Time: 5.09479
Timestep Consumption Time: 2.02431
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.11910

Cumulative Model Updates: 45972
Cumulative Timesteps: 383787651

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.84499
Policy Entropy: 1.19018
Value Function Loss: 0.03325

Mean KL Divergence: 0.02820
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.10102
Value Function Update Magnitude: 0.20762

Collected Steps per Second: 10325.21965
Overall Steps per Second: 7384.26388

Timestep Collection Time: 4.84358
Timestep Consumption Time: 1.92907
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 6.77265

Cumulative Model Updates: 45978
Cumulative Timesteps: 383837662

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 383837662...
Checkpoint 383837662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.73873
Policy Entropy: 1.17454
Value Function Loss: 0.03195

Mean KL Divergence: 0.03108
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.10175
Value Function Update Magnitude: 0.20911

Collected Steps per Second: 9802.63192
Overall Steps per Second: 7033.91094

Timestep Collection Time: 5.10312
Timestep Consumption Time: 2.00871
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.11183

Cumulative Model Updates: 45984
Cumulative Timesteps: 383887686

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.05025
Policy Entropy: 1.18606
Value Function Loss: 0.03121

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.10627
Value Function Update Magnitude: 0.20136

Collected Steps per Second: 9719.60681
Overall Steps per Second: 6987.89651

Timestep Collection Time: 5.14578
Timestep Consumption Time: 2.01159
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.15738

Cumulative Model Updates: 45990
Cumulative Timesteps: 383937701

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.11125
Policy Entropy: 1.18027
Value Function Loss: 0.03267

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.10851
Value Function Update Magnitude: 0.20377

Collected Steps per Second: 10292.60996
Overall Steps per Second: 7189.91798

Timestep Collection Time: 4.85960
Timestep Consumption Time: 2.09708
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 6.95669

Cumulative Model Updates: 45996
Cumulative Timesteps: 383987719

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.26590
Policy Entropy: 1.17968
Value Function Loss: 0.03278

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.11121
Value Function Update Magnitude: 0.21146

Collected Steps per Second: 10071.56584
Overall Steps per Second: 7101.88896

Timestep Collection Time: 4.96705
Timestep Consumption Time: 2.07699
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.04404

Cumulative Model Updates: 46002
Cumulative Timesteps: 384037745

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.45413
Policy Entropy: 1.17195
Value Function Loss: 0.03187

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.10590
Value Function Update Magnitude: 0.20695

Collected Steps per Second: 10095.71756
Overall Steps per Second: 7148.08649

Timestep Collection Time: 4.95289
Timestep Consumption Time: 2.04241
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 6.99530

Cumulative Model Updates: 46008
Cumulative Timesteps: 384087748

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.42936
Policy Entropy: 1.16776
Value Function Loss: 0.03203

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.11054
Value Function Update Magnitude: 0.19454

Collected Steps per Second: 10356.08206
Overall Steps per Second: 7220.16488

Timestep Collection Time: 4.83243
Timestep Consumption Time: 2.09886
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 6.93128

Cumulative Model Updates: 46014
Cumulative Timesteps: 384137793

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.47365
Policy Entropy: 1.17096
Value Function Loss: 0.03305

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.10841
Value Function Update Magnitude: 0.19944

Collected Steps per Second: 10015.31539
Overall Steps per Second: 7270.08525

Timestep Collection Time: 4.99545
Timestep Consumption Time: 1.88631
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.88176

Cumulative Model Updates: 46020
Cumulative Timesteps: 384187824

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.44520
Policy Entropy: 1.17114
Value Function Loss: 0.03260

Mean KL Divergence: 0.03181
SB3 Clip Fraction: 0.16262
Policy Update Magnitude: 0.09539
Value Function Update Magnitude: 0.20975

Collected Steps per Second: 9876.83514
Overall Steps per Second: 6994.81953

Timestep Collection Time: 5.06549
Timestep Consumption Time: 2.08709
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 7.15258

Cumulative Model Updates: 46026
Cumulative Timesteps: 384237855

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.73583
Policy Entropy: 1.17229
Value Function Loss: 0.03363

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.08598
Value Function Update Magnitude: 0.22190

Collected Steps per Second: 10383.21849
Overall Steps per Second: 7248.27277

Timestep Collection Time: 4.81566
Timestep Consumption Time: 2.08282
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 6.89847

Cumulative Model Updates: 46032
Cumulative Timesteps: 384287857

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.85237
Policy Entropy: 1.16533
Value Function Loss: 0.03303

Mean KL Divergence: 0.02921
SB3 Clip Fraction: 0.15681
Policy Update Magnitude: 0.08142
Value Function Update Magnitude: 0.22402

Collected Steps per Second: 9809.50920
Overall Steps per Second: 7030.87129

Timestep Collection Time: 5.09781
Timestep Consumption Time: 2.01468
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.11249

Cumulative Model Updates: 46038
Cumulative Timesteps: 384337864

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 384337864...
Checkpoint 384337864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.69113
Policy Entropy: 1.15949
Value Function Loss: 0.03314

Mean KL Divergence: 0.02250
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.09127
Value Function Update Magnitude: 0.22867

Collected Steps per Second: 9699.56072
Overall Steps per Second: 6975.33979

Timestep Collection Time: 5.15941
Timestep Consumption Time: 2.01501
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.17442

Cumulative Model Updates: 46044
Cumulative Timesteps: 384387908

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.62984
Policy Entropy: 1.15890
Value Function Loss: 0.03179

Mean KL Divergence: 0.02940
SB3 Clip Fraction: 0.14911
Policy Update Magnitude: 0.09323
Value Function Update Magnitude: 0.21732

Collected Steps per Second: 10436.85879
Overall Steps per Second: 7236.08344

Timestep Collection Time: 4.79320
Timestep Consumption Time: 2.12020
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 6.91341

Cumulative Model Updates: 46050
Cumulative Timesteps: 384437934

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.88340
Policy Entropy: 1.15777
Value Function Loss: 0.03087

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.10053
Value Function Update Magnitude: 0.20983

Collected Steps per Second: 9933.93645
Overall Steps per Second: 7087.05748

Timestep Collection Time: 5.03698
Timestep Consumption Time: 2.02336
PPO Batch Consumption Time: 0.02851
Total Iteration Time: 7.06034

Cumulative Model Updates: 46056
Cumulative Timesteps: 384487971

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.16844
Policy Entropy: 1.15710
Value Function Loss: 0.03126

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.10622
Value Function Update Magnitude: 0.20045

Collected Steps per Second: 9865.21021
Overall Steps per Second: 7098.05772

Timestep Collection Time: 5.07095
Timestep Consumption Time: 1.97689
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.04784

Cumulative Model Updates: 46062
Cumulative Timesteps: 384537997

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.32901
Policy Entropy: 1.15118
Value Function Loss: 0.03252

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.11325
Value Function Update Magnitude: 0.19608

Collected Steps per Second: 10721.89368
Overall Steps per Second: 7386.80585

Timestep Collection Time: 4.66755
Timestep Consumption Time: 2.10737
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 6.77492

Cumulative Model Updates: 46068
Cumulative Timesteps: 384588042

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.63992
Policy Entropy: 1.15707
Value Function Loss: 0.03259

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.10627
Value Function Update Magnitude: 0.20155

Collected Steps per Second: 9833.31148
Overall Steps per Second: 7030.14676

Timestep Collection Time: 5.08628
Timestep Consumption Time: 2.02808
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.11436

Cumulative Model Updates: 46074
Cumulative Timesteps: 384638057

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.49998
Policy Entropy: 1.15245
Value Function Loss: 0.03303

Mean KL Divergence: 0.02981
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.09188
Value Function Update Magnitude: 0.19885

Collected Steps per Second: 9733.35298
Overall Steps per Second: 7012.70528

Timestep Collection Time: 5.13749
Timestep Consumption Time: 1.99314
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.13063

Cumulative Model Updates: 46080
Cumulative Timesteps: 384688062

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.72093
Policy Entropy: 1.15296
Value Function Loss: 0.03294

Mean KL Divergence: 0.03342
SB3 Clip Fraction: 0.16932
Policy Update Magnitude: 0.08629
Value Function Update Magnitude: 0.20698

Collected Steps per Second: 10431.38471
Overall Steps per Second: 7264.58197

Timestep Collection Time: 4.79697
Timestep Consumption Time: 2.09111
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.88808

Cumulative Model Updates: 46086
Cumulative Timesteps: 384738101

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.65556
Policy Entropy: 1.14335
Value Function Loss: 0.03462

Mean KL Divergence: 0.02753
SB3 Clip Fraction: 0.15127
Policy Update Magnitude: 0.08739
Value Function Update Magnitude: 0.21300

Collected Steps per Second: 9744.93712
Overall Steps per Second: 6994.60863

Timestep Collection Time: 5.13415
Timestep Consumption Time: 2.01878
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.15294

Cumulative Model Updates: 46092
Cumulative Timesteps: 384788133

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.16250
Policy Entropy: 1.14843
Value Function Loss: 0.03343

Mean KL Divergence: 0.02610
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.09360
Value Function Update Magnitude: 0.22955

Collected Steps per Second: 10153.55686
Overall Steps per Second: 7194.74019

Timestep Collection Time: 4.92744
Timestep Consumption Time: 2.02639
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 6.95383

Cumulative Model Updates: 46098
Cumulative Timesteps: 384838164

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 384838164...
Checkpoint 384838164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.76725
Policy Entropy: 1.14074
Value Function Loss: 0.03378

Mean KL Divergence: 0.04382
SB3 Clip Fraction: 0.18314
Policy Update Magnitude: 0.09816
Value Function Update Magnitude: 0.23210

Collected Steps per Second: 10431.47155
Overall Steps per Second: 7235.56762

Timestep Collection Time: 4.79702
Timestep Consumption Time: 2.11881
PPO Batch Consumption Time: 0.02883
Total Iteration Time: 6.91584

Cumulative Model Updates: 46104
Cumulative Timesteps: 384888204

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.51183
Policy Entropy: 1.16106
Value Function Loss: 0.03230

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.09927
Value Function Update Magnitude: 0.22593

Collected Steps per Second: 10441.11977
Overall Steps per Second: 7327.22050

Timestep Collection Time: 4.78924
Timestep Consumption Time: 2.03532
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 6.82455

Cumulative Model Updates: 46110
Cumulative Timesteps: 384938209

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.90896
Policy Entropy: 1.13996
Value Function Loss: 0.03294

Mean KL Divergence: 0.03617
SB3 Clip Fraction: 0.17097
Policy Update Magnitude: 0.10754
Value Function Update Magnitude: 0.22722

Collected Steps per Second: 9713.63961
Overall Steps per Second: 6973.14438

Timestep Collection Time: 5.14843
Timestep Consumption Time: 2.02337
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.17180

Cumulative Model Updates: 46116
Cumulative Timesteps: 384988219

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.41811
Policy Entropy: 1.15380
Value Function Loss: 0.03181

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.10560
Value Function Update Magnitude: 0.22249

Collected Steps per Second: 10364.39254
Overall Steps per Second: 7269.42731

Timestep Collection Time: 4.82749
Timestep Consumption Time: 2.05531
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.88280

Cumulative Model Updates: 46122
Cumulative Timesteps: 385038253

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.29310
Policy Entropy: 1.13933
Value Function Loss: 0.03197

Mean KL Divergence: 0.02771
SB3 Clip Fraction: 0.14848
Policy Update Magnitude: 0.11177
Value Function Update Magnitude: 0.21210

Collected Steps per Second: 10493.08286
Overall Steps per Second: 7310.80661

Timestep Collection Time: 4.76762
Timestep Consumption Time: 2.07527
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 6.84288

Cumulative Model Updates: 46128
Cumulative Timesteps: 385088280

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.85165
Policy Entropy: 1.14985
Value Function Loss: 0.03024

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.10738
Value Function Update Magnitude: 0.20195

Collected Steps per Second: 10075.97048
Overall Steps per Second: 7072.42887

Timestep Collection Time: 4.96359
Timestep Consumption Time: 2.10795
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.07155

Cumulative Model Updates: 46134
Cumulative Timesteps: 385138293

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.27915
Policy Entropy: 1.14551
Value Function Loss: 0.03086

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.10145
Value Function Update Magnitude: 0.19777

Collected Steps per Second: 10608.60878
Overall Steps per Second: 7351.95343

Timestep Collection Time: 4.71391
Timestep Consumption Time: 2.08809
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 6.80200

Cumulative Model Updates: 46140
Cumulative Timesteps: 385188301

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.58024
Policy Entropy: 1.14521
Value Function Loss: 0.03174

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.10146
Value Function Update Magnitude: 0.20015

Collected Steps per Second: 9917.28031
Overall Steps per Second: 7100.73431

Timestep Collection Time: 5.04392
Timestep Consumption Time: 2.00070
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.04462

Cumulative Model Updates: 46146
Cumulative Timesteps: 385238323

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.36593
Policy Entropy: 1.13591
Value Function Loss: 0.03301

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.10030
Value Function Update Magnitude: 0.20905

Collected Steps per Second: 9803.67073
Overall Steps per Second: 7031.53609

Timestep Collection Time: 5.10472
Timestep Consumption Time: 2.01250
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.11722

Cumulative Model Updates: 46152
Cumulative Timesteps: 385288368

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.72097
Policy Entropy: 1.12725
Value Function Loss: 0.03282

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.10156
Value Function Update Magnitude: 0.21246

Collected Steps per Second: 10362.80548
Overall Steps per Second: 7223.40676

Timestep Collection Time: 4.82804
Timestep Consumption Time: 2.09834
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 6.92637

Cumulative Model Updates: 46158
Cumulative Timesteps: 385338400

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 385338400...
Checkpoint 385338400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.20697
Policy Entropy: 1.12646
Value Function Loss: 0.03330

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.10395
Value Function Update Magnitude: 0.21037

Collected Steps per Second: 9879.60416
Overall Steps per Second: 6940.87530

Timestep Collection Time: 5.06225
Timestep Consumption Time: 2.14333
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.20558

Cumulative Model Updates: 46164
Cumulative Timesteps: 385388413

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.36177
Policy Entropy: 1.12209
Value Function Loss: 0.03202

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.10416
Value Function Update Magnitude: 0.21228

Collected Steps per Second: 9706.87716
Overall Steps per Second: 6989.92144

Timestep Collection Time: 5.15408
Timestep Consumption Time: 2.00337
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.15745

Cumulative Model Updates: 46170
Cumulative Timesteps: 385438443

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.46878
Policy Entropy: 1.13311
Value Function Loss: 0.03205

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.10105
Value Function Update Magnitude: 0.20886

Collected Steps per Second: 10267.96050
Overall Steps per Second: 7212.17734

Timestep Collection Time: 4.87117
Timestep Consumption Time: 2.06390
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 6.93508

Cumulative Model Updates: 46176
Cumulative Timesteps: 385488460

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.10911
Policy Entropy: 1.14249
Value Function Loss: 0.03181

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.10085
Value Function Update Magnitude: 0.20462

Collected Steps per Second: 9783.41585
Overall Steps per Second: 6989.32690

Timestep Collection Time: 5.11273
Timestep Consumption Time: 2.04389
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.15663

Cumulative Model Updates: 46182
Cumulative Timesteps: 385538480

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.60564
Policy Entropy: 1.14862
Value Function Loss: 0.03195

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.09966
Value Function Update Magnitude: 0.20170

Collected Steps per Second: 9809.94894
Overall Steps per Second: 7042.65538

Timestep Collection Time: 5.10033
Timestep Consumption Time: 2.00409
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 7.10442

Cumulative Model Updates: 46188
Cumulative Timesteps: 385588514

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.82615
Policy Entropy: 1.15278
Value Function Loss: 0.03117

Mean KL Divergence: 0.02643
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.10124
Value Function Update Magnitude: 0.20476

Collected Steps per Second: 10438.06369
Overall Steps per Second: 7297.10051

Timestep Collection Time: 4.79332
Timestep Consumption Time: 2.06324
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.85656

Cumulative Model Updates: 46194
Cumulative Timesteps: 385638547

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.57958
Policy Entropy: 1.15405
Value Function Loss: 0.02982

Mean KL Divergence: 0.02638
SB3 Clip Fraction: 0.15029
Policy Update Magnitude: 0.09918
Value Function Update Magnitude: 0.20139

Collected Steps per Second: 9944.22345
Overall Steps per Second: 7103.54034

Timestep Collection Time: 5.03126
Timestep Consumption Time: 2.01199
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.04325

Cumulative Model Updates: 46200
Cumulative Timesteps: 385688579

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.93961
Policy Entropy: 1.15771
Value Function Loss: 0.02828

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.10146
Value Function Update Magnitude: 0.19636

Collected Steps per Second: 9677.34965
Overall Steps per Second: 7018.58706

Timestep Collection Time: 5.16867
Timestep Consumption Time: 1.95798
PPO Batch Consumption Time: 0.02447
Total Iteration Time: 7.12665

Cumulative Model Updates: 46206
Cumulative Timesteps: 385738598

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.01091
Policy Entropy: 1.13805
Value Function Loss: 0.03167

Mean KL Divergence: 0.02665
SB3 Clip Fraction: 0.14716
Policy Update Magnitude: 0.10688
Value Function Update Magnitude: 0.19473

Collected Steps per Second: 10540.31982
Overall Steps per Second: 7340.22013

Timestep Collection Time: 4.74435
Timestep Consumption Time: 2.06839
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 6.81274

Cumulative Model Updates: 46212
Cumulative Timesteps: 385788605

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.31416
Policy Entropy: 1.15572
Value Function Loss: 0.03261

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.10155
Value Function Update Magnitude: 0.22008

Collected Steps per Second: 9887.65862
Overall Steps per Second: 7013.84035

Timestep Collection Time: 5.05964
Timestep Consumption Time: 2.07311
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.13275

Cumulative Model Updates: 46218
Cumulative Timesteps: 385838633

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 385838633...
Checkpoint 385838633 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.66610
Policy Entropy: 1.15360
Value Function Loss: 0.03398

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.10365
Value Function Update Magnitude: 0.22886

Collected Steps per Second: 9759.83329
Overall Steps per Second: 6993.30992

Timestep Collection Time: 5.12314
Timestep Consumption Time: 2.02669
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.14983

Cumulative Model Updates: 46224
Cumulative Timesteps: 385888634

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.32667
Policy Entropy: 1.16134
Value Function Loss: 0.03147

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.10406
Value Function Update Magnitude: 0.23494

Collected Steps per Second: 10293.56530
Overall Steps per Second: 7236.28161

Timestep Collection Time: 4.86022
Timestep Consumption Time: 2.05341
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.91363

Cumulative Model Updates: 46230
Cumulative Timesteps: 385938663

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18865
Policy Entropy: 1.15082
Value Function Loss: 0.03135

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.10214
Value Function Update Magnitude: 0.22714

Collected Steps per Second: 9835.09580
Overall Steps per Second: 7004.69001

Timestep Collection Time: 5.08668
Timestep Consumption Time: 2.05539
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.14207

Cumulative Model Updates: 46236
Cumulative Timesteps: 385988691

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.55141
Policy Entropy: 1.15074
Value Function Loss: 0.03289

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.10594
Value Function Update Magnitude: 0.21508

Collected Steps per Second: 9827.19867
Overall Steps per Second: 7036.64753

Timestep Collection Time: 5.09077
Timestep Consumption Time: 2.01887
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.10964

Cumulative Model Updates: 46242
Cumulative Timesteps: 386038719

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.16310
Policy Entropy: 1.14775
Value Function Loss: 0.03356

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.10986
Value Function Update Magnitude: 0.21111

Collected Steps per Second: 10331.70644
Overall Steps per Second: 7219.13844

Timestep Collection Time: 4.84131
Timestep Consumption Time: 2.08736
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 6.92867

Cumulative Model Updates: 46248
Cumulative Timesteps: 386088738

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.28077
Policy Entropy: 1.16295
Value Function Loss: 0.03443

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.11151
Value Function Update Magnitude: 0.20811

Collected Steps per Second: 9808.27643
Overall Steps per Second: 7020.99939

Timestep Collection Time: 5.10130
Timestep Consumption Time: 2.02517
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.12648

Cumulative Model Updates: 46254
Cumulative Timesteps: 386138773

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.94899
Policy Entropy: 1.16515
Value Function Loss: 0.03404

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.11024
Policy Update Magnitude: 0.11364
Value Function Update Magnitude: 0.21109

Collected Steps per Second: 9684.14826
Overall Steps per Second: 6963.15578

Timestep Collection Time: 5.16659
Timestep Consumption Time: 2.01895
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.18554

Cumulative Model Updates: 46260
Cumulative Timesteps: 386188807

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.46503
Policy Entropy: 1.16465
Value Function Loss: 0.03328

Mean KL Divergence: 0.03004
SB3 Clip Fraction: 0.14642
Policy Update Magnitude: 0.10642
Value Function Update Magnitude: 0.21657

Collected Steps per Second: 10298.74947
Overall Steps per Second: 7213.31537

Timestep Collection Time: 4.85816
Timestep Consumption Time: 2.07804
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.93620

Cumulative Model Updates: 46266
Cumulative Timesteps: 386238840

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.85072
Policy Entropy: 1.17315
Value Function Loss: 0.03186

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.09490
Value Function Update Magnitude: 0.20288

Collected Steps per Second: 9867.64858
Overall Steps per Second: 7033.06116

Timestep Collection Time: 5.06706
Timestep Consumption Time: 2.04222
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.10928

Cumulative Model Updates: 46272
Cumulative Timesteps: 386288840

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.07873
Policy Entropy: 1.17409
Value Function Loss: 0.03087

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.10135
Value Function Update Magnitude: 0.19182

Collected Steps per Second: 9826.88895
Overall Steps per Second: 6988.95157

Timestep Collection Time: 5.08869
Timestep Consumption Time: 2.06632
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.15501

Cumulative Model Updates: 46278
Cumulative Timesteps: 386338846

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 386338846...
Checkpoint 386338846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.91723
Policy Entropy: 1.17464
Value Function Loss: 0.03193

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.10659
Value Function Update Magnitude: 0.19670

Collected Steps per Second: 10371.12475
Overall Steps per Second: 7274.83773

Timestep Collection Time: 4.82291
Timestep Consumption Time: 2.05271
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.87562

Cumulative Model Updates: 46284
Cumulative Timesteps: 386388865

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.74708
Policy Entropy: 1.17423
Value Function Loss: 0.03149

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.10069
Value Function Update Magnitude: 0.20214

Collected Steps per Second: 9908.14367
Overall Steps per Second: 7026.72331

Timestep Collection Time: 5.05009
Timestep Consumption Time: 2.07087
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.12096

Cumulative Model Updates: 46290
Cumulative Timesteps: 386438902

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.24189
Policy Entropy: 1.15949
Value Function Loss: 0.03321

Mean KL Divergence: 0.03601
SB3 Clip Fraction: 0.17267
Policy Update Magnitude: 0.08958
Value Function Update Magnitude: 0.20696

Collected Steps per Second: 9754.43195
Overall Steps per Second: 7009.89680

Timestep Collection Time: 5.12834
Timestep Consumption Time: 2.00786
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 7.13620

Cumulative Model Updates: 46296
Cumulative Timesteps: 386488926

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.37975
Policy Entropy: 1.15968
Value Function Loss: 0.03308

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.09751
Value Function Update Magnitude: 0.22100

Collected Steps per Second: 10407.37190
Overall Steps per Second: 7265.29704

Timestep Collection Time: 4.80621
Timestep Consumption Time: 2.07858
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 6.88478

Cumulative Model Updates: 46302
Cumulative Timesteps: 386538946

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.28892
Policy Entropy: 1.16346
Value Function Loss: 0.03174

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.10921
Value Function Update Magnitude: 0.24334

Collected Steps per Second: 9869.52643
Overall Steps per Second: 7082.88493

Timestep Collection Time: 5.07015
Timestep Consumption Time: 1.99477
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 7.06492

Cumulative Model Updates: 46308
Cumulative Timesteps: 386588986

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.92400
Policy Entropy: 1.17537
Value Function Loss: 0.03213

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.10576
Value Function Update Magnitude: 0.23348

Collected Steps per Second: 9964.00615
Overall Steps per Second: 7066.60356

Timestep Collection Time: 5.02218
Timestep Consumption Time: 2.05916
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 7.08134

Cumulative Model Updates: 46314
Cumulative Timesteps: 386639027

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.24683
Policy Entropy: 1.16404
Value Function Loss: 0.03181

Mean KL Divergence: 0.03665
SB3 Clip Fraction: 0.16770
Policy Update Magnitude: 0.09468
Value Function Update Magnitude: 0.22101

Collected Steps per Second: 10695.78560
Overall Steps per Second: 7403.81046

Timestep Collection Time: 4.67493
Timestep Consumption Time: 2.07862
PPO Batch Consumption Time: 0.02967
Total Iteration Time: 6.75355

Cumulative Model Updates: 46320
Cumulative Timesteps: 386689029

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.16574
Policy Entropy: 1.17151
Value Function Loss: 0.03277

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.09666
Value Function Update Magnitude: 0.21726

Collected Steps per Second: 9930.29474
Overall Steps per Second: 7025.66434

Timestep Collection Time: 5.03852
Timestep Consumption Time: 2.08308
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 7.12160

Cumulative Model Updates: 46326
Cumulative Timesteps: 386739063

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.98562
Policy Entropy: 1.16168
Value Function Loss: 0.03363

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.10512
Value Function Update Magnitude: 0.20615

Collected Steps per Second: 9871.90342
Overall Steps per Second: 7062.10866

Timestep Collection Time: 5.06822
Timestep Consumption Time: 2.01649
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.08471

Cumulative Model Updates: 46332
Cumulative Timesteps: 386789096

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.87871
Policy Entropy: 1.16631
Value Function Loss: 0.03445

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.10842
Value Function Update Magnitude: 0.21438

Collected Steps per Second: 10276.84108
Overall Steps per Second: 7182.94774

Timestep Collection Time: 4.86579
Timestep Consumption Time: 2.09583
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 6.96163

Cumulative Model Updates: 46338
Cumulative Timesteps: 386839101

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 386839101...
Checkpoint 386839101 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.99471
Policy Entropy: 1.16058
Value Function Loss: 0.03573

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.10582
Value Function Update Magnitude: 0.21581

Collected Steps per Second: 10024.96556
Overall Steps per Second: 3197.22603

Timestep Collection Time: 4.99184
Timestep Consumption Time: 10.66017
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 15.65201

Cumulative Model Updates: 46344
Cumulative Timesteps: 386889144

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.15373
Policy Entropy: 1.18706
Value Function Loss: 0.03377

Mean KL Divergence: 0.03169
SB3 Clip Fraction: 0.16166
Policy Update Magnitude: 0.09792
Value Function Update Magnitude: 0.22089

Collected Steps per Second: 9813.97762
Overall Steps per Second: 7043.86158

Timestep Collection Time: 5.09640
Timestep Consumption Time: 2.00425
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.10065

Cumulative Model Updates: 46350
Cumulative Timesteps: 386939160

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.50039
Policy Entropy: 1.16868
Value Function Loss: 0.03384

Mean KL Divergence: 0.03619
SB3 Clip Fraction: 0.16857
Policy Update Magnitude: 0.09780
Value Function Update Magnitude: 0.21242

Collected Steps per Second: 10343.58061
Overall Steps per Second: 7253.61485

Timestep Collection Time: 4.83827
Timestep Consumption Time: 2.06105
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 6.89932

Cumulative Model Updates: 46356
Cumulative Timesteps: 386989205

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.22037
Policy Entropy: 1.18018
Value Function Loss: 0.03256

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.09856
Value Function Update Magnitude: 0.20664

Collected Steps per Second: 9884.74486
Overall Steps per Second: 7068.02856

Timestep Collection Time: 5.06285
Timestep Consumption Time: 2.01762
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.08048

Cumulative Model Updates: 46362
Cumulative Timesteps: 387039250

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.92023
Policy Entropy: 1.17399
Value Function Loss: 0.03150

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.10423
Value Function Update Magnitude: 0.20395

Collected Steps per Second: 10001.41018
Overall Steps per Second: 7108.75833

Timestep Collection Time: 5.00099
Timestep Consumption Time: 2.03497
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.03597

Cumulative Model Updates: 46368
Cumulative Timesteps: 387089267

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.73083
Policy Entropy: 1.17578
Value Function Loss: 0.03105

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.10759
Value Function Update Magnitude: 0.19637

Collected Steps per Second: 10423.61156
Overall Steps per Second: 7248.90965

Timestep Collection Time: 4.80035
Timestep Consumption Time: 2.10234
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 6.90269

Cumulative Model Updates: 46374
Cumulative Timesteps: 387139304

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.80919
Policy Entropy: 1.16607
Value Function Loss: 0.03045

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.10668
Value Function Update Magnitude: 0.19441

Collected Steps per Second: 9897.57079
Overall Steps per Second: 6994.23073

Timestep Collection Time: 5.05528
Timestep Consumption Time: 2.09847
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.15375

Cumulative Model Updates: 46380
Cumulative Timesteps: 387189339

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.82742
Policy Entropy: 1.16143
Value Function Loss: 0.03236

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.10739
Value Function Update Magnitude: 0.19943

Collected Steps per Second: 9668.29859
Overall Steps per Second: 6922.19720

Timestep Collection Time: 5.17454
Timestep Consumption Time: 2.05279
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.22733

Cumulative Model Updates: 46386
Cumulative Timesteps: 387239368

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.03867
Policy Entropy: 1.16583
Value Function Loss: 0.03246

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.10177
Value Function Update Magnitude: 0.20337

Collected Steps per Second: 10287.30944
Overall Steps per Second: 7198.94720

Timestep Collection Time: 4.86123
Timestep Consumption Time: 2.08548
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.94671

Cumulative Model Updates: 46392
Cumulative Timesteps: 387289377

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.19759
Policy Entropy: 1.17424
Value Function Loss: 0.03332

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.10517
Value Function Update Magnitude: 0.21006

Collected Steps per Second: 9809.84470
Overall Steps per Second: 7020.44490

Timestep Collection Time: 5.10130
Timestep Consumption Time: 2.02688
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.12818

Cumulative Model Updates: 46398
Cumulative Timesteps: 387339420

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 387339420...
Checkpoint 387339420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.95689
Policy Entropy: 1.17720
Value Function Loss: 0.03252

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.11157
Value Function Update Magnitude: 0.21326

Collected Steps per Second: 9916.69406
Overall Steps per Second: 7190.33576

Timestep Collection Time: 5.04281
Timestep Consumption Time: 1.91208
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 6.95489

Cumulative Model Updates: 46404
Cumulative Timesteps: 387389428

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.72391
Policy Entropy: 1.18789
Value Function Loss: 0.03186

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.11133
Value Function Update Magnitude: 0.21471

Collected Steps per Second: 10677.00674
Overall Steps per Second: 7417.24037

Timestep Collection Time: 4.68727
Timestep Consumption Time: 2.05998
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 6.74725

Cumulative Model Updates: 46410
Cumulative Timesteps: 387439474

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.74327
Policy Entropy: 1.18395
Value Function Loss: 0.03102

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.10789
Value Function Update Magnitude: 0.20634

Collected Steps per Second: 9775.99026
Overall Steps per Second: 6996.20647

Timestep Collection Time: 5.11600
Timestep Consumption Time: 2.03273
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.14873

Cumulative Model Updates: 46416
Cumulative Timesteps: 387489488

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.09984
Policy Entropy: 1.17888
Value Function Loss: 0.03166

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.10352
Value Function Update Magnitude: 0.19767

Collected Steps per Second: 9929.05896
Overall Steps per Second: 7042.38487

Timestep Collection Time: 5.03794
Timestep Consumption Time: 2.06505
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 7.10299

Cumulative Model Updates: 46422
Cumulative Timesteps: 387539510

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.11967
Policy Entropy: 1.16919
Value Function Loss: 0.03284

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.09767
Value Function Update Magnitude: 0.19398

Collected Steps per Second: 10328.22889
Overall Steps per Second: 7241.16299

Timestep Collection Time: 4.84255
Timestep Consumption Time: 2.06449
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.90704

Cumulative Model Updates: 46428
Cumulative Timesteps: 387589525

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.14842
Policy Entropy: 1.17205
Value Function Loss: 0.03311

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.10139
Value Function Update Magnitude: 0.19603

Collected Steps per Second: 9874.83828
Overall Steps per Second: 7030.16110

Timestep Collection Time: 5.06489
Timestep Consumption Time: 2.04945
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.11435

Cumulative Model Updates: 46434
Cumulative Timesteps: 387639540

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.21906
Policy Entropy: 1.16381
Value Function Loss: 0.03157

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.11134
Value Function Update Magnitude: 0.19135

Collected Steps per Second: 9697.48172
Overall Steps per Second: 6985.74448

Timestep Collection Time: 5.16072
Timestep Consumption Time: 2.00330
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.16402

Cumulative Model Updates: 46440
Cumulative Timesteps: 387689586

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.74624
Policy Entropy: 1.16510
Value Function Loss: 0.03070

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.10860
Value Function Update Magnitude: 0.19515

Collected Steps per Second: 10413.29419
Overall Steps per Second: 7279.32977

Timestep Collection Time: 4.80415
Timestep Consumption Time: 2.06833
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 6.87247

Cumulative Model Updates: 46446
Cumulative Timesteps: 387739613

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.65496
Policy Entropy: 1.18568
Value Function Loss: 0.03025

Mean KL Divergence: 0.03506
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.09873
Value Function Update Magnitude: 0.19594

Collected Steps per Second: 9819.41446
Overall Steps per Second: 7021.21849

Timestep Collection Time: 5.09643
Timestep Consumption Time: 2.03110
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.12754

Cumulative Model Updates: 46452
Cumulative Timesteps: 387789657

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.05765
Policy Entropy: 1.18461
Value Function Loss: 0.03084

Mean KL Divergence: 0.03151
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.09969
Value Function Update Magnitude: 0.19409

Collected Steps per Second: 9650.34740
Overall Steps per Second: 6917.34395

Timestep Collection Time: 5.18282
Timestep Consumption Time: 2.04770
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.23052

Cumulative Model Updates: 46458
Cumulative Timesteps: 387839673

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 387839673...
Checkpoint 387839673 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.92188
Policy Entropy: 1.18910
Value Function Loss: 0.03227

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.11071
Value Function Update Magnitude: 0.19570

Collected Steps per Second: 10351.16381
Overall Steps per Second: 7236.65676

Timestep Collection Time: 4.83298
Timestep Consumption Time: 2.08002
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 6.91300

Cumulative Model Updates: 46464
Cumulative Timesteps: 387889700

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.61190
Policy Entropy: 1.18385
Value Function Loss: 0.03351

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.10725
Value Function Update Magnitude: 0.20295

Collected Steps per Second: 9860.59538
Overall Steps per Second: 7048.26596

Timestep Collection Time: 5.07282
Timestep Consumption Time: 2.02411
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 7.09692

Cumulative Model Updates: 46470
Cumulative Timesteps: 387939721

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.06668
Policy Entropy: 1.17719
Value Function Loss: 0.03180

Mean KL Divergence: 0.03473
SB3 Clip Fraction: 0.16525
Policy Update Magnitude: 0.09343
Value Function Update Magnitude: 0.19995

Collected Steps per Second: 9890.01503
Overall Steps per Second: 7057.53954

Timestep Collection Time: 5.05641
Timestep Consumption Time: 2.02934
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.08576

Cumulative Model Updates: 46476
Cumulative Timesteps: 387989729

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.82516
Policy Entropy: 1.17903
Value Function Loss: 0.03207

Mean KL Divergence: 0.02773
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.09558
Value Function Update Magnitude: 0.19817

Collected Steps per Second: 10384.52067
Overall Steps per Second: 7250.03058

Timestep Collection Time: 4.81784
Timestep Consumption Time: 2.08295
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 6.90080

Cumulative Model Updates: 46482
Cumulative Timesteps: 388039760

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.06569
Policy Entropy: 1.17015
Value Function Loss: 0.02985

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.10033
Value Function Update Magnitude: 0.19600

Collected Steps per Second: 9830.45905
Overall Steps per Second: 7050.55908

Timestep Collection Time: 5.09061
Timestep Consumption Time: 2.00713
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.09774

Cumulative Model Updates: 46488
Cumulative Timesteps: 388089803

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.90416
Policy Entropy: 1.17149
Value Function Loss: 0.03006

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.10732
Value Function Update Magnitude: 0.19202

Collected Steps per Second: 9741.74492
Overall Steps per Second: 6905.51814

Timestep Collection Time: 5.13666
Timestep Consumption Time: 2.10972
PPO Batch Consumption Time: 0.03293
Total Iteration Time: 7.24638

Cumulative Model Updates: 46494
Cumulative Timesteps: 388139843

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.99343
Policy Entropy: 1.16465
Value Function Loss: 0.02993

Mean KL Divergence: 0.02143
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.10733
Value Function Update Magnitude: 0.18844

Collected Steps per Second: 10467.83769
Overall Steps per Second: 7290.68718

Timestep Collection Time: 4.77768
Timestep Consumption Time: 2.08203
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 6.85971

Cumulative Model Updates: 46500
Cumulative Timesteps: 388189855

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.08759
Policy Entropy: 1.16771
Value Function Loss: 0.03121

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.10310
Value Function Update Magnitude: 0.18518

Collected Steps per Second: 10057.54963
Overall Steps per Second: 7160.51858

Timestep Collection Time: 4.97298
Timestep Consumption Time: 2.01199
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 6.98497

Cumulative Model Updates: 46506
Cumulative Timesteps: 388239871

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.26526
Policy Entropy: 1.16322
Value Function Loss: 0.03107

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.10043
Value Function Update Magnitude: 0.18816

Collected Steps per Second: 10075.89713
Overall Steps per Second: 7153.92446

Timestep Collection Time: 4.96313
Timestep Consumption Time: 2.02716
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 6.99029

Cumulative Model Updates: 46512
Cumulative Timesteps: 388289879

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.42128
Policy Entropy: 1.17383
Value Function Loss: 0.03146

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.09883
Value Function Update Magnitude: 0.19257

Collected Steps per Second: 10390.37131
Overall Steps per Second: 7252.68956

Timestep Collection Time: 4.81552
Timestep Consumption Time: 2.08330
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 6.89882

Cumulative Model Updates: 46518
Cumulative Timesteps: 388339914

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 388339914...
Checkpoint 388339914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.33110
Policy Entropy: 1.16241
Value Function Loss: 0.03078

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.10747
Value Function Update Magnitude: 0.19687

Collected Steps per Second: 9787.71897
Overall Steps per Second: 6958.81055

Timestep Collection Time: 5.11100
Timestep Consumption Time: 2.07773
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 7.18873

Cumulative Model Updates: 46524
Cumulative Timesteps: 388389939

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.32832
Policy Entropy: 1.16340
Value Function Loss: 0.03136

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.11218
Value Function Update Magnitude: 0.20214

Collected Steps per Second: 10223.37913
Overall Steps per Second: 7420.78309

Timestep Collection Time: 4.89134
Timestep Consumption Time: 1.84730
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.73864

Cumulative Model Updates: 46530
Cumulative Timesteps: 388439945

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.87480
Policy Entropy: 1.14386
Value Function Loss: 0.03220

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.10805
Value Function Update Magnitude: 0.20537

Collected Steps per Second: 10507.16891
Overall Steps per Second: 7332.23566

Timestep Collection Time: 4.76256
Timestep Consumption Time: 2.06224
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 6.82479

Cumulative Model Updates: 46536
Cumulative Timesteps: 388489986

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.90573
Policy Entropy: 1.15561
Value Function Loss: 0.03313

Mean KL Divergence: 0.02672
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.09896
Value Function Update Magnitude: 0.21582

Collected Steps per Second: 10048.35228
Overall Steps per Second: 7039.14950

Timestep Collection Time: 4.98042
Timestep Consumption Time: 2.12911
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 7.10952

Cumulative Model Updates: 46542
Cumulative Timesteps: 388540031

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.56109
Policy Entropy: 1.14409
Value Function Loss: 0.03207

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.10331
Value Function Update Magnitude: 0.22007

Collected Steps per Second: 9752.80607
Overall Steps per Second: 6990.61680

Timestep Collection Time: 5.12837
Timestep Consumption Time: 2.02636
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.15473

Cumulative Model Updates: 46548
Cumulative Timesteps: 388590047

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.90789
Policy Entropy: 1.15367
Value Function Loss: 0.03169

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.11178
Value Function Update Magnitude: 0.22017

Collected Steps per Second: 10414.53599
Overall Steps per Second: 7235.12661

Timestep Collection Time: 4.80271
Timestep Consumption Time: 2.11051
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 6.91322

Cumulative Model Updates: 46554
Cumulative Timesteps: 388640065

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.41391
Policy Entropy: 1.15190
Value Function Loss: 0.03176

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.10985
Value Function Update Magnitude: 0.22311

Collected Steps per Second: 9908.20858
Overall Steps per Second: 7047.16316

Timestep Collection Time: 5.04713
Timestep Consumption Time: 2.04906
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.09619

Cumulative Model Updates: 46560
Cumulative Timesteps: 388690073

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.44702
Policy Entropy: 1.16630
Value Function Loss: 0.03184

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.10812
Value Function Update Magnitude: 0.22582

Collected Steps per Second: 9749.05107
Overall Steps per Second: 7007.51221

Timestep Collection Time: 5.13106
Timestep Consumption Time: 2.00742
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.13848

Cumulative Model Updates: 46566
Cumulative Timesteps: 388740096

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.44456
Policy Entropy: 1.16340
Value Function Loss: 0.03312

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.10786
Value Function Update Magnitude: 0.23586

Collected Steps per Second: 10725.19463
Overall Steps per Second: 7380.69547

Timestep Collection Time: 4.66360
Timestep Consumption Time: 2.11327
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 6.77687

Cumulative Model Updates: 46572
Cumulative Timesteps: 388790114

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.19554
Policy Entropy: 1.17089
Value Function Loss: 0.03253

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.11095
Value Function Update Magnitude: 0.23890

Collected Steps per Second: 9742.98378
Overall Steps per Second: 6959.28695

Timestep Collection Time: 5.13600
Timestep Consumption Time: 2.05439
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.19039

Cumulative Model Updates: 46578
Cumulative Timesteps: 388840154

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 388840154...
Checkpoint 388840154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.31883
Policy Entropy: 1.16427
Value Function Loss: 0.03229

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.10666
Value Function Update Magnitude: 0.24035

Collected Steps per Second: 9894.34933
Overall Steps per Second: 7084.49351

Timestep Collection Time: 5.05582
Timestep Consumption Time: 2.00524
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.06106

Cumulative Model Updates: 46584
Cumulative Timesteps: 388890178

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.12722
Policy Entropy: 1.16410
Value Function Loss: 0.03113

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.09699
Value Function Update Magnitude: 0.23628

Collected Steps per Second: 10327.75526
Overall Steps per Second: 7198.34632

Timestep Collection Time: 4.84316
Timestep Consumption Time: 2.10552
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 6.94868

Cumulative Model Updates: 46590
Cumulative Timesteps: 388940197

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.94180
Policy Entropy: 1.16690
Value Function Loss: 0.03169

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.09634
Value Function Update Magnitude: 0.23292

Collected Steps per Second: 9683.95907
Overall Steps per Second: 6976.77818

Timestep Collection Time: 5.16473
Timestep Consumption Time: 2.00406
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 7.16878

Cumulative Model Updates: 46596
Cumulative Timesteps: 388990212

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.24215
Policy Entropy: 1.17169
Value Function Loss: 0.03179

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.10699
Value Function Update Magnitude: 0.23230

Collected Steps per Second: 9767.02223
Overall Steps per Second: 6980.92278

Timestep Collection Time: 5.11978
Timestep Consumption Time: 2.04331
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.16309

Cumulative Model Updates: 46602
Cumulative Timesteps: 389040217

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.57618
Policy Entropy: 1.17440
Value Function Loss: 0.03310

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.10747
Value Function Update Magnitude: 0.23264

Collected Steps per Second: 10509.10125
Overall Steps per Second: 7305.55904

Timestep Collection Time: 4.76187
Timestep Consumption Time: 2.08812
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 6.84999

Cumulative Model Updates: 46608
Cumulative Timesteps: 389090260

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.16587
Policy Entropy: 1.16942
Value Function Loss: 0.03381

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.11049
Value Function Update Magnitude: 0.22495

Collected Steps per Second: 10148.51847
Overall Steps per Second: 7112.39875

Timestep Collection Time: 4.92702
Timestep Consumption Time: 2.10323
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.03026

Cumulative Model Updates: 46614
Cumulative Timesteps: 389140262

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.24829
Policy Entropy: 1.17514
Value Function Loss: 0.03367

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.11099
Value Function Update Magnitude: 0.22780

Collected Steps per Second: 9884.01032
Overall Steps per Second: 7043.33420

Timestep Collection Time: 5.05938
Timestep Consumption Time: 2.04052
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 7.09990

Cumulative Model Updates: 46620
Cumulative Timesteps: 389190269

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.35484
Policy Entropy: 1.17366
Value Function Loss: 0.03433

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.11669
Value Function Update Magnitude: 0.21179

Collected Steps per Second: 10384.00494
Overall Steps per Second: 7268.95316

Timestep Collection Time: 4.81770
Timestep Consumption Time: 2.06459
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.88228

Cumulative Model Updates: 46626
Cumulative Timesteps: 389240296

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.96694
Policy Entropy: 1.17189
Value Function Loss: 0.03484

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.11354
Value Function Update Magnitude: 0.20794

Collected Steps per Second: 10004.82021
Overall Steps per Second: 7034.04875

Timestep Collection Time: 5.00069
Timestep Consumption Time: 2.11200
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 7.11269

Cumulative Model Updates: 46632
Cumulative Timesteps: 389290327

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.02983
Policy Entropy: 1.16711
Value Function Loss: 0.03544

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.11007
Value Function Update Magnitude: 0.21676

Collected Steps per Second: 9743.13820
Overall Steps per Second: 7009.86194

Timestep Collection Time: 5.13531
Timestep Consumption Time: 2.00235
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 7.13766

Cumulative Model Updates: 46638
Cumulative Timesteps: 389340361

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 389340361...
Checkpoint 389340361 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.43201
Policy Entropy: 1.16677
Value Function Loss: 0.03309

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.10332
Value Function Update Magnitude: 0.22136

Collected Steps per Second: 10398.10487
Overall Steps per Second: 7241.44284

Timestep Collection Time: 4.81280
Timestep Consumption Time: 2.09798
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.91078

Cumulative Model Updates: 46644
Cumulative Timesteps: 389390405

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.37769
Policy Entropy: 1.17221
Value Function Loss: 0.03224

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.10560
Value Function Update Magnitude: 0.21635

Collected Steps per Second: 9927.21760
Overall Steps per Second: 7053.71717

Timestep Collection Time: 5.03867
Timestep Consumption Time: 2.05262
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.09130

Cumulative Model Updates: 46650
Cumulative Timesteps: 389440425

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.72749
Policy Entropy: 1.17299
Value Function Loss: 0.03072

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.09730
Value Function Update Magnitude: 0.21236

Collected Steps per Second: 9714.67620
Overall Steps per Second: 6984.75883

Timestep Collection Time: 5.15128
Timestep Consumption Time: 2.01332
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.16460

Cumulative Model Updates: 46656
Cumulative Timesteps: 389490468

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.39712
Policy Entropy: 1.16868
Value Function Loss: 0.03279

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.10827
Value Function Update Magnitude: 0.21704

Collected Steps per Second: 10402.90974
Overall Steps per Second: 7253.11867

Timestep Collection Time: 4.81000
Timestep Consumption Time: 2.08883
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.89883

Cumulative Model Updates: 46662
Cumulative Timesteps: 389540506

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.65239
Policy Entropy: 1.15667
Value Function Loss: 0.03147

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.10577
Value Function Update Magnitude: 0.21162

Collected Steps per Second: 10249.71033
Overall Steps per Second: 7226.11832

Timestep Collection Time: 4.87936
Timestep Consumption Time: 2.04165
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 6.92100

Cumulative Model Updates: 46668
Cumulative Timesteps: 389590518

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 389590518...
Checkpoint 389590518 saved!
