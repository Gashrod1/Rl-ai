Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 1135.71293
Policy Entropy: 1.38245
Value Function Loss: 0.52137

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.03771
Policy Update Magnitude: 0.03759
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 9840.91933
Overall Steps per Second: 1129.13146

Timestep Collection Time: 5.08459
Timestep Consumption Time: 39.23001
PPO Batch Consumption Time: 0.18010
Total Iteration Time: 44.31459

Cumulative Model Updates: 10316
Cumulative Timesteps: 86304675

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1086.54354
Policy Entropy: 1.38208
Value Function Loss: 0.55234

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.05175
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.12211

Collected Steps per Second: 10128.75774
Overall Steps per Second: 2681.66093

Timestep Collection Time: 4.94039
Timestep Consumption Time: 13.71969
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 18.66008

Cumulative Model Updates: 10320
Cumulative Timesteps: 86354715

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 86354715...
Checkpoint 86354715 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1095.58852
Policy Entropy: 1.38216
Value Function Loss: 0.54618

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.04354
Policy Update Magnitude: 0.09687
Value Function Update Magnitude: 0.17817

Collected Steps per Second: 11169.87959
Overall Steps per Second: 7751.34221

Timestep Collection Time: 4.47901
Timestep Consumption Time: 1.97536
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 6.45437

Cumulative Model Updates: 10326
Cumulative Timesteps: 86404745

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.98947
Policy Entropy: 1.38062
Value Function Loss: 0.55696

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.03768
Policy Update Magnitude: 0.10061
Value Function Update Magnitude: 0.15312

Collected Steps per Second: 10185.45780
Overall Steps per Second: 7258.09748

Timestep Collection Time: 4.91122
Timestep Consumption Time: 1.98081
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 6.89203

Cumulative Model Updates: 10332
Cumulative Timesteps: 86454768

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 86454768...
Checkpoint 86454768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1053.87845
Policy Entropy: 1.38049
Value Function Loss: 0.54359

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 0.09940
Value Function Update Magnitude: 0.14415

Collected Steps per Second: 10098.56816
Overall Steps per Second: 7189.36739

Timestep Collection Time: 4.95347
Timestep Consumption Time: 2.00444
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 6.95791

Cumulative Model Updates: 10338
Cumulative Timesteps: 86504791

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1066.10292
Policy Entropy: 1.37868
Value Function Loss: 0.54903

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.04845
Policy Update Magnitude: 0.11645
Value Function Update Magnitude: 0.13805

Collected Steps per Second: 10202.41308
Overall Steps per Second: 7174.81022

Timestep Collection Time: 4.90247
Timestep Consumption Time: 2.06873
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 6.97119

Cumulative Model Updates: 10344
Cumulative Timesteps: 86554808

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 86554808...
Checkpoint 86554808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1062.09429
Policy Entropy: 1.38263
Value Function Loss: 0.54167

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.05662
Policy Update Magnitude: 0.10673
Value Function Update Magnitude: 0.14456

Collected Steps per Second: 10078.46864
Overall Steps per Second: 7139.77662

Timestep Collection Time: 4.96246
Timestep Consumption Time: 2.04252
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.00498

Cumulative Model Updates: 10350
Cumulative Timesteps: 86604822

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1048.19027
Policy Entropy: 1.38217
Value Function Loss: 0.53352

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.06072
Policy Update Magnitude: 0.09482
Value Function Update Magnitude: 0.18293

Collected Steps per Second: 10073.72618
Overall Steps per Second: 7119.61319

Timestep Collection Time: 4.96460
Timestep Consumption Time: 2.05994
PPO Batch Consumption Time: 0.02870
Total Iteration Time: 7.02454

Cumulative Model Updates: 10356
Cumulative Timesteps: 86654834

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 86654834...
Checkpoint 86654834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1018.73687
Policy Entropy: 1.38269
Value Function Loss: 0.50847

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.05778
Policy Update Magnitude: 0.09209
Value Function Update Magnitude: 0.16803

Collected Steps per Second: 9264.64554
Overall Steps per Second: 6423.51729

Timestep Collection Time: 5.40053
Timestep Consumption Time: 2.38866
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 7.78919

Cumulative Model Updates: 10362
Cumulative Timesteps: 86704868

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.54615
Policy Entropy: 1.38156
Value Function Loss: 0.51849

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.05752
Policy Update Magnitude: 0.09516
Value Function Update Magnitude: 0.13908

Collected Steps per Second: 10398.47899
Overall Steps per Second: 7230.63655

Timestep Collection Time: 4.80888
Timestep Consumption Time: 2.10684
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 6.91571

Cumulative Model Updates: 10368
Cumulative Timesteps: 86754873

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 86754873...
Checkpoint 86754873 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1079.55843
Policy Entropy: 1.38185
Value Function Loss: 0.51796

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.04448
Policy Update Magnitude: 0.10009
Value Function Update Magnitude: 0.14010

Collected Steps per Second: 9895.71398
Overall Steps per Second: 7036.31359

Timestep Collection Time: 5.05684
Timestep Consumption Time: 2.05498
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.11182

Cumulative Model Updates: 10374
Cumulative Timesteps: 86804914

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.32233
Policy Entropy: 1.38225
Value Function Loss: 0.53235

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.04319
Policy Update Magnitude: 0.10769
Value Function Update Magnitude: 0.13951

Collected Steps per Second: 8925.96448
Overall Steps per Second: 6223.38288

Timestep Collection Time: 5.60634
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.02982
Total Iteration Time: 8.04096

Cumulative Model Updates: 10380
Cumulative Timesteps: 86854956

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 86854956...
Checkpoint 86854956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.06959
Policy Entropy: 1.38145
Value Function Loss: 0.52775

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.04232
Policy Update Magnitude: 0.10744
Value Function Update Magnitude: 0.15345

Collected Steps per Second: 9527.57682
Overall Steps per Second: 6827.42904

Timestep Collection Time: 5.25097
Timestep Consumption Time: 2.07668
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.32765

Cumulative Model Updates: 10386
Cumulative Timesteps: 86904985

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1014.20435
Policy Entropy: 1.38074
Value Function Loss: 0.54125

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.04086
Policy Update Magnitude: 0.10179
Value Function Update Magnitude: 0.16490

Collected Steps per Second: 10324.47829
Overall Steps per Second: 7317.18743

Timestep Collection Time: 4.84441
Timestep Consumption Time: 1.99100
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 6.83541

Cumulative Model Updates: 10392
Cumulative Timesteps: 86955001

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 86955001...
Checkpoint 86955001 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.16120
Policy Entropy: 1.38205
Value Function Loss: 0.53268

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05306
Policy Update Magnitude: 0.09871
Value Function Update Magnitude: 0.20227

Collected Steps per Second: 10840.76384
Overall Steps per Second: 7390.23106

Timestep Collection Time: 4.61314
Timestep Consumption Time: 2.15390
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 6.76704

Cumulative Model Updates: 10398
Cumulative Timesteps: 87005011

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1432.46314
Policy Entropy: 1.37945
Value Function Loss: 0.52172

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.08870
Value Function Update Magnitude: 0.18464

Collected Steps per Second: 10156.45826
Overall Steps per Second: 7178.29134

Timestep Collection Time: 4.92554
Timestep Consumption Time: 2.04353
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 6.96907

Cumulative Model Updates: 10404
Cumulative Timesteps: 87055037

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 87055037...
Checkpoint 87055037 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.72950
Policy Entropy: 1.38120
Value Function Loss: 0.51852

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.06151
Policy Update Magnitude: 0.08668
Value Function Update Magnitude: 0.18007

Collected Steps per Second: 10023.38441
Overall Steps per Second: 7202.15682

Timestep Collection Time: 4.98973
Timestep Consumption Time: 1.95458
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 6.94431

Cumulative Model Updates: 10410
Cumulative Timesteps: 87105051

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1041.99980
Policy Entropy: 1.37934
Value Function Loss: 0.52713

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.04559
Policy Update Magnitude: 0.09717
Value Function Update Magnitude: 0.20863

Collected Steps per Second: 10454.59421
Overall Steps per Second: 7208.98037

Timestep Collection Time: 4.78603
Timestep Consumption Time: 2.15476
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.94079

Cumulative Model Updates: 10416
Cumulative Timesteps: 87155087

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 87155087...
Checkpoint 87155087 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.53026
Policy Entropy: 1.37909
Value Function Loss: 0.52460

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03785
Policy Update Magnitude: 0.10491
Value Function Update Magnitude: 0.17190

Collected Steps per Second: 9546.35912
Overall Steps per Second: 6831.31588

Timestep Collection Time: 5.24231
Timestep Consumption Time: 2.08351
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.32582

Cumulative Model Updates: 10422
Cumulative Timesteps: 87205132

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1184.11003
Policy Entropy: 1.37980
Value Function Loss: 0.54182

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.04922
Policy Update Magnitude: 0.09902
Value Function Update Magnitude: 0.14721

Collected Steps per Second: 10026.35338
Overall Steps per Second: 7163.03765

Timestep Collection Time: 4.99035
Timestep Consumption Time: 1.99482
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 6.98517

Cumulative Model Updates: 10428
Cumulative Timesteps: 87255167

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 87255167...
Checkpoint 87255167 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1008.16087
Policy Entropy: 1.37948
Value Function Loss: 0.53299

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.05866
Policy Update Magnitude: 0.08280
Value Function Update Magnitude: 0.17766

Collected Steps per Second: 10077.67058
Overall Steps per Second: 7047.56741

Timestep Collection Time: 4.96186
Timestep Consumption Time: 2.13335
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.09521

Cumulative Model Updates: 10434
Cumulative Timesteps: 87305171

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.48367
Policy Entropy: 1.37882
Value Function Loss: 0.54845

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.07982
Value Function Update Magnitude: 0.18323

Collected Steps per Second: 10028.20056
Overall Steps per Second: 7099.83899

Timestep Collection Time: 4.98913
Timestep Consumption Time: 2.05779
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.04692

Cumulative Model Updates: 10440
Cumulative Timesteps: 87355203

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 87355203...
Checkpoint 87355203 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.92882
Policy Entropy: 1.37804
Value Function Loss: 0.54291

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.04833
Policy Update Magnitude: 0.08987
Value Function Update Magnitude: 0.20758

Collected Steps per Second: 10333.27713
Overall Steps per Second: 6831.27939

Timestep Collection Time: 4.84096
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.05281
Total Iteration Time: 7.32264

Cumulative Model Updates: 10446
Cumulative Timesteps: 87405226

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1141.67843
Policy Entropy: 1.37649
Value Function Loss: 0.55288

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.04502
Policy Update Magnitude: 0.09977
Value Function Update Magnitude: 0.19508

Collected Steps per Second: 9643.15853
Overall Steps per Second: 6820.04363

Timestep Collection Time: 5.18699
Timestep Consumption Time: 2.14712
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 7.33412

Cumulative Model Updates: 10452
Cumulative Timesteps: 87455245

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 87455245...
Checkpoint 87455245 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783.75979
Policy Entropy: 1.37373
Value Function Loss: 0.54303

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.04106
Policy Update Magnitude: 0.11244
Value Function Update Magnitude: 0.16858

Collected Steps per Second: 10218.38525
Overall Steps per Second: 7193.14203

Timestep Collection Time: 4.89598
Timestep Consumption Time: 2.05912
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 6.95510

Cumulative Model Updates: 10458
Cumulative Timesteps: 87505274

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.08313
Policy Entropy: 1.37330
Value Function Loss: 0.54679

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.06352
Policy Update Magnitude: 0.10196
Value Function Update Magnitude: 0.15241

Collected Steps per Second: 10086.40689
Overall Steps per Second: 7283.64610

Timestep Collection Time: 4.95766
Timestep Consumption Time: 1.90772
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.86538

Cumulative Model Updates: 10464
Cumulative Timesteps: 87555279

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 87555279...
Checkpoint 87555279 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.36185
Policy Entropy: 1.37370
Value Function Loss: 0.54506

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.04640
Policy Update Magnitude: 0.09377
Value Function Update Magnitude: 0.14575

Collected Steps per Second: 10388.78413
Overall Steps per Second: 7327.62969

Timestep Collection Time: 4.81481
Timestep Consumption Time: 2.01141
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 6.82622

Cumulative Model Updates: 10470
Cumulative Timesteps: 87605299

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.09450
Policy Entropy: 1.37085
Value Function Loss: 0.54196

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.05714
Policy Update Magnitude: 0.09382
Value Function Update Magnitude: 0.18468

Collected Steps per Second: 10157.81668
Overall Steps per Second: 7275.67428

Timestep Collection Time: 4.92340
Timestep Consumption Time: 1.95033
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 6.87373

Cumulative Model Updates: 10476
Cumulative Timesteps: 87655310

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 87655310...
Checkpoint 87655310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1073.11593
Policy Entropy: 1.36987
Value Function Loss: 0.54817

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.09060
Value Function Update Magnitude: 0.18908

Collected Steps per Second: 10045.87128
Overall Steps per Second: 7234.10043

Timestep Collection Time: 4.97886
Timestep Consumption Time: 1.93520
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 6.91406

Cumulative Model Updates: 10482
Cumulative Timesteps: 87705327

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.70751
Policy Entropy: 1.36684
Value Function Loss: 0.55288

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.06142
Policy Update Magnitude: 0.07979
Value Function Update Magnitude: 0.19078

Collected Steps per Second: 10727.76782
Overall Steps per Second: 7547.06193

Timestep Collection Time: 4.66295
Timestep Consumption Time: 1.96520
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 6.62814

Cumulative Model Updates: 10488
Cumulative Timesteps: 87755350

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 87755350...
Checkpoint 87755350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.60034
Policy Entropy: 1.36905
Value Function Loss: 0.55969

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.07448
Value Function Update Magnitude: 0.20078

Collected Steps per Second: 9858.35794
Overall Steps per Second: 7145.95300

Timestep Collection Time: 5.07458
Timestep Consumption Time: 1.92617
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.00075

Cumulative Model Updates: 10494
Cumulative Timesteps: 87805377

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.86892
Policy Entropy: 1.36835
Value Function Loss: 0.56284

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.05691
Policy Update Magnitude: 0.07523
Value Function Update Magnitude: 0.17177

Collected Steps per Second: 10112.43958
Overall Steps per Second: 7264.05083

Timestep Collection Time: 4.94816
Timestep Consumption Time: 1.94028
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 6.88844

Cumulative Model Updates: 10500
Cumulative Timesteps: 87855415

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 87855415...
Checkpoint 87855415 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1448.17771
Policy Entropy: 1.36902
Value Function Loss: 0.56489

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.04876
Policy Update Magnitude: 0.08233
Value Function Update Magnitude: 0.15045

Collected Steps per Second: 10702.14402
Overall Steps per Second: 7486.22284

Timestep Collection Time: 4.67561
Timestep Consumption Time: 2.00854
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 6.68415

Cumulative Model Updates: 10506
Cumulative Timesteps: 87905454

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.41050
Policy Entropy: 1.36930
Value Function Loss: 0.55348

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.05782
Policy Update Magnitude: 0.08931
Value Function Update Magnitude: 0.16599

Collected Steps per Second: 10207.87799
Overall Steps per Second: 7212.79184

Timestep Collection Time: 4.90210
Timestep Consumption Time: 2.03558
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 6.93767

Cumulative Model Updates: 10512
Cumulative Timesteps: 87955494

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 87955494...
Checkpoint 87955494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1336.69055
Policy Entropy: 1.36789
Value Function Loss: 0.55093

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.05779
Policy Update Magnitude: 0.08685
Value Function Update Magnitude: 0.15595

Collected Steps per Second: 9827.58632
Overall Steps per Second: 7098.12082

Timestep Collection Time: 5.09138
Timestep Consumption Time: 1.95781
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 7.04919

Cumulative Model Updates: 10518
Cumulative Timesteps: 88005530

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1066.28579
Policy Entropy: 1.36947
Value Function Loss: 0.55800

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.05995
Policy Update Magnitude: 0.08723
Value Function Update Magnitude: 0.14232

Collected Steps per Second: 10260.32820
Overall Steps per Second: 7220.27390

Timestep Collection Time: 4.87402
Timestep Consumption Time: 2.05218
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 6.92619

Cumulative Model Updates: 10524
Cumulative Timesteps: 88055539

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 88055539...
Checkpoint 88055539 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.95308
Policy Entropy: 1.36979
Value Function Loss: 0.55598

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.09105
Value Function Update Magnitude: 0.11456

Collected Steps per Second: 9967.03616
Overall Steps per Second: 7160.91614

Timestep Collection Time: 5.01694
Timestep Consumption Time: 1.96597
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 6.98291

Cumulative Model Updates: 10530
Cumulative Timesteps: 88105543

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1608.54822
Policy Entropy: 1.36716
Value Function Loss: 0.56595

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.08689
Value Function Update Magnitude: 0.14087

Collected Steps per Second: 9881.42557
Overall Steps per Second: 7128.64869

Timestep Collection Time: 5.06364
Timestep Consumption Time: 1.95536
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.01900

Cumulative Model Updates: 10536
Cumulative Timesteps: 88155579

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 88155579...
Checkpoint 88155579 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.12101
Policy Entropy: 1.36830
Value Function Loss: 0.55983

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.08333
Value Function Update Magnitude: 0.14897

Collected Steps per Second: 10482.05610
Overall Steps per Second: 7355.90181

Timestep Collection Time: 4.77387
Timestep Consumption Time: 2.02883
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 6.80270

Cumulative Model Updates: 10542
Cumulative Timesteps: 88205619

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.16389
Policy Entropy: 1.36694
Value Function Loss: 0.56789

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.08375
Value Function Update Magnitude: 0.13825

Collected Steps per Second: 9818.51642
Overall Steps per Second: 7125.67682

Timestep Collection Time: 5.09609
Timestep Consumption Time: 1.92584
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 7.02193

Cumulative Model Updates: 10548
Cumulative Timesteps: 88255655

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 88255655...
Checkpoint 88255655 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1032.22464
Policy Entropy: 1.36699
Value Function Loss: 0.55116

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.08902
Value Function Update Magnitude: 0.12772

Collected Steps per Second: 9827.23901
Overall Steps per Second: 7112.56637

Timestep Collection Time: 5.09177
Timestep Consumption Time: 1.94339
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.03515

Cumulative Model Updates: 10554
Cumulative Timesteps: 88305693

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.92575
Policy Entropy: 1.36758
Value Function Loss: 0.55301

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.08317
Value Function Update Magnitude: 0.13348

Collected Steps per Second: 10576.60997
Overall Steps per Second: 7406.79786

Timestep Collection Time: 4.73082
Timestep Consumption Time: 2.02460
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 6.75542

Cumulative Model Updates: 10560
Cumulative Timesteps: 88355729

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 88355729...
Checkpoint 88355729 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.57471
Policy Entropy: 1.36613
Value Function Loss: 0.53682

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.09279
Value Function Update Magnitude: 0.16765

Collected Steps per Second: 10662.78721
Overall Steps per Second: 7553.76872

Timestep Collection Time: 4.69127
Timestep Consumption Time: 1.93086
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.62212

Cumulative Model Updates: 10566
Cumulative Timesteps: 88405751

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1197.10176
Policy Entropy: 1.36558
Value Function Loss: 0.52723

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.09166
Value Function Update Magnitude: 0.18986

Collected Steps per Second: 9924.30169
Overall Steps per Second: 7110.94400

Timestep Collection Time: 5.03814
Timestep Consumption Time: 1.99328
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.03142

Cumulative Model Updates: 10572
Cumulative Timesteps: 88455751

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 88455751...
Checkpoint 88455751 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1466.34681
Policy Entropy: 1.36405
Value Function Loss: 0.51568

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.08209
Value Function Update Magnitude: 0.18944

Collected Steps per Second: 10322.47986
Overall Steps per Second: 7301.45795

Timestep Collection Time: 4.84515
Timestep Consumption Time: 2.00471
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.84986

Cumulative Model Updates: 10578
Cumulative Timesteps: 88505765

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1094.63353
Policy Entropy: 1.36560
Value Function Loss: 0.53036

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.08029
Value Function Update Magnitude: 0.17317

Collected Steps per Second: 9929.00608
Overall Steps per Second: 7064.96139

Timestep Collection Time: 5.03998
Timestep Consumption Time: 2.04314
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.08312

Cumulative Model Updates: 10584
Cumulative Timesteps: 88555807

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 88555807...
Checkpoint 88555807 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1703.25289
Policy Entropy: 1.36497
Value Function Loss: 0.52841

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06121
Policy Update Magnitude: 0.09188
Value Function Update Magnitude: 0.20510

Collected Steps per Second: 9990.63610
Overall Steps per Second: 7159.79334

Timestep Collection Time: 5.00559
Timestep Consumption Time: 1.97911
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 6.98470

Cumulative Model Updates: 10590
Cumulative Timesteps: 88605816

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1103.82170
Policy Entropy: 1.36582
Value Function Loss: 0.53830

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.08969
Value Function Update Magnitude: 0.21592

Collected Steps per Second: 10475.53537
Overall Steps per Second: 7376.75029

Timestep Collection Time: 4.77474
Timestep Consumption Time: 2.00575
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 6.78049

Cumulative Model Updates: 10596
Cumulative Timesteps: 88655834

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 88655834...
Checkpoint 88655834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.53111
Policy Entropy: 1.36389
Value Function Loss: 0.54485

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.06084
Policy Update Magnitude: 0.09089
Value Function Update Magnitude: 0.19272

Collected Steps per Second: 9935.25719
Overall Steps per Second: 7071.69035

Timestep Collection Time: 5.03580
Timestep Consumption Time: 2.03917
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 7.07497

Cumulative Model Updates: 10602
Cumulative Timesteps: 88705866

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1457.02421
Policy Entropy: 1.36116
Value Function Loss: 0.56059

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.05959
Policy Update Magnitude: 0.09407
Value Function Update Magnitude: 0.15882

Collected Steps per Second: 10046.79508
Overall Steps per Second: 7148.34047

Timestep Collection Time: 4.97781
Timestep Consumption Time: 2.01836
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 6.99617

Cumulative Model Updates: 10608
Cumulative Timesteps: 88755877

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 88755877...
Checkpoint 88755877 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.78004
Policy Entropy: 1.36146
Value Function Loss: 0.55559

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.05919
Policy Update Magnitude: 0.09695
Value Function Update Magnitude: 0.17562

Collected Steps per Second: 10790.18889
Overall Steps per Second: 7552.18670

Timestep Collection Time: 4.63486
Timestep Consumption Time: 1.98720
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.62206

Cumulative Model Updates: 10614
Cumulative Timesteps: 88805888

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.42189
Policy Entropy: 1.35932
Value Function Loss: 0.54151

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.07285
Policy Update Magnitude: 0.08887
Value Function Update Magnitude: 0.17335

Collected Steps per Second: 10267.85560
Overall Steps per Second: 7348.02965

Timestep Collection Time: 4.86976
Timestep Consumption Time: 1.93506
PPO Batch Consumption Time: 0.02440
Total Iteration Time: 6.80482

Cumulative Model Updates: 10620
Cumulative Timesteps: 88855890

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 88855890...
Checkpoint 88855890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1198.35524
Policy Entropy: 1.36020
Value Function Loss: 0.54181

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.05749
Policy Update Magnitude: 0.09015
Value Function Update Magnitude: 0.19375

Collected Steps per Second: 9998.26581
Overall Steps per Second: 7145.29171

Timestep Collection Time: 5.00457
Timestep Consumption Time: 1.99823
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.00279

Cumulative Model Updates: 10626
Cumulative Timesteps: 88905927

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1094.44720
Policy Entropy: 1.35873
Value Function Loss: 0.53346

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.09568
Value Function Update Magnitude: 0.17151

Collected Steps per Second: 10467.93300
Overall Steps per Second: 7427.78694

Timestep Collection Time: 4.78003
Timestep Consumption Time: 1.95643
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 6.73646

Cumulative Model Updates: 10632
Cumulative Timesteps: 88955964

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 88955964...
Checkpoint 88955964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1238.91832
Policy Entropy: 1.35698
Value Function Loss: 0.53604

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.06609
Policy Update Magnitude: 0.09432
Value Function Update Magnitude: 0.18652

Collected Steps per Second: 9881.81946
Overall Steps per Second: 6825.03303

Timestep Collection Time: 5.06233
Timestep Consumption Time: 2.26731
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 7.32963

Cumulative Model Updates: 10638
Cumulative Timesteps: 89005989

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.43033
Policy Entropy: 1.35665
Value Function Loss: 0.51957

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.09851
Value Function Update Magnitude: 0.24495

Collected Steps per Second: 9626.04581
Overall Steps per Second: 6829.75594

Timestep Collection Time: 5.19528
Timestep Consumption Time: 2.12709
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.32237

Cumulative Model Updates: 10644
Cumulative Timesteps: 89055999

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 89055999...
Checkpoint 89055999 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1046.07223
Policy Entropy: 1.35700
Value Function Loss: 0.51498

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.09226
Value Function Update Magnitude: 0.22910

Collected Steps per Second: 9870.45664
Overall Steps per Second: 7004.87749

Timestep Collection Time: 5.06613
Timestep Consumption Time: 2.07247
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.13860

Cumulative Model Updates: 10650
Cumulative Timesteps: 89106004

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.86282
Policy Entropy: 1.35808
Value Function Loss: 0.51469

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.05506
Policy Update Magnitude: 0.08893
Value Function Update Magnitude: 0.21484

Collected Steps per Second: 9722.92871
Overall Steps per Second: 6921.57606

Timestep Collection Time: 5.14608
Timestep Consumption Time: 2.08276
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.22884

Cumulative Model Updates: 10656
Cumulative Timesteps: 89156039

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 89156039...
Checkpoint 89156039 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.47890
Policy Entropy: 1.35694
Value Function Loss: 0.52459

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.05999
Policy Update Magnitude: 0.09847
Value Function Update Magnitude: 0.23252

Collected Steps per Second: 10151.92817
Overall Steps per Second: 7137.84356

Timestep Collection Time: 4.92862
Timestep Consumption Time: 2.08120
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.00982

Cumulative Model Updates: 10662
Cumulative Timesteps: 89206074

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1004.97157
Policy Entropy: 1.35603
Value Function Loss: 0.52372

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.05755
Policy Update Magnitude: 0.10649
Value Function Update Magnitude: 0.18191

Collected Steps per Second: 10334.62365
Overall Steps per Second: 7245.69381

Timestep Collection Time: 4.83840
Timestep Consumption Time: 2.06267
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.90106

Cumulative Model Updates: 10668
Cumulative Timesteps: 89256077

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 89256077...
Checkpoint 89256077 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1020.92906
Policy Entropy: 1.35634
Value Function Loss: 0.52600

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.07336
Policy Update Magnitude: 0.10301
Value Function Update Magnitude: 0.21276

Collected Steps per Second: 10280.76106
Overall Steps per Second: 7356.66049

Timestep Collection Time: 4.86715
Timestep Consumption Time: 1.93458
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.80173

Cumulative Model Updates: 10674
Cumulative Timesteps: 89306115

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1102.75715
Policy Entropy: 1.35689
Value Function Loss: 0.50925

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.05640
Policy Update Magnitude: 0.09914
Value Function Update Magnitude: 0.21345

Collected Steps per Second: 10339.27202
Overall Steps per Second: 7175.08793

Timestep Collection Time: 4.83641
Timestep Consumption Time: 2.13284
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 6.96925

Cumulative Model Updates: 10680
Cumulative Timesteps: 89356120

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 89356120...
Checkpoint 89356120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1113.38679
Policy Entropy: 1.35567
Value Function Loss: 0.51524

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.06282
Policy Update Magnitude: 0.09750
Value Function Update Magnitude: 0.21668

Collected Steps per Second: 9780.92156
Overall Steps per Second: 6955.45716

Timestep Collection Time: 5.11332
Timestep Consumption Time: 2.07715
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.19047

Cumulative Model Updates: 10686
Cumulative Timesteps: 89406133

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.97463
Policy Entropy: 1.35593
Value Function Loss: 0.51327

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.08663
Value Function Update Magnitude: 0.21740

Collected Steps per Second: 9850.64735
Overall Steps per Second: 7094.49758

Timestep Collection Time: 5.07774
Timestep Consumption Time: 1.97266
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.05039

Cumulative Model Updates: 10692
Cumulative Timesteps: 89456152

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 89456152...
Checkpoint 89456152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1143.62372
Policy Entropy: 1.35414
Value Function Loss: 0.51639

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.06309
Policy Update Magnitude: 0.08900
Value Function Update Magnitude: 0.22326

Collected Steps per Second: 10473.47829
Overall Steps per Second: 7086.38611

Timestep Collection Time: 4.77673
Timestep Consumption Time: 2.28314
PPO Batch Consumption Time: 0.03496
Total Iteration Time: 7.05987

Cumulative Model Updates: 10698
Cumulative Timesteps: 89506181

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1207.10968
Policy Entropy: 1.35604
Value Function Loss: 0.54200

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.08782
Value Function Update Magnitude: 0.18418

Collected Steps per Second: 10456.59404
Overall Steps per Second: 7348.83739

Timestep Collection Time: 4.78215
Timestep Consumption Time: 2.02233
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 6.80448

Cumulative Model Updates: 10704
Cumulative Timesteps: 89556186

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 89556186...
Checkpoint 89556186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.22142
Policy Entropy: 1.35227
Value Function Loss: 0.55754

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.08380
Value Function Update Magnitude: 0.13881

Collected Steps per Second: 8956.42373
Overall Steps per Second: 6473.40175

Timestep Collection Time: 5.58404
Timestep Consumption Time: 2.14189
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 7.72592

Cumulative Model Updates: 10710
Cumulative Timesteps: 89606199

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.49133
Policy Entropy: 1.35078
Value Function Loss: 0.57137

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.08080
Value Function Update Magnitude: 0.14309

Collected Steps per Second: 9708.22286
Overall Steps per Second: 6928.92436

Timestep Collection Time: 5.15429
Timestep Consumption Time: 2.06747
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.22176

Cumulative Model Updates: 10716
Cumulative Timesteps: 89656238

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 89656238...
Checkpoint 89656238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1331.40322
Policy Entropy: 1.34572
Value Function Loss: 0.55837

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.07688
Value Function Update Magnitude: 0.15161

Collected Steps per Second: 10397.05699
Overall Steps per Second: 7320.17495

Timestep Collection Time: 4.81040
Timestep Consumption Time: 2.02195
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 6.83235

Cumulative Model Updates: 10722
Cumulative Timesteps: 89706252

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1177.74508
Policy Entropy: 1.34453
Value Function Loss: 0.55896

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.07889
Value Function Update Magnitude: 0.15741

Collected Steps per Second: 10003.12556
Overall Steps per Second: 7197.78742

Timestep Collection Time: 4.99894
Timestep Consumption Time: 1.94834
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 6.94727

Cumulative Model Updates: 10728
Cumulative Timesteps: 89756257

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 89756257...
Checkpoint 89756257 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.42153
Policy Entropy: 1.34548
Value Function Loss: 0.55857

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.07272
Value Function Update Magnitude: 0.15197

Collected Steps per Second: 9890.51579
Overall Steps per Second: 7108.54020

Timestep Collection Time: 5.05929
Timestep Consumption Time: 1.97999
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.03928

Cumulative Model Updates: 10734
Cumulative Timesteps: 89806296

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1028.77318
Policy Entropy: 1.34346
Value Function Loss: 0.56572

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.06989
Policy Update Magnitude: 0.07910
Value Function Update Magnitude: 0.14544

Collected Steps per Second: 10366.60970
Overall Steps per Second: 7108.07942

Timestep Collection Time: 4.82395
Timestep Consumption Time: 2.21143
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.03537

Cumulative Model Updates: 10740
Cumulative Timesteps: 89856304

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 89856304...
Checkpoint 89856304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1550.29250
Policy Entropy: 1.34276
Value Function Loss: 0.58881

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.06480
Policy Update Magnitude: 0.09747
Value Function Update Magnitude: 0.14969

Collected Steps per Second: 10182.75966
Overall Steps per Second: 7261.35862

Timestep Collection Time: 4.91173
Timestep Consumption Time: 1.97610
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 6.88783

Cumulative Model Updates: 10746
Cumulative Timesteps: 89906319

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1400.52035
Policy Entropy: 1.33889
Value Function Loss: 0.60490

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.09505
Value Function Update Magnitude: 0.14203

Collected Steps per Second: 9858.34372
Overall Steps per Second: 7072.42777

Timestep Collection Time: 5.07438
Timestep Consumption Time: 1.99886
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.07324

Cumulative Model Updates: 10752
Cumulative Timesteps: 89956344

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 89956344...
Checkpoint 89956344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1018.02881
Policy Entropy: 1.33396
Value Function Loss: 0.60961

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.08509
Value Function Update Magnitude: 0.14589

Collected Steps per Second: 9934.28302
Overall Steps per Second: 7106.21382

Timestep Collection Time: 5.03569
Timestep Consumption Time: 2.00406
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.03975

Cumulative Model Updates: 10758
Cumulative Timesteps: 90006370

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.21275
Policy Entropy: 1.33151
Value Function Loss: 0.60910

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.07742
Policy Update Magnitude: 0.08894
Value Function Update Magnitude: 0.12211

Collected Steps per Second: 10277.43145
Overall Steps per Second: 7357.65880

Timestep Collection Time: 4.86805
Timestep Consumption Time: 1.93181
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.79985

Cumulative Model Updates: 10764
Cumulative Timesteps: 90056401

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 90056401...
Checkpoint 90056401 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.27563
Policy Entropy: 1.33224
Value Function Loss: 0.59170

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.06295
Policy Update Magnitude: 0.09943
Value Function Update Magnitude: 0.11118

Collected Steps per Second: 10153.22665
Overall Steps per Second: 7174.87346

Timestep Collection Time: 4.92612
Timestep Consumption Time: 2.04488
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 6.97099

Cumulative Model Updates: 10770
Cumulative Timesteps: 90106417

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1097.19446
Policy Entropy: 1.32921
Value Function Loss: 0.58902

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.09176
Value Function Update Magnitude: 0.14436

Collected Steps per Second: 9973.38286
Overall Steps per Second: 7203.83875

Timestep Collection Time: 5.01565
Timestep Consumption Time: 1.92829
PPO Batch Consumption Time: 0.02878
Total Iteration Time: 6.94394

Cumulative Model Updates: 10776
Cumulative Timesteps: 90156440

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 90156440...
Checkpoint 90156440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1114.79152
Policy Entropy: 1.33220
Value Function Loss: 0.58021

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.08397
Value Function Update Magnitude: 0.15317

Collected Steps per Second: 10284.41871
Overall Steps per Second: 6932.77014

Timestep Collection Time: 4.86377
Timestep Consumption Time: 2.35139
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.21515

Cumulative Model Updates: 10782
Cumulative Timesteps: 90206461

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1067.36275
Policy Entropy: 1.32791
Value Function Loss: 0.59046

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.08428
Value Function Update Magnitude: 0.14640

Collected Steps per Second: 10104.38420
Overall Steps per Second: 7140.46186

Timestep Collection Time: 4.95132
Timestep Consumption Time: 2.05523
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.00655

Cumulative Model Updates: 10788
Cumulative Timesteps: 90256491

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 90256491...
Checkpoint 90256491 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1181.07349
Policy Entropy: 1.33254
Value Function Loss: 0.61208

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.08843
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 9640.93800
Overall Steps per Second: 6959.15037

Timestep Collection Time: 5.18829
Timestep Consumption Time: 1.99937
PPO Batch Consumption Time: 0.02462
Total Iteration Time: 7.18766

Cumulative Model Updates: 10794
Cumulative Timesteps: 90306511

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1496.56474
Policy Entropy: 1.32870
Value Function Loss: 0.62459

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.07795
Value Function Update Magnitude: 0.12756

Collected Steps per Second: 9775.61465
Overall Steps per Second: 7111.45065

Timestep Collection Time: 5.11487
Timestep Consumption Time: 1.91618
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 7.03105

Cumulative Model Updates: 10800
Cumulative Timesteps: 90356512

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 90356512...
Checkpoint 90356512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1120.48339
Policy Entropy: 1.32762
Value Function Loss: 0.61150

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.07881
Policy Update Magnitude: 0.07656
Value Function Update Magnitude: 0.12808

Collected Steps per Second: 10436.41326
Overall Steps per Second: 7294.76480

Timestep Collection Time: 4.79370
Timestep Consumption Time: 2.06451
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 6.85821

Cumulative Model Updates: 10806
Cumulative Timesteps: 90406541

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1227.67424
Policy Entropy: 1.32502
Value Function Loss: 0.59910

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.07105
Value Function Update Magnitude: 0.13233

Collected Steps per Second: 9913.23463
Overall Steps per Second: 7041.27516

Timestep Collection Time: 5.04628
Timestep Consumption Time: 2.05825
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.10454

Cumulative Model Updates: 10812
Cumulative Timesteps: 90456566

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 90456566...
Checkpoint 90456566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1475.64508
Policy Entropy: 1.32548
Value Function Loss: 0.60946

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.08096
Value Function Update Magnitude: 0.15557

Collected Steps per Second: 9824.84554
Overall Steps per Second: 6917.61455

Timestep Collection Time: 5.09026
Timestep Consumption Time: 2.13926
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 7.22952

Cumulative Model Updates: 10818
Cumulative Timesteps: 90506577

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.48377
Policy Entropy: 1.32738
Value Function Loss: 0.64248

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.07590
Value Function Update Magnitude: 0.13734

Collected Steps per Second: 10640.78533
Overall Steps per Second: 7443.47385

Timestep Collection Time: 4.70125
Timestep Consumption Time: 2.01940
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 6.72065

Cumulative Model Updates: 10824
Cumulative Timesteps: 90556602

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 90556602...
Checkpoint 90556602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1249.78003
Policy Entropy: 1.32279
Value Function Loss: 0.65370

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.08405
Value Function Update Magnitude: 0.13213

Collected Steps per Second: 10440.60930
Overall Steps per Second: 7354.26829

Timestep Collection Time: 4.79129
Timestep Consumption Time: 2.01075
PPO Batch Consumption Time: 0.02957
Total Iteration Time: 6.80204

Cumulative Model Updates: 10830
Cumulative Timesteps: 90606626

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1366.05605
Policy Entropy: 1.32258
Value Function Loss: 0.64353

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.07588
Value Function Update Magnitude: 0.13540

Collected Steps per Second: 10059.68362
Overall Steps per Second: 7160.14080

Timestep Collection Time: 4.97222
Timestep Consumption Time: 2.01353
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 6.98576

Cumulative Model Updates: 10836
Cumulative Timesteps: 90656645

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 90656645...
Checkpoint 90656645 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1240.25702
Policy Entropy: 1.31749
Value Function Loss: 0.62717

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.09058
Value Function Update Magnitude: 0.13352

Collected Steps per Second: 7143.51413
Overall Steps per Second: 5487.48139

Timestep Collection Time: 7.00006
Timestep Consumption Time: 2.11250
PPO Batch Consumption Time: 0.03252
Total Iteration Time: 9.11256

Cumulative Model Updates: 10842
Cumulative Timesteps: 90706650

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1520.37361
Policy Entropy: 1.32076
Value Function Loss: 0.61202

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.09618
Value Function Update Magnitude: 0.17010

Collected Steps per Second: 10968.89199
Overall Steps per Second: 7558.19066

Timestep Collection Time: 4.55835
Timestep Consumption Time: 2.05699
PPO Batch Consumption Time: 0.02444
Total Iteration Time: 6.61534

Cumulative Model Updates: 10848
Cumulative Timesteps: 90756650

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 90756650...
Checkpoint 90756650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1323.62047
Policy Entropy: 1.31787
Value Function Loss: 0.62214

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.06525
Policy Update Magnitude: 0.09614
Value Function Update Magnitude: 0.16129

Collected Steps per Second: 10373.68909
Overall Steps per Second: 7224.18829

Timestep Collection Time: 4.82162
Timestep Consumption Time: 2.10206
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 6.92368

Cumulative Model Updates: 10854
Cumulative Timesteps: 90806668

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1254.95377
Policy Entropy: 1.32357
Value Function Loss: 0.61095

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.08997
Value Function Update Magnitude: 0.15843

Collected Steps per Second: 10155.78412
Overall Steps per Second: 7068.91995

Timestep Collection Time: 4.92547
Timestep Consumption Time: 2.15086
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 7.07633

Cumulative Model Updates: 10860
Cumulative Timesteps: 90856690

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 90856690...
Checkpoint 90856690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1518.96074
Policy Entropy: 1.31982
Value Function Loss: 0.61347

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.08057
Value Function Update Magnitude: 0.14399

Collected Steps per Second: 9144.33303
Overall Steps per Second: 6552.62038

Timestep Collection Time: 5.47202
Timestep Consumption Time: 2.16431
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.63633

Cumulative Model Updates: 10866
Cumulative Timesteps: 90906728

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1346.04433
Policy Entropy: 1.32530
Value Function Loss: 0.60674

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.08779
Value Function Update Magnitude: 0.14596

Collected Steps per Second: 10702.10646
Overall Steps per Second: 7471.96362

Timestep Collection Time: 4.67600
Timestep Consumption Time: 2.02144
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 6.69744

Cumulative Model Updates: 10872
Cumulative Timesteps: 90956771

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 90956771...
Checkpoint 90956771 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1224.19006
Policy Entropy: 1.32044
Value Function Loss: 0.62970

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.09409
Value Function Update Magnitude: 0.14608

Collected Steps per Second: 10219.49845
Overall Steps per Second: 7136.59482

Timestep Collection Time: 4.89593
Timestep Consumption Time: 2.11497
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.01091

Cumulative Model Updates: 10878
Cumulative Timesteps: 91006805

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1200.48139
Policy Entropy: 1.32549
Value Function Loss: 0.62239

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.06630
Policy Update Magnitude: 0.09234
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 9648.91968
Overall Steps per Second: 6877.76974

Timestep Collection Time: 5.18607
Timestep Consumption Time: 2.08954
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 7.27561

Cumulative Model Updates: 10884
Cumulative Timesteps: 91056845

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 91056845...
Checkpoint 91056845 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.43641
Policy Entropy: 1.32163
Value Function Loss: 0.62875

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.06963
Policy Update Magnitude: 0.10255
Value Function Update Magnitude: 0.13913

Collected Steps per Second: 10767.18980
Overall Steps per Second: 7512.73590

Timestep Collection Time: 4.64764
Timestep Consumption Time: 2.01332
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 6.66096

Cumulative Model Updates: 10890
Cumulative Timesteps: 91106887

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1244.60059
Policy Entropy: 1.32237
Value Function Loss: 0.60817

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.09818
Value Function Update Magnitude: 0.13920

Collected Steps per Second: 9808.95323
Overall Steps per Second: 6956.90839

Timestep Collection Time: 5.09779
Timestep Consumption Time: 2.08988
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.18768

Cumulative Model Updates: 10896
Cumulative Timesteps: 91156891

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 91156891...
Checkpoint 91156891 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1670.46423
Policy Entropy: 1.32150
Value Function Loss: 0.61180

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.09695
Value Function Update Magnitude: 0.17355

Collected Steps per Second: 9553.63155
Overall Steps per Second: 6885.79448

Timestep Collection Time: 5.23550
Timestep Consumption Time: 2.02844
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.26394

Cumulative Model Updates: 10902
Cumulative Timesteps: 91206909

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1452.52622
Policy Entropy: 1.32133
Value Function Loss: 0.61295

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.06395
Policy Update Magnitude: 0.11169
Value Function Update Magnitude: 0.16997

Collected Steps per Second: 10528.19363
Overall Steps per Second: 7440.80582

Timestep Collection Time: 4.75172
Timestep Consumption Time: 1.97161
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 6.72333

Cumulative Model Updates: 10908
Cumulative Timesteps: 91256936

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 91256936...
Checkpoint 91256936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1081.39852
Policy Entropy: 1.32438
Value Function Loss: 0.61421

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.10053
Value Function Update Magnitude: 0.14007

Collected Steps per Second: 9308.08708
Overall Steps per Second: 6696.97039

Timestep Collection Time: 5.37543
Timestep Consumption Time: 2.09586
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.47129

Cumulative Model Updates: 10914
Cumulative Timesteps: 91306971

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1307.75682
Policy Entropy: 1.32073
Value Function Loss: 0.62991

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.08822
Value Function Update Magnitude: 0.15593

Collected Steps per Second: 9887.30383
Overall Steps per Second: 7120.56398

Timestep Collection Time: 5.05780
Timestep Consumption Time: 1.96524
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.02304

Cumulative Model Updates: 10920
Cumulative Timesteps: 91356979

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 91356979...
Checkpoint 91356979 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1440.83233
Policy Entropy: 1.31759
Value Function Loss: 0.61925

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.07656
Value Function Update Magnitude: 0.14241

Collected Steps per Second: 9980.72434
Overall Steps per Second: 7197.60145

Timestep Collection Time: 5.01437
Timestep Consumption Time: 1.93892
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.95329

Cumulative Model Updates: 10926
Cumulative Timesteps: 91407026

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1325.28428
Policy Entropy: 1.31527
Value Function Loss: 0.62957

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.07633
Value Function Update Magnitude: 0.13028

Collected Steps per Second: 10260.70127
Overall Steps per Second: 7425.76469

Timestep Collection Time: 4.87744
Timestep Consumption Time: 1.86206
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 6.73951

Cumulative Model Updates: 10932
Cumulative Timesteps: 91457072

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 91457072...
Checkpoint 91457072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1264.76338
Policy Entropy: 1.31797
Value Function Loss: 0.62643

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.07414
Value Function Update Magnitude: 0.14291

Collected Steps per Second: 10382.58493
Overall Steps per Second: 7499.61529

Timestep Collection Time: 4.81624
Timestep Consumption Time: 1.85144
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 6.66768

Cumulative Model Updates: 10938
Cumulative Timesteps: 91507077

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1646.13304
Policy Entropy: 1.31793
Value Function Loss: 0.62914

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.07548
Value Function Update Magnitude: 0.16149

Collected Steps per Second: 11043.59735
Overall Steps per Second: 7665.55529

Timestep Collection Time: 4.52860
Timestep Consumption Time: 1.99565
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 6.52425

Cumulative Model Updates: 10944
Cumulative Timesteps: 91557089

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 91557089...
Checkpoint 91557089 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1093.83657
Policy Entropy: 1.32073
Value Function Loss: 0.62142

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.08164
Value Function Update Magnitude: 0.19404

Collected Steps per Second: 10743.21280
Overall Steps per Second: 7423.65599

Timestep Collection Time: 4.65708
Timestep Consumption Time: 2.08246
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 6.73954

Cumulative Model Updates: 10950
Cumulative Timesteps: 91607121

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1204.40295
Policy Entropy: 1.31741
Value Function Loss: 0.61351

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.08680
Value Function Update Magnitude: 0.18698

Collected Steps per Second: 10211.78791
Overall Steps per Second: 7383.22153

Timestep Collection Time: 4.89944
Timestep Consumption Time: 1.87701
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 6.77645

Cumulative Model Updates: 10956
Cumulative Timesteps: 91657153

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 91657153...
Checkpoint 91657153 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.08538
Policy Entropy: 1.31805
Value Function Loss: 0.61892

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.08087
Value Function Update Magnitude: 0.19629

Collected Steps per Second: 10441.12803
Overall Steps per Second: 7350.19789

Timestep Collection Time: 4.79048
Timestep Consumption Time: 2.01451
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 6.80499

Cumulative Model Updates: 10962
Cumulative Timesteps: 91707171

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1285.82825
Policy Entropy: 1.31406
Value Function Loss: 0.62022

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.10239
Value Function Update Magnitude: 0.19743

Collected Steps per Second: 10084.37542
Overall Steps per Second: 7170.47328

Timestep Collection Time: 4.96035
Timestep Consumption Time: 2.01576
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 6.97611

Cumulative Model Updates: 10968
Cumulative Timesteps: 91757193

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 91757193...
Checkpoint 91757193 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1896.84946
Policy Entropy: 1.31378
Value Function Loss: 0.62733

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06290
Policy Update Magnitude: 0.11821
Value Function Update Magnitude: 0.20308

Collected Steps per Second: 10550.47922
Overall Steps per Second: 7553.83777

Timestep Collection Time: 4.74168
Timestep Consumption Time: 1.88105
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 6.62273

Cumulative Model Updates: 10974
Cumulative Timesteps: 91807220

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1739.96901
Policy Entropy: 1.31213
Value Function Loss: 0.61788

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.11666
Value Function Update Magnitude: 0.20120

Collected Steps per Second: 10383.57943
Overall Steps per Second: 6991.96787

Timestep Collection Time: 4.81809
Timestep Consumption Time: 2.33712
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.15521

Cumulative Model Updates: 10980
Cumulative Timesteps: 91857249

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 91857249...
Checkpoint 91857249 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1057.62526
Policy Entropy: 1.31116
Value Function Loss: 0.63175

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.10809
Value Function Update Magnitude: 0.18254

Collected Steps per Second: 9609.82298
Overall Steps per Second: 6825.82877

Timestep Collection Time: 5.20790
Timestep Consumption Time: 2.12410
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.33200

Cumulative Model Updates: 10986
Cumulative Timesteps: 91907296

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1446.85483
Policy Entropy: 1.31661
Value Function Loss: 0.64590

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.10146
Value Function Update Magnitude: 0.14004

Collected Steps per Second: 9939.46136
Overall Steps per Second: 7056.94703

Timestep Collection Time: 5.03216
Timestep Consumption Time: 2.05546
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.08763

Cumulative Model Updates: 10992
Cumulative Timesteps: 91957313

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 91957313...
Checkpoint 91957313 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1191.77396
Policy Entropy: 1.30964
Value Function Loss: 0.65339

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.09173
Value Function Update Magnitude: 0.13211

Collected Steps per Second: 10148.42066
Overall Steps per Second: 7136.85729

Timestep Collection Time: 4.93141
Timestep Consumption Time: 2.08092
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.01233

Cumulative Model Updates: 10998
Cumulative Timesteps: 92007359

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1556.76281
Policy Entropy: 1.31478
Value Function Loss: 0.65465

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.08643
Value Function Update Magnitude: 0.13913

Collected Steps per Second: 9833.16230
Overall Steps per Second: 6881.02387

Timestep Collection Time: 5.08565
Timestep Consumption Time: 2.18188
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.26752

Cumulative Model Updates: 11004
Cumulative Timesteps: 92057367

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 92057367...
Checkpoint 92057367 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1646.56622
Policy Entropy: 1.30534
Value Function Loss: 0.65651

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.09275
Value Function Update Magnitude: 0.15300

Collected Steps per Second: 9492.98260
Overall Steps per Second: 6788.28941

Timestep Collection Time: 5.26958
Timestep Consumption Time: 2.09958
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.36916

Cumulative Model Updates: 11010
Cumulative Timesteps: 92107391

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1099.28793
Policy Entropy: 1.31238
Value Function Loss: 0.66496

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.09286
Value Function Update Magnitude: 0.14804

Collected Steps per Second: 10529.46703
Overall Steps per Second: 7378.28204

Timestep Collection Time: 4.75238
Timestep Consumption Time: 2.02969
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 6.78207

Cumulative Model Updates: 11016
Cumulative Timesteps: 92157431

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 92157431...
Checkpoint 92157431 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1488.17276
Policy Entropy: 1.30529
Value Function Loss: 0.66772

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.09197
Value Function Update Magnitude: 0.13838

Collected Steps per Second: 9684.66413
Overall Steps per Second: 6927.30519

Timestep Collection Time: 5.16652
Timestep Consumption Time: 2.05649
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.22301

Cumulative Model Updates: 11022
Cumulative Timesteps: 92207467

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1373.14723
Policy Entropy: 1.30854
Value Function Loss: 0.67146

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.09273
Value Function Update Magnitude: 0.14359

Collected Steps per Second: 10852.42375
Overall Steps per Second: 7431.43362

Timestep Collection Time: 4.60754
Timestep Consumption Time: 2.12104
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 6.72858

Cumulative Model Updates: 11028
Cumulative Timesteps: 92257470

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 92257470...
Checkpoint 92257470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1804.55842
Policy Entropy: 1.30505
Value Function Loss: 0.65919

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.09816
Value Function Update Magnitude: 0.16270

Collected Steps per Second: 10121.11060
Overall Steps per Second: 7092.78151

Timestep Collection Time: 4.94244
Timestep Consumption Time: 2.11022
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.05266

Cumulative Model Updates: 11034
Cumulative Timesteps: 92307493

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1081.99192
Policy Entropy: 1.30346
Value Function Loss: 0.66696

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.08871
Value Function Update Magnitude: 0.13342

Collected Steps per Second: 9067.67513
Overall Steps per Second: 6487.37927

Timestep Collection Time: 5.51784
Timestep Consumption Time: 2.19467
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 7.71251

Cumulative Model Updates: 11040
Cumulative Timesteps: 92357527

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 92357527...
Checkpoint 92357527 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1388.87767
Policy Entropy: 1.30182
Value Function Loss: 0.66249

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.08855
Value Function Update Magnitude: 0.13353

Collected Steps per Second: 10072.12830
Overall Steps per Second: 7178.63935

Timestep Collection Time: 4.96539
Timestep Consumption Time: 2.00139
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 6.96678

Cumulative Model Updates: 11046
Cumulative Timesteps: 92407539

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1158.12142
Policy Entropy: 1.29775
Value Function Loss: 0.66335

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.09874
Value Function Update Magnitude: 0.13489

Collected Steps per Second: 10846.83319
Overall Steps per Second: 7579.29986

Timestep Collection Time: 4.61075
Timestep Consumption Time: 1.98775
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 6.59850

Cumulative Model Updates: 11052
Cumulative Timesteps: 92457551

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 92457551...
Checkpoint 92457551 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2034.68057
Policy Entropy: 1.29578
Value Function Loss: 0.66260

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.10326
Value Function Update Magnitude: 0.15621

Collected Steps per Second: 10162.75353
Overall Steps per Second: 7264.44798

Timestep Collection Time: 4.92278
Timestep Consumption Time: 1.96405
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.88683

Cumulative Model Updates: 11058
Cumulative Timesteps: 92507580

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1574.21526
Policy Entropy: 1.29148
Value Function Loss: 0.66231

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.09059
Value Function Update Magnitude: 0.14437

Collected Steps per Second: 9955.86026
Overall Steps per Second: 7255.24482

Timestep Collection Time: 5.02488
Timestep Consumption Time: 1.87041
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 6.89529

Cumulative Model Updates: 11064
Cumulative Timesteps: 92557607

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 92557607...
Checkpoint 92557607 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1514.40031
Policy Entropy: 1.29195
Value Function Loss: 0.67369

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.08110
Value Function Update Magnitude: 0.14915

Collected Steps per Second: 10597.58639
Overall Steps per Second: 7279.01556

Timestep Collection Time: 4.71872
Timestep Consumption Time: 2.15131
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 6.87002

Cumulative Model Updates: 11070
Cumulative Timesteps: 92607614

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1017.05051
Policy Entropy: 1.29095
Value Function Loss: 0.67577

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.08181
Value Function Update Magnitude: 0.12763

Collected Steps per Second: 10868.34300
Overall Steps per Second: 7600.76497

Timestep Collection Time: 4.60401
Timestep Consumption Time: 1.97927
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.58328

Cumulative Model Updates: 11076
Cumulative Timesteps: 92657652

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 92657652...
Checkpoint 92657652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1345.17911
Policy Entropy: 1.29445
Value Function Loss: 0.67896

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.08238
Value Function Update Magnitude: 0.13101

Collected Steps per Second: 10215.90081
Overall Steps per Second: 7374.65751

Timestep Collection Time: 4.89551
Timestep Consumption Time: 1.88610
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 6.78160

Cumulative Model Updates: 11082
Cumulative Timesteps: 92707664

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1912.19426
Policy Entropy: 1.28992
Value Function Loss: 0.66874

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.08555
Value Function Update Magnitude: 0.18166

Collected Steps per Second: 10154.48167
Overall Steps per Second: 7280.63138

Timestep Collection Time: 4.92640
Timestep Consumption Time: 1.94457
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 6.87097

Cumulative Model Updates: 11088
Cumulative Timesteps: 92757689

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 92757689...
Checkpoint 92757689 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1722.55835
Policy Entropy: 1.28777
Value Function Loss: 0.67785

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.09526
Value Function Update Magnitude: 0.19525

Collected Steps per Second: 11059.45622
Overall Steps per Second: 7480.87855

Timestep Collection Time: 4.52111
Timestep Consumption Time: 2.16273
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 6.68384

Cumulative Model Updates: 11094
Cumulative Timesteps: 92807690

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1368.35319
Policy Entropy: 1.28406
Value Function Loss: 0.67405

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.08153
Value Function Update Magnitude: 0.16651

Collected Steps per Second: 10731.27463
Overall Steps per Second: 7544.42698

Timestep Collection Time: 4.66161
Timestep Consumption Time: 1.96911
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 6.63072

Cumulative Model Updates: 11100
Cumulative Timesteps: 92857715

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 92857715...
Checkpoint 92857715 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1576.86580
Policy Entropy: 1.27931
Value Function Loss: 0.69357

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.07896
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 9657.18311
Overall Steps per Second: 6886.64707

Timestep Collection Time: 5.18132
Timestep Consumption Time: 2.08448
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.26580

Cumulative Model Updates: 11106
Cumulative Timesteps: 92907752

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1857.43517
Policy Entropy: 1.28157
Value Function Loss: 0.70659

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.12799

Collected Steps per Second: 9224.31574
Overall Steps per Second: 6727.27101

Timestep Collection Time: 5.42393
Timestep Consumption Time: 2.01327
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.43719

Cumulative Model Updates: 11112
Cumulative Timesteps: 92957784

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 92957784...
Checkpoint 92957784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1722.94319
Policy Entropy: 1.27350
Value Function Loss: 0.70696

Mean KL Divergence: 0.02399
SB3 Clip Fraction: 0.16868
Policy Update Magnitude: 0.08999
Value Function Update Magnitude: 0.15991

Collected Steps per Second: 9876.33864
Overall Steps per Second: 7160.34423

Timestep Collection Time: 5.06311
Timestep Consumption Time: 1.92049
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 6.98360

Cumulative Model Updates: 11118
Cumulative Timesteps: 93007789

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2267.40616
Policy Entropy: 1.27232
Value Function Loss: 0.69822

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.07637
Value Function Update Magnitude: 0.17755

Collected Steps per Second: 9491.78636
Overall Steps per Second: 6739.65292

Timestep Collection Time: 5.26866
Timestep Consumption Time: 2.15145
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.42012

Cumulative Model Updates: 11124
Cumulative Timesteps: 93057798

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 93057798...
Checkpoint 93057798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1666.21109
Policy Entropy: 1.27346
Value Function Loss: 0.69937

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.09691
Value Function Update Magnitude: 0.17295

Collected Steps per Second: 9511.40991
Overall Steps per Second: 6886.18583

Timestep Collection Time: 5.25737
Timestep Consumption Time: 2.00427
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.26164

Cumulative Model Updates: 11130
Cumulative Timesteps: 93107803

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1670.53730
Policy Entropy: 1.27602
Value Function Loss: 0.69573

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.09501
Value Function Update Magnitude: 0.15057

Collected Steps per Second: 9838.82475
Overall Steps per Second: 7129.89416

Timestep Collection Time: 5.08516
Timestep Consumption Time: 1.93205
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 7.01721

Cumulative Model Updates: 11136
Cumulative Timesteps: 93157835

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 93157835...
Checkpoint 93157835 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1801.40171
Policy Entropy: 1.27267
Value Function Loss: 0.69026

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.09204
Value Function Update Magnitude: 0.18917

Collected Steps per Second: 9944.91627
Overall Steps per Second: 6771.71958

Timestep Collection Time: 5.02779
Timestep Consumption Time: 2.35600
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.38380

Cumulative Model Updates: 11142
Cumulative Timesteps: 93207836

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1337.91860
Policy Entropy: 1.27992
Value Function Loss: 0.67472

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.08608
Value Function Update Magnitude: 0.18726

Collected Steps per Second: 10682.78773
Overall Steps per Second: 7395.96640

Timestep Collection Time: 4.68155
Timestep Consumption Time: 2.08051
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 6.76206

Cumulative Model Updates: 11148
Cumulative Timesteps: 93257848

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 93257848...
Checkpoint 93257848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1298.06055
Policy Entropy: 1.28383
Value Function Loss: 0.69678

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.09149
Value Function Update Magnitude: 0.15109

Collected Steps per Second: 10257.94221
Overall Steps per Second: 7187.46425

Timestep Collection Time: 4.87846
Timestep Consumption Time: 2.08408
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 6.96254

Cumulative Model Updates: 11154
Cumulative Timesteps: 93307891

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1895.12497
Policy Entropy: 1.28210
Value Function Loss: 0.70311

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.08843
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 9085.85073
Overall Steps per Second: 6604.12993

Timestep Collection Time: 5.50537
Timestep Consumption Time: 2.06883
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.57420

Cumulative Model Updates: 11160
Cumulative Timesteps: 93357912

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 93357912...
Checkpoint 93357912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1522.22522
Policy Entropy: 1.28472
Value Function Loss: 0.70787

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.09314
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 10626.86644
Overall Steps per Second: 7574.04299

Timestep Collection Time: 4.70534
Timestep Consumption Time: 1.89655
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 6.60189

Cumulative Model Updates: 11166
Cumulative Timesteps: 93407915

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1468.33392
Policy Entropy: 1.28212
Value Function Loss: 0.70606

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.08725
Value Function Update Magnitude: 0.15466

Collected Steps per Second: 10498.08140
Overall Steps per Second: 7406.93121

Timestep Collection Time: 4.76363
Timestep Consumption Time: 1.98802
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.75165

Cumulative Model Updates: 11172
Cumulative Timesteps: 93457924

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 93457924...
Checkpoint 93457924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1271.32845
Policy Entropy: 1.28944
Value Function Loss: 0.69790

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.06964
Policy Update Magnitude: 0.08603
Value Function Update Magnitude: 0.14737

Collected Steps per Second: 10381.34706
Overall Steps per Second: 7475.41304

Timestep Collection Time: 4.81835
Timestep Consumption Time: 1.87305
PPO Batch Consumption Time: 0.02437
Total Iteration Time: 6.69140

Cumulative Model Updates: 11178
Cumulative Timesteps: 93507945

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1445.01552
Policy Entropy: 1.28296
Value Function Loss: 0.70189

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.09082
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10137.51272
Overall Steps per Second: 7309.09008

Timestep Collection Time: 4.93553
Timestep Consumption Time: 1.90992
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 6.84545

Cumulative Model Updates: 11184
Cumulative Timesteps: 93557979

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 93557979...
Checkpoint 93557979 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1609.83038
Policy Entropy: 1.28906
Value Function Loss: 0.72136

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.08244
Value Function Update Magnitude: 0.12690

Collected Steps per Second: 9789.46863
Overall Steps per Second: 6788.41018

Timestep Collection Time: 5.10876
Timestep Consumption Time: 2.25851
PPO Batch Consumption Time: 0.03417
Total Iteration Time: 7.36726

Cumulative Model Updates: 11190
Cumulative Timesteps: 93607991

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1125.55776
Policy Entropy: 1.28856
Value Function Loss: 0.72414

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.08178
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 9708.86775
Overall Steps per Second: 6877.86618

Timestep Collection Time: 5.15374
Timestep Consumption Time: 2.12133
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.27508

Cumulative Model Updates: 11196
Cumulative Timesteps: 93658028

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 93658028...
Checkpoint 93658028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1631.79881
Policy Entropy: 1.28610
Value Function Loss: 0.72439

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.08409
Value Function Update Magnitude: 0.13336

Collected Steps per Second: 10482.95879
Overall Steps per Second: 7419.15001

Timestep Collection Time: 4.77251
Timestep Consumption Time: 1.97085
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 6.74336

Cumulative Model Updates: 11202
Cumulative Timesteps: 93708058

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1526.80881
Policy Entropy: 1.28517
Value Function Loss: 0.70636

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.08384
Value Function Update Magnitude: 0.14284

Collected Steps per Second: 9839.32453
Overall Steps per Second: 6999.43657

Timestep Collection Time: 5.08317
Timestep Consumption Time: 2.06240
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.14558

Cumulative Model Updates: 11208
Cumulative Timesteps: 93758073

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 93758073...
Checkpoint 93758073 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1494.21610
Policy Entropy: 1.28144
Value Function Loss: 0.72132

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.08055
Value Function Update Magnitude: 0.12877

Collected Steps per Second: 9879.22269
Overall Steps per Second: 7048.36934

Timestep Collection Time: 5.06214
Timestep Consumption Time: 2.03312
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.09526

Cumulative Model Updates: 11214
Cumulative Timesteps: 93808083

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1542.75190
Policy Entropy: 1.28058
Value Function Loss: 0.72459

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.08240
Value Function Update Magnitude: 0.12872

Collected Steps per Second: 9885.71948
Overall Steps per Second: 7086.81432

Timestep Collection Time: 5.05851
Timestep Consumption Time: 1.99784
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 7.05634

Cumulative Model Updates: 11220
Cumulative Timesteps: 93858090

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 93858090...
Checkpoint 93858090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1851.13032
Policy Entropy: 1.27641
Value Function Loss: 0.71761

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.09942
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 8920.78342
Overall Steps per Second: 6479.13118

Timestep Collection Time: 5.60713
Timestep Consumption Time: 2.11304
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.72017

Cumulative Model Updates: 11226
Cumulative Timesteps: 93908110

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1154.10956
Policy Entropy: 1.27772
Value Function Loss: 0.71254

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.10345
Value Function Update Magnitude: 0.12892

Collected Steps per Second: 10865.83500
Overall Steps per Second: 7422.48639

Timestep Collection Time: 4.60535
Timestep Consumption Time: 2.13646
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 6.74181

Cumulative Model Updates: 11232
Cumulative Timesteps: 93958151

Timesteps Collected: 50041
--------END ITERATION REPORT--------


Saving checkpoint 93958151...
Checkpoint 93958151 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1405.41242
Policy Entropy: 1.27671
Value Function Loss: 0.71630

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.08948
Value Function Update Magnitude: 0.12329

Collected Steps per Second: 10213.15867
Overall Steps per Second: 7064.73530

Timestep Collection Time: 4.89976
Timestep Consumption Time: 2.18359
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 7.08335

Cumulative Model Updates: 11238
Cumulative Timesteps: 94008193

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1536.45472
Policy Entropy: 1.27821
Value Function Loss: 0.71733

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.08430
Value Function Update Magnitude: 0.12341

Collected Steps per Second: 8995.73376
Overall Steps per Second: 6612.07626

Timestep Collection Time: 5.56075
Timestep Consumption Time: 2.00465
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.56540

Cumulative Model Updates: 11244
Cumulative Timesteps: 94058216

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 94058216...
Checkpoint 94058216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1720.67637
Policy Entropy: 1.27788
Value Function Loss: 0.71283

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.07607
Value Function Update Magnitude: 0.12426

Collected Steps per Second: 9876.48258
Overall Steps per Second: 7146.85770

Timestep Collection Time: 5.06456
Timestep Consumption Time: 1.93432
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 6.99888

Cumulative Model Updates: 11250
Cumulative Timesteps: 94108236

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1445.62934
Policy Entropy: 1.27676
Value Function Loss: 0.71229

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.07925
Value Function Update Magnitude: 0.13253

Collected Steps per Second: 10545.18662
Overall Steps per Second: 7306.59925

Timestep Collection Time: 4.74359
Timestep Consumption Time: 2.10255
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 6.84614

Cumulative Model Updates: 11256
Cumulative Timesteps: 94158258

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 94158258...
Checkpoint 94158258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1697.27241
Policy Entropy: 1.27923
Value Function Loss: 0.71671

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07680
Policy Update Magnitude: 0.09433
Value Function Update Magnitude: 0.13477

Collected Steps per Second: 10406.52614
Overall Steps per Second: 7396.07592

Timestep Collection Time: 4.80602
Timestep Consumption Time: 1.95621
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 6.76223

Cumulative Model Updates: 11262
Cumulative Timesteps: 94208272

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1721.47779
Policy Entropy: 1.28516
Value Function Loss: 0.72541

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.09322
Value Function Update Magnitude: 0.12840

Collected Steps per Second: 10111.15779
Overall Steps per Second: 7280.83336

Timestep Collection Time: 4.94741
Timestep Consumption Time: 1.92324
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.87064

Cumulative Model Updates: 11268
Cumulative Timesteps: 94258296

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 94258296...
Checkpoint 94258296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1829.10587
Policy Entropy: 1.28055
Value Function Loss: 0.71535

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.08261
Value Function Update Magnitude: 0.12736

Collected Steps per Second: 9946.76862
Overall Steps per Second: 7166.19238

Timestep Collection Time: 5.03128
Timestep Consumption Time: 1.95220
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 6.98349

Cumulative Model Updates: 11274
Cumulative Timesteps: 94308341

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1362.42041
Policy Entropy: 1.28420
Value Function Loss: 0.72523

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.08624
Value Function Update Magnitude: 0.16984

Collected Steps per Second: 10187.42474
Overall Steps per Second: 7370.50952

Timestep Collection Time: 4.90899
Timestep Consumption Time: 1.87615
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 6.78515

Cumulative Model Updates: 11280
Cumulative Timesteps: 94358351

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 94358351...
Checkpoint 94358351 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1433.86952
Policy Entropy: 1.27616
Value Function Loss: 0.73142

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.08492
Value Function Update Magnitude: 0.15787

Collected Steps per Second: 10825.33162
Overall Steps per Second: 7631.95260

Timestep Collection Time: 4.61972
Timestep Consumption Time: 1.93299
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 6.55271

Cumulative Model Updates: 11286
Cumulative Timesteps: 94408361

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1488.85087
Policy Entropy: 1.28515
Value Function Loss: 0.73592

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.08656
Value Function Update Magnitude: 0.12994

Collected Steps per Second: 10210.91592
Overall Steps per Second: 7216.71801

Timestep Collection Time: 4.89721
Timestep Consumption Time: 2.03184
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 6.92905

Cumulative Model Updates: 11292
Cumulative Timesteps: 94458366

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 94458366...
Checkpoint 94458366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1214.88824
Policy Entropy: 1.28214
Value Function Loss: 0.72782

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.09479
Value Function Update Magnitude: 0.12988

Collected Steps per Second: 10114.27680
Overall Steps per Second: 7338.36109

Timestep Collection Time: 4.94657
Timestep Consumption Time: 1.87116
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 6.81773

Cumulative Model Updates: 11298
Cumulative Timesteps: 94508397

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1341.74625
Policy Entropy: 1.28206
Value Function Loss: 0.72471

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.10136
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 9562.16483
Overall Steps per Second: 6805.92301

Timestep Collection Time: 5.23041
Timestep Consumption Time: 2.11819
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.34860

Cumulative Model Updates: 11304
Cumulative Timesteps: 94558411

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 94558411...
Checkpoint 94558411 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1567.33099
Policy Entropy: 1.28575
Value Function Loss: 0.72919

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.08724
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 9524.86029
Overall Steps per Second: 6845.92106

Timestep Collection Time: 5.25425
Timestep Consumption Time: 2.05609
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.31034

Cumulative Model Updates: 11310
Cumulative Timesteps: 94608457

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1575.74948
Policy Entropy: 1.28798
Value Function Loss: 0.72560

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.08766
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 10534.70652
Overall Steps per Second: 7347.97296

Timestep Collection Time: 4.74906
Timestep Consumption Time: 2.05962
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 6.80868

Cumulative Model Updates: 11316
Cumulative Timesteps: 94658487

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 94658487...
Checkpoint 94658487 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2099.78005
Policy Entropy: 1.29052
Value Function Loss: 0.73569

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.09428
Value Function Update Magnitude: 0.11967

Collected Steps per Second: 9165.74961
Overall Steps per Second: 6592.01459

Timestep Collection Time: 5.45793
Timestep Consumption Time: 2.13095
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.58888

Cumulative Model Updates: 11322
Cumulative Timesteps: 94708513

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1634.51896
Policy Entropy: 1.29784
Value Function Loss: 0.73288

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.09395
Value Function Update Magnitude: 0.14666

Collected Steps per Second: 9663.89164
Overall Steps per Second: 6783.29303

Timestep Collection Time: 5.17535
Timestep Consumption Time: 2.19777
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.37312

Cumulative Model Updates: 11328
Cumulative Timesteps: 94758527

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 94758527...
Checkpoint 94758527 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1017.30241
Policy Entropy: 1.29482
Value Function Loss: 0.74102

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.09744
Value Function Update Magnitude: 0.13342

Collected Steps per Second: 10209.72474
Overall Steps per Second: 7288.72516

Timestep Collection Time: 4.90003
Timestep Consumption Time: 1.96372
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 6.86375

Cumulative Model Updates: 11334
Cumulative Timesteps: 94808555

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1288.32116
Policy Entropy: 1.29923
Value Function Loss: 0.73955

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.09285
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 9116.33786
Overall Steps per Second: 6650.96118

Timestep Collection Time: 5.48949
Timestep Consumption Time: 2.03484
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.52433

Cumulative Model Updates: 11340
Cumulative Timesteps: 94858599

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 94858599...
Checkpoint 94858599 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1723.16201
Policy Entropy: 1.29491
Value Function Loss: 0.73648

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.09233
Value Function Update Magnitude: 0.13008

Collected Steps per Second: 9989.02285
Overall Steps per Second: 7203.22209

Timestep Collection Time: 5.00700
Timestep Consumption Time: 1.93642
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 6.94342

Cumulative Model Updates: 11346
Cumulative Timesteps: 94908614

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2045.50899
Policy Entropy: 1.29727
Value Function Loss: 0.72661

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.11075
Value Function Update Magnitude: 0.14106

Collected Steps per Second: 10260.67299
Overall Steps per Second: 7121.07378

Timestep Collection Time: 4.87609
Timestep Consumption Time: 2.14981
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 7.02591

Cumulative Model Updates: 11352
Cumulative Timesteps: 94958646

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 94958646...
Checkpoint 94958646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1603.06605
Policy Entropy: 1.29345
Value Function Loss: 0.72335

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.10488
Value Function Update Magnitude: 0.15448

Collected Steps per Second: 9286.01887
Overall Steps per Second: 6730.90426

Timestep Collection Time: 5.38638
Timestep Consumption Time: 2.04472
PPO Batch Consumption Time: 0.02459
Total Iteration Time: 7.43110

Cumulative Model Updates: 11358
Cumulative Timesteps: 95008664

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2011.37467
Policy Entropy: 1.29738
Value Function Loss: 0.73987

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.09513
Value Function Update Magnitude: 0.13459

Collected Steps per Second: 10450.22291
Overall Steps per Second: 7284.40238

Timestep Collection Time: 4.78899
Timestep Consumption Time: 2.08131
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 6.87030

Cumulative Model Updates: 11364
Cumulative Timesteps: 95058710

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 95058710...
Checkpoint 95058710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1546.75901
Policy Entropy: 1.29506
Value Function Loss: 0.75823

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.08743
Value Function Update Magnitude: 0.14230

Collected Steps per Second: 11371.08827
Overall Steps per Second: 7874.58535

Timestep Collection Time: 4.39914
Timestep Consumption Time: 1.95332
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 6.35246

Cumulative Model Updates: 11370
Cumulative Timesteps: 95108733

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1836.44076
Policy Entropy: 1.29691
Value Function Loss: 0.76149

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.08862
Value Function Update Magnitude: 0.13469

Collected Steps per Second: 10047.93329
Overall Steps per Second: 7217.21954

Timestep Collection Time: 4.97953
Timestep Consumption Time: 1.95306
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 6.93259

Cumulative Model Updates: 11376
Cumulative Timesteps: 95158767

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 95158767...
Checkpoint 95158767 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.69760
Policy Entropy: 1.29749
Value Function Loss: 0.74996

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.08064
Value Function Update Magnitude: 0.13215

Collected Steps per Second: 10016.20455
Overall Steps per Second: 7254.67749

Timestep Collection Time: 4.99381
Timestep Consumption Time: 1.90092
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 6.89472

Cumulative Model Updates: 11382
Cumulative Timesteps: 95208786

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2416.84186
Policy Entropy: 1.29720
Value Function Loss: 0.73823

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.08578
Value Function Update Magnitude: 0.18520

Collected Steps per Second: 9887.92579
Overall Steps per Second: 7027.68111

Timestep Collection Time: 5.05799
Timestep Consumption Time: 2.05859
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.11657

Cumulative Model Updates: 11388
Cumulative Timesteps: 95258799

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 95258799...
Checkpoint 95258799 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1255.11394
Policy Entropy: 1.28935
Value Function Loss: 0.73500

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.09191
Value Function Update Magnitude: 0.15871

Collected Steps per Second: 10004.83614
Overall Steps per Second: 6857.29797

Timestep Collection Time: 5.00028
Timestep Consumption Time: 2.29516
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.29544

Cumulative Model Updates: 11394
Cumulative Timesteps: 95308826

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1391.69135
Policy Entropy: 1.29444
Value Function Loss: 0.72745

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.08273
Value Function Update Magnitude: 0.15723

Collected Steps per Second: 10098.76086
Overall Steps per Second: 7130.12552

Timestep Collection Time: 4.95536
Timestep Consumption Time: 2.06317
PPO Batch Consumption Time: 0.02398
Total Iteration Time: 7.01853

Cumulative Model Updates: 11400
Cumulative Timesteps: 95358869

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 95358869...
Checkpoint 95358869 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1547.21273
Policy Entropy: 1.28842
Value Function Loss: 0.73503

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.08768
Value Function Update Magnitude: 0.15288

Collected Steps per Second: 10008.17393
Overall Steps per Second: 7107.21937

Timestep Collection Time: 4.99702
Timestep Consumption Time: 2.03963
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.03665

Cumulative Model Updates: 11406
Cumulative Timesteps: 95408880

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1315.54972
Policy Entropy: 1.29559
Value Function Loss: 0.73806

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.09778
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 9295.95749
Overall Steps per Second: 6783.05399

Timestep Collection Time: 5.38212
Timestep Consumption Time: 1.99390
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.37603

Cumulative Model Updates: 11412
Cumulative Timesteps: 95458912

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 95458912...
Checkpoint 95458912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2282.51633
Policy Entropy: 1.28544
Value Function Loss: 0.75993

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.09950
Value Function Update Magnitude: 0.13446

Collected Steps per Second: 10205.58398
Overall Steps per Second: 6935.55626

Timestep Collection Time: 4.89967
Timestep Consumption Time: 2.31013
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 7.20980

Cumulative Model Updates: 11418
Cumulative Timesteps: 95508916

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1299.89155
Policy Entropy: 1.28452
Value Function Loss: 0.73903

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.11087
Value Function Update Magnitude: 0.13841

Collected Steps per Second: 9151.61379
Overall Steps per Second: 6581.06459

Timestep Collection Time: 5.46625
Timestep Consumption Time: 2.13510
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.60135

Cumulative Model Updates: 11424
Cumulative Timesteps: 95558941

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 95558941...
Checkpoint 95558941 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1296.88775
Policy Entropy: 1.28429
Value Function Loss: 0.74860

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.11664
Value Function Update Magnitude: 0.13338

Collected Steps per Second: 9071.96501
Overall Steps per Second: 6513.98477

Timestep Collection Time: 5.51369
Timestep Consumption Time: 2.16517
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.67886

Cumulative Model Updates: 11430
Cumulative Timesteps: 95608961

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1319.57962
Policy Entropy: 1.28725
Value Function Loss: 0.73291

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.10427
Value Function Update Magnitude: 0.14810

Collected Steps per Second: 8999.91986
Overall Steps per Second: 6460.27498

Timestep Collection Time: 5.55827
Timestep Consumption Time: 2.18505
PPO Batch Consumption Time: 0.02961
Total Iteration Time: 7.74332

Cumulative Model Updates: 11436
Cumulative Timesteps: 95658985

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 95658985...
Checkpoint 95658985 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1556.13565
Policy Entropy: 1.28691
Value Function Loss: 0.76721

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06160
Policy Update Magnitude: 0.11625
Value Function Update Magnitude: 0.14915

Collected Steps per Second: 9274.11512
Overall Steps per Second: 6558.77412

Timestep Collection Time: 5.39135
Timestep Consumption Time: 2.23203
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.62338

Cumulative Model Updates: 11442
Cumulative Timesteps: 95708985

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1777.57058
Policy Entropy: 1.28479
Value Function Loss: 0.77142

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.10992
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 9616.71534
Overall Steps per Second: 6772.50554

Timestep Collection Time: 5.20053
Timestep Consumption Time: 2.18404
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.38456

Cumulative Model Updates: 11448
Cumulative Timesteps: 95758997

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 95758997...
Checkpoint 95758997 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1220.95655
Policy Entropy: 1.29042
Value Function Loss: 0.76432

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.09226
Value Function Update Magnitude: 0.16080

Collected Steps per Second: 9391.70119
Overall Steps per Second: 6717.45895

Timestep Collection Time: 5.32651
Timestep Consumption Time: 2.12050
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.44701

Cumulative Model Updates: 11454
Cumulative Timesteps: 95809022

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1272.86513
Policy Entropy: 1.28757
Value Function Loss: 0.74043

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.10163
Value Function Update Magnitude: 0.19470

Collected Steps per Second: 9631.15637
Overall Steps per Second: 6850.58796

Timestep Collection Time: 5.19574
Timestep Consumption Time: 2.10889
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.30463

Cumulative Model Updates: 11460
Cumulative Timesteps: 95859063

Timesteps Collected: 50041
--------END ITERATION REPORT--------


Saving checkpoint 95859063...
Checkpoint 95859063 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1918.54144
Policy Entropy: 1.28152
Value Function Loss: 0.74545

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.08344
Value Function Update Magnitude: 0.18051

Collected Steps per Second: 10088.62409
Overall Steps per Second: 7152.18226

Timestep Collection Time: 4.95806
Timestep Consumption Time: 2.03561
PPO Batch Consumption Time: 0.02394
Total Iteration Time: 6.99367

Cumulative Model Updates: 11466
Cumulative Timesteps: 95909083

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1315.29958
Policy Entropy: 1.27895
Value Function Loss: 0.75120

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.07896
Value Function Update Magnitude: 0.15887

Collected Steps per Second: 9335.93718
Overall Steps per Second: 6749.02499

Timestep Collection Time: 5.35833
Timestep Consumption Time: 2.05386
PPO Batch Consumption Time: 0.02449
Total Iteration Time: 7.41218

Cumulative Model Updates: 11472
Cumulative Timesteps: 95959108

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 95959108...
Checkpoint 95959108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1380.86592
Policy Entropy: 1.27511
Value Function Loss: 0.76328

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.08200
Value Function Update Magnitude: 0.17997

Collected Steps per Second: 9919.53308
Overall Steps per Second: 7062.97434

Timestep Collection Time: 5.04328
Timestep Consumption Time: 2.03971
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 7.08299

Cumulative Model Updates: 11478
Cumulative Timesteps: 96009135

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1841.18725
Policy Entropy: 1.28133
Value Function Loss: 0.75334

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.08497
Value Function Update Magnitude: 0.15520

Collected Steps per Second: 10246.56609
Overall Steps per Second: 7382.65002

Timestep Collection Time: 4.87988
Timestep Consumption Time: 1.89303
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 6.77291

Cumulative Model Updates: 11484
Cumulative Timesteps: 96059137

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 96059137...
Checkpoint 96059137 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1909.08734
Policy Entropy: 1.27088
Value Function Loss: 0.77587

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.09294
Value Function Update Magnitude: 0.14364

Collected Steps per Second: 10572.59309
Overall Steps per Second: 7352.59140

Timestep Collection Time: 4.73063
Timestep Consumption Time: 2.07174
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.80236

Cumulative Model Updates: 11490
Cumulative Timesteps: 96109152

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2065.69308
Policy Entropy: 1.27364
Value Function Loss: 0.78301

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.10328
Value Function Update Magnitude: 0.13295

Collected Steps per Second: 10023.10066
Overall Steps per Second: 7227.17312

Timestep Collection Time: 4.99207
Timestep Consumption Time: 1.93125
PPO Batch Consumption Time: 0.02451
Total Iteration Time: 6.92332

Cumulative Model Updates: 11496
Cumulative Timesteps: 96159188

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 96159188...
Checkpoint 96159188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1719.72459
Policy Entropy: 1.27377
Value Function Loss: 0.78590

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.07915
Policy Update Magnitude: 0.09972
Value Function Update Magnitude: 0.12473

Collected Steps per Second: 9667.24624
Overall Steps per Second: 6853.21039

Timestep Collection Time: 5.17210
Timestep Consumption Time: 2.12375
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.29585

Cumulative Model Updates: 11502
Cumulative Timesteps: 96209188

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1251.67500
Policy Entropy: 1.27725
Value Function Loss: 0.75149

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.11184
Value Function Update Magnitude: 0.15717

Collected Steps per Second: 9625.09501
Overall Steps per Second: 6771.00859

Timestep Collection Time: 5.19704
Timestep Consumption Time: 2.19063
PPO Batch Consumption Time: 0.02465
Total Iteration Time: 7.38767

Cumulative Model Updates: 11508
Cumulative Timesteps: 96259210

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 96259210...
Checkpoint 96259210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2063.78900
Policy Entropy: 1.27430
Value Function Loss: 0.74458

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.09974
Value Function Update Magnitude: 0.14828

Collected Steps per Second: 10978.20321
Overall Steps per Second: 7679.25297

Timestep Collection Time: 4.55749
Timestep Consumption Time: 1.95786
PPO Batch Consumption Time: 0.02453
Total Iteration Time: 6.51535

Cumulative Model Updates: 11514
Cumulative Timesteps: 96309243

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1361.63593
Policy Entropy: 1.27348
Value Function Loss: 0.73935

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.09342
Value Function Update Magnitude: 0.17329

Collected Steps per Second: 9310.61221
Overall Steps per Second: 6587.22153

Timestep Collection Time: 5.37365
Timestep Consumption Time: 2.22166
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.59531

Cumulative Model Updates: 11520
Cumulative Timesteps: 96359275

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 96359275...
Checkpoint 96359275 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2194.32073
Policy Entropy: 1.27318
Value Function Loss: 0.73223

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.09139
Value Function Update Magnitude: 0.18383

Collected Steps per Second: 9457.66078
Overall Steps per Second: 6909.04334

Timestep Collection Time: 5.29021
Timestep Consumption Time: 1.95146
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 7.24167

Cumulative Model Updates: 11526
Cumulative Timesteps: 96409308

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2671.36977
Policy Entropy: 1.27109
Value Function Loss: 0.75425

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.08943
Value Function Update Magnitude: 0.16116

Collected Steps per Second: 10354.13347
Overall Steps per Second: 7105.10504

Timestep Collection Time: 4.83169
Timestep Consumption Time: 2.20944
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 7.04113

Cumulative Model Updates: 11532
Cumulative Timesteps: 96459336

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 96459336...
Checkpoint 96459336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1918.12368
Policy Entropy: 1.26606
Value Function Loss: 0.75994

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.08983
Value Function Update Magnitude: 0.14572

Collected Steps per Second: 9264.45359
Overall Steps per Second: 6635.57636

Timestep Collection Time: 5.39730
Timestep Consumption Time: 2.13830
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.53559

Cumulative Model Updates: 11538
Cumulative Timesteps: 96509339

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1525.88670
Policy Entropy: 1.26778
Value Function Loss: 0.77058

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.09200
Value Function Update Magnitude: 0.13070

Collected Steps per Second: 10574.79736
Overall Steps per Second: 7233.60809

Timestep Collection Time: 4.73049
Timestep Consumption Time: 2.18501
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.91550

Cumulative Model Updates: 11544
Cumulative Timesteps: 96559363

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 96559363...
Checkpoint 96559363 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1922.21477
Policy Entropy: 1.26168
Value Function Loss: 0.77796

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.08759
Value Function Update Magnitude: 0.12334

Collected Steps per Second: 10114.34444
Overall Steps per Second: 7236.12612

Timestep Collection Time: 4.94446
Timestep Consumption Time: 1.96669
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 6.91116

Cumulative Model Updates: 11550
Cumulative Timesteps: 96609373

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1958.98654
Policy Entropy: 1.26478
Value Function Loss: 0.77419

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.09460
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 9492.99620
Overall Steps per Second: 6592.40176

Timestep Collection Time: 5.27125
Timestep Consumption Time: 2.31930
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.59056

Cumulative Model Updates: 11556
Cumulative Timesteps: 96659413

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 96659413...
Checkpoint 96659413 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2072.36382
Policy Entropy: 1.26375
Value Function Loss: 0.77595

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.10182
Value Function Update Magnitude: 0.13805

Collected Steps per Second: 10537.20353
Overall Steps per Second: 7320.99110

Timestep Collection Time: 4.74879
Timestep Consumption Time: 2.08621
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.83500

Cumulative Model Updates: 11562
Cumulative Timesteps: 96709452

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1456.20524
Policy Entropy: 1.26538
Value Function Loss: 0.77834

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.10058
Value Function Update Magnitude: 0.12843

Collected Steps per Second: 10001.48414
Overall Steps per Second: 7116.22339

Timestep Collection Time: 5.00326
Timestep Consumption Time: 2.02856
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.03182

Cumulative Model Updates: 11568
Cumulative Timesteps: 96759492

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 96759492...
Checkpoint 96759492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2450.18612
Policy Entropy: 1.25785
Value Function Loss: 0.76857

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.10083
Value Function Update Magnitude: 0.13654

Collected Steps per Second: 10062.64600
Overall Steps per Second: 7298.02704

Timestep Collection Time: 4.97165
Timestep Consumption Time: 1.88335
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.85500

Cumulative Model Updates: 11574
Cumulative Timesteps: 96809520

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1925.83099
Policy Entropy: 1.25491
Value Function Loss: 0.77439

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.10139
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 9978.50690
Overall Steps per Second: 7260.99302

Timestep Collection Time: 5.01187
Timestep Consumption Time: 1.87575
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 6.88763

Cumulative Model Updates: 11580
Cumulative Timesteps: 96859531

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 96859531...
Checkpoint 96859531 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2614.35432
Policy Entropy: 1.24913
Value Function Loss: 0.74348

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.08897
Value Function Update Magnitude: 0.11789

Collected Steps per Second: 10275.64213
Overall Steps per Second: 6983.76836

Timestep Collection Time: 4.86811
Timestep Consumption Time: 2.29464
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 7.16275

Cumulative Model Updates: 11586
Cumulative Timesteps: 96909554

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1532.21588
Policy Entropy: 1.25242
Value Function Loss: 0.75348

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.07534
Value Function Update Magnitude: 0.12018

Collected Steps per Second: 9733.83233
Overall Steps per Second: 6923.13693

Timestep Collection Time: 5.13950
Timestep Consumption Time: 2.08656
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.22606

Cumulative Model Updates: 11592
Cumulative Timesteps: 96959581

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 96959581...
Checkpoint 96959581 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2258.09099
Policy Entropy: 1.24699
Value Function Loss: 0.75165

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.07032
Value Function Update Magnitude: 0.13098

Collected Steps per Second: 10456.30034
Overall Steps per Second: 7295.78267

Timestep Collection Time: 4.78190
Timestep Consumption Time: 2.07151
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 6.85341

Cumulative Model Updates: 11598
Cumulative Timesteps: 97009582

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1273.34754
Policy Entropy: 1.24498
Value Function Loss: 0.78375

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.09286
Value Function Update Magnitude: 0.14238

Collected Steps per Second: 10086.84176
Overall Steps per Second: 7095.03945

Timestep Collection Time: 4.96042
Timestep Consumption Time: 2.09169
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.05211

Cumulative Model Updates: 11604
Cumulative Timesteps: 97059617

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 97059617...
Checkpoint 97059617 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2727.45360
Policy Entropy: 1.24410
Value Function Loss: 0.78658

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.10419
Value Function Update Magnitude: 0.16811

Collected Steps per Second: 9440.52917
Overall Steps per Second: 6840.84422

Timestep Collection Time: 5.30013
Timestep Consumption Time: 2.01418
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.31430

Cumulative Model Updates: 11610
Cumulative Timesteps: 97109653

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1924.05227
Policy Entropy: 1.23750
Value Function Loss: 0.80051

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.08671
Value Function Update Magnitude: 0.15940

Collected Steps per Second: 10016.05556
Overall Steps per Second: 6846.49274

Timestep Collection Time: 4.99588
Timestep Consumption Time: 2.31283
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.30871

Cumulative Model Updates: 11616
Cumulative Timesteps: 97159692

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 97159692...
Checkpoint 97159692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2144.23180
Policy Entropy: 1.24131
Value Function Loss: 0.81170

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.08621
Value Function Update Magnitude: 0.13496

Collected Steps per Second: 10063.80216
Overall Steps per Second: 7066.70634

Timestep Collection Time: 4.97277
Timestep Consumption Time: 2.10903
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.08180

Cumulative Model Updates: 11622
Cumulative Timesteps: 97209737

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2566.09136
Policy Entropy: 1.22960
Value Function Loss: 0.79794

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.10316
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 9668.38607
Overall Steps per Second: 6849.07828

Timestep Collection Time: 5.17522
Timestep Consumption Time: 2.13029
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.30551

Cumulative Model Updates: 11628
Cumulative Timesteps: 97259773

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 97259773...
Checkpoint 97259773 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2286.68946
Policy Entropy: 1.22792
Value Function Loss: 0.78568

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.09112
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 9530.18068
Overall Steps per Second: 6810.52638

Timestep Collection Time: 5.24660
Timestep Consumption Time: 2.09513
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.34172

Cumulative Model Updates: 11634
Cumulative Timesteps: 97309774

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2193.27862
Policy Entropy: 1.22030
Value Function Loss: 0.76484

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.08421
Value Function Update Magnitude: 0.13459

Collected Steps per Second: 9680.22706
Overall Steps per Second: 6969.40018

Timestep Collection Time: 5.16765
Timestep Consumption Time: 2.01001
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.17766

Cumulative Model Updates: 11640
Cumulative Timesteps: 97359798

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 97359798...
Checkpoint 97359798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2147.59413
Policy Entropy: 1.22465
Value Function Loss: 0.77704

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.07926
Value Function Update Magnitude: 0.15340

Collected Steps per Second: 10162.81308
Overall Steps per Second: 6896.66726

Timestep Collection Time: 4.92187
Timestep Consumption Time: 2.33091
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 7.25278

Cumulative Model Updates: 11646
Cumulative Timesteps: 97409818

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2500.72671
Policy Entropy: 1.22855
Value Function Loss: 0.77838

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.08764
Value Function Update Magnitude: 0.17193

Collected Steps per Second: 10451.93633
Overall Steps per Second: 7303.00395

Timestep Collection Time: 4.78409
Timestep Consumption Time: 2.06282
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 6.84691

Cumulative Model Updates: 11652
Cumulative Timesteps: 97459821

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 97459821...
Checkpoint 97459821 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1662.70212
Policy Entropy: 1.22979
Value Function Loss: 0.77818

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.09937
Value Function Update Magnitude: 0.16647

Collected Steps per Second: 10210.00076
Overall Steps per Second: 7117.17614

Timestep Collection Time: 4.89814
Timestep Consumption Time: 2.12852
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.02666

Cumulative Model Updates: 11658
Cumulative Timesteps: 97509831

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1845.46694
Policy Entropy: 1.22714
Value Function Loss: 0.77320

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.09740
Value Function Update Magnitude: 0.16413

Collected Steps per Second: 9974.70994
Overall Steps per Second: 7097.63893

Timestep Collection Time: 5.01268
Timestep Consumption Time: 2.03192
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.04460

Cumulative Model Updates: 11664
Cumulative Timesteps: 97559831

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 97559831...
Checkpoint 97559831 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3383.97853
Policy Entropy: 1.22616
Value Function Loss: 0.76213

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.10167
Value Function Update Magnitude: 0.16962

Collected Steps per Second: 9210.37692
Overall Steps per Second: 6765.68605

Timestep Collection Time: 5.43029
Timestep Consumption Time: 1.96216
PPO Batch Consumption Time: 0.02399
Total Iteration Time: 7.39245

Cumulative Model Updates: 11670
Cumulative Timesteps: 97609846

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1676.36886
Policy Entropy: 1.23078
Value Function Loss: 0.76930

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.09429
Value Function Update Magnitude: 0.18061

Collected Steps per Second: 10446.04784
Overall Steps per Second: 7361.26192

Timestep Collection Time: 4.78774
Timestep Consumption Time: 2.00634
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.79408

Cumulative Model Updates: 11676
Cumulative Timesteps: 97659859

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 97659859...
Checkpoint 97659859 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2242.16051
Policy Entropy: 1.23177
Value Function Loss: 0.78771

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.08749
Value Function Update Magnitude: 0.15012

Collected Steps per Second: 10224.84380
Overall Steps per Second: 7250.33728

Timestep Collection Time: 4.89250
Timestep Consumption Time: 2.00718
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 6.89968

Cumulative Model Updates: 11682
Cumulative Timesteps: 97709884

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2041.02518
Policy Entropy: 1.23552
Value Function Loss: 0.78921

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.09038
Value Function Update Magnitude: 0.13777

Collected Steps per Second: 10064.93974
Overall Steps per Second: 7222.95655

Timestep Collection Time: 4.96844
Timestep Consumption Time: 1.95491
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 6.92334

Cumulative Model Updates: 11688
Cumulative Timesteps: 97759891

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 97759891...
Checkpoint 97759891 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1727.64691
Policy Entropy: 1.23709
Value Function Loss: 0.78275

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.09223
Value Function Update Magnitude: 0.17386

Collected Steps per Second: 10096.51467
Overall Steps per Second: 7302.27205

Timestep Collection Time: 4.95557
Timestep Consumption Time: 1.89627
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 6.85184

Cumulative Model Updates: 11694
Cumulative Timesteps: 97809925

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2508.41984
Policy Entropy: 1.23911
Value Function Loss: 0.76409

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.09243
Value Function Update Magnitude: 0.19801

Collected Steps per Second: 10175.88629
Overall Steps per Second: 6861.86722

Timestep Collection Time: 4.91544
Timestep Consumption Time: 2.37397
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.28942

Cumulative Model Updates: 11700
Cumulative Timesteps: 97859944

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 97859944...
Checkpoint 97859944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3168.42648
Policy Entropy: 1.23150
Value Function Loss: 0.74748

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.10027
Value Function Update Magnitude: 0.17898

Collected Steps per Second: 9350.19644
Overall Steps per Second: 6626.88208

Timestep Collection Time: 5.35219
Timestep Consumption Time: 2.19948
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.55167

Cumulative Model Updates: 11706
Cumulative Timesteps: 97909988

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2795.21938
Policy Entropy: 1.23010
Value Function Loss: 0.73089

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.09900
Value Function Update Magnitude: 0.18763

Collected Steps per Second: 10459.33041
Overall Steps per Second: 7189.05967

Timestep Collection Time: 4.78319
Timestep Consumption Time: 2.17585
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 6.95905

Cumulative Model Updates: 11712
Cumulative Timesteps: 97960017

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 97960017...
Checkpoint 97960017 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1384.60247
Policy Entropy: 1.22811
Value Function Loss: 0.75287

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.08933
Value Function Update Magnitude: 0.18626

Collected Steps per Second: 9285.36867
Overall Steps per Second: 6688.17874

Timestep Collection Time: 5.38729
Timestep Consumption Time: 2.09202
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 7.47932

Cumulative Model Updates: 11718
Cumulative Timesteps: 98010040

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2816.02135
Policy Entropy: 1.23491
Value Function Loss: 0.79814

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.07996
Value Function Update Magnitude: 0.15211

Collected Steps per Second: 9343.49717
Overall Steps per Second: 6807.20078

Timestep Collection Time: 5.35538
Timestep Consumption Time: 1.99536
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.35075

Cumulative Model Updates: 11724
Cumulative Timesteps: 98060078

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 98060078...
Checkpoint 98060078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1864.48989
Policy Entropy: 1.23295
Value Function Loss: 0.81894

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.07863
Value Function Update Magnitude: 0.13088

Collected Steps per Second: 10146.16835
Overall Steps per Second: 7153.73766

Timestep Collection Time: 4.92836
Timestep Consumption Time: 2.06155
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 6.98991

Cumulative Model Updates: 11730
Cumulative Timesteps: 98110082

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3216.19812
Policy Entropy: 1.22460
Value Function Loss: 0.82294

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.09010
Value Function Update Magnitude: 0.13052

Collected Steps per Second: 9170.14639
Overall Steps per Second: 6599.76240

Timestep Collection Time: 5.45586
Timestep Consumption Time: 2.12487
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.58073

Cumulative Model Updates: 11736
Cumulative Timesteps: 98160113

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 98160113...
Checkpoint 98160113 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2148.09483
Policy Entropy: 1.22296
Value Function Loss: 0.80115

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.09309
Value Function Update Magnitude: 0.12242

Collected Steps per Second: 10484.59412
Overall Steps per Second: 7376.57553

Timestep Collection Time: 4.77081
Timestep Consumption Time: 2.01011
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 6.78092

Cumulative Model Updates: 11742
Cumulative Timesteps: 98210133

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2575.92775
Policy Entropy: 1.22163
Value Function Loss: 0.79977

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.09259
Value Function Update Magnitude: 0.11871

Collected Steps per Second: 9784.79025
Overall Steps per Second: 6857.37888

Timestep Collection Time: 5.11457
Timestep Consumption Time: 2.18341
PPO Batch Consumption Time: 0.03477
Total Iteration Time: 7.29798

Cumulative Model Updates: 11748
Cumulative Timesteps: 98260178

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 98260178...
Checkpoint 98260178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2857.87821
Policy Entropy: 1.22601
Value Function Loss: 0.82871

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.09811
Value Function Update Magnitude: 0.12670

Collected Steps per Second: 9687.48341
Overall Steps per Second: 6949.78110

Timestep Collection Time: 5.16471
Timestep Consumption Time: 2.03451
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.19922

Cumulative Model Updates: 11754
Cumulative Timesteps: 98310211

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2010.40457
Policy Entropy: 1.22789
Value Function Loss: 0.83051

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.10113
Value Function Update Magnitude: 0.17260

Collected Steps per Second: 10214.23968
Overall Steps per Second: 7203.22403

Timestep Collection Time: 4.89826
Timestep Consumption Time: 2.04752
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 6.94578

Cumulative Model Updates: 11760
Cumulative Timesteps: 98360243

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 98360243...
Checkpoint 98360243 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2100.67462
Policy Entropy: 1.22471
Value Function Loss: 0.85052

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.11011
Value Function Update Magnitude: 0.17168

Collected Steps per Second: 10326.56837
Overall Steps per Second: 7363.70755

Timestep Collection Time: 4.84401
Timestep Consumption Time: 1.94904
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 6.79305

Cumulative Model Updates: 11766
Cumulative Timesteps: 98410265

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2709.03387
Policy Entropy: 1.22024
Value Function Loss: 0.84580

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.09311
Value Function Update Magnitude: 0.13387

Collected Steps per Second: 10178.61737
Overall Steps per Second: 7354.82798

Timestep Collection Time: 4.91295
Timestep Consumption Time: 1.88626
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 6.79921

Cumulative Model Updates: 11772
Cumulative Timesteps: 98460272

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 98460272...
Checkpoint 98460272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2347.12225
Policy Entropy: 1.21767
Value Function Loss: 0.83503

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.08581
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 10026.09938
Overall Steps per Second: 7265.75936

Timestep Collection Time: 4.99107
Timestep Consumption Time: 1.89616
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.88724

Cumulative Model Updates: 11778
Cumulative Timesteps: 98510313

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2506.54881
Policy Entropy: 1.21322
Value Function Loss: 0.83409

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.08774
Value Function Update Magnitude: 0.11637

Collected Steps per Second: 10622.50237
Overall Steps per Second: 7361.33265

Timestep Collection Time: 4.70784
Timestep Consumption Time: 2.08563
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 6.79347

Cumulative Model Updates: 11784
Cumulative Timesteps: 98560322

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 98560322...
Checkpoint 98560322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2774.83851
Policy Entropy: 1.22329
Value Function Loss: 0.84865

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.16175
Policy Update Magnitude: 0.08359
Value Function Update Magnitude: 0.13677

Collected Steps per Second: 10391.10864
Overall Steps per Second: 7361.79818

Timestep Collection Time: 4.81219
Timestep Consumption Time: 1.98017
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 6.79236

Cumulative Model Updates: 11790
Cumulative Timesteps: 98610326

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2221.56956
Policy Entropy: 1.22537
Value Function Loss: 0.85371

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.07318
Value Function Update Magnitude: 0.12858

Collected Steps per Second: 10004.17247
Overall Steps per Second: 7212.89627

Timestep Collection Time: 4.99791
Timestep Consumption Time: 1.93411
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.93203

Cumulative Model Updates: 11796
Cumulative Timesteps: 98660326

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 98660326...
Checkpoint 98660326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2012.41515
Policy Entropy: 1.22542
Value Function Loss: 0.85116

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.08013
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 9796.61785
Overall Steps per Second: 7144.27421

Timestep Collection Time: 5.10533
Timestep Consumption Time: 1.89538
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.00071

Cumulative Model Updates: 11802
Cumulative Timesteps: 98710341

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2981.65316
Policy Entropy: 1.22907
Value Function Loss: 0.82085

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.08458
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 10235.78217
Overall Steps per Second: 7313.85612

Timestep Collection Time: 4.88629
Timestep Consumption Time: 1.95210
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 6.83839

Cumulative Model Updates: 11808
Cumulative Timesteps: 98760356

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 98760356...
Checkpoint 98760356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1744.46823
Policy Entropy: 1.22184
Value Function Loss: 0.83422

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.15251
Policy Update Magnitude: 0.08177
Value Function Update Magnitude: 0.12910

Collected Steps per Second: 9761.72939
Overall Steps per Second: 6904.16859

Timestep Collection Time: 5.12481
Timestep Consumption Time: 2.12110
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 7.24591

Cumulative Model Updates: 11814
Cumulative Timesteps: 98810383

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2866.96318
Policy Entropy: 1.23052
Value Function Loss: 0.81822

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.07520
Value Function Update Magnitude: 0.17194

Collected Steps per Second: 9513.79740
Overall Steps per Second: 6805.24031

Timestep Collection Time: 5.25742
Timestep Consumption Time: 2.09251
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.34992

Cumulative Model Updates: 11820
Cumulative Timesteps: 98860401

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 98860401...
Checkpoint 98860401 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2041.60087
Policy Entropy: 1.22050
Value Function Loss: 0.82846

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.08381
Value Function Update Magnitude: 0.16880

Collected Steps per Second: 9258.06534
Overall Steps per Second: 6703.27531

Timestep Collection Time: 5.40070
Timestep Consumption Time: 2.05834
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.45904

Cumulative Model Updates: 11826
Cumulative Timesteps: 98910401

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2393.41999
Policy Entropy: 1.21760
Value Function Loss: 0.81179

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.08012
Value Function Update Magnitude: 0.13891

Collected Steps per Second: 9690.40290
Overall Steps per Second: 6937.52801

Timestep Collection Time: 5.16274
Timestep Consumption Time: 2.04862
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.21136

Cumulative Model Updates: 11832
Cumulative Timesteps: 98960430

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 98960430...
Checkpoint 98960430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2093.86024
Policy Entropy: 1.21500
Value Function Loss: 0.81800

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.08238
Value Function Update Magnitude: 0.13799

Collected Steps per Second: 9263.92125
Overall Steps per Second: 6737.41306

Timestep Collection Time: 5.40182
Timestep Consumption Time: 2.02566
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.42748

Cumulative Model Updates: 11838
Cumulative Timesteps: 99010472

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4006.22118
Policy Entropy: 1.21244
Value Function Loss: 0.81320

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.10770
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 9473.04291
Overall Steps per Second: 6884.42122

Timestep Collection Time: 5.27898
Timestep Consumption Time: 1.98496
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 7.26394

Cumulative Model Updates: 11844
Cumulative Timesteps: 99060480

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 99060480...
Checkpoint 99060480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3053.11363
Policy Entropy: 1.21687
Value Function Loss: 0.81447

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.12770
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 10030.21227
Overall Steps per Second: 6848.92280

Timestep Collection Time: 4.98624
Timestep Consumption Time: 2.31608
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.30232

Cumulative Model Updates: 11850
Cumulative Timesteps: 99110493

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1829.95579
Policy Entropy: 1.21330
Value Function Loss: 0.81364

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.11525
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 9774.56895
Overall Steps per Second: 6862.83071

Timestep Collection Time: 5.11562
Timestep Consumption Time: 2.17044
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.28606

Cumulative Model Updates: 11856
Cumulative Timesteps: 99160496

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 99160496...
Checkpoint 99160496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1587.11708
Policy Entropy: 1.21346
Value Function Loss: 0.82178

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.09126
Value Function Update Magnitude: 0.12768

Collected Steps per Second: 9546.38998
Overall Steps per Second: 6843.04054

Timestep Collection Time: 5.23968
Timestep Consumption Time: 2.06994
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.30962

Cumulative Model Updates: 11862
Cumulative Timesteps: 99210516

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2694.91551
Policy Entropy: 1.21761
Value Function Loss: 0.81138

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.08107
Value Function Update Magnitude: 0.14075

Collected Steps per Second: 9293.37378
Overall Steps per Second: 6723.55998

Timestep Collection Time: 5.38093
Timestep Consumption Time: 2.05665
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.43758

Cumulative Model Updates: 11868
Cumulative Timesteps: 99260523

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 99260523...
Checkpoint 99260523 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3234.14079
Policy Entropy: 1.21619
Value Function Loss: 0.80775

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.08483
Value Function Update Magnitude: 0.13229

Collected Steps per Second: 9435.07765
Overall Steps per Second: 6855.72322

Timestep Collection Time: 5.30096
Timestep Consumption Time: 1.99440
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 7.29536

Cumulative Model Updates: 11874
Cumulative Timesteps: 99310538

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3121.27068
Policy Entropy: 1.21940
Value Function Loss: 0.82369

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.08181
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 10214.48926
Overall Steps per Second: 7262.36821

Timestep Collection Time: 4.89550
Timestep Consumption Time: 1.99000
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 6.88550

Cumulative Model Updates: 11880
Cumulative Timesteps: 99360543

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 99360543...
Checkpoint 99360543 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2263.29748
Policy Entropy: 1.21754
Value Function Loss: 0.85362

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.08164
Value Function Update Magnitude: 0.15226

Collected Steps per Second: 10436.99148
Overall Steps per Second: 7499.62480

Timestep Collection Time: 4.79314
Timestep Consumption Time: 1.87732
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 6.67047

Cumulative Model Updates: 11886
Cumulative Timesteps: 99410569

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3140.84156
Policy Entropy: 1.21181
Value Function Loss: 0.84831

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.09679
Value Function Update Magnitude: 0.13616

Collected Steps per Second: 10418.16505
Overall Steps per Second: 7089.25780

Timestep Collection Time: 4.80286
Timestep Consumption Time: 2.25528
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.05814

Cumulative Model Updates: 11892
Cumulative Timesteps: 99460606

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 99460606...
Checkpoint 99460606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2411.93461
Policy Entropy: 1.20821
Value Function Loss: 0.85374

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.10874
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 10017.93610
Overall Steps per Second: 7141.26991

Timestep Collection Time: 4.99514
Timestep Consumption Time: 2.01216
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 7.00730

Cumulative Model Updates: 11898
Cumulative Timesteps: 99510647

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3477.95237
Policy Entropy: 1.20410
Value Function Loss: 0.82718

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.09904
Value Function Update Magnitude: 0.10483

Collected Steps per Second: 9621.35500
Overall Steps per Second: 6856.10427

Timestep Collection Time: 5.20041
Timestep Consumption Time: 2.09747
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.29788

Cumulative Model Updates: 11904
Cumulative Timesteps: 99560682

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 99560682...
Checkpoint 99560682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2784.50688
Policy Entropy: 1.20523
Value Function Loss: 0.83851

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.08736
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 9709.13893
Overall Steps per Second: 6940.00892

Timestep Collection Time: 5.15288
Timestep Consumption Time: 2.05605
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 7.20892

Cumulative Model Updates: 11910
Cumulative Timesteps: 99610712

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3558.96023
Policy Entropy: 1.20440
Value Function Loss: 0.83396

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.08184
Value Function Update Magnitude: 0.12440

Collected Steps per Second: 9472.88102
Overall Steps per Second: 6828.86643

Timestep Collection Time: 5.27939
Timestep Consumption Time: 2.04408
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.32347

Cumulative Model Updates: 11916
Cumulative Timesteps: 99660723

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 99660723...
Checkpoint 99660723 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2755.75667
Policy Entropy: 1.20536
Value Function Loss: 0.84486

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.09453
Value Function Update Magnitude: 0.12161

Collected Steps per Second: 9879.27709
Overall Steps per Second: 7090.45925

Timestep Collection Time: 5.06312
Timestep Consumption Time: 1.99143
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.05455

Cumulative Model Updates: 11922
Cumulative Timesteps: 99710743

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1890.39578
Policy Entropy: 1.20043
Value Function Loss: 0.81740

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.09435
Value Function Update Magnitude: 0.14066

Collected Steps per Second: 9656.65269
Overall Steps per Second: 6923.86976

Timestep Collection Time: 5.17975
Timestep Consumption Time: 2.04439
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.22414

Cumulative Model Updates: 11928
Cumulative Timesteps: 99760762

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 99760762...
Checkpoint 99760762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2740.41402
Policy Entropy: 1.20419
Value Function Loss: 0.78878

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.08140
Value Function Update Magnitude: 0.13715

Collected Steps per Second: 10058.53997
Overall Steps per Second: 7096.48081

Timestep Collection Time: 4.97547
Timestep Consumption Time: 2.07675
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.05223

Cumulative Model Updates: 11934
Cumulative Timesteps: 99810808

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2517.52795
Policy Entropy: 1.19727
Value Function Loss: 0.76667

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.08145
Value Function Update Magnitude: 0.14477

Collected Steps per Second: 9356.82705
Overall Steps per Second: 6682.75934

Timestep Collection Time: 5.34455
Timestep Consumption Time: 2.13859
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 7.48314

Cumulative Model Updates: 11940
Cumulative Timesteps: 99860816

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 99860816...
Checkpoint 99860816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2957.08311
Policy Entropy: 1.20422
Value Function Loss: 0.75044

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.08243
Value Function Update Magnitude: 0.15646

Collected Steps per Second: 9768.82337
Overall Steps per Second: 7022.53320

Timestep Collection Time: 5.12303
Timestep Consumption Time: 2.00346
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.12649

Cumulative Model Updates: 11946
Cumulative Timesteps: 99910862

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3858.02399
Policy Entropy: 1.19314
Value Function Loss: 0.75758

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.08272
Value Function Update Magnitude: 0.14762

Collected Steps per Second: 9124.89571
Overall Steps per Second: 6546.03140

Timestep Collection Time: 5.48357
Timestep Consumption Time: 2.16030
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.64387

Cumulative Model Updates: 11952
Cumulative Timesteps: 99960899

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 99960899...
Checkpoint 99960899 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3936.11161
Policy Entropy: 1.19992
Value Function Loss: 0.78113

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.08691
Value Function Update Magnitude: 0.11514

Collected Steps per Second: 9492.33402
Overall Steps per Second: 6857.80170

Timestep Collection Time: 5.27162
Timestep Consumption Time: 2.02518
PPO Batch Consumption Time: 0.02447
Total Iteration Time: 7.29680

Cumulative Model Updates: 11958
Cumulative Timesteps: 100010939

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2293.45272
Policy Entropy: 1.19288
Value Function Loss: 0.80437

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.08914
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 10935.78359
Overall Steps per Second: 7487.68233

Timestep Collection Time: 4.57260
Timestep Consumption Time: 2.10570
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 6.67830

Cumulative Model Updates: 11964
Cumulative Timesteps: 100060944

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 100060944...
Checkpoint 100060944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3163.49735
Policy Entropy: 1.20010
Value Function Loss: 0.80562

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.08512
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 10450.86019
Overall Steps per Second: 7390.91836

Timestep Collection Time: 4.78430
Timestep Consumption Time: 1.98076
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 6.76506

Cumulative Model Updates: 11970
Cumulative Timesteps: 100110944

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3243.26972
Policy Entropy: 1.20065
Value Function Loss: 0.80797

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.09303
Value Function Update Magnitude: 0.13986

Collected Steps per Second: 10087.22243
Overall Steps per Second: 7258.15275

Timestep Collection Time: 4.95895
Timestep Consumption Time: 1.93289
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 6.89184

Cumulative Model Updates: 11976
Cumulative Timesteps: 100160966

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 100160966...
Checkpoint 100160966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3817.66720
Policy Entropy: 1.20525
Value Function Loss: 0.78407

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.09267
Value Function Update Magnitude: 0.16498

Collected Steps per Second: 10171.24526
Overall Steps per Second: 7378.89797

Timestep Collection Time: 4.91877
Timestep Consumption Time: 1.86138
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.78015

Cumulative Model Updates: 11982
Cumulative Timesteps: 100210996

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3346.50447
Policy Entropy: 1.20984
Value Function Loss: 0.79414

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.08332
Value Function Update Magnitude: 0.15280

Collected Steps per Second: 10051.00259
Overall Steps per Second: 7251.05080

Timestep Collection Time: 4.97612
Timestep Consumption Time: 1.92150
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.89762

Cumulative Model Updates: 11988
Cumulative Timesteps: 100261011

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 100261011...
Checkpoint 100261011 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2982.40333
Policy Entropy: 1.21237
Value Function Loss: 0.81382

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.08267
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 11125.74849
Overall Steps per Second: 7594.79262

Timestep Collection Time: 4.49606
Timestep Consumption Time: 2.09030
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 6.58635

Cumulative Model Updates: 11994
Cumulative Timesteps: 100311033

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4188.99638
Policy Entropy: 1.21174
Value Function Loss: 0.83333

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.08607
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 10689.63912
Overall Steps per Second: 7423.27040

Timestep Collection Time: 4.67752
Timestep Consumption Time: 2.05819
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 6.73571

Cumulative Model Updates: 12000
Cumulative Timesteps: 100361034

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 100361034...
Checkpoint 100361034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3181.41457
Policy Entropy: 1.20751
Value Function Loss: 0.81459

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.09263
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 10017.66187
Overall Steps per Second: 7111.43020

Timestep Collection Time: 4.99248
Timestep Consumption Time: 2.04028
PPO Batch Consumption Time: 0.02399
Total Iteration Time: 7.03276

Cumulative Model Updates: 12006
Cumulative Timesteps: 100411047

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2654.39812
Policy Entropy: 1.20595
Value Function Loss: 0.81826

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.10081
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 9491.49526
Overall Steps per Second: 6905.20986

Timestep Collection Time: 5.26872
Timestep Consumption Time: 1.97335
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.24207

Cumulative Model Updates: 12012
Cumulative Timesteps: 100461055

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 100461055...
Checkpoint 100461055 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2512.35777
Policy Entropy: 1.20121
Value Function Loss: 0.80666

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.10188
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 9286.82482
Overall Steps per Second: 6684.08958

Timestep Collection Time: 5.38623
Timestep Consumption Time: 2.09736
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.48359

Cumulative Model Updates: 12018
Cumulative Timesteps: 100511076

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4069.19358
Policy Entropy: 1.20385
Value Function Loss: 0.81003

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.09119
Value Function Update Magnitude: 0.13267

Collected Steps per Second: 9438.71474
Overall Steps per Second: 6818.27166

Timestep Collection Time: 5.29977
Timestep Consumption Time: 2.03684
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.33661

Cumulative Model Updates: 12024
Cumulative Timesteps: 100561099

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 100561099...
Checkpoint 100561099 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2428.73342
Policy Entropy: 1.20438
Value Function Loss: 0.76135

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.07761
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 9421.63778
Overall Steps per Second: 6740.14762

Timestep Collection Time: 5.30704
Timestep Consumption Time: 2.11134
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.41838

Cumulative Model Updates: 12030
Cumulative Timesteps: 100611100

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4059.06827
Policy Entropy: 1.20097
Value Function Loss: 0.78252

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.08346
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 9483.11602
Overall Steps per Second: 6815.29655

Timestep Collection Time: 5.27379
Timestep Consumption Time: 2.06440
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.33820

Cumulative Model Updates: 12036
Cumulative Timesteps: 100661112

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 100661112...
Checkpoint 100661112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3198.82328
Policy Entropy: 1.20411
Value Function Loss: 0.79759

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.08854
Value Function Update Magnitude: 0.10422

Collected Steps per Second: 9775.89006
Overall Steps per Second: 6839.85530

Timestep Collection Time: 5.11595
Timestep Consumption Time: 2.19604
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.31200

Cumulative Model Updates: 12042
Cumulative Timesteps: 100711125

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2556.28488
Policy Entropy: 1.20315
Value Function Loss: 0.82072

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.10203
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 9768.41426
Overall Steps per Second: 6988.62358

Timestep Collection Time: 5.12253
Timestep Consumption Time: 2.03753
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.16007

Cumulative Model Updates: 12048
Cumulative Timesteps: 100761164

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 100761164...
Checkpoint 100761164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4289.94114
Policy Entropy: 1.19824
Value Function Loss: 0.80661

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.09578
Value Function Update Magnitude: 0.11543

Collected Steps per Second: 10017.26512
Overall Steps per Second: 7081.75315

Timestep Collection Time: 4.99168
Timestep Consumption Time: 2.06914
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.06082

Cumulative Model Updates: 12054
Cumulative Timesteps: 100811167

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3003.59446
Policy Entropy: 1.20484
Value Function Loss: 0.80358

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.08457
Value Function Update Magnitude: 0.11028

Collected Steps per Second: 9763.56845
Overall Steps per Second: 7006.53622

Timestep Collection Time: 5.12395
Timestep Consumption Time: 2.01624
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.14019

Cumulative Model Updates: 12060
Cumulative Timesteps: 100861195

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 100861195...
Checkpoint 100861195 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1894.86188
Policy Entropy: 1.20158
Value Function Loss: 0.82049

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.08066
Value Function Update Magnitude: 0.11018

Collected Steps per Second: 9552.98749
Overall Steps per Second: 6778.02952

Timestep Collection Time: 5.23533
Timestep Consumption Time: 2.14337
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 7.37869

Cumulative Model Updates: 12066
Cumulative Timesteps: 100911208

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4333.07491
Policy Entropy: 1.20259
Value Function Loss: 0.80512

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.09702
Value Function Update Magnitude: 0.12533

Collected Steps per Second: 9240.80986
Overall Steps per Second: 6706.50867

Timestep Collection Time: 5.41338
Timestep Consumption Time: 2.04564
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.45902

Cumulative Model Updates: 12072
Cumulative Timesteps: 100961232

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 100961232...
Checkpoint 100961232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3032.68716
Policy Entropy: 1.20369
Value Function Loss: 0.81309

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.10135
Value Function Update Magnitude: 0.11620

Collected Steps per Second: 9679.89944
Overall Steps per Second: 7076.98416

Timestep Collection Time: 5.16627
Timestep Consumption Time: 1.90016
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.06643

Cumulative Model Updates: 12078
Cumulative Timesteps: 101011241

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4216.99690
Policy Entropy: 1.20554
Value Function Loss: 0.78327

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.10745
Value Function Update Magnitude: 0.11174

Collected Steps per Second: 9946.39763
Overall Steps per Second: 7167.12702

Timestep Collection Time: 5.02996
Timestep Consumption Time: 1.95052
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 6.98048

Cumulative Model Updates: 12084
Cumulative Timesteps: 101061271

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 101061271...
Checkpoint 101061271 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3206.28502
Policy Entropy: 1.20614
Value Function Loss: 0.80571

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.11262
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 10668.81531
Overall Steps per Second: 7525.88924

Timestep Collection Time: 4.68787
Timestep Consumption Time: 1.95773
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.64559

Cumulative Model Updates: 12090
Cumulative Timesteps: 101111285

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3926.49646
Policy Entropy: 1.19914
Value Function Loss: 0.79171

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.09823
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 10183.16918
Overall Steps per Second: 7317.95658

Timestep Collection Time: 4.91075
Timestep Consumption Time: 1.92271
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 6.83346

Cumulative Model Updates: 12096
Cumulative Timesteps: 101161292

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 101161292...
Checkpoint 101161292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5038.61759
Policy Entropy: 1.20011
Value Function Loss: 0.79527

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.09013
Value Function Update Magnitude: 0.11343

Collected Steps per Second: 10492.45059
Overall Steps per Second: 7426.72347

Timestep Collection Time: 4.76724
Timestep Consumption Time: 1.96790
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 6.73514

Cumulative Model Updates: 12102
Cumulative Timesteps: 101211312

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4417.98350
Policy Entropy: 1.19895
Value Function Loss: 0.77016

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.09711
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10080.04162
Overall Steps per Second: 7192.30861

Timestep Collection Time: 4.96099
Timestep Consumption Time: 1.99185
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 6.95284

Cumulative Model Updates: 12108
Cumulative Timesteps: 101261319

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 101261319...
Checkpoint 101261319 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2958.08412
Policy Entropy: 1.20462
Value Function Loss: 0.76946

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.10682
Value Function Update Magnitude: 0.11437

Collected Steps per Second: 9869.66356
Overall Steps per Second: 7101.40810

Timestep Collection Time: 5.06927
Timestep Consumption Time: 1.97609
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.04536

Cumulative Model Updates: 12114
Cumulative Timesteps: 101311351

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2507.15967
Policy Entropy: 1.20830
Value Function Loss: 0.77858

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.10940
Value Function Update Magnitude: 0.11863

Collected Steps per Second: 9961.01703
Overall Steps per Second: 7214.16396

Timestep Collection Time: 5.02228
Timestep Consumption Time: 1.91227
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.93455

Cumulative Model Updates: 12120
Cumulative Timesteps: 101361378

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 101361378...
Checkpoint 101361378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4948.22874
Policy Entropy: 1.20963
Value Function Loss: 0.80943

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.09333
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 10098.68906
Overall Steps per Second: 7247.22180

Timestep Collection Time: 4.95401
Timestep Consumption Time: 1.94919
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 6.90320

Cumulative Model Updates: 12126
Cumulative Timesteps: 101411407

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3639.25236
Policy Entropy: 1.21559
Value Function Loss: 0.80091

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.08908
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 9510.31773
Overall Steps per Second: 6868.37953

Timestep Collection Time: 5.25850
Timestep Consumption Time: 2.02269
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.28119

Cumulative Model Updates: 12132
Cumulative Timesteps: 101461417

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 101461417...
Checkpoint 101461417 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3832.26090
Policy Entropy: 1.22058
Value Function Loss: 0.80953

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.08790
Value Function Update Magnitude: 0.11526

Collected Steps per Second: 9888.08689
Overall Steps per Second: 7004.69386

Timestep Collection Time: 5.05801
Timestep Consumption Time: 2.08206
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.14007

Cumulative Model Updates: 12138
Cumulative Timesteps: 101511431

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3175.37988
Policy Entropy: 1.21873
Value Function Loss: 0.78313

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.07856
Value Function Update Magnitude: 0.12487

Collected Steps per Second: 9357.28812
Overall Steps per Second: 6739.36870

Timestep Collection Time: 5.34407
Timestep Consumption Time: 2.07591
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 7.41998

Cumulative Model Updates: 12144
Cumulative Timesteps: 101561437

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 101561437...
Checkpoint 101561437 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3319.89733
Policy Entropy: 1.21671
Value Function Loss: 0.79186

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.07519
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 9603.95319
Overall Steps per Second: 6919.50409

Timestep Collection Time: 5.20952
Timestep Consumption Time: 2.02105
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 7.23058

Cumulative Model Updates: 12150
Cumulative Timesteps: 101611469

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5620.73229
Policy Entropy: 1.21529
Value Function Loss: 0.78823

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.08206
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 9594.35826
Overall Steps per Second: 6820.47072

Timestep Collection Time: 5.21390
Timestep Consumption Time: 2.12049
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.33439

Cumulative Model Updates: 12156
Cumulative Timesteps: 101661493

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 101661493...
Checkpoint 101661493 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3016.10827
Policy Entropy: 1.22230
Value Function Loss: 0.82086

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.08193
Value Function Update Magnitude: 0.11196

Collected Steps per Second: 9502.00550
Overall Steps per Second: 6918.85883

Timestep Collection Time: 5.26689
Timestep Consumption Time: 1.96639
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 7.23327

Cumulative Model Updates: 12162
Cumulative Timesteps: 101711539

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3765.57492
Policy Entropy: 1.22126
Value Function Loss: 0.80429

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.08045
Value Function Update Magnitude: 0.11298

Collected Steps per Second: 9235.98760
Overall Steps per Second: 6727.71250

Timestep Collection Time: 5.41436
Timestep Consumption Time: 2.01862
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.43299

Cumulative Model Updates: 12168
Cumulative Timesteps: 101761546

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 101761546...
Checkpoint 101761546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2759.64227
Policy Entropy: 1.23114
Value Function Loss: 0.82229

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.08266
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 9344.97547
Overall Steps per Second: 6819.71964

Timestep Collection Time: 5.35090
Timestep Consumption Time: 1.98137
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.33227

Cumulative Model Updates: 12174
Cumulative Timesteps: 101811550

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4496.47474
Policy Entropy: 1.21789
Value Function Loss: 0.79982

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.08234
Value Function Update Magnitude: 0.11486

Collected Steps per Second: 9626.30375
Overall Steps per Second: 6837.45769

Timestep Collection Time: 5.19504
Timestep Consumption Time: 2.11894
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 7.31398

Cumulative Model Updates: 12180
Cumulative Timesteps: 101861559

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 101861559...
Checkpoint 101861559 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3831.26645
Policy Entropy: 1.21867
Value Function Loss: 0.83035

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.07683
Value Function Update Magnitude: 0.11121

Collected Steps per Second: 9494.88361
Overall Steps per Second: 6774.96887

Timestep Collection Time: 5.26989
Timestep Consumption Time: 2.11568
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 7.38557

Cumulative Model Updates: 12186
Cumulative Timesteps: 101911596

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4167.58269
Policy Entropy: 1.20977
Value Function Loss: 0.81920

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.07156
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 9533.13870
Overall Steps per Second: 6819.51082

Timestep Collection Time: 5.24665
Timestep Consumption Time: 2.08775
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.33440

Cumulative Model Updates: 12192
Cumulative Timesteps: 101961613

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 101961613...
Checkpoint 101961613 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4943.97744
Policy Entropy: 1.20977
Value Function Loss: 0.81984

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.07733
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 10177.19476
Overall Steps per Second: 7257.69163

Timestep Collection Time: 4.91491
Timestep Consumption Time: 1.97709
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 6.89200

Cumulative Model Updates: 12198
Cumulative Timesteps: 102011633

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3951.26789
Policy Entropy: 1.21448
Value Function Loss: 0.80692

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.08273
Value Function Update Magnitude: 0.12347

Collected Steps per Second: 10002.94247
Overall Steps per Second: 7261.68795

Timestep Collection Time: 5.00123
Timestep Consumption Time: 1.88794
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.88917

Cumulative Model Updates: 12204
Cumulative Timesteps: 102061660

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 102061660...
Checkpoint 102061660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2929.05016
Policy Entropy: 1.20703
Value Function Loss: 0.79938

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.08813
Value Function Update Magnitude: 0.13724

Collected Steps per Second: 10005.42441
Overall Steps per Second: 7248.42646

Timestep Collection Time: 5.00199
Timestep Consumption Time: 1.90255
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.90453

Cumulative Model Updates: 12210
Cumulative Timesteps: 102111707

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2996.02505
Policy Entropy: 1.21162
Value Function Loss: 0.82848

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.10682
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 9819.58588
Overall Steps per Second: 6944.46242

Timestep Collection Time: 5.09197
Timestep Consumption Time: 2.10816
PPO Batch Consumption Time: 0.02447
Total Iteration Time: 7.20013

Cumulative Model Updates: 12216
Cumulative Timesteps: 102161708

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 102161708...
Checkpoint 102161708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3769.28763
Policy Entropy: 1.20181
Value Function Loss: 0.82766

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.08789
Value Function Update Magnitude: 0.12303

Collected Steps per Second: 9528.01054
Overall Steps per Second: 6867.00522

Timestep Collection Time: 5.24968
Timestep Consumption Time: 2.03428
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.28396

Cumulative Model Updates: 12222
Cumulative Timesteps: 102211727

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2843.13967
Policy Entropy: 1.20015
Value Function Loss: 0.82060

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.08463
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 9616.28790
Overall Steps per Second: 6957.92768

Timestep Collection Time: 5.20242
Timestep Consumption Time: 1.98765
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 7.19007

Cumulative Model Updates: 12228
Cumulative Timesteps: 102261755

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 102261755...
Checkpoint 102261755 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2893.21929
Policy Entropy: 1.19523
Value Function Loss: 0.80566

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.09205
Value Function Update Magnitude: 0.15734

Collected Steps per Second: 9364.69536
Overall Steps per Second: 6734.71986

Timestep Collection Time: 5.34134
Timestep Consumption Time: 2.08585
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.42718

Cumulative Model Updates: 12234
Cumulative Timesteps: 102311775

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3046.16427
Policy Entropy: 1.18911
Value Function Loss: 0.79808

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.08961
Value Function Update Magnitude: 0.19211

Collected Steps per Second: 9549.50179
Overall Steps per Second: 6909.13185

Timestep Collection Time: 5.24027
Timestep Consumption Time: 2.00260
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.24288

Cumulative Model Updates: 12240
Cumulative Timesteps: 102361817

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 102361817...
Checkpoint 102361817 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3400.94694
Policy Entropy: 1.20403
Value Function Loss: 0.82722

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.08310
Value Function Update Magnitude: 0.18599

Collected Steps per Second: 9527.24747
Overall Steps per Second: 6849.47443

Timestep Collection Time: 5.25199
Timestep Consumption Time: 2.05324
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 7.30523

Cumulative Model Updates: 12246
Cumulative Timesteps: 102411854

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3006.66910
Policy Entropy: 1.18845
Value Function Loss: 0.82588

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.17009
Policy Update Magnitude: 0.07487
Value Function Update Magnitude: 0.18159

Collected Steps per Second: 9167.05874
Overall Steps per Second: 6629.23381

Timestep Collection Time: 5.45551
Timestep Consumption Time: 2.08850
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.54401

Cumulative Model Updates: 12252
Cumulative Timesteps: 102461865

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 102461865...
Checkpoint 102461865 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3933.77651
Policy Entropy: 1.19876
Value Function Loss: 0.83759

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.07442
Value Function Update Magnitude: 0.15680

Collected Steps per Second: 10083.12237
Overall Steps per Second: 6962.22671

Timestep Collection Time: 4.96116
Timestep Consumption Time: 2.22390
PPO Batch Consumption Time: 0.02451
Total Iteration Time: 7.18506

Cumulative Model Updates: 12258
Cumulative Timesteps: 102511889

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4132.75747
Policy Entropy: 1.18567
Value Function Loss: 0.83316

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.07621
Value Function Update Magnitude: 0.14728

Collected Steps per Second: 10185.44462
Overall Steps per Second: 7113.17919

Timestep Collection Time: 4.91221
Timestep Consumption Time: 2.12164
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.03385

Cumulative Model Updates: 12264
Cumulative Timesteps: 102561922

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 102561922...
Checkpoint 102561922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4128.00971
Policy Entropy: 1.18069
Value Function Loss: 0.84220

Mean KL Divergence: 0.02194
SB3 Clip Fraction: 0.16677
Policy Update Magnitude: 0.07595
Value Function Update Magnitude: 0.13972

Collected Steps per Second: 9725.60983
Overall Steps per Second: 6919.11448

Timestep Collection Time: 5.14394
Timestep Consumption Time: 2.08646
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.23041

Cumulative Model Updates: 12270
Cumulative Timesteps: 102611950

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4020.30292
Policy Entropy: 1.17884
Value Function Loss: 0.82950

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.07382
Value Function Update Magnitude: 0.12302

Collected Steps per Second: 9302.64539
Overall Steps per Second: 6689.95422

Timestep Collection Time: 5.37729
Timestep Consumption Time: 2.10004
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 7.47733

Cumulative Model Updates: 12276
Cumulative Timesteps: 102661973

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 102661973...
Checkpoint 102661973 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3669.38891
Policy Entropy: 1.17756
Value Function Loss: 0.82449

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.07848
Value Function Update Magnitude: 0.11399

Collected Steps per Second: 9708.52434
Overall Steps per Second: 7034.63514

Timestep Collection Time: 5.15228
Timestep Consumption Time: 1.95840
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.11067

Cumulative Model Updates: 12282
Cumulative Timesteps: 102711994

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4241.36543
Policy Entropy: 1.17356
Value Function Loss: 0.81387

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.08334
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 9638.91238
Overall Steps per Second: 6938.54560

Timestep Collection Time: 5.18928
Timestep Consumption Time: 2.01958
PPO Batch Consumption Time: 0.02460
Total Iteration Time: 7.20886

Cumulative Model Updates: 12288
Cumulative Timesteps: 102762013

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 102762013...
Checkpoint 102762013 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3745.51195
Policy Entropy: 1.16425
Value Function Loss: 0.80965

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.09910
Value Function Update Magnitude: 0.08508

Collected Steps per Second: 9516.78955
Overall Steps per Second: 6944.82995

Timestep Collection Time: 5.25566
Timestep Consumption Time: 1.94639
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.20205

Cumulative Model Updates: 12294
Cumulative Timesteps: 102812030

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5848.43083
Policy Entropy: 1.16245
Value Function Loss: 0.80480

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.14870
Policy Update Magnitude: 0.09805
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 9910.55236
Overall Steps per Second: 7219.74566

Timestep Collection Time: 5.04836
Timestep Consumption Time: 1.88153
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 6.92988

Cumulative Model Updates: 12300
Cumulative Timesteps: 102862062

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 102862062...
Checkpoint 102862062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6262.03376
Policy Entropy: 1.15307
Value Function Loss: 0.78232

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.19775
Policy Update Magnitude: 0.08932
Value Function Update Magnitude: 0.08173

Collected Steps per Second: 9633.01398
Overall Steps per Second: 6839.78556

Timestep Collection Time: 5.19173
Timestep Consumption Time: 2.12020
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.31193

Cumulative Model Updates: 12306
Cumulative Timesteps: 102912074

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4513.67369
Policy Entropy: 1.14552
Value Function Loss: 0.79364

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.17502
Policy Update Magnitude: 0.09210
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 9915.74230
Overall Steps per Second: 6860.02807

Timestep Collection Time: 5.04642
Timestep Consumption Time: 2.24787
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 7.29429

Cumulative Model Updates: 12312
Cumulative Timesteps: 102962113

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 102962113...
Checkpoint 102962113 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6367.54172
Policy Entropy: 1.14333
Value Function Loss: 0.79948

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.09574
Value Function Update Magnitude: 0.06935

Collected Steps per Second: 10442.52658
Overall Steps per Second: 7373.50286

Timestep Collection Time: 4.79079
Timestep Consumption Time: 1.99404
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 6.78483

Cumulative Model Updates: 12318
Cumulative Timesteps: 103012141

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3265.00499
Policy Entropy: 1.12735
Value Function Loss: 0.78183

Mean KL Divergence: 0.02413
SB3 Clip Fraction: 0.21791
Policy Update Magnitude: 0.08951
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 10148.72307
Overall Steps per Second: 7276.79868

Timestep Collection Time: 4.93028
Timestep Consumption Time: 1.94583
PPO Batch Consumption Time: 0.02389
Total Iteration Time: 6.87610

Cumulative Model Updates: 12324
Cumulative Timesteps: 103062177

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 103062177...
Checkpoint 103062177 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7187.59235
Policy Entropy: 1.12579
Value Function Loss: 0.76108

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.09641
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 9261.34514
Overall Steps per Second: 6650.75088

Timestep Collection Time: 5.40343
Timestep Consumption Time: 2.12099
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.52441

Cumulative Model Updates: 12330
Cumulative Timesteps: 103112220

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5413.09917
Policy Entropy: 1.11851
Value Function Loss: 0.75835

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.21478
Policy Update Magnitude: 0.08356
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 9635.17507
Overall Steps per Second: 7034.59095

Timestep Collection Time: 5.19077
Timestep Consumption Time: 1.91895
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.10972

Cumulative Model Updates: 12336
Cumulative Timesteps: 103162234

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 103162234...
Checkpoint 103162234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6100.78313
Policy Entropy: 1.11066
Value Function Loss: 0.76655

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.18433
Policy Update Magnitude: 0.08208
Value Function Update Magnitude: 0.07028

Collected Steps per Second: 9397.74796
Overall Steps per Second: 6798.86343

Timestep Collection Time: 5.32521
Timestep Consumption Time: 2.03558
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.36079

Cumulative Model Updates: 12342
Cumulative Timesteps: 103212279

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7623.38861
Policy Entropy: 1.09697
Value Function Loss: 0.76218

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.20155
Policy Update Magnitude: 0.09996
Value Function Update Magnitude: 0.06903

Collected Steps per Second: 9172.75841
Overall Steps per Second: 6671.36825

Timestep Collection Time: 5.45278
Timestep Consumption Time: 2.04449
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 7.49726

Cumulative Model Updates: 12348
Cumulative Timesteps: 103262296

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 103262296...
Checkpoint 103262296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4521.99875
Policy Entropy: 1.08998
Value Function Loss: 0.75454

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.19747
Policy Update Magnitude: 0.09944
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 10043.57170
Overall Steps per Second: 7165.13501

Timestep Collection Time: 4.97831
Timestep Consumption Time: 1.99993
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 6.97824

Cumulative Model Updates: 12354
Cumulative Timesteps: 103312296

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5860.36091
Policy Entropy: 1.07778
Value Function Loss: 0.74935

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.21170
Policy Update Magnitude: 0.08888
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 9668.27867
Overall Steps per Second: 6914.32828

Timestep Collection Time: 5.17569
Timestep Consumption Time: 2.06146
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 7.23715

Cumulative Model Updates: 12360
Cumulative Timesteps: 103362336

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 103362336...
Checkpoint 103362336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5879.25020
Policy Entropy: 1.06287
Value Function Loss: 0.75096

Mean KL Divergence: 0.03618
SB3 Clip Fraction: 0.27149
Policy Update Magnitude: 0.09446
Value Function Update Magnitude: 0.07098

Collected Steps per Second: 9451.96626
Overall Steps per Second: 6737.74386

Timestep Collection Time: 5.29371
Timestep Consumption Time: 2.13251
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.42622

Cumulative Model Updates: 12366
Cumulative Timesteps: 103412372

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7181.03982
Policy Entropy: 1.05083
Value Function Loss: 0.75773

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.19453
Policy Update Magnitude: 0.08726
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 9936.42106
Overall Steps per Second: 7119.13921

Timestep Collection Time: 5.03209
Timestep Consumption Time: 1.99137
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.02346

Cumulative Model Updates: 12372
Cumulative Timesteps: 103462373

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 103462373...
Checkpoint 103462373 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6941.57329
Policy Entropy: 1.03815
Value Function Loss: 0.76402

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.24646
Policy Update Magnitude: 0.08452
Value Function Update Magnitude: 0.07163

Collected Steps per Second: 9133.11184
Overall Steps per Second: 6607.22893

Timestep Collection Time: 5.47721
Timestep Consumption Time: 2.09389
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.57110

Cumulative Model Updates: 12378
Cumulative Timesteps: 103512397

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6029.86181
Policy Entropy: 1.03192
Value Function Loss: 0.76980

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.22790
Policy Update Magnitude: 0.07198
Value Function Update Magnitude: 0.06978

Collected Steps per Second: 9728.55067
Overall Steps per Second: 6975.98124

Timestep Collection Time: 5.14003
Timestep Consumption Time: 2.02814
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.16817

Cumulative Model Updates: 12384
Cumulative Timesteps: 103562402

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 103562402...
Checkpoint 103562402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6106.41828
Policy Entropy: 1.01417
Value Function Loss: 0.75769

Mean KL Divergence: 0.02715
SB3 Clip Fraction: 0.26477
Policy Update Magnitude: 0.08057
Value Function Update Magnitude: 0.07223

Collected Steps per Second: 9865.58412
Overall Steps per Second: 6856.39934

Timestep Collection Time: 5.06893
Timestep Consumption Time: 2.22469
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.29362

Cumulative Model Updates: 12390
Cumulative Timesteps: 103612410

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10952.16918
Policy Entropy: 1.01411
Value Function Loss: 0.75120

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.24230
Policy Update Magnitude: 0.07334
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 10369.06050
Overall Steps per Second: 7309.15087

Timestep Collection Time: 4.82638
Timestep Consumption Time: 2.02052
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.84690

Cumulative Model Updates: 12396
Cumulative Timesteps: 103662455

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 103662455...
Checkpoint 103662455 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8503.76897
Policy Entropy: 1.00340
Value Function Loss: 0.73374

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.25784
Policy Update Magnitude: 0.07493
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 9704.80413
Overall Steps per Second: 7020.49510

Timestep Collection Time: 5.15394
Timestep Consumption Time: 1.97063
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.12457

Cumulative Model Updates: 12402
Cumulative Timesteps: 103712473

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7696.83205
Policy Entropy: 0.98213
Value Function Loss: 0.74346

Mean KL Divergence: 0.04951
SB3 Clip Fraction: 0.36893
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.06791

Collected Steps per Second: 10064.81128
Overall Steps per Second: 7175.92379

Timestep Collection Time: 4.96870
Timestep Consumption Time: 2.00030
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 6.96900

Cumulative Model Updates: 12408
Cumulative Timesteps: 103762482

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 103762482...
Checkpoint 103762482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11014.98578
Policy Entropy: 0.94615
Value Function Loss: 0.73688

Mean KL Divergence: 0.04534
SB3 Clip Fraction: 0.35999
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.06746

Collected Steps per Second: 9835.25529
Overall Steps per Second: 7082.96413

Timestep Collection Time: 5.08650
Timestep Consumption Time: 1.97651
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.06300

Cumulative Model Updates: 12414
Cumulative Timesteps: 103812509

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7286.39777
Policy Entropy: 0.93148
Value Function Loss: 0.77808

Mean KL Divergence: 0.03453
SB3 Clip Fraction: 0.31368
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.06419

Collected Steps per Second: 9961.35501
Overall Steps per Second: 7194.01296

Timestep Collection Time: 5.02100
Timestep Consumption Time: 1.93144
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 6.95245

Cumulative Model Updates: 12420
Cumulative Timesteps: 103862525

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 103862525...
Checkpoint 103862525 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4161.23852
Policy Entropy: 0.92688
Value Function Loss: 0.78588

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.22756
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.06671

Collected Steps per Second: 10069.42541
Overall Steps per Second: 7287.84682

Timestep Collection Time: 4.96622
Timestep Consumption Time: 1.89548
PPO Batch Consumption Time: 0.02434
Total Iteration Time: 6.86170

Cumulative Model Updates: 12426
Cumulative Timesteps: 103912532

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8402.00623
Policy Entropy: 0.92080
Value Function Loss: 0.79328

Mean KL Divergence: 0.02406
SB3 Clip Fraction: 0.25278
Policy Update Magnitude: 0.07638
Value Function Update Magnitude: 0.07033

Collected Steps per Second: 9874.17369
Overall Steps per Second: 7093.27803

Timestep Collection Time: 5.06371
Timestep Consumption Time: 1.98521
PPO Batch Consumption Time: 0.02975
Total Iteration Time: 7.04893

Cumulative Model Updates: 12432
Cumulative Timesteps: 103962532

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 103962532...
Checkpoint 103962532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7294.73896
Policy Entropy: 0.90058
Value Function Loss: 0.78907

Mean KL Divergence: 0.02497
SB3 Clip Fraction: 0.26344
Policy Update Magnitude: 0.07613
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 9940.61410
Overall Steps per Second: 7232.48284

Timestep Collection Time: 5.03460
Timestep Consumption Time: 1.88516
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 6.91975

Cumulative Model Updates: 12438
Cumulative Timesteps: 104012579

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5704.71981
Policy Entropy: 0.89634
Value Function Loss: 0.79881

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.26876
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.06527

Collected Steps per Second: 9240.59621
Overall Steps per Second: 6719.43567

Timestep Collection Time: 5.41210
Timestep Consumption Time: 2.03064
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.44274

Cumulative Model Updates: 12444
Cumulative Timesteps: 104062590

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 104062590...
Checkpoint 104062590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4692.16978
Policy Entropy: 0.89921
Value Function Loss: 0.81336

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.24550
Policy Update Magnitude: 0.07026
Value Function Update Magnitude: 0.06676

Collected Steps per Second: 9640.33011
Overall Steps per Second: 7029.70496

Timestep Collection Time: 5.18955
Timestep Consumption Time: 1.92725
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.11680

Cumulative Model Updates: 12450
Cumulative Timesteps: 104112619

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8899.91737
Policy Entropy: 0.88432
Value Function Loss: 0.79041

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.27203
Policy Update Magnitude: 0.06513
Value Function Update Magnitude: 0.06943

Collected Steps per Second: 9566.86351
Overall Steps per Second: 6974.04815

Timestep Collection Time: 5.23129
Timestep Consumption Time: 1.94489
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.17618

Cumulative Model Updates: 12456
Cumulative Timesteps: 104162666

Timesteps Collected: 50047
--------END ITERATION REPORT--------


Saving checkpoint 104162666...
Checkpoint 104162666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7777.53449
Policy Entropy: 0.87940
Value Function Loss: 0.77907

Mean KL Divergence: 0.02458
SB3 Clip Fraction: 0.26393
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 9544.74714
Overall Steps per Second: 6863.95120

Timestep Collection Time: 5.24068
Timestep Consumption Time: 2.04681
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.28749

Cumulative Model Updates: 12462
Cumulative Timesteps: 104212687

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9081.93390
Policy Entropy: 0.86161
Value Function Loss: 0.77919

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.31051
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 10648.50784
Overall Steps per Second: 7416.18985

Timestep Collection Time: 4.69549
Timestep Consumption Time: 2.04651
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 6.74201

Cumulative Model Updates: 12468
Cumulative Timesteps: 104262687

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 104262687...
Checkpoint 104262687 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6644.05066
Policy Entropy: 0.84979
Value Function Loss: 0.75567

Mean KL Divergence: 0.03049
SB3 Clip Fraction: 0.31527
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.07220

Collected Steps per Second: 9619.30612
Overall Steps per Second: 6767.02727

Timestep Collection Time: 5.19923
Timestep Consumption Time: 2.19146
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.39069

Cumulative Model Updates: 12474
Cumulative Timesteps: 104312700

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10952.30547
Policy Entropy: 0.84017
Value Function Loss: 0.75572

Mean KL Divergence: 0.03220
SB3 Clip Fraction: 0.30916
Policy Update Magnitude: 0.06639
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 9173.93243
Overall Steps per Second: 6731.75403

Timestep Collection Time: 5.45339
Timestep Consumption Time: 1.97841
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.43179

Cumulative Model Updates: 12480
Cumulative Timesteps: 104362729

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 104362729...
Checkpoint 104362729 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7130.18010
Policy Entropy: 0.83545
Value Function Loss: 0.75320

Mean KL Divergence: 0.02808
SB3 Clip Fraction: 0.30183
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 9845.92866
Overall Steps per Second: 7029.38506

Timestep Collection Time: 5.08159
Timestep Consumption Time: 2.03610
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.11769

Cumulative Model Updates: 12486
Cumulative Timesteps: 104412762

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6584.66874
Policy Entropy: 0.83357
Value Function Loss: 0.77276

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.27121
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 8892.86759
Overall Steps per Second: 6469.07365

Timestep Collection Time: 5.62293
Timestep Consumption Time: 2.10677
PPO Batch Consumption Time: 0.03151
Total Iteration Time: 7.72970

Cumulative Model Updates: 12492
Cumulative Timesteps: 104462766

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 104462766...
Checkpoint 104462766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5606.16914
Policy Entropy: 0.81300
Value Function Loss: 0.76260

Mean KL Divergence: 0.03119
SB3 Clip Fraction: 0.30855
Policy Update Magnitude: 0.06727
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 10246.25215
Overall Steps per Second: 7099.82977

Timestep Collection Time: 4.88296
Timestep Consumption Time: 2.16397
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.04693

Cumulative Model Updates: 12498
Cumulative Timesteps: 104512798

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7995.52943
Policy Entropy: 0.79996
Value Function Loss: 0.75802

Mean KL Divergence: 0.02870
SB3 Clip Fraction: 0.31101
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.07282

Collected Steps per Second: 10522.48681
Overall Steps per Second: 7388.98076

Timestep Collection Time: 4.75296
Timestep Consumption Time: 2.01563
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 6.76859

Cumulative Model Updates: 12504
Cumulative Timesteps: 104562811

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 104562811...
Checkpoint 104562811 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6844.86949
Policy Entropy: 0.79055
Value Function Loss: 0.73375

Mean KL Divergence: 0.03337
SB3 Clip Fraction: 0.29340
Policy Update Magnitude: 0.06891
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 9485.35035
Overall Steps per Second: 6832.55040

Timestep Collection Time: 5.27150
Timestep Consumption Time: 2.04671
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.31820

Cumulative Model Updates: 12510
Cumulative Timesteps: 104612813

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6962.15576
Policy Entropy: 0.77401
Value Function Loss: 0.72872

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.27479
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.06754

Collected Steps per Second: 9964.36841
Overall Steps per Second: 7157.73346

Timestep Collection Time: 5.02059
Timestep Consumption Time: 1.96863
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 6.98922

Cumulative Model Updates: 12516
Cumulative Timesteps: 104662840

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 104662840...
Checkpoint 104662840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9970.03131
Policy Entropy: 0.75817
Value Function Loss: 0.71387

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.28335
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.06788

Collected Steps per Second: 9740.73585
Overall Steps per Second: 6923.66844

Timestep Collection Time: 5.13462
Timestep Consumption Time: 2.08915
PPO Batch Consumption Time: 0.02927
Total Iteration Time: 7.22377

Cumulative Model Updates: 12522
Cumulative Timesteps: 104712855

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13071.46215
Policy Entropy: 0.76039
Value Function Loss: 0.69131

Mean KL Divergence: 0.02684
SB3 Clip Fraction: 0.29279
Policy Update Magnitude: 0.06816
Value Function Update Magnitude: 0.07160

Collected Steps per Second: 9269.42835
Overall Steps per Second: 6776.55864

Timestep Collection Time: 5.39526
Timestep Consumption Time: 1.98474
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.38000

Cumulative Model Updates: 12528
Cumulative Timesteps: 104762866

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 104762866...
Checkpoint 104762866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10379.71082
Policy Entropy: 0.73892
Value Function Loss: 0.69869

Mean KL Divergence: 0.02934
SB3 Clip Fraction: 0.33640
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.06775

Collected Steps per Second: 10192.70403
Overall Steps per Second: 7287.66230

Timestep Collection Time: 4.90714
Timestep Consumption Time: 1.95611
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 6.86324

Cumulative Model Updates: 12534
Cumulative Timesteps: 104812883

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9413.91007
Policy Entropy: 0.73729
Value Function Loss: 0.69247

Mean KL Divergence: 0.02881
SB3 Clip Fraction: 0.29433
Policy Update Magnitude: 0.07633
Value Function Update Magnitude: 0.06909

Collected Steps per Second: 9381.36493
Overall Steps per Second: 6771.74408

Timestep Collection Time: 5.33345
Timestep Consumption Time: 2.05535
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.38879

Cumulative Model Updates: 12540
Cumulative Timesteps: 104862918

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 104862918...
Checkpoint 104862918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6862.86955
Policy Entropy: 0.72200
Value Function Loss: 0.72578

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.25876
Policy Update Magnitude: 0.07110
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 10115.72166
Overall Steps per Second: 6948.09276

Timestep Collection Time: 4.94379
Timestep Consumption Time: 2.25387
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.19766

Cumulative Model Updates: 12546
Cumulative Timesteps: 104912928

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15629.40917
Policy Entropy: 0.71184
Value Function Loss: 0.70178

Mean KL Divergence: 0.02913
SB3 Clip Fraction: 0.27523
Policy Update Magnitude: 0.07012
Value Function Update Magnitude: 0.07638

Collected Steps per Second: 10253.78122
Overall Steps per Second: 7148.30360

Timestep Collection Time: 4.88074
Timestep Consumption Time: 2.12037
PPO Batch Consumption Time: 0.02431
Total Iteration Time: 7.00110

Cumulative Model Updates: 12552
Cumulative Timesteps: 104962974

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 104962974...
Checkpoint 104962974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10107.31757
Policy Entropy: 0.70278
Value Function Loss: 0.69542

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.26556
Policy Update Magnitude: 0.06605
Value Function Update Magnitude: 0.07196

Collected Steps per Second: 9711.33868
Overall Steps per Second: 6741.82293

Timestep Collection Time: 5.15181
Timestep Consumption Time: 2.26918
PPO Batch Consumption Time: 0.02483
Total Iteration Time: 7.42099

Cumulative Model Updates: 12558
Cumulative Timesteps: 105013005

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7143.71744
Policy Entropy: 0.68457
Value Function Loss: 0.67053

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.25126
Policy Update Magnitude: 0.06945
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 10168.38260
Overall Steps per Second: 7016.46254

Timestep Collection Time: 4.92005
Timestep Consumption Time: 2.21018
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.13023

Cumulative Model Updates: 12564
Cumulative Timesteps: 105063034

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 105063034...
Checkpoint 105063034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8943.58772
Policy Entropy: 0.68252
Value Function Loss: 0.68279

Mean KL Divergence: 0.02169
SB3 Clip Fraction: 0.24234
Policy Update Magnitude: 0.06822
Value Function Update Magnitude: 0.06411

Collected Steps per Second: 10186.11585
Overall Steps per Second: 7068.76728

Timestep Collection Time: 4.91188
Timestep Consumption Time: 2.16616
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.07804

Cumulative Model Updates: 12570
Cumulative Timesteps: 105113067

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12080.78932
Policy Entropy: 0.66429
Value Function Loss: 0.68865

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.24685
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 9680.81627
Overall Steps per Second: 6689.85489

Timestep Collection Time: 5.16826
Timestep Consumption Time: 2.31067
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.47894

Cumulative Model Updates: 12576
Cumulative Timesteps: 105163100

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 105163100...
Checkpoint 105163100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6981.89728
Policy Entropy: 0.65878
Value Function Loss: 0.68293

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.22421
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 10594.68338
Overall Steps per Second: 7121.77685

Timestep Collection Time: 4.72237
Timestep Consumption Time: 2.30284
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.02521

Cumulative Model Updates: 12582
Cumulative Timesteps: 105213132

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8162.53160
Policy Entropy: 0.65573
Value Function Loss: 0.65313

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.23954
Policy Update Magnitude: 0.06795
Value Function Update Magnitude: 0.07851

Collected Steps per Second: 10699.06982
Overall Steps per Second: 7358.46910

Timestep Collection Time: 4.67545
Timestep Consumption Time: 2.12256
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 6.79802

Cumulative Model Updates: 12588
Cumulative Timesteps: 105263155

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 105263155...
Checkpoint 105263155 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16376.54493
Policy Entropy: 0.63841
Value Function Loss: 0.68654

Mean KL Divergence: 0.03078
SB3 Clip Fraction: 0.29820
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.07607

Collected Steps per Second: 9472.59391
Overall Steps per Second: 6790.10600

Timestep Collection Time: 5.28124
Timestep Consumption Time: 2.08640
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.36763

Cumulative Model Updates: 12594
Cumulative Timesteps: 105313182

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10761.65202
Policy Entropy: 0.63061
Value Function Loss: 0.70239

Mean KL Divergence: 0.02868
SB3 Clip Fraction: 0.25459
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 9816.41121
Overall Steps per Second: 6973.69631

Timestep Collection Time: 5.09636
Timestep Consumption Time: 2.07745
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.17381

Cumulative Model Updates: 12600
Cumulative Timesteps: 105363210

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 105363210...
Checkpoint 105363210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11199.27329
Policy Entropy: 0.62114
Value Function Loss: 0.68519

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.25821
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.07749

Collected Steps per Second: 9965.83288
Overall Steps per Second: 7038.95935

Timestep Collection Time: 5.01724
Timestep Consumption Time: 2.08622
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.10346

Cumulative Model Updates: 12606
Cumulative Timesteps: 105413211

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13496.42513
Policy Entropy: 0.60645
Value Function Loss: 0.68103

Mean KL Divergence: 0.02764
SB3 Clip Fraction: 0.28200
Policy Update Magnitude: 0.06565
Value Function Update Magnitude: 0.08499

Collected Steps per Second: 9561.80306
Overall Steps per Second: 6825.40655

Timestep Collection Time: 5.23175
Timestep Consumption Time: 2.09748
PPO Batch Consumption Time: 0.02449
Total Iteration Time: 7.32923

Cumulative Model Updates: 12612
Cumulative Timesteps: 105463236

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 105463236...
Checkpoint 105463236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10046.59670
Policy Entropy: 0.60679
Value Function Loss: 0.68759

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.21790
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.11057

Collected Steps per Second: 9992.71755
Overall Steps per Second: 7139.60298

Timestep Collection Time: 5.00615
Timestep Consumption Time: 2.00055
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.00669

Cumulative Model Updates: 12618
Cumulative Timesteps: 105513261

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11715.16293
Policy Entropy: 0.59501
Value Function Loss: 0.72144

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.26017
Policy Update Magnitude: 0.07319
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 9939.44296
Overall Steps per Second: 7038.82455

Timestep Collection Time: 5.03408
Timestep Consumption Time: 2.07449
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.10857

Cumulative Model Updates: 12624
Cumulative Timesteps: 105563297

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 105563297...
Checkpoint 105563297 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11758.50497
Policy Entropy: 0.58329
Value Function Loss: 0.72931

Mean KL Divergence: 0.02651
SB3 Clip Fraction: 0.26555
Policy Update Magnitude: 0.07302
Value Function Update Magnitude: 0.08350

Collected Steps per Second: 9095.47611
Overall Steps per Second: 6559.78327

Timestep Collection Time: 5.49889
Timestep Consumption Time: 2.12560
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.62449

Cumulative Model Updates: 12630
Cumulative Timesteps: 105613312

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8606.15575
Policy Entropy: 0.57673
Value Function Loss: 0.74867

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.22651
Policy Update Magnitude: 0.07833
Value Function Update Magnitude: 0.07364

Collected Steps per Second: 9369.32667
Overall Steps per Second: 6771.28050

Timestep Collection Time: 5.34073
Timestep Consumption Time: 2.04916
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.38989

Cumulative Model Updates: 12636
Cumulative Timesteps: 105663351

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 105663351...
Checkpoint 105663351 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7008.48543
Policy Entropy: 0.56205
Value Function Loss: 0.72957

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.24707
Policy Update Magnitude: 0.08806
Value Function Update Magnitude: 0.07271

Collected Steps per Second: 9619.77780
Overall Steps per Second: 6971.86140

Timestep Collection Time: 5.20022
Timestep Consumption Time: 1.97505
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.17527

Cumulative Model Updates: 12642
Cumulative Timesteps: 105713376

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7598.90420
Policy Entropy: 0.55858
Value Function Loss: 0.72832

Mean KL Divergence: 0.02852
SB3 Clip Fraction: 0.24568
Policy Update Magnitude: 0.09428
Value Function Update Magnitude: 0.06906

Collected Steps per Second: 9689.42874
Overall Steps per Second: 6993.86827

Timestep Collection Time: 5.16408
Timestep Consumption Time: 1.99033
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 7.15441

Cumulative Model Updates: 12648
Cumulative Timesteps: 105763413

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 105763413...
Checkpoint 105763413 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13809.81737
Policy Entropy: 0.54575
Value Function Loss: 0.68759

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.25531
Policy Update Magnitude: 0.08041
Value Function Update Magnitude: 0.06983

Collected Steps per Second: 9328.67080
Overall Steps per Second: 6761.85201

Timestep Collection Time: 5.36336
Timestep Consumption Time: 2.03595
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.39930

Cumulative Model Updates: 12654
Cumulative Timesteps: 105813446

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9067.75262
Policy Entropy: 0.53623
Value Function Loss: 0.69856

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.24705
Policy Update Magnitude: 0.07284
Value Function Update Magnitude: 0.07132

Collected Steps per Second: 9370.95795
Overall Steps per Second: 6840.97929

Timestep Collection Time: 5.33638
Timestep Consumption Time: 1.97354
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.30992

Cumulative Model Updates: 12660
Cumulative Timesteps: 105863453

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 105863453...
Checkpoint 105863453 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7816.19201
Policy Entropy: 0.53273
Value Function Loss: 0.69604

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.24201
Policy Update Magnitude: 0.07650
Value Function Update Magnitude: 0.07073

Collected Steps per Second: 10470.88448
Overall Steps per Second: 7440.28060

Timestep Collection Time: 4.77925
Timestep Consumption Time: 1.94670
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 6.72596

Cumulative Model Updates: 12666
Cumulative Timesteps: 105913496

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9630.81775
Policy Entropy: 0.51396
Value Function Loss: 0.71327

Mean KL Divergence: 0.02929
SB3 Clip Fraction: 0.30662
Policy Update Magnitude: 0.08438
Value Function Update Magnitude: 0.07034

Collected Steps per Second: 9492.96463
Overall Steps per Second: 6760.13220

Timestep Collection Time: 5.27180
Timestep Consumption Time: 2.13116
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.40296

Cumulative Model Updates: 12672
Cumulative Timesteps: 105963541

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 105963541...
Checkpoint 105963541 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14740.99655
Policy Entropy: 0.51086
Value Function Loss: 0.71666

Mean KL Divergence: 0.03047
SB3 Clip Fraction: 0.31652
Policy Update Magnitude: 0.08125
Value Function Update Magnitude: 0.06645

Collected Steps per Second: 9842.97796
Overall Steps per Second: 7073.37056

Timestep Collection Time: 5.07987
Timestep Consumption Time: 1.98904
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.06891

Cumulative Model Updates: 12678
Cumulative Timesteps: 106013542

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11774.62559
Policy Entropy: 0.51115
Value Function Loss: 0.72003

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.25502
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.06650

Collected Steps per Second: 9725.05375
Overall Steps per Second: 6947.09525

Timestep Collection Time: 5.14496
Timestep Consumption Time: 2.05733
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.20229

Cumulative Model Updates: 12684
Cumulative Timesteps: 106063577

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 106063577...
Checkpoint 106063577 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11853.50081
Policy Entropy: 0.49998
Value Function Loss: 0.72371

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.25742
Policy Update Magnitude: 0.06993
Value Function Update Magnitude: 0.07078

Collected Steps per Second: 9291.73809
Overall Steps per Second: 6719.27292

Timestep Collection Time: 5.38468
Timestep Consumption Time: 2.06152
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.44619

Cumulative Model Updates: 12690
Cumulative Timesteps: 106113610

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13583.64672
Policy Entropy: 0.49565
Value Function Loss: 0.69994

Mean KL Divergence: 0.02268
SB3 Clip Fraction: 0.24907
Policy Update Magnitude: 0.07234
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 9178.09945
Overall Steps per Second: 6706.76576

Timestep Collection Time: 5.44949
Timestep Consumption Time: 2.00805
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 7.45754

Cumulative Model Updates: 12696
Cumulative Timesteps: 106163626

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 106163626...
Checkpoint 106163626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12721.65903
Policy Entropy: 0.48734
Value Function Loss: 0.71492

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.27756
Policy Update Magnitude: 0.07550
Value Function Update Magnitude: 0.07283

Collected Steps per Second: 9194.69778
Overall Steps per Second: 6771.61183

Timestep Collection Time: 5.44161
Timestep Consumption Time: 1.94717
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.38879

Cumulative Model Updates: 12702
Cumulative Timesteps: 106213660

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10141.80503
Policy Entropy: 0.48039
Value Function Loss: 0.72002

Mean KL Divergence: 0.03002
SB3 Clip Fraction: 0.27549
Policy Update Magnitude: 0.07519
Value Function Update Magnitude: 0.06965

Collected Steps per Second: 9933.34938
Overall Steps per Second: 7046.57850

Timestep Collection Time: 5.03727
Timestep Consumption Time: 2.06362
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.10089

Cumulative Model Updates: 12708
Cumulative Timesteps: 106263697

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 106263697...
Checkpoint 106263697 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9676.40637
Policy Entropy: 0.47294
Value Function Loss: 0.71956

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.24357
Policy Update Magnitude: 0.07627
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 9561.50514
Overall Steps per Second: 6957.45732

Timestep Collection Time: 5.23003
Timestep Consumption Time: 1.95751
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.18754

Cumulative Model Updates: 12714
Cumulative Timesteps: 106313704

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10941.76686
Policy Entropy: 0.46106
Value Function Loss: 0.70244

Mean KL Divergence: 0.02401
SB3 Clip Fraction: 0.24593
Policy Update Magnitude: 0.07485
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 9062.20757
Overall Steps per Second: 6643.23803

Timestep Collection Time: 5.52106
Timestep Consumption Time: 2.01036
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.53142

Cumulative Model Updates: 12720
Cumulative Timesteps: 106363737

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 106363737...
Checkpoint 106363737 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13711.43597
Policy Entropy: 0.44582
Value Function Loss: 0.69608

Mean KL Divergence: 0.03440
SB3 Clip Fraction: 0.29373
Policy Update Magnitude: 0.07341
Value Function Update Magnitude: 0.06513

Collected Steps per Second: 10045.06708
Overall Steps per Second: 7200.54482

Timestep Collection Time: 4.98006
Timestep Consumption Time: 1.96733
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 6.94739

Cumulative Model Updates: 12726
Cumulative Timesteps: 106413762

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14885.96011
Policy Entropy: 0.43462
Value Function Loss: 0.68546

Mean KL Divergence: 0.03035
SB3 Clip Fraction: 0.28969
Policy Update Magnitude: 0.06739
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 10095.58849
Overall Steps per Second: 7147.05872

Timestep Collection Time: 4.95414
Timestep Consumption Time: 2.04384
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.99798

Cumulative Model Updates: 12732
Cumulative Timesteps: 106463777

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 106463777...
Checkpoint 106463777 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14994.93111
Policy Entropy: 0.42329
Value Function Loss: 0.69945

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.28373
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.06951

Collected Steps per Second: 9549.93718
Overall Steps per Second: 6900.70112

Timestep Collection Time: 5.23825
Timestep Consumption Time: 2.01101
PPO Batch Consumption Time: 0.02394
Total Iteration Time: 7.24926

Cumulative Model Updates: 12738
Cumulative Timesteps: 106513802

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9276.79174
Policy Entropy: 0.42193
Value Function Loss: 0.70351

Mean KL Divergence: 0.02220
SB3 Clip Fraction: 0.23429
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.06713

Collected Steps per Second: 10236.85626
Overall Steps per Second: 7269.78885

Timestep Collection Time: 4.88754
Timestep Consumption Time: 1.99478
PPO Batch Consumption Time: 0.02447
Total Iteration Time: 6.88232

Cumulative Model Updates: 12744
Cumulative Timesteps: 106563835

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 106563835...
Checkpoint 106563835 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9504.33352
Policy Entropy: 0.40782
Value Function Loss: 0.72230

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.25498
Policy Update Magnitude: 0.06897
Value Function Update Magnitude: 0.06283

Collected Steps per Second: 10093.65373
Overall Steps per Second: 7055.86909

Timestep Collection Time: 4.95608
Timestep Consumption Time: 2.13376
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.08984

Cumulative Model Updates: 12750
Cumulative Timesteps: 106613860

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9694.70567
Policy Entropy: 0.40642
Value Function Loss: 0.68766

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.23117
Policy Update Magnitude: 0.07807
Value Function Update Magnitude: 0.06687

Collected Steps per Second: 9107.53228
Overall Steps per Second: 6635.22431

Timestep Collection Time: 5.49106
Timestep Consumption Time: 2.04599
PPO Batch Consumption Time: 0.02405
Total Iteration Time: 7.53705

Cumulative Model Updates: 12756
Cumulative Timesteps: 106663870

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 106663870...
Checkpoint 106663870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6934.03403
Policy Entropy: 0.40108
Value Function Loss: 0.70469

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.26189
Policy Update Magnitude: 0.08867
Value Function Update Magnitude: 0.07065

Collected Steps per Second: 9867.48005
Overall Steps per Second: 7002.93393

Timestep Collection Time: 5.06968
Timestep Consumption Time: 2.07375
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.14343

Cumulative Model Updates: 12762
Cumulative Timesteps: 106713895

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10924.14961
Policy Entropy: 0.40215
Value Function Loss: 0.72277

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.24591
Policy Update Magnitude: 0.08101
Value Function Update Magnitude: 0.06794

Collected Steps per Second: 10125.89689
Overall Steps per Second: 7198.20765

Timestep Collection Time: 4.94030
Timestep Consumption Time: 2.00934
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 6.94965

Cumulative Model Updates: 12768
Cumulative Timesteps: 106763920

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 106763920...
Checkpoint 106763920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11830.78551
Policy Entropy: 0.38520
Value Function Loss: 0.74755

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.28182
Policy Update Magnitude: 0.07163
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 9472.51892
Overall Steps per Second: 6688.40144

Timestep Collection Time: 5.27906
Timestep Consumption Time: 2.19746
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.47652

Cumulative Model Updates: 12774
Cumulative Timesteps: 106813926

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13813.38636
Policy Entropy: 0.37027
Value Function Loss: 0.73602

Mean KL Divergence: 0.02311
SB3 Clip Fraction: 0.25777
Policy Update Magnitude: 0.06990
Value Function Update Magnitude: 0.07132

Collected Steps per Second: 10721.34106
Overall Steps per Second: 7288.96849

Timestep Collection Time: 4.66518
Timestep Consumption Time: 2.19683
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.86201

Cumulative Model Updates: 12780
Cumulative Timesteps: 106863943

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 106863943...
Checkpoint 106863943 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14007.14258
Policy Entropy: 0.35542
Value Function Loss: 0.70909

Mean KL Divergence: 0.02915
SB3 Clip Fraction: 0.27039
Policy Update Magnitude: 0.07021
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 10539.27069
Overall Steps per Second: 7086.80989

Timestep Collection Time: 4.74625
Timestep Consumption Time: 2.31222
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.05847

Cumulative Model Updates: 12786
Cumulative Timesteps: 106913965

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8934.79270
Policy Entropy: 0.34920
Value Function Loss: 0.69243

Mean KL Divergence: 0.03140
SB3 Clip Fraction: 0.30412
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.07546

Collected Steps per Second: 9713.29344
Overall Steps per Second: 6747.54937

Timestep Collection Time: 5.14789
Timestep Consumption Time: 2.26265
PPO Batch Consumption Time: 0.03143
Total Iteration Time: 7.41054

Cumulative Model Updates: 12792
Cumulative Timesteps: 106963968

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 106963968...
Checkpoint 106963968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14442.99997
Policy Entropy: 0.34043
Value Function Loss: 0.69389

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.26683
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.07388

Collected Steps per Second: 11593.74524
Overall Steps per Second: 7845.32986

Timestep Collection Time: 4.31500
Timestep Consumption Time: 2.06166
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 6.37666

Cumulative Model Updates: 12798
Cumulative Timesteps: 107013995

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14544.76883
Policy Entropy: 0.32682
Value Function Loss: 0.69754

Mean KL Divergence: 0.02826
SB3 Clip Fraction: 0.28620
Policy Update Magnitude: 0.06809
Value Function Update Magnitude: 0.06827

Collected Steps per Second: 10385.34619
Overall Steps per Second: 7245.08511

Timestep Collection Time: 4.81640
Timestep Consumption Time: 2.08759
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 6.90399

Cumulative Model Updates: 12804
Cumulative Timesteps: 107064015

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 107064015...
Checkpoint 107064015 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13999.73498
Policy Entropy: 0.31540
Value Function Loss: 0.68010

Mean KL Divergence: 0.03948
SB3 Clip Fraction: 0.33571
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 9297.91357
Overall Steps per Second: 6757.67509

Timestep Collection Time: 5.38207
Timestep Consumption Time: 2.02314
PPO Batch Consumption Time: 0.02437
Total Iteration Time: 7.40521

Cumulative Model Updates: 12810
Cumulative Timesteps: 107114057

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12542.92341
Policy Entropy: 0.30435
Value Function Loss: 0.65815

Mean KL Divergence: 0.03291
SB3 Clip Fraction: 0.31769
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.07195

Collected Steps per Second: 9937.69537
Overall Steps per Second: 6926.93721

Timestep Collection Time: 5.03527
Timestep Consumption Time: 2.18856
PPO Batch Consumption Time: 0.02435
Total Iteration Time: 7.22383

Cumulative Model Updates: 12816
Cumulative Timesteps: 107164096

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 107164096...
Checkpoint 107164096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15352.71989
Policy Entropy: 0.29363
Value Function Loss: 0.66541

Mean KL Divergence: 0.03350
SB3 Clip Fraction: 0.32981
Policy Update Magnitude: 0.06573
Value Function Update Magnitude: 0.07295

Collected Steps per Second: 9221.49429
Overall Steps per Second: 6686.13114

Timestep Collection Time: 5.42472
Timestep Consumption Time: 2.05704
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 7.48176

Cumulative Model Updates: 12822
Cumulative Timesteps: 107214120

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9137.03416
Policy Entropy: 0.29589
Value Function Loss: 0.69401

Mean KL Divergence: 0.04306
SB3 Clip Fraction: 0.34607
Policy Update Magnitude: 0.06890
Value Function Update Magnitude: 0.07649

Collected Steps per Second: 9973.39635
Overall Steps per Second: 7078.33410

Timestep Collection Time: 5.01785
Timestep Consumption Time: 2.05232
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.07017

Cumulative Model Updates: 12828
Cumulative Timesteps: 107264165

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 107264165...
Checkpoint 107264165 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11607.79892
Policy Entropy: 0.28052
Value Function Loss: 0.71231

Mean KL Divergence: 0.02885
SB3 Clip Fraction: 0.28495
Policy Update Magnitude: 0.06823
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 10411.37112
Overall Steps per Second: 7202.70348

Timestep Collection Time: 4.80628
Timestep Consumption Time: 2.14111
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 6.94739

Cumulative Model Updates: 12834
Cumulative Timesteps: 107314205

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11264.10788
Policy Entropy: 0.27573
Value Function Loss: 0.70085

Mean KL Divergence: 0.02526
SB3 Clip Fraction: 0.26062
Policy Update Magnitude: 0.07807
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 9589.18729
Overall Steps per Second: 6895.39458

Timestep Collection Time: 5.21692
Timestep Consumption Time: 2.03807
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.25499

Cumulative Model Updates: 12840
Cumulative Timesteps: 107364231

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 107364231...
Checkpoint 107364231 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10509.22990
Policy Entropy: 0.26414
Value Function Loss: 0.67849

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.26909
Policy Update Magnitude: 0.08758
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 10288.47118
Overall Steps per Second: 7365.76637

Timestep Collection Time: 4.86097
Timestep Consumption Time: 1.92881
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 6.78979

Cumulative Model Updates: 12846
Cumulative Timesteps: 107414243

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19214.79721
Policy Entropy: 0.25279
Value Function Loss: 0.64101

Mean KL Divergence: 0.04373
SB3 Clip Fraction: 0.37845
Policy Update Magnitude: 0.07630
Value Function Update Magnitude: 0.07886

Collected Steps per Second: 10326.11092
Overall Steps per Second: 7334.41273

Timestep Collection Time: 4.84219
Timestep Consumption Time: 1.97512
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 6.81731

Cumulative Model Updates: 12852
Cumulative Timesteps: 107464244

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 107464244...
Checkpoint 107464244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12537.85876
Policy Entropy: 0.25688
Value Function Loss: 0.64193

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.28513
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 9356.22226
Overall Steps per Second: 6814.21659

Timestep Collection Time: 5.34788
Timestep Consumption Time: 1.99500
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 7.34288

Cumulative Model Updates: 12858
Cumulative Timesteps: 107514280

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12264.20666
Policy Entropy: 0.24230
Value Function Loss: 0.63329

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.29306
Policy Update Magnitude: 0.06554
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 9686.46633
Overall Steps per Second: 7053.15775

Timestep Collection Time: 5.16422
Timestep Consumption Time: 1.92807
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.09228

Cumulative Model Updates: 12864
Cumulative Timesteps: 107564303

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 107564303...
Checkpoint 107564303 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20156.29925
Policy Entropy: 0.23195
Value Function Loss: 0.64945

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.26762
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.07245

Collected Steps per Second: 9100.63262
Overall Steps per Second: 6615.77823

Timestep Collection Time: 5.49896
Timestep Consumption Time: 2.06538
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.56434

Cumulative Model Updates: 12870
Cumulative Timesteps: 107614347

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13352.29363
Policy Entropy: 0.22631
Value Function Loss: 0.70137

Mean KL Divergence: 0.04828
SB3 Clip Fraction: 0.34598
Policy Update Magnitude: 0.06520
Value Function Update Magnitude: 0.07460

Collected Steps per Second: 9052.92808
Overall Steps per Second: 6631.24099

Timestep Collection Time: 5.52584
Timestep Consumption Time: 2.01800
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.54384

Cumulative Model Updates: 12876
Cumulative Timesteps: 107664372

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 107664372...
Checkpoint 107664372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13306.14763
Policy Entropy: 0.21690
Value Function Loss: 0.74288

Mean KL Divergence: 0.03020
SB3 Clip Fraction: 0.27771
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.07982

Collected Steps per Second: 10139.37806
Overall Steps per Second: 7078.51914

Timestep Collection Time: 4.93373
Timestep Consumption Time: 2.13342
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.06716

Cumulative Model Updates: 12882
Cumulative Timesteps: 107714397

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11866.59509
Policy Entropy: 0.21724
Value Function Loss: 0.73783

Mean KL Divergence: 0.02616
SB3 Clip Fraction: 0.24561
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.08162

Collected Steps per Second: 9703.67688
Overall Steps per Second: 7003.75915

Timestep Collection Time: 5.15660
Timestep Consumption Time: 1.98785
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.14445

Cumulative Model Updates: 12888
Cumulative Timesteps: 107764435

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 107764435...
Checkpoint 107764435 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15568.68233
Policy Entropy: 0.21043
Value Function Loss: 0.72239

Mean KL Divergence: 0.03072
SB3 Clip Fraction: 0.29431
Policy Update Magnitude: 0.07128
Value Function Update Magnitude: 0.10178

Collected Steps per Second: 9127.68441
Overall Steps per Second: 6691.81530

Timestep Collection Time: 5.48058
Timestep Consumption Time: 1.99497
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.47555

Cumulative Model Updates: 12894
Cumulative Timesteps: 107814460

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12765.60529
Policy Entropy: 0.20434
Value Function Loss: 0.69682

Mean KL Divergence: 0.02845
SB3 Clip Fraction: 0.25959
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.12045

Collected Steps per Second: 10269.56441
Overall Steps per Second: 7278.35851

Timestep Collection Time: 4.87246
Timestep Consumption Time: 2.00245
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.87490

Cumulative Model Updates: 12900
Cumulative Timesteps: 107864498

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 107864498...
Checkpoint 107864498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12134.12390
Policy Entropy: 0.19842
Value Function Loss: 0.69025

Mean KL Divergence: 0.03401
SB3 Clip Fraction: 0.27380
Policy Update Magnitude: 0.06776
Value Function Update Magnitude: 0.11453

Collected Steps per Second: 9796.33612
Overall Steps per Second: 7012.31716

Timestep Collection Time: 5.10681
Timestep Consumption Time: 2.02750
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.13430

Cumulative Model Updates: 12906
Cumulative Timesteps: 107914526

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17107.80547
Policy Entropy: 0.20340
Value Function Loss: 0.69018

Mean KL Divergence: 0.04883
SB3 Clip Fraction: 0.34897
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 9273.80213
Overall Steps per Second: 6771.03162

Timestep Collection Time: 5.39574
Timestep Consumption Time: 1.99442
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 7.39016

Cumulative Model Updates: 12912
Cumulative Timesteps: 107964565

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 107964565...
Checkpoint 107964565 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13946.72768
Policy Entropy: 0.21576
Value Function Loss: 0.70462

Mean KL Divergence: 0.05456
SB3 Clip Fraction: 0.38215
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.12359

Collected Steps per Second: 9874.39968
Overall Steps per Second: 7139.62015

Timestep Collection Time: 5.06643
Timestep Consumption Time: 1.94066
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.00710

Cumulative Model Updates: 12918
Cumulative Timesteps: 108014593

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13763.32090
Policy Entropy: 0.22989
Value Function Loss: 0.72029

Mean KL Divergence: 0.05326
SB3 Clip Fraction: 0.35272
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.19051

Collected Steps per Second: 9954.81959
Overall Steps per Second: 7215.00817

Timestep Collection Time: 5.02701
Timestep Consumption Time: 1.90895
PPO Batch Consumption Time: 0.02443
Total Iteration Time: 6.93596

Cumulative Model Updates: 12924
Cumulative Timesteps: 108064636

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 108064636...
Checkpoint 108064636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10516.10270
Policy Entropy: 0.24203
Value Function Loss: 0.73688

Mean KL Divergence: 0.04381
SB3 Clip Fraction: 0.29702
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.23169

Collected Steps per Second: 9776.96868
Overall Steps per Second: 7004.00872

Timestep Collection Time: 5.11611
Timestep Consumption Time: 2.02552
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.14162

Cumulative Model Updates: 12930
Cumulative Timesteps: 108114656

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10609.39149
Policy Entropy: 0.24400
Value Function Loss: 0.70308

Mean KL Divergence: 0.04838
SB3 Clip Fraction: 0.31020
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.20447

Collected Steps per Second: 9873.78470
Overall Steps per Second: 7065.62089

Timestep Collection Time: 5.06736
Timestep Consumption Time: 2.01397
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.08133

Cumulative Model Updates: 12936
Cumulative Timesteps: 108164690

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 108164690...
Checkpoint 108164690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11699.90843
Policy Entropy: 0.24574
Value Function Loss: 0.69588

Mean KL Divergence: 0.04727
SB3 Clip Fraction: 0.32027
Policy Update Magnitude: 0.06657
Value Function Update Magnitude: 0.19257

Collected Steps per Second: 9285.73354
Overall Steps per Second: 5502.82645

Timestep Collection Time: 5.38913
Timestep Consumption Time: 3.70474
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 9.09387

Cumulative Model Updates: 12942
Cumulative Timesteps: 108214732

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8639.95737
Policy Entropy: 0.26960
Value Function Loss: 0.75012

Mean KL Divergence: 0.04347
SB3 Clip Fraction: 0.31287
Policy Update Magnitude: 0.08889
Value Function Update Magnitude: 0.17577

Collected Steps per Second: 9329.40504
Overall Steps per Second: 6735.31250

Timestep Collection Time: 5.36186
Timestep Consumption Time: 2.06511
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.42698

Cumulative Model Updates: 12948
Cumulative Timesteps: 108264755

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 108264755...
Checkpoint 108264755 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14516.15628
Policy Entropy: 0.28780
Value Function Loss: 0.77059

Mean KL Divergence: 0.04711
SB3 Clip Fraction: 0.32662
Policy Update Magnitude: 0.10920
Value Function Update Magnitude: 0.14085

Collected Steps per Second: 9723.42406
Overall Steps per Second: 6998.67188

Timestep Collection Time: 5.14531
Timestep Consumption Time: 2.00319
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.14850

Cumulative Model Updates: 12954
Cumulative Timesteps: 108314785

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7774.67728
Policy Entropy: 0.31152
Value Function Loss: 0.79819

Mean KL Divergence: 0.03921
SB3 Clip Fraction: 0.29233
Policy Update Magnitude: 0.11182
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 9904.98971
Overall Steps per Second: 7059.70181

Timestep Collection Time: 5.05109
Timestep Consumption Time: 2.03575
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.08684

Cumulative Model Updates: 12960
Cumulative Timesteps: 108364816

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 108364816...
Checkpoint 108364816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6652.86206
Policy Entropy: 0.32351
Value Function Loss: 0.77641

Mean KL Divergence: 0.04440
SB3 Clip Fraction: 0.31444
Policy Update Magnitude: 0.11069
Value Function Update Magnitude: 0.12955

Collected Steps per Second: 10109.76943
Overall Steps per Second: 7286.98125

Timestep Collection Time: 4.94907
Timestep Consumption Time: 1.91714
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 6.86622

Cumulative Model Updates: 12966
Cumulative Timesteps: 108414850

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12136.65553
Policy Entropy: 0.33439
Value Function Loss: 0.79518

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.27416
Policy Update Magnitude: 0.11377
Value Function Update Magnitude: 0.12281

Collected Steps per Second: 10093.17610
Overall Steps per Second: 7247.38923

Timestep Collection Time: 4.95741
Timestep Consumption Time: 1.94659
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 6.90400

Cumulative Model Updates: 12972
Cumulative Timesteps: 108464886

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 108464886...
Checkpoint 108464886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8770.58252
Policy Entropy: 0.33046
Value Function Loss: 0.75058

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.25071
Policy Update Magnitude: 0.10317
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 9457.12190
Overall Steps per Second: 6862.74521

Timestep Collection Time: 5.28977
Timestep Consumption Time: 1.99973
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 7.28950

Cumulative Model Updates: 12978
Cumulative Timesteps: 108514912

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8052.36561
Policy Entropy: 0.31347
Value Function Loss: 0.71727

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.19179
Policy Update Magnitude: 0.09675
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 9614.40986
Overall Steps per Second: 7119.42494

Timestep Collection Time: 5.20521
Timestep Consumption Time: 1.82415
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.02936

Cumulative Model Updates: 12984
Cumulative Timesteps: 108564957

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 108564957...
Checkpoint 108564957 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7767.67235
Policy Entropy: 0.32913
Value Function Loss: 0.71412

Mean KL Divergence: 0.02847
SB3 Clip Fraction: 0.27940
Policy Update Magnitude: 0.09706
Value Function Update Magnitude: 0.15013

Collected Steps per Second: 10388.73531
Overall Steps per Second: 7385.66825

Timestep Collection Time: 4.81695
Timestep Consumption Time: 1.95861
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 6.77555

Cumulative Model Updates: 12990
Cumulative Timesteps: 108614999

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11298.28957
Policy Entropy: 0.33308
Value Function Loss: 0.76778

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.23251
Policy Update Magnitude: 0.09591
Value Function Update Magnitude: 0.13580

Collected Steps per Second: 10287.13107
Overall Steps per Second: 7250.78206

Timestep Collection Time: 4.86482
Timestep Consumption Time: 2.03720
PPO Batch Consumption Time: 0.02468
Total Iteration Time: 6.90201

Cumulative Model Updates: 12996
Cumulative Timesteps: 108665044

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 108665044...
Checkpoint 108665044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10475.35321
Policy Entropy: 0.34321
Value Function Loss: 0.78106

Mean KL Divergence: 0.02575
SB3 Clip Fraction: 0.24809
Policy Update Magnitude: 0.09425
Value Function Update Magnitude: 0.09865

Collected Steps per Second: 9980.31611
Overall Steps per Second: 7103.99340

Timestep Collection Time: 5.01136
Timestep Consumption Time: 2.02904
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.04041

Cumulative Model Updates: 13002
Cumulative Timesteps: 108715059

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12105.46121
Policy Entropy: 0.33947
Value Function Loss: 0.70781

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.26384
Policy Update Magnitude: 0.07916
Value Function Update Magnitude: 0.11139

Collected Steps per Second: 10156.67187
Overall Steps per Second: 7191.36072

Timestep Collection Time: 4.92464
Timestep Consumption Time: 2.03065
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.95529

Cumulative Model Updates: 13008
Cumulative Timesteps: 108765077

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 108765077...
Checkpoint 108765077 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12506.51356
Policy Entropy: 0.32877
Value Function Loss: 0.68570

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.21017
Policy Update Magnitude: 0.07366
Value Function Update Magnitude: 0.15144

Collected Steps per Second: 9712.40250
Overall Steps per Second: 7004.61274

Timestep Collection Time: 5.15125
Timestep Consumption Time: 1.99133
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.14258

Cumulative Model Updates: 13014
Cumulative Timesteps: 108815108

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11917.63103
Policy Entropy: 0.32235
Value Function Loss: 0.67246

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.23555
Policy Update Magnitude: 0.07961
Value Function Update Magnitude: 0.14104

Collected Steps per Second: 9891.63491
Overall Steps per Second: 7168.87685

Timestep Collection Time: 5.05720
Timestep Consumption Time: 1.92074
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 6.97794

Cumulative Model Updates: 13020
Cumulative Timesteps: 108865132

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 108865132...
Checkpoint 108865132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12743.14177
Policy Entropy: 0.32676
Value Function Loss: 0.70073

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.20221
Policy Update Magnitude: 0.08178
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 10005.65656
Overall Steps per Second: 7220.01035

Timestep Collection Time: 4.99967
Timestep Consumption Time: 1.92899
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.92866

Cumulative Model Updates: 13026
Cumulative Timesteps: 108915157

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12802.68751
Policy Entropy: 0.32783
Value Function Loss: 0.68896

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.22410
Policy Update Magnitude: 0.07679
Value Function Update Magnitude: 0.12049

Collected Steps per Second: 9958.88445
Overall Steps per Second: 7166.93509

Timestep Collection Time: 5.02406
Timestep Consumption Time: 1.95717
PPO Batch Consumption Time: 0.02459
Total Iteration Time: 6.98123

Cumulative Model Updates: 13032
Cumulative Timesteps: 108965191

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 108965191...
Checkpoint 108965191 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9833.08991
Policy Entropy: 0.32643
Value Function Loss: 0.70415

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.22110
Policy Update Magnitude: 0.07866
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 9558.72371
Overall Steps per Second: 6917.71386

Timestep Collection Time: 5.23438
Timestep Consumption Time: 1.99836
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.23274

Cumulative Model Updates: 13038
Cumulative Timesteps: 109015225

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12484.30757
Policy Entropy: 0.31671
Value Function Loss: 0.67680

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.25035
Policy Update Magnitude: 0.08695
Value Function Update Magnitude: 0.11320

Collected Steps per Second: 9489.15073
Overall Steps per Second: 6836.10377

Timestep Collection Time: 5.27076
Timestep Consumption Time: 2.04555
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.31630

Cumulative Model Updates: 13044
Cumulative Timesteps: 109065240

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 109065240...
Checkpoint 109065240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8389.74764
Policy Entropy: 0.31495
Value Function Loss: 0.67002

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.24372
Policy Update Magnitude: 0.08700
Value Function Update Magnitude: 0.14776

Collected Steps per Second: 9514.45407
Overall Steps per Second: 6917.46194

Timestep Collection Time: 5.25968
Timestep Consumption Time: 1.97462
PPO Batch Consumption Time: 0.02417
Total Iteration Time: 7.23430

Cumulative Model Updates: 13050
Cumulative Timesteps: 109115283

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15455.58453
Policy Entropy: 0.31044
Value Function Loss: 0.67862

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.23725
Policy Update Magnitude: 0.07867
Value Function Update Magnitude: 0.16118

Collected Steps per Second: 9942.21360
Overall Steps per Second: 7169.72330

Timestep Collection Time: 5.02926
Timestep Consumption Time: 1.94479
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.97405

Cumulative Model Updates: 13056
Cumulative Timesteps: 109165285

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 109165285...
Checkpoint 109165285 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15046.54039
Policy Entropy: 0.31379
Value Function Loss: 0.71813

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.22422
Policy Update Magnitude: 0.08068
Value Function Update Magnitude: 0.16604

Collected Steps per Second: 9956.06448
Overall Steps per Second: 6888.82838

Timestep Collection Time: 5.02668
Timestep Consumption Time: 2.23812
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.26481

Cumulative Model Updates: 13062
Cumulative Timesteps: 109215331

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13206.89867
Policy Entropy: 0.31161
Value Function Loss: 0.71990

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.21853
Policy Update Magnitude: 0.08235
Value Function Update Magnitude: 0.17158

Collected Steps per Second: 9463.75792
Overall Steps per Second: 7007.08881

Timestep Collection Time: 5.28331
Timestep Consumption Time: 1.85232
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.13563

Cumulative Model Updates: 13068
Cumulative Timesteps: 109265331

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 109265331...
Checkpoint 109265331 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6123.40823
Policy Entropy: 0.31640
Value Function Loss: 0.71645

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.22665
Policy Update Magnitude: 0.08389
Value Function Update Magnitude: 0.17338

Collected Steps per Second: 9555.41488
Overall Steps per Second: 6923.97956

Timestep Collection Time: 5.23441
Timestep Consumption Time: 1.98932
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.22374

Cumulative Model Updates: 13074
Cumulative Timesteps: 109315348

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11463.45312
Policy Entropy: 0.31319
Value Function Loss: 0.69950

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.22329
Policy Update Magnitude: 0.08512
Value Function Update Magnitude: 0.14769

Collected Steps per Second: 9959.35223
Overall Steps per Second: 7144.20218

Timestep Collection Time: 5.02322
Timestep Consumption Time: 1.97938
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.00260

Cumulative Model Updates: 13080
Cumulative Timesteps: 109365376

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 109365376...
Checkpoint 109365376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16371.96958
Policy Entropy: 0.31462
Value Function Loss: 0.66745

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.22716
Policy Update Magnitude: 0.09035
Value Function Update Magnitude: 0.15021

Collected Steps per Second: 9646.24887
Overall Steps per Second: 6844.93671

Timestep Collection Time: 5.18440
Timestep Consumption Time: 2.12173
PPO Batch Consumption Time: 0.02331
Total Iteration Time: 7.30613

Cumulative Model Updates: 13086
Cumulative Timesteps: 109415386

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16872.96924
Policy Entropy: 0.31383
Value Function Loss: 0.65903

Mean KL Divergence: 0.02502
SB3 Clip Fraction: 0.23409
Policy Update Magnitude: 0.08912
Value Function Update Magnitude: 0.13915

Collected Steps per Second: 9485.73031
Overall Steps per Second: 6836.17891

Timestep Collection Time: 5.27350
Timestep Consumption Time: 2.04389
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.31739

Cumulative Model Updates: 13092
Cumulative Timesteps: 109465409

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 109465409...
Checkpoint 109465409 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11959.55471
Policy Entropy: 0.31319
Value Function Loss: 0.65152

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.23630
Policy Update Magnitude: 0.09446
Value Function Update Magnitude: 0.10872

Collected Steps per Second: 10483.65491
Overall Steps per Second: 7342.46584

Timestep Collection Time: 4.77152
Timestep Consumption Time: 2.04131
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 6.81283

Cumulative Model Updates: 13098
Cumulative Timesteps: 109515432

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14074.24765
Policy Entropy: 0.31184
Value Function Loss: 0.64851

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.20478
Policy Update Magnitude: 0.09290
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 11117.73999
Overall Steps per Second: 7731.23036

Timestep Collection Time: 4.49903
Timestep Consumption Time: 1.97071
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 6.46973

Cumulative Model Updates: 13104
Cumulative Timesteps: 109565451

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 109565451...
Checkpoint 109565451 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16308.50799
Policy Entropy: 0.30662
Value Function Loss: 0.63471

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.20005
Policy Update Magnitude: 0.09348
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 10675.43109
Overall Steps per Second: 7580.01656

Timestep Collection Time: 4.68571
Timestep Consumption Time: 1.91348
PPO Batch Consumption Time: 0.02430
Total Iteration Time: 6.59919

Cumulative Model Updates: 13110
Cumulative Timesteps: 109615473

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18359.83947
Policy Entropy: 0.32388
Value Function Loss: 0.63659

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.23026
Policy Update Magnitude: 0.08862
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 9458.87400
Overall Steps per Second: 6928.62352

Timestep Collection Time: 5.28678
Timestep Consumption Time: 1.93067
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 7.21745

Cumulative Model Updates: 13116
Cumulative Timesteps: 109665480

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 109665480...
Checkpoint 109665480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17654.29960
Policy Entropy: 0.33119
Value Function Loss: 0.67158

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.27098
Policy Update Magnitude: 0.08649
Value Function Update Magnitude: 0.11034

Collected Steps per Second: 9730.26610
Overall Steps per Second: 7046.65716

Timestep Collection Time: 5.14117
Timestep Consumption Time: 1.95794
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.09911

Cumulative Model Updates: 13122
Cumulative Timesteps: 109715505

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16174.63190
Policy Entropy: 0.32761
Value Function Loss: 0.68553

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.25021
Policy Update Magnitude: 0.07744
Value Function Update Magnitude: 0.11960

Collected Steps per Second: 10055.86852
Overall Steps per Second: 7261.72639

Timestep Collection Time: 4.97421
Timestep Consumption Time: 1.91396
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 6.88817

Cumulative Model Updates: 13128
Cumulative Timesteps: 109765525

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 109765525...
Checkpoint 109765525 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21783.82518
Policy Entropy: 0.32466
Value Function Loss: 0.65731

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.27037
Policy Update Magnitude: 0.07097
Value Function Update Magnitude: 0.11766

Collected Steps per Second: 9987.44741
Overall Steps per Second: 7023.42758

Timestep Collection Time: 5.00859
Timestep Consumption Time: 2.11372
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 7.12231

Cumulative Model Updates: 13134
Cumulative Timesteps: 109815548

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16543.68337
Policy Entropy: 0.32348
Value Function Loss: 0.68088

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.23579
Policy Update Magnitude: 0.07428
Value Function Update Magnitude: 0.11174

Collected Steps per Second: 9526.85795
Overall Steps per Second: 6875.17794

Timestep Collection Time: 5.25157
Timestep Consumption Time: 2.02547
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.27705

Cumulative Model Updates: 13140
Cumulative Timesteps: 109865579

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 109865579...
Checkpoint 109865579 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14474.64694
Policy Entropy: 0.32694
Value Function Loss: 0.65283

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.21330
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.12709

Collected Steps per Second: 9859.70477
Overall Steps per Second: 7091.21703

Timestep Collection Time: 5.07419
Timestep Consumption Time: 1.98102
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.05521

Cumulative Model Updates: 13146
Cumulative Timesteps: 109915609

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17440.74477
Policy Entropy: 0.32750
Value Function Loss: 0.69315

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.20600
Policy Update Magnitude: 0.08941
Value Function Update Magnitude: 0.16848

Collected Steps per Second: 9379.98683
Overall Steps per Second: 6678.38018

Timestep Collection Time: 5.33114
Timestep Consumption Time: 2.15661
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.48774

Cumulative Model Updates: 13152
Cumulative Timesteps: 109965615

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 109965615...
Checkpoint 109965615 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14840.18777
Policy Entropy: 0.33117
Value Function Loss: 0.65141

Mean KL Divergence: 0.02207
SB3 Clip Fraction: 0.21704
Policy Update Magnitude: 0.08215
Value Function Update Magnitude: 0.11484

Collected Steps per Second: 9122.22407
Overall Steps per Second: 6678.69552

Timestep Collection Time: 5.48419
Timestep Consumption Time: 2.00650
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.49068

Cumulative Model Updates: 13158
Cumulative Timesteps: 110015643

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9098.66553
Policy Entropy: 0.34211
Value Function Loss: 0.67747

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.19831
Policy Update Magnitude: 0.07763
Value Function Update Magnitude: 0.09532

Collected Steps per Second: 10298.50149
Overall Steps per Second: 7277.05768

Timestep Collection Time: 4.85741
Timestep Consumption Time: 2.01680
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 6.87421

Cumulative Model Updates: 13164
Cumulative Timesteps: 110065667

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 110065667...
Checkpoint 110065667 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10454.25420
Policy Entropy: 0.34473
Value Function Loss: 0.64680

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.18413
Policy Update Magnitude: 0.07832
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 9303.98745
Overall Steps per Second: 6640.90207

Timestep Collection Time: 5.37490
Timestep Consumption Time: 2.15540
PPO Batch Consumption Time: 0.02465
Total Iteration Time: 7.53030

Cumulative Model Updates: 13170
Cumulative Timesteps: 110115675

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14372.40473
Policy Entropy: 0.34673
Value Function Loss: 0.64349

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.19008
Policy Update Magnitude: 0.08328
Value Function Update Magnitude: 0.11883

Collected Steps per Second: 9767.03215
Overall Steps per Second: 6947.84246

Timestep Collection Time: 5.12131
Timestep Consumption Time: 2.07805
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.19936

Cumulative Model Updates: 13176
Cumulative Timesteps: 110165695

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 110165695...
Checkpoint 110165695 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14098.00138
Policy Entropy: 0.33991
Value Function Loss: 0.66241

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.21263
Policy Update Magnitude: 0.08220
Value Function Update Magnitude: 0.11193

Collected Steps per Second: 10253.88377
Overall Steps per Second: 7257.84088

Timestep Collection Time: 4.87698
Timestep Consumption Time: 2.01322
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.89020

Cumulative Model Updates: 13182
Cumulative Timesteps: 110215703

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11698.94890
Policy Entropy: 0.34905
Value Function Loss: 0.68902

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.23654
Policy Update Magnitude: 0.07456
Value Function Update Magnitude: 0.11144

Collected Steps per Second: 9726.69326
Overall Steps per Second: 6967.15212

Timestep Collection Time: 5.14368
Timestep Consumption Time: 2.03730
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.18098

Cumulative Model Updates: 13188
Cumulative Timesteps: 110265734

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 110265734...
Checkpoint 110265734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9983.51987
Policy Entropy: 0.35233
Value Function Loss: 0.67267

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.22460
Policy Update Magnitude: 0.07351
Value Function Update Magnitude: 0.11505

Collected Steps per Second: 10301.51766
Overall Steps per Second: 7222.41648

Timestep Collection Time: 4.85569
Timestep Consumption Time: 2.07011
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.92580

Cumulative Model Updates: 13194
Cumulative Timesteps: 110315755

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14504.76285
Policy Entropy: 0.35059
Value Function Loss: 0.64912

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.19949
Policy Update Magnitude: 0.07860
Value Function Update Magnitude: 0.13574

Collected Steps per Second: 11128.32146
Overall Steps per Second: 7570.14835

Timestep Collection Time: 4.49367
Timestep Consumption Time: 2.11215
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 6.60582

Cumulative Model Updates: 13200
Cumulative Timesteps: 110365762

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 110365762...
Checkpoint 110365762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18921.98393
Policy Entropy: 0.34703
Value Function Loss: 0.63010

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.20866
Policy Update Magnitude: 0.08324
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 10337.06252
Overall Steps per Second: 7519.71763

Timestep Collection Time: 4.83861
Timestep Consumption Time: 1.81284
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.65145

Cumulative Model Updates: 13206
Cumulative Timesteps: 110415779

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17706.52947
Policy Entropy: 0.34976
Value Function Loss: 0.66905

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15690
Policy Update Magnitude: 0.08636
Value Function Update Magnitude: 0.13117

Collected Steps per Second: 10339.34376
Overall Steps per Second: 7331.97723

Timestep Collection Time: 4.83686
Timestep Consumption Time: 1.98394
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 6.82081

Cumulative Model Updates: 13212
Cumulative Timesteps: 110465789

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 110465789...
Checkpoint 110465789 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11691.84646
Policy Entropy: 0.35510
Value Function Loss: 0.70711

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.16640
Policy Update Magnitude: 0.08405
Value Function Update Magnitude: 0.13072

Collected Steps per Second: 10214.26934
Overall Steps per Second: 7260.49257

Timestep Collection Time: 4.89834
Timestep Consumption Time: 1.99279
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 6.89113

Cumulative Model Updates: 13218
Cumulative Timesteps: 110515822

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13601.87927
Policy Entropy: 0.35153
Value Function Loss: 0.72895

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.18367
Policy Update Magnitude: 0.08857
Value Function Update Magnitude: 0.12440

Collected Steps per Second: 10166.37674
Overall Steps per Second: 7172.43747

Timestep Collection Time: 4.92093
Timestep Consumption Time: 2.05411
PPO Batch Consumption Time: 0.02415
Total Iteration Time: 6.97503

Cumulative Model Updates: 13224
Cumulative Timesteps: 110565850

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 110565850...
Checkpoint 110565850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10404.36258
Policy Entropy: 0.35502
Value Function Loss: 0.68681

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.17266
Policy Update Magnitude: 0.09008
Value Function Update Magnitude: 0.13143

Collected Steps per Second: 9688.74520
Overall Steps per Second: 6881.61608

Timestep Collection Time: 5.16187
Timestep Consumption Time: 2.10561
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 7.26748

Cumulative Model Updates: 13230
Cumulative Timesteps: 110615862

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11211.02459
Policy Entropy: 0.35490
Value Function Loss: 0.70503

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.23622
Policy Update Magnitude: 0.09196
Value Function Update Magnitude: 0.14905

Collected Steps per Second: 9616.43779
Overall Steps per Second: 6799.01176

Timestep Collection Time: 5.20151
Timestep Consumption Time: 2.15544
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.35695

Cumulative Model Updates: 13236
Cumulative Timesteps: 110665882

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 110665882...
Checkpoint 110665882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22978.01423
Policy Entropy: 0.36975
Value Function Loss: 0.69639

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.17831
Policy Update Magnitude: 0.08911
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 9345.68808
Overall Steps per Second: 6768.67613

Timestep Collection Time: 5.35145
Timestep Consumption Time: 2.03744
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.38889

Cumulative Model Updates: 13242
Cumulative Timesteps: 110715895

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10294.69177
Policy Entropy: 0.38048
Value Function Loss: 0.71704

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.22086
Policy Update Magnitude: 0.09236
Value Function Update Magnitude: 0.11304

Collected Steps per Second: 9202.39986
Overall Steps per Second: 6705.65885

Timestep Collection Time: 5.43793
Timestep Consumption Time: 2.02472
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 7.46265

Cumulative Model Updates: 13248
Cumulative Timesteps: 110765937

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 110765937...
Checkpoint 110765937 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12500.38354
Policy Entropy: 0.38106
Value Function Loss: 0.66523

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.21058
Policy Update Magnitude: 0.08810
Value Function Update Magnitude: 0.10694

Collected Steps per Second: 9652.84999
Overall Steps per Second: 6938.66515

Timestep Collection Time: 5.18438
Timestep Consumption Time: 2.02796
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 7.21234

Cumulative Model Updates: 13254
Cumulative Timesteps: 110815981

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18498.01746
Policy Entropy: 0.38544
Value Function Loss: 0.65114

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.22474
Policy Update Magnitude: 0.08231
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 9459.82366
Overall Steps per Second: 6764.94624

Timestep Collection Time: 5.28636
Timestep Consumption Time: 2.10587
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.39222

Cumulative Model Updates: 13260
Cumulative Timesteps: 110865989

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 110865989...
Checkpoint 110865989 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15874.21887
Policy Entropy: 0.38303
Value Function Loss: 0.64451

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.21846
Policy Update Magnitude: 0.07960
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 9249.94775
Overall Steps per Second: 6786.22996

Timestep Collection Time: 5.40846
Timestep Consumption Time: 1.96352
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.37199

Cumulative Model Updates: 13266
Cumulative Timesteps: 110916017

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14349.44497
Policy Entropy: 0.40991
Value Function Loss: 0.63881

Mean KL Divergence: 0.02598
SB3 Clip Fraction: 0.26440
Policy Update Magnitude: 0.08418
Value Function Update Magnitude: 0.10360

Collected Steps per Second: 9410.50695
Overall Steps per Second: 6729.83290

Timestep Collection Time: 5.31555
Timestep Consumption Time: 2.11733
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.43287

Cumulative Model Updates: 13272
Cumulative Timesteps: 110966039

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 110966039...
Checkpoint 110966039 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21451.77216
Policy Entropy: 0.40131
Value Function Loss: 0.64918

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.27365
Policy Update Magnitude: 0.07978
Value Function Update Magnitude: 0.10570

Collected Steps per Second: 9662.57090
Overall Steps per Second: 6914.88030

Timestep Collection Time: 5.17844
Timestep Consumption Time: 2.05770
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.23613

Cumulative Model Updates: 13278
Cumulative Timesteps: 111016076

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12373.10788
Policy Entropy: 0.42666
Value Function Loss: 0.65767

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.28428
Policy Update Magnitude: 0.08007
Value Function Update Magnitude: 0.11355

Collected Steps per Second: 10175.67842
Overall Steps per Second: 7233.12414

Timestep Collection Time: 4.91692
Timestep Consumption Time: 2.00028
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.91720

Cumulative Model Updates: 13284
Cumulative Timesteps: 111066109

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 111066109...
Checkpoint 111066109 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12433.45020
Policy Entropy: 0.41646
Value Function Loss: 0.65293

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.25041
Policy Update Magnitude: 0.08520
Value Function Update Magnitude: 0.12718

Collected Steps per Second: 9572.49655
Overall Steps per Second: 6924.60468

Timestep Collection Time: 5.22361
Timestep Consumption Time: 1.99745
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.22106

Cumulative Model Updates: 13290
Cumulative Timesteps: 111116112

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20453.85159
Policy Entropy: 0.43221
Value Function Loss: 0.64380

Mean KL Divergence: 0.02833
SB3 Clip Fraction: 0.26735
Policy Update Magnitude: 0.08389
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 10019.77342
Overall Steps per Second: 7145.51196

Timestep Collection Time: 4.99243
Timestep Consumption Time: 2.00819
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.00062

Cumulative Model Updates: 13296
Cumulative Timesteps: 111166135

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 111166135...
Checkpoint 111166135 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17603.30599
Policy Entropy: 0.42988
Value Function Loss: 0.62516

Mean KL Divergence: 0.04050
SB3 Clip Fraction: 0.31067
Policy Update Magnitude: 0.08076
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 10582.91988
Overall Steps per Second: 7545.82464

Timestep Collection Time: 4.72790
Timestep Consumption Time: 1.90292
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 6.63082

Cumulative Model Updates: 13302
Cumulative Timesteps: 111216170

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15778.63902
Policy Entropy: 0.44450
Value Function Loss: 0.63599

Mean KL Divergence: 0.04329
SB3 Clip Fraction: 0.31188
Policy Update Magnitude: 0.07722
Value Function Update Magnitude: 0.10334

Collected Steps per Second: 10042.18386
Overall Steps per Second: 7259.12286

Timestep Collection Time: 4.98079
Timestep Consumption Time: 1.90958
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 6.89036

Cumulative Model Updates: 13308
Cumulative Timesteps: 111266188

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 111266188...
Checkpoint 111266188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12472.12244
Policy Entropy: 0.46247
Value Function Loss: 0.62960

Mean KL Divergence: 0.04252
SB3 Clip Fraction: 0.32262
Policy Update Magnitude: 0.07894
Value Function Update Magnitude: 0.14050

Collected Steps per Second: 10064.39432
Overall Steps per Second: 7315.26978

Timestep Collection Time: 4.97010
Timestep Consumption Time: 1.86779
PPO Batch Consumption Time: 0.02433
Total Iteration Time: 6.83789

Cumulative Model Updates: 13314
Cumulative Timesteps: 111316209

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23887.22036
Policy Entropy: 0.46113
Value Function Loss: 0.62102

Mean KL Divergence: 0.04381
SB3 Clip Fraction: 0.31200
Policy Update Magnitude: 0.08408
Value Function Update Magnitude: 0.16864

Collected Steps per Second: 9846.50694
Overall Steps per Second: 7168.49574

Timestep Collection Time: 5.08140
Timestep Consumption Time: 1.89831
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.97971

Cumulative Model Updates: 13320
Cumulative Timesteps: 111366243

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 111366243...
Checkpoint 111366243 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17700.79475
Policy Entropy: 0.47757
Value Function Loss: 0.63403

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.26310
Policy Update Magnitude: 0.08368
Value Function Update Magnitude: 0.15648

Collected Steps per Second: 10007.94237
Overall Steps per Second: 7174.75432

Timestep Collection Time: 4.99663
Timestep Consumption Time: 1.97308
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.96972

Cumulative Model Updates: 13326
Cumulative Timesteps: 111416249

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13980.86720
Policy Entropy: 0.48936
Value Function Loss: 0.66490

Mean KL Divergence: 0.02544
SB3 Clip Fraction: 0.28884
Policy Update Magnitude: 0.08615
Value Function Update Magnitude: 0.13129

Collected Steps per Second: 10597.03667
Overall Steps per Second: 7335.72735

Timestep Collection Time: 4.72113
Timestep Consumption Time: 2.09892
PPO Batch Consumption Time: 0.02461
Total Iteration Time: 6.82005

Cumulative Model Updates: 13332
Cumulative Timesteps: 111466279

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 111466279...
Checkpoint 111466279 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10771.13473
Policy Entropy: 0.49529
Value Function Loss: 0.66138

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.26675
Policy Update Magnitude: 0.08119
Value Function Update Magnitude: 0.13033

Collected Steps per Second: 9448.76668
Overall Steps per Second: 6913.78419

Timestep Collection Time: 5.29424
Timestep Consumption Time: 1.94116
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.23540

Cumulative Model Updates: 13338
Cumulative Timesteps: 111516303

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21190.73056
Policy Entropy: 0.50145
Value Function Loss: 0.63998

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.27725
Policy Update Magnitude: 0.08287
Value Function Update Magnitude: 0.11687

Collected Steps per Second: 9399.37346
Overall Steps per Second: 6628.75545

Timestep Collection Time: 5.32259
Timestep Consumption Time: 2.22468
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.54727

Cumulative Model Updates: 13344
Cumulative Timesteps: 111566332

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 111566332...
Checkpoint 111566332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20427.30955
Policy Entropy: 0.49191
Value Function Loss: 0.60261

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.19382
Policy Update Magnitude: 0.08434
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 10109.88545
Overall Steps per Second: 6890.69053

Timestep Collection Time: 4.94991
Timestep Consumption Time: 2.31250
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.26241

Cumulative Model Updates: 13350
Cumulative Timesteps: 111616375

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11706.14988
Policy Entropy: 0.49505
Value Function Loss: 0.63572

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.22899
Policy Update Magnitude: 0.08594
Value Function Update Magnitude: 0.14494

Collected Steps per Second: 10453.91182
Overall Steps per Second: 7266.17233

Timestep Collection Time: 4.78558
Timestep Consumption Time: 2.09948
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 6.88506

Cumulative Model Updates: 13356
Cumulative Timesteps: 111666403

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 111666403...
Checkpoint 111666403 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13436.53470
Policy Entropy: 0.49753
Value Function Loss: 0.63655

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.27315
Policy Update Magnitude: 0.08069
Value Function Update Magnitude: 0.15435

Collected Steps per Second: 10141.12375
Overall Steps per Second: 7257.62856

Timestep Collection Time: 4.93338
Timestep Consumption Time: 1.96006
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 6.89344

Cumulative Model Updates: 13362
Cumulative Timesteps: 111716433

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11241.60294
Policy Entropy: 0.49347
Value Function Loss: 0.65571

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.26567
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.15563

Collected Steps per Second: 9810.48211
Overall Steps per Second: 6951.74796

Timestep Collection Time: 5.09985
Timestep Consumption Time: 2.09719
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.19704

Cumulative Model Updates: 13368
Cumulative Timesteps: 111766465

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 111766465...
Checkpoint 111766465 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14712.93456
Policy Entropy: 0.50619
Value Function Loss: 0.64480

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.26780
Policy Update Magnitude: 0.08059
Value Function Update Magnitude: 0.13072

Collected Steps per Second: 9157.60391
Overall Steps per Second: 6606.03775

Timestep Collection Time: 5.46475
Timestep Consumption Time: 2.11075
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.57549

Cumulative Model Updates: 13374
Cumulative Timesteps: 111816509

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12892.05905
Policy Entropy: 0.49137
Value Function Loss: 0.65832

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.18172
Policy Update Magnitude: 0.09168
Value Function Update Magnitude: 0.13240

Collected Steps per Second: 9947.64599
Overall Steps per Second: 7187.71147

Timestep Collection Time: 5.03074
Timestep Consumption Time: 1.93170
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 6.96244

Cumulative Model Updates: 13380
Cumulative Timesteps: 111866553

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 111866553...
Checkpoint 111866553 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11160.29756
Policy Entropy: 0.48947
Value Function Loss: 0.63778

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.23493
Policy Update Magnitude: 0.10174
Value Function Update Magnitude: 0.14861

Collected Steps per Second: 9700.87412
Overall Steps per Second: 6940.56410

Timestep Collection Time: 5.15696
Timestep Consumption Time: 2.05096
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.20792

Cumulative Model Updates: 13386
Cumulative Timesteps: 111916580

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7561.01446
Policy Entropy: 0.49460
Value Function Loss: 0.64238

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.26298
Policy Update Magnitude: 0.08906
Value Function Update Magnitude: 0.14491

Collected Steps per Second: 9325.89558
Overall Steps per Second: 6693.04992

Timestep Collection Time: 5.36152
Timestep Consumption Time: 2.10906
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.47059

Cumulative Model Updates: 13392
Cumulative Timesteps: 111966581

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 111966581...
Checkpoint 111966581 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19130.32465
Policy Entropy: 0.50113
Value Function Loss: 0.64959

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.26658
Policy Update Magnitude: 0.07991
Value Function Update Magnitude: 0.14832

Collected Steps per Second: 9634.36065
Overall Steps per Second: 6879.91277

Timestep Collection Time: 5.19142
Timestep Consumption Time: 2.07844
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 7.26986

Cumulative Model Updates: 13398
Cumulative Timesteps: 112016597

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14699.19434
Policy Entropy: 0.50840
Value Function Loss: 0.66440

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.19185
Policy Update Magnitude: 0.09367
Value Function Update Magnitude: 0.15606

Collected Steps per Second: 9095.93259
Overall Steps per Second: 6628.16824

Timestep Collection Time: 5.49861
Timestep Consumption Time: 2.04721
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.54583

Cumulative Model Updates: 13404
Cumulative Timesteps: 112066612

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 112066612...
Checkpoint 112066612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8898.62162
Policy Entropy: 0.50530
Value Function Loss: 0.67082

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.25175
Policy Update Magnitude: 0.10279
Value Function Update Magnitude: 0.14254

Collected Steps per Second: 9920.16838
Overall Steps per Second: 7130.29883

Timestep Collection Time: 5.04447
Timestep Consumption Time: 1.97375
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.01822

Cumulative Model Updates: 13410
Cumulative Timesteps: 112116654

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9970.18848
Policy Entropy: 0.50952
Value Function Loss: 0.65623

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.22565
Policy Update Magnitude: 0.08404
Value Function Update Magnitude: 0.14513

Collected Steps per Second: 10334.59765
Overall Steps per Second: 7417.26061

Timestep Collection Time: 4.83947
Timestep Consumption Time: 1.90345
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 6.74292

Cumulative Model Updates: 13416
Cumulative Timesteps: 112166668

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 112166668...
Checkpoint 112166668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13949.48333
Policy Entropy: 0.49799
Value Function Loss: 0.60377

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.18320
Policy Update Magnitude: 0.08682
Value Function Update Magnitude: 0.18263

Collected Steps per Second: 9908.75170
Overall Steps per Second: 7181.45171

Timestep Collection Time: 5.04645
Timestep Consumption Time: 1.91649
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 6.96294

Cumulative Model Updates: 13422
Cumulative Timesteps: 112216672

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14283.51356
Policy Entropy: 0.48899
Value Function Loss: 0.59252

Mean KL Divergence: 0.02832
SB3 Clip Fraction: 0.26038
Policy Update Magnitude: 0.08913
Value Function Update Magnitude: 0.16420

Collected Steps per Second: 9285.25319
Overall Steps per Second: 6745.30244

Timestep Collection Time: 5.38618
Timestep Consumption Time: 2.02817
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.41435

Cumulative Model Updates: 13428
Cumulative Timesteps: 112266684

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 112266684...
Checkpoint 112266684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20948.05657
Policy Entropy: 0.48914
Value Function Loss: 0.58778

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.18383
Policy Update Magnitude: 0.08264
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 10045.69487
Overall Steps per Second: 7017.20176

Timestep Collection Time: 4.97875
Timestep Consumption Time: 2.14874
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.12748

Cumulative Model Updates: 13434
Cumulative Timesteps: 112316699

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24077.80984
Policy Entropy: 0.49200
Value Function Loss: 0.61163

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.18253
Policy Update Magnitude: 0.09219
Value Function Update Magnitude: 0.11583

Collected Steps per Second: 9473.23322
Overall Steps per Second: 6781.20773

Timestep Collection Time: 5.27961
Timestep Consumption Time: 2.09592
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.37553

Cumulative Model Updates: 13440
Cumulative Timesteps: 112366714

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 112366714...
Checkpoint 112366714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12761.84744
Policy Entropy: 0.47557
Value Function Loss: 0.62341

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.17743
Policy Update Magnitude: 0.10086
Value Function Update Magnitude: 0.11105

Collected Steps per Second: 9758.03995
Overall Steps per Second: 6909.59391

Timestep Collection Time: 5.12880
Timestep Consumption Time: 2.11432
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.24312

Cumulative Model Updates: 13446
Cumulative Timesteps: 112416761

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8684.92239
Policy Entropy: 0.47069
Value Function Loss: 0.61654

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.19740
Policy Update Magnitude: 0.09682
Value Function Update Magnitude: 0.11484

Collected Steps per Second: 10010.19251
Overall Steps per Second: 7063.32566

Timestep Collection Time: 4.99890
Timestep Consumption Time: 2.08558
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 7.08448

Cumulative Model Updates: 13452
Cumulative Timesteps: 112466801

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 112466801...
Checkpoint 112466801 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14140.63125
Policy Entropy: 0.46377
Value Function Loss: 0.60510

Mean KL Divergence: 0.02298
SB3 Clip Fraction: 0.24472
Policy Update Magnitude: 0.09015
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 9496.42779
Overall Steps per Second: 6780.88327

Timestep Collection Time: 5.26745
Timestep Consumption Time: 2.10946
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.37692

Cumulative Model Updates: 13458
Cumulative Timesteps: 112516823

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14668.54800
Policy Entropy: 0.47368
Value Function Loss: 0.59645

Mean KL Divergence: 0.02545
SB3 Clip Fraction: 0.23306
Policy Update Magnitude: 0.08971
Value Function Update Magnitude: 0.13065

Collected Steps per Second: 9411.17445
Overall Steps per Second: 6813.96386

Timestep Collection Time: 5.31400
Timestep Consumption Time: 2.02549
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 7.33949

Cumulative Model Updates: 13464
Cumulative Timesteps: 112566834

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 112566834...
Checkpoint 112566834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11206.28912
Policy Entropy: 0.46758
Value Function Loss: 0.59829

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.19689
Policy Update Magnitude: 0.09390
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 9492.88773
Overall Steps per Second: 6934.63058

Timestep Collection Time: 5.27174
Timestep Consumption Time: 1.94480
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.21653

Cumulative Model Updates: 13470
Cumulative Timesteps: 112616878

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15194.44403
Policy Entropy: 0.46940
Value Function Loss: 0.60237

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.22594
Policy Update Magnitude: 0.08652
Value Function Update Magnitude: 0.12658

Collected Steps per Second: 9315.91060
Overall Steps per Second: 6733.70055

Timestep Collection Time: 5.36899
Timestep Consumption Time: 2.05888
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.42786

Cumulative Model Updates: 13476
Cumulative Timesteps: 112666895

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 112666895...
Checkpoint 112666895 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14254.55646
Policy Entropy: 0.46992
Value Function Loss: 0.60862

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.19784
Policy Update Magnitude: 0.08903
Value Function Update Magnitude: 0.11068

Collected Steps per Second: 9616.37166
Overall Steps per Second: 6929.62344

Timestep Collection Time: 5.20144
Timestep Consumption Time: 2.01670
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.21814

Cumulative Model Updates: 13482
Cumulative Timesteps: 112716914

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13343.38326
Policy Entropy: 0.47335
Value Function Loss: 0.62569

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.09533
Value Function Update Magnitude: 0.11135

Collected Steps per Second: 9998.17444
Overall Steps per Second: 7059.61218

Timestep Collection Time: 5.00531
Timestep Consumption Time: 2.08346
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.08877

Cumulative Model Updates: 13488
Cumulative Timesteps: 112766958

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 112766958...
Checkpoint 112766958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13636.48121
Policy Entropy: 0.46320
Value Function Loss: 0.64999

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.20204
Policy Update Magnitude: 0.09741
Value Function Update Magnitude: 0.11008

Collected Steps per Second: 9521.63644
Overall Steps per Second: 6955.21761

Timestep Collection Time: 5.25361
Timestep Consumption Time: 1.93854
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.19215

Cumulative Model Updates: 13494
Cumulative Timesteps: 112816981

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19520.21009
Policy Entropy: 0.47002
Value Function Loss: 0.62901

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.20461
Policy Update Magnitude: 0.08858
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 9810.68203
Overall Steps per Second: 7038.61727

Timestep Collection Time: 5.09700
Timestep Consumption Time: 2.00738
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.10438

Cumulative Model Updates: 13500
Cumulative Timesteps: 112866986

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 112866986...
Checkpoint 112866986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17840.62620
Policy Entropy: 0.46966
Value Function Loss: 0.61593

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.24908
Policy Update Magnitude: 0.08814
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 9984.14785
Overall Steps per Second: 7201.83653

Timestep Collection Time: 5.00944
Timestep Consumption Time: 1.93532
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 6.94476

Cumulative Model Updates: 13506
Cumulative Timesteps: 112917001

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19402.19461
Policy Entropy: 0.47383
Value Function Loss: 0.57850

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.22244
Policy Update Magnitude: 0.08450
Value Function Update Magnitude: 0.10787

Collected Steps per Second: 9890.67424
Overall Steps per Second: 7178.20013

Timestep Collection Time: 5.05921
Timestep Consumption Time: 1.91176
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 6.97097

Cumulative Model Updates: 13512
Cumulative Timesteps: 112967040

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 112967040...
Checkpoint 112967040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17590.14286
Policy Entropy: 0.47728
Value Function Loss: 0.57901

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.24749
Policy Update Magnitude: 0.08384
Value Function Update Magnitude: 0.10020

Collected Steps per Second: 10014.61493
Overall Steps per Second: 7275.39300

Timestep Collection Time: 4.99740
Timestep Consumption Time: 1.88154
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 6.87894

Cumulative Model Updates: 13518
Cumulative Timesteps: 113017087

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15787.75846
Policy Entropy: 0.46730
Value Function Loss: 0.57561

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.18307
Policy Update Magnitude: 0.09329
Value Function Update Magnitude: 0.10904

Collected Steps per Second: 10031.85166
Overall Steps per Second: 7257.35885

Timestep Collection Time: 4.98632
Timestep Consumption Time: 1.90627
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 6.89259

Cumulative Model Updates: 13524
Cumulative Timesteps: 113067109

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 113067109...
Checkpoint 113067109 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15229.84158
Policy Entropy: 0.46786
Value Function Loss: 0.54954

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.18662
Policy Update Magnitude: 0.11588
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 9909.85153
Overall Steps per Second: 7223.33502

Timestep Collection Time: 5.04962
Timestep Consumption Time: 1.87806
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 6.92769

Cumulative Model Updates: 13530
Cumulative Timesteps: 113117150

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16825.75134
Policy Entropy: 0.47094
Value Function Loss: 0.55558

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.19799
Policy Update Magnitude: 0.10039
Value Function Update Magnitude: 0.11370

Collected Steps per Second: 10009.67285
Overall Steps per Second: 7251.77185

Timestep Collection Time: 4.99767
Timestep Consumption Time: 1.90065
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 6.89831

Cumulative Model Updates: 13536
Cumulative Timesteps: 113167175

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 113167175...
Checkpoint 113167175 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22295.15334
Policy Entropy: 0.47082
Value Function Loss: 0.56599

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.18914
Policy Update Magnitude: 0.08834
Value Function Update Magnitude: 0.11267

Collected Steps per Second: 9538.73589
Overall Steps per Second: 6890.19695

Timestep Collection Time: 5.24199
Timestep Consumption Time: 2.01498
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 7.25698

Cumulative Model Updates: 13542
Cumulative Timesteps: 113217177

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21069.43055
Policy Entropy: 0.47203
Value Function Loss: 0.56991

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.17543
Policy Update Magnitude: 0.08943
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 9275.11995
Overall Steps per Second: 6684.25911

Timestep Collection Time: 5.39325
Timestep Consumption Time: 2.09046
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.48370

Cumulative Model Updates: 13548
Cumulative Timesteps: 113267200

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 113267200...
Checkpoint 113267200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29249.99656
Policy Entropy: 0.46639
Value Function Loss: 0.53843

Mean KL Divergence: 0.02710
SB3 Clip Fraction: 0.24774
Policy Update Magnitude: 0.08867
Value Function Update Magnitude: 0.13117

Collected Steps per Second: 9441.48012
Overall Steps per Second: 6803.52957

Timestep Collection Time: 5.30076
Timestep Consumption Time: 2.05528
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.35603

Cumulative Model Updates: 13554
Cumulative Timesteps: 113317247

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21350.98776
Policy Entropy: 0.47311
Value Function Loss: 0.54150

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.24598
Policy Update Magnitude: 0.07963
Value Function Update Magnitude: 0.10885

Collected Steps per Second: 9924.10952
Overall Steps per Second: 7021.57073

Timestep Collection Time: 5.04186
Timestep Consumption Time: 2.08418
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 7.12604

Cumulative Model Updates: 13560
Cumulative Timesteps: 113367283

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 113367283...
Checkpoint 113367283 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16483.77313
Policy Entropy: 0.48253
Value Function Loss: 0.56707

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.25439
Policy Update Magnitude: 0.07968
Value Function Update Magnitude: 0.12018

Collected Steps per Second: 9406.20369
Overall Steps per Second: 6757.86592

Timestep Collection Time: 5.31968
Timestep Consumption Time: 2.08473
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.40441

Cumulative Model Updates: 13566
Cumulative Timesteps: 113417321

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33391.78942
Policy Entropy: 0.48790
Value Function Loss: 0.58803

Mean KL Divergence: 0.02843
SB3 Clip Fraction: 0.28464
Policy Update Magnitude: 0.07540
Value Function Update Magnitude: 0.14154

Collected Steps per Second: 9753.71883
Overall Steps per Second: 7012.90959

Timestep Collection Time: 5.13076
Timestep Consumption Time: 2.00522
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.13598

Cumulative Model Updates: 13572
Cumulative Timesteps: 113467365

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 113467365...
Checkpoint 113467365 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34024.51816
Policy Entropy: 0.49738
Value Function Loss: 0.57691

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.20701
Policy Update Magnitude: 0.08068
Value Function Update Magnitude: 0.15582

Collected Steps per Second: 9538.76656
Overall Steps per Second: 6805.11547

Timestep Collection Time: 5.24470
Timestep Consumption Time: 2.10683
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.35153

Cumulative Model Updates: 13578
Cumulative Timesteps: 113517393

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25238.26324
Policy Entropy: 0.49597
Value Function Loss: 0.57086

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.22082
Policy Update Magnitude: 0.09191
Value Function Update Magnitude: 0.17119

Collected Steps per Second: 9743.02954
Overall Steps per Second: 6915.51510

Timestep Collection Time: 5.13413
Timestep Consumption Time: 2.09917
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 7.23330

Cumulative Model Updates: 13584
Cumulative Timesteps: 113567415

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 113567415...
Checkpoint 113567415 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25465.81452
Policy Entropy: 0.51216
Value Function Loss: 0.55403

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.25268
Policy Update Magnitude: 0.08743
Value Function Update Magnitude: 0.20505

Collected Steps per Second: 9345.72200
Overall Steps per Second: 6507.74030

Timestep Collection Time: 5.35282
Timestep Consumption Time: 2.33433
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.68715

Cumulative Model Updates: 13590
Cumulative Timesteps: 113617441

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17381.27659
Policy Entropy: 0.50494
Value Function Loss: 0.55984

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.24851
Policy Update Magnitude: 0.08399
Value Function Update Magnitude: 0.18249

Collected Steps per Second: 10178.37213
Overall Steps per Second: 6959.09223

Timestep Collection Time: 4.91464
Timestep Consumption Time: 2.27351
PPO Batch Consumption Time: 0.02429
Total Iteration Time: 7.18815

Cumulative Model Updates: 13596
Cumulative Timesteps: 113667464

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 113667464...
Checkpoint 113667464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21081.97622
Policy Entropy: 0.50941
Value Function Loss: 0.58719

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.17450
Policy Update Magnitude: 0.09275
Value Function Update Magnitude: 0.13861

Collected Steps per Second: 9904.70476
Overall Steps per Second: 7140.77430

Timestep Collection Time: 5.04952
Timestep Consumption Time: 1.95448
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.00400

Cumulative Model Updates: 13602
Cumulative Timesteps: 113717478

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15397.56049
Policy Entropy: 0.50879
Value Function Loss: 0.60539

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.19020
Policy Update Magnitude: 0.10331
Value Function Update Magnitude: 0.12878

Collected Steps per Second: 9476.94569
Overall Steps per Second: 6804.61513

Timestep Collection Time: 5.27670
Timestep Consumption Time: 2.07228
PPO Batch Consumption Time: 0.02459
Total Iteration Time: 7.34898

Cumulative Model Updates: 13608
Cumulative Timesteps: 113767485

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 113767485...
Checkpoint 113767485 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9651.45149
Policy Entropy: 0.50788
Value Function Loss: 0.60754

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.22968
Policy Update Magnitude: 0.09886
Value Function Update Magnitude: 0.13617

Collected Steps per Second: 10070.99982
Overall Steps per Second: 7129.58732

Timestep Collection Time: 4.96723
Timestep Consumption Time: 2.04930
PPO Batch Consumption Time: 0.02464
Total Iteration Time: 7.01654

Cumulative Model Updates: 13614
Cumulative Timesteps: 113817510

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11516.75214
Policy Entropy: 0.50885
Value Function Loss: 0.59326

Mean KL Divergence: 0.02414
SB3 Clip Fraction: 0.26968
Policy Update Magnitude: 0.09120
Value Function Update Magnitude: 0.18519

Collected Steps per Second: 10415.75055
Overall Steps per Second: 7399.62196

Timestep Collection Time: 4.80129
Timestep Consumption Time: 1.95703
PPO Batch Consumption Time: 0.02395
Total Iteration Time: 6.75832

Cumulative Model Updates: 13620
Cumulative Timesteps: 113867519

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 113867519...
Checkpoint 113867519 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14574.55403
Policy Entropy: 0.52449
Value Function Loss: 0.59887

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.20981
Policy Update Magnitude: 0.09412
Value Function Update Magnitude: 0.16405

Collected Steps per Second: 10021.47882
Overall Steps per Second: 7083.33650

Timestep Collection Time: 4.99008
Timestep Consumption Time: 2.06987
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.05995

Cumulative Model Updates: 13626
Cumulative Timesteps: 113917527

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12151.08935
Policy Entropy: 0.53883
Value Function Loss: 0.61701

Mean KL Divergence: 0.02613
SB3 Clip Fraction: 0.26030
Policy Update Magnitude: 0.10714
Value Function Update Magnitude: 0.20370

Collected Steps per Second: 9847.87016
Overall Steps per Second: 7117.13250

Timestep Collection Time: 5.07917
Timestep Consumption Time: 1.94880
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 7.02797

Cumulative Model Updates: 13632
Cumulative Timesteps: 113967546

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 113967546...
Checkpoint 113967546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13402.22651
Policy Entropy: 0.54343
Value Function Loss: 0.62173

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.22483
Policy Update Magnitude: 0.09887
Value Function Update Magnitude: 0.23717

Collected Steps per Second: 10030.55729
Overall Steps per Second: 7198.41168

Timestep Collection Time: 4.98586
Timestep Consumption Time: 1.96164
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 6.94750

Cumulative Model Updates: 13638
Cumulative Timesteps: 114017557

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20757.05576
Policy Entropy: 0.53799
Value Function Loss: 0.60786

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.24957
Policy Update Magnitude: 0.08480
Value Function Update Magnitude: 0.21410

Collected Steps per Second: 9908.66641
Overall Steps per Second: 7119.79180

Timestep Collection Time: 5.04669
Timestep Consumption Time: 1.97683
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.02352

Cumulative Model Updates: 13644
Cumulative Timesteps: 114067563

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 114067563...
Checkpoint 114067563 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13336.17130
Policy Entropy: 0.54608
Value Function Loss: 0.59186

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.18462
Policy Update Magnitude: 0.08378
Value Function Update Magnitude: 0.15743

Collected Steps per Second: 9292.42664
Overall Steps per Second: 6763.96151

Timestep Collection Time: 5.38428
Timestep Consumption Time: 2.01272
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.39700

Cumulative Model Updates: 13650
Cumulative Timesteps: 114117596

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17366.74282
Policy Entropy: 0.53219
Value Function Loss: 0.57794

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.20562
Policy Update Magnitude: 0.09397
Value Function Update Magnitude: 0.12582

Collected Steps per Second: 9635.80594
Overall Steps per Second: 6994.00302

Timestep Collection Time: 5.19064
Timestep Consumption Time: 1.96063
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.15127

Cumulative Model Updates: 13656
Cumulative Timesteps: 114167612

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 114167612...
Checkpoint 114167612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15807.67525
Policy Entropy: 0.54393
Value Function Loss: 0.58771

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.23253
Policy Update Magnitude: 0.09050
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 9064.34305
Overall Steps per Second: 6565.82317

Timestep Collection Time: 5.51998
Timestep Consumption Time: 2.10054
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 7.62052

Cumulative Model Updates: 13662
Cumulative Timesteps: 114217647

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13433.45094
Policy Entropy: 0.52978
Value Function Loss: 0.57277

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.19028
Policy Update Magnitude: 0.10273
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 9335.17308
Overall Steps per Second: 6799.92592

Timestep Collection Time: 5.35780
Timestep Consumption Time: 1.99757
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.35537

Cumulative Model Updates: 13668
Cumulative Timesteps: 114267663

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 114267663...
Checkpoint 114267663 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20855.02342
Policy Entropy: 0.53976
Value Function Loss: 0.57497

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.19242
Policy Update Magnitude: 0.12856
Value Function Update Magnitude: 0.12226

Collected Steps per Second: 10070.24471
Overall Steps per Second: 7117.94006

Timestep Collection Time: 4.96552
Timestep Consumption Time: 2.05955
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.02507

Cumulative Model Updates: 13674
Cumulative Timesteps: 114317667

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14048.64035
Policy Entropy: 0.53837
Value Function Loss: 0.57788

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.22070
Policy Update Magnitude: 0.10990
Value Function Update Magnitude: 0.11981

Collected Steps per Second: 9151.63439
Overall Steps per Second: 6645.13997

Timestep Collection Time: 5.46602
Timestep Consumption Time: 2.06174
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.52776

Cumulative Model Updates: 13680
Cumulative Timesteps: 114367690

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 114367690...
Checkpoint 114367690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14413.29059
Policy Entropy: 0.56379
Value Function Loss: 0.59427

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.24461
Policy Update Magnitude: 0.10212
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 9354.03956
Overall Steps per Second: 6748.74038

Timestep Collection Time: 5.34603
Timestep Consumption Time: 2.06379
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.40983

Cumulative Model Updates: 13686
Cumulative Timesteps: 114417697

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22566.36328
Policy Entropy: 0.55306
Value Function Loss: 0.60018

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.27760
Policy Update Magnitude: 0.09693
Value Function Update Magnitude: 0.17548

Collected Steps per Second: 10096.73551
Overall Steps per Second: 7053.54884

Timestep Collection Time: 4.95259
Timestep Consumption Time: 2.13675
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.08934

Cumulative Model Updates: 13692
Cumulative Timesteps: 114467702

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 114467702...
Checkpoint 114467702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16312.36700
Policy Entropy: 0.55587
Value Function Loss: 0.61198

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.22092
Policy Update Magnitude: 0.09920
Value Function Update Magnitude: 0.16195

Collected Steps per Second: 9091.64053
Overall Steps per Second: 6570.02158

Timestep Collection Time: 5.50319
Timestep Consumption Time: 2.11216
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.61535

Cumulative Model Updates: 13698
Cumulative Timesteps: 114517735

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22157.94361
Policy Entropy: 0.55513
Value Function Loss: 0.60510

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.20817
Policy Update Magnitude: 0.10050
Value Function Update Magnitude: 0.12475

Collected Steps per Second: 9879.71100
Overall Steps per Second: 7155.54510

Timestep Collection Time: 5.06320
Timestep Consumption Time: 1.92760
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 6.99080

Cumulative Model Updates: 13704
Cumulative Timesteps: 114567758

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 114567758...
Checkpoint 114567758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18782.60309
Policy Entropy: 0.57209
Value Function Loss: 0.59846

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.20369
Policy Update Magnitude: 0.11828
Value Function Update Magnitude: 0.12250

Collected Steps per Second: 9605.82367
Overall Steps per Second: 6931.41610

Timestep Collection Time: 5.20799
Timestep Consumption Time: 2.00944
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.21743

Cumulative Model Updates: 13710
Cumulative Timesteps: 114617785

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15573.05448
Policy Entropy: 0.58314
Value Function Loss: 0.60943

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.20635
Policy Update Magnitude: 0.11296
Value Function Update Magnitude: 0.12436

Collected Steps per Second: 10055.90220
Overall Steps per Second: 6853.83354

Timestep Collection Time: 4.97568
Timestep Consumption Time: 2.32461
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 7.30029

Cumulative Model Updates: 13716
Cumulative Timesteps: 114667820

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 114667820...
Checkpoint 114667820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14859.95913
Policy Entropy: 0.57487
Value Function Loss: 0.60649

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.24815
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.13549

Collected Steps per Second: 10425.12421
Overall Steps per Second: 7114.02372

Timestep Collection Time: 4.79812
Timestep Consumption Time: 2.23320
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.03132

Cumulative Model Updates: 13722
Cumulative Timesteps: 114717841

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12475.85842
Policy Entropy: 0.58390
Value Function Loss: 0.60088

Mean KL Divergence: 0.02251
SB3 Clip Fraction: 0.25007
Policy Update Magnitude: 0.10132
Value Function Update Magnitude: 0.13442

Collected Steps per Second: 10444.24553
Overall Steps per Second: 7146.13991

Timestep Collection Time: 4.79001
Timestep Consumption Time: 2.21070
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.00070

Cumulative Model Updates: 13728
Cumulative Timesteps: 114767869

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 114767869...
Checkpoint 114767869 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16658.32044
Policy Entropy: 0.57829
Value Function Loss: 0.58302

Mean KL Divergence: 0.03258
SB3 Clip Fraction: 0.32334
Policy Update Magnitude: 0.09166
Value Function Update Magnitude: 0.11899

Collected Steps per Second: 10063.92448
Overall Steps per Second: 7235.16991

Timestep Collection Time: 4.97053
Timestep Consumption Time: 1.94334
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.91387

Cumulative Model Updates: 13734
Cumulative Timesteps: 114817892

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16751.19248
Policy Entropy: 0.58653
Value Function Loss: 0.58021

Mean KL Divergence: 0.03043
SB3 Clip Fraction: 0.32689
Policy Update Magnitude: 0.08014
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 10531.70675
Overall Steps per Second: 7444.51619

Timestep Collection Time: 4.74956
Timestep Consumption Time: 1.96961
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.71917

Cumulative Model Updates: 13740
Cumulative Timesteps: 114867913

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 114867913...
Checkpoint 114867913 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13845.30185
Policy Entropy: 0.59382
Value Function Loss: 0.58269

Mean KL Divergence: 0.02511
SB3 Clip Fraction: 0.28038
Policy Update Magnitude: 0.08612
Value Function Update Magnitude: 0.12386

Collected Steps per Second: 10150.12472
Overall Steps per Second: 7245.76714

Timestep Collection Time: 4.92900
Timestep Consumption Time: 1.97572
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 6.90472

Cumulative Model Updates: 13746
Cumulative Timesteps: 114917943

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27541.22146
Policy Entropy: 0.60316
Value Function Loss: 0.57534

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.17612
Policy Update Magnitude: 0.10659
Value Function Update Magnitude: 0.12780

Collected Steps per Second: 9913.73700
Overall Steps per Second: 6981.45050

Timestep Collection Time: 5.04724
Timestep Consumption Time: 2.11990
PPO Batch Consumption Time: 0.02426
Total Iteration Time: 7.16714

Cumulative Model Updates: 13752
Cumulative Timesteps: 114967980

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 114967980...
Checkpoint 114967980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20517.91242
Policy Entropy: 0.61146
Value Function Loss: 0.58575

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.21745
Policy Update Magnitude: 0.10456
Value Function Update Magnitude: 0.13606

Collected Steps per Second: 9678.24818
Overall Steps per Second: 6908.83042

Timestep Collection Time: 5.16674
Timestep Consumption Time: 2.07110
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.23784

Cumulative Model Updates: 13758
Cumulative Timesteps: 115017985

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12260.26659
Policy Entropy: 0.62238
Value Function Loss: 0.59215

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.19513
Policy Update Magnitude: 0.12476
Value Function Update Magnitude: 0.14939

Collected Steps per Second: 9445.56981
Overall Steps per Second: 6750.10596

Timestep Collection Time: 5.29592
Timestep Consumption Time: 2.11478
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.41070

Cumulative Model Updates: 13764
Cumulative Timesteps: 115068008

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 115068008...
Checkpoint 115068008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14369.03752
Policy Entropy: 0.63139
Value Function Loss: 0.60038

Mean KL Divergence: 0.03103
SB3 Clip Fraction: 0.30525
Policy Update Magnitude: 0.10615
Value Function Update Magnitude: 0.13968

Collected Steps per Second: 9510.71846
Overall Steps per Second: 6775.75808

Timestep Collection Time: 5.25754
Timestep Consumption Time: 2.12215
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 7.37969

Cumulative Model Updates: 13770
Cumulative Timesteps: 115118011

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14856.92713
Policy Entropy: 0.64240
Value Function Loss: 0.57756

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.30264
Policy Update Magnitude: 0.08981
Value Function Update Magnitude: 0.13472

Collected Steps per Second: 9419.69919
Overall Steps per Second: 6825.59929

Timestep Collection Time: 5.31142
Timestep Consumption Time: 2.01863
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.33005

Cumulative Model Updates: 13776
Cumulative Timesteps: 115168043

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 115168043...
Checkpoint 115168043 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13649.50286
Policy Entropy: 0.61893
Value Function Loss: 0.57597

Mean KL Divergence: 0.03648
SB3 Clip Fraction: 0.34740
Policy Update Magnitude: 0.07763
Value Function Update Magnitude: 0.11481

Collected Steps per Second: 9656.67730
Overall Steps per Second: 6875.84382

Timestep Collection Time: 5.18056
Timestep Consumption Time: 2.09520
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.27576

Cumulative Model Updates: 13782
Cumulative Timesteps: 115218070

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17285.13885
Policy Entropy: 0.63538
Value Function Loss: 0.56059

Mean KL Divergence: 0.02348
SB3 Clip Fraction: 0.26045
Policy Update Magnitude: 0.10298
Value Function Update Magnitude: 0.11636

Collected Steps per Second: 9681.57974
Overall Steps per Second: 6867.34266

Timestep Collection Time: 5.16909
Timestep Consumption Time: 2.11829
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.28739

Cumulative Model Updates: 13788
Cumulative Timesteps: 115268115

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 115268115...
Checkpoint 115268115 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26590.45947
Policy Entropy: 0.62381
Value Function Loss: 0.54815

Mean KL Divergence: 0.02448
SB3 Clip Fraction: 0.26609
Policy Update Magnitude: 0.10545
Value Function Update Magnitude: 0.14500

Collected Steps per Second: 9672.56977
Overall Steps per Second: 6946.34279

Timestep Collection Time: 5.17132
Timestep Consumption Time: 2.02959
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.20091

Cumulative Model Updates: 13794
Cumulative Timesteps: 115318135

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24550.13483
Policy Entropy: 0.63584
Value Function Loss: 0.56240

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.25481
Policy Update Magnitude: 0.08628
Value Function Update Magnitude: 0.12456

Collected Steps per Second: 9061.24070
Overall Steps per Second: 6674.63472

Timestep Collection Time: 5.51845
Timestep Consumption Time: 1.97320
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.49165

Cumulative Model Updates: 13800
Cumulative Timesteps: 115368139

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 115368139...
Checkpoint 115368139 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12614.13284
Policy Entropy: 0.64150
Value Function Loss: 0.57066

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.28633
Policy Update Magnitude: 0.07484
Value Function Update Magnitude: 0.12377

Collected Steps per Second: 9440.14926
Overall Steps per Second: 6823.19377

Timestep Collection Time: 5.29886
Timestep Consumption Time: 2.03231
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.33117

Cumulative Model Updates: 13806
Cumulative Timesteps: 115418161

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13309.99547
Policy Entropy: 0.64219
Value Function Loss: 0.59416

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.29555
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.14637

Collected Steps per Second: 9890.18358
Overall Steps per Second: 7031.46107

Timestep Collection Time: 5.05825
Timestep Consumption Time: 2.05649
PPO Batch Consumption Time: 0.02490
Total Iteration Time: 7.11474

Cumulative Model Updates: 13812
Cumulative Timesteps: 115468188

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 115468188...
Checkpoint 115468188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14096.85266
Policy Entropy: 0.65690
Value Function Loss: 0.56316

Mean KL Divergence: 0.02554
SB3 Clip Fraction: 0.29839
Policy Update Magnitude: 0.07323
Value Function Update Magnitude: 0.15145

Collected Steps per Second: 9432.60112
Overall Steps per Second: 6888.26176

Timestep Collection Time: 5.30098
Timestep Consumption Time: 1.95804
PPO Batch Consumption Time: 0.02387
Total Iteration Time: 7.25902

Cumulative Model Updates: 13818
Cumulative Timesteps: 115518190

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6969.70744
Policy Entropy: 0.64434
Value Function Loss: 0.57990

Mean KL Divergence: 0.02555
SB3 Clip Fraction: 0.28787
Policy Update Magnitude: 0.07476
Value Function Update Magnitude: 0.14521

Collected Steps per Second: 10175.01759
Overall Steps per Second: 7204.24299

Timestep Collection Time: 4.91862
Timestep Consumption Time: 2.02826
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 6.94688

Cumulative Model Updates: 13824
Cumulative Timesteps: 115568237

Timesteps Collected: 50047
--------END ITERATION REPORT--------


Saving checkpoint 115568237...
Checkpoint 115568237 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16563.60050
Policy Entropy: 0.65470
Value Function Loss: 0.55292

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.20106
Policy Update Magnitude: 0.09491
Value Function Update Magnitude: 0.14590

Collected Steps per Second: 10606.47709
Overall Steps per Second: 7521.51525

Timestep Collection Time: 4.71721
Timestep Consumption Time: 1.93477
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 6.65198

Cumulative Model Updates: 13830
Cumulative Timesteps: 115618270

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14039.68294
Policy Entropy: 0.67336
Value Function Loss: 0.55877

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.27701
Policy Update Magnitude: 0.09496
Value Function Update Magnitude: 0.14871

Collected Steps per Second: 10087.55045
Overall Steps per Second: 7479.62257

Timestep Collection Time: 4.95908
Timestep Consumption Time: 1.72909
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.68817

Cumulative Model Updates: 13836
Cumulative Timesteps: 115668295

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 115668295...
Checkpoint 115668295 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24447.66608
Policy Entropy: 0.69007
Value Function Loss: 0.56576

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.23856
Policy Update Magnitude: 0.09062
Value Function Update Magnitude: 0.12461

Collected Steps per Second: 10159.98212
Overall Steps per Second: 7186.08343

Timestep Collection Time: 4.92560
Timestep Consumption Time: 2.03842
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 6.96402

Cumulative Model Updates: 13842
Cumulative Timesteps: 115718339

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17675.09124
Policy Entropy: 0.70936
Value Function Loss: 0.60596

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.27700
Policy Update Magnitude: 0.07915
Value Function Update Magnitude: 0.13588

Collected Steps per Second: 10019.38198
Overall Steps per Second: 7001.88058

Timestep Collection Time: 4.99432
Timestep Consumption Time: 2.15233
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.14665

Cumulative Model Updates: 13848
Cumulative Timesteps: 115768379

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 115768379...
Checkpoint 115768379 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10956.81236
Policy Entropy: 0.69481
Value Function Loss: 0.60496

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.26597
Policy Update Magnitude: 0.07566
Value Function Update Magnitude: 0.12862

Collected Steps per Second: 10753.24467
Overall Steps per Second: 7386.44950

Timestep Collection Time: 4.65004
Timestep Consumption Time: 2.11952
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 6.76956

Cumulative Model Updates: 13854
Cumulative Timesteps: 115818382

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14846.71003
Policy Entropy: 0.71868
Value Function Loss: 0.59005

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.27898
Policy Update Magnitude: 0.07499
Value Function Update Magnitude: 0.12453

Collected Steps per Second: 11061.99636
Overall Steps per Second: 7556.04622

Timestep Collection Time: 4.52260
Timestep Consumption Time: 2.09845
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 6.62106

Cumulative Model Updates: 13860
Cumulative Timesteps: 115868411

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 115868411...
Checkpoint 115868411 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20737.46838
Policy Entropy: 0.71133
Value Function Loss: 0.56781

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.26926
Policy Update Magnitude: 0.07362
Value Function Update Magnitude: 0.16251

Collected Steps per Second: 10363.65536
Overall Steps per Second: 7154.47984

Timestep Collection Time: 4.82832
Timestep Consumption Time: 2.16576
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 6.99408

Cumulative Model Updates: 13866
Cumulative Timesteps: 115918450

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12182.15862
Policy Entropy: 0.72523
Value Function Loss: 0.57347

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.19039
Policy Update Magnitude: 0.09034
Value Function Update Magnitude: 0.17840

Collected Steps per Second: 10058.74642
Overall Steps per Second: 6903.00024

Timestep Collection Time: 4.97308
Timestep Consumption Time: 2.27347
PPO Batch Consumption Time: 0.02490
Total Iteration Time: 7.24656

Cumulative Model Updates: 13872
Cumulative Timesteps: 115968473

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 115968473...
Checkpoint 115968473 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16774.75331
Policy Entropy: 0.72410
Value Function Loss: 0.60381

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.21345
Policy Update Magnitude: 0.09389
Value Function Update Magnitude: 0.15316

Collected Steps per Second: 9596.95424
Overall Steps per Second: 6636.57732

Timestep Collection Time: 5.21238
Timestep Consumption Time: 2.32509
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.53747

Cumulative Model Updates: 13878
Cumulative Timesteps: 116018496

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13979.30372
Policy Entropy: 0.73209
Value Function Loss: 0.61317

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.17393
Policy Update Magnitude: 0.10460
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 9974.28705
Overall Steps per Second: 6878.83590

Timestep Collection Time: 5.01630
Timestep Consumption Time: 2.25732
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 7.27361

Cumulative Model Updates: 13884
Cumulative Timesteps: 116068530

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 116068530...
Checkpoint 116068530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13757.99224
Policy Entropy: 0.72599
Value Function Loss: 0.59329

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.21255
Policy Update Magnitude: 0.10919
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 9452.70994
Overall Steps per Second: 6984.51762

Timestep Collection Time: 5.29298
Timestep Consumption Time: 1.87044
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 7.16342

Cumulative Model Updates: 13890
Cumulative Timesteps: 116118563

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12490.13548
Policy Entropy: 0.72996
Value Function Loss: 0.58183

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.23286
Policy Update Magnitude: 0.09043
Value Function Update Magnitude: 0.11612

Collected Steps per Second: 9041.96566
Overall Steps per Second: 6590.77179

Timestep Collection Time: 5.53309
Timestep Consumption Time: 2.05783
PPO Batch Consumption Time: 0.02455
Total Iteration Time: 7.59092

Cumulative Model Updates: 13896
Cumulative Timesteps: 116168593

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 116168593...
Checkpoint 116168593 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13753.13647
Policy Entropy: 0.74213
Value Function Loss: 0.58812

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.21651
Policy Update Magnitude: 0.08678
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 9682.72755
Overall Steps per Second: 6977.47006

Timestep Collection Time: 5.16435
Timestep Consumption Time: 2.00229
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.16664

Cumulative Model Updates: 13902
Cumulative Timesteps: 116218598

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18440.69409
Policy Entropy: 0.73940
Value Function Loss: 0.56909

Mean KL Divergence: 0.02881
SB3 Clip Fraction: 0.25358
Policy Update Magnitude: 0.08812
Value Function Update Magnitude: 0.13286

Collected Steps per Second: 9442.53908
Overall Steps per Second: 6726.45863

Timestep Collection Time: 5.29773
Timestep Consumption Time: 2.13917
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.43690

Cumulative Model Updates: 13908
Cumulative Timesteps: 116268622

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 116268622...
Checkpoint 116268622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12224.71554
Policy Entropy: 0.73264
Value Function Loss: 0.57002

Mean KL Divergence: 0.02850
SB3 Clip Fraction: 0.24366
Policy Update Magnitude: 0.09251
Value Function Update Magnitude: 0.16081

Collected Steps per Second: 9677.74876
Overall Steps per Second: 6981.18789

Timestep Collection Time: 5.16659
Timestep Consumption Time: 1.99565
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.16225

Cumulative Model Updates: 13914
Cumulative Timesteps: 116318623

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16230.92650
Policy Entropy: 0.73570
Value Function Loss: 0.57011

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.19396
Policy Update Magnitude: 0.09058
Value Function Update Magnitude: 0.14838

Collected Steps per Second: 10491.21139
Overall Steps per Second: 7322.26944

Timestep Collection Time: 4.76809
Timestep Consumption Time: 2.06354
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 6.83163

Cumulative Model Updates: 13920
Cumulative Timesteps: 116368646

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 116368646...
Checkpoint 116368646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18693.77571
Policy Entropy: 0.75100
Value Function Loss: 0.56899

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.19053
Policy Update Magnitude: 0.10054
Value Function Update Magnitude: 0.13905

Collected Steps per Second: 9394.58749
Overall Steps per Second: 6724.18717

Timestep Collection Time: 5.32487
Timestep Consumption Time: 2.11469
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.43956

Cumulative Model Updates: 13926
Cumulative Timesteps: 116418671

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11616.27093
Policy Entropy: 0.76470
Value Function Loss: 0.58211

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.22981
Policy Update Magnitude: 0.09643
Value Function Update Magnitude: 0.13260

Collected Steps per Second: 9377.98881
Overall Steps per Second: 6831.27568

Timestep Collection Time: 5.33505
Timestep Consumption Time: 1.98892
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.32396

Cumulative Model Updates: 13932
Cumulative Timesteps: 116468703

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 116468703...
Checkpoint 116468703 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10697.06409
Policy Entropy: 0.78010
Value Function Loss: 0.59400

Mean KL Divergence: 0.02856
SB3 Clip Fraction: 0.25730
Policy Update Magnitude: 0.10749
Value Function Update Magnitude: 0.18679

Collected Steps per Second: 10378.03244
Overall Steps per Second: 7276.00050

Timestep Collection Time: 4.81960
Timestep Consumption Time: 2.05478
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 6.87438

Cumulative Model Updates: 13938
Cumulative Timesteps: 116518721

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12579.63970
Policy Entropy: 0.77938
Value Function Loss: 0.59581

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.20881
Policy Update Magnitude: 0.11764
Value Function Update Magnitude: 0.20491

Collected Steps per Second: 10196.32253
Overall Steps per Second: 7361.67136

Timestep Collection Time: 4.90451
Timestep Consumption Time: 1.88851
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 6.79302

Cumulative Model Updates: 13944
Cumulative Timesteps: 116568729

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 116568729...
Checkpoint 116568729 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10263.42729
Policy Entropy: 0.77761
Value Function Loss: 0.58967

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.19567
Policy Update Magnitude: 0.12100
Value Function Update Magnitude: 0.17581

Collected Steps per Second: 9883.53759
Overall Steps per Second: 7167.65905

Timestep Collection Time: 5.06236
Timestep Consumption Time: 1.91816
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 6.98052

Cumulative Model Updates: 13950
Cumulative Timesteps: 116618763

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10063.60253
Policy Entropy: 0.79130
Value Function Loss: 0.58341

Mean KL Divergence: 0.02415
SB3 Clip Fraction: 0.24609
Policy Update Magnitude: 0.11278
Value Function Update Magnitude: 0.17053

Collected Steps per Second: 10152.45334
Overall Steps per Second: 7304.06413

Timestep Collection Time: 4.92610
Timestep Consumption Time: 1.92105
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 6.84715

Cumulative Model Updates: 13956
Cumulative Timesteps: 116668775

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 116668775...
Checkpoint 116668775 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12273.51332
Policy Entropy: 0.77114
Value Function Loss: 0.57607

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.28154
Policy Update Magnitude: 0.09008
Value Function Update Magnitude: 0.16807

Collected Steps per Second: 9696.24399
Overall Steps per Second: 6997.79385

Timestep Collection Time: 5.15932
Timestep Consumption Time: 1.98951
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.14882

Cumulative Model Updates: 13962
Cumulative Timesteps: 116718801

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15435.04702
Policy Entropy: 0.80218
Value Function Loss: 0.57756

Mean KL Divergence: 0.03427
SB3 Clip Fraction: 0.33496
Policy Update Magnitude: 0.08477
Value Function Update Magnitude: 0.17023

Collected Steps per Second: 9570.03130
Overall Steps per Second: 6964.85775

Timestep Collection Time: 5.22548
Timestep Consumption Time: 1.95457
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.18005

Cumulative Model Updates: 13968
Cumulative Timesteps: 116768809

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 116768809...
Checkpoint 116768809 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12343.70953
Policy Entropy: 0.80177
Value Function Loss: 0.57686

Mean KL Divergence: 0.03383
SB3 Clip Fraction: 0.32096
Policy Update Magnitude: 0.08687
Value Function Update Magnitude: 0.18411

Collected Steps per Second: 9998.59741
Overall Steps per Second: 7242.82059

Timestep Collection Time: 5.00310
Timestep Consumption Time: 1.90360
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.90670

Cumulative Model Updates: 13974
Cumulative Timesteps: 116818833

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12526.73196
Policy Entropy: 0.83262
Value Function Loss: 0.59771

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.24130
Policy Update Magnitude: 0.09092
Value Function Update Magnitude: 0.14902

Collected Steps per Second: 9408.90638
Overall Steps per Second: 6818.62480

Timestep Collection Time: 5.31666
Timestep Consumption Time: 2.01971
PPO Batch Consumption Time: 0.02447
Total Iteration Time: 7.33638

Cumulative Model Updates: 13980
Cumulative Timesteps: 116868857

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 116868857...
Checkpoint 116868857 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10183.80088
Policy Entropy: 0.81191
Value Function Loss: 0.61090

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.21301
Policy Update Magnitude: 0.09976
Value Function Update Magnitude: 0.13964

Collected Steps per Second: 9701.23559
Overall Steps per Second: 6948.70614

Timestep Collection Time: 5.15821
Timestep Consumption Time: 2.04328
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.20148

Cumulative Model Updates: 13986
Cumulative Timesteps: 116918898

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10473.80817
Policy Entropy: 0.82244
Value Function Loss: 0.58819

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.18522
Policy Update Magnitude: 0.10756
Value Function Update Magnitude: 0.15396

Collected Steps per Second: 9241.10951
Overall Steps per Second: 6718.45831

Timestep Collection Time: 5.41450
Timestep Consumption Time: 2.03304
PPO Batch Consumption Time: 0.02347
Total Iteration Time: 7.44754

Cumulative Model Updates: 13992
Cumulative Timesteps: 116968934

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 116968934...
Checkpoint 116968934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8160.91958
Policy Entropy: 0.80592
Value Function Loss: 0.58903

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.26165
Policy Update Magnitude: 0.10647
Value Function Update Magnitude: 0.18670

Collected Steps per Second: 9462.29297
Overall Steps per Second: 6802.64150

Timestep Collection Time: 5.28508
Timestep Consumption Time: 2.06633
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.35141

Cumulative Model Updates: 13998
Cumulative Timesteps: 117018943

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12338.05210
Policy Entropy: 0.83039
Value Function Loss: 0.58768

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.25933
Policy Update Magnitude: 0.08949
Value Function Update Magnitude: 0.18284

Collected Steps per Second: 9736.01548
Overall Steps per Second: 6945.89042

Timestep Collection Time: 5.13732
Timestep Consumption Time: 2.06363
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.20095

Cumulative Model Updates: 14004
Cumulative Timesteps: 117068960

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 117068960...
Checkpoint 117068960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15821.97501
Policy Entropy: 0.82263
Value Function Loss: 0.58366

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.19974
Policy Update Magnitude: 0.09252
Value Function Update Magnitude: 0.16389

Collected Steps per Second: 9416.71570
Overall Steps per Second: 6808.46518

Timestep Collection Time: 5.31172
Timestep Consumption Time: 2.03487
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.34659

Cumulative Model Updates: 14010
Cumulative Timesteps: 117118979

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14096.18078
Policy Entropy: 0.81657
Value Function Loss: 0.58363

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.18969
Policy Update Magnitude: 0.09041
Value Function Update Magnitude: 0.14320

Collected Steps per Second: 9497.48752
Overall Steps per Second: 6839.16453

Timestep Collection Time: 5.26813
Timestep Consumption Time: 2.04768
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.31581

Cumulative Model Updates: 14016
Cumulative Timesteps: 117169013

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 117169013...
Checkpoint 117169013 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11391.11476
Policy Entropy: 0.80927
Value Function Loss: 0.56510

Mean KL Divergence: 0.02708
SB3 Clip Fraction: 0.27005
Policy Update Magnitude: 0.08394
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 9720.99342
Overall Steps per Second: 6955.84124

Timestep Collection Time: 5.14587
Timestep Consumption Time: 2.04564
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 7.19151

Cumulative Model Updates: 14022
Cumulative Timesteps: 117219036

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11005.39208
Policy Entropy: 0.81595
Value Function Loss: 0.54171

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.22778
Policy Update Magnitude: 0.07932
Value Function Update Magnitude: 0.12598

Collected Steps per Second: 9474.93753
Overall Steps per Second: 6869.44520

Timestep Collection Time: 5.27961
Timestep Consumption Time: 2.00249
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.28210

Cumulative Model Updates: 14028
Cumulative Timesteps: 117269060

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 117269060...
Checkpoint 117269060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16315.67963
Policy Entropy: 0.81316
Value Function Loss: 0.54735

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.27649
Policy Update Magnitude: 0.08111
Value Function Update Magnitude: 0.12277

Collected Steps per Second: 10037.46212
Overall Steps per Second: 7162.23474

Timestep Collection Time: 4.98313
Timestep Consumption Time: 2.00044
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 6.98357

Cumulative Model Updates: 14034
Cumulative Timesteps: 117319078

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10913.36668
Policy Entropy: 0.80353
Value Function Loss: 0.54764

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.26831
Policy Update Magnitude: 0.07600
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 9687.49508
Overall Steps per Second: 6972.29144

Timestep Collection Time: 5.16346
Timestep Consumption Time: 2.01079
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.17426

Cumulative Model Updates: 14040
Cumulative Timesteps: 117369099

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 117369099...
Checkpoint 117369099 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15038.28893
Policy Entropy: 0.80711
Value Function Loss: 0.56654

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.15728
Policy Update Magnitude: 0.09863
Value Function Update Magnitude: 0.11529

Collected Steps per Second: 10000.90401
Overall Steps per Second: 7119.15648

Timestep Collection Time: 5.00205
Timestep Consumption Time: 2.02477
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.02682

Cumulative Model Updates: 14046
Cumulative Timesteps: 117419124

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17943.81090
Policy Entropy: 0.81059
Value Function Loss: 0.56374

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.19021
Policy Update Magnitude: 0.11244
Value Function Update Magnitude: 0.11591

Collected Steps per Second: 10444.50873
Overall Steps per Second: 7413.56636

Timestep Collection Time: 4.78979
Timestep Consumption Time: 1.95824
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 6.74803

Cumulative Model Updates: 14052
Cumulative Timesteps: 117469151

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 117469151...
Checkpoint 117469151 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16348.89471
Policy Entropy: 0.81995
Value Function Loss: 0.56582

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.20520
Policy Update Magnitude: 0.10991
Value Function Update Magnitude: 0.16577

Collected Steps per Second: 10318.60125
Overall Steps per Second: 7299.12408

Timestep Collection Time: 4.84804
Timestep Consumption Time: 2.00552
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 6.85356

Cumulative Model Updates: 14058
Cumulative Timesteps: 117519176

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11649.15494
Policy Entropy: 0.83600
Value Function Loss: 0.55536

Mean KL Divergence: 0.02989
SB3 Clip Fraction: 0.28478
Policy Update Magnitude: 0.09784
Value Function Update Magnitude: 0.13994

Collected Steps per Second: 10071.37916
Overall Steps per Second: 7264.25177

Timestep Collection Time: 4.96834
Timestep Consumption Time: 1.91992
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 6.88825

Cumulative Model Updates: 14064
Cumulative Timesteps: 117569214

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 117569214...
Checkpoint 117569214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16357.00217
Policy Entropy: 0.82778
Value Function Loss: 0.56896

Mean KL Divergence: 0.02388
SB3 Clip Fraction: 0.25878
Policy Update Magnitude: 0.10418
Value Function Update Magnitude: 0.12530

Collected Steps per Second: 10034.13320
Overall Steps per Second: 7170.20849

Timestep Collection Time: 4.98369
Timestep Consumption Time: 1.99059
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 6.97427

Cumulative Model Updates: 14070
Cumulative Timesteps: 117619221

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11298.46171
Policy Entropy: 0.81309
Value Function Loss: 0.57100

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.25326
Policy Update Magnitude: 0.08490
Value Function Update Magnitude: 0.12857

Collected Steps per Second: 9537.73608
Overall Steps per Second: 6731.40248

Timestep Collection Time: 5.24254
Timestep Consumption Time: 2.18563
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.42817

Cumulative Model Updates: 14076
Cumulative Timesteps: 117669223

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 117669223...
Checkpoint 117669223 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10673.41817
Policy Entropy: 0.82689
Value Function Loss: 0.57013

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16093
Policy Update Magnitude: 0.10528
Value Function Update Magnitude: 0.13743

Collected Steps per Second: 9143.74967
Overall Steps per Second: 6653.08964

Timestep Collection Time: 5.47018
Timestep Consumption Time: 2.04783
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.51801

Cumulative Model Updates: 14082
Cumulative Timesteps: 117719241

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9834.55946
Policy Entropy: 0.81922
Value Function Loss: 0.55377

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.17644
Policy Update Magnitude: 0.12810
Value Function Update Magnitude: 0.14680

Collected Steps per Second: 9790.48611
Overall Steps per Second: 7074.23044

Timestep Collection Time: 5.10822
Timestep Consumption Time: 1.96138
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 7.06960

Cumulative Model Updates: 14088
Cumulative Timesteps: 117769253

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 117769253...
Checkpoint 117769253 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6837.66272
Policy Entropy: 0.83251
Value Function Loss: 0.55448

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.22085
Policy Update Magnitude: 0.12065
Value Function Update Magnitude: 0.15448

Collected Steps per Second: 9093.86121
Overall Steps per Second: 6654.93496

Timestep Collection Time: 5.49986
Timestep Consumption Time: 2.01561
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.51548

Cumulative Model Updates: 14094
Cumulative Timesteps: 117819268

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7328.03674
Policy Entropy: 0.83165
Value Function Loss: 0.52980

Mean KL Divergence: 0.02699
SB3 Clip Fraction: 0.28246
Policy Update Magnitude: 0.08972
Value Function Update Magnitude: 0.13806

Collected Steps per Second: 9712.85472
Overall Steps per Second: 7005.50641

Timestep Collection Time: 5.15255
Timestep Consumption Time: 1.99126
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.14381

Cumulative Model Updates: 14100
Cumulative Timesteps: 117869314

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 117869314...
Checkpoint 117869314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26798.48259
Policy Entropy: 0.82392
Value Function Loss: 0.54838

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.23611
Policy Update Magnitude: 0.07374
Value Function Update Magnitude: 0.13408

Collected Steps per Second: 10260.23398
Overall Steps per Second: 7309.81242

Timestep Collection Time: 4.87533
Timestep Consumption Time: 1.96780
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 6.84313

Cumulative Model Updates: 14106
Cumulative Timesteps: 117919336

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13594.38310
Policy Entropy: 0.82556
Value Function Loss: 0.53781

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.24858
Policy Update Magnitude: 0.07447
Value Function Update Magnitude: 0.12645

Collected Steps per Second: 9333.09451
Overall Steps per Second: 6714.73850

Timestep Collection Time: 5.36157
Timestep Consumption Time: 2.09070
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.45226

Cumulative Model Updates: 14112
Cumulative Timesteps: 117969376

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 117969376...
Checkpoint 117969376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11831.34100
Policy Entropy: 0.81966
Value Function Loss: 0.57487

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.20820
Policy Update Magnitude: 0.08152
Value Function Update Magnitude: 0.13526

Collected Steps per Second: 9758.65229
Overall Steps per Second: 7080.30483

Timestep Collection Time: 5.12786
Timestep Consumption Time: 1.93977
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.06763

Cumulative Model Updates: 14118
Cumulative Timesteps: 118019417

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13255.81097
Policy Entropy: 0.83251
Value Function Loss: 0.58898

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.18656
Policy Update Magnitude: 0.09661
Value Function Update Magnitude: 0.09705

Collected Steps per Second: 10122.38407
Overall Steps per Second: 6885.56397

Timestep Collection Time: 4.94231
Timestep Consumption Time: 2.32332
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.26564

Cumulative Model Updates: 14124
Cumulative Timesteps: 118069445

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 118069445...
Checkpoint 118069445 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8780.54526
Policy Entropy: 0.83016
Value Function Loss: 0.62447

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.16977
Policy Update Magnitude: 0.11232
Value Function Update Magnitude: 0.09481

Collected Steps per Second: 9553.70662
Overall Steps per Second: 6624.13229

Timestep Collection Time: 5.23566
Timestep Consumption Time: 2.31551
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.55118

Cumulative Model Updates: 14130
Cumulative Timesteps: 118119465

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5893.13583
Policy Entropy: 0.83538
Value Function Loss: 0.60897

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.20027
Policy Update Magnitude: 0.10649
Value Function Update Magnitude: 0.10530

Collected Steps per Second: 10579.52798
Overall Steps per Second: 7207.85664

Timestep Collection Time: 4.72649
Timestep Consumption Time: 2.21094
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 6.93743

Cumulative Model Updates: 14136
Cumulative Timesteps: 118169469

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 118169469...
Checkpoint 118169469 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11937.21322
Policy Entropy: 0.83058
Value Function Loss: 0.57328

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.16865
Policy Update Magnitude: 0.10117
Value Function Update Magnitude: 0.14636

Collected Steps per Second: 10919.06409
Overall Steps per Second: 7380.60387

Timestep Collection Time: 4.58025
Timestep Consumption Time: 2.19589
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 6.77614

Cumulative Model Updates: 14142
Cumulative Timesteps: 118219481

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15806.90483
Policy Entropy: 0.83284
Value Function Loss: 0.54510

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.10210
Value Function Update Magnitude: 0.19308

Collected Steps per Second: 10692.09187
Overall Steps per Second: 7491.36145

Timestep Collection Time: 4.68000
Timestep Consumption Time: 1.99956
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 6.67956

Cumulative Model Updates: 14148
Cumulative Timesteps: 118269520

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 118269520...
Checkpoint 118269520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8536.81418
Policy Entropy: 0.83398
Value Function Loss: 0.55178

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.15035
Policy Update Magnitude: 0.10360
Value Function Update Magnitude: 0.19271

Collected Steps per Second: 10242.93564
Overall Steps per Second: 7322.58136

Timestep Collection Time: 4.88337
Timestep Consumption Time: 1.94756
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 6.83092

Cumulative Model Updates: 14154
Cumulative Timesteps: 118319540

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11053.64387
Policy Entropy: 0.84386
Value Function Loss: 0.57998

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.16300
Policy Update Magnitude: 0.10305
Value Function Update Magnitude: 0.15637

Collected Steps per Second: 9999.07109
Overall Steps per Second: 7211.07373

Timestep Collection Time: 5.00226
Timestep Consumption Time: 1.93401
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.93628

Cumulative Model Updates: 14160
Cumulative Timesteps: 118369558

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 118369558...
Checkpoint 118369558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11097.62569
Policy Entropy: 0.84182
Value Function Loss: 0.57269

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.10927
Value Function Update Magnitude: 0.16955

Collected Steps per Second: 10018.10148
Overall Steps per Second: 7231.90806

Timestep Collection Time: 4.99256
Timestep Consumption Time: 1.92345
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 6.91602

Cumulative Model Updates: 14166
Cumulative Timesteps: 118419574

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9091.07464
Policy Entropy: 0.85114
Value Function Loss: 0.58009

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.16968
Policy Update Magnitude: 0.12428
Value Function Update Magnitude: 0.17616

Collected Steps per Second: 9894.79257
Overall Steps per Second: 7121.49621

Timestep Collection Time: 5.05387
Timestep Consumption Time: 1.96811
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.02198

Cumulative Model Updates: 14172
Cumulative Timesteps: 118469581

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 118469581...
Checkpoint 118469581 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10652.89313
Policy Entropy: 0.84073
Value Function Loss: 0.57436

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.15860
Policy Update Magnitude: 0.11283
Value Function Update Magnitude: 0.17176

Collected Steps per Second: 10126.34349
Overall Steps per Second: 7297.77471

Timestep Collection Time: 4.93920
Timestep Consumption Time: 1.91440
PPO Batch Consumption Time: 0.02431
Total Iteration Time: 6.85360

Cumulative Model Updates: 14178
Cumulative Timesteps: 118519597

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12434.67530
Policy Entropy: 0.83686
Value Function Loss: 0.58063

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.21239
Policy Update Magnitude: 0.09795
Value Function Update Magnitude: 0.18945

Collected Steps per Second: 9785.68018
Overall Steps per Second: 7123.27607

Timestep Collection Time: 5.11308
Timestep Consumption Time: 1.91107
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.02416

Cumulative Model Updates: 14184
Cumulative Timesteps: 118569632

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 118569632...
Checkpoint 118569632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18493.01824
Policy Entropy: 0.84230
Value Function Loss: 0.59193

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.29708
Policy Update Magnitude: 0.07735
Value Function Update Magnitude: 0.16266

Collected Steps per Second: 9410.26253
Overall Steps per Second: 6707.48355

Timestep Collection Time: 5.31739
Timestep Consumption Time: 2.14264
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.46003

Cumulative Model Updates: 14190
Cumulative Timesteps: 118619670

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6554.25237
Policy Entropy: 0.83665
Value Function Loss: 0.61490

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.24897
Policy Update Magnitude: 0.07320
Value Function Update Magnitude: 0.14048

Collected Steps per Second: 9242.74688
Overall Steps per Second: 6838.56389

Timestep Collection Time: 5.41246
Timestep Consumption Time: 1.90282
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.31528

Cumulative Model Updates: 14196
Cumulative Timesteps: 118669696

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 118669696...
Checkpoint 118669696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9772.75725
Policy Entropy: 0.84535
Value Function Loss: 0.60834

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.19172
Policy Update Magnitude: 0.08223
Value Function Update Magnitude: 0.14292

Collected Steps per Second: 10143.43564
Overall Steps per Second: 7243.83640

Timestep Collection Time: 4.93344
Timestep Consumption Time: 1.97478
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 6.90822

Cumulative Model Updates: 14202
Cumulative Timesteps: 118719738

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12417.11295
Policy Entropy: 0.84720
Value Function Loss: 0.59861

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.23394
Policy Update Magnitude: 0.08642
Value Function Update Magnitude: 0.15231

Collected Steps per Second: 9058.21656
Overall Steps per Second: 6501.34057

Timestep Collection Time: 5.52140
Timestep Consumption Time: 2.17148
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.69287

Cumulative Model Updates: 14208
Cumulative Timesteps: 118769752

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 118769752...
Checkpoint 118769752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11028.49717
Policy Entropy: 0.85596
Value Function Loss: 0.57480

Mean KL Divergence: 0.03397
SB3 Clip Fraction: 0.30893
Policy Update Magnitude: 0.07772
Value Function Update Magnitude: 0.13745

Collected Steps per Second: 9415.52354
Overall Steps per Second: 6911.05731

Timestep Collection Time: 5.31250
Timestep Consumption Time: 1.92517
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.23768

Cumulative Model Updates: 14214
Cumulative Timesteps: 118819772

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10681.85010
Policy Entropy: 0.85493
Value Function Loss: 0.55641

Mean KL Divergence: 0.02788
SB3 Clip Fraction: 0.28599
Policy Update Magnitude: 0.08234
Value Function Update Magnitude: 0.14661

Collected Steps per Second: 9899.47364
Overall Steps per Second: 7118.10688

Timestep Collection Time: 5.05249
Timestep Consumption Time: 1.97424
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 7.02673

Cumulative Model Updates: 14220
Cumulative Timesteps: 118869789

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 118869789...
Checkpoint 118869789 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13026.88100
Policy Entropy: 0.84304
Value Function Loss: 0.52303

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.20497
Policy Update Magnitude: 0.08586
Value Function Update Magnitude: 0.17104

Collected Steps per Second: 9201.34909
Overall Steps per Second: 6643.11784

Timestep Collection Time: 5.43562
Timestep Consumption Time: 2.09323
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.52884

Cumulative Model Updates: 14226
Cumulative Timesteps: 118919804

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8765.75781
Policy Entropy: 0.84153
Value Function Loss: 0.52615

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.22119
Policy Update Magnitude: 0.09278
Value Function Update Magnitude: 0.13693

Collected Steps per Second: 10423.42835
Overall Steps per Second: 7355.02585

Timestep Collection Time: 4.80034
Timestep Consumption Time: 2.00263
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 6.80297

Cumulative Model Updates: 14232
Cumulative Timesteps: 118969840

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 118969840...
Checkpoint 118969840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15345.34100
Policy Entropy: 0.84609
Value Function Loss: 0.52305

Mean KL Divergence: 0.03154
SB3 Clip Fraction: 0.29985
Policy Update Magnitude: 0.08201
Value Function Update Magnitude: 0.12114

Collected Steps per Second: 9454.17011
Overall Steps per Second: 6694.95768

Timestep Collection Time: 5.29015
Timestep Consumption Time: 2.18025
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.47040

Cumulative Model Updates: 14238
Cumulative Timesteps: 119019854

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14064.09761
Policy Entropy: 0.84563
Value Function Loss: 0.55965

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.28320
Policy Update Magnitude: 0.07021
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 9155.42104
Overall Steps per Second: 6550.33236

Timestep Collection Time: 5.46365
Timestep Consumption Time: 2.17291
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.63656

Cumulative Model Updates: 14244
Cumulative Timesteps: 119069876

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 119069876...
Checkpoint 119069876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9083.01428
Policy Entropy: 0.84681
Value Function Loss: 0.55529

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.27987
Policy Update Magnitude: 0.06913
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 9994.79051
Overall Steps per Second: 7136.59069

Timestep Collection Time: 5.00551
Timestep Consumption Time: 2.00470
PPO Batch Consumption Time: 0.02426
Total Iteration Time: 7.01021

Cumulative Model Updates: 14250
Cumulative Timesteps: 119119905

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19259.99608
Policy Entropy: 0.84255
Value Function Loss: 0.54473

Mean KL Divergence: 0.02649
SB3 Clip Fraction: 0.28268
Policy Update Magnitude: 0.06900
Value Function Update Magnitude: 0.12542

Collected Steps per Second: 9970.08601
Overall Steps per Second: 7119.92843

Timestep Collection Time: 5.01590
Timestep Consumption Time: 2.00790
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.02381

Cumulative Model Updates: 14256
Cumulative Timesteps: 119169914

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 119169914...
Checkpoint 119169914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15779.75786
Policy Entropy: 0.83885
Value Function Loss: 0.53792

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.27495
Policy Update Magnitude: 0.07210
Value Function Update Magnitude: 0.15321

Collected Steps per Second: 10386.86213
Overall Steps per Second: 7456.50453

Timestep Collection Time: 4.81387
Timestep Consumption Time: 1.89182
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 6.70569

Cumulative Model Updates: 14262
Cumulative Timesteps: 119219915

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14902.68664
Policy Entropy: 0.84387
Value Function Loss: 0.53300

Mean KL Divergence: 0.02759
SB3 Clip Fraction: 0.27756
Policy Update Magnitude: 0.07564
Value Function Update Magnitude: 0.16843

Collected Steps per Second: 10059.68284
Overall Steps per Second: 7252.03233

Timestep Collection Time: 4.97073
Timestep Consumption Time: 1.92444
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.89517

Cumulative Model Updates: 14268
Cumulative Timesteps: 119269919

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 119269919...
Checkpoint 119269919 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13599.70414
Policy Entropy: 0.84576
Value Function Loss: 0.53222

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.19442
Policy Update Magnitude: 0.09104
Value Function Update Magnitude: 0.14111

Collected Steps per Second: 9148.64374
Overall Steps per Second: 6658.14663

Timestep Collection Time: 5.46715
Timestep Consumption Time: 2.04500
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.51215

Cumulative Model Updates: 14274
Cumulative Timesteps: 119319936

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12136.01374
Policy Entropy: 0.85799
Value Function Loss: 0.53828

Mean KL Divergence: 0.02561
SB3 Clip Fraction: 0.23811
Policy Update Magnitude: 0.09031
Value Function Update Magnitude: 0.13479

Collected Steps per Second: 9619.38662
Overall Steps per Second: 6979.64980

Timestep Collection Time: 5.20064
Timestep Consumption Time: 1.96691
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.16755

Cumulative Model Updates: 14280
Cumulative Timesteps: 119369963

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 119369963...
Checkpoint 119369963 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11940.68520
Policy Entropy: 0.86685
Value Function Loss: 0.52942

Mean KL Divergence: 0.02797
SB3 Clip Fraction: 0.27479
Policy Update Magnitude: 0.08310
Value Function Update Magnitude: 0.14312

Collected Steps per Second: 9766.04931
Overall Steps per Second: 6985.76126

Timestep Collection Time: 5.12213
Timestep Consumption Time: 2.03858
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.16071

Cumulative Model Updates: 14286
Cumulative Timesteps: 119419986

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14029.69491
Policy Entropy: 0.87896
Value Function Loss: 0.54825

Mean KL Divergence: 0.02740
SB3 Clip Fraction: 0.25892
Policy Update Magnitude: 0.07788
Value Function Update Magnitude: 0.14502

Collected Steps per Second: 9345.52783
Overall Steps per Second: 6730.56598

Timestep Collection Time: 5.35176
Timestep Consumption Time: 2.07927
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.43102

Cumulative Model Updates: 14292
Cumulative Timesteps: 119470001

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 119470001...
Checkpoint 119470001 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15655.09134
Policy Entropy: 0.86406
Value Function Loss: 0.50834

Mean KL Divergence: 0.02977
SB3 Clip Fraction: 0.28857
Policy Update Magnitude: 0.07604
Value Function Update Magnitude: 0.13597

Collected Steps per Second: 9652.09747
Overall Steps per Second: 6915.53735

Timestep Collection Time: 5.18323
Timestep Consumption Time: 2.05106
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.23429

Cumulative Model Updates: 14298
Cumulative Timesteps: 119520030

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14333.67489
Policy Entropy: 0.88635
Value Function Loss: 0.51452

Mean KL Divergence: 0.02892
SB3 Clip Fraction: 0.27984
Policy Update Magnitude: 0.08074
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 9483.19026
Overall Steps per Second: 6865.17684

Timestep Collection Time: 5.27460
Timestep Consumption Time: 2.01145
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.28605

Cumulative Model Updates: 14304
Cumulative Timesteps: 119570050

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 119570050...
Checkpoint 119570050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12466.26024
Policy Entropy: 0.86731
Value Function Loss: 0.50122

Mean KL Divergence: 0.02578
SB3 Clip Fraction: 0.23010
Policy Update Magnitude: 0.09220
Value Function Update Magnitude: 0.13479

Collected Steps per Second: 9075.63276
Overall Steps per Second: 6543.99774

Timestep Collection Time: 5.51433
Timestep Consumption Time: 2.13329
PPO Batch Consumption Time: 0.02424
Total Iteration Time: 7.64762

Cumulative Model Updates: 14310
Cumulative Timesteps: 119620096

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13004.29751
Policy Entropy: 0.88358
Value Function Loss: 0.49394

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.17774
Policy Update Magnitude: 0.09609
Value Function Update Magnitude: 0.13187

Collected Steps per Second: 9549.33120
Overall Steps per Second: 6969.89579

Timestep Collection Time: 5.23869
Timestep Consumption Time: 1.93875
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 7.17744

Cumulative Model Updates: 14316
Cumulative Timesteps: 119670122

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 119670122...
Checkpoint 119670122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13728.53180
Policy Entropy: 0.88650
Value Function Loss: 0.49536

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.21767
Policy Update Magnitude: 0.10089
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 9905.29742
Overall Steps per Second: 7133.80381

Timestep Collection Time: 5.05103
Timestep Consumption Time: 1.96233
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.01337

Cumulative Model Updates: 14322
Cumulative Timesteps: 119720154

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12209.74910
Policy Entropy: 0.89752
Value Function Loss: 0.49390

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.25905
Policy Update Magnitude: 0.08202
Value Function Update Magnitude: 0.12144

Collected Steps per Second: 9398.40595
Overall Steps per Second: 6847.05896

Timestep Collection Time: 5.32399
Timestep Consumption Time: 1.98382
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.30781

Cumulative Model Updates: 14328
Cumulative Timesteps: 119770191

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 119770191...
Checkpoint 119770191 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15033.96364
Policy Entropy: 0.89395
Value Function Loss: 0.50105

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.25713
Policy Update Magnitude: 0.07370
Value Function Update Magnitude: 0.13794

Collected Steps per Second: 9933.42031
Overall Steps per Second: 7101.92181

Timestep Collection Time: 5.03432
Timestep Consumption Time: 2.00716
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.04147

Cumulative Model Updates: 14334
Cumulative Timesteps: 119820199

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17668.18981
Policy Entropy: 0.90369
Value Function Loss: 0.49916

Mean KL Divergence: 0.02470
SB3 Clip Fraction: 0.25372
Policy Update Magnitude: 0.07172
Value Function Update Magnitude: 0.13722

Collected Steps per Second: 9339.83464
Overall Steps per Second: 6765.03351

Timestep Collection Time: 5.35395
Timestep Consumption Time: 2.03774
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.39169

Cumulative Model Updates: 14340
Cumulative Timesteps: 119870204

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 119870204...
Checkpoint 119870204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11901.16386
Policy Entropy: 0.90424
Value Function Loss: 0.49911

Mean KL Divergence: 0.02439
SB3 Clip Fraction: 0.25855
Policy Update Magnitude: 0.07341
Value Function Update Magnitude: 0.18878

Collected Steps per Second: 9305.32449
Overall Steps per Second: 6736.63802

Timestep Collection Time: 5.37456
Timestep Consumption Time: 2.04932
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.42388

Cumulative Model Updates: 14346
Cumulative Timesteps: 119920216

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15977.42550
Policy Entropy: 0.90417
Value Function Loss: 0.50459

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.23864
Policy Update Magnitude: 0.08120
Value Function Update Magnitude: 0.16207

Collected Steps per Second: 10208.71478
Overall Steps per Second: 7311.22036

Timestep Collection Time: 4.90101
Timestep Consumption Time: 1.94231
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.84332

Cumulative Model Updates: 14352
Cumulative Timesteps: 119970249

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 119970249...
Checkpoint 119970249 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14621.54258
Policy Entropy: 0.92075
Value Function Loss: 0.51580

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.28030
Policy Update Magnitude: 0.07555
Value Function Update Magnitude: 0.13340

Collected Steps per Second: 9984.61147
Overall Steps per Second: 7087.29761

Timestep Collection Time: 5.01021
Timestep Consumption Time: 2.04819
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.05840

Cumulative Model Updates: 14358
Cumulative Timesteps: 120020274

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9260.36733
Policy Entropy: 0.90652
Value Function Loss: 0.52464

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.23217
Policy Update Magnitude: 0.08120
Value Function Update Magnitude: 0.12945

Collected Steps per Second: 9557.56474
Overall Steps per Second: 6954.67429

Timestep Collection Time: 5.23146
Timestep Consumption Time: 1.95795
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.18941

Cumulative Model Updates: 14364
Cumulative Timesteps: 120070274

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 120070274...
Checkpoint 120070274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10587.51829
Policy Entropy: 0.91479
Value Function Loss: 0.55625

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.24697
Policy Update Magnitude: 0.08096
Value Function Update Magnitude: 0.12233

Collected Steps per Second: 10138.60705
Overall Steps per Second: 7319.44915

Timestep Collection Time: 4.93381
Timestep Consumption Time: 1.90031
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 6.83412

Cumulative Model Updates: 14370
Cumulative Timesteps: 120120296

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10157.58421
Policy Entropy: 0.91619
Value Function Loss: 0.55479

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.21011
Policy Update Magnitude: 0.08327
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 9495.53735
Overall Steps per Second: 6883.40127

Timestep Collection Time: 5.26816
Timestep Consumption Time: 1.99918
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.26734

Cumulative Model Updates: 14376
Cumulative Timesteps: 120170320

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 120170320...
Checkpoint 120170320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16848.73367
Policy Entropy: 0.92304
Value Function Loss: 0.55124

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.22129
Policy Update Magnitude: 0.08458
Value Function Update Magnitude: 0.15280

Collected Steps per Second: 9359.17133
Overall Steps per Second: 6825.27212

Timestep Collection Time: 5.34470
Timestep Consumption Time: 1.98423
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 7.32894

Cumulative Model Updates: 14382
Cumulative Timesteps: 120220342

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10572.30728
Policy Entropy: 0.92442
Value Function Loss: 0.55838

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.19429
Policy Update Magnitude: 0.09659
Value Function Update Magnitude: 0.14803

Collected Steps per Second: 9702.00483
Overall Steps per Second: 7050.73841

Timestep Collection Time: 5.15667
Timestep Consumption Time: 1.93904
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.09571

Cumulative Model Updates: 14388
Cumulative Timesteps: 120270372

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 120270372...
Checkpoint 120270372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11356.07268
Policy Entropy: 0.94357
Value Function Loss: 0.55214

Mean KL Divergence: 0.02967
SB3 Clip Fraction: 0.26559
Policy Update Magnitude: 0.09706
Value Function Update Magnitude: 0.17452

Collected Steps per Second: 9627.61732
Overall Steps per Second: 6854.03963

Timestep Collection Time: 5.19744
Timestep Consumption Time: 2.10321
PPO Batch Consumption Time: 0.03024
Total Iteration Time: 7.30066

Cumulative Model Updates: 14394
Cumulative Timesteps: 120320411

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8653.94225
Policy Entropy: 0.95604
Value Function Loss: 0.54175

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.26680
Policy Update Magnitude: 0.08927
Value Function Update Magnitude: 0.18383

Collected Steps per Second: 9588.47975
Overall Steps per Second: 6752.50992

Timestep Collection Time: 5.21563
Timestep Consumption Time: 2.19050
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.40613

Cumulative Model Updates: 14400
Cumulative Timesteps: 120370421

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 120370421...
Checkpoint 120370421 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8260.99606
Policy Entropy: 0.96423
Value Function Loss: 0.53279

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.21698
Policy Update Magnitude: 0.09448
Value Function Update Magnitude: 0.17062

Collected Steps per Second: 10898.75666
Overall Steps per Second: 7433.37301

Timestep Collection Time: 4.59016
Timestep Consumption Time: 2.13990
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.73005

Cumulative Model Updates: 14406
Cumulative Timesteps: 120420448

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9208.11340
Policy Entropy: 0.98727
Value Function Loss: 0.54924

Mean KL Divergence: 0.02817
SB3 Clip Fraction: 0.24217
Policy Update Magnitude: 0.09211
Value Function Update Magnitude: 0.16284

Collected Steps per Second: 10492.61295
Overall Steps per Second: 7353.02931

Timestep Collection Time: 4.76821
Timestep Consumption Time: 2.03592
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 6.80413

Cumulative Model Updates: 14412
Cumulative Timesteps: 120470479

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 120470479...
Checkpoint 120470479 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8012.08009
Policy Entropy: 1.00514
Value Function Loss: 0.54797

Mean KL Divergence: 0.03030
SB3 Clip Fraction: 0.27991
Policy Update Magnitude: 0.09522
Value Function Update Magnitude: 0.14148

Collected Steps per Second: 9711.85398
Overall Steps per Second: 6876.87994

Timestep Collection Time: 5.15267
Timestep Consumption Time: 2.12417
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.27685

Cumulative Model Updates: 14418
Cumulative Timesteps: 120520521

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10901.50673
Policy Entropy: 1.00625
Value Function Loss: 0.53545

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.16776
Policy Update Magnitude: 0.09665
Value Function Update Magnitude: 0.14099

Collected Steps per Second: 10364.24549
Overall Steps per Second: 7252.10079

Timestep Collection Time: 4.82428
Timestep Consumption Time: 2.07028
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 6.89455

Cumulative Model Updates: 14424
Cumulative Timesteps: 120570521

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 120570521...
Checkpoint 120570521 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9019.88108
Policy Entropy: 1.00998
Value Function Loss: 0.50482

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.17181
Policy Update Magnitude: 0.11817
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 9341.08685
Overall Steps per Second: 6684.34402

Timestep Collection Time: 5.35377
Timestep Consumption Time: 2.12789
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.48166

Cumulative Model Updates: 14430
Cumulative Timesteps: 120620531

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12088.64188
Policy Entropy: 1.01827
Value Function Loss: 0.50813

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.17889
Policy Update Magnitude: 0.10799
Value Function Update Magnitude: 0.14219

Collected Steps per Second: 9818.08071
Overall Steps per Second: 6957.18790

Timestep Collection Time: 5.09509
Timestep Consumption Time: 2.09517
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.19026

Cumulative Model Updates: 14436
Cumulative Timesteps: 120670555

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 120670555...
Checkpoint 120670555 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8760.17051
Policy Entropy: 1.01296
Value Function Loss: 0.52332

Mean KL Divergence: 0.02167
SB3 Clip Fraction: 0.20001
Policy Update Magnitude: 0.10072
Value Function Update Magnitude: 0.12640

Collected Steps per Second: 9371.31212
Overall Steps per Second: 6654.64965

Timestep Collection Time: 5.33757
Timestep Consumption Time: 2.17898
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 7.51655

Cumulative Model Updates: 14442
Cumulative Timesteps: 120720575

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10045.12064
Policy Entropy: 1.03051
Value Function Loss: 0.54272

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.27875
Policy Update Magnitude: 0.08713
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 9245.41587
Overall Steps per Second: 6682.28330

Timestep Collection Time: 5.41079
Timestep Consumption Time: 2.07542
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.48621

Cumulative Model Updates: 14448
Cumulative Timesteps: 120770600

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 120770600...
Checkpoint 120770600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9933.83000
Policy Entropy: 1.02259
Value Function Loss: 0.54892

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.24379
Policy Update Magnitude: 0.08724
Value Function Update Magnitude: 0.11799

Collected Steps per Second: 9332.20588
Overall Steps per Second: 6836.77893

Timestep Collection Time: 5.36165
Timestep Consumption Time: 1.95700
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.31865

Cumulative Model Updates: 14454
Cumulative Timesteps: 120820636

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10936.54691
Policy Entropy: 1.04174
Value Function Loss: 0.55984

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.22726
Policy Update Magnitude: 0.10214
Value Function Update Magnitude: 0.13507

Collected Steps per Second: 9816.93734
Overall Steps per Second: 7004.04911

Timestep Collection Time: 5.09466
Timestep Consumption Time: 2.04606
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.14073

Cumulative Model Updates: 14460
Cumulative Timesteps: 120870650

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 120870650...
Checkpoint 120870650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9926.26228
Policy Entropy: 1.03484
Value Function Loss: 0.55368

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.20876
Policy Update Magnitude: 0.10159
Value Function Update Magnitude: 0.13359

Collected Steps per Second: 9804.86014
Overall Steps per Second: 7029.52648

Timestep Collection Time: 5.10227
Timestep Consumption Time: 2.01443
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.11670

Cumulative Model Updates: 14466
Cumulative Timesteps: 120920677

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11757.38512
Policy Entropy: 1.05167
Value Function Loss: 0.56290

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.11360
Value Function Update Magnitude: 0.15359

Collected Steps per Second: 10294.04708
Overall Steps per Second: 7371.17007

Timestep Collection Time: 4.85873
Timestep Consumption Time: 1.92662
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 6.78535

Cumulative Model Updates: 14472
Cumulative Timesteps: 120970693

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 120970693...
Checkpoint 120970693 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9864.51942
Policy Entropy: 1.05210
Value Function Loss: 0.56392

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.11763
Value Function Update Magnitude: 0.14220

Collected Steps per Second: 9573.60463
Overall Steps per Second: 6907.64319

Timestep Collection Time: 5.22708
Timestep Consumption Time: 2.01736
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.24444

Cumulative Model Updates: 14478
Cumulative Timesteps: 121020735

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6003.20297
Policy Entropy: 1.05955
Value Function Loss: 0.55901

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.11765
Value Function Update Magnitude: 0.14524

Collected Steps per Second: 9787.28230
Overall Steps per Second: 7112.80357

Timestep Collection Time: 5.11306
Timestep Consumption Time: 1.92256
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.03562

Cumulative Model Updates: 14484
Cumulative Timesteps: 121070778

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 121070778...
Checkpoint 121070778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6337.09058
Policy Entropy: 1.05687
Value Function Loss: 0.54313

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.16025
Policy Update Magnitude: 0.11045
Value Function Update Magnitude: 0.14690

Collected Steps per Second: 9808.44657
Overall Steps per Second: 7141.66153

Timestep Collection Time: 5.10081
Timestep Consumption Time: 1.90470
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.00551

Cumulative Model Updates: 14490
Cumulative Timesteps: 121120809

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5528.97793
Policy Entropy: 1.06505
Value Function Loss: 0.55767

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.17786
Policy Update Magnitude: 0.10626
Value Function Update Magnitude: 0.15667

Collected Steps per Second: 9811.46804
Overall Steps per Second: 6813.45447

Timestep Collection Time: 5.09812
Timestep Consumption Time: 2.24324
PPO Batch Consumption Time: 0.02490
Total Iteration Time: 7.34136

Cumulative Model Updates: 14496
Cumulative Timesteps: 121170829

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 121170829...
Checkpoint 121170829 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7749.69823
Policy Entropy: 1.07212
Value Function Loss: 0.56728

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.21364
Policy Update Magnitude: 0.09218
Value Function Update Magnitude: 0.13763

Collected Steps per Second: 10170.82800
Overall Steps per Second: 6952.04855

Timestep Collection Time: 4.91720
Timestep Consumption Time: 2.27665
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.19385

Cumulative Model Updates: 14502
Cumulative Timesteps: 121220841

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5391.72971
Policy Entropy: 1.07167
Value Function Loss: 0.58019

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.19825
Policy Update Magnitude: 0.10327
Value Function Update Magnitude: 0.13373

Collected Steps per Second: 10813.85458
Overall Steps per Second: 7221.27693

Timestep Collection Time: 4.62666
Timestep Consumption Time: 2.30176
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 6.92841

Cumulative Model Updates: 14508
Cumulative Timesteps: 121270873

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 121270873...
Checkpoint 121270873 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5898.91807
Policy Entropy: 1.07800
Value Function Loss: 0.58240

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.20775
Policy Update Magnitude: 0.08537
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 9965.94602
Overall Steps per Second: 7080.06293

Timestep Collection Time: 5.01719
Timestep Consumption Time: 2.04504
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.06223

Cumulative Model Updates: 14514
Cumulative Timesteps: 121320874

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8087.57609
Policy Entropy: 1.08844
Value Function Loss: 0.58050

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.16908
Policy Update Magnitude: 0.08116
Value Function Update Magnitude: 0.17126

Collected Steps per Second: 9938.61068
Overall Steps per Second: 7132.95858

Timestep Collection Time: 5.03149
Timestep Consumption Time: 1.97907
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.01056

Cumulative Model Updates: 14520
Cumulative Timesteps: 121370880

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 121370880...
Checkpoint 121370880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6744.73706
Policy Entropy: 1.09218
Value Function Loss: 0.59340

Mean KL Divergence: 0.02381
SB3 Clip Fraction: 0.21897
Policy Update Magnitude: 0.08112
Value Function Update Magnitude: 0.17577

Collected Steps per Second: 9853.22855
Overall Steps per Second: 6990.95061

Timestep Collection Time: 5.07448
Timestep Consumption Time: 2.07762
PPO Batch Consumption Time: 0.02450
Total Iteration Time: 7.15210

Cumulative Model Updates: 14526
Cumulative Timesteps: 121420880

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7726.53231
Policy Entropy: 1.10422
Value Function Loss: 0.57385

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.09709
Value Function Update Magnitude: 0.18224

Collected Steps per Second: 9096.04468
Overall Steps per Second: 6582.36113

Timestep Collection Time: 5.50173
Timestep Consumption Time: 2.10101
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.60274

Cumulative Model Updates: 14532
Cumulative Timesteps: 121470924

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 121470924...
Checkpoint 121470924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6705.13841
Policy Entropy: 1.11240
Value Function Loss: 0.59179

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.17886
Policy Update Magnitude: 0.11354
Value Function Update Magnitude: 0.17123

Collected Steps per Second: 10098.50530
Overall Steps per Second: 7248.77833

Timestep Collection Time: 4.95489
Timestep Consumption Time: 1.94793
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 6.90282

Cumulative Model Updates: 14538
Cumulative Timesteps: 121520961

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6574.41339
Policy Entropy: 1.12223
Value Function Loss: 0.58110

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.10998
Value Function Update Magnitude: 0.16095

Collected Steps per Second: 9997.78520
Overall Steps per Second: 7120.07021

Timestep Collection Time: 5.00171
Timestep Consumption Time: 2.02154
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.02325

Cumulative Model Updates: 14544
Cumulative Timesteps: 121570967

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 121570967...
Checkpoint 121570967 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5989.12102
Policy Entropy: 1.11942
Value Function Loss: 0.57660

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.12050
Value Function Update Magnitude: 0.16734

Collected Steps per Second: 9245.56287
Overall Steps per Second: 6760.02603

Timestep Collection Time: 5.41146
Timestep Consumption Time: 1.98969
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.40115

Cumulative Model Updates: 14550
Cumulative Timesteps: 121620999

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5660.82482
Policy Entropy: 1.11415
Value Function Loss: 0.55820

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.17223
Policy Update Magnitude: 0.10408
Value Function Update Magnitude: 0.16899

Collected Steps per Second: 9912.70614
Overall Steps per Second: 7096.62660

Timestep Collection Time: 5.04575
Timestep Consumption Time: 2.00225
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 7.04800

Cumulative Model Updates: 14556
Cumulative Timesteps: 121671016

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 121671016...
Checkpoint 121671016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7763.44072
Policy Entropy: 1.12538
Value Function Loss: 0.55661

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.16239
Policy Update Magnitude: 0.10183
Value Function Update Magnitude: 0.14274

Collected Steps per Second: 10442.34700
Overall Steps per Second: 7353.10751

Timestep Collection Time: 4.78934
Timestep Consumption Time: 2.01213
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 6.80148

Cumulative Model Updates: 14562
Cumulative Timesteps: 121721028

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4572.55646
Policy Entropy: 1.13268
Value Function Loss: 0.55007

Mean KL Divergence: 0.02245
SB3 Clip Fraction: 0.19205
Policy Update Magnitude: 0.10093
Value Function Update Magnitude: 0.16457

Collected Steps per Second: 9932.07496
Overall Steps per Second: 7073.87933

Timestep Collection Time: 5.03581
Timestep Consumption Time: 2.03471
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.07052

Cumulative Model Updates: 14568
Cumulative Timesteps: 121771044

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 121771044...
Checkpoint 121771044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7093.38892
Policy Entropy: 1.14118
Value Function Loss: 0.58072

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.09696
Value Function Update Magnitude: 0.17079

Collected Steps per Second: 10901.70732
Overall Steps per Second: 7464.79282

Timestep Collection Time: 4.58946
Timestep Consumption Time: 2.11307
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.70253

Cumulative Model Updates: 14574
Cumulative Timesteps: 121821077

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3801.49320
Policy Entropy: 1.14517
Value Function Loss: 0.57826

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.17099
Policy Update Magnitude: 0.09585
Value Function Update Magnitude: 0.22271

Collected Steps per Second: 9824.64142
Overall Steps per Second: 6989.89725

Timestep Collection Time: 5.09006
Timestep Consumption Time: 2.06427
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 7.15433

Cumulative Model Updates: 14580
Cumulative Timesteps: 121871085

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 121871085...
Checkpoint 121871085 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6133.76279
Policy Entropy: 1.14619
Value Function Loss: 0.56618

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.18311
Policy Update Magnitude: 0.08223
Value Function Update Magnitude: 0.19965

Collected Steps per Second: 9496.56498
Overall Steps per Second: 6798.67295

Timestep Collection Time: 5.26917
Timestep Consumption Time: 2.09094
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.36011

Cumulative Model Updates: 14586
Cumulative Timesteps: 121921124

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6825.93383
Policy Entropy: 1.15173
Value Function Loss: 0.56008

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.16469
Policy Update Magnitude: 0.08638
Value Function Update Magnitude: 0.18506

Collected Steps per Second: 9340.18447
Overall Steps per Second: 6634.81196

Timestep Collection Time: 5.35407
Timestep Consumption Time: 2.18314
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 7.53721

Cumulative Model Updates: 14592
Cumulative Timesteps: 121971132

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 121971132...
Checkpoint 121971132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7386.72174
Policy Entropy: 1.14759
Value Function Loss: 0.54911

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.08367
Value Function Update Magnitude: 0.17279

Collected Steps per Second: 9243.80405
Overall Steps per Second: 6663.19120

Timestep Collection Time: 5.40935
Timestep Consumption Time: 2.09501
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 7.50436

Cumulative Model Updates: 14598
Cumulative Timesteps: 122021135

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5107.75223
Policy Entropy: 1.15940
Value Function Loss: 0.57803

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.17284
Policy Update Magnitude: 0.07633
Value Function Update Magnitude: 0.15080

Collected Steps per Second: 9453.81285
Overall Steps per Second: 6915.56259

Timestep Collection Time: 5.29099
Timestep Consumption Time: 1.94197
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.23296

Cumulative Model Updates: 14604
Cumulative Timesteps: 122071155

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 122071155...
Checkpoint 122071155 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6858.59599
Policy Entropy: 1.15736
Value Function Loss: 0.60652

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.16218
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.13852

Collected Steps per Second: 9608.82133
Overall Steps per Second: 6948.20027

Timestep Collection Time: 5.20407
Timestep Consumption Time: 1.99276
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 7.19683

Cumulative Model Updates: 14610
Cumulative Timesteps: 122121160

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4814.86923
Policy Entropy: 1.16191
Value Function Loss: 0.62336

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.16361
Policy Update Magnitude: 0.07582
Value Function Update Magnitude: 0.15035

Collected Steps per Second: 9300.32185
Overall Steps per Second: 6771.24639

Timestep Collection Time: 5.37680
Timestep Consumption Time: 2.00825
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 7.38505

Cumulative Model Updates: 14616
Cumulative Timesteps: 122171166

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 122171166...
Checkpoint 122171166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5875.53813
Policy Entropy: 1.16306
Value Function Loss: 0.62935

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.16879
Policy Update Magnitude: 0.07573
Value Function Update Magnitude: 0.15115

Collected Steps per Second: 9582.07362
Overall Steps per Second: 6930.84084

Timestep Collection Time: 5.21839
Timestep Consumption Time: 1.99617
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.21456

Cumulative Model Updates: 14622
Cumulative Timesteps: 122221169

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5904.81770
Policy Entropy: 1.16587
Value Function Loss: 0.61039

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.15052
Policy Update Magnitude: 0.07948
Value Function Update Magnitude: 0.14650

Collected Steps per Second: 10604.02254
Overall Steps per Second: 7093.58518

Timestep Collection Time: 4.71698
Timestep Consumption Time: 2.33432
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.05130

Cumulative Model Updates: 14628
Cumulative Timesteps: 122271188

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 122271188...
Checkpoint 122271188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8756.45198
Policy Entropy: 1.16086
Value Function Loss: 0.59606

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.08964
Value Function Update Magnitude: 0.15012

Collected Steps per Second: 9402.17935
Overall Steps per Second: 6669.81572

Timestep Collection Time: 5.32153
Timestep Consumption Time: 2.18002
PPO Batch Consumption Time: 0.02420
Total Iteration Time: 7.50156

Cumulative Model Updates: 14634
Cumulative Timesteps: 122321222

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5265.70118
Policy Entropy: 1.15597
Value Function Loss: 0.59681

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.09779
Value Function Update Magnitude: 0.14452

Collected Steps per Second: 9939.62462
Overall Steps per Second: 7090.76775

Timestep Collection Time: 5.03490
Timestep Consumption Time: 2.02287
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.05777

Cumulative Model Updates: 14640
Cumulative Timesteps: 122371267

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 122371267...
Checkpoint 122371267 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4074.83348
Policy Entropy: 1.15810
Value Function Loss: 0.59235

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.18389
Policy Update Magnitude: 0.09509
Value Function Update Magnitude: 0.18267

Collected Steps per Second: 9683.45022
Overall Steps per Second: 6739.66233

Timestep Collection Time: 5.16562
Timestep Consumption Time: 2.25627
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.42189

Cumulative Model Updates: 14646
Cumulative Timesteps: 122421288

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5568.87785
Policy Entropy: 1.14918
Value Function Loss: 0.59648

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.17214
Policy Update Magnitude: 0.08814
Value Function Update Magnitude: 0.20611

Collected Steps per Second: 9280.75022
Overall Steps per Second: 6656.42951

Timestep Collection Time: 5.39181
Timestep Consumption Time: 2.12574
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.51754

Cumulative Model Updates: 14652
Cumulative Timesteps: 122471328

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 122471328...
Checkpoint 122471328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4782.29427
Policy Entropy: 1.14608
Value Function Loss: 0.58608

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.18212
Policy Update Magnitude: 0.08289
Value Function Update Magnitude: 0.18336

Collected Steps per Second: 10117.15425
Overall Steps per Second: 7248.80321

Timestep Collection Time: 4.94240
Timestep Consumption Time: 1.95571
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 6.89810

Cumulative Model Updates: 14658
Cumulative Timesteps: 122521331

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6645.20926
Policy Entropy: 1.13599
Value Function Loss: 0.59865

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.09117
Value Function Update Magnitude: 0.15470

Collected Steps per Second: 9662.62745
Overall Steps per Second: 6951.81974

Timestep Collection Time: 5.17561
Timestep Consumption Time: 2.01819
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.19380

Cumulative Model Updates: 14664
Cumulative Timesteps: 122571341

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 122571341...
Checkpoint 122571341 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5846.04994
Policy Entropy: 1.13639
Value Function Loss: 0.59437

Mean KL Divergence: 0.02067
SB3 Clip Fraction: 0.18351
Policy Update Magnitude: 0.09897
Value Function Update Magnitude: 0.16200

Collected Steps per Second: 9203.51345
Overall Steps per Second: 6778.14378

Timestep Collection Time: 5.43542
Timestep Consumption Time: 1.94491
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.38034

Cumulative Model Updates: 14670
Cumulative Timesteps: 122621366

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5078.10112
Policy Entropy: 1.12487
Value Function Loss: 0.60178

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.08333
Value Function Update Magnitude: 0.15622

Collected Steps per Second: 9997.38690
Overall Steps per Second: 7280.66219

Timestep Collection Time: 5.00141
Timestep Consumption Time: 1.86624
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 6.86764

Cumulative Model Updates: 14676
Cumulative Timesteps: 122671367

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 122671367...
Checkpoint 122671367 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4472.59909
Policy Entropy: 1.12272
Value Function Loss: 0.59785

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.11585
Value Function Update Magnitude: 0.20044

Collected Steps per Second: 9458.79947
Overall Steps per Second: 6867.83139

Timestep Collection Time: 5.28809
Timestep Consumption Time: 1.99499
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 7.28309

Cumulative Model Updates: 14682
Cumulative Timesteps: 122721386

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5553.47730
Policy Entropy: 1.11359
Value Function Loss: 0.57695

Mean KL Divergence: 0.02763
SB3 Clip Fraction: 0.21249
Policy Update Magnitude: 0.10754
Value Function Update Magnitude: 0.20979

Collected Steps per Second: 9485.88413
Overall Steps per Second: 6962.51106

Timestep Collection Time: 5.27331
Timestep Consumption Time: 1.91117
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.18448

Cumulative Model Updates: 14688
Cumulative Timesteps: 122771408

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 122771408...
Checkpoint 122771408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6597.02911
Policy Entropy: 1.10182
Value Function Loss: 0.57663

Mean KL Divergence: 0.02520
SB3 Clip Fraction: 0.21363
Policy Update Magnitude: 0.07733
Value Function Update Magnitude: 0.22676

Collected Steps per Second: 9667.52513
Overall Steps per Second: 7071.79121

Timestep Collection Time: 5.17578
Timestep Consumption Time: 1.89979
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.07558

Cumulative Model Updates: 14694
Cumulative Timesteps: 122821445

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5791.88853
Policy Entropy: 1.09895
Value Function Loss: 0.55942

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.20799
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.21501

Collected Steps per Second: 9996.55671
Overall Steps per Second: 7198.10739

Timestep Collection Time: 5.00292
Timestep Consumption Time: 1.94501
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.94794

Cumulative Model Updates: 14700
Cumulative Timesteps: 122871457

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 122871457...
Checkpoint 122871457 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9418.44251
Policy Entropy: 1.08906
Value Function Loss: 0.55152

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.19979
Policy Update Magnitude: 0.07602
Value Function Update Magnitude: 0.17891

Collected Steps per Second: 9862.12000
Overall Steps per Second: 7067.61296

Timestep Collection Time: 5.07173
Timestep Consumption Time: 2.00534
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.07707

Cumulative Model Updates: 14706
Cumulative Timesteps: 122921475

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7148.83759
Policy Entropy: 1.09398
Value Function Loss: 0.55099

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.20890
Policy Update Magnitude: 0.06927
Value Function Update Magnitude: 0.15039

Collected Steps per Second: 9229.90104
Overall Steps per Second: 6741.63533

Timestep Collection Time: 5.42064
Timestep Consumption Time: 2.00070
PPO Batch Consumption Time: 0.02397
Total Iteration Time: 7.42134

Cumulative Model Updates: 14712
Cumulative Timesteps: 122971507

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 122971507...
Checkpoint 122971507 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6715.49134
Policy Entropy: 1.08484
Value Function Loss: 0.56197

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.18848
Policy Update Magnitude: 0.07528
Value Function Update Magnitude: 0.14088

Collected Steps per Second: 10839.31521
Overall Steps per Second: 7506.54900

Timestep Collection Time: 4.61524
Timestep Consumption Time: 2.04908
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 6.66431

Cumulative Model Updates: 14718
Cumulative Timesteps: 123021533

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5410.32464
Policy Entropy: 1.08568
Value Function Loss: 0.57025

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.18295
Policy Update Magnitude: 0.08856
Value Function Update Magnitude: 0.14850

Collected Steps per Second: 10247.61331
Overall Steps per Second: 7206.03807

Timestep Collection Time: 4.88270
Timestep Consumption Time: 2.06092
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 6.94362

Cumulative Model Updates: 14724
Cumulative Timesteps: 123071569

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 123071569...
Checkpoint 123071569 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11755.28613
Policy Entropy: 1.09343
Value Function Loss: 0.56638

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.20409
Policy Update Magnitude: 0.07706
Value Function Update Magnitude: 0.14759

Collected Steps per Second: 9336.39581
Overall Steps per Second: 6731.30412

Timestep Collection Time: 5.35860
Timestep Consumption Time: 2.07384
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 7.43244

Cumulative Model Updates: 14730
Cumulative Timesteps: 123121599

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5431.60856
Policy Entropy: 1.08167
Value Function Loss: 0.57754

Mean KL Divergence: 0.02806
SB3 Clip Fraction: 0.24192
Policy Update Magnitude: 0.07065
Value Function Update Magnitude: 0.15396

Collected Steps per Second: 10059.31399
Overall Steps per Second: 7156.46758

Timestep Collection Time: 4.97430
Timestep Consumption Time: 2.01770
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 6.99200

Cumulative Model Updates: 14736
Cumulative Timesteps: 123171637

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 123171637...
Checkpoint 123171637 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6195.50891
Policy Entropy: 1.09787
Value Function Loss: 0.57822

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.20829
Policy Update Magnitude: 0.07094
Value Function Update Magnitude: 0.14934

Collected Steps per Second: 9920.58079
Overall Steps per Second: 7114.49501

Timestep Collection Time: 5.04477
Timestep Consumption Time: 1.98975
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.03451

Cumulative Model Updates: 14742
Cumulative Timesteps: 123221684

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7948.81678
Policy Entropy: 1.05980
Value Function Loss: 0.58600

Mean KL Divergence: 0.08142
SB3 Clip Fraction: 0.38231
Policy Update Magnitude: 0.07520
Value Function Update Magnitude: 0.13661

Collected Steps per Second: 9316.55401
Overall Steps per Second: 6815.33942

Timestep Collection Time: 5.37033
Timestep Consumption Time: 1.97090
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.34123

Cumulative Model Updates: 14748
Cumulative Timesteps: 123271717

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 123271717...
Checkpoint 123271717 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10019.94138
Policy Entropy: 1.10094
Value Function Loss: 0.60699

Mean KL Divergence: 0.02598
SB3 Clip Fraction: 0.21049
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.12692

Collected Steps per Second: 9255.06838
Overall Steps per Second: 6773.40299

Timestep Collection Time: 5.40547
Timestep Consumption Time: 1.98048
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 7.38595

Cumulative Model Updates: 14754
Cumulative Timesteps: 123321745

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8377.89839
Policy Entropy: 1.10175
Value Function Loss: 0.59805

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.18098
Policy Update Magnitude: 0.08007
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 9239.67345
Overall Steps per Second: 6672.47902

Timestep Collection Time: 5.41383
Timestep Consumption Time: 2.08294
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.49676

Cumulative Model Updates: 14760
Cumulative Timesteps: 123371767

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 123371767...
Checkpoint 123371767 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8141.52232
Policy Entropy: 1.10960
Value Function Loss: 0.60100

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.16087
Policy Update Magnitude: 0.09038
Value Function Update Magnitude: 0.12742

Collected Steps per Second: 9355.04975
Overall Steps per Second: 6674.93807

Timestep Collection Time: 5.34866
Timestep Consumption Time: 2.14759
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.49625

Cumulative Model Updates: 14766
Cumulative Timesteps: 123421804

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5354.78217
Policy Entropy: 1.11750
Value Function Loss: 0.58269

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.17523
Policy Update Magnitude: 0.09747
Value Function Update Magnitude: 0.15045

Collected Steps per Second: 9171.16954
Overall Steps per Second: 6691.11497

Timestep Collection Time: 5.45427
Timestep Consumption Time: 2.02162
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.47588

Cumulative Model Updates: 14772
Cumulative Timesteps: 123471826

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 123471826...
Checkpoint 123471826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6290.63370
Policy Entropy: 1.11208
Value Function Loss: 0.58415

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.16932
Policy Update Magnitude: 0.08630
Value Function Update Magnitude: 0.17673

Collected Steps per Second: 10207.04042
Overall Steps per Second: 7512.02951

Timestep Collection Time: 4.89936
Timestep Consumption Time: 1.75769
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 6.65706

Cumulative Model Updates: 14778
Cumulative Timesteps: 123521834

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10016.88384
Policy Entropy: 1.12662
Value Function Loss: 0.58603

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.15312
Policy Update Magnitude: 0.08465
Value Function Update Magnitude: 0.17220

Collected Steps per Second: 10144.61668
Overall Steps per Second: 7100.93869

Timestep Collection Time: 4.93198
Timestep Consumption Time: 2.11399
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.04597

Cumulative Model Updates: 14784
Cumulative Timesteps: 123571867

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 123571867...
Checkpoint 123571867 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6017.50094
Policy Entropy: 1.11931
Value Function Loss: 0.58079

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.10543
Value Function Update Magnitude: 0.15572

Collected Steps per Second: 9439.15484
Overall Steps per Second: 6737.37996

Timestep Collection Time: 5.29846
Timestep Consumption Time: 2.12475
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.42321

Cumulative Model Updates: 14790
Cumulative Timesteps: 123621880

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7036.59153
Policy Entropy: 1.11312
Value Function Loss: 0.57517

Mean KL Divergence: 0.02722
SB3 Clip Fraction: 0.20068
Policy Update Magnitude: 0.10695
Value Function Update Magnitude: 0.15584

Collected Steps per Second: 9805.51131
Overall Steps per Second: 7035.72285

Timestep Collection Time: 5.09928
Timestep Consumption Time: 2.00746
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.10673

Cumulative Model Updates: 14796
Cumulative Timesteps: 123671881

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 123671881...
Checkpoint 123671881 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4007.30121
Policy Entropy: 1.12404
Value Function Loss: 0.56660

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.18772
Policy Update Magnitude: 0.08426
Value Function Update Magnitude: 0.15046

Collected Steps per Second: 9676.60886
Overall Steps per Second: 7064.91428

Timestep Collection Time: 5.16896
Timestep Consumption Time: 1.91081
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 7.07977

Cumulative Model Updates: 14802
Cumulative Timesteps: 123721899

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5285.36442
Policy Entropy: 1.11099
Value Function Loss: 0.56561

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.18157
Policy Update Magnitude: 0.08200
Value Function Update Magnitude: 0.16119

Collected Steps per Second: 9289.17923
Overall Steps per Second: 6756.57380

Timestep Collection Time: 5.38444
Timestep Consumption Time: 2.01828
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.40272

Cumulative Model Updates: 14808
Cumulative Timesteps: 123771916

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 123771916...
Checkpoint 123771916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8040.78230
Policy Entropy: 1.11935
Value Function Loss: 0.55792

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15348
Policy Update Magnitude: 0.09195
Value Function Update Magnitude: 0.16516

Collected Steps per Second: 9702.59655
Overall Steps per Second: 7006.09448

Timestep Collection Time: 5.15687
Timestep Consumption Time: 1.98477
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.14164

Cumulative Model Updates: 14814
Cumulative Timesteps: 123821951

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7890.10288
Policy Entropy: 1.10829
Value Function Loss: 0.53833

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.17994
Policy Update Magnitude: 0.08978
Value Function Update Magnitude: 0.16091

Collected Steps per Second: 9852.38233
Overall Steps per Second: 7126.28612

Timestep Collection Time: 5.07806
Timestep Consumption Time: 1.94257
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.02063

Cumulative Model Updates: 14820
Cumulative Timesteps: 123871982

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 123871982...
Checkpoint 123871982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12932.51376
Policy Entropy: 1.10920
Value Function Loss: 0.54162

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.18335
Policy Update Magnitude: 0.08300
Value Function Update Magnitude: 0.13891

Collected Steps per Second: 9547.63042
Overall Steps per Second: 6936.79004

Timestep Collection Time: 5.23942
Timestep Consumption Time: 1.97199
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.21140

Cumulative Model Updates: 14826
Cumulative Timesteps: 123922006

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7504.64798
Policy Entropy: 1.10306
Value Function Loss: 0.53910

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.18837
Policy Update Magnitude: 0.07732
Value Function Update Magnitude: 0.14284

Collected Steps per Second: 9906.63160
Overall Steps per Second: 7168.44542

Timestep Collection Time: 5.05146
Timestep Consumption Time: 1.92955
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 6.98101

Cumulative Model Updates: 14832
Cumulative Timesteps: 123972049

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 123972049...
Checkpoint 123972049 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6337.13327
Policy Entropy: 1.10427
Value Function Loss: 0.56464

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.17785
Policy Update Magnitude: 0.08234
Value Function Update Magnitude: 0.13899

Collected Steps per Second: 9775.09582
Overall Steps per Second: 6976.06628

Timestep Collection Time: 5.11555
Timestep Consumption Time: 2.05253
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.16808

Cumulative Model Updates: 14838
Cumulative Timesteps: 124022054

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7820.02170
Policy Entropy: 1.09902
Value Function Loss: 0.56348

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.18047
Policy Update Magnitude: 0.08541
Value Function Update Magnitude: 0.14100

Collected Steps per Second: 9486.49663
Overall Steps per Second: 6851.04899

Timestep Collection Time: 5.27328
Timestep Consumption Time: 2.02852
PPO Batch Consumption Time: 0.03151
Total Iteration Time: 7.30180

Cumulative Model Updates: 14844
Cumulative Timesteps: 124072079

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 124072079...
Checkpoint 124072079 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9271.20515
Policy Entropy: 1.08953
Value Function Loss: 0.55270

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.15828
Policy Update Magnitude: 0.10444
Value Function Update Magnitude: 0.18052

Collected Steps per Second: 9951.30609
Overall Steps per Second: 7213.44241

Timestep Collection Time: 5.02638
Timestep Consumption Time: 1.90776
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.93414

Cumulative Model Updates: 14850
Cumulative Timesteps: 124122098

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8411.99799
Policy Entropy: 1.09710
Value Function Loss: 0.53517

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.10119
Value Function Update Magnitude: 0.18645

Collected Steps per Second: 10049.37076
Overall Steps per Second: 7230.11242

Timestep Collection Time: 4.97563
Timestep Consumption Time: 1.94016
PPO Batch Consumption Time: 0.02414
Total Iteration Time: 6.91580

Cumulative Model Updates: 14856
Cumulative Timesteps: 124172100

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 124172100...
Checkpoint 124172100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9852.33216
Policy Entropy: 1.09665
Value Function Loss: 0.53684

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.09497
Value Function Update Magnitude: 0.16257

Collected Steps per Second: 10048.02725
Overall Steps per Second: 7085.60894

Timestep Collection Time: 4.97948
Timestep Consumption Time: 2.08187
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.06135

Cumulative Model Updates: 14862
Cumulative Timesteps: 124222134

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8660.18594
Policy Entropy: 1.08802
Value Function Loss: 0.54540

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.17606
Policy Update Magnitude: 0.08358
Value Function Update Magnitude: 0.14763

Collected Steps per Second: 10107.61504
Overall Steps per Second: 7173.74873

Timestep Collection Time: 4.94963
Timestep Consumption Time: 2.02426
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 6.97390

Cumulative Model Updates: 14868
Cumulative Timesteps: 124272163

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 124272163...
Checkpoint 124272163 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10168.30770
Policy Entropy: 1.09908
Value Function Loss: 0.55664

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.16514
Policy Update Magnitude: 0.07303
Value Function Update Magnitude: 0.12303

Collected Steps per Second: 9427.35021
Overall Steps per Second: 6693.56571

Timestep Collection Time: 5.30404
Timestep Consumption Time: 2.16627
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.47031

Cumulative Model Updates: 14874
Cumulative Timesteps: 124322166

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8847.95082
Policy Entropy: 1.07847
Value Function Loss: 0.54627

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.18193
Policy Update Magnitude: 0.07799
Value Function Update Magnitude: 0.13795

Collected Steps per Second: 9598.60307
Overall Steps per Second: 6783.36319

Timestep Collection Time: 5.21295
Timestep Consumption Time: 2.16348
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 7.37643

Cumulative Model Updates: 14880
Cumulative Timesteps: 124372203

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 124372203...
Checkpoint 124372203 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10157.31659
Policy Entropy: 1.08939
Value Function Loss: 0.54806

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16913
Policy Update Magnitude: 0.08201
Value Function Update Magnitude: 0.13911

Collected Steps per Second: 10001.93283
Overall Steps per Second: 7081.46314

Timestep Collection Time: 4.99953
Timestep Consumption Time: 2.06186
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.06139

Cumulative Model Updates: 14886
Cumulative Timesteps: 124422208

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6643.99611
Policy Entropy: 1.07142
Value Function Loss: 0.54263

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.18376
Policy Update Magnitude: 0.08145
Value Function Update Magnitude: 0.14056

Collected Steps per Second: 9494.12193
Overall Steps per Second: 6906.42579

Timestep Collection Time: 5.26926
Timestep Consumption Time: 1.97428
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 7.24354

Cumulative Model Updates: 14892
Cumulative Timesteps: 124472235

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 124472235...
Checkpoint 124472235 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6425.82785
Policy Entropy: 1.07981
Value Function Loss: 0.54078

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.08005
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 10119.54514
Overall Steps per Second: 7280.61445

Timestep Collection Time: 4.94321
Timestep Consumption Time: 1.92750
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 6.87071

Cumulative Model Updates: 14898
Cumulative Timesteps: 124522258

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10412.83171
Policy Entropy: 1.06497
Value Function Loss: 0.53051

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15345
Policy Update Magnitude: 0.08131
Value Function Update Magnitude: 0.12113

Collected Steps per Second: 10085.64944
Overall Steps per Second: 7175.43328

Timestep Collection Time: 4.95883
Timestep Consumption Time: 2.01120
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 6.97003

Cumulative Model Updates: 14904
Cumulative Timesteps: 124572271

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 124572271...
Checkpoint 124572271 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10625.68587
Policy Entropy: 1.06453
Value Function Loss: 0.53005

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.08775
Value Function Update Magnitude: 0.12110

Collected Steps per Second: 9312.63224
Overall Steps per Second: 6802.45412

Timestep Collection Time: 5.36959
Timestep Consumption Time: 1.98144
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.35102

Cumulative Model Updates: 14910
Cumulative Timesteps: 124622276

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13230.74960
Policy Entropy: 1.05813
Value Function Loss: 0.53326

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.09015
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 9899.95884
Overall Steps per Second: 7120.74689

Timestep Collection Time: 5.05234
Timestep Consumption Time: 1.97192
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.02426

Cumulative Model Updates: 14916
Cumulative Timesteps: 124672294

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 124672294...
Checkpoint 124672294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8707.31549
Policy Entropy: 1.05846
Value Function Loss: 0.51192

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.09437
Value Function Update Magnitude: 0.21334

Collected Steps per Second: 9756.64035
Overall Steps per Second: 7004.19437

Timestep Collection Time: 5.12707
Timestep Consumption Time: 2.01479
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.14186

Cumulative Model Updates: 14922
Cumulative Timesteps: 124722317

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6547.34565
Policy Entropy: 1.05859
Value Function Loss: 0.51330

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.09257
Value Function Update Magnitude: 0.20981

Collected Steps per Second: 9697.24117
Overall Steps per Second: 6676.35327

Timestep Collection Time: 5.15662
Timestep Consumption Time: 2.33325
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.48987

Cumulative Model Updates: 14928
Cumulative Timesteps: 124772322

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 124772322...
Checkpoint 124772322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9269.03690
Policy Entropy: 1.06583
Value Function Loss: 0.53682

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.09437
Value Function Update Magnitude: 0.17985

Collected Steps per Second: 10620.04895
Overall Steps per Second: 7096.66155

Timestep Collection Time: 4.71222
Timestep Consumption Time: 2.33955
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 7.05177

Cumulative Model Updates: 14934
Cumulative Timesteps: 124822366

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9431.53611
Policy Entropy: 1.07005
Value Function Loss: 0.55526

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.16313
Policy Update Magnitude: 0.08749
Value Function Update Magnitude: 0.17929

Collected Steps per Second: 9359.82734
Overall Steps per Second: 6730.13407

Timestep Collection Time: 5.34380
Timestep Consumption Time: 2.08800
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.43180

Cumulative Model Updates: 14940
Cumulative Timesteps: 124872383

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 124872383...
Checkpoint 124872383 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10324.17754
Policy Entropy: 1.07068
Value Function Loss: 0.53044

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.08431
Value Function Update Magnitude: 0.16444

Collected Steps per Second: 9515.45641
Overall Steps per Second: 6904.33967

Timestep Collection Time: 5.25913
Timestep Consumption Time: 1.98892
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.24805

Cumulative Model Updates: 14946
Cumulative Timesteps: 124922426

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11192.61802
Policy Entropy: 1.06524
Value Function Loss: 0.52706

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.08797
Value Function Update Magnitude: 0.14678

Collected Steps per Second: 9741.66389
Overall Steps per Second: 6987.22036

Timestep Collection Time: 5.13742
Timestep Consumption Time: 2.02523
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.16265

Cumulative Model Updates: 14952
Cumulative Timesteps: 124972473

Timesteps Collected: 50047
--------END ITERATION REPORT--------


Saving checkpoint 124972473...
Checkpoint 124972473 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10836.03894
Policy Entropy: 1.07002
Value Function Loss: 0.51781

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.10812
Value Function Update Magnitude: 0.13409

Collected Steps per Second: 9110.49202
Overall Steps per Second: 6516.10204

Timestep Collection Time: 5.49290
Timestep Consumption Time: 2.18700
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 7.67990

Cumulative Model Updates: 14958
Cumulative Timesteps: 125022516

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9085.23784
Policy Entropy: 1.07310
Value Function Loss: 0.54288

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.19162
Policy Update Magnitude: 0.09963
Value Function Update Magnitude: 0.13614

Collected Steps per Second: 9180.89420
Overall Steps per Second: 6691.25626

Timestep Collection Time: 5.44805
Timestep Consumption Time: 2.02708
PPO Batch Consumption Time: 0.02453
Total Iteration Time: 7.47513

Cumulative Model Updates: 14964
Cumulative Timesteps: 125072534

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 125072534...
Checkpoint 125072534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6321.00901
Policy Entropy: 1.06530
Value Function Loss: 0.52006

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.16116
Policy Update Magnitude: 0.09440
Value Function Update Magnitude: 0.13522

Collected Steps per Second: 9653.25006
Overall Steps per Second: 7055.20738

Timestep Collection Time: 5.18230
Timestep Consumption Time: 1.90835
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.09065

Cumulative Model Updates: 14970
Cumulative Timesteps: 125122560

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15830.08268
Policy Entropy: 1.05864
Value Function Loss: 0.53211

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.16756
Policy Update Magnitude: 0.12163
Value Function Update Magnitude: 0.12831

Collected Steps per Second: 8844.28386
Overall Steps per Second: 6478.25054

Timestep Collection Time: 5.65574
Timestep Consumption Time: 2.06563
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.72137

Cumulative Model Updates: 14976
Cumulative Timesteps: 125172581

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 125172581...
Checkpoint 125172581 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11048.34576
Policy Entropy: 1.05762
Value Function Loss: 0.51544

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.11243
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 9436.77828
Overall Steps per Second: 6839.86495

Timestep Collection Time: 5.30149
Timestep Consumption Time: 2.01283
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 7.31433

Cumulative Model Updates: 14982
Cumulative Timesteps: 125222610

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13774.18544
Policy Entropy: 1.06652
Value Function Loss: 0.52080

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.16279
Policy Update Magnitude: 0.11635
Value Function Update Magnitude: 0.14386

Collected Steps per Second: 9722.65208
Overall Steps per Second: 6852.74194

Timestep Collection Time: 5.14613
Timestep Consumption Time: 2.15518
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 7.30131

Cumulative Model Updates: 14988
Cumulative Timesteps: 125272644

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 125272644...
Checkpoint 125272644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19693.74950
Policy Entropy: 1.06131
Value Function Loss: 0.53027

Mean KL Divergence: 0.02530
SB3 Clip Fraction: 0.18965
Policy Update Magnitude: 0.09377
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 9296.15767
Overall Steps per Second: 6704.43599

Timestep Collection Time: 5.37878
Timestep Consumption Time: 2.07927
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.45805

Cumulative Model Updates: 14994
Cumulative Timesteps: 125322646

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9198.91031
Policy Entropy: 1.05924
Value Function Loss: 0.55692

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.09305
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 10098.76191
Overall Steps per Second: 7202.22707

Timestep Collection Time: 4.95308
Timestep Consumption Time: 1.99199
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 6.94507

Cumulative Model Updates: 15000
Cumulative Timesteps: 125372666

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 125372666...
Checkpoint 125372666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11571.16080
Policy Entropy: 1.05758
Value Function Loss: 0.55773

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.09980
Value Function Update Magnitude: 0.12853

Collected Steps per Second: 10049.71396
Overall Steps per Second: 7133.46134

Timestep Collection Time: 4.97626
Timestep Consumption Time: 2.03436
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 7.01062

Cumulative Model Updates: 15006
Cumulative Timesteps: 125422676

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10018.71154
Policy Entropy: 1.06466
Value Function Loss: 0.55211

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.09200
Value Function Update Magnitude: 0.15923

Collected Steps per Second: 9790.63229
Overall Steps per Second: 7091.12847

Timestep Collection Time: 5.10937
Timestep Consumption Time: 1.94507
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.05445

Cumulative Model Updates: 15012
Cumulative Timesteps: 125472700

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 125472700...
Checkpoint 125472700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13096.81389
Policy Entropy: 1.06975
Value Function Loss: 0.56292

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.08536
Value Function Update Magnitude: 0.16183

Collected Steps per Second: 9842.45817
Overall Steps per Second: 7142.42042

Timestep Collection Time: 5.08054
Timestep Consumption Time: 1.92059
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.00113

Cumulative Model Updates: 15018
Cumulative Timesteps: 125522705

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11182.46648
Policy Entropy: 1.06186
Value Function Loss: 0.57526

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.08285
Value Function Update Magnitude: 0.14699

Collected Steps per Second: 10049.84870
Overall Steps per Second: 7221.80283

Timestep Collection Time: 4.97769
Timestep Consumption Time: 1.94925
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.92694

Cumulative Model Updates: 15024
Cumulative Timesteps: 125572730

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 125572730...
Checkpoint 125572730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13264.80088
Policy Entropy: 1.06566
Value Function Loss: 0.54884

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.16135
Policy Update Magnitude: 0.07705
Value Function Update Magnitude: 0.14140

Collected Steps per Second: 10040.37595
Overall Steps per Second: 7228.80742

Timestep Collection Time: 4.98079
Timestep Consumption Time: 1.93723
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 6.91802

Cumulative Model Updates: 15030
Cumulative Timesteps: 125622739

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13025.19091
Policy Entropy: 1.04472
Value Function Loss: 0.49487

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.18524
Policy Update Magnitude: 0.07729
Value Function Update Magnitude: 0.16550

Collected Steps per Second: 10200.14838
Overall Steps per Second: 7325.36656

Timestep Collection Time: 4.90434
Timestep Consumption Time: 1.92467
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 6.82901

Cumulative Model Updates: 15036
Cumulative Timesteps: 125672764

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 125672764...
Checkpoint 125672764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13302.43632
Policy Entropy: 1.05966
Value Function Loss: 0.50644

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.08538
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10226.15138
Overall Steps per Second: 7346.25500

Timestep Collection Time: 4.89089
Timestep Consumption Time: 1.91734
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 6.80823

Cumulative Model Updates: 15042
Cumulative Timesteps: 125722779

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11243.14148
Policy Entropy: 1.05204
Value Function Loss: 0.51997

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.17797
Policy Update Magnitude: 0.09306
Value Function Update Magnitude: 0.11931

Collected Steps per Second: 10193.40201
Overall Steps per Second: 7269.57271

Timestep Collection Time: 4.90896
Timestep Consumption Time: 1.97439
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.88335

Cumulative Model Updates: 15048
Cumulative Timesteps: 125772818

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 125772818...
Checkpoint 125772818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10792.71272
Policy Entropy: 1.06552
Value Function Loss: 0.53867

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.08783
Value Function Update Magnitude: 0.12118

Collected Steps per Second: 9821.29731
Overall Steps per Second: 7043.86915

Timestep Collection Time: 5.09149
Timestep Consumption Time: 2.00760
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.09908

Cumulative Model Updates: 15054
Cumulative Timesteps: 125822823

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10391.61662
Policy Entropy: 1.05459
Value Function Loss: 0.52913

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.09613
Value Function Update Magnitude: 0.12388

Collected Steps per Second: 9182.72208
Overall Steps per Second: 6756.78677

Timestep Collection Time: 5.44588
Timestep Consumption Time: 1.95527
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 7.40115

Cumulative Model Updates: 15060
Cumulative Timesteps: 125872831

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 125872831...
Checkpoint 125872831 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14240.28497
Policy Entropy: 1.05233
Value Function Loss: 0.52772

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.17774
Policy Update Magnitude: 0.09490
Value Function Update Magnitude: 0.16296

Collected Steps per Second: 10200.72772
Overall Steps per Second: 7295.09076

Timestep Collection Time: 4.90161
Timestep Consumption Time: 1.95231
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 6.85392

Cumulative Model Updates: 15066
Cumulative Timesteps: 125922831

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13531.59781
Policy Entropy: 1.05416
Value Function Loss: 0.54046

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.08514
Value Function Update Magnitude: 0.15184

Collected Steps per Second: 10043.60977
Overall Steps per Second: 7369.12111

Timestep Collection Time: 4.98128
Timestep Consumption Time: 1.80786
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 6.78914

Cumulative Model Updates: 15072
Cumulative Timesteps: 125972861

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 125972861...
Checkpoint 125972861 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8132.72104
Policy Entropy: 1.04782
Value Function Loss: 0.52402

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.09241
Value Function Update Magnitude: 0.13686

Collected Steps per Second: 9279.86137
Overall Steps per Second: 6484.13127

Timestep Collection Time: 5.38920
Timestep Consumption Time: 2.32363
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.71283

Cumulative Model Updates: 15078
Cumulative Timesteps: 126022872

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13663.61269
Policy Entropy: 1.04307
Value Function Loss: 0.52332

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.10289
Value Function Update Magnitude: 0.13279

Collected Steps per Second: 10303.35733
Overall Steps per Second: 7132.67507

Timestep Collection Time: 4.85618
Timestep Consumption Time: 2.15872
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.01490

Cumulative Model Updates: 15084
Cumulative Timesteps: 126072907

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 126072907...
Checkpoint 126072907 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7214.18310
Policy Entropy: 1.04129
Value Function Loss: 0.51942

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.09664
Value Function Update Magnitude: 0.13314

Collected Steps per Second: 10112.43909
Overall Steps per Second: 6893.69547

Timestep Collection Time: 4.94441
Timestep Consumption Time: 2.30860
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.25300

Cumulative Model Updates: 15090
Cumulative Timesteps: 126122907

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11697.05489
Policy Entropy: 1.03110
Value Function Loss: 0.52227

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.09593
Value Function Update Magnitude: 0.14013

Collected Steps per Second: 9518.59447
Overall Steps per Second: 6636.89551

Timestep Collection Time: 5.25624
Timestep Consumption Time: 2.28223
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.53846

Cumulative Model Updates: 15096
Cumulative Timesteps: 126172939

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 126172939...
Checkpoint 126172939 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17830.72177
Policy Entropy: 1.02602
Value Function Loss: 0.51834

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.09799
Value Function Update Magnitude: 0.12788

Collected Steps per Second: 10102.15413
Overall Steps per Second: 7100.08471

Timestep Collection Time: 4.95043
Timestep Consumption Time: 2.09315
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.04358

Cumulative Model Updates: 15102
Cumulative Timesteps: 126222949

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18197.28810
Policy Entropy: 1.01918
Value Function Loss: 0.50561

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.18337
Policy Update Magnitude: 0.09988
Value Function Update Magnitude: 0.13816

Collected Steps per Second: 9365.65860
Overall Steps per Second: 6493.08730

Timestep Collection Time: 5.34143
Timestep Consumption Time: 2.36307
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 7.70450

Cumulative Model Updates: 15108
Cumulative Timesteps: 126272975

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 126272975...
Checkpoint 126272975 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13503.78938
Policy Entropy: 1.02435
Value Function Loss: 0.52872

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.08806
Value Function Update Magnitude: 0.12986

Collected Steps per Second: 9721.23911
Overall Steps per Second: 6742.61762

Timestep Collection Time: 5.14348
Timestep Consumption Time: 2.27219
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.41567

Cumulative Model Updates: 15114
Cumulative Timesteps: 126322976

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11553.02331
Policy Entropy: 1.02668
Value Function Loss: 0.55524

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.18978
Policy Update Magnitude: 0.09282
Value Function Update Magnitude: 0.12228

Collected Steps per Second: 10694.68928
Overall Steps per Second: 7372.84822

Timestep Collection Time: 4.67550
Timestep Consumption Time: 2.10655
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 6.78205

Cumulative Model Updates: 15120
Cumulative Timesteps: 126372979

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 126372979...
Checkpoint 126372979 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9171.59357
Policy Entropy: 1.02849
Value Function Loss: 0.56657

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.09063
Value Function Update Magnitude: 0.11894

Collected Steps per Second: 9787.83268
Overall Steps per Second: 6719.39318

Timestep Collection Time: 5.11196
Timestep Consumption Time: 2.33440
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.44636

Cumulative Model Updates: 15126
Cumulative Timesteps: 126423014

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18014.26045
Policy Entropy: 1.02555
Value Function Loss: 0.54691

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.16172
Policy Update Magnitude: 0.09047
Value Function Update Magnitude: 0.13373

Collected Steps per Second: 9777.00359
Overall Steps per Second: 6753.81791

Timestep Collection Time: 5.11568
Timestep Consumption Time: 2.28991
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.40559

Cumulative Model Updates: 15132
Cumulative Timesteps: 126473030

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 126473030...
Checkpoint 126473030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14203.31635
Policy Entropy: 1.01786
Value Function Loss: 0.50643

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.16000
Policy Update Magnitude: 0.08143
Value Function Update Magnitude: 0.13311

Collected Steps per Second: 10128.78411
Overall Steps per Second: 7241.09084

Timestep Collection Time: 4.93791
Timestep Consumption Time: 1.96920
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 6.90711

Cumulative Model Updates: 15138
Cumulative Timesteps: 126523045

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14371.35291
Policy Entropy: 1.01814
Value Function Loss: 0.49679

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.17219
Policy Update Magnitude: 0.07761
Value Function Update Magnitude: 0.11828

Collected Steps per Second: 10110.24310
Overall Steps per Second: 7076.43310

Timestep Collection Time: 4.94607
Timestep Consumption Time: 2.12048
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.06655

Cumulative Model Updates: 15144
Cumulative Timesteps: 126573051

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 126573051...
Checkpoint 126573051 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8598.03049
Policy Entropy: 1.00566
Value Function Loss: 0.50590

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.08153
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10396.49969
Overall Steps per Second: 7385.70731

Timestep Collection Time: 4.81123
Timestep Consumption Time: 1.96131
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.77254

Cumulative Model Updates: 15150
Cumulative Timesteps: 126623071

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12613.32061
Policy Entropy: 0.99888
Value Function Loss: 0.51149

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.08979
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 9919.96881
Overall Steps per Second: 7023.83481

Timestep Collection Time: 5.04114
Timestep Consumption Time: 2.07861
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.11976

Cumulative Model Updates: 15156
Cumulative Timesteps: 126673079

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 126673079...
Checkpoint 126673079 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13949.37960
Policy Entropy: 0.99839
Value Function Loss: 0.53140

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.15700
Policy Update Magnitude: 0.08883
Value Function Update Magnitude: 0.12128

Collected Steps per Second: 10041.84901
Overall Steps per Second: 7137.53556

Timestep Collection Time: 4.98046
Timestep Consumption Time: 2.02658
PPO Batch Consumption Time: 0.02436
Total Iteration Time: 7.00704

Cumulative Model Updates: 15162
Cumulative Timesteps: 126723092

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15508.80232
Policy Entropy: 1.00179
Value Function Loss: 0.52114

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.09707
Value Function Update Magnitude: 0.12772

Collected Steps per Second: 9644.14451
Overall Steps per Second: 6895.51463

Timestep Collection Time: 5.18677
Timestep Consumption Time: 2.06751
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.25428

Cumulative Model Updates: 15168
Cumulative Timesteps: 126773114

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 126773114...
Checkpoint 126773114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11091.86520
Policy Entropy: 1.00518
Value Function Loss: 0.51222

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.16442
Policy Update Magnitude: 0.10158
Value Function Update Magnitude: 0.12869

Collected Steps per Second: 9407.58940
Overall Steps per Second: 6847.71490

Timestep Collection Time: 5.31635
Timestep Consumption Time: 1.98740
PPO Batch Consumption Time: 0.02413
Total Iteration Time: 7.30375

Cumulative Model Updates: 15174
Cumulative Timesteps: 126823128

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15440.52690
Policy Entropy: 0.99871
Value Function Loss: 0.49612

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.17192
Policy Update Magnitude: 0.10045
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 10125.56446
Overall Steps per Second: 7252.95883

Timestep Collection Time: 4.93898
Timestep Consumption Time: 1.95613
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.89512

Cumulative Model Updates: 15180
Cumulative Timesteps: 126873138

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 126873138...
Checkpoint 126873138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22113.05502
Policy Entropy: 1.00689
Value Function Loss: 0.51576

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.09522
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 9929.00468
Overall Steps per Second: 7144.66826

Timestep Collection Time: 5.03867
Timestep Consumption Time: 1.96361
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.00228

Cumulative Model Updates: 15186
Cumulative Timesteps: 126923167

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18222.11165
Policy Entropy: 1.00195
Value Function Loss: 0.50337

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.10462
Value Function Update Magnitude: 0.11578

Collected Steps per Second: 9746.70455
Overall Steps per Second: 7054.16189

Timestep Collection Time: 5.13199
Timestep Consumption Time: 1.95886
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.09085

Cumulative Model Updates: 15192
Cumulative Timesteps: 126973187

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 126973187...
Checkpoint 126973187 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16980.57120
Policy Entropy: 1.00494
Value Function Loss: 0.50592

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.10089
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 9880.44510
Overall Steps per Second: 7128.76785

Timestep Collection Time: 5.06364
Timestep Consumption Time: 1.95455
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 7.01818

Cumulative Model Updates: 15198
Cumulative Timesteps: 127023218

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7225.58381
Policy Entropy: 1.00311
Value Function Loss: 0.49889

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.18560
Policy Update Magnitude: 0.09374
Value Function Update Magnitude: 0.11040

Collected Steps per Second: 9859.04859
Overall Steps per Second: 7095.16332

Timestep Collection Time: 5.07341
Timestep Consumption Time: 1.97632
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.04973

Cumulative Model Updates: 15204
Cumulative Timesteps: 127073237

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 127073237...
Checkpoint 127073237 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14544.42511
Policy Entropy: 0.99164
Value Function Loss: 0.49903

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.15288
Policy Update Magnitude: 0.09318
Value Function Update Magnitude: 0.11746

Collected Steps per Second: 9936.65771
Overall Steps per Second: 7152.25624

Timestep Collection Time: 5.03197
Timestep Consumption Time: 1.95897
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.99094

Cumulative Model Updates: 15210
Cumulative Timesteps: 127123238

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14322.99336
Policy Entropy: 0.99539
Value Function Loss: 0.50250

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.17362
Policy Update Magnitude: 0.10970
Value Function Update Magnitude: 0.13293

Collected Steps per Second: 10064.71052
Overall Steps per Second: 7210.63114

Timestep Collection Time: 4.97143
Timestep Consumption Time: 1.96777
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 6.93920

Cumulative Model Updates: 15216
Cumulative Timesteps: 127173274

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 127173274...
Checkpoint 127173274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20218.32529
Policy Entropy: 0.99641
Value Function Loss: 0.48970

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.18051
Policy Update Magnitude: 0.10246
Value Function Update Magnitude: 0.13686

Collected Steps per Second: 9905.74714
Overall Steps per Second: 7105.65669

Timestep Collection Time: 5.04879
Timestep Consumption Time: 1.98955
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.03834

Cumulative Model Updates: 15222
Cumulative Timesteps: 127223286

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21650.70016
Policy Entropy: 1.00912
Value Function Loss: 0.49829

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.16591
Policy Update Magnitude: 0.10476
Value Function Update Magnitude: 0.12293

Collected Steps per Second: 9815.52176
Overall Steps per Second: 7107.06903

Timestep Collection Time: 5.09570
Timestep Consumption Time: 1.94194
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.03764

Cumulative Model Updates: 15228
Cumulative Timesteps: 127273303

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 127273303...
Checkpoint 127273303 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18761.37342
Policy Entropy: 1.01778
Value Function Loss: 0.52643

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.09279
Value Function Update Magnitude: 0.11075

Collected Steps per Second: 9881.30989
Overall Steps per Second: 7162.32796

Timestep Collection Time: 5.06137
Timestep Consumption Time: 1.92141
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.98279

Cumulative Model Updates: 15234
Cumulative Timesteps: 127323316

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16525.47967
Policy Entropy: 1.01786
Value Function Loss: 0.52671

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.11026
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 9934.63106
Overall Steps per Second: 7168.15984

Timestep Collection Time: 5.03370
Timestep Consumption Time: 1.94270
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 6.97641

Cumulative Model Updates: 15240
Cumulative Timesteps: 127373324

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 127373324...
Checkpoint 127373324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9586.72258
Policy Entropy: 1.03175
Value Function Loss: 0.54649

Mean KL Divergence: 0.02141
SB3 Clip Fraction: 0.18133
Policy Update Magnitude: 0.10386
Value Function Update Magnitude: 0.12234

Collected Steps per Second: 9883.11678
Overall Steps per Second: 7100.45551

Timestep Collection Time: 5.06045
Timestep Consumption Time: 1.98318
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.04363

Cumulative Model Updates: 15246
Cumulative Timesteps: 127423337

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8673.03575
Policy Entropy: 1.02726
Value Function Loss: 0.54571

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.16492
Policy Update Magnitude: 0.09806
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 9872.00128
Overall Steps per Second: 7119.80189

Timestep Collection Time: 5.06878
Timestep Consumption Time: 1.95937
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.02814

Cumulative Model Updates: 15252
Cumulative Timesteps: 127473376

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 127473376...
Checkpoint 127473376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10936.47160
Policy Entropy: 1.03943
Value Function Loss: 0.56812

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.16662
Policy Update Magnitude: 0.10252
Value Function Update Magnitude: 0.13320

Collected Steps per Second: 10411.05816
Overall Steps per Second: 7073.02717

Timestep Collection Time: 4.80556
Timestep Consumption Time: 2.26793
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.07349

Cumulative Model Updates: 15258
Cumulative Timesteps: 127523407

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9523.86780
Policy Entropy: 1.02841
Value Function Loss: 0.55098

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.19636
Policy Update Magnitude: 0.09434
Value Function Update Magnitude: 0.13880

Collected Steps per Second: 10530.13722
Overall Steps per Second: 7179.69121

Timestep Collection Time: 4.75141
Timestep Consumption Time: 2.21727
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.96868

Cumulative Model Updates: 15264
Cumulative Timesteps: 127573440

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 127573440...
Checkpoint 127573440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15100.77236
Policy Entropy: 1.03881
Value Function Loss: 0.54971

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.17897
Policy Update Magnitude: 0.08285
Value Function Update Magnitude: 0.13192

Collected Steps per Second: 10338.95446
Overall Steps per Second: 6924.53878

Timestep Collection Time: 4.83821
Timestep Consumption Time: 2.38567
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.22387

Cumulative Model Updates: 15270
Cumulative Timesteps: 127623462

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14189.28111
Policy Entropy: 1.01838
Value Function Loss: 0.52070

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.18504
Policy Update Magnitude: 0.08366
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 10498.67426
Overall Steps per Second: 7006.39637

Timestep Collection Time: 4.76594
Timestep Consumption Time: 2.37554
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 7.14147

Cumulative Model Updates: 15276
Cumulative Timesteps: 127673498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 127673498...
Checkpoint 127673498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12776.64223
Policy Entropy: 1.01975
Value Function Loss: 0.50487

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.18128
Policy Update Magnitude: 0.08558
Value Function Update Magnitude: 0.14014

Collected Steps per Second: 10480.03501
Overall Steps per Second: 7079.95362

Timestep Collection Time: 4.77393
Timestep Consumption Time: 2.29264
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.06657

Cumulative Model Updates: 15282
Cumulative Timesteps: 127723529

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14626.90129
Policy Entropy: 1.03370
Value Function Loss: 0.50687

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.18410
Policy Update Magnitude: 0.08067
Value Function Update Magnitude: 0.13854

Collected Steps per Second: 9863.41375
Overall Steps per Second: 6904.91984

Timestep Collection Time: 5.07208
Timestep Consumption Time: 2.17319
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.24527

Cumulative Model Updates: 15288
Cumulative Timesteps: 127773557

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 127773557...
Checkpoint 127773557 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24932.10897
Policy Entropy: 1.01922
Value Function Loss: 0.51119

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.18467
Policy Update Magnitude: 0.08299
Value Function Update Magnitude: 0.15240

Collected Steps per Second: 9338.81154
Overall Steps per Second: 6806.46677

Timestep Collection Time: 5.35646
Timestep Consumption Time: 1.99287
PPO Batch Consumption Time: 0.02490
Total Iteration Time: 7.34933

Cumulative Model Updates: 15294
Cumulative Timesteps: 127823580

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13634.40571
Policy Entropy: 1.02180
Value Function Loss: 0.51249

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.16595
Policy Update Magnitude: 0.09744
Value Function Update Magnitude: 0.14591

Collected Steps per Second: 10189.98219
Overall Steps per Second: 7139.07835

Timestep Collection Time: 4.91041
Timestep Consumption Time: 2.09848
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.00889

Cumulative Model Updates: 15300
Cumulative Timesteps: 127873617

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 127873617...
Checkpoint 127873617 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11790.60866
Policy Entropy: 1.00877
Value Function Loss: 0.50741

Mean KL Divergence: 0.02914
SB3 Clip Fraction: 0.22551
Policy Update Magnitude: 0.09289
Value Function Update Magnitude: 0.15312

Collected Steps per Second: 9658.86837
Overall Steps per Second: 6817.88555

Timestep Collection Time: 5.17669
Timestep Consumption Time: 2.15711
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.33380

Cumulative Model Updates: 15306
Cumulative Timesteps: 127923618

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8734.19861
Policy Entropy: 1.01396
Value Function Loss: 0.51694

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.18939
Policy Update Magnitude: 0.07960
Value Function Update Magnitude: 0.16017

Collected Steps per Second: 9481.50628
Overall Steps per Second: 6797.02986

Timestep Collection Time: 5.27448
Timestep Consumption Time: 2.08315
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.35763

Cumulative Model Updates: 15312
Cumulative Timesteps: 127973628

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 127973628...
Checkpoint 127973628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16141.81758
Policy Entropy: 1.01450
Value Function Loss: 0.52931

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.19242
Policy Update Magnitude: 0.08533
Value Function Update Magnitude: 0.16694

Collected Steps per Second: 9999.54453
Overall Steps per Second: 7045.12281

Timestep Collection Time: 5.00033
Timestep Consumption Time: 2.09692
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.09725

Cumulative Model Updates: 15318
Cumulative Timesteps: 128023629

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11165.63791
Policy Entropy: 1.01312
Value Function Loss: 0.50022

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.16068
Policy Update Magnitude: 0.08815
Value Function Update Magnitude: 0.19177

Collected Steps per Second: 9284.80672
Overall Steps per Second: 6639.80730

Timestep Collection Time: 5.38848
Timestep Consumption Time: 2.14653
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.53501

Cumulative Model Updates: 15324
Cumulative Timesteps: 128073660

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 128073660...
Checkpoint 128073660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9462.92405
Policy Entropy: 1.01558
Value Function Loss: 0.49357

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.10257
Value Function Update Magnitude: 0.19330

Collected Steps per Second: 9582.62531
Overall Steps per Second: 6937.21249

Timestep Collection Time: 5.22112
Timestep Consumption Time: 1.99100
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.21212

Cumulative Model Updates: 15330
Cumulative Timesteps: 128123692

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18871.55106
Policy Entropy: 1.01053
Value Function Loss: 0.48063

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.19867
Policy Update Magnitude: 0.10480
Value Function Update Magnitude: 0.18328

Collected Steps per Second: 9954.43021
Overall Steps per Second: 7122.70836

Timestep Collection Time: 5.02661
Timestep Consumption Time: 1.99839
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.02500

Cumulative Model Updates: 15336
Cumulative Timesteps: 128173729

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 128173729...
Checkpoint 128173729 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15937.35220
Policy Entropy: 1.00790
Value Function Loss: 0.48726

Mean KL Divergence: 0.02265
SB3 Clip Fraction: 0.17153
Policy Update Magnitude: 0.08944
Value Function Update Magnitude: 0.18636

Collected Steps per Second: 9984.55778
Overall Steps per Second: 7187.80400

Timestep Collection Time: 5.00863
Timestep Consumption Time: 1.94885
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 6.95748

Cumulative Model Updates: 15342
Cumulative Timesteps: 128223738

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21244.12442
Policy Entropy: 0.99932
Value Function Loss: 0.48083

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.16431
Policy Update Magnitude: 0.09047
Value Function Update Magnitude: 0.21274

Collected Steps per Second: 9688.07726
Overall Steps per Second: 6932.88539

Timestep Collection Time: 5.16398
Timestep Consumption Time: 2.05221
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.21619

Cumulative Model Updates: 15348
Cumulative Timesteps: 128273767

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 128273767...
Checkpoint 128273767 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16941.35861
Policy Entropy: 1.00604
Value Function Loss: 0.49091

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.17818
Policy Update Magnitude: 0.08365
Value Function Update Magnitude: 0.20054

Collected Steps per Second: 9451.03424
Overall Steps per Second: 6810.75944

Timestep Collection Time: 5.29445
Timestep Consumption Time: 2.05246
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 7.34690

Cumulative Model Updates: 15354
Cumulative Timesteps: 128323805

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16640.27207
Policy Entropy: 1.00524
Value Function Loss: 0.49356

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.20055
Policy Update Magnitude: 0.08258
Value Function Update Magnitude: 0.18430

Collected Steps per Second: 9580.32885
Overall Steps per Second: 6934.81433

Timestep Collection Time: 5.22352
Timestep Consumption Time: 1.99268
PPO Batch Consumption Time: 0.02354
Total Iteration Time: 7.21620

Cumulative Model Updates: 15360
Cumulative Timesteps: 128373848

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 128373848...
Checkpoint 128373848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22180.07951
Policy Entropy: 1.00130
Value Function Loss: 0.50961

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.17442
Policy Update Magnitude: 0.08373
Value Function Update Magnitude: 0.18361

Collected Steps per Second: 9284.90305
Overall Steps per Second: 6726.10014

Timestep Collection Time: 5.38606
Timestep Consumption Time: 2.04901
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.43507

Cumulative Model Updates: 15366
Cumulative Timesteps: 128423857

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13420.20834
Policy Entropy: 1.01381
Value Function Loss: 0.50634

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.18995
Policy Update Magnitude: 0.07849
Value Function Update Magnitude: 0.19772

Collected Steps per Second: 10064.62562
Overall Steps per Second: 7296.72836

Timestep Collection Time: 4.97088
Timestep Consumption Time: 1.88562
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.85650

Cumulative Model Updates: 15372
Cumulative Timesteps: 128473887

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 128473887...
Checkpoint 128473887 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13459.50951
Policy Entropy: 0.99417
Value Function Loss: 0.51054

Mean KL Divergence: 0.02742
SB3 Clip Fraction: 0.24806
Policy Update Magnitude: 0.07493
Value Function Update Magnitude: 0.17361

Collected Steps per Second: 9682.24961
Overall Steps per Second: 6987.06511

Timestep Collection Time: 5.16894
Timestep Consumption Time: 1.99386
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.16281

Cumulative Model Updates: 15378
Cumulative Timesteps: 128523934

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18211.77336
Policy Entropy: 1.01697
Value Function Loss: 0.51459

Mean KL Divergence: 0.02212
SB3 Clip Fraction: 0.21932
Policy Update Magnitude: 0.07371
Value Function Update Magnitude: 0.14161

Collected Steps per Second: 9216.19387
Overall Steps per Second: 6776.35233

Timestep Collection Time: 5.42578
Timestep Consumption Time: 1.95356
PPO Batch Consumption Time: 0.02459
Total Iteration Time: 7.37934

Cumulative Model Updates: 15384
Cumulative Timesteps: 128573939

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 128573939...
Checkpoint 128573939 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25379.09532
Policy Entropy: 0.99733
Value Function Loss: 0.51161

Mean KL Divergence: 0.02426
SB3 Clip Fraction: 0.22411
Policy Update Magnitude: 0.08533
Value Function Update Magnitude: 0.14422

Collected Steps per Second: 9615.12927
Overall Steps per Second: 7045.96923

Timestep Collection Time: 5.20222
Timestep Consumption Time: 1.89688
PPO Batch Consumption Time: 0.02491
Total Iteration Time: 7.09909

Cumulative Model Updates: 15390
Cumulative Timesteps: 128623959

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16251.76137
Policy Entropy: 1.00034
Value Function Loss: 0.50507

Mean KL Divergence: 0.03118
SB3 Clip Fraction: 0.22392
Policy Update Magnitude: 0.07922
Value Function Update Magnitude: 0.12830

Collected Steps per Second: 9344.33090
Overall Steps per Second: 6918.26016

Timestep Collection Time: 5.35341
Timestep Consumption Time: 1.87731
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.23072

Cumulative Model Updates: 15396
Cumulative Timesteps: 128673983

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 128673983...
Checkpoint 128673983 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13950.87863
Policy Entropy: 1.00418
Value Function Loss: 0.51758

Mean KL Divergence: 0.02816
SB3 Clip Fraction: 0.21269
Policy Update Magnitude: 0.07628
Value Function Update Magnitude: 0.13878

Collected Steps per Second: 9349.60578
Overall Steps per Second: 6765.21287

Timestep Collection Time: 5.35220
Timestep Consumption Time: 2.04461
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 7.39681

Cumulative Model Updates: 15402
Cumulative Timesteps: 128724024

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14782.81337
Policy Entropy: 1.01373
Value Function Loss: 0.49444

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.16457
Policy Update Magnitude: 0.09499
Value Function Update Magnitude: 0.13144

Collected Steps per Second: 9934.11129
Overall Steps per Second: 7101.56481

Timestep Collection Time: 5.03397
Timestep Consumption Time: 2.00786
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.04183

Cumulative Model Updates: 15408
Cumulative Timesteps: 128774032

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 128774032...
Checkpoint 128774032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19722.93226
Policy Entropy: 1.02117
Value Function Loss: 0.48457

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16438
Policy Update Magnitude: 0.09432
Value Function Update Magnitude: 0.15016

Collected Steps per Second: 9851.24583
Overall Steps per Second: 7048.23883

Timestep Collection Time: 5.07692
Timestep Consumption Time: 2.01904
PPO Batch Consumption Time: 0.02422
Total Iteration Time: 7.09596

Cumulative Model Updates: 15414
Cumulative Timesteps: 128824046

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8950.18556
Policy Entropy: 1.02052
Value Function Loss: 0.47199

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.09186
Value Function Update Magnitude: 0.17534

Collected Steps per Second: 9438.74647
Overall Steps per Second: 6721.24412

Timestep Collection Time: 5.29827
Timestep Consumption Time: 2.14217
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.44044

Cumulative Model Updates: 15420
Cumulative Timesteps: 128874055

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 128874055...
Checkpoint 128874055 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13066.54621
Policy Entropy: 1.02156
Value Function Loss: 0.46818

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.09164
Value Function Update Magnitude: 0.15998

Collected Steps per Second: 9804.08432
Overall Steps per Second: 7043.35949

Timestep Collection Time: 5.10094
Timestep Consumption Time: 1.99937
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.10030

Cumulative Model Updates: 15426
Cumulative Timesteps: 128924065

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15507.98017
Policy Entropy: 1.01806
Value Function Loss: 0.47835

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.09170
Value Function Update Magnitude: 0.13074

Collected Steps per Second: 10215.14647
Overall Steps per Second: 7239.71671

Timestep Collection Time: 4.89802
Timestep Consumption Time: 2.01302
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 6.91104

Cumulative Model Updates: 15432
Cumulative Timesteps: 128974099

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 128974099...
Checkpoint 128974099 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20636.32092
Policy Entropy: 1.01912
Value Function Loss: 0.48631

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.09741
Value Function Update Magnitude: 0.12714

Collected Steps per Second: 9363.80619
Overall Steps per Second: 6720.52943

Timestep Collection Time: 5.34270
Timestep Consumption Time: 2.10136
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 7.44406

Cumulative Model Updates: 15438
Cumulative Timesteps: 129024127

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24350.76673
Policy Entropy: 1.02213
Value Function Loss: 0.49950

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.10317
Value Function Update Magnitude: 0.13085

Collected Steps per Second: 9810.63236
Overall Steps per Second: 7106.10408

Timestep Collection Time: 5.09651
Timestep Consumption Time: 1.93969
PPO Batch Consumption Time: 0.02443
Total Iteration Time: 7.03620

Cumulative Model Updates: 15444
Cumulative Timesteps: 129074127

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 129074127...
Checkpoint 129074127 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18336.99667
Policy Entropy: 1.02560
Value Function Loss: 0.48644

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.10549
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 9717.02268
Overall Steps per Second: 6967.03228

Timestep Collection Time: 5.14798
Timestep Consumption Time: 2.03198
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 7.17996

Cumulative Model Updates: 15450
Cumulative Timesteps: 129124150

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14414.33301
Policy Entropy: 1.02376
Value Function Loss: 0.46117

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.17515
Policy Update Magnitude: 0.09837
Value Function Update Magnitude: 0.13047

Collected Steps per Second: 9340.87790
Overall Steps per Second: 6799.76559

Timestep Collection Time: 5.35528
Timestep Consumption Time: 2.00130
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.35658

Cumulative Model Updates: 15456
Cumulative Timesteps: 129174173

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 129174173...
Checkpoint 129174173 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18570.69256
Policy Entropy: 1.03164
Value Function Loss: 0.45484

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.08619
Value Function Update Magnitude: 0.13254

Collected Steps per Second: 9783.73954
Overall Steps per Second: 6973.16321

Timestep Collection Time: 5.11113
Timestep Consumption Time: 2.06007
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.17121

Cumulative Model Updates: 15462
Cumulative Timesteps: 129224179

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14491.76767
Policy Entropy: 1.01353
Value Function Loss: 0.43559

Mean KL Divergence: 0.02135
SB3 Clip Fraction: 0.17830
Policy Update Magnitude: 0.08727
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 9636.05612
Overall Steps per Second: 6940.78359

Timestep Collection Time: 5.19082
Timestep Consumption Time: 2.01572
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.20654

Cumulative Model Updates: 15468
Cumulative Timesteps: 129274198

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 129274198...
Checkpoint 129274198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18308.15436
Policy Entropy: 1.01155
Value Function Loss: 0.43403

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16739
Policy Update Magnitude: 0.10205
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 9311.22998
Overall Steps per Second: 6764.25905

Timestep Collection Time: 5.37050
Timestep Consumption Time: 2.02218
PPO Batch Consumption Time: 0.02483
Total Iteration Time: 7.39268

Cumulative Model Updates: 15474
Cumulative Timesteps: 129324204

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12459.96917
Policy Entropy: 1.00921
Value Function Loss: 0.46372

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.17868
Policy Update Magnitude: 0.09745
Value Function Update Magnitude: 0.11315

Collected Steps per Second: 9522.54988
Overall Steps per Second: 6760.43741

Timestep Collection Time: 5.25437
Timestep Consumption Time: 2.14678
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.40115

Cumulative Model Updates: 15480
Cumulative Timesteps: 129374239

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 129374239...
Checkpoint 129374239 saved!
