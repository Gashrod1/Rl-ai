Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.39547
Policy Entropy: 0.28307
Value Function Loss: 0.27441

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00271
Policy Update Magnitude: 0.02055
Value Function Update Magnitude: 0.01264

Collected Steps per Second: 2,677.12757
Overall Steps per Second: 2,333.15371

Timestep Collection Time: 18.67673
Timestep Consumption Time: 2.75349
PPO Batch Consumption Time: 0.71467
Total Iteration Time: 21.43022

Cumulative Model Updates: 1,482
Cumulative Timesteps: 12,750,565

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.39168
Policy Entropy: 0.28686
Value Function Loss: 0.28286

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04788
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.03081

Collected Steps per Second: 2,545.43504
Overall Steps per Second: 1,996.74174

Timestep Collection Time: 19.64536
Timestep Consumption Time: 5.39843
PPO Batch Consumption Time: 0.97002
Total Iteration Time: 25.04380

Cumulative Model Updates: 1,486
Cumulative Timesteps: 12,800,571

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 12800571...
Checkpoint 12800571 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.13252
Policy Entropy: 0.28790
Value Function Loss: 0.29220

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.03449

Collected Steps per Second: 2,457.03687
Overall Steps per Second: 1,806.11932

Timestep Collection Time: 20.35053
Timestep Consumption Time: 7.33424
PPO Batch Consumption Time: 0.95917
Total Iteration Time: 27.68477

Cumulative Model Updates: 1,492
Cumulative Timesteps: 12,850,573

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.02681
Policy Entropy: 0.28472
Value Function Loss: 0.29759

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05357
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.03698

Collected Steps per Second: 2,470.09842
Overall Steps per Second: 1,925.53949

Timestep Collection Time: 20.24413
Timestep Consumption Time: 5.72521
PPO Batch Consumption Time: 0.72200
Total Iteration Time: 25.96935

Cumulative Model Updates: 1,498
Cumulative Timesteps: 12,900,578

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 12900578...
Checkpoint 12900578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.28588
Policy Entropy: 0.28794
Value Function Loss: 0.29620

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.03323

Collected Steps per Second: 1,952.72162
Overall Steps per Second: 1,480.17635

Timestep Collection Time: 25.60580
Timestep Consumption Time: 8.17463
PPO Batch Consumption Time: 1.11874
Total Iteration Time: 33.78043

Cumulative Model Updates: 1,504
Cumulative Timesteps: 12,950,579

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.18967
Policy Entropy: 0.28570
Value Function Loss: 0.28727

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.03795
Value Function Update Magnitude: 0.03068

Collected Steps per Second: 2,005.29722
Overall Steps per Second: 1,423.87446

Timestep Collection Time: 24.93446
Timestep Consumption Time: 10.18170
PPO Batch Consumption Time: 1.42591
Total Iteration Time: 35.11616

Cumulative Model Updates: 1,510
Cumulative Timesteps: 13,000,580

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 13000580...
Checkpoint 13000580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.09425
Policy Entropy: 0.28983
Value Function Loss: 0.28479

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.02652

Collected Steps per Second: 1,546.53897
Overall Steps per Second: 1,247.68081

Timestep Collection Time: 32.33414
Timestep Consumption Time: 7.74503
PPO Batch Consumption Time: 1.02062
Total Iteration Time: 40.07916

Cumulative Model Updates: 1,516
Cumulative Timesteps: 13,050,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.62896
Policy Entropy: 0.28877
Value Function Loss: 0.27840

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06642
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.02781

Collected Steps per Second: 2,039.65218
Overall Steps per Second: 1,616.92240

Timestep Collection Time: 24.51742
Timestep Consumption Time: 6.40986
PPO Batch Consumption Time: 0.80994
Total Iteration Time: 30.92727

Cumulative Model Updates: 1,522
Cumulative Timesteps: 13,100,593

Timesteps Collected: 50,007
--------END ITERATION REPORT--------


Saving checkpoint 13100593...
Checkpoint 13100593 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.91760
Policy Entropy: 0.29158
Value Function Loss: 0.27561

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05997
Policy Update Magnitude: 0.04332
Value Function Update Magnitude: 0.02782

Collected Steps per Second: 2,167.35879
Overall Steps per Second: 1,675.17405

Timestep Collection Time: 23.07002
Timestep Consumption Time: 6.77823
PPO Batch Consumption Time: 0.88655
Total Iteration Time: 29.84824

Cumulative Model Updates: 1,528
Cumulative Timesteps: 13,150,594

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.04590
Policy Entropy: 0.28899
Value Function Loss: 0.26758

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05565
Policy Update Magnitude: 0.04110
Value Function Update Magnitude: 0.03012

Collected Steps per Second: 2,278.34288
Overall Steps per Second: 1,776.14907

Timestep Collection Time: 21.94665
Timestep Consumption Time: 6.20526
PPO Batch Consumption Time: 0.79673
Total Iteration Time: 28.15192

Cumulative Model Updates: 1,534
Cumulative Timesteps: 13,200,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13200596...
Checkpoint 13200596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.94400
Policy Entropy: 0.28858
Value Function Loss: 0.26669

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05759
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.02977

Collected Steps per Second: 2,306.71391
Overall Steps per Second: 1,762.83161

Timestep Collection Time: 21.67846
Timestep Consumption Time: 6.68840
PPO Batch Consumption Time: 0.87758
Total Iteration Time: 28.36686

Cumulative Model Updates: 1,540
Cumulative Timesteps: 13,250,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.20257
Policy Entropy: 0.28833
Value Function Loss: 0.26412

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06066
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.02886

Collected Steps per Second: 1,630.53485
Overall Steps per Second: 1,269.25763

Timestep Collection Time: 30.66724
Timestep Consumption Time: 8.72902
PPO Batch Consumption Time: 1.12378
Total Iteration Time: 39.39626

Cumulative Model Updates: 1,546
Cumulative Timesteps: 13,300,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13300606...
Checkpoint 13300606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.83740
Policy Entropy: 0.28818
Value Function Loss: 0.26446

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04183
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.02724

Collected Steps per Second: 1,750.51290
Overall Steps per Second: 1,341.42546

Timestep Collection Time: 28.56306
Timestep Consumption Time: 8.71072
PPO Batch Consumption Time: 1.14336
Total Iteration Time: 37.27378

Cumulative Model Updates: 1,552
Cumulative Timesteps: 13,350,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.11933
Policy Entropy: 0.28290
Value Function Loss: 0.27117

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05958
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.02699

Collected Steps per Second: 1,748.68108
Overall Steps per Second: 1,337.32224

Timestep Collection Time: 28.59469
Timestep Consumption Time: 8.79570
PPO Batch Consumption Time: 1.14097
Total Iteration Time: 37.39039

Cumulative Model Updates: 1,558
Cumulative Timesteps: 13,400,609

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 13400609...
Checkpoint 13400609 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.40219
Policy Entropy: 0.28293
Value Function Loss: 0.27293

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05959
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.02679

Collected Steps per Second: 1,662.80690
Overall Steps per Second: 1,335.04250

Timestep Collection Time: 30.07264
Timestep Consumption Time: 7.38309
PPO Batch Consumption Time: 0.97687
Total Iteration Time: 37.45574

Cumulative Model Updates: 1,564
Cumulative Timesteps: 13,450,614

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 13450614...
Checkpoint 13450614 saved!
