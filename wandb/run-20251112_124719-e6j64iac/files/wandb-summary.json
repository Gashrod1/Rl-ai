{"_step":319,"performance/avg_velocity_y":22.528717041015625,"Cumulative Model Updates":638,"performance/max_speed":2300.000244140625,"SB3 Clip Fraction":0.10889749618945643,"Mean KL Divergence":0.008511202075169422,"_wandb":{"runtime":2371},"Policy Update Magnitude":0.06392482668161392,"Total Iteration Time":14.770735822850838,"_timestamp":1.762954008158468e+09,"PPO Batch Consumption Time":0.04793894290924072,"Overall Steps per Second":6770.278826955489,"Cumulative Timesteps":16003350,"Timesteps Collected":100002,"performance/avg_speed":797.5923461914062,"gameplay/cumulative_touches":0,"gameplay/cumulative_goals":0,"training/timesteps":16003350,"gameplay/interval_touches":0,"Value Function Update Magnitude":0.07558067888021469,"Policy Entropy":0.11439630296081305,"Timestep Consumption Time":4.9785462787840515,"performance/avg_velocity_z":-30.305309295654297,"gameplay/interval_goals":0,"Collected Steps per Second":10212.424866774816,"Value Function Loss":1.2188725769519806,"_runtime":2371,"performance/avg_velocity_x":-60.35894775390625,"Timestep Collection Time":9.792189544066787,"Policy Reward":201.52674902390723}