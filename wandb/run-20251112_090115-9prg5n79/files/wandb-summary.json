{"Cumulative Timesteps":403396680,"Policy Reward":117.99743700111883,"Policy Entropy":1.1527526179949443,"Value Function Update Magnitude":0.20182015001773834,"_wandb":{"runtime":87523},"Collected Steps per Second":10462.150719758236,"Timestep Collection Time":4.782955373171717,"y_vel":125.56406996877509,"Overall Steps per Second":7287.674472483702,"PPO Batch Consumption Time":0.024784366289774578,"x_vel":-14.377281086735888,"_timestamp":1.7629400738884182e+09,"Timesteps Collected":50040,"total_goals":0,"z_vel":-27.64055030953637,"Mean KL Divergence":0.031187575000027817,"Timestep Consumption Time":2.0834325519390404,"Value Function Loss":0.03097675150881211,"SB3 Clip Fraction":0.16394666333993277,"_step":16274,"Total Iteration Time":6.866387925110757,"Policy Update Magnitude":0.10222794115543365,"total_touches":0,"Cumulative Model Updates":48318,"episode_goals":0,"_runtime":87523,"episode_touches":0}