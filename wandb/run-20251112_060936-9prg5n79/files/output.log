Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.32352
Policy Entropy: 1.25607
Value Function Loss: 0.04460

Mean KL Divergence: 0.02795
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.08727

Collected Steps per Second: 8479.78278
Overall Steps per Second: 6041.73616

Timestep Collection Time: 5.89791
Timestep Consumption Time: 2.38001
PPO Batch Consumption Time: 0.18058
Total Iteration Time: 8.27792

Cumulative Model Updates: 40478
Cumulative Timesteps: 337917959

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.73607
Policy Entropy: 1.24349
Value Function Loss: 0.04261

Mean KL Divergence: 0.03926
SB3 Clip Fraction: 0.17391
Policy Update Magnitude: 0.11541
Value Function Update Magnitude: 0.19885

Collected Steps per Second: 9760.10505
Overall Steps per Second: 7054.07179

Timestep Collection Time: 5.12402
Timestep Consumption Time: 1.96564
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.08966

Cumulative Model Updates: 40482
Cumulative Timesteps: 337967970

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.61332
Policy Entropy: 1.24032
Value Function Loss: 0.04204

Mean KL Divergence: 0.05045
SB3 Clip Fraction: 0.21273
Policy Update Magnitude: 0.17471
Value Function Update Magnitude: 0.28339

Collected Steps per Second: 9789.02272
Overall Steps per Second: 6730.11133

Timestep Collection Time: 5.10889
Timestep Consumption Time: 2.32205
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 7.43093

Cumulative Model Updates: 40488
Cumulative Timesteps: 338017981

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.46516
Policy Entropy: 1.22774
Value Function Loss: 0.04937

Mean KL Divergence: 0.03769
SB3 Clip Fraction: 0.20306
Policy Update Magnitude: 0.16209
Value Function Update Magnitude: 0.24863

Collected Steps per Second: 9041.22164
Overall Steps per Second: 6509.52138

Timestep Collection Time: 5.53465
Timestep Consumption Time: 2.15255
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.68720

Cumulative Model Updates: 40494
Cumulative Timesteps: 338068021

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.59860
Policy Entropy: 1.21939
Value Function Loss: 0.04723

Mean KL Divergence: 0.03020
SB3 Clip Fraction: 0.17949
Policy Update Magnitude: 0.16541
Value Function Update Magnitude: 0.25595

Collected Steps per Second: 10070.23065
Overall Steps per Second: 7081.22612

Timestep Collection Time: 4.96880
Timestep Consumption Time: 2.09735
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.06615

Cumulative Model Updates: 40500
Cumulative Timesteps: 338118058

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.39531
Policy Entropy: 1.20576
Value Function Loss: 0.05000

Mean KL Divergence: 0.03103
SB3 Clip Fraction: 0.17317
Policy Update Magnitude: 0.16279
Value Function Update Magnitude: 0.27694

Collected Steps per Second: 10637.31336
Overall Steps per Second: 7221.66821

Timestep Collection Time: 4.70260
Timestep Consumption Time: 2.22420
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.92679

Cumulative Model Updates: 40506
Cumulative Timesteps: 338168081

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.26385
Policy Entropy: 1.20261
Value Function Loss: 0.05594

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.15665
Policy Update Magnitude: 0.15442
Value Function Update Magnitude: 0.25494

Collected Steps per Second: 9401.26149
Overall Steps per Second: 6758.38806

Timestep Collection Time: 5.32184
Timestep Consumption Time: 2.08111
PPO Batch Consumption Time: 0.02447
Total Iteration Time: 7.40295

Cumulative Model Updates: 40512
Cumulative Timesteps: 338218113

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.93229
Policy Entropy: 1.20624
Value Function Loss: 0.06197

Mean KL Divergence: 0.04187
SB3 Clip Fraction: 0.20714
Policy Update Magnitude: 0.14480
Value Function Update Magnitude: 0.21388

Collected Steps per Second: 10039.99702
Overall Steps per Second: 7051.08705

Timestep Collection Time: 4.98267
Timestep Consumption Time: 2.11212
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 7.09479

Cumulative Model Updates: 40518
Cumulative Timesteps: 338268139

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.57576
Policy Entropy: 1.20516
Value Function Loss: 0.06084

Mean KL Divergence: 0.02823
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.14856
Value Function Update Magnitude: 0.23189

Collected Steps per Second: 9972.61880
Overall Steps per Second: 7038.65295

Timestep Collection Time: 5.01664
Timestep Consumption Time: 2.09112
PPO Batch Consumption Time: 0.02483
Total Iteration Time: 7.10775

Cumulative Model Updates: 40524
Cumulative Timesteps: 338318168

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.31445
Policy Entropy: 1.20694
Value Function Loss: 0.05689

Mean KL Divergence: 0.02740
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.16038
Value Function Update Magnitude: 0.26032

Collected Steps per Second: 9631.65944
Overall Steps per Second: 6971.13827

Timestep Collection Time: 5.19537
Timestep Consumption Time: 1.98280
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.17817

Cumulative Model Updates: 40530
Cumulative Timesteps: 338368208

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 338368208...
Checkpoint 338368208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.08556
Policy Entropy: 1.20383
Value Function Loss: 0.05843

Mean KL Divergence: 0.03366
SB3 Clip Fraction: 0.18709
Policy Update Magnitude: 0.14263
Value Function Update Magnitude: 0.29208

Collected Steps per Second: 9949.73588
Overall Steps per Second: 7169.73181

Timestep Collection Time: 5.02546
Timestep Consumption Time: 1.94858
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 6.97404

Cumulative Model Updates: 40536
Cumulative Timesteps: 338418210

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.36833
Policy Entropy: 1.20993
Value Function Loss: 0.05956

Mean KL Divergence: 0.02770
SB3 Clip Fraction: 0.16962
Policy Update Magnitude: 0.14780
Value Function Update Magnitude: 0.31656

Collected Steps per Second: 10519.13326
Overall Steps per Second: 7209.70360

Timestep Collection Time: 4.75486
Timestep Consumption Time: 2.18260
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.93746

Cumulative Model Updates: 40542
Cumulative Timesteps: 338468227

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.97772
Policy Entropy: 1.19099
Value Function Loss: 0.06086

Mean KL Divergence: 0.05917
SB3 Clip Fraction: 0.23917
Policy Update Magnitude: 0.14494
Value Function Update Magnitude: 0.31940

Collected Steps per Second: 8877.97378
Overall Steps per Second: 6286.42433

Timestep Collection Time: 5.63631
Timestep Consumption Time: 2.32354
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.95985

Cumulative Model Updates: 40548
Cumulative Timesteps: 338518266

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.87817
Policy Entropy: 1.20582
Value Function Loss: 0.05906

Mean KL Divergence: 0.04451
SB3 Clip Fraction: 0.22107
Policy Update Magnitude: 0.16107
Value Function Update Magnitude: 0.30904

Collected Steps per Second: 9381.33320
Overall Steps per Second: 6722.16956

Timestep Collection Time: 5.33410
Timestep Consumption Time: 2.11007
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.44417

Cumulative Model Updates: 40554
Cumulative Timesteps: 338568307

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.39911
Policy Entropy: 1.19110
Value Function Loss: 0.05646

Mean KL Divergence: 0.05097
SB3 Clip Fraction: 0.22466
Policy Update Magnitude: 0.15601
Value Function Update Magnitude: 0.29780

Collected Steps per Second: 9618.96723
Overall Steps per Second: 6682.41346

Timestep Collection Time: 5.20253
Timestep Consumption Time: 2.28623
PPO Batch Consumption Time: 0.03080
Total Iteration Time: 7.48876

Cumulative Model Updates: 40560
Cumulative Timesteps: 338618350

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.42972
Policy Entropy: 1.19922
Value Function Loss: 0.06059

Mean KL Divergence: 0.03076
SB3 Clip Fraction: 0.18014
Policy Update Magnitude: 0.15027
Value Function Update Magnitude: 0.31823

Collected Steps per Second: 9035.57752
Overall Steps per Second: 6581.45076

Timestep Collection Time: 5.53589
Timestep Consumption Time: 2.06425
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 7.60015

Cumulative Model Updates: 40566
Cumulative Timesteps: 338668370

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.69263
Policy Entropy: 1.18156
Value Function Loss: 0.06017

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.17047
Value Function Update Magnitude: 0.34033

Collected Steps per Second: 9488.94448
Overall Steps per Second: 6847.35482

Timestep Collection Time: 5.26992
Timestep Consumption Time: 2.03304
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.30297

Cumulative Model Updates: 40572
Cumulative Timesteps: 338718376

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.60904
Policy Entropy: 1.18714
Value Function Loss: 0.06122

Mean KL Divergence: 0.02558
SB3 Clip Fraction: 0.16826
Policy Update Magnitude: 0.16490
Value Function Update Magnitude: 0.33221

Collected Steps per Second: 9444.22876
Overall Steps per Second: 6497.88206

Timestep Collection Time: 5.29614
Timestep Consumption Time: 2.40144
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.69759

Cumulative Model Updates: 40578
Cumulative Timesteps: 338768394

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.06268
Policy Entropy: 1.19942
Value Function Loss: 0.05894

Mean KL Divergence: 0.03529
SB3 Clip Fraction: 0.20112
Policy Update Magnitude: 0.16096
Value Function Update Magnitude: 0.33254

Collected Steps per Second: 8856.84430
Overall Steps per Second: 6412.24120

Timestep Collection Time: 5.64896
Timestep Consumption Time: 2.15361
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.80258

Cumulative Model Updates: 40584
Cumulative Timesteps: 338818426

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.09251
Policy Entropy: 1.19696
Value Function Loss: 0.05662

Mean KL Divergence: 0.03471
SB3 Clip Fraction: 0.19860
Policy Update Magnitude: 0.14970
Value Function Update Magnitude: 0.34099

Collected Steps per Second: 9592.40971
Overall Steps per Second: 6999.36233

Timestep Collection Time: 5.21464
Timestep Consumption Time: 1.93186
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.14651

Cumulative Model Updates: 40590
Cumulative Timesteps: 338868447

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 338868447...
Checkpoint 338868447 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.37142
Policy Entropy: 1.19585
Value Function Loss: 0.05447

Mean KL Divergence: 0.03605
SB3 Clip Fraction: 0.19943
Policy Update Magnitude: 0.15036
Value Function Update Magnitude: 0.33255

Collected Steps per Second: 10455.04576
Overall Steps per Second: 7149.69684

Timestep Collection Time: 4.78601
Timestep Consumption Time: 2.21260
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 6.99862

Cumulative Model Updates: 40596
Cumulative Timesteps: 338918485

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.09780
Policy Entropy: 1.20128
Value Function Loss: 0.05750

Mean KL Divergence: 0.03507
SB3 Clip Fraction: 0.19666
Policy Update Magnitude: 0.15573
Value Function Update Magnitude: 0.33358

Collected Steps per Second: 9223.56742
Overall Steps per Second: 6538.45059

Timestep Collection Time: 5.42512
Timestep Consumption Time: 2.22791
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.65304

Cumulative Model Updates: 40602
Cumulative Timesteps: 338968524

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.06342
Policy Entropy: 1.20584
Value Function Loss: 0.05844

Mean KL Divergence: 0.03313
SB3 Clip Fraction: 0.17679
Policy Update Magnitude: 0.15317
Value Function Update Magnitude: 0.31880

Collected Steps per Second: 9610.04941
Overall Steps per Second: 6921.71397

Timestep Collection Time: 5.20642
Timestep Consumption Time: 2.02213
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.22856

Cumulative Model Updates: 40608
Cumulative Timesteps: 339018558

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.24044
Policy Entropy: 1.20693
Value Function Loss: 0.05987

Mean KL Divergence: 0.03171
SB3 Clip Fraction: 0.17448
Policy Update Magnitude: 0.14616
Value Function Update Magnitude: 0.32251

Collected Steps per Second: 10075.32407
Overall Steps per Second: 7301.13456

Timestep Collection Time: 4.96500
Timestep Consumption Time: 1.88654
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 6.85154

Cumulative Model Updates: 40614
Cumulative Timesteps: 339068582

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.38209
Policy Entropy: 1.20981
Value Function Loss: 0.05842

Mean KL Divergence: 0.03100
SB3 Clip Fraction: 0.17717
Policy Update Magnitude: 0.14112
Value Function Update Magnitude: 0.32479

Collected Steps per Second: 9951.16170
Overall Steps per Second: 7154.06912

Timestep Collection Time: 5.02464
Timestep Consumption Time: 1.96453
PPO Batch Consumption Time: 0.02387
Total Iteration Time: 6.98917

Cumulative Model Updates: 40620
Cumulative Timesteps: 339118583

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.00041
Policy Entropy: 1.21271
Value Function Loss: 0.05810

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.15035
Value Function Update Magnitude: 0.33204

Collected Steps per Second: 9926.67693
Overall Steps per Second: 7205.43508

Timestep Collection Time: 5.04036
Timestep Consumption Time: 1.90357
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 6.94392

Cumulative Model Updates: 40626
Cumulative Timesteps: 339168617

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.54572
Policy Entropy: 1.21735
Value Function Loss: 0.05787

Mean KL Divergence: 0.02770
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.15081
Value Function Update Magnitude: 0.33259

Collected Steps per Second: 10326.34292
Overall Steps per Second: 7293.84469

Timestep Collection Time: 4.84567
Timestep Consumption Time: 2.01464
PPO Batch Consumption Time: 0.02386
Total Iteration Time: 6.86031

Cumulative Model Updates: 40632
Cumulative Timesteps: 339218655

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.79905
Policy Entropy: 1.21613
Value Function Loss: 0.05494

Mean KL Divergence: 0.02500
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.14854
Value Function Update Magnitude: 0.32611

Collected Steps per Second: 9813.27849
Overall Steps per Second: 7061.09816

Timestep Collection Time: 5.09972
Timestep Consumption Time: 1.98770
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.08742

Cumulative Model Updates: 40638
Cumulative Timesteps: 339268700

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.76385
Policy Entropy: 1.21494
Value Function Loss: 0.05601

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.15665
Value Function Update Magnitude: 0.32286

Collected Steps per Second: 9258.42739
Overall Steps per Second: 6621.31360

Timestep Collection Time: 5.40243
Timestep Consumption Time: 2.15166
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 7.55409

Cumulative Model Updates: 40644
Cumulative Timesteps: 339318718

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.96409
Policy Entropy: 1.20722
Value Function Loss: 0.05727

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.15837
Value Function Update Magnitude: 0.32006

Collected Steps per Second: 9840.35496
Overall Steps per Second: 7029.30940

Timestep Collection Time: 5.08122
Timestep Consumption Time: 2.03200
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 7.11322

Cumulative Model Updates: 40650
Cumulative Timesteps: 339368719

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 339368719...
Checkpoint 339368719 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.07727
Policy Entropy: 1.20691
Value Function Loss: 0.05870

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.14877
Value Function Update Magnitude: 0.31226

Collected Steps per Second: 9825.69911
Overall Steps per Second: 7059.15837

Timestep Collection Time: 5.09155
Timestep Consumption Time: 1.99542
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.08696

Cumulative Model Updates: 40656
Cumulative Timesteps: 339418747

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.30557
Policy Entropy: 1.20156
Value Function Loss: 0.05807

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.15262
Value Function Update Magnitude: 0.31238

Collected Steps per Second: 9268.22536
Overall Steps per Second: 6620.03639

Timestep Collection Time: 5.39780
Timestep Consumption Time: 2.15926
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.55706

Cumulative Model Updates: 40662
Cumulative Timesteps: 339468775

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.82922
Policy Entropy: 1.20308
Value Function Loss: 0.05487

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.15438
Value Function Update Magnitude: 0.30667

Collected Steps per Second: 9475.69734
Overall Steps per Second: 6571.10247

Timestep Collection Time: 5.27676
Timestep Consumption Time: 2.33246
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.60923

Cumulative Model Updates: 40668
Cumulative Timesteps: 339518776

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.27074
Policy Entropy: 1.22129
Value Function Loss: 0.05201

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.13534
Value Function Update Magnitude: 0.30752

Collected Steps per Second: 9390.75148
Overall Steps per Second: 6787.16250

Timestep Collection Time: 5.32801
Timestep Consumption Time: 2.04385
PPO Batch Consumption Time: 0.02468
Total Iteration Time: 7.37186

Cumulative Model Updates: 40674
Cumulative Timesteps: 339568810

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.92680
Policy Entropy: 1.21654
Value Function Loss: 0.05263

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.15344
Value Function Update Magnitude: 0.30522

Collected Steps per Second: 9259.57593
Overall Steps per Second: 6748.28764

Timestep Collection Time: 5.40230
Timestep Consumption Time: 2.01040
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 7.41270

Cumulative Model Updates: 40680
Cumulative Timesteps: 339618833

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.23817
Policy Entropy: 1.20501
Value Function Loss: 0.05330

Mean KL Divergence: 0.03934
SB3 Clip Fraction: 0.18320
Policy Update Magnitude: 0.16117
Value Function Update Magnitude: 0.30934

Collected Steps per Second: 9222.88945
Overall Steps per Second: 6501.97803

Timestep Collection Time: 5.42184
Timestep Consumption Time: 2.26890
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.69074

Cumulative Model Updates: 40686
Cumulative Timesteps: 339668838

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.79769
Policy Entropy: 1.20276
Value Function Loss: 0.05429

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.13758
Value Function Update Magnitude: 0.30300

Collected Steps per Second: 9512.57676
Overall Steps per Second: 6875.94608

Timestep Collection Time: 5.25935
Timestep Consumption Time: 2.01674
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.27609

Cumulative Model Updates: 40692
Cumulative Timesteps: 339718868

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.61193
Policy Entropy: 1.19945
Value Function Loss: 0.05627

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.13667
Value Function Update Magnitude: 0.29403

Collected Steps per Second: 9360.06838
Overall Steps per Second: 6678.74365

Timestep Collection Time: 5.34227
Timestep Consumption Time: 2.14477
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.48704

Cumulative Model Updates: 40698
Cumulative Timesteps: 339768872

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.38371
Policy Entropy: 1.19858
Value Function Loss: 0.05705

Mean KL Divergence: 0.02961
SB3 Clip Fraction: 0.16897
Policy Update Magnitude: 0.14386
Value Function Update Magnitude: 0.29448

Collected Steps per Second: 9450.98902
Overall Steps per Second: 6727.06654

Timestep Collection Time: 5.29119
Timestep Consumption Time: 2.14251
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.43370

Cumulative Model Updates: 40704
Cumulative Timesteps: 339818879

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.57672
Policy Entropy: 1.19230
Value Function Loss: 0.05530

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.16506
Policy Update Magnitude: 0.15147
Value Function Update Magnitude: 0.29797

Collected Steps per Second: 9785.56817
Overall Steps per Second: 6904.14448

Timestep Collection Time: 5.10957
Timestep Consumption Time: 2.13246
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.24203

Cumulative Model Updates: 40710
Cumulative Timesteps: 339868879

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 339868879...
Checkpoint 339868879 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.24092
Policy Entropy: 1.20240
Value Function Loss: 0.05386

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.14673
Value Function Update Magnitude: 0.30123

Collected Steps per Second: 9782.25031
Overall Steps per Second: 7063.86450

Timestep Collection Time: 5.11283
Timestep Consumption Time: 1.96757
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 7.08040

Cumulative Model Updates: 40716
Cumulative Timesteps: 339918894

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.42135
Policy Entropy: 1.19037
Value Function Loss: 0.05391

Mean KL Divergence: 0.03677
SB3 Clip Fraction: 0.19627
Policy Update Magnitude: 0.14505
Value Function Update Magnitude: 0.29348

Collected Steps per Second: 9760.67450
Overall Steps per Second: 6981.76456

Timestep Collection Time: 5.12639
Timestep Consumption Time: 2.04043
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.16681

Cumulative Model Updates: 40722
Cumulative Timesteps: 339968931

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.51188
Policy Entropy: 1.18809
Value Function Loss: 0.05394

Mean KL Divergence: 0.03881
SB3 Clip Fraction: 0.20841
Policy Update Magnitude: 0.13116
Value Function Update Magnitude: 0.29380

Collected Steps per Second: 9691.79363
Overall Steps per Second: 7053.37464

Timestep Collection Time: 5.15962
Timestep Consumption Time: 1.93003
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.08966

Cumulative Model Updates: 40728
Cumulative Timesteps: 340018937

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.51832
Policy Entropy: 1.19759
Value Function Loss: 0.05145

Mean KL Divergence: 0.04168
SB3 Clip Fraction: 0.21399
Policy Update Magnitude: 0.12427
Value Function Update Magnitude: 0.29176

Collected Steps per Second: 9665.22274
Overall Steps per Second: 7080.59094

Timestep Collection Time: 5.17412
Timestep Consumption Time: 1.88871
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.06283

Cumulative Model Updates: 40734
Cumulative Timesteps: 340068946

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.38652
Policy Entropy: 1.20209
Value Function Loss: 0.05099

Mean KL Divergence: 0.03251
SB3 Clip Fraction: 0.18811
Policy Update Magnitude: 0.13026
Value Function Update Magnitude: 0.28826

Collected Steps per Second: 10526.82164
Overall Steps per Second: 7502.89877

Timestep Collection Time: 4.75177
Timestep Consumption Time: 1.91512
PPO Batch Consumption Time: 0.02468
Total Iteration Time: 6.66689

Cumulative Model Updates: 40740
Cumulative Timesteps: 340118967

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.20045
Policy Entropy: 1.20310
Value Function Loss: 0.05555

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.15644
Policy Update Magnitude: 0.16519
Value Function Update Magnitude: 0.28603

Collected Steps per Second: 10414.06954
Overall Steps per Second: 7408.98359

Timestep Collection Time: 4.80571
Timestep Consumption Time: 1.94920
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.75491

Cumulative Model Updates: 40746
Cumulative Timesteps: 340169014

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.56443
Policy Entropy: 1.19242
Value Function Loss: 0.05742

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.15777
Policy Update Magnitude: 0.17114
Value Function Update Magnitude: 0.28349

Collected Steps per Second: 9795.83640
Overall Steps per Second: 6969.29004

Timestep Collection Time: 5.10666
Timestep Consumption Time: 2.07112
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 7.17778

Cumulative Model Updates: 40752
Cumulative Timesteps: 340219038

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.40038
Policy Entropy: 1.19959
Value Function Loss: 0.05975

Mean KL Divergence: 0.02624
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.17858
Value Function Update Magnitude: 0.27648

Collected Steps per Second: 9801.37459
Overall Steps per Second: 6675.24734

Timestep Collection Time: 5.10367
Timestep Consumption Time: 2.39013
PPO Batch Consumption Time: 0.02884
Total Iteration Time: 7.49380

Cumulative Model Updates: 40758
Cumulative Timesteps: 340269061

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.12264
Policy Entropy: 1.19911
Value Function Loss: 0.05784

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.16513
Value Function Update Magnitude: 0.28079

Collected Steps per Second: 9262.64159
Overall Steps per Second: 6404.00417

Timestep Collection Time: 5.40094
Timestep Consumption Time: 2.41089
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.81183

Cumulative Model Updates: 40764
Cumulative Timesteps: 340319088

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.37602
Policy Entropy: 1.20034
Value Function Loss: 0.05896

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.16514
Value Function Update Magnitude: 0.29158

Collected Steps per Second: 9485.85846
Overall Steps per Second: 6910.67768

Timestep Collection Time: 5.27111
Timestep Consumption Time: 1.96422
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.23533

Cumulative Model Updates: 40770
Cumulative Timesteps: 340369089

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 340369089...
Checkpoint 340369089 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.62530
Policy Entropy: 1.19926
Value Function Loss: 0.05673

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.15273
Value Function Update Magnitude: 0.29870

Collected Steps per Second: 10936.84921
Overall Steps per Second: 7417.33124

Timestep Collection Time: 4.57508
Timestep Consumption Time: 2.17087
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 6.74596

Cumulative Model Updates: 40776
Cumulative Timesteps: 340419126

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.63688
Policy Entropy: 1.19538
Value Function Loss: 0.05484

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.15976
Policy Update Magnitude: 0.14090
Value Function Update Magnitude: 0.30325

Collected Steps per Second: 9332.13610
Overall Steps per Second: 6495.84163

Timestep Collection Time: 5.36212
Timestep Consumption Time: 2.34127
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 7.70339

Cumulative Model Updates: 40782
Cumulative Timesteps: 340469166

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.58261
Policy Entropy: 1.19660
Value Function Loss: 0.05647

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.14336
Value Function Update Magnitude: 0.30767

Collected Steps per Second: 9077.68846
Overall Steps per Second: 6438.73068

Timestep Collection Time: 5.50999
Timestep Consumption Time: 2.25831
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.76830

Cumulative Model Updates: 40788
Cumulative Timesteps: 340519184

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.62451
Policy Entropy: 1.20174
Value Function Loss: 0.05620

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.15555
Value Function Update Magnitude: 0.30859

Collected Steps per Second: 9860.62329
Overall Steps per Second: 6889.93528

Timestep Collection Time: 5.07067
Timestep Consumption Time: 2.18629
PPO Batch Consumption Time: 0.02421
Total Iteration Time: 7.25696

Cumulative Model Updates: 40794
Cumulative Timesteps: 340569184

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.40072
Policy Entropy: 1.20364
Value Function Loss: 0.05703

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.15061
Value Function Update Magnitude: 0.30170

Collected Steps per Second: 9301.69960
Overall Steps per Second: 6550.22842

Timestep Collection Time: 5.37536
Timestep Consumption Time: 2.25796
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.63332

Cumulative Model Updates: 40800
Cumulative Timesteps: 340619184

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.84062
Policy Entropy: 1.20317
Value Function Loss: 0.05554

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.14966
Value Function Update Magnitude: 0.28927

Collected Steps per Second: 8990.86282
Overall Steps per Second: 6404.28713

Timestep Collection Time: 5.56254
Timestep Consumption Time: 2.24661
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.80914

Cumulative Model Updates: 40806
Cumulative Timesteps: 340669196

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.65829
Policy Entropy: 1.20108
Value Function Loss: 0.05403

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.13123
Value Function Update Magnitude: 0.27996

Collected Steps per Second: 9730.42805
Overall Steps per Second: 6811.06515

Timestep Collection Time: 5.13893
Timestep Consumption Time: 2.20265
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.34158

Cumulative Model Updates: 40812
Cumulative Timesteps: 340719200

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.28908
Policy Entropy: 1.21820
Value Function Loss: 0.05569

Mean KL Divergence: 0.02827
SB3 Clip Fraction: 0.16974
Policy Update Magnitude: 0.13212
Value Function Update Magnitude: 0.27067

Collected Steps per Second: 9250.24682
Overall Steps per Second: 6584.44906

Timestep Collection Time: 5.40559
Timestep Consumption Time: 2.18852
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.59411

Cumulative Model Updates: 40818
Cumulative Timesteps: 340769203

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.51742
Policy Entropy: 1.20533
Value Function Loss: 0.05681

Mean KL Divergence: 0.04167
SB3 Clip Fraction: 0.21031
Policy Update Magnitude: 0.12364
Value Function Update Magnitude: 0.28088

Collected Steps per Second: 9391.05634
Overall Steps per Second: 6759.08621

Timestep Collection Time: 5.32698
Timestep Consumption Time: 2.07431
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.40130

Cumulative Model Updates: 40824
Cumulative Timesteps: 340819229

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.62721
Policy Entropy: 1.18853
Value Function Loss: 0.05640

Mean KL Divergence: 0.03490
SB3 Clip Fraction: 0.18583
Policy Update Magnitude: 0.12200
Value Function Update Magnitude: 0.29077

Collected Steps per Second: 9859.02734
Overall Steps per Second: 6908.35669

Timestep Collection Time: 5.07149
Timestep Consumption Time: 2.16612
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 7.23761

Cumulative Model Updates: 40830
Cumulative Timesteps: 340869229

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 340869229...
Checkpoint 340869229 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.87908
Policy Entropy: 1.19968
Value Function Loss: 0.05512

Mean KL Divergence: 0.03422
SB3 Clip Fraction: 0.18982
Policy Update Magnitude: 0.12507
Value Function Update Magnitude: 0.30393

Collected Steps per Second: 9996.44528
Overall Steps per Second: 7186.53804

Timestep Collection Time: 5.00458
Timestep Consumption Time: 1.95677
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.96135

Cumulative Model Updates: 40836
Cumulative Timesteps: 340919257

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.12635
Policy Entropy: 1.19882
Value Function Loss: 0.05453

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.13635
Value Function Update Magnitude: 0.29938

Collected Steps per Second: 9781.88519
Overall Steps per Second: 7090.07559

Timestep Collection Time: 5.11261
Timestep Consumption Time: 1.94105
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.05366

Cumulative Model Updates: 40842
Cumulative Timesteps: 340969268

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.57492
Policy Entropy: 1.20835
Value Function Loss: 0.05487

Mean KL Divergence: 0.02493
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.14011
Value Function Update Magnitude: 0.29858

Collected Steps per Second: 10394.18399
Overall Steps per Second: 7434.02481

Timestep Collection Time: 4.81317
Timestep Consumption Time: 1.91656
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 6.72973

Cumulative Model Updates: 40848
Cumulative Timesteps: 341019297

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.62365
Policy Entropy: 1.20671
Value Function Loss: 0.05739

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.13112
Value Function Update Magnitude: 0.28951

Collected Steps per Second: 9211.14661
Overall Steps per Second: 6589.81430

Timestep Collection Time: 5.43114
Timestep Consumption Time: 2.16043
PPO Batch Consumption Time: 0.02475
Total Iteration Time: 7.59156

Cumulative Model Updates: 40854
Cumulative Timesteps: 341069324

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.44909
Policy Entropy: 1.20443
Value Function Loss: 0.05840

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.12577
Value Function Update Magnitude: 0.29215

Collected Steps per Second: 9721.00470
Overall Steps per Second: 6899.53473

Timestep Collection Time: 5.14813
Timestep Consumption Time: 2.10526
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.25339

Cumulative Model Updates: 40860
Cumulative Timesteps: 341119369

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.45701
Policy Entropy: 1.19628
Value Function Loss: 0.05798

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.13245
Value Function Update Magnitude: 0.28122

Collected Steps per Second: 10212.93085
Overall Steps per Second: 7161.16460

Timestep Collection Time: 4.89957
Timestep Consumption Time: 2.08798
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 6.98755

Cumulative Model Updates: 40866
Cumulative Timesteps: 341169408

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.64227
Policy Entropy: 1.20932
Value Function Loss: 0.05432

Mean KL Divergence: 0.03472
SB3 Clip Fraction: 0.18990
Policy Update Magnitude: 0.13409
Value Function Update Magnitude: 0.26942

Collected Steps per Second: 9065.19481
Overall Steps per Second: 6345.19820

Timestep Collection Time: 5.51913
Timestep Consumption Time: 2.36589
PPO Batch Consumption Time: 0.02983
Total Iteration Time: 7.88502

Cumulative Model Updates: 40872
Cumulative Timesteps: 341219440

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.46704
Policy Entropy: 1.20390
Value Function Loss: 0.05363

Mean KL Divergence: 0.02880
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.15693
Value Function Update Magnitude: 0.26922

Collected Steps per Second: 8894.43274
Overall Steps per Second: 6413.59136

Timestep Collection Time: 5.62296
Timestep Consumption Time: 2.17502
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.79797

Cumulative Model Updates: 40878
Cumulative Timesteps: 341269453

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.46528
Policy Entropy: 1.21986
Value Function Loss: 0.05189

Mean KL Divergence: 0.02567
SB3 Clip Fraction: 0.16275
Policy Update Magnitude: 0.15355
Value Function Update Magnitude: 0.27207

Collected Steps per Second: 10352.92409
Overall Steps per Second: 7321.19635

Timestep Collection Time: 4.83081
Timestep Consumption Time: 2.00045
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 6.83126

Cumulative Model Updates: 40884
Cumulative Timesteps: 341319466

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.83714
Policy Entropy: 1.20395
Value Function Loss: 0.05166

Mean KL Divergence: 0.03176
SB3 Clip Fraction: 0.17626
Policy Update Magnitude: 0.14462
Value Function Update Magnitude: 0.27227

Collected Steps per Second: 9225.68035
Overall Steps per Second: 6529.41070

Timestep Collection Time: 5.41998
Timestep Consumption Time: 2.23814
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.65812

Cumulative Model Updates: 40890
Cumulative Timesteps: 341369469

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 341369469...
Checkpoint 341369469 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.25539
Policy Entropy: 1.20862
Value Function Loss: 0.05264

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.15657
Value Function Update Magnitude: 0.26496

Collected Steps per Second: 8718.62387
Overall Steps per Second: 6336.47444

Timestep Collection Time: 5.73508
Timestep Consumption Time: 2.15606
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.89114

Cumulative Model Updates: 40896
Cumulative Timesteps: 341419471

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.20017
Policy Entropy: 1.20287
Value Function Loss: 0.05580

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.15208
Value Function Update Magnitude: 0.27270

Collected Steps per Second: 10252.32229
Overall Steps per Second: 7190.22228

Timestep Collection Time: 4.87704
Timestep Consumption Time: 2.07699
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 6.95403

Cumulative Model Updates: 40902
Cumulative Timesteps: 341469472

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.98662
Policy Entropy: 1.19287
Value Function Loss: 0.06227

Mean KL Divergence: 0.03155
SB3 Clip Fraction: 0.18391
Policy Update Magnitude: 0.13462
Value Function Update Magnitude: 0.29177

Collected Steps per Second: 9136.45539
Overall Steps per Second: 6566.07339

Timestep Collection Time: 5.47762
Timestep Consumption Time: 2.14429
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 7.62191

Cumulative Model Updates: 40908
Cumulative Timesteps: 341519518

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.15291
Policy Entropy: 1.19298
Value Function Loss: 0.05803

Mean KL Divergence: 0.03252
SB3 Clip Fraction: 0.18805
Policy Update Magnitude: 0.13103
Value Function Update Magnitude: 0.30552

Collected Steps per Second: 8820.45696
Overall Steps per Second: 6313.44484

Timestep Collection Time: 5.66966
Timestep Consumption Time: 2.25137
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.92103

Cumulative Model Updates: 40914
Cumulative Timesteps: 341569527

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.87217
Policy Entropy: 1.19179
Value Function Loss: 0.05779

Mean KL Divergence: 0.02909
SB3 Clip Fraction: 0.17867
Policy Update Magnitude: 0.13910
Value Function Update Magnitude: 0.29161

Collected Steps per Second: 10327.20961
Overall Steps per Second: 7402.01437

Timestep Collection Time: 4.84390
Timestep Consumption Time: 1.91426
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.75816

Cumulative Model Updates: 40920
Cumulative Timesteps: 341619551

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.23417
Policy Entropy: 1.20595
Value Function Loss: 0.05307

Mean KL Divergence: 0.03022
SB3 Clip Fraction: 0.18442
Policy Update Magnitude: 0.13489
Value Function Update Magnitude: 0.28758

Collected Steps per Second: 9712.90249
Overall Steps per Second: 7012.03925

Timestep Collection Time: 5.15047
Timestep Consumption Time: 1.98383
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.13430

Cumulative Model Updates: 40926
Cumulative Timesteps: 341669577

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.12511
Policy Entropy: 1.19495
Value Function Loss: 0.05442

Mean KL Divergence: 0.03042
SB3 Clip Fraction: 0.17378
Policy Update Magnitude: 0.14598
Value Function Update Magnitude: 0.29572

Collected Steps per Second: 9208.80665
Overall Steps per Second: 6677.34719

Timestep Collection Time: 5.43024
Timestep Consumption Time: 2.05867
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 7.48890

Cumulative Model Updates: 40932
Cumulative Timesteps: 341719583

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.63065
Policy Entropy: 1.19874
Value Function Loss: 0.05654

Mean KL Divergence: 0.03349
SB3 Clip Fraction: 0.17541
Policy Update Magnitude: 0.14268
Value Function Update Magnitude: 0.27888

Collected Steps per Second: 9792.13641
Overall Steps per Second: 6977.83056

Timestep Collection Time: 5.11084
Timestep Consumption Time: 2.06131
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 7.17214

Cumulative Model Updates: 40938
Cumulative Timesteps: 341769629

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.64674
Policy Entropy: 1.18580
Value Function Loss: 0.05667

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.14527
Value Function Update Magnitude: 0.26644

Collected Steps per Second: 9769.95574
Overall Steps per Second: 7061.98435

Timestep Collection Time: 5.12172
Timestep Consumption Time: 1.96396
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.08569

Cumulative Model Updates: 40944
Cumulative Timesteps: 341819668

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.06135
Policy Entropy: 1.18312
Value Function Loss: 0.05869

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.15044
Value Function Update Magnitude: 0.26419

Collected Steps per Second: 10228.19827
Overall Steps per Second: 7373.69368

Timestep Collection Time: 4.89030
Timestep Consumption Time: 1.89313
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.78344

Cumulative Model Updates: 40950
Cumulative Timesteps: 341869687

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 341869687...
Checkpoint 341869687 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.48833
Policy Entropy: 1.19067
Value Function Loss: 0.05889

Mean KL Divergence: 0.02893
SB3 Clip Fraction: 0.18025
Policy Update Magnitude: 0.14304
Value Function Update Magnitude: 0.26586

Collected Steps per Second: 10941.19393
Overall Steps per Second: 7671.05855

Timestep Collection Time: 4.57254
Timestep Consumption Time: 1.94925
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.52179

Cumulative Model Updates: 40956
Cumulative Timesteps: 341919716

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.92556
Policy Entropy: 1.19347
Value Function Loss: 0.05983

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.17184
Policy Update Magnitude: 0.14404
Value Function Update Magnitude: 0.26917

Collected Steps per Second: 10044.35968
Overall Steps per Second: 7110.61018

Timestep Collection Time: 4.98090
Timestep Consumption Time: 2.05506
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.03596

Cumulative Model Updates: 40962
Cumulative Timesteps: 341969746

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.71340
Policy Entropy: 1.19616
Value Function Loss: 0.05917

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.14936
Value Function Update Magnitude: 0.27129

Collected Steps per Second: 8887.77397
Overall Steps per Second: 6370.31545

Timestep Collection Time: 5.62604
Timestep Consumption Time: 2.22333
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.84938

Cumulative Model Updates: 40968
Cumulative Timesteps: 342019749

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.28257
Policy Entropy: 1.19946
Value Function Loss: 0.05876

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.15632
Policy Update Magnitude: 0.14235
Value Function Update Magnitude: 0.27114

Collected Steps per Second: 9301.43554
Overall Steps per Second: 6555.56360

Timestep Collection Time: 5.37971
Timestep Consumption Time: 2.25335
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.63306

Cumulative Model Updates: 40974
Cumulative Timesteps: 342069788

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.23435
Policy Entropy: 1.20653
Value Function Loss: 0.05731

Mean KL Divergence: 0.02309
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.13474
Value Function Update Magnitude: 0.26635

Collected Steps per Second: 9148.10925
Overall Steps per Second: 6470.32927

Timestep Collection Time: 5.46583
Timestep Consumption Time: 2.26206
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.72789

Cumulative Model Updates: 40980
Cumulative Timesteps: 342119790

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.90398
Policy Entropy: 1.20383
Value Function Loss: 0.05683

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.14431
Value Function Update Magnitude: 0.25443

Collected Steps per Second: 9381.32802
Overall Steps per Second: 6682.99888

Timestep Collection Time: 5.33155
Timestep Consumption Time: 2.15267
PPO Batch Consumption Time: 0.02929
Total Iteration Time: 7.48421

Cumulative Model Updates: 40986
Cumulative Timesteps: 342169807

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.79931
Policy Entropy: 1.20632
Value Function Loss: 0.05568

Mean KL Divergence: 0.01737
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.14415
Value Function Update Magnitude: 0.25076

Collected Steps per Second: 10488.67661
Overall Steps per Second: 7136.42046

Timestep Collection Time: 4.76981
Timestep Consumption Time: 2.24057
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 7.01038

Cumulative Model Updates: 40992
Cumulative Timesteps: 342219836

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.12853
Policy Entropy: 1.20559
Value Function Loss: 0.05699

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.13851
Value Function Update Magnitude: 0.24288

Collected Steps per Second: 9267.19195
Overall Steps per Second: 6686.00278

Timestep Collection Time: 5.39678
Timestep Consumption Time: 2.08347
PPO Batch Consumption Time: 0.03019
Total Iteration Time: 7.48025

Cumulative Model Updates: 40998
Cumulative Timesteps: 342269849

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.95635
Policy Entropy: 1.21247
Value Function Loss: 0.06083

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.13994
Value Function Update Magnitude: 0.21154

Collected Steps per Second: 9132.48290
Overall Steps per Second: 6572.70409

Timestep Collection Time: 5.47803
Timestep Consumption Time: 2.13345
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.61148

Cumulative Model Updates: 41004
Cumulative Timesteps: 342319877

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.40677
Policy Entropy: 1.21271
Value Function Loss: 0.06363

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.14394
Value Function Update Magnitude: 0.19363

Collected Steps per Second: 9637.02050
Overall Steps per Second: 6642.72097

Timestep Collection Time: 5.19196
Timestep Consumption Time: 2.34035
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.53230

Cumulative Model Updates: 41010
Cumulative Timesteps: 342369912

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 342369912...
Checkpoint 342369912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.18825
Policy Entropy: 1.21796
Value Function Loss: 0.06405

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.15972
Value Function Update Magnitude: 0.19270

Collected Steps per Second: 9200.55326
Overall Steps per Second: 6596.53135

Timestep Collection Time: 5.43826
Timestep Consumption Time: 2.14679
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.58505

Cumulative Model Updates: 41016
Cumulative Timesteps: 342419947

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.36052
Policy Entropy: 1.21172
Value Function Loss: 0.06123

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.15325
Value Function Update Magnitude: 0.20210

Collected Steps per Second: 8984.44977
Overall Steps per Second: 6513.43507

Timestep Collection Time: 5.56829
Timestep Consumption Time: 2.11245
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.68074

Cumulative Model Updates: 41022
Cumulative Timesteps: 342469975

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.49773
Policy Entropy: 1.21651
Value Function Loss: 0.06226

Mean KL Divergence: 0.03386
SB3 Clip Fraction: 0.17811
Policy Update Magnitude: 0.13427
Value Function Update Magnitude: 0.18687

Collected Steps per Second: 10094.56179
Overall Steps per Second: 7004.16725

Timestep Collection Time: 4.95405
Timestep Consumption Time: 2.18584
PPO Batch Consumption Time: 0.02948
Total Iteration Time: 7.13989

Cumulative Model Updates: 41028
Cumulative Timesteps: 342519984

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.17949
Policy Entropy: 1.20903
Value Function Loss: 0.06220

Mean KL Divergence: 0.03264
SB3 Clip Fraction: 0.18114
Policy Update Magnitude: 0.12584
Value Function Update Magnitude: 0.18721

Collected Steps per Second: 9761.60699
Overall Steps per Second: 7011.50087

Timestep Collection Time: 5.12303
Timestep Consumption Time: 2.00939
PPO Batch Consumption Time: 0.02875
Total Iteration Time: 7.13242

Cumulative Model Updates: 41034
Cumulative Timesteps: 342569993

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.02920
Policy Entropy: 1.21933
Value Function Loss: 0.06190

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.12980
Value Function Update Magnitude: 0.19737

Collected Steps per Second: 9548.26445
Overall Steps per Second: 7052.92898

Timestep Collection Time: 5.23718
Timestep Consumption Time: 1.85292
PPO Batch Consumption Time: 0.02410
Total Iteration Time: 7.09010

Cumulative Model Updates: 41040
Cumulative Timesteps: 342619999

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.77363
Policy Entropy: 1.20876
Value Function Loss: 0.06156

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.14141
Value Function Update Magnitude: 0.21802

Collected Steps per Second: 10568.68200
Overall Steps per Second: 7456.06316

Timestep Collection Time: 4.73351
Timestep Consumption Time: 1.97606
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 6.70957

Cumulative Model Updates: 41046
Cumulative Timesteps: 342670026

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.07755
Policy Entropy: 1.21350
Value Function Loss: 0.06078

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.14273
Value Function Update Magnitude: 0.23916

Collected Steps per Second: 10170.36318
Overall Steps per Second: 7145.13874

Timestep Collection Time: 4.91821
Timestep Consumption Time: 2.08235
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.00056

Cumulative Model Updates: 41052
Cumulative Timesteps: 342720046

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.42485
Policy Entropy: 1.19852
Value Function Loss: 0.06224

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.14948
Policy Update Magnitude: 0.13160
Value Function Update Magnitude: 0.25624

Collected Steps per Second: 9859.07666
Overall Steps per Second: 7060.34153

Timestep Collection Time: 5.07147
Timestep Consumption Time: 2.01034
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.08181

Cumulative Model Updates: 41058
Cumulative Timesteps: 342770046

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.78075
Policy Entropy: 1.20602
Value Function Loss: 0.05904

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.13337
Value Function Update Magnitude: 0.24950

Collected Steps per Second: 10552.65210
Overall Steps per Second: 7465.64471

Timestep Collection Time: 4.73900
Timestep Consumption Time: 1.95955
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 6.69855

Cumulative Model Updates: 41064
Cumulative Timesteps: 342820055

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.40390
Policy Entropy: 1.20544
Value Function Loss: 0.06246

Mean KL Divergence: 0.02359
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.13369
Value Function Update Magnitude: 0.25424

Collected Steps per Second: 10001.09210
Overall Steps per Second: 7038.90539

Timestep Collection Time: 5.00265
Timestep Consumption Time: 2.10527
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.10792

Cumulative Model Updates: 41070
Cumulative Timesteps: 342870087

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 342870087...
Checkpoint 342870087 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.85446
Policy Entropy: 1.22196
Value Function Loss: 0.06213

Mean KL Divergence: 0.02987
SB3 Clip Fraction: 0.16310
Policy Update Magnitude: 0.12444
Value Function Update Magnitude: 0.25390

Collected Steps per Second: 9836.72695
Overall Steps per Second: 7085.32157

Timestep Collection Time: 5.08757
Timestep Consumption Time: 1.97563
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.06319

Cumulative Model Updates: 41076
Cumulative Timesteps: 342920132

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.85635
Policy Entropy: 1.22279
Value Function Loss: 0.06461

Mean KL Divergence: 0.02731
SB3 Clip Fraction: 0.16180
Policy Update Magnitude: 0.12894
Value Function Update Magnitude: 0.24468

Collected Steps per Second: 10343.45877
Overall Steps per Second: 7195.95193

Timestep Collection Time: 4.83842
Timestep Consumption Time: 2.11632
PPO Batch Consumption Time: 0.02444
Total Iteration Time: 6.95474

Cumulative Model Updates: 41082
Cumulative Timesteps: 342970178

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.39701
Policy Entropy: 1.21667
Value Function Loss: 0.05860

Mean KL Divergence: 0.02796
SB3 Clip Fraction: 0.16991
Policy Update Magnitude: 0.12930
Value Function Update Magnitude: 0.24016

Collected Steps per Second: 9167.44728
Overall Steps per Second: 6479.71598

Timestep Collection Time: 5.45506
Timestep Consumption Time: 2.26271
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.71778

Cumulative Model Updates: 41088
Cumulative Timesteps: 343020187

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.03043
Policy Entropy: 1.22308
Value Function Loss: 0.05674

Mean KL Divergence: 0.03053
SB3 Clip Fraction: 0.17610
Policy Update Magnitude: 0.12346
Value Function Update Magnitude: 0.25112

Collected Steps per Second: 8772.45029
Overall Steps per Second: 6388.43199

Timestep Collection Time: 5.70126
Timestep Consumption Time: 2.12758
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.82884

Cumulative Model Updates: 41094
Cumulative Timesteps: 343070201

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.52647
Policy Entropy: 1.21047
Value Function Loss: 0.05793

Mean KL Divergence: 0.02655
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.12784
Value Function Update Magnitude: 0.26281

Collected Steps per Second: 9865.48936
Overall Steps per Second: 7041.30085

Timestep Collection Time: 5.07111
Timestep Consumption Time: 2.03397
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.10508

Cumulative Model Updates: 41100
Cumulative Timesteps: 343120230

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.47366
Policy Entropy: 1.21273
Value Function Loss: 0.05957

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.13949
Value Function Update Magnitude: 0.26103

Collected Steps per Second: 9348.59201
Overall Steps per Second: 6766.26257

Timestep Collection Time: 5.34883
Timestep Consumption Time: 2.04137
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.39020

Cumulative Model Updates: 41106
Cumulative Timesteps: 343170234

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.61673
Policy Entropy: 1.20037
Value Function Loss: 0.05936

Mean KL Divergence: 0.02840
SB3 Clip Fraction: 0.17141
Policy Update Magnitude: 0.13444
Value Function Update Magnitude: 0.24944

Collected Steps per Second: 9199.37399
Overall Steps per Second: 6641.13749

Timestep Collection Time: 5.43852
Timestep Consumption Time: 2.09498
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.53350

Cumulative Model Updates: 41112
Cumulative Timesteps: 343220265

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.92482
Policy Entropy: 1.19412
Value Function Loss: 0.05646

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.16426
Policy Update Magnitude: 0.12283
Value Function Update Magnitude: 0.24166

Collected Steps per Second: 9938.17864
Overall Steps per Second: 7162.39826

Timestep Collection Time: 5.03372
Timestep Consumption Time: 1.95081
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.98453

Cumulative Model Updates: 41118
Cumulative Timesteps: 343270291

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.00342
Policy Entropy: 1.18313
Value Function Loss: 0.05627

Mean KL Divergence: 0.04063
SB3 Clip Fraction: 0.20633
Policy Update Magnitude: 0.12677
Value Function Update Magnitude: 0.24308

Collected Steps per Second: 9088.38601
Overall Steps per Second: 6468.58377

Timestep Collection Time: 5.50560
Timestep Consumption Time: 2.22979
PPO Batch Consumption Time: 0.02935
Total Iteration Time: 7.73539

Cumulative Model Updates: 41124
Cumulative Timesteps: 343320328

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.19413
Policy Entropy: 1.18043
Value Function Loss: 0.05252

Mean KL Divergence: 0.02421
SB3 Clip Fraction: 0.15609
Policy Update Magnitude: 0.13202
Value Function Update Magnitude: 0.24701

Collected Steps per Second: 9050.28540
Overall Steps per Second: 6596.69669

Timestep Collection Time: 5.52944
Timestep Consumption Time: 2.05663
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 7.58607

Cumulative Model Updates: 41130
Cumulative Timesteps: 343370371

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 343370371...
Checkpoint 343370371 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.37275
Policy Entropy: 1.16941
Value Function Loss: 0.05301

Mean KL Divergence: 0.03134
SB3 Clip Fraction: 0.17358
Policy Update Magnitude: 0.13510
Value Function Update Magnitude: 0.25578

Collected Steps per Second: 10261.12974
Overall Steps per Second: 7280.72847

Timestep Collection Time: 4.87441
Timestep Consumption Time: 1.99537
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.86978

Cumulative Model Updates: 41136
Cumulative Timesteps: 343420388

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.66344
Policy Entropy: 1.16400
Value Function Loss: 0.05334

Mean KL Divergence: 0.02262
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.12028
Value Function Update Magnitude: 0.25874

Collected Steps per Second: 9110.88572
Overall Steps per Second: 6374.72833

Timestep Collection Time: 5.49025
Timestep Consumption Time: 2.35652
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.84677

Cumulative Model Updates: 41142
Cumulative Timesteps: 343470409

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.29095
Policy Entropy: 1.13978
Value Function Loss: 0.05730

Mean KL Divergence: 0.03331
SB3 Clip Fraction: 0.18418
Policy Update Magnitude: 0.12292
Value Function Update Magnitude: 0.26195

Collected Steps per Second: 8863.72268
Overall Steps per Second: 6418.35355

Timestep Collection Time: 5.64289
Timestep Consumption Time: 2.14992
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 7.79281

Cumulative Model Updates: 41148
Cumulative Timesteps: 343520426

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.40352
Policy Entropy: 1.14039
Value Function Loss: 0.05660

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.15321
Policy Update Magnitude: 0.11695
Value Function Update Magnitude: 0.26934

Collected Steps per Second: 10176.24860
Overall Steps per Second: 7299.74732

Timestep Collection Time: 4.91556
Timestep Consumption Time: 1.93700
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.85257

Cumulative Model Updates: 41154
Cumulative Timesteps: 343570448

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.60204
Policy Entropy: 1.14646
Value Function Loss: 0.05896

Mean KL Divergence: 0.03140
SB3 Clip Fraction: 0.18657
Policy Update Magnitude: 0.11882
Value Function Update Magnitude: 0.26993

Collected Steps per Second: 9893.65558
Overall Steps per Second: 7142.12315

Timestep Collection Time: 5.05445
Timestep Consumption Time: 1.94725
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.00170

Cumulative Model Updates: 41160
Cumulative Timesteps: 343620455

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.23809
Policy Entropy: 1.15106
Value Function Loss: 0.05940

Mean KL Divergence: 0.03299
SB3 Clip Fraction: 0.17759
Policy Update Magnitude: 0.12272
Value Function Update Magnitude: 0.28427

Collected Steps per Second: 10028.95356
Overall Steps per Second: 7285.95325

Timestep Collection Time: 4.98616
Timestep Consumption Time: 1.87718
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 6.86334

Cumulative Model Updates: 41166
Cumulative Timesteps: 343670461

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.56819
Policy Entropy: 1.14496
Value Function Loss: 0.05953

Mean KL Divergence: 0.03203
SB3 Clip Fraction: 0.18271
Policy Update Magnitude: 0.12906
Value Function Update Magnitude: 0.27142

Collected Steps per Second: 10365.95160
Overall Steps per Second: 7342.50083

Timestep Collection Time: 4.82696
Timestep Consumption Time: 1.98762
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 6.81457

Cumulative Model Updates: 41172
Cumulative Timesteps: 343720497

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.80425
Policy Entropy: 1.15068
Value Function Loss: 0.05771

Mean KL Divergence: 0.03080
SB3 Clip Fraction: 0.18701
Policy Update Magnitude: 0.12310
Value Function Update Magnitude: 0.27574

Collected Steps per Second: 9923.29686
Overall Steps per Second: 7166.01668

Timestep Collection Time: 5.04066
Timestep Consumption Time: 1.93950
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 6.98017

Cumulative Model Updates: 41178
Cumulative Timesteps: 343770517

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.18694
Policy Entropy: 1.15125
Value Function Loss: 0.05412

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.13564
Value Function Update Magnitude: 0.26955

Collected Steps per Second: 9126.44604
Overall Steps per Second: 6552.68272

Timestep Collection Time: 5.47990
Timestep Consumption Time: 2.15240
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 7.63229

Cumulative Model Updates: 41184
Cumulative Timesteps: 343820529

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.11168
Policy Entropy: 1.15801
Value Function Loss: 0.05585

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.14220
Value Function Update Magnitude: 0.26072

Collected Steps per Second: 9820.43476
Overall Steps per Second: 6991.77055

Timestep Collection Time: 5.09580
Timestep Consumption Time: 2.06161
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 7.15741

Cumulative Model Updates: 41190
Cumulative Timesteps: 343870572

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 343870572...
Checkpoint 343870572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.98922
Policy Entropy: 1.15437
Value Function Loss: 0.05685

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.16427
Policy Update Magnitude: 0.15840
Value Function Update Magnitude: 0.25137

Collected Steps per Second: 9682.85880
Overall Steps per Second: 6990.31774

Timestep Collection Time: 5.16387
Timestep Consumption Time: 1.98903
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 7.15289

Cumulative Model Updates: 41196
Cumulative Timesteps: 343920573

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.10970
Policy Entropy: 1.15816
Value Function Loss: 0.06069

Mean KL Divergence: 0.02961
SB3 Clip Fraction: 0.17570
Policy Update Magnitude: 0.13089
Value Function Update Magnitude: 0.25117

Collected Steps per Second: 9702.32314
Overall Steps per Second: 7023.62728

Timestep Collection Time: 5.15588
Timestep Consumption Time: 1.96637
PPO Batch Consumption Time: 0.02471
Total Iteration Time: 7.12225

Cumulative Model Updates: 41202
Cumulative Timesteps: 343970597

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.94518
Policy Entropy: 1.14721
Value Function Loss: 0.05853

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.13521
Value Function Update Magnitude: 0.25507

Collected Steps per Second: 9644.17486
Overall Steps per Second: 6692.64701

Timestep Collection Time: 5.18779
Timestep Consumption Time: 2.28787
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 7.47567

Cumulative Model Updates: 41208
Cumulative Timesteps: 344020629

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.52153
Policy Entropy: 1.14305
Value Function Loss: 0.05792

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.14642
Policy Update Magnitude: 0.13849
Value Function Update Magnitude: 0.26256

Collected Steps per Second: 9572.59352
Overall Steps per Second: 6803.78720

Timestep Collection Time: 5.22439
Timestep Consumption Time: 2.12607
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.35047

Cumulative Model Updates: 41214
Cumulative Timesteps: 344070640

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.56504
Policy Entropy: 1.14101
Value Function Loss: 0.05592

Mean KL Divergence: 0.03270
SB3 Clip Fraction: 0.18137
Policy Update Magnitude: 0.13177
Value Function Update Magnitude: 0.28094

Collected Steps per Second: 9477.77347
Overall Steps per Second: 6676.07856

Timestep Collection Time: 5.27751
Timestep Consumption Time: 2.21477
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.49227

Cumulative Model Updates: 41220
Cumulative Timesteps: 344120659

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.00130
Policy Entropy: 1.14741
Value Function Loss: 0.06011

Mean KL Divergence: 0.03256
SB3 Clip Fraction: 0.19423
Policy Update Magnitude: 0.11330
Value Function Update Magnitude: 0.28192

Collected Steps per Second: 10137.52837
Overall Steps per Second: 6757.08676

Timestep Collection Time: 4.93631
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 7.40585

Cumulative Model Updates: 41226
Cumulative Timesteps: 344170701

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.49792
Policy Entropy: 1.14348
Value Function Loss: 0.06066

Mean KL Divergence: 0.03257
SB3 Clip Fraction: 0.19708
Policy Update Magnitude: 0.10806
Value Function Update Magnitude: 0.28155

Collected Steps per Second: 9645.92864
Overall Steps per Second: 6666.25264

Timestep Collection Time: 5.18602
Timestep Consumption Time: 2.31804
PPO Batch Consumption Time: 0.02863
Total Iteration Time: 7.50407

Cumulative Model Updates: 41232
Cumulative Timesteps: 344220725

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.87227
Policy Entropy: 1.14247
Value Function Loss: 0.06270

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.13717
Value Function Update Magnitude: 0.27869

Collected Steps per Second: 9153.88145
Overall Steps per Second: 6530.06970

Timestep Collection Time: 5.46391
Timestep Consumption Time: 2.19542
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.65934

Cumulative Model Updates: 41238
Cumulative Timesteps: 344270741

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.95190
Policy Entropy: 1.14512
Value Function Loss: 0.05922

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.15035
Value Function Update Magnitude: 0.28753

Collected Steps per Second: 9471.85494
Overall Steps per Second: 6615.93500

Timestep Collection Time: 5.28112
Timestep Consumption Time: 2.27972
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 7.56084

Cumulative Model Updates: 41244
Cumulative Timesteps: 344320763

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.85516
Policy Entropy: 1.13734
Value Function Loss: 0.05623

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.13800
Value Function Update Magnitude: 0.28219

Collected Steps per Second: 9909.30096
Overall Steps per Second: 6942.39688

Timestep Collection Time: 5.04576
Timestep Consumption Time: 2.15636
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 7.20212

Cumulative Model Updates: 41250
Cumulative Timesteps: 344370763

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 344370763...
Checkpoint 344370763 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.54978
Policy Entropy: 1.13528
Value Function Loss: 0.05422

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.15531
Policy Update Magnitude: 0.11820
Value Function Update Magnitude: 0.27222

Collected Steps per Second: 9671.14518
Overall Steps per Second: 6963.61602

Timestep Collection Time: 5.17198
Timestep Consumption Time: 2.01092
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.18291

Cumulative Model Updates: 41256
Cumulative Timesteps: 344420782

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.53072
Policy Entropy: 1.13423
Value Function Loss: 0.05611

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.11591
Value Function Update Magnitude: 0.26644

Collected Steps per Second: 9931.21787
Overall Steps per Second: 7004.62043

Timestep Collection Time: 5.03644
Timestep Consumption Time: 2.10427
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.14072

Cumulative Model Updates: 41262
Cumulative Timesteps: 344470800

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.07620
Policy Entropy: 1.13188
Value Function Loss: 0.05516

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.16225
Policy Update Magnitude: 0.11294
Value Function Update Magnitude: 0.25447

Collected Steps per Second: 9606.28695
Overall Steps per Second: 6760.84640

Timestep Collection Time: 5.20898
Timestep Consumption Time: 2.19231
PPO Batch Consumption Time: 0.02441
Total Iteration Time: 7.40129

Cumulative Model Updates: 41268
Cumulative Timesteps: 344520839

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.10210
Policy Entropy: 1.12869
Value Function Loss: 0.05550

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.12319
Value Function Update Magnitude: 0.25367

Collected Steps per Second: 9505.50465
Overall Steps per Second: 6818.32506

Timestep Collection Time: 5.26295
Timestep Consumption Time: 2.07419
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.33714

Cumulative Model Updates: 41274
Cumulative Timesteps: 344570866

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.50943
Policy Entropy: 1.12276
Value Function Loss: 0.05560

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.15545
Policy Update Magnitude: 0.13409
Value Function Update Magnitude: 0.25902

Collected Steps per Second: 9564.45090
Overall Steps per Second: 7071.65448

Timestep Collection Time: 5.23031
Timestep Consumption Time: 1.84371
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.07402

Cumulative Model Updates: 41280
Cumulative Timesteps: 344620891

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.42687
Policy Entropy: 1.14319
Value Function Loss: 0.05864

Mean KL Divergence: 0.03361
SB3 Clip Fraction: 0.20242
Policy Update Magnitude: 0.12680
Value Function Update Magnitude: 0.25821

Collected Steps per Second: 10466.68622
Overall Steps per Second: 7378.18963

Timestep Collection Time: 4.78146
Timestep Consumption Time: 2.00151
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.78296

Cumulative Model Updates: 41286
Cumulative Timesteps: 344670937

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.93555
Policy Entropy: 1.14018
Value Function Loss: 0.05755

Mean KL Divergence: 0.03606
SB3 Clip Fraction: 0.19993
Policy Update Magnitude: 0.11449
Value Function Update Magnitude: 0.25721

Collected Steps per Second: 9836.96393
Overall Steps per Second: 7070.61775

Timestep Collection Time: 5.08399
Timestep Consumption Time: 1.98909
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.07307

Cumulative Model Updates: 41292
Cumulative Timesteps: 344720948

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.00490
Policy Entropy: 1.14236
Value Function Loss: 0.05732

Mean KL Divergence: 0.03511
SB3 Clip Fraction: 0.19240
Policy Update Magnitude: 0.11923
Value Function Update Magnitude: 0.24793

Collected Steps per Second: 9797.23078
Overall Steps per Second: 7051.53971

Timestep Collection Time: 5.10491
Timestep Consumption Time: 1.98772
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 7.09264

Cumulative Model Updates: 41298
Cumulative Timesteps: 344770962

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.46785
Policy Entropy: 1.14834
Value Function Loss: 0.05427

Mean KL Divergence: 0.03432
SB3 Clip Fraction: 0.20598
Policy Update Magnitude: 0.11314
Value Function Update Magnitude: 0.24423

Collected Steps per Second: 9722.14943
Overall Steps per Second: 6788.70054

Timestep Collection Time: 5.14660
Timestep Consumption Time: 2.22388
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.37048

Cumulative Model Updates: 41304
Cumulative Timesteps: 344820998

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.94699
Policy Entropy: 1.14356
Value Function Loss: 0.05820

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.19788
Policy Update Magnitude: 0.11431
Value Function Update Magnitude: 0.25124

Collected Steps per Second: 9273.53908
Overall Steps per Second: 6697.45656

Timestep Collection Time: 5.39578
Timestep Consumption Time: 2.07541
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.47119

Cumulative Model Updates: 41310
Cumulative Timesteps: 344871036

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 344871036...
Checkpoint 344871036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.84901
Policy Entropy: 1.14566
Value Function Loss: 0.05726

Mean KL Divergence: 0.03194
SB3 Clip Fraction: 0.19554
Policy Update Magnitude: 0.11716
Value Function Update Magnitude: 0.26409

Collected Steps per Second: 10069.25400
Overall Steps per Second: 7195.34011

Timestep Collection Time: 4.96760
Timestep Consumption Time: 1.98412
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 6.95172

Cumulative Model Updates: 41316
Cumulative Timesteps: 344921056

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.31514
Policy Entropy: 1.12864
Value Function Loss: 0.05887

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.12837
Value Function Update Magnitude: 0.26805

Collected Steps per Second: 10523.27945
Overall Steps per Second: 7276.16618

Timestep Collection Time: 4.75299
Timestep Consumption Time: 2.12110
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 6.87409

Cumulative Model Updates: 41322
Cumulative Timesteps: 344971073

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.21940
Policy Entropy: 1.13368
Value Function Loss: 0.05585

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.14944
Policy Update Magnitude: 0.13119
Value Function Update Magnitude: 0.27078

Collected Steps per Second: 9234.61145
Overall Steps per Second: 6575.26122

Timestep Collection Time: 5.41939
Timestep Consumption Time: 2.19186
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.61126

Cumulative Model Updates: 41328
Cumulative Timesteps: 345021119

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.56989
Policy Entropy: 1.12103
Value Function Loss: 0.05878

Mean KL Divergence: 0.03333
SB3 Clip Fraction: 0.18484
Policy Update Magnitude: 0.12234
Value Function Update Magnitude: 0.26981

Collected Steps per Second: 9736.58652
Overall Steps per Second: 6966.59656

Timestep Collection Time: 5.13548
Timestep Consumption Time: 2.04192
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 7.17739

Cumulative Model Updates: 41334
Cumulative Timesteps: 345071121

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.60796
Policy Entropy: 1.12570
Value Function Loss: 0.05930

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.12077
Value Function Update Magnitude: 0.26877

Collected Steps per Second: 9991.49030
Overall Steps per Second: 7011.40257

Timestep Collection Time: 5.00596
Timestep Consumption Time: 2.12771
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.13367

Cumulative Model Updates: 41340
Cumulative Timesteps: 345121138

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.06579
Policy Entropy: 1.12034
Value Function Loss: 0.06049

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.12548
Value Function Update Magnitude: 0.26902

Collected Steps per Second: 9070.16816
Overall Steps per Second: 6541.42801

Timestep Collection Time: 5.51743
Timestep Consumption Time: 2.13289
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.65032

Cumulative Model Updates: 41346
Cumulative Timesteps: 345171182

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.75570
Policy Entropy: 1.11979
Value Function Loss: 0.05942

Mean KL Divergence: 0.02662
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.13689
Value Function Update Magnitude: 0.26619

Collected Steps per Second: 9041.09291
Overall Steps per Second: 6507.44026

Timestep Collection Time: 5.53075
Timestep Consumption Time: 2.15338
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.68413

Cumulative Model Updates: 41352
Cumulative Timesteps: 345221186

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.66961
Policy Entropy: 1.13365
Value Function Loss: 0.05910

Mean KL Divergence: 0.03087
SB3 Clip Fraction: 0.18768
Policy Update Magnitude: 0.12488
Value Function Update Magnitude: 0.26730

Collected Steps per Second: 9850.25492
Overall Steps per Second: 6852.60971

Timestep Collection Time: 5.08048
Timestep Consumption Time: 2.22243
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 7.30291

Cumulative Model Updates: 41358
Cumulative Timesteps: 345271230

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.37924
Policy Entropy: 1.12502
Value Function Loss: 0.05737

Mean KL Divergence: 0.02473
SB3 Clip Fraction: 0.16357
Policy Update Magnitude: 0.12710
Value Function Update Magnitude: 0.28085

Collected Steps per Second: 9380.21682
Overall Steps per Second: 6810.41250

Timestep Collection Time: 5.33506
Timestep Consumption Time: 2.01310
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.34816

Cumulative Model Updates: 41364
Cumulative Timesteps: 345321274

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.20102
Policy Entropy: 1.12095
Value Function Loss: 0.05860

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.15249
Policy Update Magnitude: 0.13575
Value Function Update Magnitude: 0.27787

Collected Steps per Second: 9117.94461
Overall Steps per Second: 6484.84791

Timestep Collection Time: 5.48523
Timestep Consumption Time: 2.22721
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.71244

Cumulative Model Updates: 41370
Cumulative Timesteps: 345371288

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 345371288...
Checkpoint 345371288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.64234
Policy Entropy: 1.10941
Value Function Loss: 0.05809

Mean KL Divergence: 0.03660
SB3 Clip Fraction: 0.19998
Policy Update Magnitude: 0.12789
Value Function Update Magnitude: 0.27354

Collected Steps per Second: 9966.07591
Overall Steps per Second: 7034.68154

Timestep Collection Time: 5.01953
Timestep Consumption Time: 2.09167
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.11120

Cumulative Model Updates: 41376
Cumulative Timesteps: 345421313

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.91474
Policy Entropy: 1.12707
Value Function Loss: 0.06033

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.16494
Policy Update Magnitude: 0.13543
Value Function Update Magnitude: 0.28137

Collected Steps per Second: 10234.95525
Overall Steps per Second: 7259.64438

Timestep Collection Time: 4.88590
Timestep Consumption Time: 2.00245
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 6.88835

Cumulative Model Updates: 41382
Cumulative Timesteps: 345471320

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.47214
Policy Entropy: 1.13080
Value Function Loss: 0.05969

Mean KL Divergence: 0.03081
SB3 Clip Fraction: 0.18837
Policy Update Magnitude: 0.13405
Value Function Update Magnitude: 0.27845

Collected Steps per Second: 9605.42960
Overall Steps per Second: 6864.05884

Timestep Collection Time: 5.20705
Timestep Consumption Time: 2.07960
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.28665

Cumulative Model Updates: 41388
Cumulative Timesteps: 345521336

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.36896
Policy Entropy: 1.12762
Value Function Loss: 0.06102

Mean KL Divergence: 0.02145
SB3 Clip Fraction: 0.14288
Policy Update Magnitude: 0.15103
Value Function Update Magnitude: 0.27929

Collected Steps per Second: 9394.43542
Overall Steps per Second: 6549.95621

Timestep Collection Time: 5.32379
Timestep Consumption Time: 2.31199
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 7.63578

Cumulative Model Updates: 41394
Cumulative Timesteps: 345571350

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.09076
Policy Entropy: 1.12032
Value Function Loss: 0.06074

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.15686
Value Function Update Magnitude: 0.27715

Collected Steps per Second: 9448.67562
Overall Steps per Second: 6892.69565

Timestep Collection Time: 5.29408
Timestep Consumption Time: 1.96317
PPO Batch Consumption Time: 0.02451
Total Iteration Time: 7.25725

Cumulative Model Updates: 41400
Cumulative Timesteps: 345621372

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.79081
Policy Entropy: 1.10898
Value Function Loss: 0.06267

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.16354
Value Function Update Magnitude: 0.25898

Collected Steps per Second: 9465.90584
Overall Steps per Second: 6764.18901

Timestep Collection Time: 5.28328
Timestep Consumption Time: 2.11022
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 7.39350

Cumulative Model Updates: 41406
Cumulative Timesteps: 345671383

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.37706
Policy Entropy: 1.11209
Value Function Loss: 0.06382

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.15830
Policy Update Magnitude: 0.15376
Value Function Update Magnitude: 0.26453

Collected Steps per Second: 9459.54868
Overall Steps per Second: 6666.09847

Timestep Collection Time: 5.28609
Timestep Consumption Time: 2.21515
PPO Batch Consumption Time: 0.02869
Total Iteration Time: 7.50124

Cumulative Model Updates: 41412
Cumulative Timesteps: 345721387

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.22046
Policy Entropy: 1.12553
Value Function Loss: 0.06454

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.18451
Policy Update Magnitude: 0.14175
Value Function Update Magnitude: 0.27457

Collected Steps per Second: 9378.56915
Overall Steps per Second: 6773.38102

Timestep Collection Time: 5.33472
Timestep Consumption Time: 2.05185
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.38656

Cumulative Model Updates: 41418
Cumulative Timesteps: 345771419

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.15752
Policy Entropy: 1.12247
Value Function Loss: 0.06509

Mean KL Divergence: 0.02842
SB3 Clip Fraction: 0.17293
Policy Update Magnitude: 0.14177
Value Function Update Magnitude: 0.27148

Collected Steps per Second: 9749.14263
Overall Steps per Second: 7116.36632

Timestep Collection Time: 5.13286
Timestep Consumption Time: 1.89896
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 7.03182

Cumulative Model Updates: 41424
Cumulative Timesteps: 345821460

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.17996
Policy Entropy: 1.12432
Value Function Loss: 0.06216

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.14848
Policy Update Magnitude: 0.14664
Value Function Update Magnitude: 0.27314

Collected Steps per Second: 9927.14258
Overall Steps per Second: 7038.68089

Timestep Collection Time: 5.03851
Timestep Consumption Time: 2.06765
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 7.10616

Cumulative Model Updates: 41430
Cumulative Timesteps: 345871478

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 345871478...
Checkpoint 345871478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.10855
Policy Entropy: 1.11618
Value Function Loss: 0.05971

Mean KL Divergence: 0.02624
SB3 Clip Fraction: 0.16251
Policy Update Magnitude: 0.14982
Value Function Update Magnitude: 0.26107

Collected Steps per Second: 9143.62335
Overall Steps per Second: 6471.42190

Timestep Collection Time: 5.47070
Timestep Consumption Time: 2.25898
PPO Batch Consumption Time: 0.02935
Total Iteration Time: 7.72968

Cumulative Model Updates: 41436
Cumulative Timesteps: 345921500

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.40406
Policy Entropy: 1.12008
Value Function Loss: 0.05906

Mean KL Divergence: 0.03128
SB3 Clip Fraction: 0.18199
Policy Update Magnitude: 0.13038
Value Function Update Magnitude: 0.25251

Collected Steps per Second: 8958.36080
Overall Steps per Second: 6465.19018

Timestep Collection Time: 5.58160
Timestep Consumption Time: 2.15243
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.73403

Cumulative Model Updates: 41442
Cumulative Timesteps: 345971502

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.69192
Policy Entropy: 1.12308
Value Function Loss: 0.05980

Mean KL Divergence: 0.02440
SB3 Clip Fraction: 0.15793
Policy Update Magnitude: 0.11534
Value Function Update Magnitude: 0.25458

Collected Steps per Second: 9579.89010
Overall Steps per Second: 6684.62263

Timestep Collection Time: 5.22104
Timestep Consumption Time: 2.26136
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.48240

Cumulative Model Updates: 41448
Cumulative Timesteps: 346021519

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.35874
Policy Entropy: 1.11735
Value Function Loss: 0.06130

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.15069
Policy Update Magnitude: 0.12124
Value Function Update Magnitude: 0.24609

Collected Steps per Second: 9057.99611
Overall Steps per Second: 6359.39723

Timestep Collection Time: 5.52462
Timestep Consumption Time: 2.34436
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.86898

Cumulative Model Updates: 41454
Cumulative Timesteps: 346071561

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.14778
Policy Entropy: 1.13996
Value Function Loss: 0.06176

Mean KL Divergence: 0.03501
SB3 Clip Fraction: 0.20786
Policy Update Magnitude: 0.12420
Value Function Update Magnitude: 0.24845

Collected Steps per Second: 9730.55931
Overall Steps per Second: 6966.43394

Timestep Collection Time: 5.14215
Timestep Consumption Time: 2.04029
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.18244

Cumulative Model Updates: 41460
Cumulative Timesteps: 346121597

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.86137
Policy Entropy: 1.11645
Value Function Loss: 0.06281

Mean KL Divergence: 0.04178
SB3 Clip Fraction: 0.21097
Policy Update Magnitude: 0.12240
Value Function Update Magnitude: 0.24877

Collected Steps per Second: 9995.75486
Overall Steps per Second: 7115.48828

Timestep Collection Time: 5.00332
Timestep Consumption Time: 2.02529
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.02861

Cumulative Model Updates: 41466
Cumulative Timesteps: 346171609

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.51919
Policy Entropy: 1.14469
Value Function Loss: 0.06158

Mean KL Divergence: 0.03286
SB3 Clip Fraction: 0.20126
Policy Update Magnitude: 0.12221
Value Function Update Magnitude: 0.24743

Collected Steps per Second: 9347.70464
Overall Steps per Second: 6595.10695

Timestep Collection Time: 5.34955
Timestep Consumption Time: 2.23274
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.58229

Cumulative Model Updates: 41472
Cumulative Timesteps: 346221615

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.32689
Policy Entropy: 1.12456
Value Function Loss: 0.06093

Mean KL Divergence: 0.03772
SB3 Clip Fraction: 0.21124
Policy Update Magnitude: 0.11437
Value Function Update Magnitude: 0.23572

Collected Steps per Second: 9277.51303
Overall Steps per Second: 6839.17721

Timestep Collection Time: 5.38981
Timestep Consumption Time: 1.92160
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.31141

Cumulative Model Updates: 41478
Cumulative Timesteps: 346271619

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.48832
Policy Entropy: 1.13957
Value Function Loss: 0.06084

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.12454
Value Function Update Magnitude: 0.23948

Collected Steps per Second: 10461.89809
Overall Steps per Second: 7355.06227

Timestep Collection Time: 4.78097
Timestep Consumption Time: 2.01952
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 6.80049

Cumulative Model Updates: 41484
Cumulative Timesteps: 346321637

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.74617
Policy Entropy: 1.14115
Value Function Loss: 0.06116

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.14184
Value Function Update Magnitude: 0.25486

Collected Steps per Second: 9485.49401
Overall Steps per Second: 6847.43562

Timestep Collection Time: 5.27374
Timestep Consumption Time: 2.03177
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 7.30551

Cumulative Model Updates: 41490
Cumulative Timesteps: 346371661

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 346371661...
Checkpoint 346371661 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.90399
Policy Entropy: 1.14902
Value Function Loss: 0.06017

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.16062
Policy Update Magnitude: 0.13253
Value Function Update Magnitude: 0.27118

Collected Steps per Second: 9154.54370
Overall Steps per Second: 6585.93233

Timestep Collection Time: 5.46526
Timestep Consumption Time: 2.13153
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.59680

Cumulative Model Updates: 41496
Cumulative Timesteps: 346421693

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.55282
Policy Entropy: 1.15588
Value Function Loss: 0.05842

Mean KL Divergence: 0.02768
SB3 Clip Fraction: 0.16544
Policy Update Magnitude: 0.12082
Value Function Update Magnitude: 0.26170

Collected Steps per Second: 10317.87482
Overall Steps per Second: 7361.80595

Timestep Collection Time: 4.84683
Timestep Consumption Time: 1.94620
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 6.79303

Cumulative Model Updates: 41502
Cumulative Timesteps: 346471702

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.64067
Policy Entropy: 1.14654
Value Function Loss: 0.05952

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.16670
Policy Update Magnitude: 0.11356
Value Function Update Magnitude: 0.24875

Collected Steps per Second: 9916.89025
Overall Steps per Second: 7024.82797

Timestep Collection Time: 5.04331
Timestep Consumption Time: 2.07629
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.11960

Cumulative Model Updates: 41508
Cumulative Timesteps: 346521716

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.68285
Policy Entropy: 1.14052
Value Function Loss: 0.06043

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.12404
Value Function Update Magnitude: 0.24839

Collected Steps per Second: 9187.02367
Overall Steps per Second: 6585.99501

Timestep Collection Time: 5.44736
Timestep Consumption Time: 2.15134
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 7.59870

Cumulative Model Updates: 41514
Cumulative Timesteps: 346571761

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.90316
Policy Entropy: 1.14220
Value Function Loss: 0.06272

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.14797
Value Function Update Magnitude: 0.25039

Collected Steps per Second: 10052.52128
Overall Steps per Second: 7135.16288

Timestep Collection Time: 4.97626
Timestep Consumption Time: 2.03465
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.01091

Cumulative Model Updates: 41520
Cumulative Timesteps: 346621785

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.12022
Policy Entropy: 1.14119
Value Function Loss: 0.06369

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.15107
Value Function Update Magnitude: 0.25307

Collected Steps per Second: 9684.89863
Overall Steps per Second: 7009.58939

Timestep Collection Time: 5.16268
Timestep Consumption Time: 1.97041
PPO Batch Consumption Time: 0.02379
Total Iteration Time: 7.13309

Cumulative Model Updates: 41526
Cumulative Timesteps: 346671785

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.32153
Policy Entropy: 1.13745
Value Function Loss: 0.06278

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.13786
Value Function Update Magnitude: 0.25162

Collected Steps per Second: 9553.82315
Overall Steps per Second: 6922.32882

Timestep Collection Time: 5.23633
Timestep Consumption Time: 1.99057
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.22690

Cumulative Model Updates: 41532
Cumulative Timesteps: 346721812

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.24091
Policy Entropy: 1.13234
Value Function Loss: 0.06169

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.12783
Value Function Update Magnitude: 0.25532

Collected Steps per Second: 10174.09040
Overall Steps per Second: 6953.30559

Timestep Collection Time: 4.91847
Timestep Consumption Time: 2.27825
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.19672

Cumulative Model Updates: 41538
Cumulative Timesteps: 346771853

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.91922
Policy Entropy: 1.13201
Value Function Loss: 0.06052

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.13666
Value Function Update Magnitude: 0.24934

Collected Steps per Second: 10317.44028
Overall Steps per Second: 7216.82429

Timestep Collection Time: 4.84771
Timestep Consumption Time: 2.08276
PPO Batch Consumption Time: 0.02389
Total Iteration Time: 6.93047

Cumulative Model Updates: 41544
Cumulative Timesteps: 346821869

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.20006
Policy Entropy: 1.13072
Value Function Loss: 0.05617

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.15294
Value Function Update Magnitude: 0.24710

Collected Steps per Second: 10158.50468
Overall Steps per Second: 7234.67944

Timestep Collection Time: 4.92267
Timestep Consumption Time: 1.98945
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 6.91212

Cumulative Model Updates: 41550
Cumulative Timesteps: 346871876

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 346871876...
Checkpoint 346871876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.98261
Policy Entropy: 1.12655
Value Function Loss: 0.05566

Mean KL Divergence: 0.03032
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.13672
Value Function Update Magnitude: 0.24450

Collected Steps per Second: 9602.65177
Overall Steps per Second: 6859.01270

Timestep Collection Time: 5.21064
Timestep Consumption Time: 2.08428
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.29493

Cumulative Model Updates: 41556
Cumulative Timesteps: 346921912

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.64149
Policy Entropy: 1.14595
Value Function Loss: 0.05393

Mean KL Divergence: 0.02813
SB3 Clip Fraction: 0.16562
Policy Update Magnitude: 0.11966
Value Function Update Magnitude: 0.23685

Collected Steps per Second: 9361.17432
Overall Steps per Second: 6707.94849

Timestep Collection Time: 5.34217
Timestep Consumption Time: 2.11301
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 7.45519

Cumulative Model Updates: 41562
Cumulative Timesteps: 346971921

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.23037
Policy Entropy: 1.13984
Value Function Loss: 0.05822

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.11765
Value Function Update Magnitude: 0.24258

Collected Steps per Second: 9241.82481
Overall Steps per Second: 6546.24155

Timestep Collection Time: 5.41213
Timestep Consumption Time: 2.22859
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.64072

Cumulative Model Updates: 41568
Cumulative Timesteps: 347021939

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.77653
Policy Entropy: 1.15472
Value Function Loss: 0.05775

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.15452
Policy Update Magnitude: 0.12238
Value Function Update Magnitude: 0.24985

Collected Steps per Second: 9792.91888
Overall Steps per Second: 6756.01108

Timestep Collection Time: 5.10747
Timestep Consumption Time: 2.29587
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 7.40333

Cumulative Model Updates: 41574
Cumulative Timesteps: 347071956

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.69496
Policy Entropy: 1.14856
Value Function Loss: 0.05947

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.15323
Policy Update Magnitude: 0.12572
Value Function Update Magnitude: 0.24720

Collected Steps per Second: 9230.71125
Overall Steps per Second: 6503.34026

Timestep Collection Time: 5.41865
Timestep Consumption Time: 2.27247
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.69112

Cumulative Model Updates: 41580
Cumulative Timesteps: 347121974

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.58735
Policy Entropy: 1.15492
Value Function Loss: 0.05954

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.12643
Value Function Update Magnitude: 0.23586

Collected Steps per Second: 9576.19262
Overall Steps per Second: 6917.31983

Timestep Collection Time: 5.22483
Timestep Consumption Time: 2.00832
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.23315

Cumulative Model Updates: 41586
Cumulative Timesteps: 347172008

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.26774
Policy Entropy: 1.15177
Value Function Loss: 0.05979

Mean KL Divergence: 0.02542
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.12726
Value Function Update Magnitude: 0.24081

Collected Steps per Second: 9948.59806
Overall Steps per Second: 6946.06583

Timestep Collection Time: 5.02744
Timestep Consumption Time: 2.17318
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.20062

Cumulative Model Updates: 41592
Cumulative Timesteps: 347222024

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.62908
Policy Entropy: 1.16053
Value Function Loss: 0.05694

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.13218
Value Function Update Magnitude: 0.25003

Collected Steps per Second: 9375.37549
Overall Steps per Second: 6671.91000

Timestep Collection Time: 5.33419
Timestep Consumption Time: 2.16142
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.49560

Cumulative Model Updates: 41598
Cumulative Timesteps: 347272034

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.95233
Policy Entropy: 1.15900
Value Function Loss: 0.05482

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.12959
Value Function Update Magnitude: 0.24362

Collected Steps per Second: 9753.49284
Overall Steps per Second: 6928.23040

Timestep Collection Time: 5.12811
Timestep Consumption Time: 2.09119
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.21930

Cumulative Model Updates: 41604
Cumulative Timesteps: 347322051

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.23743
Policy Entropy: 1.15912
Value Function Loss: 0.05469

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.13451
Value Function Update Magnitude: 0.23442

Collected Steps per Second: 10036.01219
Overall Steps per Second: 6923.44600

Timestep Collection Time: 4.98305
Timestep Consumption Time: 2.24023
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.22328

Cumulative Model Updates: 41610
Cumulative Timesteps: 347372061

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 347372061...
Checkpoint 347372061 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.51591
Policy Entropy: 1.16804
Value Function Loss: 0.05648

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.14034
Value Function Update Magnitude: 0.23849

Collected Steps per Second: 9536.35440
Overall Steps per Second: 6797.23383

Timestep Collection Time: 5.24309
Timestep Consumption Time: 2.11284
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 7.35593

Cumulative Model Updates: 41616
Cumulative Timesteps: 347422061

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.47606
Policy Entropy: 1.17343
Value Function Loss: 0.05989

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.14476
Value Function Update Magnitude: 0.24873

Collected Steps per Second: 9632.26650
Overall Steps per Second: 6884.35398

Timestep Collection Time: 5.19317
Timestep Consumption Time: 2.07287
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.26604

Cumulative Model Updates: 41622
Cumulative Timesteps: 347472083

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.74528
Policy Entropy: 1.17865
Value Function Loss: 0.06331

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.13641
Value Function Update Magnitude: 0.24145

Collected Steps per Second: 10542.14637
Overall Steps per Second: 7437.89397

Timestep Collection Time: 4.74448
Timestep Consumption Time: 1.98014
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 6.72462

Cumulative Model Updates: 41628
Cumulative Timesteps: 347522100

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.50049
Policy Entropy: 1.17628
Value Function Loss: 0.06272

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.13264
Value Function Update Magnitude: 0.23855

Collected Steps per Second: 10032.48519
Overall Steps per Second: 7099.57705

Timestep Collection Time: 4.98750
Timestep Consumption Time: 2.06039
PPO Batch Consumption Time: 0.02843
Total Iteration Time: 7.04788

Cumulative Model Updates: 41634
Cumulative Timesteps: 347572137

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.62984
Policy Entropy: 1.17439
Value Function Loss: 0.05968

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.13297
Value Function Update Magnitude: 0.23128

Collected Steps per Second: 9269.53243
Overall Steps per Second: 6686.31802

Timestep Collection Time: 5.39801
Timestep Consumption Time: 2.08548
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.48349

Cumulative Model Updates: 41640
Cumulative Timesteps: 347622174

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.25186
Policy Entropy: 1.18162
Value Function Loss: 0.05718

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.12927
Value Function Update Magnitude: 0.23389

Collected Steps per Second: 9969.74650
Overall Steps per Second: 6834.24495

Timestep Collection Time: 5.01688
Timestep Consumption Time: 2.30171
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.31858

Cumulative Model Updates: 41646
Cumulative Timesteps: 347672191

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.89045
Policy Entropy: 1.17908
Value Function Loss: 0.05799

Mean KL Divergence: 0.02698
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.12838
Value Function Update Magnitude: 0.22530

Collected Steps per Second: 9017.98582
Overall Steps per Second: 6432.56266

Timestep Collection Time: 5.54802
Timestep Consumption Time: 2.22990
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 7.77793

Cumulative Model Updates: 41652
Cumulative Timesteps: 347722223

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.41966
Policy Entropy: 1.19386
Value Function Loss: 0.06031

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.11435
Value Function Update Magnitude: 0.22447

Collected Steps per Second: 9291.47486
Overall Steps per Second: 6623.93688

Timestep Collection Time: 5.38440
Timestep Consumption Time: 2.16836
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.55276

Cumulative Model Updates: 41658
Cumulative Timesteps: 347772252

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.73090
Policy Entropy: 1.19108
Value Function Loss: 0.06157

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.13174
Value Function Update Magnitude: 0.22417

Collected Steps per Second: 10393.35212
Overall Steps per Second: 7287.48407

Timestep Collection Time: 4.81183
Timestep Consumption Time: 2.05076
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 6.86259

Cumulative Model Updates: 41664
Cumulative Timesteps: 347822263

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.47878
Policy Entropy: 1.19040
Value Function Loss: 0.06311

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.13696
Value Function Update Magnitude: 0.23232

Collected Steps per Second: 10028.58937
Overall Steps per Second: 6903.82173

Timestep Collection Time: 4.98794
Timestep Consumption Time: 2.25761
PPO Batch Consumption Time: 0.02935
Total Iteration Time: 7.24555

Cumulative Model Updates: 41670
Cumulative Timesteps: 347872285

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 347872285...
Checkpoint 347872285 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.57290
Policy Entropy: 1.18605
Value Function Loss: 0.06183

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.13458
Value Function Update Magnitude: 0.23877

Collected Steps per Second: 9142.56886
Overall Steps per Second: 6493.46682

Timestep Collection Time: 5.47330
Timestep Consumption Time: 2.23291
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.70621

Cumulative Model Updates: 41676
Cumulative Timesteps: 347922325

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.31280
Policy Entropy: 1.19198
Value Function Loss: 0.06126

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.12945
Value Function Update Magnitude: 0.23820

Collected Steps per Second: 10003.09197
Overall Steps per Second: 7025.97586

Timestep Collection Time: 5.00095
Timestep Consumption Time: 2.11905
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 7.12001

Cumulative Model Updates: 41682
Cumulative Timesteps: 347972350

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.31421
Policy Entropy: 1.20928
Value Function Loss: 0.05867

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.12924
Value Function Update Magnitude: 0.23278

Collected Steps per Second: 9455.04309
Overall Steps per Second: 6654.17042

Timestep Collection Time: 5.28966
Timestep Consumption Time: 2.22652
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 7.51619

Cumulative Model Updates: 41688
Cumulative Timesteps: 348022364

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.77876
Policy Entropy: 1.21007
Value Function Loss: 0.05571

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.13173
Value Function Update Magnitude: 0.22554

Collected Steps per Second: 9136.17020
Overall Steps per Second: 6530.92324

Timestep Collection Time: 5.47286
Timestep Consumption Time: 2.18318
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 7.65604

Cumulative Model Updates: 41694
Cumulative Timesteps: 348072365

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.07599
Policy Entropy: 1.21329
Value Function Loss: 0.05882

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.12928
Value Function Update Magnitude: 0.22810

Collected Steps per Second: 9630.50012
Overall Steps per Second: 6742.56003

Timestep Collection Time: 5.19298
Timestep Consumption Time: 2.22423
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 7.41721

Cumulative Model Updates: 41700
Cumulative Timesteps: 348122376

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.30738
Policy Entropy: 1.21272
Value Function Loss: 0.05873

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.13276
Value Function Update Magnitude: 0.23835

Collected Steps per Second: 9848.59476
Overall Steps per Second: 7120.37728

Timestep Collection Time: 5.07727
Timestep Consumption Time: 1.94539
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 7.02266

Cumulative Model Updates: 41706
Cumulative Timesteps: 348172380

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.25445
Policy Entropy: 1.21165
Value Function Loss: 0.05980

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.13614
Value Function Update Magnitude: 0.24520

Collected Steps per Second: 9670.68837
Overall Steps per Second: 7004.79490

Timestep Collection Time: 5.17161
Timestep Consumption Time: 1.96822
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.13982

Cumulative Model Updates: 41712
Cumulative Timesteps: 348222393

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.85353
Policy Entropy: 1.21352
Value Function Loss: 0.05869

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.11991
Value Function Update Magnitude: 0.24022

Collected Steps per Second: 10305.59351
Overall Steps per Second: 7321.72816

Timestep Collection Time: 4.85280
Timestep Consumption Time: 1.97769
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.83049

Cumulative Model Updates: 41718
Cumulative Timesteps: 348272404

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.89056
Policy Entropy: 1.20405
Value Function Loss: 0.06060

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.12788
Value Function Update Magnitude: 0.24306

Collected Steps per Second: 9686.52764
Overall Steps per Second: 6932.79369

Timestep Collection Time: 5.16346
Timestep Consumption Time: 2.05095
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.21441

Cumulative Model Updates: 41724
Cumulative Timesteps: 348322420

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.22026
Policy Entropy: 1.20565
Value Function Loss: 0.06164

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.13617
Value Function Update Magnitude: 0.23983

Collected Steps per Second: 8933.66603
Overall Steps per Second: 6376.18249

Timestep Collection Time: 5.59714
Timestep Consumption Time: 2.24501
PPO Batch Consumption Time: 0.03017
Total Iteration Time: 7.84215

Cumulative Model Updates: 41730
Cumulative Timesteps: 348372423

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 348372423...
Checkpoint 348372423 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.06564
Policy Entropy: 1.20056
Value Function Loss: 0.06338

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.13272
Value Function Update Magnitude: 0.23758

Collected Steps per Second: 10193.28391
Overall Steps per Second: 7044.86915

Timestep Collection Time: 4.90529
Timestep Consumption Time: 2.19222
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.09751

Cumulative Model Updates: 41736
Cumulative Timesteps: 348422424

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.48006
Policy Entropy: 1.22434
Value Function Loss: 0.06270

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.11887
Value Function Update Magnitude: 0.25076

Collected Steps per Second: 9421.90284
Overall Steps per Second: 6512.20138

Timestep Collection Time: 5.30954
Timestep Consumption Time: 2.37234
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.68189

Cumulative Model Updates: 41742
Cumulative Timesteps: 348472450

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.81345
Policy Entropy: 1.21154
Value Function Loss: 0.06037

Mean KL Divergence: 0.03053
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.11910
Value Function Update Magnitude: 0.24716

Collected Steps per Second: 8880.55595
Overall Steps per Second: 6307.51272

Timestep Collection Time: 5.63208
Timestep Consumption Time: 2.29751
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.92959

Cumulative Model Updates: 41748
Cumulative Timesteps: 348522466

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.69529
Policy Entropy: 1.22911
Value Function Loss: 0.05704

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.11570
Value Function Update Magnitude: 0.23352

Collected Steps per Second: 10243.95915
Overall Steps per Second: 7130.63282

Timestep Collection Time: 4.88337
Timestep Consumption Time: 2.13214
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 7.01551

Cumulative Model Updates: 41754
Cumulative Timesteps: 348572491

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.21214
Policy Entropy: 1.21777
Value Function Loss: 0.05719

Mean KL Divergence: 0.02880
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.12384
Value Function Update Magnitude: 0.22951

Collected Steps per Second: 9684.65012
Overall Steps per Second: 6740.57278

Timestep Collection Time: 5.16302
Timestep Consumption Time: 2.25505
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 7.41806

Cumulative Model Updates: 41760
Cumulative Timesteps: 348622493

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.50156
Policy Entropy: 1.23331
Value Function Loss: 0.05782

Mean KL Divergence: 0.02465
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.11973
Value Function Update Magnitude: 0.23210

Collected Steps per Second: 8764.51233
Overall Steps per Second: 6351.52193

Timestep Collection Time: 5.70528
Timestep Consumption Time: 2.16748
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.87276

Cumulative Model Updates: 41766
Cumulative Timesteps: 348672497

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.64543
Policy Entropy: 1.22443
Value Function Loss: 0.05782

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.12546
Value Function Update Magnitude: 0.23708

Collected Steps per Second: 10202.00128
Overall Steps per Second: 7006.28873

Timestep Collection Time: 4.90257
Timestep Consumption Time: 2.23616
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.13873

Cumulative Model Updates: 41772
Cumulative Timesteps: 348722513

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.76661
Policy Entropy: 1.24228
Value Function Loss: 0.05813

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.12035
Value Function Update Magnitude: 0.23680

Collected Steps per Second: 9218.58151
Overall Steps per Second: 6566.40408

Timestep Collection Time: 5.42383
Timestep Consumption Time: 2.19069
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 7.61452

Cumulative Model Updates: 41778
Cumulative Timesteps: 348772513

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.46079
Policy Entropy: 1.23045
Value Function Loss: 0.05863

Mean KL Divergence: 0.02383
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.11082
Value Function Update Magnitude: 0.23678

Collected Steps per Second: 9366.59871
Overall Steps per Second: 6696.07079

Timestep Collection Time: 5.33918
Timestep Consumption Time: 2.12937
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.46856

Cumulative Model Updates: 41784
Cumulative Timesteps: 348822523

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.92238
Policy Entropy: 1.23023
Value Function Loss: 0.05841

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.12546
Value Function Update Magnitude: 0.23296

Collected Steps per Second: 10000.59695
Overall Steps per Second: 7113.09883

Timestep Collection Time: 5.00360
Timestep Consumption Time: 2.03117
PPO Batch Consumption Time: 0.02357
Total Iteration Time: 7.03477

Cumulative Model Updates: 41790
Cumulative Timesteps: 348872562

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 348872562...
Checkpoint 348872562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.18237
Policy Entropy: 1.23543
Value Function Loss: 0.05906

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.12904
Value Function Update Magnitude: 0.23121

Collected Steps per Second: 10014.39578
Overall Steps per Second: 7059.14740

Timestep Collection Time: 4.99561
Timestep Consumption Time: 2.09137
PPO Batch Consumption Time: 0.02491
Total Iteration Time: 7.08697

Cumulative Model Updates: 41796
Cumulative Timesteps: 348922590

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.43206
Policy Entropy: 1.23410
Value Function Loss: 0.05922

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.12950
Value Function Update Magnitude: 0.23445

Collected Steps per Second: 9584.83113
Overall Steps per Second: 6889.13064

Timestep Collection Time: 5.21699
Timestep Consumption Time: 2.04140
PPO Batch Consumption Time: 0.02400
Total Iteration Time: 7.25839

Cumulative Model Updates: 41802
Cumulative Timesteps: 348972594

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.27373
Policy Entropy: 1.23758
Value Function Loss: 0.05835

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.12557
Value Function Update Magnitude: 0.23601

Collected Steps per Second: 10264.73459
Overall Steps per Second: 7116.17329

Timestep Collection Time: 4.87299
Timestep Consumption Time: 2.15606
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.02906

Cumulative Model Updates: 41808
Cumulative Timesteps: 349022614

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.39745
Policy Entropy: 1.23836
Value Function Loss: 0.05683

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.11177
Value Function Update Magnitude: 0.22928

Collected Steps per Second: 9646.13782
Overall Steps per Second: 6794.28760

Timestep Collection Time: 5.18539
Timestep Consumption Time: 2.17653
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.36192

Cumulative Model Updates: 41814
Cumulative Timesteps: 349072633

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.48446
Policy Entropy: 1.24601
Value Function Loss: 0.05714

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.11080
Value Function Update Magnitude: 0.23026

Collected Steps per Second: 9278.84327
Overall Steps per Second: 6740.79829

Timestep Collection Time: 5.39216
Timestep Consumption Time: 2.03026
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.42241

Cumulative Model Updates: 41820
Cumulative Timesteps: 349122666

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.98783
Policy Entropy: 1.24377
Value Function Loss: 0.06010

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.12295
Value Function Update Magnitude: 0.23049

Collected Steps per Second: 10363.54264
Overall Steps per Second: 7200.93271

Timestep Collection Time: 4.82866
Timestep Consumption Time: 2.12072
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 6.94938

Cumulative Model Updates: 41826
Cumulative Timesteps: 349172708

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.93082
Policy Entropy: 1.24186
Value Function Loss: 0.06214

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.13185
Value Function Update Magnitude: 0.23965

Collected Steps per Second: 9791.54486
Overall Steps per Second: 7087.37574

Timestep Collection Time: 5.10910
Timestep Consumption Time: 1.94936
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.05847

Cumulative Model Updates: 41832
Cumulative Timesteps: 349222734

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.00275
Policy Entropy: 1.24087
Value Function Loss: 0.06294

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.12797
Value Function Update Magnitude: 0.24681

Collected Steps per Second: 9972.92302
Overall Steps per Second: 7200.28591

Timestep Collection Time: 5.01779
Timestep Consumption Time: 1.93222
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.95000

Cumulative Model Updates: 41838
Cumulative Timesteps: 349272776

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.94873
Policy Entropy: 1.24169
Value Function Loss: 0.06301

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.12851
Value Function Update Magnitude: 0.23698

Collected Steps per Second: 10071.48394
Overall Steps per Second: 7014.64918

Timestep Collection Time: 4.96858
Timestep Consumption Time: 2.16520
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 7.13379

Cumulative Model Updates: 41844
Cumulative Timesteps: 349322817

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.86051
Policy Entropy: 1.24751
Value Function Loss: 0.05960

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.12339
Value Function Update Magnitude: 0.22943

Collected Steps per Second: 8857.75666
Overall Steps per Second: 6358.79776

Timestep Collection Time: 5.64680
Timestep Consumption Time: 2.21915
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.86595

Cumulative Model Updates: 41850
Cumulative Timesteps: 349372835

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 349372835...
Checkpoint 349372835 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.94340
Policy Entropy: 1.23885
Value Function Loss: 0.05661

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.11164
Value Function Update Magnitude: 0.22189

Collected Steps per Second: 9314.25788
Overall Steps per Second: 6837.26950

Timestep Collection Time: 5.37187
Timestep Consumption Time: 1.94611
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.31798

Cumulative Model Updates: 41856
Cumulative Timesteps: 349422870

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.87995
Policy Entropy: 1.24912
Value Function Loss: 0.05968

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.12139
Value Function Update Magnitude: 0.23146

Collected Steps per Second: 9675.57602
Overall Steps per Second: 6570.34372

Timestep Collection Time: 5.16796
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.61041

Cumulative Model Updates: 41862
Cumulative Timesteps: 349472873

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.15087
Policy Entropy: 1.24694
Value Function Loss: 0.06083

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.13045
Value Function Update Magnitude: 0.23498

Collected Steps per Second: 9367.53493
Overall Steps per Second: 6668.52041

Timestep Collection Time: 5.33961
Timestep Consumption Time: 2.16115
PPO Batch Consumption Time: 0.02439
Total Iteration Time: 7.50076

Cumulative Model Updates: 41868
Cumulative Timesteps: 349522892

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.33081
Policy Entropy: 1.25206
Value Function Loss: 0.06098

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.12960
Value Function Update Magnitude: 0.24095

Collected Steps per Second: 9718.63415
Overall Steps per Second: 6986.32278

Timestep Collection Time: 5.14815
Timestep Consumption Time: 2.01341
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.16156

Cumulative Model Updates: 41874
Cumulative Timesteps: 349572925

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.37908
Policy Entropy: 1.25859
Value Function Loss: 0.05597

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.12487
Value Function Update Magnitude: 0.23705

Collected Steps per Second: 10278.81388
Overall Steps per Second: 6770.57434

Timestep Collection Time: 4.86447
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 7.38505

Cumulative Model Updates: 41880
Cumulative Timesteps: 349622926

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.96826
Policy Entropy: 1.26018
Value Function Loss: 0.05455

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.12005
Value Function Update Magnitude: 0.23084

Collected Steps per Second: 9461.97180
Overall Steps per Second: 6778.33957

Timestep Collection Time: 5.28568
Timestep Consumption Time: 2.09267
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.37836

Cumulative Model Updates: 41886
Cumulative Timesteps: 349672939

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.36433
Policy Entropy: 1.26276
Value Function Loss: 0.05689

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.11775
Value Function Update Magnitude: 0.23072

Collected Steps per Second: 9570.28698
Overall Steps per Second: 6907.49179

Timestep Collection Time: 5.22868
Timestep Consumption Time: 2.01562
PPO Batch Consumption Time: 0.02994
Total Iteration Time: 7.24431

Cumulative Model Updates: 41892
Cumulative Timesteps: 349722979

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.43322
Policy Entropy: 1.26068
Value Function Loss: 0.05963

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.12394
Value Function Update Magnitude: 0.23054

Collected Steps per Second: 9711.50770
Overall Steps per Second: 6736.07654

Timestep Collection Time: 5.15080
Timestep Consumption Time: 2.27519
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 7.42598

Cumulative Model Updates: 41898
Cumulative Timesteps: 349773001

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.23994
Policy Entropy: 1.25515
Value Function Loss: 0.06435

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.12726
Value Function Update Magnitude: 0.24083

Collected Steps per Second: 9125.48710
Overall Steps per Second: 6505.97979

Timestep Collection Time: 5.48289
Timestep Consumption Time: 2.20758
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.69046

Cumulative Model Updates: 41904
Cumulative Timesteps: 349823035

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.37880
Policy Entropy: 1.25363
Value Function Loss: 0.06123

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.12889
Value Function Update Magnitude: 0.23683

Collected Steps per Second: 9711.74954
Overall Steps per Second: 7120.07616

Timestep Collection Time: 5.14923
Timestep Consumption Time: 1.87429
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.02352

Cumulative Model Updates: 41910
Cumulative Timesteps: 349873043

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 349873043...
Checkpoint 349873043 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.38619
Policy Entropy: 1.24353
Value Function Loss: 0.06054

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.12620
Value Function Update Magnitude: 0.23048

Collected Steps per Second: 10468.68195
Overall Steps per Second: 7382.28077

Timestep Collection Time: 4.77921
Timestep Consumption Time: 1.99810
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 6.77731

Cumulative Model Updates: 41916
Cumulative Timesteps: 349923075

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.23274
Policy Entropy: 1.26365
Value Function Loss: 0.05661

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.11198
Value Function Update Magnitude: 0.23921

Collected Steps per Second: 9980.10021
Overall Steps per Second: 6990.11113

Timestep Collection Time: 5.01087
Timestep Consumption Time: 2.14338
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.15425

Cumulative Model Updates: 41922
Cumulative Timesteps: 349973084

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.35080
Policy Entropy: 1.25365
Value Function Loss: 0.05490

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.11733
Value Function Update Magnitude: 0.24056

Collected Steps per Second: 9880.48761
Overall Steps per Second: 7116.40026

Timestep Collection Time: 5.06190
Timestep Consumption Time: 1.96610
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.02799

Cumulative Model Updates: 41928
Cumulative Timesteps: 350023098

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.24983
Policy Entropy: 1.27221
Value Function Loss: 0.05432

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.12024
Value Function Update Magnitude: 0.23392

Collected Steps per Second: 10543.78841
Overall Steps per Second: 7472.72819

Timestep Collection Time: 4.74602
Timestep Consumption Time: 1.95047
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 6.69648

Cumulative Model Updates: 41934
Cumulative Timesteps: 350073139

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.85734
Policy Entropy: 1.26719
Value Function Loss: 0.05204

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.12385
Value Function Update Magnitude: 0.22761

Collected Steps per Second: 9906.01240
Overall Steps per Second: 7169.18753

Timestep Collection Time: 5.04764
Timestep Consumption Time: 1.92693
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 6.97457

Cumulative Model Updates: 41940
Cumulative Timesteps: 350123141

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.65670
Policy Entropy: 1.26969
Value Function Loss: 0.05650

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.12412
Value Function Update Magnitude: 0.22230

Collected Steps per Second: 9911.10727
Overall Steps per Second: 7105.35231

Timestep Collection Time: 5.04817
Timestep Consumption Time: 1.99342
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.04159

Cumulative Model Updates: 41946
Cumulative Timesteps: 350173174

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.85601
Policy Entropy: 1.26603
Value Function Loss: 0.05713

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.11836
Value Function Update Magnitude: 0.22137

Collected Steps per Second: 10522.84987
Overall Steps per Second: 7382.63637

Timestep Collection Time: 4.75356
Timestep Consumption Time: 2.02193
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.77549

Cumulative Model Updates: 41952
Cumulative Timesteps: 350223195

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.66726
Policy Entropy: 1.26461
Value Function Loss: 0.05766

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.11895
Value Function Update Magnitude: 0.22377

Collected Steps per Second: 9838.11031
Overall Steps per Second: 7102.08264

Timestep Collection Time: 5.08543
Timestep Consumption Time: 1.95913
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.04455

Cumulative Model Updates: 41958
Cumulative Timesteps: 350273226

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -4.28222
Policy Entropy: 1.27287
Value Function Loss: 0.05874

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.12235
Value Function Update Magnitude: 0.22725

Collected Steps per Second: 9679.43170
Overall Steps per Second: 6773.39408

Timestep Collection Time: 5.16632
Timestep Consumption Time: 2.21654
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.38286

Cumulative Model Updates: 41964
Cumulative Timesteps: 350323233

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30877
Policy Entropy: 1.27330
Value Function Loss: 0.06208

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.12847
Value Function Update Magnitude: 0.23763

Collected Steps per Second: 9674.03350
Overall Steps per Second: 6811.45091

Timestep Collection Time: 5.17085
Timestep Consumption Time: 2.17310
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.34396

Cumulative Model Updates: 41970
Cumulative Timesteps: 350373256

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 350373256...
Checkpoint 350373256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.91315
Policy Entropy: 1.27628
Value Function Loss: 0.06315

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.12481
Value Function Update Magnitude: 0.24185

Collected Steps per Second: 9158.94638
Overall Steps per Second: 6584.60540

Timestep Collection Time: 5.46395
Timestep Consumption Time: 2.13620
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.60015

Cumulative Model Updates: 41976
Cumulative Timesteps: 350423300

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.61900
Policy Entropy: 1.27881
Value Function Loss: 0.05976

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.12616
Value Function Update Magnitude: 0.24487

Collected Steps per Second: 9145.02806
Overall Steps per Second: 6628.41629

Timestep Collection Time: 5.47161
Timestep Consumption Time: 2.07741
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.54901

Cumulative Model Updates: 41982
Cumulative Timesteps: 350473338

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.51839
Policy Entropy: 1.27746
Value Function Loss: 0.05718

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.11819
Value Function Update Magnitude: 0.26292

Collected Steps per Second: 10586.77353
Overall Steps per Second: 7257.55838

Timestep Collection Time: 4.72420
Timestep Consumption Time: 2.16710
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 6.89130

Cumulative Model Updates: 41988
Cumulative Timesteps: 350523352

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.24086
Policy Entropy: 1.27866
Value Function Loss: 0.05575

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.07256
Policy Update Magnitude: 0.11368
Value Function Update Magnitude: 0.25060

Collected Steps per Second: 9404.63430
Overall Steps per Second: 6601.39374

Timestep Collection Time: 5.32142
Timestep Consumption Time: 2.25971
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.58113

Cumulative Model Updates: 41994
Cumulative Timesteps: 350573398

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.33649
Policy Entropy: 1.28457
Value Function Loss: 0.05651

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.11680
Value Function Update Magnitude: 0.26279

Collected Steps per Second: 8944.35634
Overall Steps per Second: 6454.80450

Timestep Collection Time: 5.59392
Timestep Consumption Time: 2.15752
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.75144

Cumulative Model Updates: 42000
Cumulative Timesteps: 350623432

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.07708
Policy Entropy: 1.28564
Value Function Loss: 0.05671

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.11698
Value Function Update Magnitude: 0.26114

Collected Steps per Second: 11010.26626
Overall Steps per Second: 7469.38959

Timestep Collection Time: 4.54167
Timestep Consumption Time: 2.15299
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 6.69466

Cumulative Model Updates: 42006
Cumulative Timesteps: 350673437

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.84957
Policy Entropy: 1.28759
Value Function Loss: 0.05736

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.06819
Policy Update Magnitude: 0.11600
Value Function Update Magnitude: 0.24438

Collected Steps per Second: 9819.69257
Overall Steps per Second: 6727.83384

Timestep Collection Time: 5.09436
Timestep Consumption Time: 2.34117
PPO Batch Consumption Time: 0.03039
Total Iteration Time: 7.43553

Cumulative Model Updates: 42012
Cumulative Timesteps: 350723462

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.21244
Policy Entropy: 1.28005
Value Function Loss: 0.05825

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.11817
Value Function Update Magnitude: 0.22936

Collected Steps per Second: 8740.00429
Overall Steps per Second: 6354.06153

Timestep Collection Time: 5.72494
Timestep Consumption Time: 2.14971
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.87465

Cumulative Model Updates: 42018
Cumulative Timesteps: 350773498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.95105
Policy Entropy: 1.28110
Value Function Loss: 0.05732

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.11797
Value Function Update Magnitude: 0.22116

Collected Steps per Second: 9962.83210
Overall Steps per Second: 6956.39214

Timestep Collection Time: 5.02086
Timestep Consumption Time: 2.16993
PPO Batch Consumption Time: 0.02998
Total Iteration Time: 7.19080

Cumulative Model Updates: 42024
Cumulative Timesteps: 350823520

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.98360
Policy Entropy: 1.28082
Value Function Loss: 0.06339

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.12025
Value Function Update Magnitude: 0.23282

Collected Steps per Second: 9535.25244
Overall Steps per Second: 6622.47147

Timestep Collection Time: 5.24695
Timestep Consumption Time: 2.30778
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 7.55473

Cumulative Model Updates: 42030
Cumulative Timesteps: 350873551

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 350873551...
Checkpoint 350873551 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.50633
Policy Entropy: 1.27968
Value Function Loss: 0.06155

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.12080
Value Function Update Magnitude: 0.24950

Collected Steps per Second: 8849.92074
Overall Steps per Second: 6376.07955

Timestep Collection Time: 5.65045
Timestep Consumption Time: 2.19230
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 7.84275

Cumulative Model Updates: 42036
Cumulative Timesteps: 350923557

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.37841
Policy Entropy: 1.27749
Value Function Loss: 0.06058

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.10946
Value Function Update Magnitude: 0.25955

Collected Steps per Second: 10361.75871
Overall Steps per Second: 7181.00411

Timestep Collection Time: 4.82717
Timestep Consumption Time: 2.13815
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 6.96532

Cumulative Model Updates: 42042
Cumulative Timesteps: 350973575

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.33980
Policy Entropy: 1.27576
Value Function Loss: 0.05591

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.10168
Value Function Update Magnitude: 0.25898

Collected Steps per Second: 10000.82848
Overall Steps per Second: 7200.62887

Timestep Collection Time: 5.00009
Timestep Consumption Time: 1.94445
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 6.94453

Cumulative Model Updates: 42048
Cumulative Timesteps: 351023580

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.45831
Policy Entropy: 1.27545
Value Function Loss: 0.05701

Mean KL Divergence: 0.02190
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.10486
Value Function Update Magnitude: 0.25484

Collected Steps per Second: 9660.89358
Overall Steps per Second: 6990.44880

Timestep Collection Time: 5.18016
Timestep Consumption Time: 1.97889
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.15905

Cumulative Model Updates: 42054
Cumulative Timesteps: 351073625

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.81487
Policy Entropy: 1.27187
Value Function Loss: 0.05782

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.10560
Policy Update Magnitude: 0.11368
Value Function Update Magnitude: 0.24932

Collected Steps per Second: 10194.30241
Overall Steps per Second: 7266.83666

Timestep Collection Time: 4.90588
Timestep Consumption Time: 1.97635
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 6.88222

Cumulative Model Updates: 42060
Cumulative Timesteps: 351123637

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.34724
Policy Entropy: 1.27430
Value Function Loss: 0.05637

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.12389
Value Function Update Magnitude: 0.25157

Collected Steps per Second: 9717.44298
Overall Steps per Second: 6992.76319

Timestep Collection Time: 5.14693
Timestep Consumption Time: 2.00546
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.15239

Cumulative Model Updates: 42066
Cumulative Timesteps: 351173652

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.72598
Policy Entropy: 1.27366
Value Function Loss: 0.05676

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.11952
Value Function Update Magnitude: 0.24533

Collected Steps per Second: 9838.13968
Overall Steps per Second: 7178.25127

Timestep Collection Time: 5.08318
Timestep Consumption Time: 1.88356
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 6.96674

Cumulative Model Updates: 42072
Cumulative Timesteps: 351223661

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.06432
Policy Entropy: 1.27369
Value Function Loss: 0.05684

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.12586
Value Function Update Magnitude: 0.24604

Collected Steps per Second: 10413.80317
Overall Steps per Second: 7377.33554

Timestep Collection Time: 4.80218
Timestep Consumption Time: 1.97655
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 6.77873

Cumulative Model Updates: 42078
Cumulative Timesteps: 351273670

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.88598
Policy Entropy: 1.27425
Value Function Loss: 0.05844

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.12310
Value Function Update Magnitude: 0.24572

Collected Steps per Second: 9973.27616
Overall Steps per Second: 7194.99139

Timestep Collection Time: 5.01460
Timestep Consumption Time: 1.93635
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.95095

Cumulative Model Updates: 42084
Cumulative Timesteps: 351323682

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.16503
Policy Entropy: 1.27189
Value Function Loss: 0.05973

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.11651
Value Function Update Magnitude: 0.25004

Collected Steps per Second: 9943.37108
Overall Steps per Second: 7117.91787

Timestep Collection Time: 5.03260
Timestep Consumption Time: 1.99769
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.03029

Cumulative Model Updates: 42090
Cumulative Timesteps: 351373723

Timesteps Collected: 50041
--------END ITERATION REPORT--------


Saving checkpoint 351373723...
Checkpoint 351373723 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.89558
Policy Entropy: 1.27607
Value Function Loss: 0.05720

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.11989
Value Function Update Magnitude: 0.25002

Collected Steps per Second: 9853.05388
Overall Steps per Second: 6940.09459

Timestep Collection Time: 5.07914
Timestep Consumption Time: 2.13186
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 7.21100

Cumulative Model Updates: 42096
Cumulative Timesteps: 351423768

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.65867
Policy Entropy: 1.26863
Value Function Loss: 0.05631

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.11521
Value Function Update Magnitude: 0.24128

Collected Steps per Second: 9057.24183
Overall Steps per Second: 6617.02469

Timestep Collection Time: 5.52055
Timestep Consumption Time: 2.03586
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.55642

Cumulative Model Updates: 42102
Cumulative Timesteps: 351473769

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.10699
Policy Entropy: 1.26920
Value Function Loss: 0.05455

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.10943
Value Function Update Magnitude: 0.23124

Collected Steps per Second: 9261.72214
Overall Steps per Second: 6581.32307

Timestep Collection Time: 5.40170
Timestep Consumption Time: 2.19997
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.60166

Cumulative Model Updates: 42108
Cumulative Timesteps: 351523798

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.13063
Policy Entropy: 1.26688
Value Function Loss: 0.05790

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.11371
Value Function Update Magnitude: 0.22754

Collected Steps per Second: 10001.23584
Overall Steps per Second: 7052.34650

Timestep Collection Time: 5.00068
Timestep Consumption Time: 2.09100
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.09168

Cumulative Model Updates: 42114
Cumulative Timesteps: 351573811

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.84860
Policy Entropy: 1.26721
Value Function Loss: 0.05893

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.11314
Value Function Update Magnitude: 0.23217

Collected Steps per Second: 9021.57812
Overall Steps per Second: 6419.07237

Timestep Collection Time: 5.54692
Timestep Consumption Time: 2.24891
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.79583

Cumulative Model Updates: 42120
Cumulative Timesteps: 351623853

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.48827
Policy Entropy: 1.26320
Value Function Loss: 0.06240

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.11920
Value Function Update Magnitude: 0.23784

Collected Steps per Second: 9095.90585
Overall Steps per Second: 6540.07246

Timestep Collection Time: 5.50182
Timestep Consumption Time: 2.15009
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.65190

Cumulative Model Updates: 42126
Cumulative Timesteps: 351673897

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.36920
Policy Entropy: 1.27134
Value Function Loss: 0.05940

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.11147
Value Function Update Magnitude: 0.24419

Collected Steps per Second: 9652.11190
Overall Steps per Second: 6719.63691

Timestep Collection Time: 5.18177
Timestep Consumption Time: 2.26134
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.44311

Cumulative Model Updates: 42132
Cumulative Timesteps: 351723912

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.09098
Policy Entropy: 1.26620
Value Function Loss: 0.05585

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.10249
Value Function Update Magnitude: 0.23141

Collected Steps per Second: 9531.35913
Overall Steps per Second: 6816.31373

Timestep Collection Time: 5.24752
Timestep Consumption Time: 2.09017
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.33769

Cumulative Model Updates: 42138
Cumulative Timesteps: 351773928

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.85782
Policy Entropy: 1.26658
Value Function Loss: 0.05381

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.11254
Value Function Update Magnitude: 0.22704

Collected Steps per Second: 9178.70016
Overall Steps per Second: 6675.64310

Timestep Collection Time: 5.45164
Timestep Consumption Time: 2.04411
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.49576

Cumulative Model Updates: 42144
Cumulative Timesteps: 351823967

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.41042
Policy Entropy: 1.25875
Value Function Loss: 0.05343

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.11641
Value Function Update Magnitude: 0.23386

Collected Steps per Second: 9836.45814
Overall Steps per Second: 6849.95470

Timestep Collection Time: 5.08435
Timestep Consumption Time: 2.21672
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.30107

Cumulative Model Updates: 42150
Cumulative Timesteps: 351873979

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 351873979...
Checkpoint 351873979 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.43745
Policy Entropy: 1.26187
Value Function Loss: 0.05446

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.11325
Value Function Update Magnitude: 0.23365

Collected Steps per Second: 9281.76504
Overall Steps per Second: 6672.92404

Timestep Collection Time: 5.38691
Timestep Consumption Time: 2.10606
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.49297

Cumulative Model Updates: 42156
Cumulative Timesteps: 351923979

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.17384
Policy Entropy: 1.25696
Value Function Loss: 0.05392

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.11614
Value Function Update Magnitude: 0.23671

Collected Steps per Second: 9206.10626
Overall Steps per Second: 6721.37764

Timestep Collection Time: 5.43368
Timestep Consumption Time: 2.00870
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.44237

Cumulative Model Updates: 42162
Cumulative Timesteps: 351974002

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.68961
Policy Entropy: 1.25811
Value Function Loss: 0.05802

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.12359
Value Function Update Magnitude: 0.25122

Collected Steps per Second: 10636.96984
Overall Steps per Second: 7331.12186

Timestep Collection Time: 4.70284
Timestep Consumption Time: 2.12067
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 6.82351

Cumulative Model Updates: 42168
Cumulative Timesteps: 352024026

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.14209
Policy Entropy: 1.25283
Value Function Loss: 0.05715

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.12122
Value Function Update Magnitude: 0.24549

Collected Steps per Second: 10118.52731
Overall Steps per Second: 7222.42857

Timestep Collection Time: 4.94509
Timestep Consumption Time: 1.98291
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.92800

Cumulative Model Updates: 42174
Cumulative Timesteps: 352074063

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.85360
Policy Entropy: 1.25663
Value Function Loss: 0.06007

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.12568
Value Function Update Magnitude: 0.23388

Collected Steps per Second: 9808.22711
Overall Steps per Second: 7125.76245

Timestep Collection Time: 5.10000
Timestep Consumption Time: 1.91988
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.01988

Cumulative Model Updates: 42180
Cumulative Timesteps: 352124085

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.91936
Policy Entropy: 1.25024
Value Function Loss: 0.05733

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.11956
Value Function Update Magnitude: 0.23084

Collected Steps per Second: 10345.63204
Overall Steps per Second: 7418.15835

Timestep Collection Time: 4.83547
Timestep Consumption Time: 1.90825
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 6.74372

Cumulative Model Updates: 42186
Cumulative Timesteps: 352174111

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.02759
Policy Entropy: 1.24521
Value Function Loss: 0.05722

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.11917
Value Function Update Magnitude: 0.23668

Collected Steps per Second: 10236.50167
Overall Steps per Second: 7353.85027

Timestep Collection Time: 4.88526
Timestep Consumption Time: 1.91498
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 6.80025

Cumulative Model Updates: 42192
Cumulative Timesteps: 352224119

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.32281
Policy Entropy: 1.24049
Value Function Loss: 0.05822

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.11945
Value Function Update Magnitude: 0.23586

Collected Steps per Second: 10064.57602
Overall Steps per Second: 7236.61831

Timestep Collection Time: 4.96871
Timestep Consumption Time: 1.94170
PPO Batch Consumption Time: 0.02366
Total Iteration Time: 6.91041

Cumulative Model Updates: 42198
Cumulative Timesteps: 352274127

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.23859
Policy Entropy: 1.23619
Value Function Loss: 0.05650

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.10584
Value Function Update Magnitude: 0.23947

Collected Steps per Second: 10398.52964
Overall Steps per Second: 7278.32152

Timestep Collection Time: 4.81183
Timestep Consumption Time: 2.06283
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 6.87466

Cumulative Model Updates: 42204
Cumulative Timesteps: 352324163

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.79402
Policy Entropy: 1.23570
Value Function Loss: 0.05712

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.10529
Value Function Update Magnitude: 0.23426

Collected Steps per Second: 9947.86479
Overall Steps per Second: 7033.65179

Timestep Collection Time: 5.02761
Timestep Consumption Time: 2.08306
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.11067

Cumulative Model Updates: 42210
Cumulative Timesteps: 352374177

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 352374177...
Checkpoint 352374177 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.77657
Policy Entropy: 1.23868
Value Function Loss: 0.05357

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.11011
Value Function Update Magnitude: 0.22585

Collected Steps per Second: 9072.51260
Overall Steps per Second: 6607.89269

Timestep Collection Time: 5.51126
Timestep Consumption Time: 2.05560
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.56686

Cumulative Model Updates: 42216
Cumulative Timesteps: 352424178

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.16137
Policy Entropy: 1.24134
Value Function Loss: 0.05701

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.11174
Value Function Update Magnitude: 0.22498

Collected Steps per Second: 10006.40701
Overall Steps per Second: 6994.31464

Timestep Collection Time: 4.99800
Timestep Consumption Time: 2.15238
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.15038

Cumulative Model Updates: 42222
Cumulative Timesteps: 352474190

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.06062
Policy Entropy: 1.24298
Value Function Loss: 0.05528

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.11640
Value Function Update Magnitude: 0.22577

Collected Steps per Second: 9640.52938
Overall Steps per Second: 6794.96054

Timestep Collection Time: 5.18976
Timestep Consumption Time: 2.17335
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.36310

Cumulative Model Updates: 42228
Cumulative Timesteps: 352524222

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.29295
Policy Entropy: 1.23224
Value Function Loss: 0.05840

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.10713
Value Function Update Magnitude: 0.21726

Collected Steps per Second: 8610.10421
Overall Steps per Second: 6342.44034

Timestep Collection Time: 5.80992
Timestep Consumption Time: 2.07727
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 7.88718

Cumulative Model Updates: 42234
Cumulative Timesteps: 352574246

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.31102
Policy Entropy: 1.23437
Value Function Loss: 0.05691

Mean KL Divergence: 0.02586
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.10451
Value Function Update Magnitude: 0.21377

Collected Steps per Second: 9819.18138
Overall Steps per Second: 6870.00221

Timestep Collection Time: 5.09401
Timestep Consumption Time: 2.18677
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.28078

Cumulative Model Updates: 42240
Cumulative Timesteps: 352624265

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.77050
Policy Entropy: 1.23548
Value Function Loss: 0.05914

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.10339
Value Function Update Magnitude: 0.21605

Collected Steps per Second: 9480.69840
Overall Steps per Second: 6756.15699

Timestep Collection Time: 5.27609
Timestep Consumption Time: 2.12768
PPO Batch Consumption Time: 0.03086
Total Iteration Time: 7.40377

Cumulative Model Updates: 42246
Cumulative Timesteps: 352674286

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.77561
Policy Entropy: 1.23729
Value Function Loss: 0.05942

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.11885
Value Function Update Magnitude: 0.21836

Collected Steps per Second: 9089.55701
Overall Steps per Second: 6694.76176

Timestep Collection Time: 5.50236
Timestep Consumption Time: 1.96826
PPO Batch Consumption Time: 0.02371
Total Iteration Time: 7.47062

Cumulative Model Updates: 42252
Cumulative Timesteps: 352724300

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.79829
Policy Entropy: 1.23942
Value Function Loss: 0.06018

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.12566
Value Function Update Magnitude: 0.21907

Collected Steps per Second: 10274.45390
Overall Steps per Second: 7068.05027

Timestep Collection Time: 4.86858
Timestep Consumption Time: 2.20862
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.07720

Cumulative Model Updates: 42258
Cumulative Timesteps: 352774322

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.07539
Policy Entropy: 1.23204
Value Function Loss: 0.06107

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.11447
Value Function Update Magnitude: 0.22713

Collected Steps per Second: 10064.73534
Overall Steps per Second: 7222.24761

Timestep Collection Time: 4.96873
Timestep Consumption Time: 1.95556
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 6.92430

Cumulative Model Updates: 42264
Cumulative Timesteps: 352824331

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.99254
Policy Entropy: 1.22769
Value Function Loss: 0.05891

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.11310
Value Function Update Magnitude: 0.23326

Collected Steps per Second: 8985.63690
Overall Steps per Second: 6439.34125

Timestep Collection Time: 5.56477
Timestep Consumption Time: 2.20047
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.76524

Cumulative Model Updates: 42270
Cumulative Timesteps: 352874334

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 352874334...
Checkpoint 352874334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.90587
Policy Entropy: 1.21918
Value Function Loss: 0.05980

Mean KL Divergence: 0.02931
SB3 Clip Fraction: 0.16116
Policy Update Magnitude: 0.11796
Value Function Update Magnitude: 0.23136

Collected Steps per Second: 9923.87929
Overall Steps per Second: 6924.43055

Timestep Collection Time: 5.04017
Timestep Consumption Time: 2.18324
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 7.22341

Cumulative Model Updates: 42276
Cumulative Timesteps: 352924352

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.63244
Policy Entropy: 1.19581
Value Function Loss: 0.05825

Mean KL Divergence: 0.03648
SB3 Clip Fraction: 0.18387
Policy Update Magnitude: 0.10066
Value Function Update Magnitude: 0.22071

Collected Steps per Second: 9531.90360
Overall Steps per Second: 6967.71514

Timestep Collection Time: 5.24659
Timestep Consumption Time: 1.93080
PPO Batch Consumption Time: 0.02440
Total Iteration Time: 7.17739

Cumulative Model Updates: 42282
Cumulative Timesteps: 352974362

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.22602
Policy Entropy: 1.20248
Value Function Loss: 0.06091

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.10552
Value Function Update Magnitude: 0.22465

Collected Steps per Second: 9577.38114
Overall Steps per Second: 6915.53845

Timestep Collection Time: 5.22314
Timestep Consumption Time: 2.01043
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.23357

Cumulative Model Updates: 42288
Cumulative Timesteps: 353024386

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.84286
Policy Entropy: 1.20068
Value Function Loss: 0.06075

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.12071
Value Function Update Magnitude: 0.24184

Collected Steps per Second: 10205.85153
Overall Steps per Second: 7221.61354

Timestep Collection Time: 4.90042
Timestep Consumption Time: 2.02504
PPO Batch Consumption Time: 0.02435
Total Iteration Time: 6.92546

Cumulative Model Updates: 42294
Cumulative Timesteps: 353074399

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.64208
Policy Entropy: 1.19364
Value Function Loss: 0.06180

Mean KL Divergence: 0.02573
SB3 Clip Fraction: 0.15602
Policy Update Magnitude: 0.12157
Value Function Update Magnitude: 0.22706

Collected Steps per Second: 9739.06056
Overall Steps per Second: 6772.51703

Timestep Collection Time: 5.13643
Timestep Consumption Time: 2.24989
PPO Batch Consumption Time: 0.02445
Total Iteration Time: 7.38632

Cumulative Model Updates: 42300
Cumulative Timesteps: 353124423

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.74060
Policy Entropy: 1.18893
Value Function Loss: 0.06538

Mean KL Divergence: 0.02655
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.10687
Value Function Update Magnitude: 0.23916

Collected Steps per Second: 9456.24087
Overall Steps per Second: 6756.84578

Timestep Collection Time: 5.29111
Timestep Consumption Time: 2.11383
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.40493

Cumulative Model Updates: 42306
Cumulative Timesteps: 353174457

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.79194
Policy Entropy: 1.17805
Value Function Loss: 0.06618

Mean KL Divergence: 0.02857
SB3 Clip Fraction: 0.16671
Policy Update Magnitude: 0.10259
Value Function Update Magnitude: 0.24895

Collected Steps per Second: 10319.01319
Overall Steps per Second: 7279.89343

Timestep Collection Time: 4.84572
Timestep Consumption Time: 2.02293
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.86864

Cumulative Model Updates: 42312
Cumulative Timesteps: 353224460

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.09984
Policy Entropy: 1.17341
Value Function Loss: 0.06661

Mean KL Divergence: 0.03609
SB3 Clip Fraction: 0.18725
Policy Update Magnitude: 0.09969
Value Function Update Magnitude: 0.25867

Collected Steps per Second: 10235.66636
Overall Steps per Second: 7300.35722

Timestep Collection Time: 4.88576
Timestep Consumption Time: 1.96445
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 6.85021

Cumulative Model Updates: 42318
Cumulative Timesteps: 353274469

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.39930
Policy Entropy: 1.16659
Value Function Loss: 0.06401

Mean KL Divergence: 0.02600
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.10723
Value Function Update Magnitude: 0.24687

Collected Steps per Second: 11082.84964
Overall Steps per Second: 7626.83668

Timestep Collection Time: 4.51148
Timestep Consumption Time: 2.04432
PPO Batch Consumption Time: 0.02427
Total Iteration Time: 6.55580

Cumulative Model Updates: 42324
Cumulative Timesteps: 353324469

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.21685
Policy Entropy: 1.16588
Value Function Loss: 0.06483

Mean KL Divergence: 0.03184
SB3 Clip Fraction: 0.16497
Policy Update Magnitude: 0.12672
Value Function Update Magnitude: 0.22707

Collected Steps per Second: 10582.87615
Overall Steps per Second: 7423.79205

Timestep Collection Time: 4.72461
Timestep Consumption Time: 2.01049
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 6.73510

Cumulative Model Updates: 42330
Cumulative Timesteps: 353374469

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 353374469...
Checkpoint 353374469 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.84082
Policy Entropy: 1.15788
Value Function Loss: 0.06333

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.17576
Policy Update Magnitude: 0.11643
Value Function Update Magnitude: 0.23686

Collected Steps per Second: 9557.57569
Overall Steps per Second: 6949.18388

Timestep Collection Time: 5.23208
Timestep Consumption Time: 1.96387
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 7.19595

Cumulative Model Updates: 42336
Cumulative Timesteps: 353424475

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.71653
Policy Entropy: 1.15867
Value Function Loss: 0.06071

Mean KL Divergence: 0.02795
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.11265
Value Function Update Magnitude: 0.24021

Collected Steps per Second: 9353.21955
Overall Steps per Second: 6633.14244

Timestep Collection Time: 5.34714
Timestep Consumption Time: 2.19272
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 7.53987

Cumulative Model Updates: 42342
Cumulative Timesteps: 353474488

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.80848
Policy Entropy: 1.15465
Value Function Loss: 0.05891

Mean KL Divergence: 0.02400
SB3 Clip Fraction: 0.15755
Policy Update Magnitude: 0.11783
Value Function Update Magnitude: 0.24216

Collected Steps per Second: 9682.58277
Overall Steps per Second: 6823.70782

Timestep Collection Time: 5.16505
Timestep Consumption Time: 2.16396
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 7.32901

Cumulative Model Updates: 42348
Cumulative Timesteps: 353524499

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.94732
Policy Entropy: 1.15125
Value Function Loss: 0.05917

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.12110
Value Function Update Magnitude: 0.24753

Collected Steps per Second: 9819.92900
Overall Steps per Second: 6933.70781

Timestep Collection Time: 5.09362
Timestep Consumption Time: 2.12027
PPO Batch Consumption Time: 0.03052
Total Iteration Time: 7.21389

Cumulative Model Updates: 42354
Cumulative Timesteps: 353574518

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.03393
Policy Entropy: 1.15206
Value Function Loss: 0.06100

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.12996
Value Function Update Magnitude: 0.24266

Collected Steps per Second: 8886.33557
Overall Steps per Second: 6322.83801

Timestep Collection Time: 5.62740
Timestep Consumption Time: 2.28154
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.90895

Cumulative Model Updates: 42360
Cumulative Timesteps: 353624525

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.94926
Policy Entropy: 1.15274
Value Function Loss: 0.06329

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.13477
Value Function Update Magnitude: 0.24315

Collected Steps per Second: 9793.61772
Overall Steps per Second: 6967.21100

Timestep Collection Time: 5.10833
Timestep Consumption Time: 2.07231
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 7.18064

Cumulative Model Updates: 42366
Cumulative Timesteps: 353674554

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.10289
Policy Entropy: 1.16140
Value Function Loss: 0.06447

Mean KL Divergence: 0.03686
SB3 Clip Fraction: 0.19381
Policy Update Magnitude: 0.11491
Value Function Update Magnitude: 0.24317

Collected Steps per Second: 9444.30245
Overall Steps per Second: 6978.85179

Timestep Collection Time: 5.29780
Timestep Consumption Time: 1.87158
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.16937

Cumulative Model Updates: 42372
Cumulative Timesteps: 353724588

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.67876
Policy Entropy: 1.15155
Value Function Loss: 0.06333

Mean KL Divergence: 0.02647
SB3 Clip Fraction: 0.16614
Policy Update Magnitude: 0.10729
Value Function Update Magnitude: 0.25012

Collected Steps per Second: 9393.33395
Overall Steps per Second: 6688.26563

Timestep Collection Time: 5.32505
Timestep Consumption Time: 2.15372
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.47877

Cumulative Model Updates: 42378
Cumulative Timesteps: 353774608

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.06492
Policy Entropy: 1.14202
Value Function Loss: 0.06165

Mean KL Divergence: 0.03801
SB3 Clip Fraction: 0.20043
Policy Update Magnitude: 0.10719
Value Function Update Magnitude: 0.23310

Collected Steps per Second: 10340.00634
Overall Steps per Second: 7248.27828

Timestep Collection Time: 4.83713
Timestep Consumption Time: 2.06326
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 6.90040

Cumulative Model Updates: 42384
Cumulative Timesteps: 353824624

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.93265
Policy Entropy: 1.13121
Value Function Loss: 0.05819

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.15665
Policy Update Magnitude: 0.10677
Value Function Update Magnitude: 0.21509

Collected Steps per Second: 10261.34148
Overall Steps per Second: 7214.48676

Timestep Collection Time: 4.87578
Timestep Consumption Time: 2.05916
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 6.93494

Cumulative Model Updates: 42390
Cumulative Timesteps: 353874656

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 353874656...
Checkpoint 353874656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.57669
Policy Entropy: 1.13141
Value Function Loss: 0.05806

Mean KL Divergence: 0.02874
SB3 Clip Fraction: 0.17628
Policy Update Magnitude: 0.09676
Value Function Update Magnitude: 0.18899

Collected Steps per Second: 9409.29515
Overall Steps per Second: 6756.85499

Timestep Collection Time: 5.31804
Timestep Consumption Time: 2.08763
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.40566

Cumulative Model Updates: 42396
Cumulative Timesteps: 353924695

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.93885
Policy Entropy: 1.13618
Value Function Loss: 0.06068

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.09992
Value Function Update Magnitude: 0.17503

Collected Steps per Second: 9960.22164
Overall Steps per Second: 7070.25609

Timestep Collection Time: 5.02318
Timestep Consumption Time: 2.05322
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.07641

Cumulative Model Updates: 42402
Cumulative Timesteps: 353974727

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.17459
Policy Entropy: 1.11285
Value Function Loss: 0.06500

Mean KL Divergence: 0.04846
SB3 Clip Fraction: 0.23794
Policy Update Magnitude: 0.10875
Value Function Update Magnitude: 0.19016

Collected Steps per Second: 10318.88961
Overall Steps per Second: 7250.98769

Timestep Collection Time: 4.84694
Timestep Consumption Time: 2.05074
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 6.89768

Cumulative Model Updates: 42408
Cumulative Timesteps: 354024742

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.27913
Policy Entropy: 1.10387
Value Function Loss: 0.06500

Mean KL Divergence: 0.03332
SB3 Clip Fraction: 0.17795
Policy Update Magnitude: 0.12726
Value Function Update Magnitude: 0.20745

Collected Steps per Second: 9232.68821
Overall Steps per Second: 6502.97702

Timestep Collection Time: 5.41565
Timestep Consumption Time: 2.27329
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.68894

Cumulative Model Updates: 42414
Cumulative Timesteps: 354074743

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.90731
Policy Entropy: 1.08545
Value Function Loss: 0.06373

Mean KL Divergence: 0.03081
SB3 Clip Fraction: 0.17830
Policy Update Magnitude: 0.12077
Value Function Update Magnitude: 0.21560

Collected Steps per Second: 9587.91151
Overall Steps per Second: 6836.38970

Timestep Collection Time: 5.21657
Timestep Consumption Time: 2.09957
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 7.31614

Cumulative Model Updates: 42420
Cumulative Timesteps: 354124759

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.98131
Policy Entropy: 1.10024
Value Function Loss: 0.06195

Mean KL Divergence: 0.03163
SB3 Clip Fraction: 0.18409
Policy Update Magnitude: 0.10813
Value Function Update Magnitude: 0.22110

Collected Steps per Second: 9133.11789
Overall Steps per Second: 6639.35350

Timestep Collection Time: 5.47776
Timestep Consumption Time: 2.05746
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.53522

Cumulative Model Updates: 42426
Cumulative Timesteps: 354174788

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.79009
Policy Entropy: 1.10421
Value Function Loss: 0.06220

Mean KL Divergence: 0.03980
SB3 Clip Fraction: 0.20970
Policy Update Magnitude: 0.10975
Value Function Update Magnitude: 0.23451

Collected Steps per Second: 9513.14128
Overall Steps per Second: 6833.83576

Timestep Collection Time: 5.25652
Timestep Consumption Time: 2.06090
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.31741

Cumulative Model Updates: 42432
Cumulative Timesteps: 354224794

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.06008
Policy Entropy: 1.10413
Value Function Loss: 0.06146

Mean KL Divergence: 0.03825
SB3 Clip Fraction: 0.21208
Policy Update Magnitude: 0.09737
Value Function Update Magnitude: 0.24159

Collected Steps per Second: 10530.72210
Overall Steps per Second: 7302.80614

Timestep Collection Time: 4.74849
Timestep Consumption Time: 2.09888
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.84737

Cumulative Model Updates: 42438
Cumulative Timesteps: 354274799

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.99797
Policy Entropy: 1.10824
Value Function Loss: 0.06468

Mean KL Divergence: 0.02703
SB3 Clip Fraction: 0.16324
Policy Update Magnitude: 0.11603
Value Function Update Magnitude: 0.24519

Collected Steps per Second: 9846.50987
Overall Steps per Second: 7015.95784

Timestep Collection Time: 5.07957
Timestep Consumption Time: 2.04932
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.12889

Cumulative Model Updates: 42444
Cumulative Timesteps: 354324815

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.55290
Policy Entropy: 1.11084
Value Function Loss: 0.06363

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.12749
Value Function Update Magnitude: 0.24897

Collected Steps per Second: 9393.24076
Overall Steps per Second: 6680.56339

Timestep Collection Time: 5.32330
Timestep Consumption Time: 2.16155
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 7.48485

Cumulative Model Updates: 42450
Cumulative Timesteps: 354374818

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 354374818...
Checkpoint 354374818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.25533
Policy Entropy: 1.10556
Value Function Loss: 0.06291

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.16639
Policy Update Magnitude: 0.12919
Value Function Update Magnitude: 0.24035

Collected Steps per Second: 10607.72718
Overall Steps per Second: 7386.75762

Timestep Collection Time: 4.71373
Timestep Consumption Time: 2.05541
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 6.76914

Cumulative Model Updates: 42456
Cumulative Timesteps: 354424820

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.72801
Policy Entropy: 1.10487
Value Function Loss: 0.05893

Mean KL Divergence: 0.02549
SB3 Clip Fraction: 0.16919
Policy Update Magnitude: 0.11369
Value Function Update Magnitude: 0.22961

Collected Steps per Second: 10189.48254
Overall Steps per Second: 7035.07738

Timestep Collection Time: 4.90889
Timestep Consumption Time: 2.20106
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.10994

Cumulative Model Updates: 42462
Cumulative Timesteps: 354474839

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.18757
Policy Entropy: 1.09024
Value Function Loss: 0.05656

Mean KL Divergence: 0.02792
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.12083
Value Function Update Magnitude: 0.21448

Collected Steps per Second: 9382.55780
Overall Steps per Second: 6768.27969

Timestep Collection Time: 5.33394
Timestep Consumption Time: 2.06026
PPO Batch Consumption Time: 0.02425
Total Iteration Time: 7.39420

Cumulative Model Updates: 42468
Cumulative Timesteps: 354524885

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.90404
Policy Entropy: 1.09265
Value Function Loss: 0.05761

Mean KL Divergence: 0.04408
SB3 Clip Fraction: 0.22940
Policy Update Magnitude: 0.10776
Value Function Update Magnitude: 0.20984

Collected Steps per Second: 9942.82207
Overall Steps per Second: 6994.94240

Timestep Collection Time: 5.02926
Timestep Consumption Time: 2.11948
PPO Batch Consumption Time: 0.02404
Total Iteration Time: 7.14874

Cumulative Model Updates: 42474
Cumulative Timesteps: 354574890

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.63653
Policy Entropy: 1.07646
Value Function Loss: 0.06059

Mean KL Divergence: 0.04248
SB3 Clip Fraction: 0.23287
Policy Update Magnitude: 0.10218
Value Function Update Magnitude: 0.22296

Collected Steps per Second: 9755.92427
Overall Steps per Second: 6787.41204

Timestep Collection Time: 5.12796
Timestep Consumption Time: 2.24274
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.37070

Cumulative Model Updates: 42480
Cumulative Timesteps: 354624918

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.42362
Policy Entropy: 1.08250
Value Function Loss: 0.06211

Mean KL Divergence: 0.04825
SB3 Clip Fraction: 0.24157
Policy Update Magnitude: 0.10743
Value Function Update Magnitude: 0.23482

Collected Steps per Second: 8891.88042
Overall Steps per Second: 6470.76858

Timestep Collection Time: 5.62727
Timestep Consumption Time: 2.10551
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.73278

Cumulative Model Updates: 42486
Cumulative Timesteps: 354674955

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.23066
Policy Entropy: 1.06197
Value Function Loss: 0.06278

Mean KL Divergence: 0.04768
SB3 Clip Fraction: 0.24315
Policy Update Magnitude: 0.10140
Value Function Update Magnitude: 0.22632

Collected Steps per Second: 10489.66788
Overall Steps per Second: 7164.48177

Timestep Collection Time: 4.77069
Timestep Consumption Time: 2.21418
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 6.98487

Cumulative Model Updates: 42492
Cumulative Timesteps: 354724998

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.22537
Policy Entropy: 1.08222
Value Function Loss: 0.06316

Mean KL Divergence: 0.04401
SB3 Clip Fraction: 0.23891
Policy Update Magnitude: 0.10448
Value Function Update Magnitude: 0.22866

Collected Steps per Second: 10319.18300
Overall Steps per Second: 7189.58728

Timestep Collection Time: 4.84806
Timestep Consumption Time: 2.11034
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 6.95840

Cumulative Model Updates: 42498
Cumulative Timesteps: 354775026

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.09490
Policy Entropy: 1.06541
Value Function Loss: 0.06328

Mean KL Divergence: 0.03379
SB3 Clip Fraction: 0.19736
Policy Update Magnitude: 0.10059
Value Function Update Magnitude: 0.22984

Collected Steps per Second: 9515.52714
Overall Steps per Second: 6820.63704

Timestep Collection Time: 5.25604
Timestep Consumption Time: 2.07671
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.33275

Cumulative Model Updates: 42504
Cumulative Timesteps: 354825040

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.29843
Policy Entropy: 1.06447
Value Function Loss: 0.06209

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.16954
Policy Update Magnitude: 0.11430
Value Function Update Magnitude: 0.22193

Collected Steps per Second: 9786.42664
Overall Steps per Second: 6824.46113

Timestep Collection Time: 5.10983
Timestep Consumption Time: 2.21778
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 7.32761

Cumulative Model Updates: 42510
Cumulative Timesteps: 354875047

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 354875047...
Checkpoint 354875047 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.85932
Policy Entropy: 1.06104
Value Function Loss: 0.06210

Mean KL Divergence: 0.03122
SB3 Clip Fraction: 0.19174
Policy Update Magnitude: 0.10458
Value Function Update Magnitude: 0.22385

Collected Steps per Second: 9846.72095
Overall Steps per Second: 6918.28695

Timestep Collection Time: 5.08047
Timestep Consumption Time: 2.15051
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 7.23098

Cumulative Model Updates: 42516
Cumulative Timesteps: 354925073

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.04362
Policy Entropy: 1.06717
Value Function Loss: 0.05874

Mean KL Divergence: 0.03143
SB3 Clip Fraction: 0.18484
Policy Update Magnitude: 0.10014
Value Function Update Magnitude: 0.22568

Collected Steps per Second: 9536.53498
Overall Steps per Second: 6876.33297

Timestep Collection Time: 5.24645
Timestep Consumption Time: 2.02966
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.27612

Cumulative Model Updates: 42522
Cumulative Timesteps: 354975106

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.50317
Policy Entropy: 1.06158
Value Function Loss: 0.05599

Mean KL Divergence: 0.02903
SB3 Clip Fraction: 0.17663
Policy Update Magnitude: 0.11256
Value Function Update Magnitude: 0.21677

Collected Steps per Second: 10375.12817
Overall Steps per Second: 7185.52858

Timestep Collection Time: 4.82230
Timestep Consumption Time: 2.14058
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 6.96288

Cumulative Model Updates: 42528
Cumulative Timesteps: 355025138

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.00541
Policy Entropy: 1.07850
Value Function Loss: 0.05552

Mean KL Divergence: 0.02808
SB3 Clip Fraction: 0.18132
Policy Update Magnitude: 0.11623
Value Function Update Magnitude: 0.20164

Collected Steps per Second: 10243.14848
Overall Steps per Second: 7190.86370

Timestep Collection Time: 4.88561
Timestep Consumption Time: 2.07378
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.95939

Cumulative Model Updates: 42534
Cumulative Timesteps: 355075182

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.52905
Policy Entropy: 1.07978
Value Function Loss: 0.05760

Mean KL Divergence: 0.02579
SB3 Clip Fraction: 0.16360
Policy Update Magnitude: 0.12735
Value Function Update Magnitude: 0.21707

Collected Steps per Second: 9167.09542
Overall Steps per Second: 6545.97788

Timestep Collection Time: 5.45571
Timestep Consumption Time: 2.18456
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.64026

Cumulative Model Updates: 42540
Cumulative Timesteps: 355125195

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.25064
Policy Entropy: 1.07851
Value Function Loss: 0.06021

Mean KL Divergence: 0.02586
SB3 Clip Fraction: 0.16440
Policy Update Magnitude: 0.12781
Value Function Update Magnitude: 0.22573

Collected Steps per Second: 9311.53705
Overall Steps per Second: 6691.63384

Timestep Collection Time: 5.37097
Timestep Consumption Time: 2.10284
PPO Batch Consumption Time: 0.02858
Total Iteration Time: 7.47381

Cumulative Model Updates: 42546
Cumulative Timesteps: 355175207

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.46973
Policy Entropy: 1.06715
Value Function Loss: 0.05893

Mean KL Divergence: 0.03206
SB3 Clip Fraction: 0.18312
Policy Update Magnitude: 0.11858
Value Function Update Magnitude: 0.22401

Collected Steps per Second: 9682.24626
Overall Steps per Second: 6793.86326

Timestep Collection Time: 5.16605
Timestep Consumption Time: 2.19633
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.36238

Cumulative Model Updates: 42552
Cumulative Timesteps: 355225226

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.68018
Policy Entropy: 1.07690
Value Function Loss: 0.06125

Mean KL Divergence: 0.02727
SB3 Clip Fraction: 0.17531
Policy Update Magnitude: 0.12088
Value Function Update Magnitude: 0.22195

Collected Steps per Second: 9564.49165
Overall Steps per Second: 6963.35534

Timestep Collection Time: 5.22945
Timestep Consumption Time: 1.95344
PPO Batch Consumption Time: 0.02485
Total Iteration Time: 7.18289

Cumulative Model Updates: 42558
Cumulative Timesteps: 355275243

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.11809
Policy Entropy: 1.08768
Value Function Loss: 0.06076

Mean KL Divergence: 0.03403
SB3 Clip Fraction: 0.20118
Policy Update Magnitude: 0.12798
Value Function Update Magnitude: 0.22404

Collected Steps per Second: 9777.17039
Overall Steps per Second: 7060.08938

Timestep Collection Time: 5.11426
Timestep Consumption Time: 1.96823
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.08249

Cumulative Model Updates: 42564
Cumulative Timesteps: 355325246

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.36201
Policy Entropy: 1.06844
Value Function Loss: 0.06175

Mean KL Divergence: 0.03771
SB3 Clip Fraction: 0.19757
Policy Update Magnitude: 0.11083
Value Function Update Magnitude: 0.23636

Collected Steps per Second: 10343.77363
Overall Steps per Second: 7283.20431

Timestep Collection Time: 4.83721
Timestep Consumption Time: 2.03271
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 6.86992

Cumulative Model Updates: 42570
Cumulative Timesteps: 355375281

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 355375281...
Checkpoint 355375281 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.51150
Policy Entropy: 1.07097
Value Function Loss: 0.06063

Mean KL Divergence: 0.02836
SB3 Clip Fraction: 0.18080
Policy Update Magnitude: 0.11010
Value Function Update Magnitude: 0.22729

Collected Steps per Second: 9304.09341
Overall Steps per Second: 6722.89429

Timestep Collection Time: 5.37462
Timestep Consumption Time: 2.06354
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.43817

Cumulative Model Updates: 42576
Cumulative Timesteps: 355425287

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.17499
Policy Entropy: 1.06999
Value Function Loss: 0.05954

Mean KL Divergence: 0.03362
SB3 Clip Fraction: 0.19860
Policy Update Magnitude: 0.11059
Value Function Update Magnitude: 0.22407

Collected Steps per Second: 9750.88077
Overall Steps per Second: 6896.23021

Timestep Collection Time: 5.12774
Timestep Consumption Time: 2.12260
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.25034

Cumulative Model Updates: 42582
Cumulative Timesteps: 355475287

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.63126
Policy Entropy: 1.07829
Value Function Loss: 0.06094

Mean KL Divergence: 0.03713
SB3 Clip Fraction: 0.22196
Policy Update Magnitude: 0.10173
Value Function Update Magnitude: 0.21581

Collected Steps per Second: 10425.13186
Overall Steps per Second: 6878.43955

Timestep Collection Time: 4.79821
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.27229

Cumulative Model Updates: 42588
Cumulative Timesteps: 355525309

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.99163
Policy Entropy: 1.06849
Value Function Loss: 0.06160

Mean KL Divergence: 0.02679
SB3 Clip Fraction: 0.18047
Policy Update Magnitude: 0.11076
Value Function Update Magnitude: 0.21799

Collected Steps per Second: 9747.65880
Overall Steps per Second: 6926.32950

Timestep Collection Time: 5.13200
Timestep Consumption Time: 2.09044
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 7.22244

Cumulative Model Updates: 42594
Cumulative Timesteps: 355575334

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.91245
Policy Entropy: 1.06429
Value Function Loss: 0.06305

Mean KL Divergence: 0.03757
SB3 Clip Fraction: 0.21390
Policy Update Magnitude: 0.11025
Value Function Update Magnitude: 0.23099

Collected Steps per Second: 9468.47790
Overall Steps per Second: 6838.66673

Timestep Collection Time: 5.28258
Timestep Consumption Time: 2.03142
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.31400

Cumulative Model Updates: 42600
Cumulative Timesteps: 355625352

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.42233
Policy Entropy: 1.06123
Value Function Loss: 0.06131

Mean KL Divergence: 0.02833
SB3 Clip Fraction: 0.17562
Policy Update Magnitude: 0.10169
Value Function Update Magnitude: 0.23781

Collected Steps per Second: 9598.07245
Overall Steps per Second: 6855.87714

Timestep Collection Time: 5.20959
Timestep Consumption Time: 2.08372
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.29330

Cumulative Model Updates: 42606
Cumulative Timesteps: 355675354

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.62731
Policy Entropy: 1.06352
Value Function Loss: 0.06357

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.16524
Policy Update Magnitude: 0.12159
Value Function Update Magnitude: 0.23973

Collected Steps per Second: 9199.60440
Overall Steps per Second: 6514.63690

Timestep Collection Time: 5.43697
Timestep Consumption Time: 2.24081
PPO Batch Consumption Time: 0.02897
Total Iteration Time: 7.67779

Cumulative Model Updates: 42612
Cumulative Timesteps: 355725372

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.93053
Policy Entropy: 1.05057
Value Function Loss: 0.06761

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.12220
Value Function Update Magnitude: 0.23326

Collected Steps per Second: 9315.45241
Overall Steps per Second: 6745.61692

Timestep Collection Time: 5.36893
Timestep Consumption Time: 2.04537
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.41430

Cumulative Model Updates: 42618
Cumulative Timesteps: 355775386

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.71414
Policy Entropy: 1.04460
Value Function Loss: 0.06744

Mean KL Divergence: 0.03564
SB3 Clip Fraction: 0.21249
Policy Update Magnitude: 0.10832
Value Function Update Magnitude: 0.23032

Collected Steps per Second: 9828.97798
Overall Steps per Second: 7152.55896

Timestep Collection Time: 5.09076
Timestep Consumption Time: 1.90491
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 6.99568

Cumulative Model Updates: 42624
Cumulative Timesteps: 355825423

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.51164
Policy Entropy: 1.04621
Value Function Loss: 0.06389

Mean KL Divergence: 0.03152
SB3 Clip Fraction: 0.20242
Policy Update Magnitude: 0.09684
Value Function Update Magnitude: 0.22250

Collected Steps per Second: 9668.84118
Overall Steps per Second: 6975.72742

Timestep Collection Time: 5.17291
Timestep Consumption Time: 1.99710
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.17000

Cumulative Model Updates: 42630
Cumulative Timesteps: 355875439

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 355875439...
Checkpoint 355875439 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.02392
Policy Entropy: 1.04908
Value Function Loss: 0.05927

Mean KL Divergence: 0.03605
SB3 Clip Fraction: 0.21123
Policy Update Magnitude: 0.08964
Value Function Update Magnitude: 0.21288

Collected Steps per Second: 9586.20395
Overall Steps per Second: 6870.51768

Timestep Collection Time: 5.21812
Timestep Consumption Time: 2.06255
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.28067

Cumulative Model Updates: 42636
Cumulative Timesteps: 355925461

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.03393
Policy Entropy: 1.05511
Value Function Loss: 0.06652

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.18368
Policy Update Magnitude: 0.10526
Value Function Update Magnitude: 0.21053

Collected Steps per Second: 10125.56885
Overall Steps per Second: 7172.56145

Timestep Collection Time: 4.94115
Timestep Consumption Time: 2.03432
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 6.97547

Cumulative Model Updates: 42642
Cumulative Timesteps: 355975493

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.94876
Policy Entropy: 1.05909
Value Function Loss: 0.06485

Mean KL Divergence: 0.03774
SB3 Clip Fraction: 0.22238
Policy Update Magnitude: 0.10316
Value Function Update Magnitude: 0.21872

Collected Steps per Second: 10611.96755
Overall Steps per Second: 7304.53310

Timestep Collection Time: 4.71487
Timestep Consumption Time: 2.13485
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 6.84972

Cumulative Model Updates: 42648
Cumulative Timesteps: 356025527

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.98182
Policy Entropy: 1.05122
Value Function Loss: 0.06565

Mean KL Divergence: 0.03475
SB3 Clip Fraction: 0.20966
Policy Update Magnitude: 0.10499
Value Function Update Magnitude: 0.22470

Collected Steps per Second: 9210.93081
Overall Steps per Second: 6636.81759

Timestep Collection Time: 5.43116
Timestep Consumption Time: 2.10649
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.53765

Cumulative Model Updates: 42654
Cumulative Timesteps: 356075553

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.89761
Policy Entropy: 1.05401
Value Function Loss: 0.06077

Mean KL Divergence: 0.03564
SB3 Clip Fraction: 0.21633
Policy Update Magnitude: 0.10107
Value Function Update Magnitude: 0.21568

Collected Steps per Second: 9359.02416
Overall Steps per Second: 6801.10311

Timestep Collection Time: 5.34372
Timestep Consumption Time: 2.00979
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.35351

Cumulative Model Updates: 42660
Cumulative Timesteps: 356125565

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.59737
Policy Entropy: 1.04696
Value Function Loss: 0.06250

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.18076
Policy Update Magnitude: 0.09278
Value Function Update Magnitude: 0.21844

Collected Steps per Second: 9885.24751
Overall Steps per Second: 6899.09726

Timestep Collection Time: 5.06098
Timestep Consumption Time: 2.19055
PPO Batch Consumption Time: 0.02915
Total Iteration Time: 7.25153

Cumulative Model Updates: 42666
Cumulative Timesteps: 356175594

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.14718
Policy Entropy: 1.04130
Value Function Loss: 0.06308

Mean KL Divergence: 0.02507
SB3 Clip Fraction: 0.16761
Policy Update Magnitude: 0.11098
Value Function Update Magnitude: 0.22241

Collected Steps per Second: 9150.10926
Overall Steps per Second: 6626.51370

Timestep Collection Time: 5.46605
Timestep Consumption Time: 2.08165
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 7.54771

Cumulative Model Updates: 42672
Cumulative Timesteps: 356225609

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.18426
Policy Entropy: 1.04553
Value Function Loss: 0.06397

Mean KL Divergence: 0.03255
SB3 Clip Fraction: 0.20882
Policy Update Magnitude: 0.11113
Value Function Update Magnitude: 0.21987

Collected Steps per Second: 8989.37346
Overall Steps per Second: 6581.17195

Timestep Collection Time: 5.56357
Timestep Consumption Time: 2.03584
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 7.59941

Cumulative Model Updates: 42678
Cumulative Timesteps: 356275622

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.97624
Policy Entropy: 1.03710
Value Function Loss: 0.06468

Mean KL Divergence: 0.04208
SB3 Clip Fraction: 0.23240
Policy Update Magnitude: 0.09689
Value Function Update Magnitude: 0.22767

Collected Steps per Second: 10143.70635
Overall Steps per Second: 7108.00333

Timestep Collection Time: 4.93242
Timestep Consumption Time: 2.10655
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.03897

Cumulative Model Updates: 42684
Cumulative Timesteps: 356325655

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.24785
Policy Entropy: 1.04510
Value Function Loss: 0.06232

Mean KL Divergence: 0.03263
SB3 Clip Fraction: 0.21482
Policy Update Magnitude: 0.08969
Value Function Update Magnitude: 0.23097

Collected Steps per Second: 10015.00142
Overall Steps per Second: 7163.32084

Timestep Collection Time: 4.99571
Timestep Consumption Time: 1.98876
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 6.98447

Cumulative Model Updates: 42690
Cumulative Timesteps: 356375687

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 356375687...
Checkpoint 356375687 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.43700
Policy Entropy: 1.03097
Value Function Loss: 0.06317

Mean KL Divergence: 0.03947
SB3 Clip Fraction: 0.23159
Policy Update Magnitude: 0.09551
Value Function Update Magnitude: 0.22984

Collected Steps per Second: 9837.28965
Overall Steps per Second: 7014.93515

Timestep Collection Time: 5.08443
Timestep Consumption Time: 2.04564
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.13007

Cumulative Model Updates: 42696
Cumulative Timesteps: 356425704

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.08968
Policy Entropy: 1.04660
Value Function Loss: 0.06414

Mean KL Divergence: 0.03095
SB3 Clip Fraction: 0.20070
Policy Update Magnitude: 0.09446
Value Function Update Magnitude: 0.23326

Collected Steps per Second: 9644.14748
Overall Steps per Second: 6756.29141

Timestep Collection Time: 5.18646
Timestep Consumption Time: 2.21686
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.40332

Cumulative Model Updates: 42702
Cumulative Timesteps: 356475723

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.73755
Policy Entropy: 1.03880
Value Function Loss: 0.06768

Mean KL Divergence: 0.02724
SB3 Clip Fraction: 0.18517
Policy Update Magnitude: 0.10433
Value Function Update Magnitude: 0.23110

Collected Steps per Second: 9361.92903
Overall Steps per Second: 6746.96991

Timestep Collection Time: 5.34334
Timestep Consumption Time: 2.07095
PPO Batch Consumption Time: 0.02913
Total Iteration Time: 7.41429

Cumulative Model Updates: 42708
Cumulative Timesteps: 356525747

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.54940
Policy Entropy: 1.04346
Value Function Loss: 0.06542

Mean KL Divergence: 0.02745
SB3 Clip Fraction: 0.17654
Policy Update Magnitude: 0.11409
Value Function Update Magnitude: 0.22659

Collected Steps per Second: 9239.42857
Overall Steps per Second: 6559.61622

Timestep Collection Time: 5.41549
Timestep Consumption Time: 2.21240
PPO Batch Consumption Time: 0.03009
Total Iteration Time: 7.62789

Cumulative Model Updates: 42714
Cumulative Timesteps: 356575783

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.95262
Policy Entropy: 1.02563
Value Function Loss: 0.06457

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.18716
Policy Update Magnitude: 0.11017
Value Function Update Magnitude: 0.22811

Collected Steps per Second: 10014.47387
Overall Steps per Second: 6958.78556

Timestep Collection Time: 4.99627
Timestep Consumption Time: 2.19392
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.19019

Cumulative Model Updates: 42720
Cumulative Timesteps: 356625818

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.30816
Policy Entropy: 1.04310
Value Function Loss: 0.06117

Mean KL Divergence: 0.02701
SB3 Clip Fraction: 0.18502
Policy Update Magnitude: 0.09964
Value Function Update Magnitude: 0.22331

Collected Steps per Second: 9073.37277
Overall Steps per Second: 6564.88007

Timestep Collection Time: 5.51272
Timestep Consumption Time: 2.10646
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 7.61918

Cumulative Model Updates: 42726
Cumulative Timesteps: 356675837

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.21226
Policy Entropy: 1.05225
Value Function Loss: 0.06358

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.19306
Policy Update Magnitude: 0.10691
Value Function Update Magnitude: 0.21915

Collected Steps per Second: 8970.35283
Overall Steps per Second: 6414.73095

Timestep Collection Time: 5.57748
Timestep Consumption Time: 2.22206
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 7.79955

Cumulative Model Updates: 42732
Cumulative Timesteps: 356725869

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.85289
Policy Entropy: 1.05784
Value Function Loss: 0.06072

Mean KL Divergence: 0.02937
SB3 Clip Fraction: 0.19255
Policy Update Magnitude: 0.09400
Value Function Update Magnitude: 0.22120

Collected Steps per Second: 9765.56346
Overall Steps per Second: 6819.38569

Timestep Collection Time: 5.12157
Timestep Consumption Time: 2.21267
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.33424

Cumulative Model Updates: 42738
Cumulative Timesteps: 356775884

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.49352
Policy Entropy: 1.05284
Value Function Loss: 0.06276

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.10768
Value Function Update Magnitude: 0.22759

Collected Steps per Second: 9261.87643
Overall Steps per Second: 6852.04032

Timestep Collection Time: 5.40225
Timestep Consumption Time: 1.89995
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 7.30220

Cumulative Model Updates: 42744
Cumulative Timesteps: 356825919

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.36250
Policy Entropy: 1.04803
Value Function Loss: 0.06043

Mean KL Divergence: 0.02773
SB3 Clip Fraction: 0.17558
Policy Update Magnitude: 0.10916
Value Function Update Magnitude: 0.22435

Collected Steps per Second: 9887.11734
Overall Steps per Second: 7121.04645

Timestep Collection Time: 5.05901
Timestep Consumption Time: 1.96510
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.02411

Cumulative Model Updates: 42750
Cumulative Timesteps: 356875938

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 356875938...
Checkpoint 356875938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.87848
Policy Entropy: 1.04262
Value Function Loss: 0.06342

Mean KL Divergence: 0.02378
SB3 Clip Fraction: 0.16052
Policy Update Magnitude: 0.10236
Value Function Update Magnitude: 0.22307

Collected Steps per Second: 9767.03306
Overall Steps per Second: 6731.16181

Timestep Collection Time: 5.12244
Timestep Consumption Time: 2.31031
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 7.43274

Cumulative Model Updates: 42756
Cumulative Timesteps: 356925969

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.23085
Policy Entropy: 1.04743
Value Function Loss: 0.06350

Mean KL Divergence: 0.02422
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.11262
Value Function Update Magnitude: 0.23507

Collected Steps per Second: 9317.68671
Overall Steps per Second: 6720.42455

Timestep Collection Time: 5.36700
Timestep Consumption Time: 2.07420
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.44120

Cumulative Model Updates: 42762
Cumulative Timesteps: 356975977

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.42408
Policy Entropy: 1.05764
Value Function Loss: 0.06487

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.16538
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.23479

Collected Steps per Second: 9585.91741
Overall Steps per Second: 6984.90741

Timestep Collection Time: 5.21745
Timestep Consumption Time: 1.94285
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.16030

Cumulative Model Updates: 42768
Cumulative Timesteps: 357025991

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.54681
Policy Entropy: 1.06427
Value Function Loss: 0.06445

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.16350
Policy Update Magnitude: 0.11920
Value Function Update Magnitude: 0.23155

Collected Steps per Second: 10324.39811
Overall Steps per Second: 7319.74871

Timestep Collection Time: 4.84542
Timestep Consumption Time: 1.98897
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 6.83439

Cumulative Model Updates: 42774
Cumulative Timesteps: 357076017

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.87006
Policy Entropy: 1.06958
Value Function Loss: 0.06385

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.12279
Value Function Update Magnitude: 0.22983

Collected Steps per Second: 10016.28337
Overall Steps per Second: 7156.59408

Timestep Collection Time: 4.99197
Timestep Consumption Time: 1.99473
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 6.98670

Cumulative Model Updates: 42780
Cumulative Timesteps: 357126018

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.21761
Policy Entropy: 1.07258
Value Function Loss: 0.06507

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.13372
Value Function Update Magnitude: 0.23704

Collected Steps per Second: 9980.69006
Overall Steps per Second: 7207.41629

Timestep Collection Time: 5.01328
Timestep Consumption Time: 1.92901
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 6.94229

Cumulative Model Updates: 42786
Cumulative Timesteps: 357176054

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.70780
Policy Entropy: 1.06991
Value Function Loss: 0.06649

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.13260
Value Function Update Magnitude: 0.24070

Collected Steps per Second: 11043.25668
Overall Steps per Second: 7679.35686

Timestep Collection Time: 4.52937
Timestep Consumption Time: 1.98407
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 6.51344

Cumulative Model Updates: 42792
Cumulative Timesteps: 357226073

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.26828
Policy Entropy: 1.07347
Value Function Loss: 0.06523

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.12931
Value Function Update Magnitude: 0.23525

Collected Steps per Second: 9578.79642
Overall Steps per Second: 6849.56812

Timestep Collection Time: 5.22164
Timestep Consumption Time: 2.08057
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.30221

Cumulative Model Updates: 42798
Cumulative Timesteps: 357276090

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.25828
Policy Entropy: 1.06904
Value Function Loss: 0.06570

Mean KL Divergence: 0.02323
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.11837
Value Function Update Magnitude: 0.22657

Collected Steps per Second: 9316.66217
Overall Steps per Second: 6821.89968

Timestep Collection Time: 5.36705
Timestep Consumption Time: 1.96273
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.32978

Cumulative Model Updates: 42804
Cumulative Timesteps: 357326093

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.55646
Policy Entropy: 1.06762
Value Function Loss: 0.06586

Mean KL Divergence: 0.02329
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.11259
Value Function Update Magnitude: 0.22834

Collected Steps per Second: 10772.11503
Overall Steps per Second: 7352.13335

Timestep Collection Time: 4.64384
Timestep Consumption Time: 2.16017
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.80401

Cumulative Model Updates: 42810
Cumulative Timesteps: 357376117

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 357376117...
Checkpoint 357376117 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.59938
Policy Entropy: 1.08144
Value Function Loss: 0.06507

Mean KL Divergence: 0.03025
SB3 Clip Fraction: 0.19175
Policy Update Magnitude: 0.11187
Value Function Update Magnitude: 0.23179

Collected Steps per Second: 10108.06542
Overall Steps per Second: 6992.91245

Timestep Collection Time: 4.94773
Timestep Consumption Time: 2.20408
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.15181

Cumulative Model Updates: 42816
Cumulative Timesteps: 357426129

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.71034
Policy Entropy: 1.09151
Value Function Loss: 0.06559

Mean KL Divergence: 0.03555
SB3 Clip Fraction: 0.20245
Policy Update Magnitude: 0.12369
Value Function Update Magnitude: 0.23880

Collected Steps per Second: 9125.21075
Overall Steps per Second: 6612.35600

Timestep Collection Time: 5.48119
Timestep Consumption Time: 2.08298
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.56417

Cumulative Model Updates: 42822
Cumulative Timesteps: 357476146

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.30341
Policy Entropy: 1.08504
Value Function Loss: 0.06877

Mean KL Divergence: 0.03578
SB3 Clip Fraction: 0.18481
Policy Update Magnitude: 0.11823
Value Function Update Magnitude: 0.24859

Collected Steps per Second: 9612.24398
Overall Steps per Second: 6699.14483

Timestep Collection Time: 5.20295
Timestep Consumption Time: 2.26248
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 7.46543

Cumulative Model Updates: 42828
Cumulative Timesteps: 357526158

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.02328
Policy Entropy: 1.10895
Value Function Loss: 0.07032

Mean KL Divergence: 0.04425
SB3 Clip Fraction: 0.22790
Policy Update Magnitude: 0.11069
Value Function Update Magnitude: 0.25195

Collected Steps per Second: 8917.87844
Overall Steps per Second: 6400.05357

Timestep Collection Time: 5.60963
Timestep Consumption Time: 2.20687
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.81650

Cumulative Model Updates: 42834
Cumulative Timesteps: 357576184

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.88872
Policy Entropy: 1.09562
Value Function Loss: 0.06779

Mean KL Divergence: 0.03684
SB3 Clip Fraction: 0.19565
Policy Update Magnitude: 0.10702
Value Function Update Magnitude: 0.25360

Collected Steps per Second: 9028.15154
Overall Steps per Second: 6473.20517

Timestep Collection Time: 5.54189
Timestep Consumption Time: 2.18736
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.72925

Cumulative Model Updates: 42840
Cumulative Timesteps: 357626217

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.29029
Policy Entropy: 1.12438
Value Function Loss: 0.06498

Mean KL Divergence: 0.03493
SB3 Clip Fraction: 0.19489
Policy Update Magnitude: 0.11072
Value Function Update Magnitude: 0.24154

Collected Steps per Second: 9416.45020
Overall Steps per Second: 6712.17896

Timestep Collection Time: 5.31357
Timestep Consumption Time: 2.14079
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.45436

Cumulative Model Updates: 42846
Cumulative Timesteps: 357676252

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.96587
Policy Entropy: 1.10559
Value Function Loss: 0.06583

Mean KL Divergence: 0.03414
SB3 Clip Fraction: 0.18609
Policy Update Magnitude: 0.10799
Value Function Update Magnitude: 0.23100

Collected Steps per Second: 9054.56023
Overall Steps per Second: 6598.12405

Timestep Collection Time: 5.52705
Timestep Consumption Time: 2.05768
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 7.58473

Cumulative Model Updates: 42852
Cumulative Timesteps: 357726297

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.78403
Policy Entropy: 1.10379
Value Function Loss: 0.06498

Mean KL Divergence: 0.03508
SB3 Clip Fraction: 0.19724
Policy Update Magnitude: 0.10135
Value Function Update Magnitude: 0.23044

Collected Steps per Second: 9335.22567
Overall Steps per Second: 6648.31361

Timestep Collection Time: 5.36109
Timestep Consumption Time: 2.16668
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.52777

Cumulative Model Updates: 42858
Cumulative Timesteps: 357776344

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.71243
Policy Entropy: 1.10525
Value Function Loss: 0.06280

Mean KL Divergence: 0.03425
SB3 Clip Fraction: 0.20762
Policy Update Magnitude: 0.09426
Value Function Update Magnitude: 0.23127

Collected Steps per Second: 9471.68320
Overall Steps per Second: 6875.72879

Timestep Collection Time: 5.28027
Timestep Consumption Time: 1.99358
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.27385

Cumulative Model Updates: 42864
Cumulative Timesteps: 357826357

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.12933
Policy Entropy: 1.10435
Value Function Loss: 0.05965

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.11224
Value Function Update Magnitude: 0.23611

Collected Steps per Second: 9847.15989
Overall Steps per Second: 7019.83883

Timestep Collection Time: 5.07954
Timestep Consumption Time: 2.04584
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.12538

Cumulative Model Updates: 42870
Cumulative Timesteps: 357876376

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 357876376...
Checkpoint 357876376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.44975
Policy Entropy: 1.12326
Value Function Loss: 0.06072

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.11203
Value Function Update Magnitude: 0.23552

Collected Steps per Second: 9609.37180
Overall Steps per Second: 6875.96682

Timestep Collection Time: 5.20388
Timestep Consumption Time: 2.06870
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.27258

Cumulative Model Updates: 42876
Cumulative Timesteps: 357926382

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.82845
Policy Entropy: 1.10900
Value Function Loss: 0.06352

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.12886
Value Function Update Magnitude: 0.24223

Collected Steps per Second: 9747.27023
Overall Steps per Second: 6907.44303

Timestep Collection Time: 5.13416
Timestep Consumption Time: 2.11078
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.24494

Cumulative Model Updates: 42882
Cumulative Timesteps: 357976426

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.94585
Policy Entropy: 1.10039
Value Function Loss: 0.06527

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.13418
Value Function Update Magnitude: 0.25036

Collected Steps per Second: 10531.71165
Overall Steps per Second: 7308.36644

Timestep Collection Time: 4.74899
Timestep Consumption Time: 2.09454
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 6.84353

Cumulative Model Updates: 42888
Cumulative Timesteps: 358026441

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.60359
Policy Entropy: 1.09147
Value Function Loss: 0.06547

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.14247
Value Function Update Magnitude: 0.24572

Collected Steps per Second: 10379.68061
Overall Steps per Second: 7392.01064

Timestep Collection Time: 4.81759
Timestep Consumption Time: 1.94715
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 6.76474

Cumulative Model Updates: 42894
Cumulative Timesteps: 358076446

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.58823
Policy Entropy: 1.08649
Value Function Loss: 0.06502

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.15046
Policy Update Magnitude: 0.12030
Value Function Update Magnitude: 0.23927

Collected Steps per Second: 10485.63466
Overall Steps per Second: 7437.20526

Timestep Collection Time: 4.77053
Timestep Consumption Time: 1.95539
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 6.72591

Cumulative Model Updates: 42900
Cumulative Timesteps: 358126468

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.90680
Policy Entropy: 1.08753
Value Function Loss: 0.06524

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.12036
Value Function Update Magnitude: 0.23853

Collected Steps per Second: 9963.55519
Overall Steps per Second: 7246.47551

Timestep Collection Time: 5.02180
Timestep Consumption Time: 1.88293
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.90474

Cumulative Model Updates: 42906
Cumulative Timesteps: 358176503

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.65117
Policy Entropy: 1.09071
Value Function Loss: 0.06496

Mean KL Divergence: 0.02150
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.12384
Value Function Update Magnitude: 0.24684

Collected Steps per Second: 9466.78581
Overall Steps per Second: 6754.33060

Timestep Collection Time: 5.28585
Timestep Consumption Time: 2.12273
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.40858

Cumulative Model Updates: 42912
Cumulative Timesteps: 358226543

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.46665
Policy Entropy: 1.08650
Value Function Loss: 0.06264

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.12157
Value Function Update Magnitude: 0.24183

Collected Steps per Second: 9542.35410
Overall Steps per Second: 6886.83775

Timestep Collection Time: 5.24420
Timestep Consumption Time: 2.02213
PPO Batch Consumption Time: 0.02417
Total Iteration Time: 7.26632

Cumulative Model Updates: 42918
Cumulative Timesteps: 358276585

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.35599
Policy Entropy: 1.07912
Value Function Loss: 0.06159

Mean KL Divergence: 0.03707
SB3 Clip Fraction: 0.19691
Policy Update Magnitude: 0.12203
Value Function Update Magnitude: 0.24087

Collected Steps per Second: 9775.19939
Overall Steps per Second: 6985.62100

Timestep Collection Time: 5.11816
Timestep Consumption Time: 2.04384
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.16200

Cumulative Model Updates: 42924
Cumulative Timesteps: 358326616

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.04515
Policy Entropy: 1.09304
Value Function Loss: 0.06093

Mean KL Divergence: 0.06782
SB3 Clip Fraction: 0.27531
Policy Update Magnitude: 0.16169
Value Function Update Magnitude: 0.23766

Collected Steps per Second: 9581.74902
Overall Steps per Second: 6922.94364

Timestep Collection Time: 5.22212
Timestep Consumption Time: 2.00559
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.22771

Cumulative Model Updates: 42930
Cumulative Timesteps: 358376653

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 358376653...
Checkpoint 358376653 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.75952
Policy Entropy: 1.09175
Value Function Loss: 0.06394

Mean KL Divergence: 0.05642
SB3 Clip Fraction: 0.23025
Policy Update Magnitude: 0.13910
Value Function Update Magnitude: 0.24019

Collected Steps per Second: 9609.88661
Overall Steps per Second: 6744.84181

Timestep Collection Time: 5.20724
Timestep Consumption Time: 2.21191
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.41915

Cumulative Model Updates: 42936
Cumulative Timesteps: 358426694

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.81603
Policy Entropy: 1.08716
Value Function Loss: 0.06416

Mean KL Divergence: 0.03717
SB3 Clip Fraction: 0.18070
Policy Update Magnitude: 0.13161
Value Function Update Magnitude: 0.24960

Collected Steps per Second: 9604.25330
Overall Steps per Second: 6934.92982

Timestep Collection Time: 5.21019
Timestep Consumption Time: 2.00545
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.21565

Cumulative Model Updates: 42942
Cumulative Timesteps: 358476734

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.44892
Policy Entropy: 1.09162
Value Function Loss: 0.06690

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.15269
Policy Update Magnitude: 0.13068
Value Function Update Magnitude: 0.25408

Collected Steps per Second: 9753.34235
Overall Steps per Second: 7024.26746

Timestep Collection Time: 5.13004
Timestep Consumption Time: 1.99313
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.12316

Cumulative Model Updates: 42948
Cumulative Timesteps: 358526769

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.11007
Policy Entropy: 1.08956
Value Function Loss: 0.06317

Mean KL Divergence: 0.03046
SB3 Clip Fraction: 0.17574
Policy Update Magnitude: 0.13295
Value Function Update Magnitude: 0.25128

Collected Steps per Second: 9710.59549
Overall Steps per Second: 6766.05404

Timestep Collection Time: 5.14943
Timestep Consumption Time: 2.24100
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.39042

Cumulative Model Updates: 42954
Cumulative Timesteps: 358576773

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.88293
Policy Entropy: 1.10500
Value Function Loss: 0.06092

Mean KL Divergence: 0.03639
SB3 Clip Fraction: 0.19704
Policy Update Magnitude: 0.11125
Value Function Update Magnitude: 0.24431

Collected Steps per Second: 8934.93124
Overall Steps per Second: 6566.11761

Timestep Collection Time: 5.59691
Timestep Consumption Time: 2.01916
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 7.61607

Cumulative Model Updates: 42960
Cumulative Timesteps: 358626781

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.40681
Policy Entropy: 1.10179
Value Function Loss: 0.06172

Mean KL Divergence: 0.03241
SB3 Clip Fraction: 0.18691
Policy Update Magnitude: 0.10272
Value Function Update Magnitude: 0.23257

Collected Steps per Second: 9977.09335
Overall Steps per Second: 7179.22512

Timestep Collection Time: 5.01248
Timestep Consumption Time: 1.95345
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 6.96593

Cumulative Model Updates: 42966
Cumulative Timesteps: 358676791

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.05561
Policy Entropy: 1.09943
Value Function Loss: 0.06164

Mean KL Divergence: 0.04469
SB3 Clip Fraction: 0.21463
Policy Update Magnitude: 0.10514
Value Function Update Magnitude: 0.23654

Collected Steps per Second: 9765.73427
Overall Steps per Second: 6755.59440

Timestep Collection Time: 5.12476
Timestep Consumption Time: 2.28347
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 7.40823

Cumulative Model Updates: 42972
Cumulative Timesteps: 358726838

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.80352
Policy Entropy: 1.09954
Value Function Loss: 0.06381

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.16767
Policy Update Magnitude: 0.09684
Value Function Update Magnitude: 0.23939

Collected Steps per Second: 9159.38833
Overall Steps per Second: 6553.16083

Timestep Collection Time: 5.46281
Timestep Consumption Time: 2.17259
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.63540

Cumulative Model Updates: 42978
Cumulative Timesteps: 358776874

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.77231
Policy Entropy: 1.10224
Value Function Loss: 0.06212

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.11193
Value Function Update Magnitude: 0.24142

Collected Steps per Second: 9557.95929
Overall Steps per Second: 6961.25055

Timestep Collection Time: 5.23281
Timestep Consumption Time: 1.95196
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.18477

Cumulative Model Updates: 42984
Cumulative Timesteps: 358826889

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.87181
Policy Entropy: 1.09535
Value Function Loss: 0.06233

Mean KL Divergence: 0.02645
SB3 Clip Fraction: 0.16616
Policy Update Magnitude: 0.10169
Value Function Update Magnitude: 0.25370

Collected Steps per Second: 10609.04180
Overall Steps per Second: 7367.72024

Timestep Collection Time: 4.71673
Timestep Consumption Time: 2.07506
PPO Batch Consumption Time: 0.02418
Total Iteration Time: 6.79179

Cumulative Model Updates: 42990
Cumulative Timesteps: 358876929

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 358876929...
Checkpoint 358876929 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.55254
Policy Entropy: 1.09999
Value Function Loss: 0.06096

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.10402
Value Function Update Magnitude: 0.24611

Collected Steps per Second: 9495.95983
Overall Steps per Second: 6855.74874

Timestep Collection Time: 5.26698
Timestep Consumption Time: 2.02836
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.29534

Cumulative Model Updates: 42996
Cumulative Timesteps: 358926944

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.39372
Policy Entropy: 1.09287
Value Function Loss: 0.06234

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.15379
Policy Update Magnitude: 0.12083
Value Function Update Magnitude: 0.23684

Collected Steps per Second: 9904.92863
Overall Steps per Second: 7065.12339

Timestep Collection Time: 5.05203
Timestep Consumption Time: 2.03065
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.08268

Cumulative Model Updates: 43002
Cumulative Timesteps: 358976984

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.20494
Policy Entropy: 1.09886
Value Function Loss: 0.06366

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.11879
Value Function Update Magnitude: 0.23818

Collected Steps per Second: 10325.54643
Overall Steps per Second: 7173.49275

Timestep Collection Time: 4.84507
Timestep Consumption Time: 2.12894
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 6.97401

Cumulative Model Updates: 43008
Cumulative Timesteps: 359027012

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.45349
Policy Entropy: 1.09860
Value Function Loss: 0.06689

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.12211
Value Function Update Magnitude: 0.24166

Collected Steps per Second: 9313.46718
Overall Steps per Second: 6600.15581

Timestep Collection Time: 5.36943
Timestep Consumption Time: 2.20736
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 7.57679

Cumulative Model Updates: 43014
Cumulative Timesteps: 359077020

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.02129
Policy Entropy: 1.09602
Value Function Loss: 0.06742

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.11894
Value Function Update Magnitude: 0.23823

Collected Steps per Second: 9765.79859
Overall Steps per Second: 6849.19063

Timestep Collection Time: 5.12155
Timestep Consumption Time: 2.18092
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.30247

Cumulative Model Updates: 43020
Cumulative Timesteps: 359127036

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.45808
Policy Entropy: 1.08973
Value Function Loss: 0.06518

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.15377
Policy Update Magnitude: 0.11256
Value Function Update Magnitude: 0.22463

Collected Steps per Second: 10261.57485
Overall Steps per Second: 7230.18974

Timestep Collection Time: 4.87498
Timestep Consumption Time: 2.04392
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 6.91891

Cumulative Model Updates: 43026
Cumulative Timesteps: 359177061

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.18203
Policy Entropy: 1.07653
Value Function Loss: 0.06234

Mean KL Divergence: 0.03570
SB3 Clip Fraction: 0.18976
Policy Update Magnitude: 0.11476
Value Function Update Magnitude: 0.21629

Collected Steps per Second: 10012.64000
Overall Steps per Second: 7209.97321

Timestep Collection Time: 4.99638
Timestep Consumption Time: 1.94220
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 6.93858

Cumulative Model Updates: 43032
Cumulative Timesteps: 359227088

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.96440
Policy Entropy: 1.09837
Value Function Loss: 0.05977

Mean KL Divergence: 0.03190
SB3 Clip Fraction: 0.19208
Policy Update Magnitude: 0.10145
Value Function Update Magnitude: 0.21351

Collected Steps per Second: 9523.66685
Overall Steps per Second: 6701.72061

Timestep Collection Time: 5.25449
Timestep Consumption Time: 2.21255
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 7.46704

Cumulative Model Updates: 43038
Cumulative Timesteps: 359277130

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.31929
Policy Entropy: 1.09240
Value Function Loss: 0.05851

Mean KL Divergence: 0.03005
SB3 Clip Fraction: 0.18348
Policy Update Magnitude: 0.10709
Value Function Update Magnitude: 0.21478

Collected Steps per Second: 9436.68671
Overall Steps per Second: 6565.40549

Timestep Collection Time: 5.29942
Timestep Consumption Time: 2.31762
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 7.61705

Cumulative Model Updates: 43044
Cumulative Timesteps: 359327139

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.52315
Policy Entropy: 1.10377
Value Function Loss: 0.05631

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.11556
Value Function Update Magnitude: 0.21192

Collected Steps per Second: 9327.21718
Overall Steps per Second: 6762.77233

Timestep Collection Time: 5.36376
Timestep Consumption Time: 2.03394
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 7.39771

Cumulative Model Updates: 43050
Cumulative Timesteps: 359377168

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 359377168...
Checkpoint 359377168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.89889
Policy Entropy: 1.08975
Value Function Loss: 0.05933

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.16155
Policy Update Magnitude: 0.11817
Value Function Update Magnitude: 0.21976

Collected Steps per Second: 9453.50956
Overall Steps per Second: 6720.68815

Timestep Collection Time: 5.29042
Timestep Consumption Time: 2.15123
PPO Batch Consumption Time: 0.02924
Total Iteration Time: 7.44165

Cumulative Model Updates: 43056
Cumulative Timesteps: 359427181

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.84755
Policy Entropy: 1.10260
Value Function Loss: 0.06085

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.11940
Value Function Update Magnitude: 0.24846

Collected Steps per Second: 9449.37166
Overall Steps per Second: 6508.78304

Timestep Collection Time: 5.29506
Timestep Consumption Time: 2.39224
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.68730

Cumulative Model Updates: 43062
Cumulative Timesteps: 359477216

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.13204
Policy Entropy: 1.09489
Value Function Loss: 0.06408

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.11667
Value Function Update Magnitude: 0.24927

Collected Steps per Second: 9691.21879
Overall Steps per Second: 6819.55297

Timestep Collection Time: 5.16261
Timestep Consumption Time: 2.17394
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.33655

Cumulative Model Updates: 43068
Cumulative Timesteps: 359527248

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.75392
Policy Entropy: 1.10294
Value Function Loss: 0.06044

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.11597
Value Function Update Magnitude: 0.25168

Collected Steps per Second: 9540.95173
Overall Steps per Second: 6730.59689

Timestep Collection Time: 5.24109
Timestep Consumption Time: 2.18841
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 7.42950

Cumulative Model Updates: 43074
Cumulative Timesteps: 359577253

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.16656
Policy Entropy: 1.09875
Value Function Loss: 0.06228

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.10602
Value Function Update Magnitude: 0.24663

Collected Steps per Second: 9296.41313
Overall Steps per Second: 6472.73087

Timestep Collection Time: 5.38304
Timestep Consumption Time: 2.34831
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.73136

Cumulative Model Updates: 43080
Cumulative Timesteps: 359627296

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.92429
Policy Entropy: 1.10965
Value Function Loss: 0.06247

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.09989
Value Function Update Magnitude: 0.22648

Collected Steps per Second: 9513.70560
Overall Steps per Second: 6757.39185

Timestep Collection Time: 5.25968
Timestep Consumption Time: 2.14540
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.40508

Cumulative Model Updates: 43086
Cumulative Timesteps: 359677335

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.01550
Policy Entropy: 1.13135
Value Function Loss: 0.06366

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.10126
Value Function Update Magnitude: 0.22816

Collected Steps per Second: 9912.64298
Overall Steps per Second: 6975.50941

Timestep Collection Time: 5.04558
Timestep Consumption Time: 2.12451
PPO Batch Consumption Time: 0.03022
Total Iteration Time: 7.17009

Cumulative Model Updates: 43092
Cumulative Timesteps: 359727350

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.42048
Policy Entropy: 1.14016
Value Function Loss: 0.06167

Mean KL Divergence: 0.02985
SB3 Clip Fraction: 0.17261
Policy Update Magnitude: 0.10640
Value Function Update Magnitude: 0.21809

Collected Steps per Second: 9489.24633
Overall Steps per Second: 6634.05507

Timestep Collection Time: 5.27271
Timestep Consumption Time: 2.26929
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.54199

Cumulative Model Updates: 43098
Cumulative Timesteps: 359777384

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.38296
Policy Entropy: 1.13972
Value Function Loss: 0.06123

Mean KL Divergence: 0.03354
SB3 Clip Fraction: 0.18350
Policy Update Magnitude: 0.09808
Value Function Update Magnitude: 0.21103

Collected Steps per Second: 9973.55305
Overall Steps per Second: 7013.70073

Timestep Collection Time: 5.01697
Timestep Consumption Time: 2.11721
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.13418

Cumulative Model Updates: 43104
Cumulative Timesteps: 359827421

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.04918
Policy Entropy: 1.12109
Value Function Loss: 0.06114

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.17655
Policy Update Magnitude: 0.10055
Value Function Update Magnitude: 0.20578

Collected Steps per Second: 10547.73288
Overall Steps per Second: 7374.87698

Timestep Collection Time: 4.74263
Timestep Consumption Time: 2.04040
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 6.78303

Cumulative Model Updates: 43110
Cumulative Timesteps: 359877445

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 359877445...
Checkpoint 359877445 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.13249
Policy Entropy: 1.12180
Value Function Loss: 0.06129

Mean KL Divergence: 0.03634
SB3 Clip Fraction: 0.19460
Policy Update Magnitude: 0.09270
Value Function Update Magnitude: 0.20736

Collected Steps per Second: 10465.25918
Overall Steps per Second: 7349.49033

Timestep Collection Time: 4.77809
Timestep Consumption Time: 2.02564
PPO Batch Consumption Time: 0.02957
Total Iteration Time: 6.80374

Cumulative Model Updates: 43116
Cumulative Timesteps: 359927449

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.18626
Policy Entropy: 1.11918
Value Function Loss: 0.05995

Mean KL Divergence: 0.02736
SB3 Clip Fraction: 0.17002
Policy Update Magnitude: 0.09701
Value Function Update Magnitude: 0.20808

Collected Steps per Second: 9934.02521
Overall Steps per Second: 7167.89881

Timestep Collection Time: 5.03462
Timestep Consumption Time: 1.94288
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 6.97750

Cumulative Model Updates: 43122
Cumulative Timesteps: 359977463

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.30758
Policy Entropy: 1.12139
Value Function Loss: 0.06005

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.15953
Policy Update Magnitude: 0.09625
Value Function Update Magnitude: 0.20910

Collected Steps per Second: 9658.08614
Overall Steps per Second: 6806.38331

Timestep Collection Time: 5.17825
Timestep Consumption Time: 2.16956
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.34781

Cumulative Model Updates: 43128
Cumulative Timesteps: 360027475

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.99399
Policy Entropy: 1.12356
Value Function Loss: 0.05948

Mean KL Divergence: 0.02094
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.09712
Value Function Update Magnitude: 0.20826

Collected Steps per Second: 9727.27395
Overall Steps per Second: 6849.61544

Timestep Collection Time: 5.14224
Timestep Consumption Time: 2.16036
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.30260

Cumulative Model Updates: 43134
Cumulative Timesteps: 360077495

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.32689
Policy Entropy: 1.13163
Value Function Loss: 0.05916

Mean KL Divergence: 0.02798
SB3 Clip Fraction: 0.16344
Policy Update Magnitude: 0.11402
Value Function Update Magnitude: 0.20523

Collected Steps per Second: 9811.08959
Overall Steps per Second: 7013.27500

Timestep Collection Time: 5.09790
Timestep Consumption Time: 2.03371
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.13162

Cumulative Model Updates: 43140
Cumulative Timesteps: 360127511

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.25792
Policy Entropy: 1.13000
Value Function Loss: 0.05624

Mean KL Divergence: 0.04725
SB3 Clip Fraction: 0.20270
Policy Update Magnitude: 0.09934
Value Function Update Magnitude: 0.20246

Collected Steps per Second: 9825.54195
Overall Steps per Second: 6984.29241

Timestep Collection Time: 5.09275
Timestep Consumption Time: 2.07176
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.16451

Cumulative Model Updates: 43146
Cumulative Timesteps: 360177550

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.65739
Policy Entropy: 1.11534
Value Function Loss: 0.05728

Mean KL Divergence: 0.04177
SB3 Clip Fraction: 0.19558
Policy Update Magnitude: 0.09130
Value Function Update Magnitude: 0.20114

Collected Steps per Second: 9773.55561
Overall Steps per Second: 6855.24515

Timestep Collection Time: 5.11922
Timestep Consumption Time: 2.17928
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.29850

Cumulative Model Updates: 43152
Cumulative Timesteps: 360227583

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.14317
Policy Entropy: 1.11011
Value Function Loss: 0.05641

Mean KL Divergence: 0.03560
SB3 Clip Fraction: 0.18627
Policy Update Magnitude: 0.09379
Value Function Update Magnitude: 0.19461

Collected Steps per Second: 9482.71785
Overall Steps per Second: 6752.41875

Timestep Collection Time: 5.27507
Timestep Consumption Time: 2.13294
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.40801

Cumulative Model Updates: 43158
Cumulative Timesteps: 360277605

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.71583
Policy Entropy: 1.10822
Value Function Loss: 0.05925

Mean KL Divergence: 0.03144
SB3 Clip Fraction: 0.17665
Policy Update Magnitude: 0.08706
Value Function Update Magnitude: 0.20058

Collected Steps per Second: 9199.08610
Overall Steps per Second: 6613.64717

Timestep Collection Time: 5.43641
Timestep Consumption Time: 2.12523
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.56164

Cumulative Model Updates: 43164
Cumulative Timesteps: 360327615

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.95655
Policy Entropy: 1.11525
Value Function Loss: 0.05935

Mean KL Divergence: 0.02621
SB3 Clip Fraction: 0.16302
Policy Update Magnitude: 0.09438
Value Function Update Magnitude: 0.20353

Collected Steps per Second: 9666.69813
Overall Steps per Second: 6806.51688

Timestep Collection Time: 5.17529
Timestep Consumption Time: 2.17472
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.35001

Cumulative Model Updates: 43170
Cumulative Timesteps: 360377643

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 360377643...
Checkpoint 360377643 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.23360
Policy Entropy: 1.12458
Value Function Loss: 0.06075

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.09577
Value Function Update Magnitude: 0.21077

Collected Steps per Second: 9823.91704
Overall Steps per Second: 7030.57695

Timestep Collection Time: 5.09064
Timestep Consumption Time: 2.02258
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.11321

Cumulative Model Updates: 43176
Cumulative Timesteps: 360427653

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.71942
Policy Entropy: 1.12733
Value Function Loss: 0.05944

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.10536
Value Function Update Magnitude: 0.20893

Collected Steps per Second: 9057.19215
Overall Steps per Second: 6537.95838

Timestep Collection Time: 5.52357
Timestep Consumption Time: 2.12836
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.65193

Cumulative Model Updates: 43182
Cumulative Timesteps: 360477681

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.82134
Policy Entropy: 1.13492
Value Function Loss: 0.06118

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.14788
Policy Update Magnitude: 0.10826
Value Function Update Magnitude: 0.20947

Collected Steps per Second: 9895.63940
Overall Steps per Second: 7055.55202

Timestep Collection Time: 5.05728
Timestep Consumption Time: 2.03572
PPO Batch Consumption Time: 0.02402
Total Iteration Time: 7.09300

Cumulative Model Updates: 43188
Cumulative Timesteps: 360527726

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.63749
Policy Entropy: 1.13460
Value Function Loss: 0.06017

Mean KL Divergence: 0.02122
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.11689
Value Function Update Magnitude: 0.21332

Collected Steps per Second: 9859.18125
Overall Steps per Second: 7076.68866

Timestep Collection Time: 5.07142
Timestep Consumption Time: 1.99404
PPO Batch Consumption Time: 0.02431
Total Iteration Time: 7.06545

Cumulative Model Updates: 43194
Cumulative Timesteps: 360577726

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.85159
Policy Entropy: 1.13626
Value Function Loss: 0.05944

Mean KL Divergence: 0.03266
SB3 Clip Fraction: 0.18509
Policy Update Magnitude: 0.10475
Value Function Update Magnitude: 0.21837

Collected Steps per Second: 9375.50538
Overall Steps per Second: 6880.12844

Timestep Collection Time: 5.33603
Timestep Consumption Time: 1.93534
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.27138

Cumulative Model Updates: 43200
Cumulative Timesteps: 360627754

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.01733
Policy Entropy: 1.13264
Value Function Loss: 0.06067

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.10598
Value Function Update Magnitude: 0.20418

Collected Steps per Second: 10334.90675
Overall Steps per Second: 7205.10477

Timestep Collection Time: 4.83846
Timestep Consumption Time: 2.10176
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 6.94022

Cumulative Model Updates: 43206
Cumulative Timesteps: 360677759

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.80260
Policy Entropy: 1.12621
Value Function Loss: 0.06260

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.12046
Value Function Update Magnitude: 0.20518

Collected Steps per Second: 9446.31723
Overall Steps per Second: 6748.44328

Timestep Collection Time: 5.29349
Timestep Consumption Time: 2.11622
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.40971

Cumulative Model Updates: 43212
Cumulative Timesteps: 360727763

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.37190
Policy Entropy: 1.12313
Value Function Loss: 0.06272

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.20899

Collected Steps per Second: 9454.25301
Overall Steps per Second: 6914.29925

Timestep Collection Time: 5.29148
Timestep Consumption Time: 1.94381
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.23530

Cumulative Model Updates: 43218
Cumulative Timesteps: 360777790

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.19946
Policy Entropy: 1.13911
Value Function Loss: 0.06271

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.16568
Policy Update Magnitude: 0.11327
Value Function Update Magnitude: 0.21486

Collected Steps per Second: 10331.12804
Overall Steps per Second: 7327.07623

Timestep Collection Time: 4.84294
Timestep Consumption Time: 1.98557
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 6.82851

Cumulative Model Updates: 43224
Cumulative Timesteps: 360827823

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.49229
Policy Entropy: 1.13988
Value Function Loss: 0.06297

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.11563
Value Function Update Magnitude: 0.22003

Collected Steps per Second: 10175.45416
Overall Steps per Second: 7187.73553

Timestep Collection Time: 4.91644
Timestep Consumption Time: 2.04361
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 6.96005

Cumulative Model Updates: 43230
Cumulative Timesteps: 360877850

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 360877850...
Checkpoint 360877850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.49030
Policy Entropy: 1.13997
Value Function Loss: 0.06539

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.12188
Value Function Update Magnitude: 0.22999

Collected Steps per Second: 10249.03751
Overall Steps per Second: 7316.46517

Timestep Collection Time: 4.88095
Timestep Consumption Time: 1.95637
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 6.83732

Cumulative Model Updates: 43236
Cumulative Timesteps: 360927875

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.56697
Policy Entropy: 1.12761
Value Function Loss: 0.06360

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.12252
Value Function Update Magnitude: 0.23946

Collected Steps per Second: 10742.16390
Overall Steps per Second: 7526.35394

Timestep Collection Time: 4.65521
Timestep Consumption Time: 1.98905
PPO Batch Consumption Time: 0.02867
Total Iteration Time: 6.64425

Cumulative Model Updates: 43242
Cumulative Timesteps: 360977882

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.37119
Policy Entropy: 1.12420
Value Function Loss: 0.06322

Mean KL Divergence: 0.02758
SB3 Clip Fraction: 0.16428
Policy Update Magnitude: 0.11293
Value Function Update Magnitude: 0.24199

Collected Steps per Second: 9453.93829
Overall Steps per Second: 6721.27323

Timestep Collection Time: 5.29102
Timestep Consumption Time: 2.15117
PPO Batch Consumption Time: 0.02429
Total Iteration Time: 7.44219

Cumulative Model Updates: 43248
Cumulative Timesteps: 361027903

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.94162
Policy Entropy: 1.11508
Value Function Loss: 0.06087

Mean KL Divergence: 0.02904
SB3 Clip Fraction: 0.17158
Policy Update Magnitude: 0.09674
Value Function Update Magnitude: 0.24017

Collected Steps per Second: 9445.77349
Overall Steps per Second: 6711.93119

Timestep Collection Time: 5.29782
Timestep Consumption Time: 2.15786
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.45568

Cumulative Model Updates: 43254
Cumulative Timesteps: 361077945

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.59126
Policy Entropy: 1.11412
Value Function Loss: 0.06332

Mean KL Divergence: 0.03008
SB3 Clip Fraction: 0.17780
Policy Update Magnitude: 0.08696
Value Function Update Magnitude: 0.23280

Collected Steps per Second: 9915.40160
Overall Steps per Second: 7055.92046

Timestep Collection Time: 5.04669
Timestep Consumption Time: 2.04522
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.09192

Cumulative Model Updates: 43260
Cumulative Timesteps: 361127985

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.29167
Policy Entropy: 1.11521
Value Function Loss: 0.06303

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.15683
Policy Update Magnitude: 0.09131
Value Function Update Magnitude: 0.23738

Collected Steps per Second: 9703.78365
Overall Steps per Second: 6676.69731

Timestep Collection Time: 5.15562
Timestep Consumption Time: 2.33746
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.49308

Cumulative Model Updates: 43266
Cumulative Timesteps: 361178014

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.80246
Policy Entropy: 1.11252
Value Function Loss: 0.06500

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.15590
Policy Update Magnitude: 0.08972
Value Function Update Magnitude: 0.23731

Collected Steps per Second: 9330.59989
Overall Steps per Second: 6673.07960

Timestep Collection Time: 5.36139
Timestep Consumption Time: 2.13515
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.49654

Cumulative Model Updates: 43272
Cumulative Timesteps: 361228039

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.54728
Policy Entropy: 1.11757
Value Function Loss: 0.06267

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.09351
Value Function Update Magnitude: 0.23603

Collected Steps per Second: 9538.18654
Overall Steps per Second: 6859.57493

Timestep Collection Time: 5.24544
Timestep Consumption Time: 2.04830
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.29375

Cumulative Model Updates: 43278
Cumulative Timesteps: 361278071

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.75303
Policy Entropy: 1.11774
Value Function Loss: 0.06210

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.14892
Policy Update Magnitude: 0.09241
Value Function Update Magnitude: 0.22991

Collected Steps per Second: 9211.80481
Overall Steps per Second: 6711.48394

Timestep Collection Time: 5.42945
Timestep Consumption Time: 2.02271
PPO Batch Consumption Time: 0.02491
Total Iteration Time: 7.45215

Cumulative Model Updates: 43284
Cumulative Timesteps: 361328086

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.26188
Policy Entropy: 1.10979
Value Function Loss: 0.06194

Mean KL Divergence: 0.02945
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.10259
Value Function Update Magnitude: 0.22031

Collected Steps per Second: 9812.00325
Overall Steps per Second: 6903.40737

Timestep Collection Time: 5.09723
Timestep Consumption Time: 2.14760
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.24483

Cumulative Model Updates: 43290
Cumulative Timesteps: 361378100

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 361378100...
Checkpoint 361378100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.82288
Policy Entropy: 1.09109
Value Function Loss: 0.05951

Mean KL Divergence: 0.02338
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.09450
Value Function Update Magnitude: 0.22213

Collected Steps per Second: 10465.76432
Overall Steps per Second: 7337.26181

Timestep Collection Time: 4.77758
Timestep Consumption Time: 2.03709
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 6.81467

Cumulative Model Updates: 43296
Cumulative Timesteps: 361428101

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.71002
Policy Entropy: 1.09873
Value Function Loss: 0.06121

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.09115
Value Function Update Magnitude: 0.22810

Collected Steps per Second: 9746.17407
Overall Steps per Second: 6678.78681

Timestep Collection Time: 5.13299
Timestep Consumption Time: 2.35744
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 7.49043

Cumulative Model Updates: 43302
Cumulative Timesteps: 361478128

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.47165
Policy Entropy: 1.09863
Value Function Loss: 0.06065

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.10017
Value Function Update Magnitude: 0.23490

Collected Steps per Second: 9458.67137
Overall Steps per Second: 6598.88049

Timestep Collection Time: 5.28742
Timestep Consumption Time: 2.29144
PPO Batch Consumption Time: 0.02976
Total Iteration Time: 7.57886

Cumulative Model Updates: 43308
Cumulative Timesteps: 361528140

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.50277
Policy Entropy: 1.09736
Value Function Loss: 0.06165

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.11050
Value Function Update Magnitude: 0.23764

Collected Steps per Second: 9573.12309
Overall Steps per Second: 6963.07920

Timestep Collection Time: 5.22463
Timestep Consumption Time: 1.95840
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.18303

Cumulative Model Updates: 43314
Cumulative Timesteps: 361578156

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.04758
Policy Entropy: 1.08640
Value Function Loss: 0.06388

Mean KL Divergence: 0.03174
SB3 Clip Fraction: 0.18585
Policy Update Magnitude: 0.10247
Value Function Update Magnitude: 0.22481

Collected Steps per Second: 10230.07017
Overall Steps per Second: 7368.57084

Timestep Collection Time: 4.88775
Timestep Consumption Time: 1.89810
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 6.78585

Cumulative Model Updates: 43320
Cumulative Timesteps: 361628158

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.63292
Policy Entropy: 1.07735
Value Function Loss: 0.06470

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.15887
Policy Update Magnitude: 0.10320
Value Function Update Magnitude: 0.23286

Collected Steps per Second: 10615.77511
Overall Steps per Second: 7545.33246

Timestep Collection Time: 4.71233
Timestep Consumption Time: 1.91760
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 6.62993

Cumulative Model Updates: 43326
Cumulative Timesteps: 361678183

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.90103
Policy Entropy: 1.08009
Value Function Loss: 0.06645

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.11181
Value Function Update Magnitude: 0.23445

Collected Steps per Second: 9827.58897
Overall Steps per Second: 7146.26137

Timestep Collection Time: 5.08833
Timestep Consumption Time: 1.90918
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 6.99751

Cumulative Model Updates: 43332
Cumulative Timesteps: 361728189

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.58522
Policy Entropy: 1.07282
Value Function Loss: 0.06833

Mean KL Divergence: 0.04324
SB3 Clip Fraction: 0.22324
Policy Update Magnitude: 0.10931
Value Function Update Magnitude: 0.23308

Collected Steps per Second: 10178.83500
Overall Steps per Second: 7174.57841

Timestep Collection Time: 4.91353
Timestep Consumption Time: 2.05747
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 6.97100

Cumulative Model Updates: 43338
Cumulative Timesteps: 361778203

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.45785
Policy Entropy: 1.06417
Value Function Loss: 0.06787

Mean KL Divergence: 0.03527
SB3 Clip Fraction: 0.20325
Policy Update Magnitude: 0.09772
Value Function Update Magnitude: 0.23438

Collected Steps per Second: 9738.11738
Overall Steps per Second: 6914.78613

Timestep Collection Time: 5.13765
Timestep Consumption Time: 2.09772
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.23536

Cumulative Model Updates: 43344
Cumulative Timesteps: 361828234

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.22429
Policy Entropy: 1.04314
Value Function Loss: 0.06559

Mean KL Divergence: 0.04901
SB3 Clip Fraction: 0.22274
Policy Update Magnitude: 0.11762
Value Function Update Magnitude: 0.22545

Collected Steps per Second: 9566.03741
Overall Steps per Second: 6824.54752

Timestep Collection Time: 5.22745
Timestep Consumption Time: 2.09992
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.32737

Cumulative Model Updates: 43350
Cumulative Timesteps: 361878240

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 361878240...
Checkpoint 361878240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.22884
Policy Entropy: 1.06443
Value Function Loss: 0.05935

Mean KL Divergence: 0.03088
SB3 Clip Fraction: 0.19874
Policy Update Magnitude: 0.09805
Value Function Update Magnitude: 0.21255

Collected Steps per Second: 9493.38886
Overall Steps per Second: 6936.57993

Timestep Collection Time: 5.26851
Timestep Consumption Time: 1.94196
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 7.21047

Cumulative Model Updates: 43356
Cumulative Timesteps: 361928256

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.87448
Policy Entropy: 1.04794
Value Function Loss: 0.06060

Mean KL Divergence: 0.04672
SB3 Clip Fraction: 0.22943
Policy Update Magnitude: 0.10496
Value Function Update Magnitude: 0.21236

Collected Steps per Second: 9813.05523
Overall Steps per Second: 6823.01772

Timestep Collection Time: 5.09902
Timestep Consumption Time: 2.23453
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.33356

Cumulative Model Updates: 43362
Cumulative Timesteps: 361978293

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.55266
Policy Entropy: 1.06353
Value Function Loss: 0.05985

Mean KL Divergence: 0.04050
SB3 Clip Fraction: 0.21724
Policy Update Magnitude: 0.09773
Value Function Update Magnitude: 0.21231

Collected Steps per Second: 9201.72746
Overall Steps per Second: 6620.71145

Timestep Collection Time: 5.43604
Timestep Consumption Time: 2.11919
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.55523

Cumulative Model Updates: 43368
Cumulative Timesteps: 362028314

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.83567
Policy Entropy: 1.02831
Value Function Loss: 0.06060

Mean KL Divergence: 0.04589
SB3 Clip Fraction: 0.23539
Policy Update Magnitude: 0.09400
Value Function Update Magnitude: 0.20934

Collected Steps per Second: 9062.04199
Overall Steps per Second: 6515.79161

Timestep Collection Time: 5.51984
Timestep Consumption Time: 2.15705
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.67689

Cumulative Model Updates: 43374
Cumulative Timesteps: 362078335

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.15596
Policy Entropy: 1.03838
Value Function Loss: 0.06160

Mean KL Divergence: 0.04186
SB3 Clip Fraction: 0.22752
Policy Update Magnitude: 0.08943
Value Function Update Magnitude: 0.20764

Collected Steps per Second: 9520.60648
Overall Steps per Second: 6864.99497

Timestep Collection Time: 5.25397
Timestep Consumption Time: 2.03241
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.28639

Cumulative Model Updates: 43380
Cumulative Timesteps: 362128356

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.33657
Policy Entropy: 1.03989
Value Function Loss: 0.06231

Mean KL Divergence: 0.03679
SB3 Clip Fraction: 0.22143
Policy Update Magnitude: 0.09225
Value Function Update Magnitude: 0.21091

Collected Steps per Second: 9413.03731
Overall Steps per Second: 6787.47845

Timestep Collection Time: 5.31221
Timestep Consumption Time: 2.05489
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 7.36710

Cumulative Model Updates: 43386
Cumulative Timesteps: 362178360

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.04461
Policy Entropy: 1.03622
Value Function Loss: 0.06501

Mean KL Divergence: 0.03768
SB3 Clip Fraction: 0.21997
Policy Update Magnitude: 0.09571
Value Function Update Magnitude: 0.21402

Collected Steps per Second: 9419.11414
Overall Steps per Second: 6655.19357

Timestep Collection Time: 5.31239
Timestep Consumption Time: 2.20625
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.51864

Cumulative Model Updates: 43392
Cumulative Timesteps: 362228398

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.12987
Policy Entropy: 1.03941
Value Function Loss: 0.06475

Mean KL Divergence: 0.04015
SB3 Clip Fraction: 0.21851
Policy Update Magnitude: 0.10227
Value Function Update Magnitude: 0.21351

Collected Steps per Second: 9562.52514
Overall Steps per Second: 6689.28545

Timestep Collection Time: 5.22895
Timestep Consumption Time: 2.24599
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.47494

Cumulative Model Updates: 43398
Cumulative Timesteps: 362278400

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.18110
Policy Entropy: 1.02284
Value Function Loss: 0.06674

Mean KL Divergence: 0.04191
SB3 Clip Fraction: 0.22839
Policy Update Magnitude: 0.09459
Value Function Update Magnitude: 0.21713

Collected Steps per Second: 9210.33582
Overall Steps per Second: 6741.59068

Timestep Collection Time: 5.42999
Timestep Consumption Time: 1.98844
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 7.41843

Cumulative Model Updates: 43404
Cumulative Timesteps: 362328412

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.62064
Policy Entropy: 1.04436
Value Function Loss: 0.06745

Mean KL Divergence: 0.03840
SB3 Clip Fraction: 0.21595
Policy Update Magnitude: 0.10842
Value Function Update Magnitude: 0.23382

Collected Steps per Second: 9069.61449
Overall Steps per Second: 6685.20581

Timestep Collection Time: 5.51556
Timestep Consumption Time: 1.96723
PPO Batch Consumption Time: 0.02455
Total Iteration Time: 7.48279

Cumulative Model Updates: 43410
Cumulative Timesteps: 362378436

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 362378436...
Checkpoint 362378436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.26435
Policy Entropy: 1.02786
Value Function Loss: 0.06987

Mean KL Divergence: 0.03591
SB3 Clip Fraction: 0.21885
Policy Update Magnitude: 0.10450
Value Function Update Magnitude: 0.25395

Collected Steps per Second: 9994.11842
Overall Steps per Second: 7058.20769

Timestep Collection Time: 5.00514
Timestep Consumption Time: 2.08192
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.08707

Cumulative Model Updates: 43416
Cumulative Timesteps: 362428458

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.87533
Policy Entropy: 1.02757
Value Function Loss: 0.07031

Mean KL Divergence: 0.03110
SB3 Clip Fraction: 0.18857
Policy Update Magnitude: 0.12232
Value Function Update Magnitude: 0.24344

Collected Steps per Second: 9546.21054
Overall Steps per Second: 6899.25390

Timestep Collection Time: 5.24030
Timestep Consumption Time: 2.01048
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.25078

Cumulative Model Updates: 43422
Cumulative Timesteps: 362478483

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.99287
Policy Entropy: 1.01638
Value Function Loss: 0.07042

Mean KL Divergence: 0.06035
SB3 Clip Fraction: 0.27634
Policy Update Magnitude: 0.11887
Value Function Update Magnitude: 0.24201

Collected Steps per Second: 8956.25490
Overall Steps per Second: 6591.59085

Timestep Collection Time: 5.58660
Timestep Consumption Time: 2.00413
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.59073

Cumulative Model Updates: 43428
Cumulative Timesteps: 362528518

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.15223
Policy Entropy: 1.01533
Value Function Loss: 0.06907

Mean KL Divergence: 0.05857
SB3 Clip Fraction: 0.26590
Policy Update Magnitude: 0.10248
Value Function Update Magnitude: 0.23348

Collected Steps per Second: 9838.56192
Overall Steps per Second: 6970.15632

Timestep Collection Time: 5.08550
Timestep Consumption Time: 2.09282
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.17832

Cumulative Model Updates: 43434
Cumulative Timesteps: 362578552

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.36340
Policy Entropy: 1.02170
Value Function Loss: 0.06695

Mean KL Divergence: 0.04400
SB3 Clip Fraction: 0.22696
Policy Update Magnitude: 0.10493
Value Function Update Magnitude: 0.22109

Collected Steps per Second: 10750.24337
Overall Steps per Second: 7521.45765

Timestep Collection Time: 4.65422
Timestep Consumption Time: 1.99795
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 6.65217

Cumulative Model Updates: 43440
Cumulative Timesteps: 362628586

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.54180
Policy Entropy: 1.00690
Value Function Loss: 0.06840

Mean KL Divergence: 0.05357
SB3 Clip Fraction: 0.25784
Policy Update Magnitude: 0.10606
Value Function Update Magnitude: 0.22211

Collected Steps per Second: 10443.94066
Overall Steps per Second: 7428.46688

Timestep Collection Time: 4.79082
Timestep Consumption Time: 1.94476
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 6.73558

Cumulative Model Updates: 43446
Cumulative Timesteps: 362678621

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.02154
Policy Entropy: 0.99922
Value Function Loss: 0.06553

Mean KL Divergence: 0.03258
SB3 Clip Fraction: 0.19559
Policy Update Magnitude: 0.09785
Value Function Update Magnitude: 0.23072

Collected Steps per Second: 10487.20345
Overall Steps per Second: 7455.36291

Timestep Collection Time: 4.77067
Timestep Consumption Time: 1.94007
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 6.71074

Cumulative Model Updates: 43452
Cumulative Timesteps: 362728652

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.13673
Policy Entropy: 0.98169
Value Function Loss: 0.06736

Mean KL Divergence: 0.04037
SB3 Clip Fraction: 0.21706
Policy Update Magnitude: 0.10623
Value Function Update Magnitude: 0.22533

Collected Steps per Second: 10082.59733
Overall Steps per Second: 7328.79392

Timestep Collection Time: 4.95934
Timestep Consumption Time: 1.86348
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.82281

Cumulative Model Updates: 43458
Cumulative Timesteps: 362778655

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.86773
Policy Entropy: 0.98330
Value Function Loss: 0.06269

Mean KL Divergence: 0.03127
SB3 Clip Fraction: 0.20803
Policy Update Magnitude: 0.10171
Value Function Update Magnitude: 0.21157

Collected Steps per Second: 9900.29244
Overall Steps per Second: 6941.59674

Timestep Collection Time: 5.05308
Timestep Consumption Time: 2.15376
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.20684

Cumulative Model Updates: 43464
Cumulative Timesteps: 362828682

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.75713
Policy Entropy: 0.97986
Value Function Loss: 0.06073

Mean KL Divergence: 0.02898
SB3 Clip Fraction: 0.20465
Policy Update Magnitude: 0.10634
Value Function Update Magnitude: 0.20737

Collected Steps per Second: 9649.67095
Overall Steps per Second: 6728.46396

Timestep Collection Time: 5.18308
Timestep Consumption Time: 2.25027
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.43335

Cumulative Model Updates: 43470
Cumulative Timesteps: 362878697

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 362878697...
Checkpoint 362878697 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.66201
Policy Entropy: 0.96567
Value Function Loss: 0.06246

Mean KL Divergence: 0.05578
SB3 Clip Fraction: 0.26770
Policy Update Magnitude: 0.09802
Value Function Update Magnitude: 0.20806

Collected Steps per Second: 9261.01040
Overall Steps per Second: 6541.25457

Timestep Collection Time: 5.40243
Timestep Consumption Time: 2.24625
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.64869

Cumulative Model Updates: 43476
Cumulative Timesteps: 362928729

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.48973
Policy Entropy: 0.97394
Value Function Loss: 0.06677

Mean KL Divergence: 0.03673
SB3 Clip Fraction: 0.22374
Policy Update Magnitude: 0.08866
Value Function Update Magnitude: 0.21145

Collected Steps per Second: 8994.44247
Overall Steps per Second: 6433.07860

Timestep Collection Time: 5.56344
Timestep Consumption Time: 2.21511
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.77855

Cumulative Model Updates: 43482
Cumulative Timesteps: 362978769

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.80742
Policy Entropy: 0.95395
Value Function Loss: 0.06898

Mean KL Divergence: 0.04583
SB3 Clip Fraction: 0.25031
Policy Update Magnitude: 0.09384
Value Function Update Magnitude: 0.21985

Collected Steps per Second: 9763.49855
Overall Steps per Second: 6791.06515

Timestep Collection Time: 5.12132
Timestep Consumption Time: 2.24159
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.36291

Cumulative Model Updates: 43488
Cumulative Timesteps: 363028771

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.15598
Policy Entropy: 0.97060
Value Function Loss: 0.06662

Mean KL Divergence: 0.02931
SB3 Clip Fraction: 0.19749
Policy Update Magnitude: 0.10969
Value Function Update Magnitude: 0.23778

Collected Steps per Second: 9431.46729
Overall Steps per Second: 6718.63055

Timestep Collection Time: 5.30310
Timestep Consumption Time: 2.14128
PPO Batch Consumption Time: 0.03166
Total Iteration Time: 7.44437

Cumulative Model Updates: 43494
Cumulative Timesteps: 363078787

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.73314
Policy Entropy: 0.95836
Value Function Loss: 0.06335

Mean KL Divergence: 0.02918
SB3 Clip Fraction: 0.19024
Policy Update Magnitude: 0.12897
Value Function Update Magnitude: 0.23960

Collected Steps per Second: 9400.69002
Overall Steps per Second: 6681.65048

Timestep Collection Time: 5.31908
Timestep Consumption Time: 2.16455
PPO Batch Consumption Time: 0.02422
Total Iteration Time: 7.48363

Cumulative Model Updates: 43500
Cumulative Timesteps: 363128790

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.08713
Policy Entropy: 0.96946
Value Function Loss: 0.06369

Mean KL Divergence: 0.02826
SB3 Clip Fraction: 0.18413
Policy Update Magnitude: 0.12541
Value Function Update Magnitude: 0.22601

Collected Steps per Second: 9700.76993
Overall Steps per Second: 6776.44973

Timestep Collection Time: 5.15670
Timestep Consumption Time: 2.22533
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.38204

Cumulative Model Updates: 43506
Cumulative Timesteps: 363178814

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.44544
Policy Entropy: 0.96844
Value Function Loss: 0.06249

Mean KL Divergence: 0.02785
SB3 Clip Fraction: 0.18556
Policy Update Magnitude: 0.11254
Value Function Update Magnitude: 0.21579

Collected Steps per Second: 9089.13961
Overall Steps per Second: 6400.36359

Timestep Collection Time: 5.50426
Timestep Consumption Time: 2.31233
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.81659

Cumulative Model Updates: 43512
Cumulative Timesteps: 363228843

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.86031
Policy Entropy: 0.97653
Value Function Loss: 0.06367

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.17822
Policy Update Magnitude: 0.11919
Value Function Update Magnitude: 0.21719

Collected Steps per Second: 9113.85768
Overall Steps per Second: 6460.88896

Timestep Collection Time: 5.48900
Timestep Consumption Time: 2.25389
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 7.74290

Cumulative Model Updates: 43518
Cumulative Timesteps: 363278869

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.66558
Policy Entropy: 0.97331
Value Function Loss: 0.06171

Mean KL Divergence: 0.04698
SB3 Clip Fraction: 0.24750
Policy Update Magnitude: 0.10992
Value Function Update Magnitude: 0.22286

Collected Steps per Second: 9485.18088
Overall Steps per Second: 6612.76422

Timestep Collection Time: 5.27201
Timestep Consumption Time: 2.29003
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.56204

Cumulative Model Updates: 43524
Cumulative Timesteps: 363328875

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 363328875...
Checkpoint 363328875 saved!
