{"total_goals":0,"x_vel":13.639617252210709,"SB3 Clip Fraction":0.24750332161784172,"Value Function Update Magnitude":0.2228628545999527,"Timestep Collection Time":5.272013328038156,"Timestep Consumption Time":2.2900285557843745,"episode_touches":0,"Collected Steps per Second":9485.180876545402,"Policy Update Magnitude":0.10991766303777695,"PPO Batch Consumption Time":0.02644689877827962,"Value Function Loss":0.06171320006251335,"total_touches":0,"Cumulative Timesteps":363328875,"Policy Reward":193.66558471862365,"Timesteps Collected":50006,"Overall Steps per Second":6612.764220068364,"Policy Entropy":0.9733103513717651,"Cumulative Model Updates":43524,"episode_goals":0,"z_vel":-22.61575719088474,"_wandb":{"runtime":81592},"Total Iteration Time":7.5620418838225305,"_step":14672,"Mean KL Divergence":0.04697705448294679,"_runtime":81592,"_timestamp":1.7629314880524356e+09,"y_vel":162.94041556676365}