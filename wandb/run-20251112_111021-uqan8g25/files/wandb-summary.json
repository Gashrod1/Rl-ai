{"Value Function Loss":0.11070021862785022,"Mean KL Divergence":0.010203108579541246,"Policy Entropy":0.8703899482885996,"Timestep Consumption Time":10.943205500021577,"_step":11,"Collected Steps per Second":1605.3173710703209,"PPO Batch Consumption Time":1.5943694114685059,"Overall Steps per Second":1187.9392443972579,"Cumulative Model Updates":30,"Total Iteration Time":42.089694599970244,"_runtime":226,"Value Function Update Magnitude":0.26894262433052063,"z_vel":-35.253628603610395,"episode_goals":0,"y_vel":16.922375034715234,"SB3 Clip Fraction":0.14379666994015375,"Policy Reward":12.75407637154792,"total_goals":0,"Timestep Collection Time":31.146489099948667,"Cumulative Timesteps":300000,"x_vel":34.05356599555448,"total_touches":0,"Timesteps Collected":50000,"_wandb":{"runtime":226},"_timestamp":1.7629424443139486e+09,"episode_touches":0,"Policy Update Magnitude":0.12255524843931198}