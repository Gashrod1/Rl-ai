Created new wandb run! 9prg5n79
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.94930
Policy Entropy: 0.80195
Value Function Loss: nan

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.18535
Value Function Update Magnitude: 0.22310

Collected Steps per Second: 4,100.59040
Overall Steps per Second: 3,215.46742

Timestep Collection Time: 12.19337
Timestep Consumption Time: 3.35647
PPO Batch Consumption Time: 0.98729
Total Iteration Time: 15.54984

Cumulative Model Updates: 2
Cumulative Timesteps: 50,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.53529
Policy Entropy: 0.77773
Value Function Loss: 107.96908

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.21584
Value Function Update Magnitude: 0.39156

Collected Steps per Second: 3,847.21356
Overall Steps per Second: 2,530.20768

Timestep Collection Time: 12.99772
Timestep Consumption Time: 6.76548
PPO Batch Consumption Time: 1.31125
Total Iteration Time: 19.76320

Cumulative Model Updates: 6
Cumulative Timesteps: 100,005

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 100005...
Checkpoint 100005 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.78328
Policy Entropy: 0.78429
Value Function Loss: 68.93582

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05923
Policy Update Magnitude: 0.27641
Value Function Update Magnitude: 0.53218

Collected Steps per Second: 3,232.53835
Overall Steps per Second: 2,029.89725

Timestep Collection Time: 15.46896
Timestep Consumption Time: 9.16480
PPO Batch Consumption Time: 1.27320
Total Iteration Time: 24.63376

Cumulative Model Updates: 12
Cumulative Timesteps: 150,009

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.15962
Policy Entropy: 0.76809
Value Function Loss: 2.26622

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.04788
Policy Update Magnitude: 0.21684
Value Function Update Magnitude: 0.21382

Collected Steps per Second: 3,288.95886
Overall Steps per Second: 2,030.03494

Timestep Collection Time: 15.20329
Timestep Consumption Time: 9.42830
PPO Batch Consumption Time: 1.30710
Total Iteration Time: 24.63160

Cumulative Model Updates: 18
Cumulative Timesteps: 200,012

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 200012...
Checkpoint 200012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.28652
Policy Entropy: 0.75252
Value Function Loss: 1.00759

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.17656
Value Function Update Magnitude: 0.28254

Collected Steps per Second: 3,362.45432
Overall Steps per Second: 2,101.56469

Timestep Collection Time: 14.87069
Timestep Consumption Time: 8.92206
PPO Batch Consumption Time: 1.21366
Total Iteration Time: 23.79275

Cumulative Model Updates: 24
Cumulative Timesteps: 250,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.71766
Policy Entropy: 0.80164
Value Function Loss: 0.48553

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.17863
Value Function Update Magnitude: 0.14700

Collected Steps per Second: 3,408.22525
Overall Steps per Second: 2,103.58277

Timestep Collection Time: 14.67157
Timestep Consumption Time: 9.09931
PPO Batch Consumption Time: 1.22942
Total Iteration Time: 23.77087

Cumulative Model Updates: 30
Cumulative Timesteps: 300,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 300018...
Checkpoint 300018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.61622
Policy Entropy: 0.83792
Value Function Loss: 0.45949

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.28972
Policy Update Magnitude: 0.14330
Value Function Update Magnitude: 0.15743

Collected Steps per Second: 3,360.68967
Overall Steps per Second: 2,093.30555

Timestep Collection Time: 14.87820
Timestep Consumption Time: 9.00795
PPO Batch Consumption Time: 1.23636
Total Iteration Time: 23.88614

Cumulative Model Updates: 36
Cumulative Timesteps: 350,019

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.06379
Policy Entropy: 0.84552
Value Function Loss: 0.38175

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.13703
Value Function Update Magnitude: 0.18753

Collected Steps per Second: 3,320.48186
Overall Steps per Second: 2,075.06890

Timestep Collection Time: 15.05926
Timestep Consumption Time: 9.03825
PPO Batch Consumption Time: 1.21884
Total Iteration Time: 24.09751

Cumulative Model Updates: 42
Cumulative Timesteps: 400,023

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 400023...
Checkpoint 400023 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.18905
Policy Entropy: 0.86773
Value Function Loss: 0.36125

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.16341
Value Function Update Magnitude: 0.22804

Collected Steps per Second: 3,271.49696
Overall Steps per Second: 2,009.68471

Timestep Collection Time: 15.28444
Timestep Consumption Time: 9.59658
PPO Batch Consumption Time: 1.31875
Total Iteration Time: 24.88102

Cumulative Model Updates: 48
Cumulative Timesteps: 450,026

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.86133
Policy Entropy: 0.90346
Value Function Loss: 0.36396

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.17829
Policy Update Magnitude: 0.16139
Value Function Update Magnitude: 0.27118

Collected Steps per Second: 3,121.09031
Overall Steps per Second: 1,924.10427

Timestep Collection Time: 16.02132
Timestep Consumption Time: 9.96687
PPO Batch Consumption Time: 1.38936
Total Iteration Time: 25.98820

Cumulative Model Updates: 54
Cumulative Timesteps: 500,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 500030...
Checkpoint 500030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.56226
Policy Entropy: 0.91614
Value Function Loss: 0.35898

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.16178
Value Function Update Magnitude: 0.31666

Collected Steps per Second: 2,932.63768
Overall Steps per Second: 1,860.08069

Timestep Collection Time: 17.05052
Timestep Consumption Time: 9.83165
PPO Batch Consumption Time: 1.36657
Total Iteration Time: 26.88217

Cumulative Model Updates: 60
Cumulative Timesteps: 550,033

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.55958
Policy Entropy: 0.92922
Value Function Loss: 0.33658

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06586
Policy Update Magnitude: 0.17639
Value Function Update Magnitude: 0.35663

Collected Steps per Second: 3,132.27869
Overall Steps per Second: 1,956.15299

Timestep Collection Time: 15.96346
Timestep Consumption Time: 9.59794
PPO Batch Consumption Time: 1.33680
Total Iteration Time: 25.56140

Cumulative Model Updates: 66
Cumulative Timesteps: 600,035

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 600035...
Checkpoint 600035 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.19835
Policy Entropy: 0.96777
Value Function Loss: 0.34010

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.15117
Policy Update Magnitude: 0.17770
Value Function Update Magnitude: 0.38682

Collected Steps per Second: 3,122.52302
Overall Steps per Second: 1,821.89003

Timestep Collection Time: 16.01269
Timestep Consumption Time: 11.43134
PPO Batch Consumption Time: 1.64826
Total Iteration Time: 27.44403

Cumulative Model Updates: 72
Cumulative Timesteps: 650,035

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.42674
Policy Entropy: 0.97485
Value Function Loss: 0.33366

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.18749
Value Function Update Magnitude: 0.40019

Collected Steps per Second: 3,192.12276
Overall Steps per Second: 1,993.35694

Timestep Collection Time: 15.66481
Timestep Consumption Time: 9.42051
PPO Batch Consumption Time: 1.28310
Total Iteration Time: 25.08532

Cumulative Model Updates: 78
Cumulative Timesteps: 700,039

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 700039...
Checkpoint 700039 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.48351
Policy Entropy: 0.98736
Value Function Loss: 0.34774

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.20985
Value Function Update Magnitude: 0.44440

Collected Steps per Second: 3,224.97188
Overall Steps per Second: 1,876.25547

Timestep Collection Time: 15.50463
Timestep Consumption Time: 11.14526
PPO Batch Consumption Time: 1.59635
Total Iteration Time: 26.64989

Cumulative Model Updates: 84
Cumulative Timesteps: 750,041

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.28049
Policy Entropy: 1.01879
Value Function Loss: 0.33214

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.22574
Value Function Update Magnitude: 0.47377

Collected Steps per Second: 3,153.56094
Overall Steps per Second: 1,911.97393

Timestep Collection Time: 15.85668
Timestep Consumption Time: 10.29692
PPO Batch Consumption Time: 1.43792
Total Iteration Time: 26.15360

Cumulative Model Updates: 90
Cumulative Timesteps: 800,046

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 800046...
Checkpoint 800046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.16644
Policy Entropy: 1.02284
Value Function Loss: 0.31998

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06921
Policy Update Magnitude: 0.24544
Value Function Update Magnitude: 0.49025

Collected Steps per Second: 3,203.53677
Overall Steps per Second: 2,014.17361

Timestep Collection Time: 15.60775
Timestep Consumption Time: 9.21633
PPO Batch Consumption Time: 1.26273
Total Iteration Time: 24.82408

Cumulative Model Updates: 96
Cumulative Timesteps: 850,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.29522
Policy Entropy: 1.04596
Value Function Loss: 0.30304

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.27023
Value Function Update Magnitude: 0.49175

Collected Steps per Second: 3,223.26825
Overall Steps per Second: 2,012.00205

Timestep Collection Time: 15.51314
Timestep Consumption Time: 9.33922
PPO Batch Consumption Time: 1.28511
Total Iteration Time: 24.85236

Cumulative Model Updates: 102
Cumulative Timesteps: 900,049

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 900049...
Checkpoint 900049 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.05793
Policy Entropy: 1.06665
Value Function Loss: 0.30025

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.26747
Value Function Update Magnitude: 0.45550

Collected Steps per Second: 3,252.75351
Overall Steps per Second: 2,027.58400

Timestep Collection Time: 15.37190
Timestep Consumption Time: 9.28848
PPO Batch Consumption Time: 1.28299
Total Iteration Time: 24.66038

Cumulative Model Updates: 108
Cumulative Timesteps: 950,050

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.91904
Policy Entropy: 1.07795
Value Function Loss: 0.30217

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.27228
Value Function Update Magnitude: 0.37510

Collected Steps per Second: 3,212.36502
Overall Steps per Second: 2,009.54207

Timestep Collection Time: 15.56548
Timestep Consumption Time: 9.31681
PPO Batch Consumption Time: 1.26937
Total Iteration Time: 24.88229

Cumulative Model Updates: 114
Cumulative Timesteps: 1,000,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1000052...
Checkpoint 1000052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.01554
Policy Entropy: 1.10289
Value Function Loss: 0.30773

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.27508
Value Function Update Magnitude: 0.31715

Collected Steps per Second: 3,189.60574
Overall Steps per Second: 1,986.00866

Timestep Collection Time: 15.67717
Timestep Consumption Time: 9.50097
PPO Batch Consumption Time: 1.30646
Total Iteration Time: 25.17814

Cumulative Model Updates: 120
Cumulative Timesteps: 1,050,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.98525
Policy Entropy: 1.10451
Value Function Loss: 0.32470

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.05717
Policy Update Magnitude: 0.27558
Value Function Update Magnitude: 0.26464

Collected Steps per Second: 3,268.01117
Overall Steps per Second: 2,026.09898

Timestep Collection Time: 15.30074
Timestep Consumption Time: 9.37870
PPO Batch Consumption Time: 1.29338
Total Iteration Time: 24.67945

Cumulative Model Updates: 126
Cumulative Timesteps: 1,100,059

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 1100059...
Checkpoint 1100059 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.09530
Policy Entropy: 1.11603
Value Function Loss: 0.34387

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05228
Policy Update Magnitude: 0.29006
Value Function Update Magnitude: 0.23412

Collected Steps per Second: 3,278.56706
Overall Steps per Second: 2,027.66218

Timestep Collection Time: 15.25087
Timestep Consumption Time: 9.40856
PPO Batch Consumption Time: 1.26998
Total Iteration Time: 24.65943

Cumulative Model Updates: 132
Cumulative Timesteps: 1,150,060

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.66683
Policy Entropy: 1.13616
Value Function Loss: 0.35608

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.27265
Value Function Update Magnitude: 0.21506

Collected Steps per Second: 3,238.12073
Overall Steps per Second: 2,015.68593

Timestep Collection Time: 15.44105
Timestep Consumption Time: 9.36440
PPO Batch Consumption Time: 1.28469
Total Iteration Time: 24.80545

Cumulative Model Updates: 138
Cumulative Timesteps: 1,200,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1200060...
Checkpoint 1200060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.01129
Policy Entropy: 1.13889
Value Function Loss: 0.35817

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.24886
Value Function Update Magnitude: 0.25457

Collected Steps per Second: 2,873.26069
Overall Steps per Second: 1,750.79611

Timestep Collection Time: 17.40218
Timestep Consumption Time: 11.15683
PPO Batch Consumption Time: 1.55063
Total Iteration Time: 28.55901

Cumulative Model Updates: 144
Cumulative Timesteps: 1,250,061

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.75198
Policy Entropy: 1.14375
Value Function Loss: 0.37459

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.24669
Value Function Update Magnitude: 0.24972

Collected Steps per Second: 3,091.50092
Overall Steps per Second: 1,958.36939

Timestep Collection Time: 16.17337
Timestep Consumption Time: 9.35807
PPO Batch Consumption Time: 1.27747
Total Iteration Time: 25.53144

Cumulative Model Updates: 150
Cumulative Timesteps: 1,300,061

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1300061...
Checkpoint 1300061 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.82922
Policy Entropy: 1.14373
Value Function Loss: 0.37665

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.05751
Policy Update Magnitude: 0.25683
Value Function Update Magnitude: 0.24052

Collected Steps per Second: 3,229.28036
Overall Steps per Second: 2,004.31048

Timestep Collection Time: 15.48364
Timestep Consumption Time: 9.46310
PPO Batch Consumption Time: 1.30277
Total Iteration Time: 24.94673

Cumulative Model Updates: 156
Cumulative Timesteps: 1,350,062

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.65114
Policy Entropy: 1.15968
Value Function Loss: 0.37121

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06681
Policy Update Magnitude: 0.25912
Value Function Update Magnitude: 0.26018

Collected Steps per Second: 3,217.09024
Overall Steps per Second: 1,993.62581

Timestep Collection Time: 15.54293
Timestep Consumption Time: 9.53851
PPO Batch Consumption Time: 1.30530
Total Iteration Time: 25.08144

Cumulative Model Updates: 162
Cumulative Timesteps: 1,400,065

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 1400065...
Checkpoint 1400065 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.58645
Policy Entropy: 1.17177
Value Function Loss: 0.35414

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.25015
Value Function Update Magnitude: 0.25680

Collected Steps per Second: 3,246.91350
Overall Steps per Second: 2,020.40276

Timestep Collection Time: 15.39955
Timestep Consumption Time: 9.34849
PPO Batch Consumption Time: 1.26262
Total Iteration Time: 24.74804

Cumulative Model Updates: 168
Cumulative Timesteps: 1,450,066

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.87271
Policy Entropy: 1.17572
Value Function Loss: 0.34848

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.24614
Value Function Update Magnitude: 0.26449

Collected Steps per Second: 3,220.06340
Overall Steps per Second: 2,005.68249

Timestep Collection Time: 15.52889
Timestep Consumption Time: 9.40228
PPO Batch Consumption Time: 1.27666
Total Iteration Time: 24.93116

Cumulative Model Updates: 174
Cumulative Timesteps: 1,500,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1500070...
Checkpoint 1500070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.13449
Policy Entropy: 1.16422
Value Function Loss: 0.35513

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.04549
Policy Update Magnitude: 0.25717
Value Function Update Magnitude: 0.25176

Collected Steps per Second: 3,078.19087
Overall Steps per Second: 1,962.51336

Timestep Collection Time: 16.24428
Timestep Consumption Time: 9.23478
PPO Batch Consumption Time: 1.27744
Total Iteration Time: 25.47906

Cumulative Model Updates: 180
Cumulative Timesteps: 1,550,073

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.29714
Policy Entropy: 1.17408
Value Function Loss: 0.35722

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05894
Policy Update Magnitude: 0.25678
Value Function Update Magnitude: 0.23821

Collected Steps per Second: 3,242.57794
Overall Steps per Second: 2,019.61884

Timestep Collection Time: 15.42014
Timestep Consumption Time: 9.33750
PPO Batch Consumption Time: 1.26683
Total Iteration Time: 24.75764

Cumulative Model Updates: 186
Cumulative Timesteps: 1,600,074

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 1600074...
Checkpoint 1600074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.03772
Policy Entropy: 1.18020
Value Function Loss: 0.36557

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.05916
Policy Update Magnitude: 0.26290
Value Function Update Magnitude: 0.29639

Collected Steps per Second: 3,221.91029
Overall Steps per Second: 1,970.87269

Timestep Collection Time: 15.51874
Timestep Consumption Time: 9.85073
PPO Batch Consumption Time: 1.35576
Total Iteration Time: 25.36947

Cumulative Model Updates: 192
Cumulative Timesteps: 1,650,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.56604
Policy Entropy: 1.18430
Value Function Loss: 0.36916

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.26163
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 3,263.90808
Overall Steps per Second: 2,013.19214

Timestep Collection Time: 15.31998
Timestep Consumption Time: 9.51769
PPO Batch Consumption Time: 1.31225
Total Iteration Time: 24.83767

Cumulative Model Updates: 198
Cumulative Timesteps: 1,700,077

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 1700077...
Checkpoint 1700077 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.37403
Policy Entropy: 1.18213
Value Function Loss: 0.38165

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.03818
Policy Update Magnitude: 0.27087
Value Function Update Magnitude: 0.33613

Collected Steps per Second: 3,265.34929
Overall Steps per Second: 2,033.80474

Timestep Collection Time: 15.31260
Timestep Consumption Time: 9.27235
PPO Batch Consumption Time: 1.26929
Total Iteration Time: 24.58496

Cumulative Model Updates: 204
Cumulative Timesteps: 1,750,078

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.23620
Policy Entropy: 1.17418
Value Function Loss: 0.37835

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.04860
Policy Update Magnitude: 0.27549
Value Function Update Magnitude: 0.34432

Collected Steps per Second: 3,223.61773
Overall Steps per Second: 2,007.72682

Timestep Collection Time: 15.51145
Timestep Consumption Time: 9.39383
PPO Batch Consumption Time: 1.28638
Total Iteration Time: 24.90528

Cumulative Model Updates: 210
Cumulative Timesteps: 1,800,081

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 1800081...
Checkpoint 1800081 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.33151
Policy Entropy: 1.16975
Value Function Loss: 0.39599

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06259
Policy Update Magnitude: 0.27733
Value Function Update Magnitude: 0.29428

Collected Steps per Second: 3,246.80745
Overall Steps per Second: 2,014.22017

Timestep Collection Time: 15.40005
Timestep Consumption Time: 9.42395
PPO Batch Consumption Time: 1.26956
Total Iteration Time: 24.82400

Cumulative Model Updates: 216
Cumulative Timesteps: 1,850,082

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.46703
Policy Entropy: 1.16133
Value Function Loss: 0.40999

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.07422
Policy Update Magnitude: 0.26649
Value Function Update Magnitude: 0.24112

Collected Steps per Second: 3,274.11910
Overall Steps per Second: 2,028.86433

Timestep Collection Time: 15.27128
Timestep Consumption Time: 9.37305
PPO Batch Consumption Time: 1.27220
Total Iteration Time: 24.64433

Cumulative Model Updates: 222
Cumulative Timesteps: 1,900,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1900082...
Checkpoint 1900082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.54802
Policy Entropy: 1.15131
Value Function Loss: 0.43089

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06746
Policy Update Magnitude: 0.26773
Value Function Update Magnitude: 0.26477

Collected Steps per Second: 3,250.34495
Overall Steps per Second: 2,020.19631

Timestep Collection Time: 15.38421
Timestep Consumption Time: 9.36784
PPO Batch Consumption Time: 1.27970
Total Iteration Time: 24.75205

Cumulative Model Updates: 228
Cumulative Timesteps: 1,950,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.26711
Policy Entropy: 1.15119
Value Function Loss: 0.43687

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.07175
Policy Update Magnitude: 0.26066
Value Function Update Magnitude: 0.23677

Collected Steps per Second: 3,225.72078
Overall Steps per Second: 2,016.96030

Timestep Collection Time: 15.50134
Timestep Consumption Time: 9.28992
PPO Batch Consumption Time: 1.27236
Total Iteration Time: 24.79127

Cumulative Model Updates: 234
Cumulative Timesteps: 2,000,089

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 2000089...
Checkpoint 2000089 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.69677
Policy Entropy: 1.14448
Value Function Loss: 0.44923

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04401
Policy Update Magnitude: 0.25942
Value Function Update Magnitude: 0.23415

Collected Steps per Second: 3,270.96733
Overall Steps per Second: 2,033.28666

Timestep Collection Time: 15.28600
Timestep Consumption Time: 9.30473
PPO Batch Consumption Time: 1.26201
Total Iteration Time: 24.59073

Cumulative Model Updates: 240
Cumulative Timesteps: 2,050,089

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.75477
Policy Entropy: 1.14254
Value Function Loss: 0.44105

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05846
Policy Update Magnitude: 0.26742
Value Function Update Magnitude: 0.20558

Collected Steps per Second: 3,254.46578
Overall Steps per Second: 2,024.20468

Timestep Collection Time: 15.36473
Timestep Consumption Time: 9.33830
PPO Batch Consumption Time: 1.25691
Total Iteration Time: 24.70304

Cumulative Model Updates: 246
Cumulative Timesteps: 2,100,093

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2100093...
Checkpoint 2100093 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.64830
Policy Entropy: 1.14457
Value Function Loss: 0.44143

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05422
Policy Update Magnitude: 0.26119
Value Function Update Magnitude: 0.21848

Collected Steps per Second: 3,229.84146
Overall Steps per Second: 2,017.39014

Timestep Collection Time: 15.48095
Timestep Consumption Time: 9.30405
PPO Batch Consumption Time: 1.27889
Total Iteration Time: 24.78499

Cumulative Model Updates: 252
Cumulative Timesteps: 2,150,094

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.49249
Policy Entropy: 1.14040
Value Function Loss: 0.42916

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06523
Policy Update Magnitude: 0.25051
Value Function Update Magnitude: 0.19672

Collected Steps per Second: 3,279.77040
Overall Steps per Second: 2,029.56519

Timestep Collection Time: 15.24619
Timestep Consumption Time: 9.39160
PPO Batch Consumption Time: 1.29662
Total Iteration Time: 24.63779

Cumulative Model Updates: 258
Cumulative Timesteps: 2,200,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2200098...
Checkpoint 2200098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.78920
Policy Entropy: 1.15066
Value Function Loss: 0.43823

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05339
Policy Update Magnitude: 0.25130
Value Function Update Magnitude: 0.21966

Collected Steps per Second: 3,298.84644
Overall Steps per Second: 2,038.19091

Timestep Collection Time: 15.15742
Timestep Consumption Time: 9.37512
PPO Batch Consumption Time: 1.27682
Total Iteration Time: 24.53254

Cumulative Model Updates: 264
Cumulative Timesteps: 2,250,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.26384
Policy Entropy: 1.14578
Value Function Loss: 0.44936

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05338
Policy Update Magnitude: 0.24988
Value Function Update Magnitude: 0.18503

Collected Steps per Second: 3,295.53130
Overall Steps per Second: 2,039.06127

Timestep Collection Time: 15.17206
Timestep Consumption Time: 9.34903
PPO Batch Consumption Time: 1.27638
Total Iteration Time: 24.52109

Cumulative Model Updates: 270
Cumulative Timesteps: 2,300,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2300100...
Checkpoint 2300100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.04324
Policy Entropy: 1.16394
Value Function Loss: 0.48468

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06896
Policy Update Magnitude: 0.25585
Value Function Update Magnitude: 0.13460

Collected Steps per Second: 3,237.24428
Overall Steps per Second: 2,011.89914

Timestep Collection Time: 15.44524
Timestep Consumption Time: 9.40690
PPO Batch Consumption Time: 1.27987
Total Iteration Time: 24.85214

Cumulative Model Updates: 276
Cumulative Timesteps: 2,350,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.63622
Policy Entropy: 1.17413
Value Function Loss: 0.48023

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.25665
Value Function Update Magnitude: 0.11944

Collected Steps per Second: 3,272.03741
Overall Steps per Second: 2,027.37583

Timestep Collection Time: 15.28100
Timestep Consumption Time: 9.38142
PPO Batch Consumption Time: 1.29267
Total Iteration Time: 24.66242

Cumulative Model Updates: 282
Cumulative Timesteps: 2,400,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2400100...
Checkpoint 2400100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.77586
Policy Entropy: 1.19111
Value Function Loss: 0.44326

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.25655
Value Function Update Magnitude: 0.13846

Collected Steps per Second: 3,282.17114
Overall Steps per Second: 2,020.99293

Timestep Collection Time: 15.23504
Timestep Consumption Time: 9.50726
PPO Batch Consumption Time: 1.30130
Total Iteration Time: 24.74229

Cumulative Model Updates: 288
Cumulative Timesteps: 2,450,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.81129
Policy Entropy: 1.20250
Value Function Loss: 0.42075

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06362
Policy Update Magnitude: 0.26202
Value Function Update Magnitude: 0.15511

Collected Steps per Second: 3,272.65629
Overall Steps per Second: 2,021.35725

Timestep Collection Time: 15.27841
Timestep Consumption Time: 9.45794
PPO Batch Consumption Time: 1.29224
Total Iteration Time: 24.73635

Cumulative Model Updates: 294
Cumulative Timesteps: 2,500,105

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 2500105...
Checkpoint 2500105 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.27205
Policy Entropy: 1.20921
Value Function Loss: 0.41686

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06862
Policy Update Magnitude: 0.26522
Value Function Update Magnitude: 0.17879

Collected Steps per Second: 3,263.29704
Overall Steps per Second: 2,018.90662

Timestep Collection Time: 15.32285
Timestep Consumption Time: 9.44452
PPO Batch Consumption Time: 1.29161
Total Iteration Time: 24.76737

Cumulative Model Updates: 300
Cumulative Timesteps: 2,550,108

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.21168
Policy Entropy: 1.21248
Value Function Loss: 0.42971

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.26211
Value Function Update Magnitude: 0.15400

Collected Steps per Second: 3,271.53901
Overall Steps per Second: 2,025.50837

Timestep Collection Time: 15.28394
Timestep Consumption Time: 9.40221
PPO Batch Consumption Time: 1.29379
Total Iteration Time: 24.68615

Cumulative Model Updates: 306
Cumulative Timesteps: 2,600,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2600110...
Checkpoint 2600110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.51835
Policy Entropy: 1.20852
Value Function Loss: 0.43903

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06566
Policy Update Magnitude: 0.26021
Value Function Update Magnitude: 0.13144

Collected Steps per Second: 3,257.10587
Overall Steps per Second: 2,028.15093

Timestep Collection Time: 15.35228
Timestep Consumption Time: 9.30269
PPO Batch Consumption Time: 1.28542
Total Iteration Time: 24.65497

Cumulative Model Updates: 312
Cumulative Timesteps: 2,650,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.62747
Policy Entropy: 1.21136
Value Function Loss: 0.44876

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.25395
Value Function Update Magnitude: 0.14406

Collected Steps per Second: 3,267.15470
Overall Steps per Second: 2,017.26245

Timestep Collection Time: 15.30384
Timestep Consumption Time: 9.48223
PPO Batch Consumption Time: 1.28417
Total Iteration Time: 24.78607

Cumulative Model Updates: 318
Cumulative Timesteps: 2,700,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2700114...
Checkpoint 2700114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.98015
Policy Entropy: 1.21750
Value Function Loss: 0.45041

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.24595
Value Function Update Magnitude: 0.13995

Collected Steps per Second: 3,294.48366
Overall Steps per Second: 2,032.28848

Timestep Collection Time: 15.17780
Timestep Consumption Time: 9.42649
PPO Batch Consumption Time: 1.29263
Total Iteration Time: 24.60428

Cumulative Model Updates: 324
Cumulative Timesteps: 2,750,117

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.93046
Policy Entropy: 1.24244
Value Function Loss: 0.45331

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.22620
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 3,302.78521
Overall Steps per Second: 2,037.75812

Timestep Collection Time: 15.13874
Timestep Consumption Time: 9.39803
PPO Batch Consumption Time: 1.27857
Total Iteration Time: 24.53677

Cumulative Model Updates: 330
Cumulative Timesteps: 2,800,117

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2800117...
Checkpoint 2800117 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.53135
Policy Entropy: 1.23212
Value Function Loss: 0.45218

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.21832
Value Function Update Magnitude: 0.11137

Collected Steps per Second: 3,246.89043
Overall Steps per Second: 2,021.49596

Timestep Collection Time: 15.39997
Timestep Consumption Time: 9.33518
PPO Batch Consumption Time: 1.27425
Total Iteration Time: 24.73515

Cumulative Model Updates: 336
Cumulative Timesteps: 2,850,119

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.84540
Policy Entropy: 1.26500
Value Function Loss: 0.44871

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.17110
Policy Update Magnitude: 0.20336
Value Function Update Magnitude: 0.11540

Collected Steps per Second: 3,210.88835
Overall Steps per Second: 2,006.43130

Timestep Collection Time: 15.57201
Timestep Consumption Time: 9.34785
PPO Batch Consumption Time: 1.28547
Total Iteration Time: 24.91987

Cumulative Model Updates: 342
Cumulative Timesteps: 2,900,119

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2900119...
Checkpoint 2900119 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.66471
Policy Entropy: 1.27916
Value Function Loss: 0.43957

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.21440
Value Function Update Magnitude: 0.11088

Collected Steps per Second: 3,279.89492
Overall Steps per Second: 2,024.74409

Timestep Collection Time: 15.24531
Timestep Consumption Time: 9.45066
PPO Batch Consumption Time: 1.28137
Total Iteration Time: 24.69596

Cumulative Model Updates: 348
Cumulative Timesteps: 2,950,122

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.92836
Policy Entropy: 1.29339
Value Function Loss: 0.42899

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.21392
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 3,282.48249
Overall Steps per Second: 2,026.52445

Timestep Collection Time: 15.23237
Timestep Consumption Time: 9.44041
PPO Batch Consumption Time: 1.29953
Total Iteration Time: 24.67278

Cumulative Model Updates: 354
Cumulative Timesteps: 3,000,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3000122...
Checkpoint 3000122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.25588
Policy Entropy: 1.30607
Value Function Loss: 0.42071

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.20881
Value Function Update Magnitude: 0.11297

Collected Steps per Second: 3,280.55285
Overall Steps per Second: 2,037.73448

Timestep Collection Time: 15.24164
Timestep Consumption Time: 9.29591
PPO Batch Consumption Time: 1.26667
Total Iteration Time: 24.53754

Cumulative Model Updates: 360
Cumulative Timesteps: 3,050,123

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.61601
Policy Entropy: 1.31681
Value Function Loss: 0.40983

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.20385
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 3,206.70164
Overall Steps per Second: 2,008.49214

Timestep Collection Time: 15.59266
Timestep Consumption Time: 9.30214
PPO Batch Consumption Time: 1.28750
Total Iteration Time: 24.89479

Cumulative Model Updates: 366
Cumulative Timesteps: 3,100,124

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 3100124...
Checkpoint 3100124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.53754
Policy Entropy: 1.32129
Value Function Loss: 0.40027

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.20789
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 3,274.79808
Overall Steps per Second: 2,027.41046

Timestep Collection Time: 15.26934
Timestep Consumption Time: 9.39464
PPO Batch Consumption Time: 1.28237
Total Iteration Time: 24.66397

Cumulative Model Updates: 372
Cumulative Timesteps: 3,150,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.93495
Policy Entropy: 1.32917
Value Function Loss: 0.39027

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.20176
Value Function Update Magnitude: 0.13146

Collected Steps per Second: 3,297.01148
Overall Steps per Second: 2,035.77182

Timestep Collection Time: 15.16525
Timestep Consumption Time: 9.39546
PPO Batch Consumption Time: 1.28714
Total Iteration Time: 24.56071

Cumulative Model Updates: 378
Cumulative Timesteps: 3,200,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3200128...
Checkpoint 3200128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.04644
Policy Entropy: 1.32991
Value Function Loss: 0.39390

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.19821
Value Function Update Magnitude: 0.14733

Collected Steps per Second: 3,277.45531
Overall Steps per Second: 2,030.04656

Timestep Collection Time: 15.25696
Timestep Consumption Time: 9.37499
PPO Batch Consumption Time: 1.27775
Total Iteration Time: 24.63195

Cumulative Model Updates: 384
Cumulative Timesteps: 3,250,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.24277
Policy Entropy: 1.33255
Value Function Loss: 0.40424

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.04482
Policy Update Magnitude: 0.20421
Value Function Update Magnitude: 0.12895

Collected Steps per Second: 3,256.74424
Overall Steps per Second: 2,016.38796

Timestep Collection Time: 15.35398
Timestep Consumption Time: 9.44481
PPO Batch Consumption Time: 1.30213
Total Iteration Time: 24.79880

Cumulative Model Updates: 390
Cumulative Timesteps: 3,300,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3300136...
Checkpoint 3300136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.02973
Policy Entropy: 1.34101
Value Function Loss: 0.41225

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.05892
Policy Update Magnitude: 0.20425
Value Function Update Magnitude: 0.11329

Collected Steps per Second: 3,274.16481
Overall Steps per Second: 2,033.13578

Timestep Collection Time: 15.27229
Timestep Consumption Time: 9.32223
PPO Batch Consumption Time: 1.28870
Total Iteration Time: 24.59452

Cumulative Model Updates: 396
Cumulative Timesteps: 3,350,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.34370
Policy Entropy: 1.33305
Value Function Loss: 0.42304

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.20930
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 3,280.60760
Overall Steps per Second: 2,033.43055

Timestep Collection Time: 15.24230
Timestep Consumption Time: 9.34866
PPO Batch Consumption Time: 1.26666
Total Iteration Time: 24.59096

Cumulative Model Updates: 402
Cumulative Timesteps: 3,400,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3400144...
Checkpoint 3400144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.76759
Policy Entropy: 1.33803
Value Function Loss: 0.42183

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.05701
Policy Update Magnitude: 0.21408
Value Function Update Magnitude: 0.14948

Collected Steps per Second: 3,272.37588
Overall Steps per Second: 2,032.97005

Timestep Collection Time: 15.28003
Timestep Consumption Time: 9.31551
PPO Batch Consumption Time: 1.27556
Total Iteration Time: 24.59554

Cumulative Model Updates: 408
Cumulative Timesteps: 3,450,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.61002
Policy Entropy: 1.33733
Value Function Loss: 0.43468

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.20707
Value Function Update Magnitude: 0.13645

Collected Steps per Second: 3,255.90638
Overall Steps per Second: 2,021.18812

Timestep Collection Time: 15.35671
Timestep Consumption Time: 9.38122
PPO Batch Consumption Time: 1.28102
Total Iteration Time: 24.73793

Cumulative Model Updates: 414
Cumulative Timesteps: 3,500,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3500146...
Checkpoint 3500146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.07708
Policy Entropy: 1.34123
Value Function Loss: 0.43358

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05378
Policy Update Magnitude: 0.20832
Value Function Update Magnitude: 0.17934

Collected Steps per Second: 3,266.75169
Overall Steps per Second: 2,014.53563

Timestep Collection Time: 15.30664
Timestep Consumption Time: 9.51446
PPO Batch Consumption Time: 1.29341
Total Iteration Time: 24.82110

Cumulative Model Updates: 420
Cumulative Timesteps: 3,550,149

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.54190
Policy Entropy: 1.34903
Value Function Loss: 0.44610

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.21014
Value Function Update Magnitude: 0.15458

Collected Steps per Second: 3,265.35288
Overall Steps per Second: 2,025.61326

Timestep Collection Time: 15.31351
Timestep Consumption Time: 9.37235
PPO Batch Consumption Time: 1.27990
Total Iteration Time: 24.68586

Cumulative Model Updates: 426
Cumulative Timesteps: 3,600,153

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3600153...
Checkpoint 3600153 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.84398
Policy Entropy: 1.35048
Value Function Loss: 0.45007

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.19961
Value Function Update Magnitude: 0.15555

Collected Steps per Second: 3,283.97858
Overall Steps per Second: 2,009.58478

Timestep Collection Time: 15.22665
Timestep Consumption Time: 9.65610
PPO Batch Consumption Time: 1.33686
Total Iteration Time: 24.88275

Cumulative Model Updates: 432
Cumulative Timesteps: 3,650,157

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.93459
Policy Entropy: 1.34876
Value Function Loss: 0.42859

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.20375
Value Function Update Magnitude: 0.22107

Collected Steps per Second: 3,110.92019
Overall Steps per Second: 1,952.52575

Timestep Collection Time: 16.07370
Timestep Consumption Time: 9.53620
PPO Batch Consumption Time: 1.30274
Total Iteration Time: 25.60991

Cumulative Model Updates: 438
Cumulative Timesteps: 3,700,161

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3700161...
Checkpoint 3700161 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.60284
Policy Entropy: 1.34931
Value Function Loss: 0.41906

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.20342
Value Function Update Magnitude: 0.24858

Collected Steps per Second: 3,264.77095
Overall Steps per Second: 2,021.51712

Timestep Collection Time: 15.31654
Timestep Consumption Time: 9.41983
PPO Batch Consumption Time: 1.29152
Total Iteration Time: 24.73637

Cumulative Model Updates: 444
Cumulative Timesteps: 3,750,166

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.83699
Policy Entropy: 1.34355
Value Function Loss: 0.40657

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.19670
Value Function Update Magnitude: 0.21006

Collected Steps per Second: 3,310.86121
Overall Steps per Second: 2,028.35081

Timestep Collection Time: 15.10332
Timestep Consumption Time: 9.54971
PPO Batch Consumption Time: 1.31443
Total Iteration Time: 24.65303

Cumulative Model Updates: 450
Cumulative Timesteps: 3,800,171

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 3800171...
Checkpoint 3800171 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.63204
Policy Entropy: 1.34045
Value Function Loss: 0.42770

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.16523
Value Function Update Magnitude: 0.17828

Collected Steps per Second: 3,277.54498
Overall Steps per Second: 2,018.62011

Timestep Collection Time: 15.25593
Timestep Consumption Time: 9.51446
PPO Batch Consumption Time: 1.30836
Total Iteration Time: 24.77039

Cumulative Model Updates: 456
Cumulative Timesteps: 3,850,173

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.88258
Policy Entropy: 1.32955
Value Function Loss: 0.43265

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.14820
Value Function Update Magnitude: 0.13214

Collected Steps per Second: 3,302.21934
Overall Steps per Second: 2,038.90964

Timestep Collection Time: 15.14133
Timestep Consumption Time: 9.38158
PPO Batch Consumption Time: 1.28049
Total Iteration Time: 24.52291

Cumulative Model Updates: 462
Cumulative Timesteps: 3,900,173

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3900173...
Checkpoint 3900173 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.73339
Policy Entropy: 1.35277
Value Function Loss: 0.44157

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.16020
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 3,287.74639
Overall Steps per Second: 2,035.14118

Timestep Collection Time: 15.20920
Timestep Consumption Time: 9.36108
PPO Batch Consumption Time: 1.28626
Total Iteration Time: 24.57029

Cumulative Model Updates: 468
Cumulative Timesteps: 3,950,177

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.41895
Policy Entropy: 1.34261
Value Function Loss: 0.43994

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.17221
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 3,297.85071
Overall Steps per Second: 2,043.26098

Timestep Collection Time: 15.16169
Timestep Consumption Time: 9.30948
PPO Batch Consumption Time: 1.26201
Total Iteration Time: 24.47118

Cumulative Model Updates: 474
Cumulative Timesteps: 4,000,178

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 4000178...
Checkpoint 4000178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.35310
Policy Entropy: 1.35257
Value Function Loss: 0.44851

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.18845
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 3,278.03530
Overall Steps per Second: 2,021.34649

Timestep Collection Time: 15.25304
Timestep Consumption Time: 9.48295
PPO Batch Consumption Time: 1.29035
Total Iteration Time: 24.73599

Cumulative Model Updates: 480
Cumulative Timesteps: 4,050,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.16120
Policy Entropy: 1.35258
Value Function Loss: 0.44151

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.17913
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 3,295.43710
Overall Steps per Second: 2,019.94652

Timestep Collection Time: 15.17310
Timestep Consumption Time: 9.58102
PPO Batch Consumption Time: 1.31660
Total Iteration Time: 24.75412

Cumulative Model Updates: 486
Cumulative Timesteps: 4,100,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 4100180...
Checkpoint 4100180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.71333
Policy Entropy: 1.35365
Value Function Loss: 0.44235

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.16967
Value Function Update Magnitude: 0.12127

Collected Steps per Second: 3,308.29518
Overall Steps per Second: 2,042.40947

Timestep Collection Time: 15.11352
Timestep Consumption Time: 9.36736
PPO Batch Consumption Time: 1.29786
Total Iteration Time: 24.48089

Cumulative Model Updates: 492
Cumulative Timesteps: 4,150,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.28152
Policy Entropy: 1.35655
Value Function Loss: 0.43342

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.18219
Value Function Update Magnitude: 0.11102

Collected Steps per Second: 3,299.66244
Overall Steps per Second: 2,032.57359

Timestep Collection Time: 15.15428
Timestep Consumption Time: 9.44705
PPO Batch Consumption Time: 1.29380
Total Iteration Time: 24.60132

Cumulative Model Updates: 498
Cumulative Timesteps: 4,200,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 4200184...
Checkpoint 4200184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.25259
Policy Entropy: 1.35575
Value Function Loss: 0.43978

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.18113
Value Function Update Magnitude: 0.11529

Collected Steps per Second: 3,251.25831
Overall Steps per Second: 2,017.07884

Timestep Collection Time: 15.37958
Timestep Consumption Time: 9.41023
PPO Batch Consumption Time: 1.27615
Total Iteration Time: 24.78981

Cumulative Model Updates: 504
Cumulative Timesteps: 4,250,187

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.39742
Policy Entropy: 1.35685
Value Function Loss: 0.43552

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.17228
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 3,311.25547
Overall Steps per Second: 2,034.70256

Timestep Collection Time: 15.10062
Timestep Consumption Time: 9.47398
PPO Batch Consumption Time: 1.28174
Total Iteration Time: 24.57460

Cumulative Model Updates: 510
Cumulative Timesteps: 4,300,189

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 4300189...
Checkpoint 4300189 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.28774
Policy Entropy: 1.36215
Value Function Loss: 0.42123

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.16092
Value Function Update Magnitude: 0.10749

Collected Steps per Second: 3,317.88770
Overall Steps per Second: 2,034.68592

Timestep Collection Time: 15.07043
Timestep Consumption Time: 9.50437
PPO Batch Consumption Time: 1.30181
Total Iteration Time: 24.57480

Cumulative Model Updates: 516
Cumulative Timesteps: 4,350,191

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.83334
Policy Entropy: 1.35922
Value Function Loss: 0.40793

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.14674
Value Function Update Magnitude: 0.10454

Collected Steps per Second: 3,291.17625
Overall Steps per Second: 2,039.03138

Timestep Collection Time: 15.19244
Timestep Consumption Time: 9.32950
PPO Batch Consumption Time: 1.28162
Total Iteration Time: 24.52194

Cumulative Model Updates: 522
Cumulative Timesteps: 4,400,192

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 4400192...
Checkpoint 4400192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.24641
Policy Entropy: 1.34990
Value Function Loss: 0.41641

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.13278
Value Function Update Magnitude: 0.10659

Collected Steps per Second: 3,255.39821
Overall Steps per Second: 2,023.92280

Timestep Collection Time: 15.35941
Timestep Consumption Time: 9.34558
PPO Batch Consumption Time: 1.27784
Total Iteration Time: 24.70499

Cumulative Model Updates: 528
Cumulative Timesteps: 4,450,193

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.07378
Policy Entropy: 1.34524
Value Function Loss: 0.42939

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.12967
Value Function Update Magnitude: 0.11040

Collected Steps per Second: 3,300.55628
Overall Steps per Second: 2,039.63252

Timestep Collection Time: 15.15048
Timestep Consumption Time: 9.36619
PPO Batch Consumption Time: 1.28622
Total Iteration Time: 24.51667

Cumulative Model Updates: 534
Cumulative Timesteps: 4,500,198

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 4500198...
Checkpoint 4500198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.59689
Policy Entropy: 1.35210
Value Function Loss: 0.43390

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.13122
Value Function Update Magnitude: 0.10372

Collected Steps per Second: 3,290.97474
Overall Steps per Second: 2,044.17539

Timestep Collection Time: 15.19367
Timestep Consumption Time: 9.26704
PPO Batch Consumption Time: 1.27736
Total Iteration Time: 24.46072

Cumulative Model Updates: 540
Cumulative Timesteps: 4,550,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.51485
Policy Entropy: 1.35238
Value Function Loss: 0.43347

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.13011
Value Function Update Magnitude: 0.10111

Collected Steps per Second: 3,262.19296
Overall Steps per Second: 2,025.95569

Timestep Collection Time: 15.32742
Timestep Consumption Time: 9.35278
PPO Batch Consumption Time: 1.29403
Total Iteration Time: 24.68020

Cumulative Model Updates: 546
Cumulative Timesteps: 4,600,201

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 4600201...
Checkpoint 4600201 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.51453
Policy Entropy: 1.35285
Value Function Loss: 0.43963

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.13447
Value Function Update Magnitude: 0.10947

Collected Steps per Second: 3,290.45297
Overall Steps per Second: 2,045.29573

Timestep Collection Time: 15.19608
Timestep Consumption Time: 9.25124
PPO Batch Consumption Time: 1.26549
Total Iteration Time: 24.44732

Cumulative Model Updates: 552
Cumulative Timesteps: 4,650,203

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.90881
Policy Entropy: 1.35784
Value Function Loss: 0.44465

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.13557
Value Function Update Magnitude: 0.11326

Collected Steps per Second: 3,262.90793
Overall Steps per Second: 2,022.83653

Timestep Collection Time: 15.32375
Timestep Consumption Time: 9.39401
PPO Batch Consumption Time: 1.28497
Total Iteration Time: 24.71777

Cumulative Model Updates: 558
Cumulative Timesteps: 4,700,203

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 4700203...
Checkpoint 4700203 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.59719
Policy Entropy: 1.34450
Value Function Loss: 0.44232

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.13200
Value Function Update Magnitude: 0.11653

Collected Steps per Second: 3,304.36556
Overall Steps per Second: 2,047.58536

Timestep Collection Time: 15.13301
Timestep Consumption Time: 9.28844
PPO Batch Consumption Time: 1.26970
Total Iteration Time: 24.42145

Cumulative Model Updates: 564
Cumulative Timesteps: 4,750,208

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.87945
Policy Entropy: 1.35880
Value Function Loss: 0.43234

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15628
Policy Update Magnitude: 0.14148
Value Function Update Magnitude: 0.10902

Collected Steps per Second: 3,271.09400
Overall Steps per Second: 2,037.54426

Timestep Collection Time: 15.28663
Timestep Consumption Time: 9.25468
PPO Batch Consumption Time: 1.27423
Total Iteration Time: 24.54131

Cumulative Model Updates: 570
Cumulative Timesteps: 4,800,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 4800212...
Checkpoint 4800212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.71152
Policy Entropy: 1.35346
Value Function Loss: 0.42363

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.14903
Value Function Update Magnitude: 0.10473

Collected Steps per Second: 3,272.18553
Overall Steps per Second: 2,036.87202

Timestep Collection Time: 15.28122
Timestep Consumption Time: 9.26769
PPO Batch Consumption Time: 1.28205
Total Iteration Time: 24.54892

Cumulative Model Updates: 576
Cumulative Timesteps: 4,850,215

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.11451
Policy Entropy: 1.36162
Value Function Loss: 0.41378

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.16500
Value Function Update Magnitude: 0.10023

Collected Steps per Second: 3,276.52750
Overall Steps per Second: 2,003.85628

Timestep Collection Time: 15.26036
Timestep Consumption Time: 9.69202
PPO Batch Consumption Time: 1.33955
Total Iteration Time: 24.95239

Cumulative Model Updates: 582
Cumulative Timesteps: 4,900,216

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 4900216...
Checkpoint 4900216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.92601
Policy Entropy: 1.36790
Value Function Loss: 0.41159

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15521
Policy Update Magnitude: 0.15504
Value Function Update Magnitude: 0.10642

Collected Steps per Second: 3,257.52981
Overall Steps per Second: 2,026.30324

Timestep Collection Time: 15.34936
Timestep Consumption Time: 9.32661
PPO Batch Consumption Time: 1.28783
Total Iteration Time: 24.67597

Cumulative Model Updates: 588
Cumulative Timesteps: 4,950,217

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.37595
Policy Entropy: 1.36426
Value Function Loss: 0.40893

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.14886
Value Function Update Magnitude: 0.10692

Collected Steps per Second: 3,277.60874
Overall Steps per Second: 2,038.94966

Timestep Collection Time: 15.25624
Timestep Consumption Time: 9.26815
PPO Batch Consumption Time: 1.27914
Total Iteration Time: 24.52439

Cumulative Model Updates: 594
Cumulative Timesteps: 5,000,221

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 5000221...
Checkpoint 5000221 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.67509
Policy Entropy: 1.36837
Value Function Loss: 0.41152

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.13486
Value Function Update Magnitude: 0.10159

Collected Steps per Second: 3,229.78623
Overall Steps per Second: 2,004.12163

Timestep Collection Time: 15.48245
Timestep Consumption Time: 9.46863
PPO Batch Consumption Time: 1.29392
Total Iteration Time: 24.95108

Cumulative Model Updates: 600
Cumulative Timesteps: 5,050,226

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.21757
Policy Entropy: 1.37019
Value Function Loss: 0.39872

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.14157
Value Function Update Magnitude: 0.10564

Collected Steps per Second: 3,285.19744
Overall Steps per Second: 2,020.93513

Timestep Collection Time: 15.21979
Timestep Consumption Time: 9.52124
PPO Batch Consumption Time: 1.30652
Total Iteration Time: 24.74102

Cumulative Model Updates: 606
Cumulative Timesteps: 5,100,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 5100226...
Checkpoint 5100226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.65493
Policy Entropy: 1.37675
Value Function Loss: 0.39567

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.15276
Value Function Update Magnitude: 0.10872

Collected Steps per Second: 3,275.38527
Overall Steps per Second: 2,018.20985

Timestep Collection Time: 15.26660
Timestep Consumption Time: 9.50981
PPO Batch Consumption Time: 1.29892
Total Iteration Time: 24.77641

Cumulative Model Updates: 612
Cumulative Timesteps: 5,150,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.60907
Policy Entropy: 1.37744
Value Function Loss: 0.39236

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.15672
Value Function Update Magnitude: 0.10115

Collected Steps per Second: 3,287.82199
Overall Steps per Second: 2,039.12812

Timestep Collection Time: 15.20764
Timestep Consumption Time: 9.31265
PPO Batch Consumption Time: 1.27436
Total Iteration Time: 24.52028

Cumulative Model Updates: 618
Cumulative Timesteps: 5,200,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 5200230...
Checkpoint 5200230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.54014
Policy Entropy: 1.37595
Value Function Loss: 0.40198

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.16690
Value Function Update Magnitude: 0.09906

Collected Steps per Second: 3,233.47775
Overall Steps per Second: 2,016.27473

Timestep Collection Time: 15.46385
Timestep Consumption Time: 9.33535
PPO Batch Consumption Time: 1.27705
Total Iteration Time: 24.79920

Cumulative Model Updates: 624
Cumulative Timesteps: 5,250,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.41334
Policy Entropy: 1.37590
Value Function Loss: 0.41042

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.16307
Value Function Update Magnitude: 0.10108

Collected Steps per Second: 3,280.52551
Overall Steps per Second: 2,029.80647

Timestep Collection Time: 15.24268
Timestep Consumption Time: 9.39218
PPO Batch Consumption Time: 1.26558
Total Iteration Time: 24.63486

Cumulative Model Updates: 630
Cumulative Timesteps: 5,300,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 5300236...
Checkpoint 5300236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.99973
Policy Entropy: 1.37186
Value Function Loss: 0.41490

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.13808
Value Function Update Magnitude: 0.10262

Collected Steps per Second: 3,319.63261
Overall Steps per Second: 2,022.88791

Timestep Collection Time: 15.06341
Timestep Consumption Time: 9.65620
PPO Batch Consumption Time: 1.32466
Total Iteration Time: 24.71961

Cumulative Model Updates: 636
Cumulative Timesteps: 5,350,241

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.28236
Policy Entropy: 1.37390
Value Function Loss: 0.41413

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.12125
Value Function Update Magnitude: 0.09925

Collected Steps per Second: 3,253.36277
Overall Steps per Second: 2,023.04895

Timestep Collection Time: 15.36994
Timestep Consumption Time: 9.34720
PPO Batch Consumption Time: 1.28932
Total Iteration Time: 24.71715

Cumulative Model Updates: 642
Cumulative Timesteps: 5,400,245

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 5400245...
Checkpoint 5400245 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.28435
Policy Entropy: 1.36924
Value Function Loss: 0.40980

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.11633
Value Function Update Magnitude: 0.09987

Collected Steps per Second: 3,302.43097
Overall Steps per Second: 2,041.36418

Timestep Collection Time: 15.14157
Timestep Consumption Time: 9.35381
PPO Batch Consumption Time: 1.27816
Total Iteration Time: 24.49538

Cumulative Model Updates: 648
Cumulative Timesteps: 5,450,249

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.39734
Policy Entropy: 1.37127
Value Function Loss: 0.40499

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.13408
Value Function Update Magnitude: 0.09935

Collected Steps per Second: 3,273.84504
Overall Steps per Second: 2,031.10121

Timestep Collection Time: 15.27317
Timestep Consumption Time: 9.34500
PPO Batch Consumption Time: 1.28580
Total Iteration Time: 24.61817

Cumulative Model Updates: 654
Cumulative Timesteps: 5,500,251

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 5500251...
Checkpoint 5500251 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.81873
Policy Entropy: 1.36658
Value Function Loss: 0.40825

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.12905
Value Function Update Magnitude: 0.10018

Collected Steps per Second: 3,293.08811
Overall Steps per Second: 2,040.56444

Timestep Collection Time: 15.18423
Timestep Consumption Time: 9.32027
PPO Batch Consumption Time: 1.25811
Total Iteration Time: 24.50449

Cumulative Model Updates: 660
Cumulative Timesteps: 5,550,254

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.50749
Policy Entropy: 1.37485
Value Function Loss: 0.41338

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.12083
Value Function Update Magnitude: 0.10191

Collected Steps per Second: 3,289.08132
Overall Steps per Second: 2,033.00877

Timestep Collection Time: 15.20303
Timestep Consumption Time: 9.39303
PPO Batch Consumption Time: 1.29896
Total Iteration Time: 24.59606

Cumulative Model Updates: 666
Cumulative Timesteps: 5,600,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 5600258...
Checkpoint 5600258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.95774
Policy Entropy: 1.36565
Value Function Loss: 0.41344

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.12731
Value Function Update Magnitude: 0.10113

Collected Steps per Second: 3,290.93068
Overall Steps per Second: 2,028.49315

Timestep Collection Time: 15.19418
Timestep Consumption Time: 9.45614
PPO Batch Consumption Time: 1.29373
Total Iteration Time: 24.65032

Cumulative Model Updates: 672
Cumulative Timesteps: 5,650,261

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.71095
Policy Entropy: 1.36953
Value Function Loss: 0.41335

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.12632
Value Function Update Magnitude: 0.10464

Collected Steps per Second: 3,262.58196
Overall Steps per Second: 2,022.59733

Timestep Collection Time: 15.32529
Timestep Consumption Time: 9.39540
PPO Batch Consumption Time: 1.30023
Total Iteration Time: 24.72069

Cumulative Model Updates: 678
Cumulative Timesteps: 5,700,261

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 5700261...
Checkpoint 5700261 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.84016
Policy Entropy: 1.36703
Value Function Loss: 0.41156

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.11167
Value Function Update Magnitude: 0.10402

Collected Steps per Second: 3,300.26784
Overall Steps per Second: 2,033.67765

Timestep Collection Time: 15.15089
Timestep Consumption Time: 9.43609
PPO Batch Consumption Time: 1.28411
Total Iteration Time: 24.58698

Cumulative Model Updates: 684
Cumulative Timesteps: 5,750,263

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.44863
Policy Entropy: 1.36375
Value Function Loss: 0.42686

Mean KL Divergence: 0.02663
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.11203
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 3,300.23124
Overall Steps per Second: 2,042.75452

Timestep Collection Time: 15.15045
Timestep Consumption Time: 9.32630
PPO Batch Consumption Time: 1.27620
Total Iteration Time: 24.47675

Cumulative Model Updates: 690
Cumulative Timesteps: 5,800,263

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 5800263...
Checkpoint 5800263 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.33977
Policy Entropy: 1.36438
Value Function Loss: 0.43017

Mean KL Divergence: 0.02559
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.09643
Value Function Update Magnitude: 0.10317

Collected Steps per Second: 3,274.42102
Overall Steps per Second: 2,030.40529

Timestep Collection Time: 15.26988
Timestep Consumption Time: 9.35575
PPO Batch Consumption Time: 1.27222
Total Iteration Time: 24.62563

Cumulative Model Updates: 696
Cumulative Timesteps: 5,850,263

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.93458
Policy Entropy: 1.36193
Value Function Loss: 0.42717

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.10094
Value Function Update Magnitude: 0.10275

Collected Steps per Second: 3,264.35891
Overall Steps per Second: 2,017.90322

Timestep Collection Time: 15.31786
Timestep Consumption Time: 9.46182
PPO Batch Consumption Time: 1.30334
Total Iteration Time: 24.77968

Cumulative Model Updates: 702
Cumulative Timesteps: 5,900,266

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 5900266...
Checkpoint 5900266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.99541
Policy Entropy: 1.36611
Value Function Loss: 0.41590

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.10606
Value Function Update Magnitude: 0.11318

Collected Steps per Second: 3,289.24919
Overall Steps per Second: 2,037.17703

Timestep Collection Time: 15.20225
Timestep Consumption Time: 9.34348
PPO Batch Consumption Time: 1.29061
Total Iteration Time: 24.54573

Cumulative Model Updates: 708
Cumulative Timesteps: 5,950,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.87007
Policy Entropy: 1.36268
Value Function Loss: 0.40983

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.10980
Value Function Update Magnitude: 0.11280

Collected Steps per Second: 3,312.21470
Overall Steps per Second: 2,045.97399

Timestep Collection Time: 15.09564
Timestep Consumption Time: 9.34260
PPO Batch Consumption Time: 1.27624
Total Iteration Time: 24.43824

Cumulative Model Updates: 714
Cumulative Timesteps: 6,000,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 6000270...
Checkpoint 6000270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.63844
Policy Entropy: 1.37549
Value Function Loss: 0.40687

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.13010
Value Function Update Magnitude: 0.10746

Collected Steps per Second: 3,280.67178
Overall Steps per Second: 2,035.61637

Timestep Collection Time: 15.24200
Timestep Consumption Time: 9.32255
PPO Batch Consumption Time: 1.27880
Total Iteration Time: 24.56455

Cumulative Model Updates: 720
Cumulative Timesteps: 6,050,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.43117
Policy Entropy: 1.37611
Value Function Loss: 0.40654

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.14208
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 3,247.11739
Overall Steps per Second: 2,032.52380

Timestep Collection Time: 15.39920
Timestep Consumption Time: 9.20224
PPO Batch Consumption Time: 1.26610
Total Iteration Time: 24.60143

Cumulative Model Updates: 726
Cumulative Timesteps: 6,100,277

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 6100277...
Checkpoint 6100277 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.12855
Policy Entropy: 1.37849
Value Function Loss: 0.40786

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.14926
Value Function Update Magnitude: 0.10154

Collected Steps per Second: 3,273.51527
Overall Steps per Second: 2,026.68220

Timestep Collection Time: 15.27471
Timestep Consumption Time: 9.39714
PPO Batch Consumption Time: 1.27385
Total Iteration Time: 24.67185

Cumulative Model Updates: 732
Cumulative Timesteps: 6,150,279

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.71658
Policy Entropy: 1.37812
Value Function Loss: 0.40121

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.15207
Value Function Update Magnitude: 0.10634

Collected Steps per Second: 3,311.48495
Overall Steps per Second: 2,030.78951

Timestep Collection Time: 15.10048
Timestep Consumption Time: 9.52295
PPO Batch Consumption Time: 1.29464
Total Iteration Time: 24.62343

Cumulative Model Updates: 738
Cumulative Timesteps: 6,200,284

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 6200284...
Checkpoint 6200284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.51676
Policy Entropy: 1.37987
Value Function Loss: 0.39094

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.13622
Value Function Update Magnitude: 0.10239

Collected Steps per Second: 3,301.93929
Overall Steps per Second: 2,042.72014

Timestep Collection Time: 15.14322
Timestep Consumption Time: 9.33492
PPO Batch Consumption Time: 1.27543
Total Iteration Time: 24.47815

Cumulative Model Updates: 744
Cumulative Timesteps: 6,250,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.63246
Policy Entropy: 1.37460
Value Function Loss: 0.38604

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.12576
Value Function Update Magnitude: 0.10590

Collected Steps per Second: 3,305.85382
Overall Steps per Second: 2,048.52717

Timestep Collection Time: 15.12469
Timestep Consumption Time: 9.28309
PPO Batch Consumption Time: 1.26584
Total Iteration Time: 24.40778

Cumulative Model Updates: 750
Cumulative Timesteps: 6,300,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 6300286...
Checkpoint 6300286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.39208
Policy Entropy: 1.37282
Value Function Loss: 0.39074

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.10709
Value Function Update Magnitude: 0.10735

Collected Steps per Second: 3,284.03375
Overall Steps per Second: 2,036.04227

Timestep Collection Time: 15.22609
Timestep Consumption Time: 9.33283
PPO Batch Consumption Time: 1.28087
Total Iteration Time: 24.55892

Cumulative Model Updates: 756
Cumulative Timesteps: 6,350,289

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.97550
Policy Entropy: 1.38569
Value Function Loss: 0.39000

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.09009
Value Function Update Magnitude: 0.10224

Collected Steps per Second: 3,330.89373
Overall Steps per Second: 2,041.99440

Timestep Collection Time: 15.01189
Timestep Consumption Time: 9.47545
PPO Batch Consumption Time: 1.27473
Total Iteration Time: 24.48733

Cumulative Model Updates: 762
Cumulative Timesteps: 6,400,292

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 6400292...
Checkpoint 6400292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.32975
Policy Entropy: 1.39154
Value Function Loss: 0.38518

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.10633
Value Function Update Magnitude: 0.09692

Collected Steps per Second: 3,326.41554
Overall Steps per Second: 2,044.85065

Timestep Collection Time: 15.03119
Timestep Consumption Time: 9.42047
PPO Batch Consumption Time: 1.30374
Total Iteration Time: 24.45166

Cumulative Model Updates: 768
Cumulative Timesteps: 6,450,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.04150
Policy Entropy: 1.39334
Value Function Loss: 0.37935

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.04235
Policy Update Magnitude: 0.11289
Value Function Update Magnitude: 0.10335

Collected Steps per Second: 3,305.50234
Overall Steps per Second: 2,045.84135

Timestep Collection Time: 15.12690
Timestep Consumption Time: 9.31390
PPO Batch Consumption Time: 1.27916
Total Iteration Time: 24.44080

Cumulative Model Updates: 774
Cumulative Timesteps: 6,500,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 6500294...
Checkpoint 6500294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.30345
Policy Entropy: 1.39239
Value Function Loss: 0.37238

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.12141
Value Function Update Magnitude: 0.10215

Collected Steps per Second: 3,250.40306
Overall Steps per Second: 2,030.26578

Timestep Collection Time: 15.38363
Timestep Consumption Time: 9.24516
PPO Batch Consumption Time: 1.26722
Total Iteration Time: 24.62880

Cumulative Model Updates: 780
Cumulative Timesteps: 6,550,297

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.22173
Policy Entropy: 1.39337
Value Function Loss: 0.36457

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.04392
Policy Update Magnitude: 0.13440
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 3,225.98523
Overall Steps per Second: 2,017.57815

Timestep Collection Time: 15.49976
Timestep Consumption Time: 9.28342
PPO Batch Consumption Time: 1.28455
Total Iteration Time: 24.78318

Cumulative Model Updates: 786
Cumulative Timesteps: 6,600,299

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 6600299...
Checkpoint 6600299 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.81174
Policy Entropy: 1.39444
Value Function Loss: 0.36017

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03835
Policy Update Magnitude: 0.12394
Value Function Update Magnitude: 0.09426

Collected Steps per Second: 3,314.21357
Overall Steps per Second: 2,044.24662

Timestep Collection Time: 15.08744
Timestep Consumption Time: 9.37292
PPO Batch Consumption Time: 1.27880
Total Iteration Time: 24.46036

Cumulative Model Updates: 792
Cumulative Timesteps: 6,650,302

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.03108
Policy Entropy: 1.39687
Value Function Loss: 0.35828

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03194
Policy Update Magnitude: 0.12379
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 3,315.02237
Overall Steps per Second: 2,034.30069

Timestep Collection Time: 15.08346
Timestep Consumption Time: 9.49600
PPO Batch Consumption Time: 1.30574
Total Iteration Time: 24.57945

Cumulative Model Updates: 798
Cumulative Timesteps: 6,700,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 6700304...
Checkpoint 6700304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.37227
Policy Entropy: 1.39601
Value Function Loss: 0.37036

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 0.12341
Value Function Update Magnitude: 0.10473

Collected Steps per Second: 3,295.51212
Overall Steps per Second: 2,027.80869

Timestep Collection Time: 15.17276
Timestep Consumption Time: 9.48539
PPO Batch Consumption Time: 1.28848
Total Iteration Time: 24.65814

Cumulative Model Updates: 804
Cumulative Timesteps: 6,750,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.16942
Policy Entropy: 1.39549
Value Function Loss: 0.36733

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.04188
Policy Update Magnitude: 0.12111
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 3,240.49120
Overall Steps per Second: 2,031.68515

Timestep Collection Time: 15.43069
Timestep Consumption Time: 9.18090
PPO Batch Consumption Time: 1.26860
Total Iteration Time: 24.61159

Cumulative Model Updates: 810
Cumulative Timesteps: 6,800,309

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 6800309...
Checkpoint 6800309 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.67383
Policy Entropy: 1.39735
Value Function Loss: 0.37263

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.04313
Policy Update Magnitude: 0.11224
Value Function Update Magnitude: 0.10679

Collected Steps per Second: 3,264.93774
Overall Steps per Second: 2,034.43814

Timestep Collection Time: 15.31453
Timestep Consumption Time: 9.26277
PPO Batch Consumption Time: 1.27069
Total Iteration Time: 24.57730

Cumulative Model Updates: 816
Cumulative Timesteps: 6,850,310

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.34975
Policy Entropy: 1.39826
Value Function Loss: 0.35767

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.03888
Policy Update Magnitude: 0.11937
Value Function Update Magnitude: 0.10244

Collected Steps per Second: 3,288.80773
Overall Steps per Second: 2,034.05166

Timestep Collection Time: 15.20369
Timestep Consumption Time: 9.37878
PPO Batch Consumption Time: 1.26555
Total Iteration Time: 24.58246

Cumulative Model Updates: 822
Cumulative Timesteps: 6,900,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 6900312...
Checkpoint 6900312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.93132
Policy Entropy: 1.39674
Value Function Loss: 0.35183

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.03255
Policy Update Magnitude: 0.11308
Value Function Update Magnitude: 0.10210

Collected Steps per Second: 3,330.37117
Overall Steps per Second: 2,050.92808

Timestep Collection Time: 15.01424
Timestep Consumption Time: 9.36643
PPO Batch Consumption Time: 1.28989
Total Iteration Time: 24.38067

Cumulative Model Updates: 828
Cumulative Timesteps: 6,950,315

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.14457
Policy Entropy: 1.39829
Value Function Loss: 0.35186

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.04283
Policy Update Magnitude: 0.11391
Value Function Update Magnitude: 0.10124

Collected Steps per Second: 3,291.22124
Overall Steps per Second: 2,031.77984

Timestep Collection Time: 15.19284
Timestep Consumption Time: 9.41760
PPO Batch Consumption Time: 1.29249
Total Iteration Time: 24.61044

Cumulative Model Updates: 834
Cumulative Timesteps: 7,000,318

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 7000318...
Checkpoint 7000318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.67068
Policy Entropy: 1.40059
Value Function Loss: 0.35140

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.04089
Policy Update Magnitude: 0.11316
Value Function Update Magnitude: 0.11960

Collected Steps per Second: 3,303.87158
Overall Steps per Second: 2,044.92369

Timestep Collection Time: 15.13437
Timestep Consumption Time: 9.31740
PPO Batch Consumption Time: 1.26297
Total Iteration Time: 24.45177

Cumulative Model Updates: 840
Cumulative Timesteps: 7,050,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.51577
Policy Entropy: 1.40213
Value Function Loss: 0.34804

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 0.11190
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 3,259.41449
Overall Steps per Second: 2,027.51229

Timestep Collection Time: 15.34141
Timestep Consumption Time: 9.32133
PPO Batch Consumption Time: 1.29348
Total Iteration Time: 24.66274

Cumulative Model Updates: 846
Cumulative Timesteps: 7,100,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 7100324...
Checkpoint 7100324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.58678
Policy Entropy: 1.40347
Value Function Loss: 0.33365

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 0.11477
Value Function Update Magnitude: 0.10652

Collected Steps per Second: 3,319.72077
Overall Steps per Second: 2,008.13731

Timestep Collection Time: 15.06211
Timestep Consumption Time: 9.83758
PPO Batch Consumption Time: 1.35365
Total Iteration Time: 24.89969

Cumulative Model Updates: 852
Cumulative Timesteps: 7,150,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.13373
Policy Entropy: 1.40216
Value Function Loss: 0.32939

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.03312
Policy Update Magnitude: 0.10640
Value Function Update Magnitude: 0.10097

Collected Steps per Second: 3,286.39387
Overall Steps per Second: 2,038.44330

Timestep Collection Time: 15.21516
Timestep Consumption Time: 9.31484
PPO Batch Consumption Time: 1.27505
Total Iteration Time: 24.52999

Cumulative Model Updates: 858
Cumulative Timesteps: 7,200,329

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 7200329...
Checkpoint 7200329 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.01887
Policy Entropy: 1.40336
Value Function Loss: 0.32497

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.11074
Value Function Update Magnitude: 0.10457

Collected Steps per Second: 3,280.88218
Overall Steps per Second: 2,023.01610

Timestep Collection Time: 15.23980
Timestep Consumption Time: 9.47577
PPO Batch Consumption Time: 1.30589
Total Iteration Time: 24.71557

Cumulative Model Updates: 864
Cumulative Timesteps: 7,250,329

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.42394
Policy Entropy: 1.40365
Value Function Loss: 0.32181

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.11176
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 3,327.92834
Overall Steps per Second: 2,050.00482

Timestep Collection Time: 15.02556
Timestep Consumption Time: 9.36657
PPO Batch Consumption Time: 1.27659
Total Iteration Time: 24.39214

Cumulative Model Updates: 870
Cumulative Timesteps: 7,300,333

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 7300333...
Checkpoint 7300333 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.67235
Policy Entropy: 1.40436
Value Function Loss: 0.32023

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.10430
Value Function Update Magnitude: 0.10108

Collected Steps per Second: 3,315.78523
Overall Steps per Second: 2,047.66953

Timestep Collection Time: 15.07938
Timestep Consumption Time: 9.33862
PPO Batch Consumption Time: 1.28224
Total Iteration Time: 24.41800

Cumulative Model Updates: 876
Cumulative Timesteps: 7,350,333

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.47094
Policy Entropy: 1.40419
Value Function Loss: 0.31861

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01499
Policy Update Magnitude: 0.10375
Value Function Update Magnitude: 0.10225

Collected Steps per Second: 3,283.89625
Overall Steps per Second: 2,039.77966

Timestep Collection Time: 15.22582
Timestep Consumption Time: 9.28664
PPO Batch Consumption Time: 1.27066
Total Iteration Time: 24.51245

Cumulative Model Updates: 882
Cumulative Timesteps: 7,400,333

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 7400333...
Checkpoint 7400333 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.44404
Policy Entropy: 1.40345
Value Function Loss: 0.32268

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02166
Policy Update Magnitude: 0.09533
Value Function Update Magnitude: 0.10730

Collected Steps per Second: 3,293.17770
Overall Steps per Second: 2,039.48445

Timestep Collection Time: 15.18381
Timestep Consumption Time: 9.33366
PPO Batch Consumption Time: 1.28569
Total Iteration Time: 24.51747

Cumulative Model Updates: 888
Cumulative Timesteps: 7,450,336

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.49945
Policy Entropy: 1.40367
Value Function Loss: 0.32262

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.08651
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 3,307.63012
Overall Steps per Second: 2,030.13229

Timestep Collection Time: 15.11687
Timestep Consumption Time: 9.51256
PPO Batch Consumption Time: 1.30196
Total Iteration Time: 24.62943

Cumulative Model Updates: 894
Cumulative Timesteps: 7,500,337

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 7500337...
Checkpoint 7500337 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.12642
Policy Entropy: 1.40359
Value Function Loss: 0.32485

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01754
Policy Update Magnitude: 0.09230
Value Function Update Magnitude: 0.10382

Collected Steps per Second: 3,313.05390
Overall Steps per Second: 2,060.23952

Timestep Collection Time: 15.09242
Timestep Consumption Time: 9.17757
PPO Batch Consumption Time: 1.26629
Total Iteration Time: 24.26999

Cumulative Model Updates: 900
Cumulative Timesteps: 7,550,339

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.15909
Policy Entropy: 1.40442
Value Function Loss: 0.31751

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01880
Policy Update Magnitude: 0.09415
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 3,253.53045
Overall Steps per Second: 2,024.02924

Timestep Collection Time: 15.36823
Timestep Consumption Time: 9.33547
PPO Batch Consumption Time: 1.28956
Total Iteration Time: 24.70369

Cumulative Model Updates: 906
Cumulative Timesteps: 7,600,340

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 7600340...
Checkpoint 7600340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.30595
Policy Entropy: 1.40228
Value Function Loss: 0.31806

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.09742
Value Function Update Magnitude: 0.09769

Collected Steps per Second: 3,298.11142
Overall Steps per Second: 2,047.78237

Timestep Collection Time: 15.16049
Timestep Consumption Time: 9.25665
PPO Batch Consumption Time: 1.27077
Total Iteration Time: 24.41715

Cumulative Model Updates: 912
Cumulative Timesteps: 7,650,341

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.85211
Policy Entropy: 1.40395
Value Function Loss: 0.30540

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.09395
Value Function Update Magnitude: 0.09606

Collected Steps per Second: 3,310.18933
Overall Steps per Second: 2,042.30982

Timestep Collection Time: 15.10578
Timestep Consumption Time: 9.37777
PPO Batch Consumption Time: 1.28139
Total Iteration Time: 24.48355

Cumulative Model Updates: 918
Cumulative Timesteps: 7,700,344

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 7700344...
Checkpoint 7700344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.18280
Policy Entropy: 1.40336
Value Function Loss: 0.29946

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.09343
Value Function Update Magnitude: 0.09931

Collected Steps per Second: 3,295.69099
Overall Steps per Second: 2,037.57983

Timestep Collection Time: 15.17284
Timestep Consumption Time: 9.36853
PPO Batch Consumption Time: 1.27935
Total Iteration Time: 24.54137

Cumulative Model Updates: 924
Cumulative Timesteps: 7,750,349

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.41178
Policy Entropy: 1.40394
Value Function Loss: 0.28911

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.09176
Value Function Update Magnitude: 0.09716

Collected Steps per Second: 3,288.22570
Overall Steps per Second: 2,040.10950

Timestep Collection Time: 15.20638
Timestep Consumption Time: 9.30309
PPO Batch Consumption Time: 1.27772
Total Iteration Time: 24.50947

Cumulative Model Updates: 930
Cumulative Timesteps: 7,800,351

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 7800351...
Checkpoint 7800351 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.92534
Policy Entropy: 1.40282
Value Function Loss: 0.29333

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.08794
Value Function Update Magnitude: 0.08820

Collected Steps per Second: 3,279.06515
Overall Steps per Second: 2,037.86840

Timestep Collection Time: 15.24947
Timestep Consumption Time: 9.28794
PPO Batch Consumption Time: 1.27178
Total Iteration Time: 24.53740

Cumulative Model Updates: 936
Cumulative Timesteps: 7,850,355

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.25851
Policy Entropy: 1.40345
Value Function Loss: 0.29270

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.03285
Policy Update Magnitude: 0.08023
Value Function Update Magnitude: 0.09055

Collected Steps per Second: 3,299.32190
Overall Steps per Second: 2,045.52014

Timestep Collection Time: 15.15493
Timestep Consumption Time: 9.28922
PPO Batch Consumption Time: 1.27445
Total Iteration Time: 24.44415

Cumulative Model Updates: 942
Cumulative Timesteps: 7,900,356

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 7900356...
Checkpoint 7900356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.27871
Policy Entropy: 1.40381
Value Function Loss: 0.29795

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.08086
Value Function Update Magnitude: 0.09756

Collected Steps per Second: 3,303.68841
Overall Steps per Second: 2,048.58240

Timestep Collection Time: 15.13551
Timestep Consumption Time: 9.27308
PPO Batch Consumption Time: 1.25696
Total Iteration Time: 24.40859

Cumulative Model Updates: 948
Cumulative Timesteps: 7,950,359

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.07670
Policy Entropy: 1.40236
Value Function Loss: 0.29898

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.03881
Policy Update Magnitude: 0.08234
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 3,273.08966
Overall Steps per Second: 2,021.04517

Timestep Collection Time: 15.27670
Timestep Consumption Time: 9.46397
PPO Batch Consumption Time: 1.29765
Total Iteration Time: 24.74066

Cumulative Model Updates: 954
Cumulative Timesteps: 8,000,361

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 8000361...
Checkpoint 8000361 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.33746
Policy Entropy: 1.40163
Value Function Loss: 0.30666

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.03873
Policy Update Magnitude: 0.07883
Value Function Update Magnitude: 0.09821

Collected Steps per Second: 3,320.19060
Overall Steps per Second: 2,057.53724

Timestep Collection Time: 15.05998
Timestep Consumption Time: 9.24189
PPO Batch Consumption Time: 1.25970
Total Iteration Time: 24.30187

Cumulative Model Updates: 960
Cumulative Timesteps: 8,050,363

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.36280
Policy Entropy: 1.40229
Value Function Loss: 0.30893

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 0.07713
Value Function Update Magnitude: 0.10319

Collected Steps per Second: 3,305.23305
Overall Steps per Second: 2,042.65706

Timestep Collection Time: 15.12843
Timestep Consumption Time: 9.35096
PPO Batch Consumption Time: 1.27564
Total Iteration Time: 24.47939

Cumulative Model Updates: 966
Cumulative Timesteps: 8,100,366

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 8100366...
Checkpoint 8100366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.77550
Policy Entropy: 1.40149
Value Function Loss: 0.31247

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.08182
Value Function Update Magnitude: 0.11658

Collected Steps per Second: 3,334.60181
Overall Steps per Second: 2,056.62312

Timestep Collection Time: 14.99489
Timestep Consumption Time: 9.31778
PPO Batch Consumption Time: 1.26347
Total Iteration Time: 24.31267

Cumulative Model Updates: 972
Cumulative Timesteps: 8,150,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.58902
Policy Entropy: 1.40181
Value Function Loss: 0.31421

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.02629
Policy Update Magnitude: 0.08602
Value Function Update Magnitude: 0.11449

Collected Steps per Second: 3,286.96921
Overall Steps per Second: 2,045.36572

Timestep Collection Time: 15.21249
Timestep Consumption Time: 9.23448
PPO Batch Consumption Time: 1.26480
Total Iteration Time: 24.44697

Cumulative Model Updates: 978
Cumulative Timesteps: 8,200,371

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 8200371...
Checkpoint 8200371 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.94064
Policy Entropy: 1.40250
Value Function Loss: 0.31289

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.08090
Value Function Update Magnitude: 0.11105

Collected Steps per Second: 3,272.41113
Overall Steps per Second: 2,021.98178

Timestep Collection Time: 15.27986
Timestep Consumption Time: 9.44934
PPO Batch Consumption Time: 1.29907
Total Iteration Time: 24.72920

Cumulative Model Updates: 984
Cumulative Timesteps: 8,250,373

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.39564
Policy Entropy: 1.40188
Value Function Loss: 0.31875

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.07778
Value Function Update Magnitude: 0.10898

Collected Steps per Second: 3,300.31953
Overall Steps per Second: 2,048.26185

Timestep Collection Time: 15.15065
Timestep Consumption Time: 9.26126
PPO Batch Consumption Time: 1.27343
Total Iteration Time: 24.41192

Cumulative Model Updates: 990
Cumulative Timesteps: 8,300,375

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 8300375...
Checkpoint 8300375 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.10240
Policy Entropy: 1.40272
Value Function Loss: 0.31498

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.07892
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 3,316.97212
Overall Steps per Second: 2,047.32701

Timestep Collection Time: 15.07459
Timestep Consumption Time: 9.34847
PPO Batch Consumption Time: 1.27750
Total Iteration Time: 24.42306

Cumulative Model Updates: 996
Cumulative Timesteps: 8,350,377

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.01651
Policy Entropy: 1.39999
Value Function Loss: 0.31355

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.02976
Policy Update Magnitude: 0.08089
Value Function Update Magnitude: 0.11294

Collected Steps per Second: 3,318.52995
Overall Steps per Second: 2,056.68847

Timestep Collection Time: 15.06721
Timestep Consumption Time: 9.24420
PPO Batch Consumption Time: 1.27506
Total Iteration Time: 24.31141

Cumulative Model Updates: 1,002
Cumulative Timesteps: 8,400,378

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 8400378...
Checkpoint 8400378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.44391
Policy Entropy: 1.40343
Value Function Loss: 0.30685

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.07703
Value Function Update Magnitude: 0.11107

Collected Steps per Second: 3,298.13113
Overall Steps per Second: 2,043.76606

Timestep Collection Time: 15.16040
Timestep Consumption Time: 9.30472
PPO Batch Consumption Time: 1.26107
Total Iteration Time: 24.46513

Cumulative Model Updates: 1,008
Cumulative Timesteps: 8,450,379

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.77384
Policy Entropy: 1.40317
Value Function Loss: 0.30340

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.07766
Value Function Update Magnitude: 0.11543

Collected Steps per Second: 3,299.13728
Overall Steps per Second: 2,035.72257

Timestep Collection Time: 15.15639
Timestep Consumption Time: 9.40639
PPO Batch Consumption Time: 1.29379
Total Iteration Time: 24.56278

Cumulative Model Updates: 1,014
Cumulative Timesteps: 8,500,382

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 8500382...
Checkpoint 8500382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.93265
Policy Entropy: 1.40130
Value Function Loss: 0.30181

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.07305
Value Function Update Magnitude: 0.10483

Collected Steps per Second: 3,190.26991
Overall Steps per Second: 1,987.14391

Timestep Collection Time: 15.67391
Timestep Consumption Time: 9.48984
PPO Batch Consumption Time: 1.31470
Total Iteration Time: 25.16375

Cumulative Model Updates: 1,020
Cumulative Timesteps: 8,550,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.75077
Policy Entropy: 1.40122
Value Function Loss: 0.30759

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01770
Policy Update Magnitude: 0.07722
Value Function Update Magnitude: 0.09818

Collected Steps per Second: 3,289.63201
Overall Steps per Second: 2,040.54979

Timestep Collection Time: 15.19988
Timestep Consumption Time: 9.30430
PPO Batch Consumption Time: 1.27085
Total Iteration Time: 24.50418

Cumulative Model Updates: 1,026
Cumulative Timesteps: 8,600,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 8600388...
Checkpoint 8600388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.79768
Policy Entropy: 1.40130
Value Function Loss: 0.31708

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.07544
Value Function Update Magnitude: 0.09979

Collected Steps per Second: 3,265.49143
Overall Steps per Second: 2,033.27979

Timestep Collection Time: 15.31194
Timestep Consumption Time: 9.27937
PPO Batch Consumption Time: 1.26293
Total Iteration Time: 24.59130

Cumulative Model Updates: 1,032
Cumulative Timesteps: 8,650,389

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.23738
Policy Entropy: 1.40007
Value Function Loss: 0.32735

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.07592
Value Function Update Magnitude: 0.11477

Collected Steps per Second: 3,273.54006
Overall Steps per Second: 2,035.33205

Timestep Collection Time: 15.27521
Timestep Consumption Time: 9.29277
PPO Batch Consumption Time: 1.27904
Total Iteration Time: 24.56798

Cumulative Model Updates: 1,038
Cumulative Timesteps: 8,700,393

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 8700393...
Checkpoint 8700393 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.81614
Policy Entropy: 1.39636
Value Function Loss: 0.32898

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.08360
Value Function Update Magnitude: 0.12521

Collected Steps per Second: 3,300.35694
Overall Steps per Second: 2,044.69670

Timestep Collection Time: 15.15018
Timestep Consumption Time: 9.30381
PPO Batch Consumption Time: 1.27821
Total Iteration Time: 24.45399

Cumulative Model Updates: 1,044
Cumulative Timesteps: 8,750,394

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.64879
Policy Entropy: 1.39498
Value Function Loss: 0.32987

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 0.07826
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 3,325.15136
Overall Steps per Second: 2,043.21176

Timestep Collection Time: 15.03691
Timestep Consumption Time: 9.43437
PPO Batch Consumption Time: 1.29866
Total Iteration Time: 24.47128

Cumulative Model Updates: 1,050
Cumulative Timesteps: 8,800,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 8800394...
Checkpoint 8800394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.60407
Policy Entropy: 1.39483
Value Function Loss: 0.32899

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 0.07360
Value Function Update Magnitude: 0.11159

Collected Steps per Second: 3,328.34031
Overall Steps per Second: 2,050.82378

Timestep Collection Time: 15.02370
Timestep Consumption Time: 9.35869
PPO Batch Consumption Time: 1.25685
Total Iteration Time: 24.38240

Cumulative Model Updates: 1,056
Cumulative Timesteps: 8,850,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.28660
Policy Entropy: 1.39716
Value Function Loss: 0.32545

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.08052
Value Function Update Magnitude: 0.10235

Collected Steps per Second: 3,298.86602
Overall Steps per Second: 2,036.85826

Timestep Collection Time: 15.15703
Timestep Consumption Time: 9.39107
PPO Batch Consumption Time: 1.30134
Total Iteration Time: 24.54810

Cumulative Model Updates: 1,062
Cumulative Timesteps: 8,900,399

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 8900399...
Checkpoint 8900399 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.20261
Policy Entropy: 1.39673
Value Function Loss: 0.32741

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.08059
Value Function Update Magnitude: 0.09851

Collected Steps per Second: 3,268.13636
Overall Steps per Second: 2,012.54457

Timestep Collection Time: 15.29985
Timestep Consumption Time: 9.54531
PPO Batch Consumption Time: 1.31851
Total Iteration Time: 24.84516

Cumulative Model Updates: 1,068
Cumulative Timesteps: 8,950,401

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.35427
Policy Entropy: 1.39453
Value Function Loss: 0.32639

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 0.08615
Value Function Update Magnitude: 0.09785

Collected Steps per Second: 3,272.28523
Overall Steps per Second: 2,029.93633

Timestep Collection Time: 15.27984
Timestep Consumption Time: 9.35147
PPO Batch Consumption Time: 1.27911
Total Iteration Time: 24.63131

Cumulative Model Updates: 1,074
Cumulative Timesteps: 9,000,401

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 9000401...
Checkpoint 9000401 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.30718
Policy Entropy: 1.39351
Value Function Loss: 0.32791

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 0.08255
Value Function Update Magnitude: 0.09267

Collected Steps per Second: 3,309.97264
Overall Steps per Second: 2,041.13966

Timestep Collection Time: 15.10647
Timestep Consumption Time: 9.39063
PPO Batch Consumption Time: 1.28938
Total Iteration Time: 24.49710

Cumulative Model Updates: 1,080
Cumulative Timesteps: 9,050,403

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.50764
Policy Entropy: 1.39680
Value Function Loss: 0.32470

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.04386
Policy Update Magnitude: 0.08045
Value Function Update Magnitude: 0.09497

Collected Steps per Second: 3,293.06052
Overall Steps per Second: 2,044.55952

Timestep Collection Time: 15.18435
Timestep Consumption Time: 9.27226
PPO Batch Consumption Time: 1.26361
Total Iteration Time: 24.45661

Cumulative Model Updates: 1,086
Cumulative Timesteps: 9,100,406

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 9100406...
Checkpoint 9100406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.10020
Policy Entropy: 1.39737
Value Function Loss: 0.32241

Mean KL Divergence: 0.03241
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.08430
Value Function Update Magnitude: 0.10723

Collected Steps per Second: 3,312.30006
Overall Steps per Second: 2,048.48545

Timestep Collection Time: 15.09646
Timestep Consumption Time: 9.31377
PPO Batch Consumption Time: 1.27922
Total Iteration Time: 24.41023

Cumulative Model Updates: 1,092
Cumulative Timesteps: 9,150,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.93662
Policy Entropy: 1.38938
Value Function Loss: 0.32521

Mean KL Divergence: 0.05864
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.06761
Value Function Update Magnitude: 0.10678

Collected Steps per Second: 3,293.73726
Overall Steps per Second: 2,033.45889

Timestep Collection Time: 15.18093
Timestep Consumption Time: 9.40870
PPO Batch Consumption Time: 1.27349
Total Iteration Time: 24.58963

Cumulative Model Updates: 1,098
Cumulative Timesteps: 9,200,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 9200412...
Checkpoint 9200412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.47532
Policy Entropy: 1.40398
Value Function Loss: 0.32170

Mean KL Divergence: 0.02775
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.08481
Value Function Update Magnitude: 0.09852

Collected Steps per Second: 3,316.22550
Overall Steps per Second: 2,059.76551

Timestep Collection Time: 15.07738
Timestep Consumption Time: 9.19723
PPO Batch Consumption Time: 1.25599
Total Iteration Time: 24.27461

Cumulative Model Updates: 1,104
Cumulative Timesteps: 9,250,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.55974
Policy Entropy: 1.40680
Value Function Loss: 0.32313

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.08593
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 3,278.88318
Overall Steps per Second: 2,029.29132

Timestep Collection Time: 15.25031
Timestep Consumption Time: 9.39080
PPO Batch Consumption Time: 1.29255
Total Iteration Time: 24.64111

Cumulative Model Updates: 1,110
Cumulative Timesteps: 9,300,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 9300416...
Checkpoint 9300416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.38806
Policy Entropy: 1.40790
Value Function Loss: 0.32273

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.07625
Value Function Update Magnitude: 0.10563

Collected Steps per Second: 3,327.18753
Overall Steps per Second: 2,056.52923

Timestep Collection Time: 15.02891
Timestep Consumption Time: 9.28584
PPO Batch Consumption Time: 1.26996
Total Iteration Time: 24.31475

Cumulative Model Updates: 1,116
Cumulative Timesteps: 9,350,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.85008
Policy Entropy: 1.40719
Value Function Loss: 0.32236

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01963
Policy Update Magnitude: 0.07408
Value Function Update Magnitude: 0.10082

Collected Steps per Second: 3,337.20155
Overall Steps per Second: 2,052.40150

Timestep Collection Time: 14.98381
Timestep Consumption Time: 9.37984
PPO Batch Consumption Time: 1.27509
Total Iteration Time: 24.36365

Cumulative Model Updates: 1,122
Cumulative Timesteps: 9,400,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 9400424...
Checkpoint 9400424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.75954
Policy Entropy: 1.40557
Value Function Loss: 0.32008

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02070
Policy Update Magnitude: 0.07487
Value Function Update Magnitude: 0.10190

Collected Steps per Second: 3,314.15640
Overall Steps per Second: 2,056.92283

Timestep Collection Time: 15.08710
Timestep Consumption Time: 9.22154
PPO Batch Consumption Time: 1.25367
Total Iteration Time: 24.30864

Cumulative Model Updates: 1,128
Cumulative Timesteps: 9,450,425

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.19142
Policy Entropy: 1.40562
Value Function Loss: 0.32608

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.07515
Value Function Update Magnitude: 0.09970

Collected Steps per Second: 3,260.85379
Overall Steps per Second: 2,031.97917

Timestep Collection Time: 15.33341
Timestep Consumption Time: 9.27314
PPO Batch Consumption Time: 1.27333
Total Iteration Time: 24.60655

Cumulative Model Updates: 1,134
Cumulative Timesteps: 9,500,425

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 9500425...
Checkpoint 9500425 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.99781
Policy Entropy: 1.40572
Value Function Loss: 0.32889

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01673
Policy Update Magnitude: 0.07640
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 3,302.67003
Overall Steps per Second: 2,040.28922

Timestep Collection Time: 15.14048
Timestep Consumption Time: 9.36781
PPO Batch Consumption Time: 1.27837
Total Iteration Time: 24.50829

Cumulative Model Updates: 1,140
Cumulative Timesteps: 9,550,429

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.88203
Policy Entropy: 1.40566
Value Function Loss: 0.33257

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.08019
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 3,338.09519
Overall Steps per Second: 2,054.45919

Timestep Collection Time: 14.97890
Timestep Consumption Time: 9.35889
PPO Batch Consumption Time: 1.27013
Total Iteration Time: 24.33779

Cumulative Model Updates: 1,146
Cumulative Timesteps: 9,600,430

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 9600430...
Checkpoint 9600430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.37964
Policy Entropy: 1.40640
Value Function Loss: 0.32909

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.07718
Value Function Update Magnitude: 0.10641

Collected Steps per Second: 3,282.27036
Overall Steps per Second: 2,043.03895

Timestep Collection Time: 15.23397
Timestep Consumption Time: 9.24036
PPO Batch Consumption Time: 1.26557
Total Iteration Time: 24.47433

Cumulative Model Updates: 1,152
Cumulative Timesteps: 9,650,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.01607
Policy Entropy: 1.40435
Value Function Loss: 0.33381

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.03203
Policy Update Magnitude: 0.07505
Value Function Update Magnitude: 0.10763

Collected Steps per Second: 3,232.91836
Overall Steps per Second: 2,017.19983

Timestep Collection Time: 15.46683
Timestep Consumption Time: 9.32149
PPO Batch Consumption Time: 1.28705
Total Iteration Time: 24.78832

Cumulative Model Updates: 1,158
Cumulative Timesteps: 9,700,435

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 9700435...
Checkpoint 9700435 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.45362
Policy Entropy: 1.40328
Value Function Loss: 0.33237

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 0.07546
Value Function Update Magnitude: 0.10464

Collected Steps per Second: 3,306.30065
Overall Steps per Second: 2,041.48061

Timestep Collection Time: 15.12325
Timestep Consumption Time: 9.36976
PPO Batch Consumption Time: 1.27271
Total Iteration Time: 24.49301

Cumulative Model Updates: 1,164
Cumulative Timesteps: 9,750,437

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.42653
Policy Entropy: 1.40012
Value Function Loss: 0.33298

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 0.07398
Value Function Update Magnitude: 0.10051

Collected Steps per Second: 3,323.76118
Overall Steps per Second: 2,041.65230

Timestep Collection Time: 15.04350
Timestep Consumption Time: 9.44696
PPO Batch Consumption Time: 1.29015
Total Iteration Time: 24.49046

Cumulative Model Updates: 1,170
Cumulative Timesteps: 9,800,438

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 9800438...
Checkpoint 9800438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.10376
Policy Entropy: 1.40258
Value Function Loss: 0.33021

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.09906

Collected Steps per Second: 3,270.76949
Overall Steps per Second: 2,043.05004

Timestep Collection Time: 15.28784
Timestep Consumption Time: 9.18684
PPO Batch Consumption Time: 1.25237
Total Iteration Time: 24.47468

Cumulative Model Updates: 1,176
Cumulative Timesteps: 9,850,441

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.36427
Policy Entropy: 1.40106
Value Function Loss: 0.32723

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.08126
Value Function Update Magnitude: 0.10105

Collected Steps per Second: 3,269.91208
Overall Steps per Second: 2,036.71643

Timestep Collection Time: 15.29215
Timestep Consumption Time: 9.25913
PPO Batch Consumption Time: 1.28660
Total Iteration Time: 24.55128

Cumulative Model Updates: 1,182
Cumulative Timesteps: 9,900,445

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 9900445...
Checkpoint 9900445 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.76636
Policy Entropy: 1.40150
Value Function Loss: 0.33119

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.08937
Value Function Update Magnitude: 0.10021

Collected Steps per Second: 3,287.58638
Overall Steps per Second: 2,036.23197

Timestep Collection Time: 15.20933
Timestep Consumption Time: 9.34681
PPO Batch Consumption Time: 1.28363
Total Iteration Time: 24.55614

Cumulative Model Updates: 1,188
Cumulative Timesteps: 9,950,447

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.11191
Policy Entropy: 1.40143
Value Function Loss: 0.33588

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.09227
Value Function Update Magnitude: 0.10270

Collected Steps per Second: 3,319.98932
Overall Steps per Second: 2,056.62552

Timestep Collection Time: 15.06029
Timestep Consumption Time: 9.25138
PPO Batch Consumption Time: 1.25376
Total Iteration Time: 24.31167

Cumulative Model Updates: 1,194
Cumulative Timesteps: 10,000,447

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10000447...
Checkpoint 10000447 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.96625
Policy Entropy: 1.40234
Value Function Loss: 0.33818

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.07996
Value Function Update Magnitude: 0.10488

Collected Steps per Second: 3,276.14243
Overall Steps per Second: 2,033.32815

Timestep Collection Time: 15.26246
Timestep Consumption Time: 9.32875
PPO Batch Consumption Time: 1.29040
Total Iteration Time: 24.59121

Cumulative Model Updates: 1,200
Cumulative Timesteps: 10,050,449

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.91499
Policy Entropy: 1.40400
Value Function Loss: 0.33585

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.08521
Value Function Update Magnitude: 0.10709

Collected Steps per Second: 3,307.41844
Overall Steps per Second: 2,049.49650

Timestep Collection Time: 15.11904
Timestep Consumption Time: 9.27963
PPO Batch Consumption Time: 1.28039
Total Iteration Time: 24.39868

Cumulative Model Updates: 1,206
Cumulative Timesteps: 10,100,454

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 10100454...
Checkpoint 10100454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.56340
Policy Entropy: 1.40421
Value Function Loss: 0.32785

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.08722
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 3,322.96772
Overall Steps per Second: 2,063.42196

Timestep Collection Time: 15.04799
Timestep Consumption Time: 9.18554
PPO Batch Consumption Time: 1.25615
Total Iteration Time: 24.23353

Cumulative Model Updates: 1,212
Cumulative Timesteps: 10,150,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.34976
Policy Entropy: 1.40541
Value Function Loss: 0.33352

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.08013
Value Function Update Magnitude: 0.10570

Collected Steps per Second: 3,233.80573
Overall Steps per Second: 2,001.77917

Timestep Collection Time: 15.46320
Timestep Consumption Time: 9.51707
PPO Batch Consumption Time: 1.30924
Total Iteration Time: 24.98028

Cumulative Model Updates: 1,218
Cumulative Timesteps: 10,200,463

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 10200463...
Checkpoint 10200463 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.83469
Policy Entropy: 1.40424
Value Function Loss: 0.33545

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02032
Policy Update Magnitude: 0.07861
Value Function Update Magnitude: 0.11449

Collected Steps per Second: 3,268.65273
Overall Steps per Second: 2,031.65371

Timestep Collection Time: 15.29774
Timestep Consumption Time: 9.31423
PPO Batch Consumption Time: 1.27406
Total Iteration Time: 24.61197

Cumulative Model Updates: 1,224
Cumulative Timesteps: 10,250,466

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.82675
Policy Entropy: 1.40451
Value Function Loss: 0.33803

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01772
Policy Update Magnitude: 0.07468
Value Function Update Magnitude: 0.11576

Collected Steps per Second: 3,316.87518
Overall Steps per Second: 2,043.38526

Timestep Collection Time: 15.07443
Timestep Consumption Time: 9.39477
PPO Batch Consumption Time: 1.28699
Total Iteration Time: 24.46920

Cumulative Model Updates: 1,230
Cumulative Timesteps: 10,300,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10300466...
Checkpoint 10300466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.76428
Policy Entropy: 1.40464
Value Function Loss: 0.33372

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.07786
Value Function Update Magnitude: 0.10397

Collected Steps per Second: 3,296.99607
Overall Steps per Second: 2,047.62697

Timestep Collection Time: 15.16593
Timestep Consumption Time: 9.25356
PPO Batch Consumption Time: 1.26183
Total Iteration Time: 24.41949

Cumulative Model Updates: 1,236
Cumulative Timesteps: 10,350,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.16095
Policy Entropy: 1.40483
Value Function Loss: 0.32525

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.08153
Value Function Update Magnitude: 0.10218

Collected Steps per Second: 3,267.21261
Overall Steps per Second: 2,033.12647

Timestep Collection Time: 15.30387
Timestep Consumption Time: 9.28929
PPO Batch Consumption Time: 1.27730
Total Iteration Time: 24.59316

Cumulative Model Updates: 1,242
Cumulative Timesteps: 10,400,469

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 10400469...
Checkpoint 10400469 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.92391
Policy Entropy: 1.40557
Value Function Loss: 0.33556

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.01753
Policy Update Magnitude: 0.08958
Value Function Update Magnitude: 0.10590

Collected Steps per Second: 3,257.66134
Overall Steps per Second: 2,029.30395

Timestep Collection Time: 15.34905
Timestep Consumption Time: 9.29093
PPO Batch Consumption Time: 1.25974
Total Iteration Time: 24.63998

Cumulative Model Updates: 1,248
Cumulative Timesteps: 10,450,471

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.43295
Policy Entropy: 1.40572
Value Function Loss: 0.34311

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.01589
Policy Update Magnitude: 0.09519
Value Function Update Magnitude: 0.11737

Collected Steps per Second: 3,321.23279
Overall Steps per Second: 2,056.75611

Timestep Collection Time: 15.05525
Timestep Consumption Time: 9.25585
PPO Batch Consumption Time: 1.25416
Total Iteration Time: 24.31110

Cumulative Model Updates: 1,254
Cumulative Timesteps: 10,500,473

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 10500473...
Checkpoint 10500473 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.52004
Policy Entropy: 1.40550
Value Function Loss: 0.34979

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01608
Policy Update Magnitude: 0.08969
Value Function Update Magnitude: 0.11706

Collected Steps per Second: 3,287.21863
Overall Steps per Second: 2,029.09611

Timestep Collection Time: 15.21073
Timestep Consumption Time: 9.43128
PPO Batch Consumption Time: 1.27323
Total Iteration Time: 24.64201

Cumulative Model Updates: 1,260
Cumulative Timesteps: 10,550,474

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.58407
Policy Entropy: 1.40613
Value Function Loss: 0.34248

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01427
Policy Update Magnitude: 0.09926
Value Function Update Magnitude: 0.10860

Collected Steps per Second: 3,320.70567
Overall Steps per Second: 2,050.01161

Timestep Collection Time: 15.05734
Timestep Consumption Time: 9.33325
PPO Batch Consumption Time: 1.27925
Total Iteration Time: 24.39059

Cumulative Model Updates: 1,266
Cumulative Timesteps: 10,600,475

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 10600475...
Checkpoint 10600475 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.56808
Policy Entropy: 1.40797
Value Function Loss: 0.33174

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.02835
Policy Update Magnitude: 0.08593
Value Function Update Magnitude: 0.10783

Collected Steps per Second: 3,310.74550
Overall Steps per Second: 2,049.30179

Timestep Collection Time: 15.10264
Timestep Consumption Time: 9.29640
PPO Batch Consumption Time: 1.27090
Total Iteration Time: 24.39904

Cumulative Model Updates: 1,272
Cumulative Timesteps: 10,650,476

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.86000
Policy Entropy: 1.40836
Value Function Loss: 0.33047

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.04054
Policy Update Magnitude: 0.07589
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 3,307.37528
Overall Steps per Second: 2,056.93824

Timestep Collection Time: 15.11803
Timestep Consumption Time: 9.19043
PPO Batch Consumption Time: 1.25216
Total Iteration Time: 24.30846

Cumulative Model Updates: 1,278
Cumulative Timesteps: 10,700,477

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 10700477...
Checkpoint 10700477 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.77657
Policy Entropy: 1.40729
Value Function Loss: 0.33272

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.03816
Policy Update Magnitude: 0.07471
Value Function Update Magnitude: 0.11170

Collected Steps per Second: 3,262.26889
Overall Steps per Second: 2,034.10536

Timestep Collection Time: 15.32676
Timestep Consumption Time: 9.25407
PPO Batch Consumption Time: 1.26665
Total Iteration Time: 24.58083

Cumulative Model Updates: 1,284
Cumulative Timesteps: 10,750,477

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.42430
Policy Entropy: 1.40706
Value Function Loss: 0.33779

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.07474
Value Function Update Magnitude: 0.10915

Collected Steps per Second: 3,296.91676
Overall Steps per Second: 2,045.11520

Timestep Collection Time: 15.16568
Timestep Consumption Time: 9.28282
PPO Batch Consumption Time: 1.27168
Total Iteration Time: 24.44850

Cumulative Model Updates: 1,290
Cumulative Timesteps: 10,800,477

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10800477...
Checkpoint 10800477 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.32812
Policy Entropy: 1.40484
Value Function Loss: 0.33685

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.07894
Value Function Update Magnitude: 0.11964

Collected Steps per Second: 3,304.00995
Overall Steps per Second: 2,036.47039

Timestep Collection Time: 15.13343
Timestep Consumption Time: 9.41935
PPO Batch Consumption Time: 1.29624
Total Iteration Time: 24.55278

Cumulative Model Updates: 1,296
Cumulative Timesteps: 10,850,478

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.39677
Policy Entropy: 1.40765
Value Function Loss: 0.33262

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.03643
Policy Update Magnitude: 0.07029
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 3,280.07264
Overall Steps per Second: 2,045.17478

Timestep Collection Time: 15.24417
Timestep Consumption Time: 9.20459
PPO Batch Consumption Time: 1.25730
Total Iteration Time: 24.44877

Cumulative Model Updates: 1,302
Cumulative Timesteps: 10,900,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 10900480...
Checkpoint 10900480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.64621
Policy Entropy: 1.40913
Value Function Loss: 0.32956

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02158
Policy Update Magnitude: 0.07152
Value Function Update Magnitude: 0.12700

Collected Steps per Second: 3,258.46134
Overall Steps per Second: 2,035.98810

Timestep Collection Time: 15.34589
Timestep Consumption Time: 9.21417
PPO Batch Consumption Time: 1.26254
Total Iteration Time: 24.56006

Cumulative Model Updates: 1,308
Cumulative Timesteps: 10,950,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.41223
Policy Entropy: 1.40976
Value Function Loss: 0.32626

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01604
Policy Update Magnitude: 0.07497
Value Function Update Magnitude: 0.12132

Collected Steps per Second: 3,307.75018
Overall Steps per Second: 2,051.64374

Timestep Collection Time: 15.11632
Timestep Consumption Time: 9.25487
PPO Batch Consumption Time: 1.26739
Total Iteration Time: 24.37119

Cumulative Model Updates: 1,314
Cumulative Timesteps: 11,000,485

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 11000485...
Checkpoint 11000485 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.59392
Policy Entropy: 1.40918
Value Function Loss: 0.32632

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02024
Policy Update Magnitude: 0.07368
Value Function Update Magnitude: 0.11514

Collected Steps per Second: 3,279.34061
Overall Steps per Second: 2,047.90044

Timestep Collection Time: 15.24697
Timestep Consumption Time: 9.16828
PPO Batch Consumption Time: 1.26018
Total Iteration Time: 24.41525

Cumulative Model Updates: 1,320
Cumulative Timesteps: 11,050,485

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.82632
Policy Entropy: 1.40882
Value Function Loss: 0.32107

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.07059
Value Function Update Magnitude: 0.11736

Collected Steps per Second: 3,272.00534
Overall Steps per Second: 2,027.20442

Timestep Collection Time: 15.28176
Timestep Consumption Time: 9.38373
PPO Batch Consumption Time: 1.29084
Total Iteration Time: 24.66549

Cumulative Model Updates: 1,326
Cumulative Timesteps: 11,100,487

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 11100487...
Checkpoint 11100487 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.01413
Policy Entropy: 1.40810
Value Function Loss: 0.32080

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01618
Policy Update Magnitude: 0.06912
Value Function Update Magnitude: 0.12182

Collected Steps per Second: 3,334.44404
Overall Steps per Second: 2,056.55770

Timestep Collection Time: 14.99530
Timestep Consumption Time: 9.31765
PPO Batch Consumption Time: 1.27062
Total Iteration Time: 24.31296

Cumulative Model Updates: 1,332
Cumulative Timesteps: 11,150,488

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.21369
Policy Entropy: 1.40899
Value Function Loss: 0.31793

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01429
Policy Update Magnitude: 0.07071
Value Function Update Magnitude: 0.12313

Collected Steps per Second: 3,314.46785
Overall Steps per Second: 2,052.67688

Timestep Collection Time: 15.08538
Timestep Consumption Time: 9.27306
PPO Batch Consumption Time: 1.26401
Total Iteration Time: 24.35844

Cumulative Model Updates: 1,338
Cumulative Timesteps: 11,200,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 11200488...
Checkpoint 11200488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.88198
Policy Entropy: 1.40827
Value Function Loss: 0.32547

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01642
Policy Update Magnitude: 0.07454
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 3,307.39679
Overall Steps per Second: 2,051.91002

Timestep Collection Time: 15.11823
Timestep Consumption Time: 9.25028
PPO Batch Consumption Time: 1.26770
Total Iteration Time: 24.36852

Cumulative Model Updates: 1,344
Cumulative Timesteps: 11,250,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.92246
Policy Entropy: 1.40754
Value Function Loss: 0.31943

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.07253
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 3,277.04635
Overall Steps per Second: 2,035.74071

Timestep Collection Time: 15.25764
Timestep Consumption Time: 9.30344
PPO Batch Consumption Time: 1.28054
Total Iteration Time: 24.56108

Cumulative Model Updates: 1,350
Cumulative Timesteps: 11,300,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 11300490...
Checkpoint 11300490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.81909
Policy Entropy: 1.40838
Value Function Loss: 0.32391

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02256
Policy Update Magnitude: 0.07118
Value Function Update Magnitude: 0.11485

Collected Steps per Second: 3,319.56178
Overall Steps per Second: 2,056.28754

Timestep Collection Time: 15.06223
Timestep Consumption Time: 9.25344
PPO Batch Consumption Time: 1.27895
Total Iteration Time: 24.31567

Cumulative Model Updates: 1,356
Cumulative Timesteps: 11,350,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.22796
Policy Entropy: 1.40805
Value Function Loss: 0.32274

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.03038
Policy Update Magnitude: 0.07455
Value Function Update Magnitude: 0.11034

Collected Steps per Second: 3,351.42509
Overall Steps per Second: 2,031.50777

Timestep Collection Time: 14.91903
Timestep Consumption Time: 9.69323
PPO Batch Consumption Time: 1.34303
Total Iteration Time: 24.61226

Cumulative Model Updates: 1,362
Cumulative Timesteps: 11,400,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 11400490...
Checkpoint 11400490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.91322
Policy Entropy: 1.40973
Value Function Loss: 0.32543

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.07276
Value Function Update Magnitude: 0.12226

Collected Steps per Second: 3,266.61729
Overall Steps per Second: 2,036.97323

Timestep Collection Time: 15.30727
Timestep Consumption Time: 9.24042
PPO Batch Consumption Time: 1.27166
Total Iteration Time: 24.54770

Cumulative Model Updates: 1,368
Cumulative Timesteps: 11,450,493

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.13471
Policy Entropy: 1.41095
Value Function Loss: 0.31906

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02096
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.12787

Collected Steps per Second: 3,283.65316
Overall Steps per Second: 2,043.35940

Timestep Collection Time: 15.22725
Timestep Consumption Time: 9.24275
PPO Batch Consumption Time: 1.27427
Total Iteration Time: 24.47000

Cumulative Model Updates: 1,374
Cumulative Timesteps: 11,500,494

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 11500494...
Checkpoint 11500494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.71017
Policy Entropy: 1.41140
Value Function Loss: 0.30610

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01262
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 3,288.54296
Overall Steps per Second: 2,036.24715

Timestep Collection Time: 15.20430
Timestep Consumption Time: 9.35067
PPO Batch Consumption Time: 1.27206
Total Iteration Time: 24.55498

Cumulative Model Updates: 1,380
Cumulative Timesteps: 11,550,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.41859
Policy Entropy: 1.41129
Value Function Loss: 0.29470

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01003
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 3,300.96054
Overall Steps per Second: 2,039.15565

Timestep Collection Time: 15.14832
Timestep Consumption Time: 9.37360
PPO Batch Consumption Time: 1.29487
Total Iteration Time: 24.52191

Cumulative Model Updates: 1,386
Cumulative Timesteps: 11,600,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 11600498...
Checkpoint 11600498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.71569
Policy Entropy: 1.41114
Value Function Loss: 0.28958

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01611
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 3,233.93711
Overall Steps per Second: 2,013.42787

Timestep Collection Time: 15.46227
Timestep Consumption Time: 9.37299
PPO Batch Consumption Time: 1.28922
Total Iteration Time: 24.83526

Cumulative Model Updates: 1,392
Cumulative Timesteps: 11,650,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.69571
Policy Entropy: 1.41084
Value Function Loss: 0.28415

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01492
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.09979

Collected Steps per Second: 3,292.93296
Overall Steps per Second: 2,045.08609

Timestep Collection Time: 15.18494
Timestep Consumption Time: 9.26537
PPO Batch Consumption Time: 1.25738
Total Iteration Time: 24.45032

Cumulative Model Updates: 1,398
Cumulative Timesteps: 11,700,505

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 11700505...
Checkpoint 11700505 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.25656
Policy Entropy: 1.41008
Value Function Loss: 0.28469

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01568
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.09590

Collected Steps per Second: 3,264.63794
Overall Steps per Second: 2,033.13387

Timestep Collection Time: 15.31717
Timestep Consumption Time: 9.27787
PPO Batch Consumption Time: 1.27711
Total Iteration Time: 24.59504

Cumulative Model Updates: 1,404
Cumulative Timesteps: 11,750,510

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.90101
Policy Entropy: 1.40931
Value Function Loss: 0.28264

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01374
Policy Update Magnitude: 0.06776
Value Function Update Magnitude: 0.09901

Collected Steps per Second: 3,289.29577
Overall Steps per Second: 2,038.17386

Timestep Collection Time: 15.20143
Timestep Consumption Time: 9.33132
PPO Batch Consumption Time: 1.29406
Total Iteration Time: 24.53275

Cumulative Model Updates: 1,410
Cumulative Timesteps: 11,800,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 11800512...
Checkpoint 11800512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.95299
Policy Entropy: 1.40896
Value Function Loss: 0.28762

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01583
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.10128

Collected Steps per Second: 3,312.34576
Overall Steps per Second: 2,043.10106

Timestep Collection Time: 15.09565
Timestep Consumption Time: 9.37794
PPO Batch Consumption Time: 1.28889
Total Iteration Time: 24.47358

Cumulative Model Updates: 1,416
Cumulative Timesteps: 11,850,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.50127
Policy Entropy: 1.40861
Value Function Loss: 0.29021

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01639
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.09685

Collected Steps per Second: 3,289.89623
Overall Steps per Second: 2,028.86734

Timestep Collection Time: 15.19926
Timestep Consumption Time: 9.44700
PPO Batch Consumption Time: 1.30784
Total Iteration Time: 24.64626

Cumulative Model Updates: 1,422
Cumulative Timesteps: 11,900,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 11900518...
Checkpoint 11900518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.25152
Policy Entropy: 1.41006
Value Function Loss: 0.29178

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01230
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.09831

Collected Steps per Second: 3,299.00367
Overall Steps per Second: 2,047.01808

Timestep Collection Time: 15.15670
Timestep Consumption Time: 9.27005
PPO Batch Consumption Time: 1.26555
Total Iteration Time: 24.42675

Cumulative Model Updates: 1,428
Cumulative Timesteps: 11,950,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.25927
Policy Entropy: 1.40922
Value Function Loss: 0.29756

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.06946
Value Function Update Magnitude: 0.10429

Collected Steps per Second: 3,304.61101
Overall Steps per Second: 2,045.57202

Timestep Collection Time: 15.13189
Timestep Consumption Time: 9.31360
PPO Batch Consumption Time: 1.27226
Total Iteration Time: 24.44548

Cumulative Model Updates: 1,434
Cumulative Timesteps: 12,000,525

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 12000525...
Checkpoint 12000525 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.39889
Policy Entropy: 1.41056
Value Function Loss: 0.30260

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.07175
Value Function Update Magnitude: 0.10957

Collected Steps per Second: 3,289.66774
Overall Steps per Second: 2,045.02557

Timestep Collection Time: 15.20032
Timestep Consumption Time: 9.25121
PPO Batch Consumption Time: 1.26473
Total Iteration Time: 24.45153

Cumulative Model Updates: 1,440
Cumulative Timesteps: 12,050,529

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.38132
Policy Entropy: 1.41024
Value Function Loss: 0.30249

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.07036
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 3,252.99712
Overall Steps per Second: 2,019.81346

Timestep Collection Time: 15.37106
Timestep Consumption Time: 9.38470
PPO Batch Consumption Time: 1.28991
Total Iteration Time: 24.75575

Cumulative Model Updates: 1,446
Cumulative Timesteps: 12,100,531

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 12100531...
Checkpoint 12100531 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.64981
Policy Entropy: 1.40985
Value Function Loss: 0.29780

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.07060
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 3,314.68594
Overall Steps per Second: 2,039.76374

Timestep Collection Time: 15.08529
Timestep Consumption Time: 9.42882
PPO Batch Consumption Time: 1.29744
Total Iteration Time: 24.51411

Cumulative Model Updates: 1,452
Cumulative Timesteps: 12,150,534

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.90811
Policy Entropy: 1.40949
Value Function Loss: 0.29426

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.06799
Value Function Update Magnitude: 0.11634

Collected Steps per Second: 3,307.40176
Overall Steps per Second: 2,045.88455

Timestep Collection Time: 15.11761
Timestep Consumption Time: 9.32170
PPO Batch Consumption Time: 1.28097
Total Iteration Time: 24.43931

Cumulative Model Updates: 1,458
Cumulative Timesteps: 12,200,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12200534...
Checkpoint 12200534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.53830
Policy Entropy: 1.40806
Value Function Loss: 0.29693

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.07194
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 3,278.50721
Overall Steps per Second: 2,021.22839

Timestep Collection Time: 15.25145
Timestep Consumption Time: 9.48697
PPO Batch Consumption Time: 1.31998
Total Iteration Time: 24.73842

Cumulative Model Updates: 1,464
Cumulative Timesteps: 12,250,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.97623
Policy Entropy: 1.40761
Value Function Loss: 0.30081

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.01963
Policy Update Magnitude: 0.07287
Value Function Update Magnitude: 0.11091

Collected Steps per Second: 3,270.42897
Overall Steps per Second: 2,029.05706

Timestep Collection Time: 15.28943
Timestep Consumption Time: 9.35404
PPO Batch Consumption Time: 1.28872
Total Iteration Time: 24.64347

Cumulative Model Updates: 1,470
Cumulative Timesteps: 12,300,539

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 12300539...
Checkpoint 12300539 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.27134
Policy Entropy: 1.40698
Value Function Loss: 0.30523

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01485
Policy Update Magnitude: 0.07293
Value Function Update Magnitude: 0.11300

Collected Steps per Second: 3,322.88702
Overall Steps per Second: 1,994.13180

Timestep Collection Time: 15.04716
Timestep Consumption Time: 10.02641
PPO Batch Consumption Time: 1.38365
Total Iteration Time: 25.07357

Cumulative Model Updates: 1,476
Cumulative Timesteps: 12,350,539

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.15964
Policy Entropy: 1.40707
Value Function Loss: 0.30777

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01595
Policy Update Magnitude: 0.07774
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 3,322.46840
Overall Steps per Second: 2,047.96280

Timestep Collection Time: 15.04905
Timestep Consumption Time: 9.36545
PPO Batch Consumption Time: 1.29597
Total Iteration Time: 24.41451

Cumulative Model Updates: 1,482
Cumulative Timesteps: 12,400,539

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12400539...
Checkpoint 12400539 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.80853
Policy Entropy: 1.40563
Value Function Loss: 0.30585

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.02602
Policy Update Magnitude: 0.07484
Value Function Update Magnitude: 0.12847

Collected Steps per Second: 3,278.74883
Overall Steps per Second: 2,034.44127

Timestep Collection Time: 15.25063
Timestep Consumption Time: 9.32761
PPO Batch Consumption Time: 1.27516
Total Iteration Time: 24.57825

Cumulative Model Updates: 1,488
Cumulative Timesteps: 12,450,542

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.49212
Policy Entropy: 1.40634
Value Function Loss: 0.30186

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.02990
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.11652

Collected Steps per Second: 3,282.25839
Overall Steps per Second: 2,028.99381

Timestep Collection Time: 15.23372
Timestep Consumption Time: 9.40953
PPO Batch Consumption Time: 1.28433
Total Iteration Time: 24.64325

Cumulative Model Updates: 1,494
Cumulative Timesteps: 12,500,543

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 12500543...
Checkpoint 12500543 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.84135
Policy Entropy: 1.40634
Value Function Loss: 0.29952

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02227
Policy Update Magnitude: 0.06747
Value Function Update Magnitude: 0.11536

Collected Steps per Second: 3,336.76877
Overall Steps per Second: 2,050.01768

Timestep Collection Time: 14.98576
Timestep Consumption Time: 9.40623
PPO Batch Consumption Time: 1.28983
Total Iteration Time: 24.39198

Cumulative Model Updates: 1,500
Cumulative Timesteps: 12,550,547

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.59300
Policy Entropy: 1.40755
Value Function Loss: 0.29861

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.06891
Value Function Update Magnitude: 0.10777

Collected Steps per Second: 3,310.66946
Overall Steps per Second: 2,044.79618

Timestep Collection Time: 15.10269
Timestep Consumption Time: 9.34963
PPO Batch Consumption Time: 1.27378
Total Iteration Time: 24.45231

Cumulative Model Updates: 1,506
Cumulative Timesteps: 12,600,547

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12600547...
Checkpoint 12600547 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.98649
Policy Entropy: 1.40574
Value Function Loss: 0.30737

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 3,274.23087
Overall Steps per Second: 2,023.28531

Timestep Collection Time: 15.27107
Timestep Consumption Time: 9.44171
PPO Batch Consumption Time: 1.30232
Total Iteration Time: 24.71278

Cumulative Model Updates: 1,512
Cumulative Timesteps: 12,650,548

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.40484
Policy Entropy: 1.40621
Value Function Loss: 0.30502

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.07066
Value Function Update Magnitude: 0.10159

Collected Steps per Second: 3,302.68877
Overall Steps per Second: 2,043.21496

Timestep Collection Time: 15.14009
Timestep Consumption Time: 9.33262
PPO Batch Consumption Time: 1.28254
Total Iteration Time: 24.47271

Cumulative Model Updates: 1,518
Cumulative Timesteps: 12,700,551

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 12700551...
Checkpoint 12700551 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.33245
Policy Entropy: 1.40534
Value Function Loss: 0.30790

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.03477
Policy Update Magnitude: 0.07356
Value Function Update Magnitude: 0.10565

Collected Steps per Second: 3,312.47970
Overall Steps per Second: 2,035.06402

Timestep Collection Time: 15.09564
Timestep Consumption Time: 9.47558
PPO Batch Consumption Time: 1.30447
Total Iteration Time: 24.57122

Cumulative Model Updates: 1,524
Cumulative Timesteps: 12,750,555

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.53048
Policy Entropy: 1.40471
Value Function Loss: 0.29920

Mean KL Divergence: 0.02009
SB3 Clip Fraction: 0.06497
Policy Update Magnitude: 0.06611
Value Function Update Magnitude: 0.10875

Collected Steps per Second: 3,305.68943
Overall Steps per Second: 2,044.64429

Timestep Collection Time: 15.12695
Timestep Consumption Time: 9.32963
PPO Batch Consumption Time: 1.28470
Total Iteration Time: 24.45658

Cumulative Model Updates: 1,530
Cumulative Timesteps: 12,800,560

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 12800560...
Checkpoint 12800560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.03645
Policy Entropy: 1.40130
Value Function Loss: 0.30212

Mean KL Divergence: 0.03217
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.07091
Value Function Update Magnitude: 0.10709

Collected Steps per Second: 3,259.32272
Overall Steps per Second: 2,031.37724

Timestep Collection Time: 15.34122
Timestep Consumption Time: 9.27360
PPO Batch Consumption Time: 1.27180
Total Iteration Time: 24.61483

Cumulative Model Updates: 1,536
Cumulative Timesteps: 12,850,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.58885
Policy Entropy: 1.40961
Value Function Loss: 0.30374

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.06565
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.10294

Collected Steps per Second: 3,263.84651
Overall Steps per Second: 2,018.77365

Timestep Collection Time: 15.32057
Timestep Consumption Time: 9.44892
PPO Batch Consumption Time: 1.30694
Total Iteration Time: 24.76949

Cumulative Model Updates: 1,542
Cumulative Timesteps: 12,900,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 12900566...
Checkpoint 12900566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.75077
Policy Entropy: 1.41013
Value Function Loss: 0.31066

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.04830
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.10302

Collected Steps per Second: 3,302.09043
Overall Steps per Second: 2,025.50415

Timestep Collection Time: 15.14192
Timestep Consumption Time: 9.54329
PPO Batch Consumption Time: 1.31082
Total Iteration Time: 24.68521

Cumulative Model Updates: 1,548
Cumulative Timesteps: 12,950,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.05210
Policy Entropy: 1.41032
Value Function Loss: 0.31590

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.11521

Collected Steps per Second: 3,333.97373
Overall Steps per Second: 2,057.85960

Timestep Collection Time: 14.99802
Timestep Consumption Time: 9.30053
PPO Batch Consumption Time: 1.26706
Total Iteration Time: 24.29855

Cumulative Model Updates: 1,554
Cumulative Timesteps: 13,000,569

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 13000569...
Checkpoint 13000569 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.76134
Policy Entropy: 1.41056
Value Function Loss: 0.31647

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02198
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 3,269.33977
Overall Steps per Second: 2,024.48430

Timestep Collection Time: 15.29514
Timestep Consumption Time: 9.40498
PPO Batch Consumption Time: 1.27785
Total Iteration Time: 24.70012

Cumulative Model Updates: 1,560
Cumulative Timesteps: 13,050,574

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.02604
Policy Entropy: 1.41140
Value Function Loss: 0.30740

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01928
Policy Update Magnitude: 0.06730
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 3,287.95130
Overall Steps per Second: 2,023.57752

Timestep Collection Time: 15.20704
Timestep Consumption Time: 9.50168
PPO Batch Consumption Time: 1.30518
Total Iteration Time: 24.70871

Cumulative Model Updates: 1,566
Cumulative Timesteps: 13,100,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 13100574...
Checkpoint 13100574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.65867
Policy Entropy: 1.41019
Value Function Loss: 0.30209

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01720
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.10923

Collected Steps per Second: 3,221.43699
Overall Steps per Second: 2,009.92566

Timestep Collection Time: 15.52227
Timestep Consumption Time: 9.35627
PPO Batch Consumption Time: 1.28430
Total Iteration Time: 24.87853

Cumulative Model Updates: 1,572
Cumulative Timesteps: 13,150,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.49490
Policy Entropy: 1.40886
Value Function Loss: 0.30282

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01222
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.10840

Collected Steps per Second: 3,332.58121
Overall Steps per Second: 2,038.55129

Timestep Collection Time: 15.00459
Timestep Consumption Time: 9.52460
PPO Batch Consumption Time: 1.30651
Total Iteration Time: 24.52918

Cumulative Model Updates: 1,578
Cumulative Timesteps: 13,200,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13200582...
Checkpoint 13200582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.10658
Policy Entropy: 1.40838
Value Function Loss: 0.30134

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02034
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 3,276.78083
Overall Steps per Second: 2,036.50278

Timestep Collection Time: 15.25949
Timestep Consumption Time: 9.29339
PPO Batch Consumption Time: 1.27305
Total Iteration Time: 24.55288

Cumulative Model Updates: 1,584
Cumulative Timesteps: 13,250,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.21454
Policy Entropy: 1.40876
Value Function Loss: 0.29675

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.10205

Collected Steps per Second: 3,268.78969
Overall Steps per Second: 2,027.00734

Timestep Collection Time: 15.29649
Timestep Consumption Time: 9.37091
PPO Batch Consumption Time: 1.28303
Total Iteration Time: 24.66740

Cumulative Model Updates: 1,590
Cumulative Timesteps: 13,300,585

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 13300585...
Checkpoint 13300585 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.65799
Policy Entropy: 1.41047
Value Function Loss: 0.29349

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.10055

Collected Steps per Second: 3,292.12818
Overall Steps per Second: 2,033.01592

Timestep Collection Time: 15.18896
Timestep Consumption Time: 9.40701
PPO Batch Consumption Time: 1.28447
Total Iteration Time: 24.59597

Cumulative Model Updates: 1,596
Cumulative Timesteps: 13,350,589

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.80121
Policy Entropy: 1.40933
Value Function Loss: 0.28676

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.07066
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 3,294.32944
Overall Steps per Second: 2,033.68915

Timestep Collection Time: 15.17881
Timestep Consumption Time: 9.40902
PPO Batch Consumption Time: 1.29797
Total Iteration Time: 24.58783

Cumulative Model Updates: 1,602
Cumulative Timesteps: 13,400,593

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13400593...
Checkpoint 13400593 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.25075
Policy Entropy: 1.40952
Value Function Loss: 0.29367

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.01710
Policy Update Magnitude: 0.07016
Value Function Update Magnitude: 0.10801

Collected Steps per Second: 3,287.78846
Overall Steps per Second: 2,032.24089

Timestep Collection Time: 15.20901
Timestep Consumption Time: 9.39634
PPO Batch Consumption Time: 1.28888
Total Iteration Time: 24.60535

Cumulative Model Updates: 1,608
Cumulative Timesteps: 13,450,597

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.47070
Policy Entropy: 1.40921
Value Function Loss: 0.29122

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01489
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.10989

Collected Steps per Second: 3,252.29759
Overall Steps per Second: 2,018.13133

Timestep Collection Time: 15.37498
Timestep Consumption Time: 9.40240
PPO Batch Consumption Time: 1.29172
Total Iteration Time: 24.77738

Cumulative Model Updates: 1,614
Cumulative Timesteps: 13,500,601

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13500601...
Checkpoint 13500601 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.49009
Policy Entropy: 1.40964
Value Function Loss: 0.30685

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01436
Policy Update Magnitude: 0.07010
Value Function Update Magnitude: 0.10965

Collected Steps per Second: 3,285.89652
Overall Steps per Second: 2,036.45630

Timestep Collection Time: 15.21685
Timestep Consumption Time: 9.33609
PPO Batch Consumption Time: 1.29271
Total Iteration Time: 24.55295

Cumulative Model Updates: 1,620
Cumulative Timesteps: 13,550,602

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.52030
Policy Entropy: 1.40859
Value Function Loss: 0.29746

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.11176

Collected Steps per Second: 3,274.93015
Overall Steps per Second: 2,023.61738

Timestep Collection Time: 15.26872
Timestep Consumption Time: 9.44148
PPO Batch Consumption Time: 1.30435
Total Iteration Time: 24.71020

Cumulative Model Updates: 1,626
Cumulative Timesteps: 13,600,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 13600606...
Checkpoint 13600606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.52721
Policy Entropy: 1.40842
Value Function Loss: 0.30185

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02135
Policy Update Magnitude: 0.06429
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 3,269.76652
Overall Steps per Second: 2,030.26609

Timestep Collection Time: 15.29161
Timestep Consumption Time: 9.33570
PPO Batch Consumption Time: 1.27126
Total Iteration Time: 24.62731

Cumulative Model Updates: 1,632
Cumulative Timesteps: 13,650,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.92795
Policy Entropy: 1.40822
Value Function Loss: 0.29482

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02072
Policy Update Magnitude: 0.06692
Value Function Update Magnitude: 0.10879

Collected Steps per Second: 3,294.72896
Overall Steps per Second: 2,022.94114

Timestep Collection Time: 15.17636
Timestep Consumption Time: 9.54111
PPO Batch Consumption Time: 1.31191
Total Iteration Time: 24.71748

Cumulative Model Updates: 1,638
Cumulative Timesteps: 13,700,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13700608...
Checkpoint 13700608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.05829
Policy Entropy: 1.40882
Value Function Loss: 0.29909

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01855
Policy Update Magnitude: 0.06937
Value Function Update Magnitude: 0.11157

Collected Steps per Second: 3,290.64025
Overall Steps per Second: 2,031.71850

Timestep Collection Time: 15.19583
Timestep Consumption Time: 9.41585
PPO Batch Consumption Time: 1.29929
Total Iteration Time: 24.61168

Cumulative Model Updates: 1,644
Cumulative Timesteps: 13,750,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.24589
Policy Entropy: 1.40940
Value Function Loss: 0.29388

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.06707
Value Function Update Magnitude: 0.11207

Collected Steps per Second: 3,264.23738
Overall Steps per Second: 2,028.19342

Timestep Collection Time: 15.31782
Timestep Consumption Time: 9.33515
PPO Batch Consumption Time: 1.28074
Total Iteration Time: 24.65297

Cumulative Model Updates: 1,650
Cumulative Timesteps: 13,800,613

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 13800613...
Checkpoint 13800613 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.89445
Policy Entropy: 1.40859
Value Function Loss: 0.29509

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01208
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.12646

Collected Steps per Second: 3,246.26503
Overall Steps per Second: 2,018.01088

Timestep Collection Time: 15.40262
Timestep Consumption Time: 9.37474
PPO Batch Consumption Time: 1.28899
Total Iteration Time: 24.77737

Cumulative Model Updates: 1,656
Cumulative Timesteps: 13,850,614

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.07644
Policy Entropy: 1.40808
Value Function Loss: 0.28920

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01209
Policy Update Magnitude: 0.07289
Value Function Update Magnitude: 0.12672

Collected Steps per Second: 3,284.98726
Overall Steps per Second: 2,020.09793

Timestep Collection Time: 15.22076
Timestep Consumption Time: 9.53052
PPO Batch Consumption Time: 1.31887
Total Iteration Time: 24.75128

Cumulative Model Updates: 1,662
Cumulative Timesteps: 13,900,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 13900614...
Checkpoint 13900614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.03519
Policy Entropy: 1.40693
Value Function Loss: 0.29034

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01263
Policy Update Magnitude: 0.07785
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 3,202.73167
Overall Steps per Second: 1,995.15001

Timestep Collection Time: 15.61292
Timestep Consumption Time: 9.44986
PPO Batch Consumption Time: 1.29087
Total Iteration Time: 25.06278

Cumulative Model Updates: 1,668
Cumulative Timesteps: 13,950,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.95585
Policy Entropy: 1.40646
Value Function Loss: 0.28459

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02070
Policy Update Magnitude: 0.08996
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 3,268.16393
Overall Steps per Second: 2,019.56225

Timestep Collection Time: 15.30003
Timestep Consumption Time: 9.45930
PPO Batch Consumption Time: 1.30452
Total Iteration Time: 24.75933

Cumulative Model Updates: 1,674
Cumulative Timesteps: 14,000,621

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 14000621...
Checkpoint 14000621 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.01291
Policy Entropy: 1.40644
Value Function Loss: 0.28544

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.09403
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 3,300.52400
Overall Steps per Second: 2,037.19918

Timestep Collection Time: 15.14972
Timestep Consumption Time: 9.39477
PPO Batch Consumption Time: 1.28986
Total Iteration Time: 24.54448

Cumulative Model Updates: 1,680
Cumulative Timesteps: 14,050,623

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.63315
Policy Entropy: 1.40574
Value Function Loss: 0.28968

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.08381
Value Function Update Magnitude: 0.11820

Collected Steps per Second: 3,251.55112
Overall Steps per Second: 2,014.40535

Timestep Collection Time: 15.37789
Timestep Consumption Time: 9.44432
PPO Batch Consumption Time: 1.27706
Total Iteration Time: 24.82221

Cumulative Model Updates: 1,686
Cumulative Timesteps: 14,100,625

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 14100625...
Checkpoint 14100625 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.69094
Policy Entropy: 1.40610
Value Function Loss: 0.29968

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.08204
Value Function Update Magnitude: 0.11105

Collected Steps per Second: 3,276.48155
Overall Steps per Second: 2,033.41425

Timestep Collection Time: 15.26119
Timestep Consumption Time: 9.32947
PPO Batch Consumption Time: 1.26911
Total Iteration Time: 24.59066

Cumulative Model Updates: 1,692
Cumulative Timesteps: 14,150,628

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.45714
Policy Entropy: 1.40705
Value Function Loss: 0.30622

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.03692
Policy Update Magnitude: 0.07770
Value Function Update Magnitude: 0.11219

Collected Steps per Second: 3,278.62038
Overall Steps per Second: 2,029.06465

Timestep Collection Time: 15.25184
Timestep Consumption Time: 9.39252
PPO Batch Consumption Time: 1.28730
Total Iteration Time: 24.64436

Cumulative Model Updates: 1,698
Cumulative Timesteps: 14,200,633

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 14200633...
Checkpoint 14200633 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.59048
Policy Entropy: 1.40524
Value Function Loss: 0.30592

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.04782
Policy Update Magnitude: 0.06896
Value Function Update Magnitude: 0.11534

Collected Steps per Second: 3,274.54944
Overall Steps per Second: 2,031.28983

Timestep Collection Time: 15.27080
Timestep Consumption Time: 9.34656
PPO Batch Consumption Time: 1.28908
Total Iteration Time: 24.61736

Cumulative Model Updates: 1,704
Cumulative Timesteps: 14,250,638

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.00660
Policy Entropy: 1.40490
Value Function Loss: 0.30095

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.07309
Value Function Update Magnitude: 0.11481

Collected Steps per Second: 3,261.59071
Overall Steps per Second: 2,026.39271

Timestep Collection Time: 15.33086
Timestep Consumption Time: 9.34501
PPO Batch Consumption Time: 1.27968
Total Iteration Time: 24.67587

Cumulative Model Updates: 1,710
Cumulative Timesteps: 14,300,641

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 14300641...
Checkpoint 14300641 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.63798
Policy Entropy: 1.40452
Value Function Loss: 0.29857

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.07048
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 3,291.02500
Overall Steps per Second: 2,035.98213

Timestep Collection Time: 15.19405
Timestep Consumption Time: 9.36609
PPO Batch Consumption Time: 1.26029
Total Iteration Time: 24.56014

Cumulative Model Updates: 1,716
Cumulative Timesteps: 14,350,645

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.57124
Policy Entropy: 1.40099
Value Function Loss: 0.30645

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.05184
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.11154

Collected Steps per Second: 3,268.95162
Overall Steps per Second: 2,024.96774

Timestep Collection Time: 15.29665
Timestep Consumption Time: 9.39708
PPO Batch Consumption Time: 1.28539
Total Iteration Time: 24.69373

Cumulative Model Updates: 1,722
Cumulative Timesteps: 14,400,649

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 14400649...
Checkpoint 14400649 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.30134
Policy Entropy: 1.40498
Value Function Loss: 0.31047

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.04510
Policy Update Magnitude: 0.07366
Value Function Update Magnitude: 0.11375

Collected Steps per Second: 3,278.01041
Overall Steps per Second: 2,023.64195

Timestep Collection Time: 15.25407
Timestep Consumption Time: 9.45534
PPO Batch Consumption Time: 1.29597
Total Iteration Time: 24.70941

Cumulative Model Updates: 1,728
Cumulative Timesteps: 14,450,652

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.47844
Policy Entropy: 1.40489
Value Function Loss: 0.31431

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.03803
Policy Update Magnitude: 0.07619
Value Function Update Magnitude: 0.12511

Collected Steps per Second: 3,295.28307
Overall Steps per Second: 2,031.86362

Timestep Collection Time: 15.17351
Timestep Consumption Time: 9.43494
PPO Batch Consumption Time: 1.29702
Total Iteration Time: 24.60844

Cumulative Model Updates: 1,734
Cumulative Timesteps: 14,500,653

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 14500653...
Checkpoint 14500653 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.73742
Policy Entropy: 1.40574
Value Function Loss: 0.30574

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.07152
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 3,268.68613
Overall Steps per Second: 2,032.79602

Timestep Collection Time: 15.29667
Timestep Consumption Time: 9.30000
PPO Batch Consumption Time: 1.28500
Total Iteration Time: 24.59666

Cumulative Model Updates: 1,740
Cumulative Timesteps: 14,550,653

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.99063
Policy Entropy: 1.40555
Value Function Loss: 0.30036

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.01952
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.11515

Collected Steps per Second: 3,278.20805
Overall Steps per Second: 2,020.78733

Timestep Collection Time: 15.25254
Timestep Consumption Time: 9.49079
PPO Batch Consumption Time: 1.28722
Total Iteration Time: 24.74333

Cumulative Model Updates: 1,746
Cumulative Timesteps: 14,600,654

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 14600654...
Checkpoint 14600654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.53853
Policy Entropy: 1.40569
Value Function Loss: 0.29577

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.01938
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.12163

Collected Steps per Second: 3,308.19777
Overall Steps per Second: 2,039.48710

Timestep Collection Time: 15.11488
Timestep Consumption Time: 9.40256
PPO Batch Consumption Time: 1.28210
Total Iteration Time: 24.51744

Cumulative Model Updates: 1,752
Cumulative Timesteps: 14,650,657

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.89557
Policy Entropy: 1.40462
Value Function Loss: 0.30117

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.06707
Value Function Update Magnitude: 0.10676

Collected Steps per Second: 3,282.03398
Overall Steps per Second: 2,028.69322

Timestep Collection Time: 15.23446
Timestep Consumption Time: 9.41195
PPO Batch Consumption Time: 1.29074
Total Iteration Time: 24.64641

Cumulative Model Updates: 1,758
Cumulative Timesteps: 14,700,657

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14700657...
Checkpoint 14700657 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.19193
Policy Entropy: 1.40440
Value Function Loss: 0.30828

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02055
Policy Update Magnitude: 0.06883
Value Function Update Magnitude: 0.10450

Collected Steps per Second: 3,286.93529
Overall Steps per Second: 2,022.87399

Timestep Collection Time: 15.21296
Timestep Consumption Time: 9.50633
PPO Batch Consumption Time: 1.30922
Total Iteration Time: 24.71929

Cumulative Model Updates: 1,764
Cumulative Timesteps: 14,750,661

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.60531
Policy Entropy: 1.40359
Value Function Loss: 0.30704

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.07048
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 3,288.98787
Overall Steps per Second: 2,017.68095

Timestep Collection Time: 15.20225
Timestep Consumption Time: 9.57868
PPO Batch Consumption Time: 1.30865
Total Iteration Time: 24.78092

Cumulative Model Updates: 1,770
Cumulative Timesteps: 14,800,661

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14800661...
Checkpoint 14800661 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.71670
Policy Entropy: 1.40646
Value Function Loss: 0.29981

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01836
Policy Update Magnitude: 0.07368
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 3,296.85385
Overall Steps per Second: 2,038.14487

Timestep Collection Time: 15.16658
Timestep Consumption Time: 9.36651
PPO Batch Consumption Time: 1.28151
Total Iteration Time: 24.53309

Cumulative Model Updates: 1,776
Cumulative Timesteps: 14,850,663

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.51224
Policy Entropy: 1.40510
Value Function Loss: 0.29576

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01967
Policy Update Magnitude: 0.07415
Value Function Update Magnitude: 0.10573

Collected Steps per Second: 3,286.65205
Overall Steps per Second: 2,013.94864

Timestep Collection Time: 15.21305
Timestep Consumption Time: 9.61380
PPO Batch Consumption Time: 1.33754
Total Iteration Time: 24.82685

Cumulative Model Updates: 1,782
Cumulative Timesteps: 14,900,663

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14900663...
Checkpoint 14900663 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.20001
Policy Entropy: 1.40502
Value Function Loss: 0.30331

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.08091
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 3,224.54407
Overall Steps per Second: 2,004.74301

Timestep Collection Time: 15.50731
Timestep Consumption Time: 9.43554
PPO Batch Consumption Time: 1.27595
Total Iteration Time: 24.94285

Cumulative Model Updates: 1,788
Cumulative Timesteps: 14,950,667

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.01006
Policy Entropy: 1.40540
Value Function Loss: 0.30292

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.07762
Value Function Update Magnitude: 0.10788

Collected Steps per Second: 3,312.23401
Overall Steps per Second: 2,036.09759

Timestep Collection Time: 15.09585
Timestep Consumption Time: 9.46142
PPO Batch Consumption Time: 1.29396
Total Iteration Time: 24.55727

Cumulative Model Updates: 1,794
Cumulative Timesteps: 15,000,668

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 15000668...
Checkpoint 15000668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.11010
Policy Entropy: 1.40513
Value Function Loss: 0.30557

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.07568
Value Function Update Magnitude: 0.10623

Collected Steps per Second: 3,313.22197
Overall Steps per Second: 2,037.34347

Timestep Collection Time: 15.09135
Timestep Consumption Time: 9.45090
PPO Batch Consumption Time: 1.30487
Total Iteration Time: 24.54225

Cumulative Model Updates: 1,800
Cumulative Timesteps: 15,050,669

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.49221
Policy Entropy: 1.40705
Value Function Loss: 0.29907

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.07465
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 3,318.88039
Overall Steps per Second: 2,042.04554

Timestep Collection Time: 15.06683
Timestep Consumption Time: 9.42087
PPO Batch Consumption Time: 1.27607
Total Iteration Time: 24.48770

Cumulative Model Updates: 1,806
Cumulative Timesteps: 15,100,674

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 15100674...
Checkpoint 15100674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.18778
Policy Entropy: 1.40595
Value Function Loss: 0.30784

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.07547
Value Function Update Magnitude: 0.11432

Collected Steps per Second: 3,291.18347
Overall Steps per Second: 2,030.06544

Timestep Collection Time: 15.19332
Timestep Consumption Time: 9.43840
PPO Batch Consumption Time: 1.30110
Total Iteration Time: 24.63172

Cumulative Model Updates: 1,812
Cumulative Timesteps: 15,150,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.30455
Policy Entropy: 1.40610
Value Function Loss: 0.30742

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.07446
Value Function Update Magnitude: 0.11821

Collected Steps per Second: 3,288.25621
Overall Steps per Second: 2,029.95098

Timestep Collection Time: 15.20563
Timestep Consumption Time: 9.42551
PPO Batch Consumption Time: 1.29415
Total Iteration Time: 24.63114

Cumulative Model Updates: 1,818
Cumulative Timesteps: 15,200,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 15200678...
Checkpoint 15200678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.62231
Policy Entropy: 1.40660
Value Function Loss: 0.31284

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.03696
Policy Update Magnitude: 0.08703
Value Function Update Magnitude: 0.11590

Collected Steps per Second: 3,298.03794
Overall Steps per Second: 2,031.73778

Timestep Collection Time: 15.16174
Timestep Consumption Time: 9.44970
PPO Batch Consumption Time: 1.28782
Total Iteration Time: 24.61144

Cumulative Model Updates: 1,824
Cumulative Timesteps: 15,250,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.88674
Policy Entropy: 1.40613
Value Function Loss: 0.30715

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.04715
Policy Update Magnitude: 0.07857
Value Function Update Magnitude: 0.10466

Collected Steps per Second: 3,305.07794
Overall Steps per Second: 2,024.24681

Timestep Collection Time: 15.12884
Timestep Consumption Time: 9.57269
PPO Batch Consumption Time: 1.31528
Total Iteration Time: 24.70153

Cumulative Model Updates: 1,830
Cumulative Timesteps: 15,300,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 15300684...
Checkpoint 15300684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.57628
Policy Entropy: 1.40561
Value Function Loss: 0.30942

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.04496
Policy Update Magnitude: 0.07263
Value Function Update Magnitude: 0.10653

Collected Steps per Second: 3,316.35473
Overall Steps per Second: 2,044.06302

Timestep Collection Time: 15.07800
Timestep Consumption Time: 9.38504
PPO Batch Consumption Time: 1.27778
Total Iteration Time: 24.46304

Cumulative Model Updates: 1,836
Cumulative Timesteps: 15,350,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.11651
Policy Entropy: 1.40570
Value Function Loss: 0.30653

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 0.07462
Value Function Update Magnitude: 0.11127

Collected Steps per Second: 3,302.24692
Overall Steps per Second: 2,039.20357

Timestep Collection Time: 15.14181
Timestep Consumption Time: 9.37855
PPO Batch Consumption Time: 1.28222
Total Iteration Time: 24.52036

Cumulative Model Updates: 1,842
Cumulative Timesteps: 15,400,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 15400690...
Checkpoint 15400690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.87895
Policy Entropy: 1.40664
Value Function Loss: 0.30833

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.02976
Policy Update Magnitude: 0.07262
Value Function Update Magnitude: 0.12191

Collected Steps per Second: 3,295.11297
Overall Steps per Second: 2,032.80110

Timestep Collection Time: 15.17520
Timestep Consumption Time: 9.42337
PPO Batch Consumption Time: 1.28491
Total Iteration Time: 24.59857

Cumulative Model Updates: 1,848
Cumulative Timesteps: 15,450,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.09519
Policy Entropy: 1.40466
Value Function Loss: 0.31359

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02160
Policy Update Magnitude: 0.07465
Value Function Update Magnitude: 0.10675

Collected Steps per Second: 3,286.75974
Overall Steps per Second: 2,039.30263

Timestep Collection Time: 15.21407
Timestep Consumption Time: 9.30657
PPO Batch Consumption Time: 1.27830
Total Iteration Time: 24.52064

Cumulative Model Updates: 1,854
Cumulative Timesteps: 15,500,699

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 15500699...
Checkpoint 15500699 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.11045
Policy Entropy: 1.40645
Value Function Loss: 0.31638

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.03737
Policy Update Magnitude: 0.07903
Value Function Update Magnitude: 0.10737

Collected Steps per Second: 3,300.17720
Overall Steps per Second: 2,031.92239

Timestep Collection Time: 15.15070
Timestep Consumption Time: 9.45654
PPO Batch Consumption Time: 1.30830
Total Iteration Time: 24.60724

Cumulative Model Updates: 1,860
Cumulative Timesteps: 15,550,699

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.51755
Policy Entropy: 1.40480
Value Function Loss: 0.31167

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.05612
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.11059

Collected Steps per Second: 3,318.81327
Overall Steps per Second: 2,036.04689

Timestep Collection Time: 15.06683
Timestep Consumption Time: 9.49252
PPO Batch Consumption Time: 1.29490
Total Iteration Time: 24.55936

Cumulative Model Updates: 1,866
Cumulative Timesteps: 15,600,703

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 15600703...
Checkpoint 15600703 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.91285
Policy Entropy: 1.40578
Value Function Loss: 0.30367

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.03835
Policy Update Magnitude: 0.07485
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 3,326.95710
Overall Steps per Second: 2,045.13358

Timestep Collection Time: 15.02905
Timestep Consumption Time: 9.41972
PPO Batch Consumption Time: 1.29359
Total Iteration Time: 24.44877

Cumulative Model Updates: 1,872
Cumulative Timesteps: 15,650,704

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.81871
Policy Entropy: 1.40626
Value Function Loss: 0.30237

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.06955
Value Function Update Magnitude: 0.11116

Collected Steps per Second: 3,263.96375
Overall Steps per Second: 2,013.20873

Timestep Collection Time: 15.32002
Timestep Consumption Time: 9.51794
PPO Batch Consumption Time: 1.30137
Total Iteration Time: 24.83796

Cumulative Model Updates: 1,878
Cumulative Timesteps: 15,700,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 15700708...
Checkpoint 15700708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.58416
Policy Entropy: 1.40583
Value Function Loss: 0.30827

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.10466

Collected Steps per Second: 3,209.43704
Overall Steps per Second: 2,013.71212

Timestep Collection Time: 15.57937
Timestep Consumption Time: 9.25089
PPO Batch Consumption Time: 1.26178
Total Iteration Time: 24.83026

Cumulative Model Updates: 1,884
Cumulative Timesteps: 15,750,709

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.95276
Policy Entropy: 1.40682
Value Function Loss: 0.30718

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.07171
Value Function Update Magnitude: 0.10238

Collected Steps per Second: 3,281.55316
Overall Steps per Second: 2,020.51342

Timestep Collection Time: 15.23760
Timestep Consumption Time: 9.51007
PPO Batch Consumption Time: 1.30983
Total Iteration Time: 24.74767

Cumulative Model Updates: 1,890
Cumulative Timesteps: 15,800,712

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 15800712...
Checkpoint 15800712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.83638
Policy Entropy: 1.40646
Value Function Loss: 0.31423

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.01916
Policy Update Magnitude: 0.07510
Value Function Update Magnitude: 0.10583

Collected Steps per Second: 3,324.66912
Overall Steps per Second: 2,003.76136

Timestep Collection Time: 15.03999
Timestep Consumption Time: 9.91458
PPO Batch Consumption Time: 1.33454
Total Iteration Time: 24.95457

Cumulative Model Updates: 1,896
Cumulative Timesteps: 15,850,715

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.58034
Policy Entropy: 1.40620
Value Function Loss: 0.31731

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.07300
Value Function Update Magnitude: 0.11214

Collected Steps per Second: 3,304.44693
Overall Steps per Second: 2,044.71269

Timestep Collection Time: 15.13173
Timestep Consumption Time: 9.32256
PPO Batch Consumption Time: 1.28254
Total Iteration Time: 24.45429

Cumulative Model Updates: 1,902
Cumulative Timesteps: 15,900,717

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 15900717...
Checkpoint 15900717 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.23385
Policy Entropy: 1.40507
Value Function Loss: 0.32205

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.04013
Policy Update Magnitude: 0.07152
Value Function Update Magnitude: 0.11753

Collected Steps per Second: 3,212.45257
Overall Steps per Second: 2,019.66623

Timestep Collection Time: 15.56474
Timestep Consumption Time: 9.19232
PPO Batch Consumption Time: 1.26622
Total Iteration Time: 24.75706

Cumulative Model Updates: 1,908
Cumulative Timesteps: 15,950,718

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.74182
Policy Entropy: 1.40671
Value Function Loss: 0.32215

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 0.06876
Value Function Update Magnitude: 0.12840

Collected Steps per Second: 3,240.12413
Overall Steps per Second: 2,016.35431

Timestep Collection Time: 15.43212
Timestep Consumption Time: 9.36610
PPO Batch Consumption Time: 1.28582
Total Iteration Time: 24.79822

Cumulative Model Updates: 1,914
Cumulative Timesteps: 16,000,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 16000720...
Checkpoint 16000720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.12115
Policy Entropy: 1.40520
Value Function Loss: 0.32411

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.03423
Policy Update Magnitude: 0.07208
Value Function Update Magnitude: 0.12231

Collected Steps per Second: 3,280.95022
Overall Steps per Second: 2,034.79828

Timestep Collection Time: 15.24071
Timestep Consumption Time: 9.33372
PPO Batch Consumption Time: 1.27571
Total Iteration Time: 24.57443

Cumulative Model Updates: 1,920
Cumulative Timesteps: 16,050,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.22413
Policy Entropy: 1.40601
Value Function Loss: 0.32288

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.12339

Collected Steps per Second: 3,322.18175
Overall Steps per Second: 2,043.97137

Timestep Collection Time: 15.05095
Timestep Consumption Time: 9.41221
PPO Batch Consumption Time: 1.29036
Total Iteration Time: 24.46316

Cumulative Model Updates: 1,926
Cumulative Timesteps: 16,100,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 16100726...
Checkpoint 16100726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.77802
Policy Entropy: 1.40639
Value Function Loss: 0.31992

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.06843
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 3,285.56952
Overall Steps per Second: 2,016.72660

Timestep Collection Time: 15.21806
Timestep Consumption Time: 9.57459
PPO Batch Consumption Time: 1.30067
Total Iteration Time: 24.79265

Cumulative Model Updates: 1,932
Cumulative Timesteps: 16,150,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.29036
Policy Entropy: 1.40609
Value Function Loss: 0.31946

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.07257
Value Function Update Magnitude: 0.10652

Collected Steps per Second: 3,276.33638
Overall Steps per Second: 2,014.39683

Timestep Collection Time: 15.26125
Timestep Consumption Time: 9.56057
PPO Batch Consumption Time: 1.31885
Total Iteration Time: 24.82182

Cumulative Model Updates: 1,938
Cumulative Timesteps: 16,200,727

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 16200727...
Checkpoint 16200727 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.31679
Policy Entropy: 1.40636
Value Function Loss: 0.32077

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01970
Policy Update Magnitude: 0.07354
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 3,220.98237
Overall Steps per Second: 2,012.82006

Timestep Collection Time: 15.52415
Timestep Consumption Time: 9.31811
PPO Batch Consumption Time: 1.28150
Total Iteration Time: 24.84226

Cumulative Model Updates: 1,944
Cumulative Timesteps: 16,250,730

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.78014
Policy Entropy: 1.40730
Value Function Loss: 0.31824

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01890
Policy Update Magnitude: 0.07265
Value Function Update Magnitude: 0.11868

Collected Steps per Second: 3,299.54816
Overall Steps per Second: 2,047.01183

Timestep Collection Time: 15.15359
Timestep Consumption Time: 9.27226
PPO Batch Consumption Time: 1.27294
Total Iteration Time: 24.42585

Cumulative Model Updates: 1,950
Cumulative Timesteps: 16,300,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16300730...
Checkpoint 16300730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.35319
Policy Entropy: 1.40597
Value Function Loss: 0.31099

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02126
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.11186

Collected Steps per Second: 3,312.86668
Overall Steps per Second: 2,032.52033

Timestep Collection Time: 15.09357
Timestep Consumption Time: 9.50790
PPO Batch Consumption Time: 1.29656
Total Iteration Time: 24.60148

Cumulative Model Updates: 1,956
Cumulative Timesteps: 16,350,733

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.22554
Policy Entropy: 1.40660
Value Function Loss: 0.30738

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.07053
Value Function Update Magnitude: 0.10579

Collected Steps per Second: 3,334.74960
Overall Steps per Second: 2,042.45139

Timestep Collection Time: 14.99363
Timestep Consumption Time: 9.48676
PPO Batch Consumption Time: 1.29869
Total Iteration Time: 24.48039

Cumulative Model Updates: 1,962
Cumulative Timesteps: 16,400,733

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16400733...
Checkpoint 16400733 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.76417
Policy Entropy: 1.40464
Value Function Loss: 0.31598

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02044
Policy Update Magnitude: 0.07191
Value Function Update Magnitude: 0.10361

Collected Steps per Second: 3,331.94967
Overall Steps per Second: 2,048.11070

Timestep Collection Time: 15.00683
Timestep Consumption Time: 9.40689
PPO Batch Consumption Time: 1.27764
Total Iteration Time: 24.41372

Cumulative Model Updates: 1,968
Cumulative Timesteps: 16,450,735

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.27758
Policy Entropy: 1.40476
Value Function Loss: 0.31440

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.07517
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 3,284.03847
Overall Steps per Second: 2,033.96229

Timestep Collection Time: 15.22607
Timestep Consumption Time: 9.35796
PPO Batch Consumption Time: 1.26858
Total Iteration Time: 24.58403

Cumulative Model Updates: 1,974
Cumulative Timesteps: 16,500,738

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 16500738...
Checkpoint 16500738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.59000
Policy Entropy: 1.40429
Value Function Loss: 0.31247

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.07512
Value Function Update Magnitude: 0.10134

Collected Steps per Second: 3,264.86382
Overall Steps per Second: 2,033.19416

Timestep Collection Time: 15.31549
Timestep Consumption Time: 9.27783
PPO Batch Consumption Time: 1.27818
Total Iteration Time: 24.59332

Cumulative Model Updates: 1,980
Cumulative Timesteps: 16,550,741

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.10531
Policy Entropy: 1.40965
Value Function Loss: 0.31100

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.04726
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.10148

Collected Steps per Second: 3,312.77923
Overall Steps per Second: 2,032.73878

Timestep Collection Time: 15.09337
Timestep Consumption Time: 9.50448
PPO Batch Consumption Time: 1.29494
Total Iteration Time: 24.59785

Cumulative Model Updates: 1,986
Cumulative Timesteps: 16,600,742

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 16600742...
Checkpoint 16600742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.36688
Policy Entropy: 1.40875
Value Function Loss: 0.30927

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.03751
Policy Update Magnitude: 0.07079
Value Function Update Magnitude: 0.11104

Collected Steps per Second: 3,323.86652
Overall Steps per Second: 2,039.81603

Timestep Collection Time: 15.04272
Timestep Consumption Time: 9.46929
PPO Batch Consumption Time: 1.29897
Total Iteration Time: 24.51201

Cumulative Model Updates: 1,992
Cumulative Timesteps: 16,650,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.59580
Policy Entropy: 1.40816
Value Function Loss: 0.30320

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.10433

Collected Steps per Second: 3,303.57467
Overall Steps per Second: 2,047.32023

Timestep Collection Time: 15.13603
Timestep Consumption Time: 9.28761
PPO Batch Consumption Time: 1.27459
Total Iteration Time: 24.42363

Cumulative Model Updates: 1,998
Cumulative Timesteps: 16,700,745

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 16700745...
Checkpoint 16700745 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.29532
Policy Entropy: 1.40825
Value Function Loss: 0.29808

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.09749

Collected Steps per Second: 3,275.86839
Overall Steps per Second: 2,036.66020

Timestep Collection Time: 15.26343
Timestep Consumption Time: 9.28705
PPO Batch Consumption Time: 1.28991
Total Iteration Time: 24.55049

Cumulative Model Updates: 2,004
Cumulative Timesteps: 16,750,746

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.70284
Policy Entropy: 1.40789
Value Function Loss: 0.30277

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03103
Policy Update Magnitude: 0.06783
Value Function Update Magnitude: 0.09770

Collected Steps per Second: 3,295.21219
Overall Steps per Second: 2,040.45791

Timestep Collection Time: 15.17353
Timestep Consumption Time: 9.33077
PPO Batch Consumption Time: 1.27785
Total Iteration Time: 24.50430

Cumulative Model Updates: 2,010
Cumulative Timesteps: 16,800,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16800746...
Checkpoint 16800746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.47110
Policy Entropy: 1.40772
Value Function Loss: 0.31221

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 3,350.65569
Overall Steps per Second: 2,053.08298

Timestep Collection Time: 14.92305
Timestep Consumption Time: 9.43154
PPO Batch Consumption Time: 1.27671
Total Iteration Time: 24.35459

Cumulative Model Updates: 2,016
Cumulative Timesteps: 16,850,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.68493
Policy Entropy: 1.40813
Value Function Loss: 0.31162

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02138
Policy Update Magnitude: 0.06846
Value Function Update Magnitude: 0.10836

Collected Steps per Second: 3,293.24701
Overall Steps per Second: 2,026.50905

Timestep Collection Time: 15.18380
Timestep Consumption Time: 9.49115
PPO Batch Consumption Time: 1.29029
Total Iteration Time: 24.67495

Cumulative Model Updates: 2,022
Cumulative Timesteps: 16,900,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 16900752...
Checkpoint 16900752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.49946
Policy Entropy: 1.40768
Value Function Loss: 0.31008

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02031
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.10350

Collected Steps per Second: 3,324.25918
Overall Steps per Second: 2,016.90486

Timestep Collection Time: 15.04185
Timestep Consumption Time: 9.75010
PPO Batch Consumption Time: 1.36178
Total Iteration Time: 24.79195

Cumulative Model Updates: 2,028
Cumulative Timesteps: 16,950,755

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.91237
Policy Entropy: 1.40771
Value Function Loss: 0.31039

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01980
Policy Update Magnitude: 0.06691
Value Function Update Magnitude: 0.10742

Collected Steps per Second: 3,256.08831
Overall Steps per Second: 2,031.88618

Timestep Collection Time: 15.35646
Timestep Consumption Time: 9.25220
PPO Batch Consumption Time: 1.28186
Total Iteration Time: 24.60866

Cumulative Model Updates: 2,034
Cumulative Timesteps: 17,000,757

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 17000757...
Checkpoint 17000757 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.65759
Policy Entropy: 1.40656
Value Function Loss: 0.31413

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.10529

Collected Steps per Second: 3,285.38816
Overall Steps per Second: 2,047.69253

Timestep Collection Time: 15.21981
Timestep Consumption Time: 9.19938
PPO Batch Consumption Time: 1.26637
Total Iteration Time: 24.41919

Cumulative Model Updates: 2,040
Cumulative Timesteps: 17,050,760

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.52118
Policy Entropy: 1.40705
Value Function Loss: 0.32234

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.01738
Policy Update Magnitude: 0.06981
Value Function Update Magnitude: 0.10876

Collected Steps per Second: 3,303.01031
Overall Steps per Second: 2,044.32381

Timestep Collection Time: 15.13771
Timestep Consumption Time: 9.32026
PPO Batch Consumption Time: 1.27634
Total Iteration Time: 24.45796

Cumulative Model Updates: 2,046
Cumulative Timesteps: 17,100,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17100760...
Checkpoint 17100760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.12183
Policy Entropy: 1.40702
Value Function Loss: 0.32946

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02175
Policy Update Magnitude: 0.06948
Value Function Update Magnitude: 0.11306

Collected Steps per Second: 3,311.63397
Overall Steps per Second: 2,038.59251

Timestep Collection Time: 15.09889
Timestep Consumption Time: 9.42882
PPO Batch Consumption Time: 1.28144
Total Iteration Time: 24.52771

Cumulative Model Updates: 2,052
Cumulative Timesteps: 17,150,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.69514
Policy Entropy: 1.40801
Value Function Loss: 0.32535

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.03136
Policy Update Magnitude: 0.06766
Value Function Update Magnitude: 0.11057

Collected Steps per Second: 3,306.48901
Overall Steps per Second: 2,046.68545

Timestep Collection Time: 15.12178
Timestep Consumption Time: 9.30796
PPO Batch Consumption Time: 1.27021
Total Iteration Time: 24.42974

Cumulative Model Updates: 2,058
Cumulative Timesteps: 17,200,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17200762...
Checkpoint 17200762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.79548
Policy Entropy: 1.40619
Value Function Loss: 0.32195

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.03353
Policy Update Magnitude: 0.06808
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 3,302.33298
Overall Steps per Second: 2,054.27286

Timestep Collection Time: 15.14142
Timestep Consumption Time: 9.19907
PPO Batch Consumption Time: 1.25969
Total Iteration Time: 24.34049

Cumulative Model Updates: 2,064
Cumulative Timesteps: 17,250,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.97289
Policy Entropy: 1.40753
Value Function Loss: 0.30690

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03193
Policy Update Magnitude: 0.06893
Value Function Update Magnitude: 0.11759

Collected Steps per Second: 3,320.97854
Overall Steps per Second: 2,057.90534

Timestep Collection Time: 15.05610
Timestep Consumption Time: 9.24093
PPO Batch Consumption Time: 1.26454
Total Iteration Time: 24.29704

Cumulative Model Updates: 2,070
Cumulative Timesteps: 17,300,765

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 17300765...
Checkpoint 17300765 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.26309
Policy Entropy: 1.40648
Value Function Loss: 0.30195

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 0.06906
Value Function Update Magnitude: 0.12037

Collected Steps per Second: 3,345.45442
Overall Steps per Second: 2,061.87955

Timestep Collection Time: 14.94685
Timestep Consumption Time: 9.30481
PPO Batch Consumption Time: 1.26107
Total Iteration Time: 24.25166

Cumulative Model Updates: 2,076
Cumulative Timesteps: 17,350,769

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.00970
Policy Entropy: 1.40705
Value Function Loss: 0.29482

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 3,339.87631
Overall Steps per Second: 2,051.57779

Timestep Collection Time: 14.97091
Timestep Consumption Time: 9.40106
PPO Batch Consumption Time: 1.29445
Total Iteration Time: 24.37197

Cumulative Model Updates: 2,082
Cumulative Timesteps: 17,400,770

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 17400770...
Checkpoint 17400770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.31800
Policy Entropy: 1.40813
Value Function Loss: 0.30919

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.10768

Collected Steps per Second: 3,338.04380
Overall Steps per Second: 2,065.84533

Timestep Collection Time: 14.97883
Timestep Consumption Time: 9.22433
PPO Batch Consumption Time: 1.26689
Total Iteration Time: 24.20317

Cumulative Model Updates: 2,088
Cumulative Timesteps: 17,450,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.39246
Policy Entropy: 1.40752
Value Function Loss: 0.31490

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.10765

Collected Steps per Second: 3,309.18936
Overall Steps per Second: 2,059.20018

Timestep Collection Time: 15.10944
Timestep Consumption Time: 9.17183
PPO Batch Consumption Time: 1.26757
Total Iteration Time: 24.28127

Cumulative Model Updates: 2,094
Cumulative Timesteps: 17,500,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17500770...
Checkpoint 17500770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.96564
Policy Entropy: 1.40725
Value Function Loss: 0.31814

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.06107
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 3,300.34175
Overall Steps per Second: 2,049.42208

Timestep Collection Time: 15.14995
Timestep Consumption Time: 9.24718
PPO Batch Consumption Time: 1.25755
Total Iteration Time: 24.39712

Cumulative Model Updates: 2,100
Cumulative Timesteps: 17,550,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.01036
Policy Entropy: 1.40557
Value Function Loss: 0.30826

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.06674
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 3,340.54972
Overall Steps per Second: 2,020.66568

Timestep Collection Time: 14.96760
Timestep Consumption Time: 9.77672
PPO Batch Consumption Time: 1.34879
Total Iteration Time: 24.74432

Cumulative Model Updates: 2,106
Cumulative Timesteps: 17,600,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17600770...
Checkpoint 17600770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.30330
Policy Entropy: 1.41291
Value Function Loss: 0.30966

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.04703
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.11134

Collected Steps per Second: 3,316.27584
Overall Steps per Second: 2,044.19523

Timestep Collection Time: 15.07776
Timestep Consumption Time: 9.38273
PPO Batch Consumption Time: 1.29171
Total Iteration Time: 24.46048

Cumulative Model Updates: 2,112
Cumulative Timesteps: 17,650,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.21139
Policy Entropy: 1.41246
Value Function Loss: 0.31160

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.06810
Value Function Update Magnitude: 0.11412

Collected Steps per Second: 3,329.05817
Overall Steps per Second: 2,061.06925

Timestep Collection Time: 15.01986
Timestep Consumption Time: 9.24036
PPO Batch Consumption Time: 1.26614
Total Iteration Time: 24.26022

Cumulative Model Updates: 2,118
Cumulative Timesteps: 17,700,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 17700774...
Checkpoint 17700774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.99806
Policy Entropy: 1.41217
Value Function Loss: 0.31194

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.11407

Collected Steps per Second: 3,269.77720
Overall Steps per Second: 2,010.56901

Timestep Collection Time: 15.29279
Timestep Consumption Time: 9.57779
PPO Batch Consumption Time: 1.32683
Total Iteration Time: 24.87057

Cumulative Model Updates: 2,124
Cumulative Timesteps: 17,750,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.93064
Policy Entropy: 1.41248
Value Function Loss: 0.31572

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.11217

Collected Steps per Second: 3,277.91721
Overall Steps per Second: 2,044.91238

Timestep Collection Time: 15.25389
Timestep Consumption Time: 9.19752
PPO Batch Consumption Time: 1.25029
Total Iteration Time: 24.45141

Cumulative Model Updates: 2,130
Cumulative Timesteps: 17,800,779

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 17800779...
Checkpoint 17800779 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.00884
Policy Entropy: 1.41231
Value Function Loss: 0.31768

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01990
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.10770

Collected Steps per Second: 3,323.73021
Overall Steps per Second: 2,060.66110

Timestep Collection Time: 15.04334
Timestep Consumption Time: 9.22072
PPO Batch Consumption Time: 1.26134
Total Iteration Time: 24.26406

Cumulative Model Updates: 2,136
Cumulative Timesteps: 17,850,779

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.72235
Policy Entropy: 1.41188
Value Function Loss: 0.32184

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01980
Policy Update Magnitude: 0.06725
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 3,290.87366
Overall Steps per Second: 2,035.12310

Timestep Collection Time: 15.19414
Timestep Consumption Time: 9.37538
PPO Batch Consumption Time: 1.28315
Total Iteration Time: 24.56952

Cumulative Model Updates: 2,142
Cumulative Timesteps: 17,900,781

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 17900781...
Checkpoint 17900781 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.27530
Policy Entropy: 1.41147
Value Function Loss: 0.31356

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01736
Policy Update Magnitude: 0.07066
Value Function Update Magnitude: 0.10761

Collected Steps per Second: 3,286.58422
Overall Steps per Second: 2,043.94865

Timestep Collection Time: 15.21397
Timestep Consumption Time: 9.24946
PPO Batch Consumption Time: 1.26091
Total Iteration Time: 24.46343

Cumulative Model Updates: 2,148
Cumulative Timesteps: 17,950,783

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.68862
Policy Entropy: 1.41093
Value Function Loss: 0.31019

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01348
Policy Update Magnitude: 0.07152
Value Function Update Magnitude: 0.10653

Collected Steps per Second: 3,292.74377
Overall Steps per Second: 2,045.07995

Timestep Collection Time: 15.18582
Timestep Consumption Time: 9.26457
PPO Batch Consumption Time: 1.26504
Total Iteration Time: 24.45039

Cumulative Model Updates: 2,154
Cumulative Timesteps: 18,000,786

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 18000786...
Checkpoint 18000786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.87514
Policy Entropy: 1.41025
Value Function Loss: 0.30462

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01658
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.10184

Collected Steps per Second: 3,303.27646
Overall Steps per Second: 2,055.54554

Timestep Collection Time: 15.13709
Timestep Consumption Time: 9.18832
PPO Batch Consumption Time: 1.26747
Total Iteration Time: 24.32542

Cumulative Model Updates: 2,160
Cumulative Timesteps: 18,050,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.17921
Policy Entropy: 1.41087
Value Function Loss: 0.30704

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01660
Policy Update Magnitude: 0.07275
Value Function Update Magnitude: 0.10592

Collected Steps per Second: 3,318.07377
Overall Steps per Second: 2,055.66343

Timestep Collection Time: 15.06929
Timestep Consumption Time: 9.25425
PPO Batch Consumption Time: 1.26787
Total Iteration Time: 24.32353

Cumulative Model Updates: 2,166
Cumulative Timesteps: 18,100,789

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 18100789...
Checkpoint 18100789 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.04969
Policy Entropy: 1.41056
Value Function Loss: 0.30051

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.10688

Collected Steps per Second: 3,329.12312
Overall Steps per Second: 2,038.44026

Timestep Collection Time: 15.01897
Timestep Consumption Time: 9.50959
PPO Batch Consumption Time: 1.31108
Total Iteration Time: 24.52856

Cumulative Model Updates: 2,172
Cumulative Timesteps: 18,150,789

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.97091
Policy Entropy: 1.41099
Value Function Loss: 0.30283

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.06882
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 3,274.20131
Overall Steps per Second: 2,044.83039

Timestep Collection Time: 15.27151
Timestep Consumption Time: 9.18137
PPO Batch Consumption Time: 1.25842
Total Iteration Time: 24.45288

Cumulative Model Updates: 2,178
Cumulative Timesteps: 18,200,791

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 18200791...
Checkpoint 18200791 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.16660
Policy Entropy: 1.41044
Value Function Loss: 0.29878

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.10550

Collected Steps per Second: 3,316.71557
Overall Steps per Second: 2,055.72715

Timestep Collection Time: 15.07546
Timestep Consumption Time: 9.24732
PPO Batch Consumption Time: 1.26418
Total Iteration Time: 24.32278

Cumulative Model Updates: 2,184
Cumulative Timesteps: 18,250,792

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.76145
Policy Entropy: 1.41012
Value Function Loss: 0.30512

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.10644

Collected Steps per Second: 3,314.98688
Overall Steps per Second: 2,051.59455

Timestep Collection Time: 15.08422
Timestep Consumption Time: 9.28901
PPO Batch Consumption Time: 1.27642
Total Iteration Time: 24.37324

Cumulative Model Updates: 2,190
Cumulative Timesteps: 18,300,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18300796...
Checkpoint 18300796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.43472
Policy Entropy: 1.41021
Value Function Loss: 0.30381

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 3,336.95307
Overall Steps per Second: 2,075.77876

Timestep Collection Time: 14.98463
Timestep Consumption Time: 9.10416
PPO Batch Consumption Time: 1.24788
Total Iteration Time: 24.08879

Cumulative Model Updates: 2,196
Cumulative Timesteps: 18,350,799

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.18038
Policy Entropy: 1.40990
Value Function Loss: 0.30667

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02404
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.11948

Collected Steps per Second: 3,312.05623
Overall Steps per Second: 2,048.44165

Timestep Collection Time: 15.09666
Timestep Consumption Time: 9.31262
PPO Batch Consumption Time: 1.28391
Total Iteration Time: 24.40929

Cumulative Model Updates: 2,202
Cumulative Timesteps: 18,400,800

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 18400800...
Checkpoint 18400800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.03158
Policy Entropy: 1.40938
Value Function Loss: 0.30777

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.07057
Value Function Update Magnitude: 0.12220

Collected Steps per Second: 3,336.31225
Overall Steps per Second: 2,068.81495

Timestep Collection Time: 14.98721
Timestep Consumption Time: 9.18219
PPO Batch Consumption Time: 1.24891
Total Iteration Time: 24.16939

Cumulative Model Updates: 2,208
Cumulative Timesteps: 18,450,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.41031
Policy Entropy: 1.40942
Value Function Loss: 0.30392

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02166
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 3,320.88981
Overall Steps per Second: 2,051.65207

Timestep Collection Time: 15.05681
Timestep Consumption Time: 9.31477
PPO Batch Consumption Time: 1.27531
Total Iteration Time: 24.37158

Cumulative Model Updates: 2,214
Cumulative Timesteps: 18,500,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 18500804...
Checkpoint 18500804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.60183
Policy Entropy: 1.40994
Value Function Loss: 0.30589

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.11863

Collected Steps per Second: 3,363.63040
Overall Steps per Second: 2,073.09339

Timestep Collection Time: 14.86519
Timestep Consumption Time: 9.25384
PPO Batch Consumption Time: 1.26234
Total Iteration Time: 24.11903

Cumulative Model Updates: 2,220
Cumulative Timesteps: 18,550,805

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.12402
Policy Entropy: 1.40992
Value Function Loss: 0.30750

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.06991
Value Function Update Magnitude: 0.11519

Collected Steps per Second: 3,370.95432
Overall Steps per Second: 2,071.88200

Timestep Collection Time: 14.83289
Timestep Consumption Time: 9.30024
PPO Batch Consumption Time: 1.27586
Total Iteration Time: 24.13313

Cumulative Model Updates: 2,226
Cumulative Timesteps: 18,600,806

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 18600806...
Checkpoint 18600806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.17430
Policy Entropy: 1.40964
Value Function Loss: 0.30669

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 0.07388
Value Function Update Magnitude: 0.11137

Collected Steps per Second: 3,336.68550
Overall Steps per Second: 2,023.77897

Timestep Collection Time: 14.98613
Timestep Consumption Time: 9.72210
PPO Batch Consumption Time: 1.34670
Total Iteration Time: 24.70823

Cumulative Model Updates: 2,232
Cumulative Timesteps: 18,650,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.04709
Policy Entropy: 1.40947
Value Function Loss: 0.29895

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.04658
Policy Update Magnitude: 0.06775
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 3,330.64124
Overall Steps per Second: 2,069.38470

Timestep Collection Time: 15.01333
Timestep Consumption Time: 9.15038
PPO Batch Consumption Time: 1.24535
Total Iteration Time: 24.16370

Cumulative Model Updates: 2,238
Cumulative Timesteps: 18,700,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18700814...
Checkpoint 18700814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.03347
Policy Entropy: 1.41031
Value Function Loss: 0.29801

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 3,327.04162
Overall Steps per Second: 2,062.22082

Timestep Collection Time: 15.02867
Timestep Consumption Time: 9.21752
PPO Batch Consumption Time: 1.26036
Total Iteration Time: 24.24619

Cumulative Model Updates: 2,244
Cumulative Timesteps: 18,750,815

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.53027
Policy Entropy: 1.40886
Value Function Loss: 0.29900

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.06800
Value Function Update Magnitude: 0.12156

Collected Steps per Second: 3,298.48579
Overall Steps per Second: 2,058.76782

Timestep Collection Time: 15.15877
Timestep Consumption Time: 9.12808
PPO Batch Consumption Time: 1.24138
Total Iteration Time: 24.28686

Cumulative Model Updates: 2,250
Cumulative Timesteps: 18,800,816

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 18800816...
Checkpoint 18800816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.20088
Policy Entropy: 1.40838
Value Function Loss: 0.30019

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.06895
Value Function Update Magnitude: 0.12409

Collected Steps per Second: 3,309.78546
Overall Steps per Second: 2,064.08655

Timestep Collection Time: 15.10732
Timestep Consumption Time: 9.11744
PPO Batch Consumption Time: 1.25425
Total Iteration Time: 24.22476

Cumulative Model Updates: 2,256
Cumulative Timesteps: 18,850,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.03641
Policy Entropy: 1.40856
Value Function Loss: 0.29780

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.07077
Value Function Update Magnitude: 0.12694

Collected Steps per Second: 3,357.76845
Overall Steps per Second: 2,062.88766

Timestep Collection Time: 14.89174
Timestep Consumption Time: 9.34759
PPO Batch Consumption Time: 1.27573
Total Iteration Time: 24.23932

Cumulative Model Updates: 2,262
Cumulative Timesteps: 18,900,821

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 18900821...
Checkpoint 18900821 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.67541
Policy Entropy: 1.40850
Value Function Loss: 0.29965

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.06805
Value Function Update Magnitude: 0.12392

Collected Steps per Second: 3,348.60150
Overall Steps per Second: 2,074.70470

Timestep Collection Time: 14.93250
Timestep Consumption Time: 9.16876
PPO Batch Consumption Time: 1.24964
Total Iteration Time: 24.10126

Cumulative Model Updates: 2,268
Cumulative Timesteps: 18,950,824

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.36116
Policy Entropy: 1.40810
Value Function Loss: 0.30083

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.06714
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 3,303.95402
Overall Steps per Second: 2,045.75071

Timestep Collection Time: 15.13338
Timestep Consumption Time: 9.30752
PPO Batch Consumption Time: 1.27335
Total Iteration Time: 24.44091

Cumulative Model Updates: 2,274
Cumulative Timesteps: 19,000,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 19000824...
Checkpoint 19000824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.21254
Policy Entropy: 1.40896
Value Function Loss: 0.29132

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01911
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.10780

Collected Steps per Second: 3,287.61690
Overall Steps per Second: 2,050.56407

Timestep Collection Time: 15.20950
Timestep Consumption Time: 9.17550
PPO Batch Consumption Time: 1.23328
Total Iteration Time: 24.38500

Cumulative Model Updates: 2,280
Cumulative Timesteps: 19,050,827

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.36938
Policy Entropy: 1.40862
Value Function Loss: 0.29175

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01414
Policy Update Magnitude: 0.07202
Value Function Update Magnitude: 0.10927

Collected Steps per Second: 3,359.36803
Overall Steps per Second: 2,071.75908

Timestep Collection Time: 14.88405
Timestep Consumption Time: 9.25051
PPO Batch Consumption Time: 1.27938
Total Iteration Time: 24.13456

Cumulative Model Updates: 2,286
Cumulative Timesteps: 19,100,828

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 19100828...
Checkpoint 19100828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.37315
Policy Entropy: 1.40801
Value Function Loss: 0.28869

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 3,344.71138
Overall Steps per Second: 2,064.49467

Timestep Collection Time: 14.95017
Timestep Consumption Time: 9.27077
PPO Batch Consumption Time: 1.27049
Total Iteration Time: 24.22094

Cumulative Model Updates: 2,292
Cumulative Timesteps: 19,150,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.84471
Policy Entropy: 1.40860
Value Function Loss: 0.30240

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.07706
Value Function Update Magnitude: 0.11075

Collected Steps per Second: 3,353.87096
Overall Steps per Second: 2,078.94575

Timestep Collection Time: 14.90844
Timestep Consumption Time: 9.14269
PPO Batch Consumption Time: 1.25590
Total Iteration Time: 24.05113

Cumulative Model Updates: 2,298
Cumulative Timesteps: 19,200,833

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 19200833...
Checkpoint 19200833 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.90741
Policy Entropy: 1.40917
Value Function Loss: 0.29835

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.07324
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 3,326.14683
Overall Steps per Second: 2,069.92873

Timestep Collection Time: 15.03331
Timestep Consumption Time: 9.12356
PPO Batch Consumption Time: 1.24966
Total Iteration Time: 24.15687

Cumulative Model Updates: 2,304
Cumulative Timesteps: 19,250,836

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.61888
Policy Entropy: 1.40890
Value Function Loss: 0.30550

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.07082
Value Function Update Magnitude: 0.12665

Collected Steps per Second: 3,313.32187
Overall Steps per Second: 2,054.85016

Timestep Collection Time: 15.09090
Timestep Consumption Time: 9.24226
PPO Batch Consumption Time: 1.25781
Total Iteration Time: 24.33316

Cumulative Model Updates: 2,310
Cumulative Timesteps: 19,300,837

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 19300837...
Checkpoint 19300837 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.12649
Policy Entropy: 1.40808
Value Function Loss: 0.30174

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.07084
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 3,275.74773
Overall Steps per Second: 2,048.14976

Timestep Collection Time: 15.26430
Timestep Consumption Time: 9.14895
PPO Batch Consumption Time: 1.25571
Total Iteration Time: 24.41325

Cumulative Model Updates: 2,316
Cumulative Timesteps: 19,350,839

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.91292
Policy Entropy: 1.40928
Value Function Loss: 0.30443

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.07229
Value Function Update Magnitude: 0.13495

Collected Steps per Second: 3,348.64193
Overall Steps per Second: 2,061.32797

Timestep Collection Time: 14.93202
Timestep Consumption Time: 9.32515
PPO Batch Consumption Time: 1.27866
Total Iteration Time: 24.25718

Cumulative Model Updates: 2,322
Cumulative Timesteps: 19,400,841

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 19400841...
Checkpoint 19400841 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.85340
Policy Entropy: 1.40897
Value Function Loss: 0.29903

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01978
Policy Update Magnitude: 0.07461
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 3,354.51090
Overall Steps per Second: 2,082.11773

Timestep Collection Time: 14.90590
Timestep Consumption Time: 9.10907
PPO Batch Consumption Time: 1.24024
Total Iteration Time: 24.01497

Cumulative Model Updates: 2,328
Cumulative Timesteps: 19,450,843

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.50237
Policy Entropy: 1.40916
Value Function Loss: 0.29706

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.07248
Value Function Update Magnitude: 0.11930

Collected Steps per Second: 3,377.24782
Overall Steps per Second: 2,082.28345

Timestep Collection Time: 14.80584
Timestep Consumption Time: 9.20770
PPO Batch Consumption Time: 1.25410
Total Iteration Time: 24.01354

Cumulative Model Updates: 2,334
Cumulative Timesteps: 19,500,846

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 19500846...
Checkpoint 19500846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.78495
Policy Entropy: 1.40822
Value Function Loss: 0.29969

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01464
Policy Update Magnitude: 0.07675
Value Function Update Magnitude: 0.11672

Collected Steps per Second: 3,333.91533
Overall Steps per Second: 2,076.77454

Timestep Collection Time: 14.99828
Timestep Consumption Time: 9.07896
PPO Batch Consumption Time: 1.24998
Total Iteration Time: 24.07724

Cumulative Model Updates: 2,340
Cumulative Timesteps: 19,550,849

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.90113
Policy Entropy: 1.40764
Value Function Loss: 0.30423

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01667
Policy Update Magnitude: 0.07542
Value Function Update Magnitude: 0.11323

Collected Steps per Second: 3,348.51744
Overall Steps per Second: 2,059.82549

Timestep Collection Time: 14.93288
Timestep Consumption Time: 9.34248
PPO Batch Consumption Time: 1.27626
Total Iteration Time: 24.27536

Cumulative Model Updates: 2,346
Cumulative Timesteps: 19,600,852

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 19600852...
Checkpoint 19600852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.29951
Policy Entropy: 1.40792
Value Function Loss: 0.29918

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01766
Policy Update Magnitude: 0.07337
Value Function Update Magnitude: 0.11502

Collected Steps per Second: 3,302.52430
Overall Steps per Second: 2,042.39662

Timestep Collection Time: 15.14145
Timestep Consumption Time: 9.34204
PPO Batch Consumption Time: 1.28287
Total Iteration Time: 24.48349

Cumulative Model Updates: 2,352
Cumulative Timesteps: 19,650,857

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.40982
Policy Entropy: 1.40829
Value Function Loss: 0.29866

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.07841
Value Function Update Magnitude: 0.11647

Collected Steps per Second: 3,363.74816
Overall Steps per Second: 2,064.02059

Timestep Collection Time: 14.86437
Timestep Consumption Time: 9.36019
PPO Batch Consumption Time: 1.28921
Total Iteration Time: 24.22456

Cumulative Model Updates: 2,358
Cumulative Timesteps: 19,700,857

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 19700857...
Checkpoint 19700857 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.49012
Policy Entropy: 1.40889
Value Function Loss: 0.29667

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02132
Policy Update Magnitude: 0.06923
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 3,298.16959
Overall Steps per Second: 2,062.34113

Timestep Collection Time: 15.16114
Timestep Consumption Time: 9.08509
PPO Batch Consumption Time: 1.24576
Total Iteration Time: 24.24623

Cumulative Model Updates: 2,364
Cumulative Timesteps: 19,750,861

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.79603
Policy Entropy: 1.40929
Value Function Loss: 0.30399

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02164
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 3,271.79532
Overall Steps per Second: 2,045.49110

Timestep Collection Time: 15.28244
Timestep Consumption Time: 9.16206
PPO Batch Consumption Time: 1.23774
Total Iteration Time: 24.44450

Cumulative Model Updates: 2,370
Cumulative Timesteps: 19,800,862

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 19800862...
Checkpoint 19800862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.34284
Policy Entropy: 1.40882
Value Function Loss: 0.29994

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.06650
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 3,349.94727
Overall Steps per Second: 2,075.13908

Timestep Collection Time: 14.92680
Timestep Consumption Time: 9.16990
PPO Batch Consumption Time: 1.24669
Total Iteration Time: 24.09670

Cumulative Model Updates: 2,376
Cumulative Timesteps: 19,850,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.55122
Policy Entropy: 1.40795
Value Function Loss: 0.30307

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02202
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.12596

Collected Steps per Second: 3,289.80802
Overall Steps per Second: 2,039.66965

Timestep Collection Time: 15.19998
Timestep Consumption Time: 9.31625
PPO Batch Consumption Time: 1.27969
Total Iteration Time: 24.51623

Cumulative Model Updates: 2,382
Cumulative Timesteps: 19,900,871

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 19900871...
Checkpoint 19900871 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.88847
Policy Entropy: 1.40753
Value Function Loss: 0.29687

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02048
Policy Update Magnitude: 0.06827
Value Function Update Magnitude: 0.11945

Collected Steps per Second: 3,350.44029
Overall Steps per Second: 2,080.91041

Timestep Collection Time: 14.92371
Timestep Consumption Time: 9.10471
PPO Batch Consumption Time: 1.23859
Total Iteration Time: 24.02843

Cumulative Model Updates: 2,388
Cumulative Timesteps: 19,950,872

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.78678
Policy Entropy: 1.40727
Value Function Loss: 0.30489

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01888
Policy Update Magnitude: 0.07465
Value Function Update Magnitude: 0.11716

Collected Steps per Second: 3,306.73556
Overall Steps per Second: 2,059.78562

Timestep Collection Time: 15.12065
Timestep Consumption Time: 9.15372
PPO Batch Consumption Time: 1.22801
Total Iteration Time: 24.27437

Cumulative Model Updates: 2,394
Cumulative Timesteps: 20,000,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 20000872...
Checkpoint 20000872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.08410
Policy Entropy: 1.40674
Value Function Loss: 0.30233

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.07152
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 3,345.02287
Overall Steps per Second: 2,076.21788

Timestep Collection Time: 14.94818
Timestep Consumption Time: 9.13504
PPO Batch Consumption Time: 1.24872
Total Iteration Time: 24.08321

Cumulative Model Updates: 2,400
Cumulative Timesteps: 20,050,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.22663
Policy Entropy: 1.40759
Value Function Loss: 0.30081

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.07229
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 3,344.40586
Overall Steps per Second: 2,055.96392

Timestep Collection Time: 14.95094
Timestep Consumption Time: 9.36953
PPO Batch Consumption Time: 1.28273
Total Iteration Time: 24.32047

Cumulative Model Updates: 2,406
Cumulative Timesteps: 20,100,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 20100876...
Checkpoint 20100876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.05519
Policy Entropy: 1.40796
Value Function Loss: 0.29721

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.07082
Value Function Update Magnitude: 0.11473

Collected Steps per Second: 3,248.37045
Overall Steps per Second: 2,030.81914

Timestep Collection Time: 15.39295
Timestep Consumption Time: 9.22864
PPO Batch Consumption Time: 1.27401
Total Iteration Time: 24.62159

Cumulative Model Updates: 2,412
Cumulative Timesteps: 20,150,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.31716
Policy Entropy: 1.40822
Value Function Loss: 0.30346

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.07039
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 3,317.17853
Overall Steps per Second: 2,066.38447

Timestep Collection Time: 15.07426
Timestep Consumption Time: 9.12453
PPO Batch Consumption Time: 1.24405
Total Iteration Time: 24.19879

Cumulative Model Updates: 2,418
Cumulative Timesteps: 20,200,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 20200882...
Checkpoint 20200882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.65726
Policy Entropy: 1.40844
Value Function Loss: 0.31191

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.07049
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 3,303.86350
Overall Steps per Second: 2,061.79886

Timestep Collection Time: 15.13410
Timestep Consumption Time: 9.11705
PPO Batch Consumption Time: 1.23765
Total Iteration Time: 24.25115

Cumulative Model Updates: 2,424
Cumulative Timesteps: 20,250,883

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.39374
Policy Entropy: 1.40825
Value Function Loss: 0.30444

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.11020

Collected Steps per Second: 3,335.49990
Overall Steps per Second: 2,035.22236

Timestep Collection Time: 14.99086
Timestep Consumption Time: 9.57747
PPO Batch Consumption Time: 1.31272
Total Iteration Time: 24.56832

Cumulative Model Updates: 2,430
Cumulative Timesteps: 20,300,885

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 20300885...
Checkpoint 20300885 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.93053
Policy Entropy: 1.40797
Value Function Loss: 0.29517

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03115
Policy Update Magnitude: 0.07058
Value Function Update Magnitude: 0.11046

Collected Steps per Second: 3,321.50075
Overall Steps per Second: 2,062.22909

Timestep Collection Time: 15.05434
Timestep Consumption Time: 9.19272
PPO Batch Consumption Time: 1.24317
Total Iteration Time: 24.24706

Cumulative Model Updates: 2,436
Cumulative Timesteps: 20,350,888

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.32950
Policy Entropy: 1.40763
Value Function Loss: 0.29442

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03373
Policy Update Magnitude: 0.07206
Value Function Update Magnitude: 0.11131

Collected Steps per Second: 3,330.69076
Overall Steps per Second: 2,054.64035

Timestep Collection Time: 15.01190
Timestep Consumption Time: 9.32326
PPO Batch Consumption Time: 1.26314
Total Iteration Time: 24.33516

Cumulative Model Updates: 2,442
Cumulative Timesteps: 20,400,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 20400888...
Checkpoint 20400888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.61107
Policy Entropy: 1.40765
Value Function Loss: 0.30278

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.11636

Collected Steps per Second: 3,319.95899
Overall Steps per Second: 2,069.09611

Timestep Collection Time: 15.06133
Timestep Consumption Time: 9.10526
PPO Batch Consumption Time: 1.23579
Total Iteration Time: 24.16659

Cumulative Model Updates: 2,448
Cumulative Timesteps: 20,450,891

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.35498
Policy Entropy: 1.40754
Value Function Loss: 0.30394

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03558
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.11023

Collected Steps per Second: 3,313.10529
Overall Steps per Second: 2,042.12072

Timestep Collection Time: 15.09219
Timestep Consumption Time: 9.39314
PPO Batch Consumption Time: 1.28991
Total Iteration Time: 24.48533

Cumulative Model Updates: 2,454
Cumulative Timesteps: 20,500,893

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 20500893...
Checkpoint 20500893 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.68125
Policy Entropy: 1.40755
Value Function Loss: 0.30399

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02856
Policy Update Magnitude: 0.06842
Value Function Update Magnitude: 0.11253

Collected Steps per Second: 3,336.80049
Overall Steps per Second: 2,076.85623

Timestep Collection Time: 14.98441
Timestep Consumption Time: 9.09043
PPO Batch Consumption Time: 1.24422
Total Iteration Time: 24.07485

Cumulative Model Updates: 2,460
Cumulative Timesteps: 20,550,893

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.71166
Policy Entropy: 1.40830
Value Function Loss: 0.30613

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03515
Policy Update Magnitude: 0.06667
Value Function Update Magnitude: 0.11287

Collected Steps per Second: 3,321.65099
Overall Steps per Second: 2,067.86545

Timestep Collection Time: 15.05306
Timestep Consumption Time: 9.12695
PPO Batch Consumption Time: 1.24648
Total Iteration Time: 24.18001

Cumulative Model Updates: 2,466
Cumulative Timesteps: 20,600,894

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 20600894...
Checkpoint 20600894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.50992
Policy Entropy: 1.40840
Value Function Loss: 0.31071

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03030
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.10796

Collected Steps per Second: 3,339.50610
Overall Steps per Second: 2,073.12810

Timestep Collection Time: 14.97287
Timestep Consumption Time: 9.14623
PPO Batch Consumption Time: 1.24881
Total Iteration Time: 24.11911

Cumulative Model Updates: 2,472
Cumulative Timesteps: 20,650,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.86590
Policy Entropy: 1.40890
Value Function Loss: 0.30907

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 3,344.67161
Overall Steps per Second: 2,052.14292

Timestep Collection Time: 14.94975
Timestep Consumption Time: 9.41600
PPO Batch Consumption Time: 1.30878
Total Iteration Time: 24.36575

Cumulative Model Updates: 2,478
Cumulative Timesteps: 20,700,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 20700898...
Checkpoint 20700898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.51579
Policy Entropy: 1.40836
Value Function Loss: 0.30243

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.06845
Value Function Update Magnitude: 0.11462

Collected Steps per Second: 3,300.36707
Overall Steps per Second: 2,055.44626

Timestep Collection Time: 15.14983
Timestep Consumption Time: 9.17579
PPO Batch Consumption Time: 1.25365
Total Iteration Time: 24.32562

Cumulative Model Updates: 2,484
Cumulative Timesteps: 20,750,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.32100
Policy Entropy: 1.40887
Value Function Loss: 0.30060

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 0.06787
Value Function Update Magnitude: 0.11766

Collected Steps per Second: 3,325.67262
Overall Steps per Second: 2,065.97121

Timestep Collection Time: 15.03545
Timestep Consumption Time: 9.16769
PPO Batch Consumption Time: 1.24460
Total Iteration Time: 24.20314

Cumulative Model Updates: 2,490
Cumulative Timesteps: 20,800,901

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 20800901...
Checkpoint 20800901 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.20181
Policy Entropy: 1.40892
Value Function Loss: 0.29469

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.12530

Collected Steps per Second: 3,349.77241
Overall Steps per Second: 2,079.33518

Timestep Collection Time: 14.92639
Timestep Consumption Time: 9.11976
PPO Batch Consumption Time: 1.23782
Total Iteration Time: 24.04615

Cumulative Model Updates: 2,496
Cumulative Timesteps: 20,850,901

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.21506
Policy Entropy: 1.40832
Value Function Loss: 0.30336

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.07001
Value Function Update Magnitude: 0.12262

Collected Steps per Second: 3,341.12939
Overall Steps per Second: 2,024.12626

Timestep Collection Time: 14.96500
Timestep Consumption Time: 9.73702
PPO Batch Consumption Time: 1.34803
Total Iteration Time: 24.70202

Cumulative Model Updates: 2,502
Cumulative Timesteps: 20,900,901

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 20900901...
Checkpoint 20900901 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.27629
Policy Entropy: 1.40814
Value Function Loss: 0.31045

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.11817

Collected Steps per Second: 3,397.11558
Overall Steps per Second: 2,082.81696

Timestep Collection Time: 14.71955
Timestep Consumption Time: 9.28832
PPO Batch Consumption Time: 1.26211
Total Iteration Time: 24.00787

Cumulative Model Updates: 2,508
Cumulative Timesteps: 20,950,905

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.84620
Policy Entropy: 1.40775
Value Function Loss: 0.31498

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.11517

Collected Steps per Second: 3,355.07168
Overall Steps per Second: 2,079.17985

Timestep Collection Time: 14.90311
Timestep Consumption Time: 9.14532
PPO Batch Consumption Time: 1.24845
Total Iteration Time: 24.04842

Cumulative Model Updates: 2,514
Cumulative Timesteps: 21,000,906

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 21000906...
Checkpoint 21000906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.87910
Policy Entropy: 1.40737
Value Function Loss: 0.30409

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.11958

Collected Steps per Second: 3,332.32241
Overall Steps per Second: 2,052.28315

Timestep Collection Time: 15.00515
Timestep Consumption Time: 9.35893
PPO Batch Consumption Time: 1.27084
Total Iteration Time: 24.36408

Cumulative Model Updates: 2,520
Cumulative Timesteps: 21,050,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.16471
Policy Entropy: 1.40818
Value Function Loss: 0.29715

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.11263

Collected Steps per Second: 3,299.46501
Overall Steps per Second: 2,048.81821

Timestep Collection Time: 15.15549
Timestep Consumption Time: 9.25127
PPO Batch Consumption Time: 1.26674
Total Iteration Time: 24.40675

Cumulative Model Updates: 2,526
Cumulative Timesteps: 21,100,913

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 21100913...
Checkpoint 21100913 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.36243
Policy Entropy: 1.40892
Value Function Loss: 0.30091

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02283
Policy Update Magnitude: 0.06660
Value Function Update Magnitude: 0.10504

Collected Steps per Second: 3,352.33623
Overall Steps per Second: 2,065.20445

Timestep Collection Time: 14.91527
Timestep Consumption Time: 9.29589
PPO Batch Consumption Time: 1.28549
Total Iteration Time: 24.21116

Cumulative Model Updates: 2,532
Cumulative Timesteps: 21,150,914

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.04298
Policy Entropy: 1.40925
Value Function Loss: 0.30033

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.10551

Collected Steps per Second: 3,328.81718
Overall Steps per Second: 2,056.99742

Timestep Collection Time: 15.02185
Timestep Consumption Time: 9.28785
PPO Batch Consumption Time: 1.26194
Total Iteration Time: 24.30970

Cumulative Model Updates: 2,538
Cumulative Timesteps: 21,200,919

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 21200919...
Checkpoint 21200919 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.85869
Policy Entropy: 1.40926
Value Function Loss: 0.29975

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.03193
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.10643

Collected Steps per Second: 3,362.21623
Overall Steps per Second: 2,077.68896

Timestep Collection Time: 14.87144
Timestep Consumption Time: 9.19424
PPO Batch Consumption Time: 1.25040
Total Iteration Time: 24.06568

Cumulative Model Updates: 2,544
Cumulative Timesteps: 21,250,920

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.81779
Policy Entropy: 1.40891
Value Function Loss: 0.29316

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.06839
Value Function Update Magnitude: 0.10639

Collected Steps per Second: 3,335.36993
Overall Steps per Second: 2,056.06092

Timestep Collection Time: 14.99204
Timestep Consumption Time: 9.32825
PPO Batch Consumption Time: 1.27923
Total Iteration Time: 24.32029

Cumulative Model Updates: 2,550
Cumulative Timesteps: 21,300,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 21300924...
Checkpoint 21300924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.02119
Policy Entropy: 1.40943
Value Function Loss: 0.29618

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.06508
Value Function Update Magnitude: 0.10835

Collected Steps per Second: 3,287.08002
Overall Steps per Second: 2,046.91482

Timestep Collection Time: 15.21229
Timestep Consumption Time: 9.21667
PPO Batch Consumption Time: 1.26613
Total Iteration Time: 24.42896

Cumulative Model Updates: 2,556
Cumulative Timesteps: 21,350,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.27903
Policy Entropy: 1.40949
Value Function Loss: 0.29780

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02985
Policy Update Magnitude: 0.06778
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 3,358.55613
Overall Steps per Second: 2,040.20803

Timestep Collection Time: 14.88735
Timestep Consumption Time: 9.61996
PPO Batch Consumption Time: 1.33342
Total Iteration Time: 24.50730

Cumulative Model Updates: 2,562
Cumulative Timesteps: 21,400,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 21400928...
Checkpoint 21400928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.07441
Policy Entropy: 1.40973
Value Function Loss: 0.29863

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02938
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 3,345.28564
Overall Steps per Second: 2,068.43423

Timestep Collection Time: 14.94641
Timestep Consumption Time: 9.22647
PPO Batch Consumption Time: 1.25075
Total Iteration Time: 24.17287

Cumulative Model Updates: 2,568
Cumulative Timesteps: 21,450,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.94694
Policy Entropy: 1.40894
Value Function Loss: 0.29663

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02967
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 3,315.41842
Overall Steps per Second: 2,024.59178

Timestep Collection Time: 15.08196
Timestep Consumption Time: 9.61586
PPO Batch Consumption Time: 1.32434
Total Iteration Time: 24.69782

Cumulative Model Updates: 2,574
Cumulative Timesteps: 21,500,931

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 21500931...
Checkpoint 21500931 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.30180
Policy Entropy: 1.40868
Value Function Loss: 0.29009

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.06624
Value Function Update Magnitude: 0.11062

Collected Steps per Second: 3,335.91510
Overall Steps per Second: 2,068.77254

Timestep Collection Time: 14.98869
Timestep Consumption Time: 9.18071
PPO Batch Consumption Time: 1.25251
Total Iteration Time: 24.16940

Cumulative Model Updates: 2,580
Cumulative Timesteps: 21,550,932

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.19291
Policy Entropy: 1.40816
Value Function Loss: 0.28489

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.11258

Collected Steps per Second: 3,351.07546
Overall Steps per Second: 2,064.41376

Timestep Collection Time: 14.92178
Timestep Consumption Time: 9.30011
PPO Batch Consumption Time: 1.27769
Total Iteration Time: 24.22189

Cumulative Model Updates: 2,586
Cumulative Timesteps: 21,600,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 21600936...
Checkpoint 21600936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.54501
Policy Entropy: 1.40937
Value Function Loss: 0.29059

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.06825
Value Function Update Magnitude: 0.11273

Collected Steps per Second: 3,379.40465
Overall Steps per Second: 2,050.01645

Timestep Collection Time: 14.79639
Timestep Consumption Time: 9.59512
PPO Batch Consumption Time: 1.33653
Total Iteration Time: 24.39151

Cumulative Model Updates: 2,592
Cumulative Timesteps: 21,650,939

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.53666
Policy Entropy: 1.41052
Value Function Loss: 0.30102

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.01906
Policy Update Magnitude: 0.06977
Value Function Update Magnitude: 0.11822

Collected Steps per Second: 3,385.42972
Overall Steps per Second: 2,081.65505

Timestep Collection Time: 14.76976
Timestep Consumption Time: 9.25055
PPO Batch Consumption Time: 1.26920
Total Iteration Time: 24.02031

Cumulative Model Updates: 2,598
Cumulative Timesteps: 21,700,941

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21700941...
Checkpoint 21700941 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.28658
Policy Entropy: 1.41039
Value Function Loss: 0.30471

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.07167
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 3,378.58209
Overall Steps per Second: 2,086.83988

Timestep Collection Time: 14.79970
Timestep Consumption Time: 9.16093
PPO Batch Consumption Time: 1.25463
Total Iteration Time: 23.96063

Cumulative Model Updates: 2,604
Cumulative Timesteps: 21,750,943

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.93178
Policy Entropy: 1.41052
Value Function Loss: 0.29869

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.06589
Value Function Update Magnitude: 0.11323

Collected Steps per Second: 3,355.81208
Overall Steps per Second: 2,062.30595

Timestep Collection Time: 14.90072
Timestep Consumption Time: 9.34593
PPO Batch Consumption Time: 1.28445
Total Iteration Time: 24.24664

Cumulative Model Updates: 2,610
Cumulative Timesteps: 21,800,947

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 21800947...
Checkpoint 21800947 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.73684
Policy Entropy: 1.40962
Value Function Loss: 0.29549

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.01996
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 3,318.63419
Overall Steps per Second: 2,059.01205

Timestep Collection Time: 15.06704
Timestep Consumption Time: 9.21742
PPO Batch Consumption Time: 1.26938
Total Iteration Time: 24.28446

Cumulative Model Updates: 2,616
Cumulative Timesteps: 21,850,949

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.19399
Policy Entropy: 1.41016
Value Function Loss: 0.29474

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01611
Policy Update Magnitude: 0.07823
Value Function Update Magnitude: 0.11152

Collected Steps per Second: 3,378.72521
Overall Steps per Second: 2,081.32924

Timestep Collection Time: 14.79907
Timestep Consumption Time: 9.22500
PPO Batch Consumption Time: 1.30307
Total Iteration Time: 24.02407

Cumulative Model Updates: 2,622
Cumulative Timesteps: 21,900,951

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21900951...
Checkpoint 21900951 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.08085
Policy Entropy: 1.40923
Value Function Loss: 0.29861

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.09337
Value Function Update Magnitude: 0.11288

Collected Steps per Second: 3,406.48657
Overall Steps per Second: 2,071.89016

Timestep Collection Time: 14.67847
Timestep Consumption Time: 9.45505
PPO Batch Consumption Time: 1.32430
Total Iteration Time: 24.13352

Cumulative Model Updates: 2,628
Cumulative Timesteps: 21,950,953

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.65118
Policy Entropy: 1.41018
Value Function Loss: 0.29080

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.07369
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 3,346.53403
Overall Steps per Second: 2,093.00845

Timestep Collection Time: 14.94143
Timestep Consumption Time: 8.94858
PPO Batch Consumption Time: 1.26120
Total Iteration Time: 23.89001

Cumulative Model Updates: 2,634
Cumulative Timesteps: 22,000,955

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22000955...
Checkpoint 22000955 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.25247
Policy Entropy: 1.41000
Value Function Loss: 0.28701

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 3,318.66310
Overall Steps per Second: 2,077.00958

Timestep Collection Time: 15.06781
Timestep Consumption Time: 9.00766
PPO Batch Consumption Time: 1.24656
Total Iteration Time: 24.07548

Cumulative Model Updates: 2,640
Cumulative Timesteps: 22,050,960

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.66267
Policy Entropy: 1.41041
Value Function Loss: 0.28519

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02435
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 3,335.69967
Overall Steps per Second: 2,050.53441

Timestep Collection Time: 14.98996
Timestep Consumption Time: 9.39490
PPO Batch Consumption Time: 1.33527
Total Iteration Time: 24.38486

Cumulative Model Updates: 2,646
Cumulative Timesteps: 22,100,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22100962...
Checkpoint 22100962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.48355
Policy Entropy: 1.40990
Value Function Loss: 0.29123

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.06939
Value Function Update Magnitude: 0.12427

Collected Steps per Second: 3,314.03296
Overall Steps per Second: 2,068.14572

Timestep Collection Time: 15.08796
Timestep Consumption Time: 9.08925
PPO Batch Consumption Time: 1.28957
Total Iteration Time: 24.17721

Cumulative Model Updates: 2,652
Cumulative Timesteps: 22,150,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.56559
Policy Entropy: 1.41135
Value Function Loss: 0.29549

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.12740

Collected Steps per Second: 3,386.84751
Overall Steps per Second: 2,091.57478

Timestep Collection Time: 14.76388
Timestep Consumption Time: 9.14299
PPO Batch Consumption Time: 1.27087
Total Iteration Time: 23.90687

Cumulative Model Updates: 2,658
Cumulative Timesteps: 22,200,967

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 22200967...
Checkpoint 22200967 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.45244
Policy Entropy: 1.41046
Value Function Loss: 0.29439

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.06737
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 3,359.44094
Overall Steps per Second: 2,090.48105

Timestep Collection Time: 14.88343
Timestep Consumption Time: 9.03451
PPO Batch Consumption Time: 1.26285
Total Iteration Time: 23.91794

Cumulative Model Updates: 2,664
Cumulative Timesteps: 22,250,967

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.57051
Policy Entropy: 1.41129
Value Function Loss: 0.29712

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 3,315.89233
Overall Steps per Second: 2,050.79214

Timestep Collection Time: 15.07920
Timestep Consumption Time: 9.30211
PPO Batch Consumption Time: 1.30929
Total Iteration Time: 24.38131

Cumulative Model Updates: 2,670
Cumulative Timesteps: 22,300,968

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 22300968...
Checkpoint 22300968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.87199
Policy Entropy: 1.41054
Value Function Loss: 0.29400

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01542
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.12679

Collected Steps per Second: 3,335.81214
Overall Steps per Second: 2,067.24309

Timestep Collection Time: 14.98975
Timestep Consumption Time: 9.19850
PPO Batch Consumption Time: 1.29991
Total Iteration Time: 24.18825

Cumulative Model Updates: 2,676
Cumulative Timesteps: 22,350,971

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.43102
Policy Entropy: 1.41078
Value Function Loss: 0.29126

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01678
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.11950

Collected Steps per Second: 3,352.25009
Overall Steps per Second: 2,066.78894

Timestep Collection Time: 14.91685
Timestep Consumption Time: 9.27769
PPO Batch Consumption Time: 1.31183
Total Iteration Time: 24.19454

Cumulative Model Updates: 2,682
Cumulative Timesteps: 22,400,976

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 22400976...
Checkpoint 22400976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.76330
Policy Entropy: 1.41057
Value Function Loss: 0.28808

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01391
Policy Update Magnitude: 0.06715
Value Function Update Magnitude: 0.12174

Collected Steps per Second: 3,322.00091
Overall Steps per Second: 2,069.12516

Timestep Collection Time: 15.05147
Timestep Consumption Time: 9.11381
PPO Batch Consumption Time: 1.27179
Total Iteration Time: 24.16529

Cumulative Model Updates: 2,688
Cumulative Timesteps: 22,450,977

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.77903
Policy Entropy: 1.41061
Value Function Loss: 0.28464

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01863
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 3,357.38066
Overall Steps per Second: 2,068.74124

Timestep Collection Time: 14.89375
Timestep Consumption Time: 9.27747
PPO Batch Consumption Time: 1.29738
Total Iteration Time: 24.17122

Cumulative Model Updates: 2,694
Cumulative Timesteps: 22,500,981

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 22500981...
Checkpoint 22500981 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.13877
Policy Entropy: 1.41091
Value Function Loss: 0.28707

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01545
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 3,286.49817
Overall Steps per Second: 2,065.06890

Timestep Collection Time: 15.21498
Timestep Consumption Time: 8.99923
PPO Batch Consumption Time: 1.26162
Total Iteration Time: 24.21420

Cumulative Model Updates: 2,700
Cumulative Timesteps: 22,550,985

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.97457
Policy Entropy: 1.41011
Value Function Loss: 0.29030

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.06962
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 3,324.98755
Overall Steps per Second: 2,068.17490

Timestep Collection Time: 15.03885
Timestep Consumption Time: 9.13899
PPO Batch Consumption Time: 1.29504
Total Iteration Time: 24.17784

Cumulative Model Updates: 2,706
Cumulative Timesteps: 22,600,989

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 22600989...
Checkpoint 22600989 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.56391
Policy Entropy: 1.41014
Value Function Loss: 0.29282

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.07100
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 3,335.15636
Overall Steps per Second: 2,085.42366

Timestep Collection Time: 14.99300
Timestep Consumption Time: 8.98486
PPO Batch Consumption Time: 1.26588
Total Iteration Time: 23.97786

Cumulative Model Updates: 2,712
Cumulative Timesteps: 22,650,993

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.92392
Policy Entropy: 1.41005
Value Function Loss: 0.29085

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02925
Policy Update Magnitude: 0.06910
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 3,378.76140
Overall Steps per Second: 2,067.16828

Timestep Collection Time: 14.79951
Timestep Consumption Time: 9.39011
PPO Batch Consumption Time: 1.31690
Total Iteration Time: 24.18961

Cumulative Model Updates: 2,718
Cumulative Timesteps: 22,700,997

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 22700997...
Checkpoint 22700997 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.70302
Policy Entropy: 1.41061
Value Function Loss: 0.28599

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.06696
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 3,330.23455
Overall Steps per Second: 2,088.14213

Timestep Collection Time: 15.01426
Timestep Consumption Time: 8.93095
PPO Batch Consumption Time: 1.24666
Total Iteration Time: 23.94521

Cumulative Model Updates: 2,724
Cumulative Timesteps: 22,750,998

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.30122
Policy Entropy: 1.41087
Value Function Loss: 0.28771

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.06397
Value Function Update Magnitude: 0.12392

Collected Steps per Second: 3,316.92536
Overall Steps per Second: 2,075.48189

Timestep Collection Time: 15.07480
Timestep Consumption Time: 9.01695
PPO Batch Consumption Time: 1.25710
Total Iteration Time: 24.09175

Cumulative Model Updates: 2,730
Cumulative Timesteps: 22,801,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22801000...
Checkpoint 22801000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.76400
Policy Entropy: 1.41130
Value Function Loss: 0.29195

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 3,349.29951
Overall Steps per Second: 2,051.35495

Timestep Collection Time: 14.92969
Timestep Consumption Time: 9.44639
PPO Batch Consumption Time: 1.32457
Total Iteration Time: 24.37608

Cumulative Model Updates: 2,736
Cumulative Timesteps: 22,851,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.57639
Policy Entropy: 1.41132
Value Function Loss: 0.29929

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01854
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.11411

Collected Steps per Second: 3,324.09613
Overall Steps per Second: 2,008.53616

Timestep Collection Time: 15.04228
Timestep Consumption Time: 9.85246
PPO Batch Consumption Time: 1.40560
Total Iteration Time: 24.89475

Cumulative Model Updates: 2,742
Cumulative Timesteps: 22,901,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22901006...
Checkpoint 22901006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.75047
Policy Entropy: 1.41092
Value Function Loss: 0.29996

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02123
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.11647

Collected Steps per Second: 2,885.31551
Overall Steps per Second: 1,836.45018

Timestep Collection Time: 17.32913
Timestep Consumption Time: 9.89731
PPO Batch Consumption Time: 1.38869
Total Iteration Time: 27.22644

Cumulative Model Updates: 2,748
Cumulative Timesteps: 22,951,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.98532
Policy Entropy: 1.41137
Value Function Loss: 0.28848

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02902
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.12184

Collected Steps per Second: 3,355.52577
Overall Steps per Second: 2,035.41811

Timestep Collection Time: 14.90199
Timestep Consumption Time: 9.66496
PPO Batch Consumption Time: 1.37298
Total Iteration Time: 24.56694

Cumulative Model Updates: 2,754
Cumulative Timesteps: 23,001,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23001010...
Checkpoint 23001010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.89690
Policy Entropy: 1.40990
Value Function Loss: 0.28008

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.03012
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.12272

Collected Steps per Second: 3,347.32754
Overall Steps per Second: 2,045.43703

Timestep Collection Time: 14.93819
Timestep Consumption Time: 9.50793
PPO Batch Consumption Time: 1.34625
Total Iteration Time: 24.44612

Cumulative Model Updates: 2,760
Cumulative Timesteps: 23,051,013

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.47031
Policy Entropy: 1.40992
Value Function Loss: 0.28603

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.13154

Collected Steps per Second: 3,333.70320
Overall Steps per Second: 2,038.26253

Timestep Collection Time: 14.99924
Timestep Consumption Time: 9.53293
PPO Batch Consumption Time: 1.36065
Total Iteration Time: 24.53217

Cumulative Model Updates: 2,766
Cumulative Timesteps: 23,101,016

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 23101016...
Checkpoint 23101016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.93232
Policy Entropy: 1.40842
Value Function Loss: 0.29279

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02234
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.12874

Collected Steps per Second: 3,301.60686
Overall Steps per Second: 2,020.17108

Timestep Collection Time: 15.14475
Timestep Consumption Time: 9.60662
PPO Batch Consumption Time: 1.36585
Total Iteration Time: 24.75137

Cumulative Model Updates: 2,772
Cumulative Timesteps: 23,151,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.64136
Policy Entropy: 1.40869
Value Function Loss: 0.29319

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 3,344.83185
Overall Steps per Second: 2,022.75494

Timestep Collection Time: 14.94873
Timestep Consumption Time: 9.77052
PPO Batch Consumption Time: 1.37392
Total Iteration Time: 24.71926

Cumulative Model Updates: 2,778
Cumulative Timesteps: 23,201,019

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 23201019...
Checkpoint 23201019 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.76517
Policy Entropy: 1.40806
Value Function Loss: 0.28887

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02920
Policy Update Magnitude: 0.06771
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 3,285.27950
Overall Steps per Second: 2,010.83118

Timestep Collection Time: 15.22001
Timestep Consumption Time: 9.64632
PPO Batch Consumption Time: 1.36358
Total Iteration Time: 24.86633

Cumulative Model Updates: 2,784
Cumulative Timesteps: 23,251,021

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.48138
Policy Entropy: 1.41002
Value Function Loss: 0.29165

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02926
Policy Update Magnitude: 0.06996
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 3,370.09709
Overall Steps per Second: 2,029.25046

Timestep Collection Time: 14.83726
Timestep Consumption Time: 9.80386
PPO Batch Consumption Time: 1.38644
Total Iteration Time: 24.64112

Cumulative Model Updates: 2,790
Cumulative Timesteps: 23,301,024

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 23301024...
Checkpoint 23301024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.45443
Policy Entropy: 1.40941
Value Function Loss: 0.29502

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.03523
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.11404

Collected Steps per Second: 3,279.99196
Overall Steps per Second: 2,035.79818

Timestep Collection Time: 15.24424
Timestep Consumption Time: 9.31664
PPO Batch Consumption Time: 1.32233
Total Iteration Time: 24.56088

Cumulative Model Updates: 2,796
Cumulative Timesteps: 23,351,025

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.09558
Policy Entropy: 1.41045
Value Function Loss: 0.29069

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.07104
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 3,331.56994
Overall Steps per Second: 2,058.11225

Timestep Collection Time: 15.00854
Timestep Consumption Time: 9.28654
PPO Batch Consumption Time: 1.32168
Total Iteration Time: 24.29508

Cumulative Model Updates: 2,802
Cumulative Timesteps: 23,401,027

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 23401027...
Checkpoint 23401027 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.59913
Policy Entropy: 1.40915
Value Function Loss: 0.29059

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02336
Policy Update Magnitude: 0.07751
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 3,348.31045
Overall Steps per Second: 2,053.83776

Timestep Collection Time: 14.93320
Timestep Consumption Time: 9.41195
PPO Batch Consumption Time: 1.32453
Total Iteration Time: 24.34516

Cumulative Model Updates: 2,808
Cumulative Timesteps: 23,451,028

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.66916
Policy Entropy: 1.40892
Value Function Loss: 0.28854

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.07436
Value Function Update Magnitude: 0.10903

Collected Steps per Second: 3,350.22626
Overall Steps per Second: 2,056.13030

Timestep Collection Time: 14.92526
Timestep Consumption Time: 9.39372
PPO Batch Consumption Time: 1.31435
Total Iteration Time: 24.31898

Cumulative Model Updates: 2,814
Cumulative Timesteps: 23,501,031

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 23501031...
Checkpoint 23501031 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.25074
Policy Entropy: 1.40868
Value Function Loss: 0.28965

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.07277
Value Function Update Magnitude: 0.10893

Collected Steps per Second: 3,356.05133
Overall Steps per Second: 2,076.89677

Timestep Collection Time: 14.89995
Timestep Consumption Time: 9.17684
PPO Batch Consumption Time: 1.29515
Total Iteration Time: 24.07679

Cumulative Model Updates: 2,820
Cumulative Timesteps: 23,551,036

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.38219
Policy Entropy: 1.40946
Value Function Loss: 0.28856

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.07109
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 3,298.13841
Overall Steps per Second: 2,051.81716

Timestep Collection Time: 15.16037
Timestep Consumption Time: 9.20876
PPO Batch Consumption Time: 1.30838
Total Iteration Time: 24.36913

Cumulative Model Updates: 2,826
Cumulative Timesteps: 23,601,037

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 23601037...
Checkpoint 23601037 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.45869
Policy Entropy: 1.40937
Value Function Loss: 0.29104

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02074
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 3,340.67308
Overall Steps per Second: 2,061.02480

Timestep Collection Time: 14.96704
Timestep Consumption Time: 9.29273
PPO Batch Consumption Time: 1.31629
Total Iteration Time: 24.25978

Cumulative Model Updates: 2,832
Cumulative Timesteps: 23,651,037

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.92333
Policy Entropy: 1.40933
Value Function Loss: 0.29407

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01480
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.11050

Collected Steps per Second: 3,327.60015
Overall Steps per Second: 2,042.82276

Timestep Collection Time: 15.02614
Timestep Consumption Time: 9.45028
PPO Batch Consumption Time: 1.31244
Total Iteration Time: 24.47643

Cumulative Model Updates: 2,838
Cumulative Timesteps: 23,701,038

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 23701038...
Checkpoint 23701038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.44034
Policy Entropy: 1.40906
Value Function Loss: 0.29422

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01814
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.10939

Collected Steps per Second: 3,374.79881
Overall Steps per Second: 2,077.12062

Timestep Collection Time: 14.81599
Timestep Consumption Time: 9.25627
PPO Batch Consumption Time: 1.29641
Total Iteration Time: 24.07227

Cumulative Model Updates: 2,844
Cumulative Timesteps: 23,751,039

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.67347
Policy Entropy: 1.41006
Value Function Loss: 0.29335

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01570
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 3,340.91638
Overall Steps per Second: 2,061.46766

Timestep Collection Time: 14.96715
Timestep Consumption Time: 9.28935
PPO Batch Consumption Time: 1.29595
Total Iteration Time: 24.25650

Cumulative Model Updates: 2,850
Cumulative Timesteps: 23,801,043

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23801043...
Checkpoint 23801043 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.79137
Policy Entropy: 1.41050
Value Function Loss: 0.28872

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.11648

Collected Steps per Second: 3,319.02546
Overall Steps per Second: 2,044.30186

Timestep Collection Time: 15.06466
Timestep Consumption Time: 9.39356
PPO Batch Consumption Time: 1.33172
Total Iteration Time: 24.45823

Cumulative Model Updates: 2,856
Cumulative Timesteps: 23,851,043

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.62865
Policy Entropy: 1.41004
Value Function Loss: 0.28924

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.11277

Collected Steps per Second: 3,378.90225
Overall Steps per Second: 2,057.65039

Timestep Collection Time: 14.79830
Timestep Consumption Time: 9.50224
PPO Batch Consumption Time: 1.34704
Total Iteration Time: 24.30053

Cumulative Model Updates: 2,862
Cumulative Timesteps: 23,901,045

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 23901045...
Checkpoint 23901045 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.79521
Policy Entropy: 1.40976
Value Function Loss: 0.29181

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 3,401.47260
Overall Steps per Second: 2,074.61272

Timestep Collection Time: 14.70040
Timestep Consumption Time: 9.40193
PPO Batch Consumption Time: 1.31693
Total Iteration Time: 24.10233

Cumulative Model Updates: 2,868
Cumulative Timesteps: 23,951,048

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.03277
Policy Entropy: 1.40928
Value Function Loss: 0.29469

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 3,322.71337
Overall Steps per Second: 2,050.71666

Timestep Collection Time: 15.04854
Timestep Consumption Time: 9.33415
PPO Batch Consumption Time: 1.30657
Total Iteration Time: 24.38270

Cumulative Model Updates: 2,874
Cumulative Timesteps: 24,001,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 24001050...
Checkpoint 24001050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.20263
Policy Entropy: 1.40895
Value Function Loss: 0.30164

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.11366

Collected Steps per Second: 3,336.39709
Overall Steps per Second: 2,052.84717

Timestep Collection Time: 14.98683
Timestep Consumption Time: 9.37057
PPO Batch Consumption Time: 1.32450
Total Iteration Time: 24.35739

Cumulative Model Updates: 2,880
Cumulative Timesteps: 24,051,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.87483
Policy Entropy: 1.40910
Value Function Loss: 0.29978

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 3,358.56380
Overall Steps per Second: 2,062.81374

Timestep Collection Time: 14.88851
Timestep Consumption Time: 9.35217
PPO Batch Consumption Time: 1.32708
Total Iteration Time: 24.24068

Cumulative Model Updates: 2,886
Cumulative Timesteps: 24,101,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 24101056...
Checkpoint 24101056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.65232
Policy Entropy: 1.40886
Value Function Loss: 0.30603

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 3,375.54848
Overall Steps per Second: 2,050.77900

Timestep Collection Time: 14.81241
Timestep Consumption Time: 9.56857
PPO Batch Consumption Time: 1.34113
Total Iteration Time: 24.38098

Cumulative Model Updates: 2,892
Cumulative Timesteps: 24,151,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.88295
Policy Entropy: 1.40948
Value Function Loss: 0.29840

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 3,351.26267
Overall Steps per Second: 2,045.41279

Timestep Collection Time: 14.92064
Timestep Consumption Time: 9.52577
PPO Batch Consumption Time: 1.34512
Total Iteration Time: 24.44641

Cumulative Model Updates: 2,898
Cumulative Timesteps: 24,201,059

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 24201059...
Checkpoint 24201059 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.73788
Policy Entropy: 1.40829
Value Function Loss: 0.30367

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.05349
Policy Update Magnitude: 0.07244
Value Function Update Magnitude: 0.11349

Collected Steps per Second: 3,320.17556
Overall Steps per Second: 2,072.59559

Timestep Collection Time: 15.05975
Timestep Consumption Time: 9.06508
PPO Batch Consumption Time: 1.27189
Total Iteration Time: 24.12482

Cumulative Model Updates: 2,904
Cumulative Timesteps: 24,251,060

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.20447
Policy Entropy: 1.40848
Value Function Loss: 0.30198

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.03708
Policy Update Magnitude: 0.06553
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 3,363.60144
Overall Steps per Second: 2,061.11557

Timestep Collection Time: 14.86532
Timestep Consumption Time: 9.39388
PPO Batch Consumption Time: 1.33628
Total Iteration Time: 24.25919

Cumulative Model Updates: 2,910
Cumulative Timesteps: 24,301,061

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 24301061...
Checkpoint 24301061 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.26956
Policy Entropy: 1.40873
Value Function Loss: 0.29948

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.03482
Policy Update Magnitude: 0.06896
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 3,347.70213
Overall Steps per Second: 2,046.84977

Timestep Collection Time: 14.93681
Timestep Consumption Time: 9.49292
PPO Batch Consumption Time: 1.35215
Total Iteration Time: 24.42974

Cumulative Model Updates: 2,916
Cumulative Timesteps: 24,351,065

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.27904
Policy Entropy: 1.40926
Value Function Loss: 0.28655

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03745
Policy Update Magnitude: 0.06708
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 3,371.27983
Overall Steps per Second: 2,059.49833

Timestep Collection Time: 14.83235
Timestep Consumption Time: 9.44735
PPO Batch Consumption Time: 1.30909
Total Iteration Time: 24.27970

Cumulative Model Updates: 2,922
Cumulative Timesteps: 24,401,069

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 24401069...
Checkpoint 24401069 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.05646
Policy Entropy: 1.40828
Value Function Loss: 0.28007

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.06696
Value Function Update Magnitude: 0.10679

Collected Steps per Second: 3,301.77080
Overall Steps per Second: 2,035.65948

Timestep Collection Time: 15.14369
Timestep Consumption Time: 9.41886
PPO Batch Consumption Time: 1.32766
Total Iteration Time: 24.56256

Cumulative Model Updates: 2,928
Cumulative Timesteps: 24,451,070

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.34516
Policy Entropy: 1.40847
Value Function Loss: 0.28227

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.10469

Collected Steps per Second: 3,345.72346
Overall Steps per Second: 2,059.13676

Timestep Collection Time: 14.94475
Timestep Consumption Time: 9.33776
PPO Batch Consumption Time: 1.29987
Total Iteration Time: 24.28251

Cumulative Model Updates: 2,934
Cumulative Timesteps: 24,501,071

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 24501071...
Checkpoint 24501071 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.99552
Policy Entropy: 1.40815
Value Function Loss: 0.29088

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.07159
Value Function Update Magnitude: 0.10333

Collected Steps per Second: 3,365.83172
Overall Steps per Second: 2,055.98958

Timestep Collection Time: 14.85517
Timestep Consumption Time: 9.46402
PPO Batch Consumption Time: 1.34342
Total Iteration Time: 24.31919

Cumulative Model Updates: 2,940
Cumulative Timesteps: 24,551,071

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.60997
Policy Entropy: 1.40776
Value Function Loss: 0.28970

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.06869
Value Function Update Magnitude: 0.10642

Collected Steps per Second: 3,335.40000
Overall Steps per Second: 2,056.77862

Timestep Collection Time: 14.99191
Timestep Consumption Time: 9.31990
PPO Batch Consumption Time: 1.32342
Total Iteration Time: 24.31180

Cumulative Model Updates: 2,946
Cumulative Timesteps: 24,601,075

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 24601075...
Checkpoint 24601075 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.30104
Policy Entropy: 1.40797
Value Function Loss: 0.29321

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.06910
Value Function Update Magnitude: 0.11085

Collected Steps per Second: 3,374.30866
Overall Steps per Second: 2,057.52579

Timestep Collection Time: 14.81815
Timestep Consumption Time: 9.48337
PPO Batch Consumption Time: 1.34045
Total Iteration Time: 24.30152

Cumulative Model Updates: 2,952
Cumulative Timesteps: 24,651,076

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.10838
Policy Entropy: 1.40858
Value Function Loss: 0.29462

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01663
Policy Update Magnitude: 0.06884
Value Function Update Magnitude: 0.11439

Collected Steps per Second: 3,383.37903
Overall Steps per Second: 2,068.50070

Timestep Collection Time: 14.77901
Timestep Consumption Time: 9.39454
PPO Batch Consumption Time: 1.32529
Total Iteration Time: 24.17355

Cumulative Model Updates: 2,958
Cumulative Timesteps: 24,701,079

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 24701079...
Checkpoint 24701079 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.30172
Policy Entropy: 1.40859
Value Function Loss: 0.28639

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.01624
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 3,344.67459
Overall Steps per Second: 2,063.42451

Timestep Collection Time: 14.94914
Timestep Consumption Time: 9.28243
PPO Batch Consumption Time: 1.31088
Total Iteration Time: 24.23156

Cumulative Model Updates: 2,964
Cumulative Timesteps: 24,751,079

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.30025
Policy Entropy: 1.40853
Value Function Loss: 0.28828

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01596
Policy Update Magnitude: 0.06890
Value Function Update Magnitude: 0.11534

Collected Steps per Second: 3,313.31794
Overall Steps per Second: 2,053.59465

Timestep Collection Time: 15.09122
Timestep Consumption Time: 9.25731
PPO Batch Consumption Time: 1.30600
Total Iteration Time: 24.34852

Cumulative Model Updates: 2,970
Cumulative Timesteps: 24,801,081

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 24801081...
Checkpoint 24801081 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.87572
Policy Entropy: 1.40951
Value Function Loss: 0.28995

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01952
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 3,324.39384
Overall Steps per Second: 2,059.41841

Timestep Collection Time: 15.04034
Timestep Consumption Time: 9.23836
PPO Batch Consumption Time: 1.30388
Total Iteration Time: 24.27870

Cumulative Model Updates: 2,976
Cumulative Timesteps: 24,851,081

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.27365
Policy Entropy: 1.40936
Value Function Loss: 0.29879

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.07003
Value Function Update Magnitude: 0.11940

Collected Steps per Second: 3,364.21922
Overall Steps per Second: 2,057.02987

Timestep Collection Time: 14.86348
Timestep Consumption Time: 9.44536
PPO Batch Consumption Time: 1.32448
Total Iteration Time: 24.30884

Cumulative Model Updates: 2,982
Cumulative Timesteps: 24,901,085

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 24901085...
Checkpoint 24901085 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52386
Policy Entropy: 1.41002
Value Function Loss: 0.29144

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02008
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 3,368.54475
Overall Steps per Second: 2,064.46319

Timestep Collection Time: 14.84410
Timestep Consumption Time: 9.37673
PPO Batch Consumption Time: 1.31986
Total Iteration Time: 24.22082

Cumulative Model Updates: 2,988
Cumulative Timesteps: 24,951,088

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.90312
Policy Entropy: 1.40952
Value Function Loss: 0.28291

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01819
Policy Update Magnitude: 0.06927
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 3,391.53669
Overall Steps per Second: 2,070.24375

Timestep Collection Time: 14.74376
Timestep Consumption Time: 9.40992
PPO Batch Consumption Time: 1.32498
Total Iteration Time: 24.15368

Cumulative Model Updates: 2,994
Cumulative Timesteps: 25,001,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 25001092...
Checkpoint 25001092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.32509
Policy Entropy: 1.40971
Value Function Loss: 0.27896

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.06681
Value Function Update Magnitude: 0.13331

Collected Steps per Second: 3,357.88692
Overall Steps per Second: 2,063.32455

Timestep Collection Time: 14.89151
Timestep Consumption Time: 9.34317
PPO Batch Consumption Time: 1.31862
Total Iteration Time: 24.23468

Cumulative Model Updates: 3,000
Cumulative Timesteps: 25,051,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.93578
Policy Entropy: 1.40969
Value Function Loss: 0.28114

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01678
Policy Update Magnitude: 0.06807
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 3,348.43002
Overall Steps per Second: 2,039.74301

Timestep Collection Time: 14.93237
Timestep Consumption Time: 9.58052
PPO Batch Consumption Time: 1.35906
Total Iteration Time: 24.51289

Cumulative Model Updates: 3,006
Cumulative Timesteps: 25,101,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 25101096...
Checkpoint 25101096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.09742
Policy Entropy: 1.41016
Value Function Loss: 0.28531

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01724
Policy Update Magnitude: 0.06741
Value Function Update Magnitude: 0.11254

Collected Steps per Second: 3,366.99765
Overall Steps per Second: 2,057.92692

Timestep Collection Time: 14.85151
Timestep Consumption Time: 9.44721
PPO Batch Consumption Time: 1.31101
Total Iteration Time: 24.29872

Cumulative Model Updates: 3,012
Cumulative Timesteps: 25,151,101

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.33935
Policy Entropy: 1.40964
Value Function Loss: 0.28551

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01578
Policy Update Magnitude: 0.07292
Value Function Update Magnitude: 0.11702

Collected Steps per Second: 3,318.86237
Overall Steps per Second: 2,049.32670

Timestep Collection Time: 15.06631
Timestep Consumption Time: 9.33341
PPO Batch Consumption Time: 1.31740
Total Iteration Time: 24.39972

Cumulative Model Updates: 3,018
Cumulative Timesteps: 25,201,104

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 25201104...
Checkpoint 25201104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.39063
Policy Entropy: 1.40821
Value Function Loss: 0.28173

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.08655
Value Function Update Magnitude: 0.11702

Collected Steps per Second: 3,346.28810
Overall Steps per Second: 2,060.58020

Timestep Collection Time: 14.94253
Timestep Consumption Time: 9.32345
PPO Batch Consumption Time: 1.31919
Total Iteration Time: 24.26598

Cumulative Model Updates: 3,024
Cumulative Timesteps: 25,251,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.91535
Policy Entropy: 1.40856
Value Function Loss: 0.27779

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.03891
Policy Update Magnitude: 0.08725
Value Function Update Magnitude: 0.12070

Collected Steps per Second: 3,345.93189
Overall Steps per Second: 2,063.69050

Timestep Collection Time: 14.94501
Timestep Consumption Time: 9.28585
PPO Batch Consumption Time: 1.32087
Total Iteration Time: 24.23086

Cumulative Model Updates: 3,030
Cumulative Timesteps: 25,301,111

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 25301111...
Checkpoint 25301111 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.86951
Policy Entropy: 1.40764
Value Function Loss: 0.28076

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.04902
Policy Update Magnitude: 0.07659
Value Function Update Magnitude: 0.11864

Collected Steps per Second: 3,315.04909
Overall Steps per Second: 2,052.97844

Timestep Collection Time: 15.08334
Timestep Consumption Time: 9.27250
PPO Batch Consumption Time: 1.31515
Total Iteration Time: 24.35583

Cumulative Model Updates: 3,036
Cumulative Timesteps: 25,351,113

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.05031
Policy Entropy: 1.40936
Value Function Loss: 0.28382

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.03945
Policy Update Magnitude: 0.07686
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 3,363.86286
Overall Steps per Second: 2,063.49244

Timestep Collection Time: 14.86476
Timestep Consumption Time: 9.36746
PPO Batch Consumption Time: 1.33309
Total Iteration Time: 24.23222

Cumulative Model Updates: 3,042
Cumulative Timesteps: 25,401,116

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 25401116...
Checkpoint 25401116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.40069
Policy Entropy: 1.40911
Value Function Loss: 0.28629

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 0.06697
Value Function Update Magnitude: 0.12260

Collected Steps per Second: 3,352.10303
Overall Steps per Second: 2,087.94032

Timestep Collection Time: 14.91720
Timestep Consumption Time: 9.03176
PPO Batch Consumption Time: 1.24760
Total Iteration Time: 23.94896

Cumulative Model Updates: 3,048
Cumulative Timesteps: 25,451,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.54739
Policy Entropy: 1.40837
Value Function Loss: 0.28486

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.03284
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.12316

Collected Steps per Second: 3,337.95424
Overall Steps per Second: 2,059.96064

Timestep Collection Time: 14.97953
Timestep Consumption Time: 9.29326
PPO Batch Consumption Time: 1.31571
Total Iteration Time: 24.27279

Cumulative Model Updates: 3,054
Cumulative Timesteps: 25,501,121

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 25501121...
Checkpoint 25501121 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.89098
Policy Entropy: 1.41026
Value Function Loss: 0.28255

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.04266
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 3,286.56018
Overall Steps per Second: 2,048.87915

Timestep Collection Time: 15.21500
Timestep Consumption Time: 9.19103
PPO Batch Consumption Time: 1.29087
Total Iteration Time: 24.40603

Cumulative Model Updates: 3,060
Cumulative Timesteps: 25,551,126

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.41880
Policy Entropy: 1.41081
Value Function Loss: 0.28321

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.06675
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 3,347.85703
Overall Steps per Second: 2,069.22029

Timestep Collection Time: 14.93552
Timestep Consumption Time: 9.22913
PPO Batch Consumption Time: 1.29627
Total Iteration Time: 24.16466

Cumulative Model Updates: 3,066
Cumulative Timesteps: 25,601,128

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 25601128...
Checkpoint 25601128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.81197
Policy Entropy: 1.41066
Value Function Loss: 0.27615

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.03706
Policy Update Magnitude: 0.06605
Value Function Update Magnitude: 0.11861

Collected Steps per Second: 3,364.74586
Overall Steps per Second: 2,069.57580

Timestep Collection Time: 14.86115
Timestep Consumption Time: 9.30032
PPO Batch Consumption Time: 1.32765
Total Iteration Time: 24.16147

Cumulative Model Updates: 3,072
Cumulative Timesteps: 25,651,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.73410
Policy Entropy: 1.41039
Value Function Loss: 0.27230

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.03961
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.11964

Collected Steps per Second: 3,346.91538
Overall Steps per Second: 2,042.75726

Timestep Collection Time: 14.93943
Timestep Consumption Time: 9.53778
PPO Batch Consumption Time: 1.35119
Total Iteration Time: 24.47721

Cumulative Model Updates: 3,078
Cumulative Timesteps: 25,701,133

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 25701133...
Checkpoint 25701133 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.28479
Policy Entropy: 1.41095
Value Function Loss: 0.26465

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.12493

Collected Steps per Second: 3,313.00057
Overall Steps per Second: 2,052.55484

Timestep Collection Time: 15.09296
Timestep Consumption Time: 9.26838
PPO Batch Consumption Time: 1.29329
Total Iteration Time: 24.36135

Cumulative Model Updates: 3,084
Cumulative Timesteps: 25,751,136

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.93823
Policy Entropy: 1.41039
Value Function Loss: 0.27366

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.14362

Collected Steps per Second: 3,307.23414
Overall Steps per Second: 2,051.52674

Timestep Collection Time: 15.11928
Timestep Consumption Time: 9.25427
PPO Batch Consumption Time: 1.29339
Total Iteration Time: 24.37356

Cumulative Model Updates: 3,090
Cumulative Timesteps: 25,801,139

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 25801139...
Checkpoint 25801139 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.61218
Policy Entropy: 1.41089
Value Function Loss: 0.28055

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03620
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.14374

Collected Steps per Second: 3,347.63703
Overall Steps per Second: 2,057.18698

Timestep Collection Time: 14.93621
Timestep Consumption Time: 9.36931
PPO Batch Consumption Time: 1.30591
Total Iteration Time: 24.30552

Cumulative Model Updates: 3,096
Cumulative Timesteps: 25,851,140

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.99463
Policy Entropy: 1.41004
Value Function Loss: 0.27610

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.13540

Collected Steps per Second: 3,363.84463
Overall Steps per Second: 2,059.52708

Timestep Collection Time: 14.86424
Timestep Consumption Time: 9.41366
PPO Batch Consumption Time: 1.31925
Total Iteration Time: 24.27790

Cumulative Model Updates: 3,102
Cumulative Timesteps: 25,901,141

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 25901141...
Checkpoint 25901141 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.20063
Policy Entropy: 1.40993
Value Function Loss: 0.27058

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.12949

Collected Steps per Second: 3,357.07143
Overall Steps per Second: 2,071.19703

Timestep Collection Time: 14.89542
Timestep Consumption Time: 9.24762
PPO Batch Consumption Time: 1.30344
Total Iteration Time: 24.14304

Cumulative Model Updates: 3,108
Cumulative Timesteps: 25,951,146

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.09487
Policy Entropy: 1.40978
Value Function Loss: 0.26785

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 3,320.33941
Overall Steps per Second: 2,042.55686

Timestep Collection Time: 15.05991
Timestep Consumption Time: 9.42117
PPO Batch Consumption Time: 1.34418
Total Iteration Time: 24.48108

Cumulative Model Updates: 3,114
Cumulative Timesteps: 26,001,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 26001150...
Checkpoint 26001150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.78947
Policy Entropy: 1.41072
Value Function Loss: 0.27339

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.11226

Collected Steps per Second: 3,309.57548
Overall Steps per Second: 2,048.86697

Timestep Collection Time: 15.10768
Timestep Consumption Time: 9.29605
PPO Batch Consumption Time: 1.30539
Total Iteration Time: 24.40373

Cumulative Model Updates: 3,120
Cumulative Timesteps: 26,051,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.83436
Policy Entropy: 1.41064
Value Function Loss: 0.27255

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.11034

Collected Steps per Second: 3,381.06800
Overall Steps per Second: 2,070.31275

Timestep Collection Time: 14.78823
Timestep Consumption Time: 9.36271
PPO Batch Consumption Time: 1.30887
Total Iteration Time: 24.15094

Cumulative Model Updates: 3,126
Cumulative Timesteps: 26,101,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 26101150...
Checkpoint 26101150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.08214
Policy Entropy: 1.41039
Value Function Loss: 0.27549

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03345
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 3,396.43839
Overall Steps per Second: 2,066.81839

Timestep Collection Time: 14.72130
Timestep Consumption Time: 9.47047
PPO Batch Consumption Time: 1.32904
Total Iteration Time: 24.19177

Cumulative Model Updates: 3,132
Cumulative Timesteps: 26,151,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.11745
Policy Entropy: 1.41023
Value Function Loss: 0.27779

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 0.06333
Value Function Update Magnitude: 0.11344

Collected Steps per Second: 3,372.37295
Overall Steps per Second: 2,076.19343

Timestep Collection Time: 14.82724
Timestep Consumption Time: 9.25673
PPO Batch Consumption Time: 1.30220
Total Iteration Time: 24.08398

Cumulative Model Updates: 3,138
Cumulative Timesteps: 26,201,153

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 26201153...
Checkpoint 26201153 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.43859
Policy Entropy: 1.41117
Value Function Loss: 0.28437

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02198
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 3,325.29119
Overall Steps per Second: 2,049.13314

Timestep Collection Time: 15.03658
Timestep Consumption Time: 9.36447
PPO Batch Consumption Time: 1.32128
Total Iteration Time: 24.40105

Cumulative Model Updates: 3,144
Cumulative Timesteps: 26,251,154

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.92212
Policy Entropy: 1.41085
Value Function Loss: 0.28458

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.10944

Collected Steps per Second: 3,347.61292
Overall Steps per Second: 2,053.40753

Timestep Collection Time: 14.93691
Timestep Consumption Time: 9.41432
PPO Batch Consumption Time: 1.32176
Total Iteration Time: 24.35123

Cumulative Model Updates: 3,150
Cumulative Timesteps: 26,301,157

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 26301157...
Checkpoint 26301157 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.49907
Policy Entropy: 1.41115
Value Function Loss: 0.28485

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02037
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 3,369.27798
Overall Steps per Second: 2,069.84161

Timestep Collection Time: 14.84087
Timestep Consumption Time: 9.31702
PPO Batch Consumption Time: 1.30611
Total Iteration Time: 24.15789

Cumulative Model Updates: 3,156
Cumulative Timesteps: 26,351,160

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.24636
Policy Entropy: 1.41115
Value Function Loss: 0.28841

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.06671
Value Function Update Magnitude: 0.11530

Collected Steps per Second: 3,365.57478
Overall Steps per Second: 2,063.96915

Timestep Collection Time: 14.85630
Timestep Consumption Time: 9.36886
PPO Batch Consumption Time: 1.31230
Total Iteration Time: 24.22517

Cumulative Model Updates: 3,162
Cumulative Timesteps: 26,401,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 26401160...
Checkpoint 26401160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.46876
Policy Entropy: 1.41057
Value Function Loss: 0.28826

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.07039
Value Function Update Magnitude: 0.11660

Collected Steps per Second: 3,366.60719
Overall Steps per Second: 2,076.86756

Timestep Collection Time: 14.85234
Timestep Consumption Time: 9.22334
PPO Batch Consumption Time: 1.29760
Total Iteration Time: 24.07568

Cumulative Model Updates: 3,168
Cumulative Timesteps: 26,451,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.30958
Policy Entropy: 1.41083
Value Function Loss: 0.28178

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01822
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 3,335.68383
Overall Steps per Second: 2,046.77738

Timestep Collection Time: 14.99003
Timestep Consumption Time: 9.43959
PPO Batch Consumption Time: 1.32885
Total Iteration Time: 24.42962

Cumulative Model Updates: 3,174
Cumulative Timesteps: 26,501,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 26501164...
Checkpoint 26501164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.29947
Policy Entropy: 1.41058
Value Function Loss: 0.28097

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01707
Policy Update Magnitude: 0.07708
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 3,386.63392
Overall Steps per Second: 2,079.31633

Timestep Collection Time: 14.76481
Timestep Consumption Time: 9.28300
PPO Batch Consumption Time: 1.31908
Total Iteration Time: 24.04781

Cumulative Model Updates: 3,180
Cumulative Timesteps: 26,551,167

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.56581
Policy Entropy: 1.41067
Value Function Loss: 0.27662

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01634
Policy Update Magnitude: 0.08819
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 3,365.63646
Overall Steps per Second: 2,050.86735

Timestep Collection Time: 14.85692
Timestep Consumption Time: 9.52447
PPO Batch Consumption Time: 1.32839
Total Iteration Time: 24.38139

Cumulative Model Updates: 3,186
Cumulative Timesteps: 26,601,170

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 26601170...
Checkpoint 26601170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.56727
Policy Entropy: 1.41087
Value Function Loss: 0.28296

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01328
Policy Update Magnitude: 0.09812
Value Function Update Magnitude: 0.11461

Collected Steps per Second: 3,386.86504
Overall Steps per Second: 2,067.59517

Timestep Collection Time: 14.76351
Timestep Consumption Time: 9.42015
PPO Batch Consumption Time: 1.33207
Total Iteration Time: 24.18365

Cumulative Model Updates: 3,192
Cumulative Timesteps: 26,651,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.71328
Policy Entropy: 1.41095
Value Function Loss: 0.27224

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01633
Policy Update Magnitude: 0.08285
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 3,351.49421
Overall Steps per Second: 2,067.12276

Timestep Collection Time: 14.91991
Timestep Consumption Time: 9.27023
PPO Batch Consumption Time: 1.31746
Total Iteration Time: 24.19015

Cumulative Model Updates: 3,198
Cumulative Timesteps: 26,701,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 26701176...
Checkpoint 26701176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.99334
Policy Entropy: 1.41048
Value Function Loss: 0.27334

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.08680
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 3,347.59683
Overall Steps per Second: 2,059.36671

Timestep Collection Time: 14.93698
Timestep Consumption Time: 9.34378
PPO Batch Consumption Time: 1.32459
Total Iteration Time: 24.28077

Cumulative Model Updates: 3,204
Cumulative Timesteps: 26,751,179

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.83432
Policy Entropy: 1.40993
Value Function Loss: 0.27494

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01672
Policy Update Magnitude: 0.08733
Value Function Update Magnitude: 0.11802

Collected Steps per Second: 3,352.00759
Overall Steps per Second: 2,059.70769

Timestep Collection Time: 14.91643
Timestep Consumption Time: 9.35886
PPO Batch Consumption Time: 1.33219
Total Iteration Time: 24.27529

Cumulative Model Updates: 3,210
Cumulative Timesteps: 26,801,179

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 26801179...
Checkpoint 26801179 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.10788
Policy Entropy: 1.40968
Value Function Loss: 0.28249

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01519
Policy Update Magnitude: 0.08342
Value Function Update Magnitude: 0.11996

Collected Steps per Second: 3,384.70167
Overall Steps per Second: 2,068.24662

Timestep Collection Time: 14.77324
Timestep Consumption Time: 9.40328
PPO Batch Consumption Time: 1.31667
Total Iteration Time: 24.17652

Cumulative Model Updates: 3,216
Cumulative Timesteps: 26,851,182

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.31039
Policy Entropy: 1.40923
Value Function Loss: 0.28410

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01946
Policy Update Magnitude: 0.08872
Value Function Update Magnitude: 0.13514

Collected Steps per Second: 3,402.47686
Overall Steps per Second: 2,054.54357

Timestep Collection Time: 14.69635
Timestep Consumption Time: 9.64190
PPO Batch Consumption Time: 1.36754
Total Iteration Time: 24.33825

Cumulative Model Updates: 3,222
Cumulative Timesteps: 26,901,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 26901186...
Checkpoint 26901186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.48402
Policy Entropy: 1.40954
Value Function Loss: 0.28228

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.09107
Value Function Update Magnitude: 0.14318

Collected Steps per Second: 3,343.99425
Overall Steps per Second: 2,059.64135

Timestep Collection Time: 14.95337
Timestep Consumption Time: 9.32464
PPO Batch Consumption Time: 1.31488
Total Iteration Time: 24.27801

Cumulative Model Updates: 3,228
Cumulative Timesteps: 26,951,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.98443
Policy Entropy: 1.41013
Value Function Loss: 0.28121

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.08727
Value Function Update Magnitude: 0.13867

Collected Steps per Second: 3,359.69231
Overall Steps per Second: 2,055.33634

Timestep Collection Time: 14.88351
Timestep Consumption Time: 9.44536
PPO Batch Consumption Time: 1.35090
Total Iteration Time: 24.32886

Cumulative Model Updates: 3,234
Cumulative Timesteps: 27,001,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 27001194...
Checkpoint 27001194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.48713
Policy Entropy: 1.41020
Value Function Loss: 0.27317

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01924
Policy Update Magnitude: 0.09183
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 3,282.03254
Overall Steps per Second: 2,044.22739

Timestep Collection Time: 15.23477
Timestep Consumption Time: 9.22484
PPO Batch Consumption Time: 1.30715
Total Iteration Time: 24.45961

Cumulative Model Updates: 3,240
Cumulative Timesteps: 27,051,195

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.45254
Policy Entropy: 1.41106
Value Function Loss: 0.28231

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01855
Policy Update Magnitude: 0.10404
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 3,388.61555
Overall Steps per Second: 2,078.63345

Timestep Collection Time: 14.75588
Timestep Consumption Time: 9.29935
PPO Batch Consumption Time: 1.30672
Total Iteration Time: 24.05523

Cumulative Model Updates: 3,246
Cumulative Timesteps: 27,101,197

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 27101197...
Checkpoint 27101197 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.68014
Policy Entropy: 1.41048
Value Function Loss: 0.28629

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01870
Policy Update Magnitude: 0.11754
Value Function Update Magnitude: 0.12962

Collected Steps per Second: 3,371.38570
Overall Steps per Second: 2,060.72674

Timestep Collection Time: 14.83188
Timestep Consumption Time: 9.43334
PPO Batch Consumption Time: 1.32929
Total Iteration Time: 24.26523

Cumulative Model Updates: 3,252
Cumulative Timesteps: 27,151,201

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.50685
Policy Entropy: 1.41187
Value Function Loss: 0.29615

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.10791
Value Function Update Magnitude: 0.12982

Collected Steps per Second: 3,362.38067
Overall Steps per Second: 2,056.59273

Timestep Collection Time: 14.87101
Timestep Consumption Time: 9.44202
PPO Batch Consumption Time: 1.32799
Total Iteration Time: 24.31303

Cumulative Model Updates: 3,258
Cumulative Timesteps: 27,201,203

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 27201203...
Checkpoint 27201203 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.34019
Policy Entropy: 1.41216
Value Function Loss: 0.28654

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.10430
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 3,364.23523
Overall Steps per Second: 2,067.80794

Timestep Collection Time: 14.86311
Timestep Consumption Time: 9.31854
PPO Batch Consumption Time: 1.31218
Total Iteration Time: 24.18165

Cumulative Model Updates: 3,264
Cumulative Timesteps: 27,251,206

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.41537
Policy Entropy: 1.41190
Value Function Loss: 0.28297

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.08524
Value Function Update Magnitude: 0.12055

Collected Steps per Second: 3,367.05522
Overall Steps per Second: 2,066.38748

Timestep Collection Time: 14.85126
Timestep Consumption Time: 9.34798
PPO Batch Consumption Time: 1.32380
Total Iteration Time: 24.19924

Cumulative Model Updates: 3,270
Cumulative Timesteps: 27,301,211

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 27301211...
Checkpoint 27301211 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.32874
Policy Entropy: 1.41121
Value Function Loss: 0.27975

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.07829
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 3,382.07587
Overall Steps per Second: 2,059.79715

Timestep Collection Time: 14.78441
Timestep Consumption Time: 9.49079
PPO Batch Consumption Time: 1.34203
Total Iteration Time: 24.27521

Cumulative Model Updates: 3,276
Cumulative Timesteps: 27,351,213

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.17618
Policy Entropy: 1.41168
Value Function Loss: 0.27672

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.07720
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 3,382.72543
Overall Steps per Second: 2,061.48621

Timestep Collection Time: 14.78098
Timestep Consumption Time: 9.47337
PPO Batch Consumption Time: 1.32646
Total Iteration Time: 24.25435

Cumulative Model Updates: 3,282
Cumulative Timesteps: 27,401,213

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27401213...
Checkpoint 27401213 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.09738
Policy Entropy: 1.41101
Value Function Loss: 0.27325

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.07525
Value Function Update Magnitude: 0.10857

Collected Steps per Second: 3,354.99047
Overall Steps per Second: 2,074.55324

Timestep Collection Time: 14.90407
Timestep Consumption Time: 9.19895
PPO Batch Consumption Time: 1.30471
Total Iteration Time: 24.10302

Cumulative Model Updates: 3,288
Cumulative Timesteps: 27,451,216

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.32184
Policy Entropy: 1.41108
Value Function Loss: 0.28000

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02388
Policy Update Magnitude: 0.07354
Value Function Update Magnitude: 0.11590

Collected Steps per Second: 3,343.16333
Overall Steps per Second: 2,033.96432

Timestep Collection Time: 14.95590
Timestep Consumption Time: 9.62664
PPO Batch Consumption Time: 1.36271
Total Iteration Time: 24.58254

Cumulative Model Updates: 3,294
Cumulative Timesteps: 27,501,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27501216...
Checkpoint 27501216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.48496
Policy Entropy: 1.41072
Value Function Loss: 0.28228

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.07467
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 3,345.65093
Overall Steps per Second: 2,062.61665

Timestep Collection Time: 14.94477
Timestep Consumption Time: 9.29628
PPO Batch Consumption Time: 1.31804
Total Iteration Time: 24.24105

Cumulative Model Updates: 3,300
Cumulative Timesteps: 27,551,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.77726
Policy Entropy: 1.41046
Value Function Loss: 0.28421

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01877
Policy Update Magnitude: 0.07529
Value Function Update Magnitude: 0.11186

Collected Steps per Second: 3,350.18548
Overall Steps per Second: 2,033.11760

Timestep Collection Time: 14.92485
Timestep Consumption Time: 9.66842
PPO Batch Consumption Time: 1.36751
Total Iteration Time: 24.59327

Cumulative Model Updates: 3,306
Cumulative Timesteps: 27,601,217

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 27601217...
Checkpoint 27601217 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.17045
Policy Entropy: 1.41093
Value Function Loss: 0.27433

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01609
Policy Update Magnitude: 0.07091
Value Function Update Magnitude: 0.11117

Collected Steps per Second: 3,359.49842
Overall Steps per Second: 2,064.92149

Timestep Collection Time: 14.88347
Timestep Consumption Time: 9.33101
PPO Batch Consumption Time: 1.31873
Total Iteration Time: 24.21448

Cumulative Model Updates: 3,312
Cumulative Timesteps: 27,651,218

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.61748
Policy Entropy: 1.41023
Value Function Loss: 0.27162

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01527
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 3,337.30397
Overall Steps per Second: 2,053.07741

Timestep Collection Time: 14.98215
Timestep Consumption Time: 9.37153
PPO Batch Consumption Time: 1.32577
Total Iteration Time: 24.35368

Cumulative Model Updates: 3,318
Cumulative Timesteps: 27,701,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27701218...
Checkpoint 27701218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.40799
Policy Entropy: 1.41115
Value Function Loss: 0.26757

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01349
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.11418

Collected Steps per Second: 3,357.41505
Overall Steps per Second: 2,055.09905

Timestep Collection Time: 14.89271
Timestep Consumption Time: 9.43751
PPO Batch Consumption Time: 1.34427
Total Iteration Time: 24.33021

Cumulative Model Updates: 3,324
Cumulative Timesteps: 27,751,219

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.21234
Policy Entropy: 1.41123
Value Function Loss: 0.27141

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01422
Policy Update Magnitude: 0.06689
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 3,345.32530
Overall Steps per Second: 2,041.51733

Timestep Collection Time: 14.94772
Timestep Consumption Time: 9.54631
PPO Batch Consumption Time: 1.34998
Total Iteration Time: 24.49404

Cumulative Model Updates: 3,330
Cumulative Timesteps: 27,801,224

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 27801224...
Checkpoint 27801224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.86499
Policy Entropy: 1.41109
Value Function Loss: 0.27114

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01439
Policy Update Magnitude: 0.06614
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 3,358.04873
Overall Steps per Second: 2,054.15203

Timestep Collection Time: 14.88990
Timestep Consumption Time: 9.45153
PPO Batch Consumption Time: 1.33602
Total Iteration Time: 24.34143

Cumulative Model Updates: 3,336
Cumulative Timesteps: 27,851,225

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.28135
Policy Entropy: 1.41103
Value Function Loss: 0.27722

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01176
Policy Update Magnitude: 0.06593
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 3,381.72796
Overall Steps per Second: 2,047.32275

Timestep Collection Time: 14.78534
Timestep Consumption Time: 9.63680
PPO Batch Consumption Time: 1.35890
Total Iteration Time: 24.42214

Cumulative Model Updates: 3,342
Cumulative Timesteps: 27,901,225

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27901225...
Checkpoint 27901225 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.77189
Policy Entropy: 1.41086
Value Function Loss: 0.28439

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01216
Policy Update Magnitude: 0.06981
Value Function Update Magnitude: 0.11744

Collected Steps per Second: 3,342.61567
Overall Steps per Second: 2,056.41675

Timestep Collection Time: 14.95835
Timestep Consumption Time: 9.35579
PPO Batch Consumption Time: 1.31775
Total Iteration Time: 24.31414

Cumulative Model Updates: 3,348
Cumulative Timesteps: 27,951,225

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.05064
Policy Entropy: 1.41108
Value Function Loss: 0.28892

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02028
Policy Update Magnitude: 0.06824
Value Function Update Magnitude: 0.13524

Collected Steps per Second: 3,369.36727
Overall Steps per Second: 2,068.48647

Timestep Collection Time: 14.84107
Timestep Consumption Time: 9.33362
PPO Batch Consumption Time: 1.31109
Total Iteration Time: 24.17468

Cumulative Model Updates: 3,354
Cumulative Timesteps: 28,001,230

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 28001230...
Checkpoint 28001230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.51173
Policy Entropy: 1.41047
Value Function Loss: 0.28458

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.07089
Value Function Update Magnitude: 0.13674

Collected Steps per Second: 3,351.87965
Overall Steps per Second: 2,068.71793

Timestep Collection Time: 14.91790
Timestep Consumption Time: 9.25311
PPO Batch Consumption Time: 1.30431
Total Iteration Time: 24.17101

Cumulative Model Updates: 3,360
Cumulative Timesteps: 28,051,233

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.83722
Policy Entropy: 1.41083
Value Function Loss: 0.27569

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.06810
Value Function Update Magnitude: 0.13346

Collected Steps per Second: 3,340.22882
Overall Steps per Second: 2,047.04613

Timestep Collection Time: 14.96993
Timestep Consumption Time: 9.45697
PPO Batch Consumption Time: 1.32864
Total Iteration Time: 24.42690

Cumulative Model Updates: 3,366
Cumulative Timesteps: 28,101,236

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 28101236...
Checkpoint 28101236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.25944
Policy Entropy: 1.41071
Value Function Loss: 0.26874

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.06657
Value Function Update Magnitude: 0.11579

Collected Steps per Second: 3,315.76684
Overall Steps per Second: 2,050.32749

Timestep Collection Time: 15.08007
Timestep Consumption Time: 9.30725
PPO Batch Consumption Time: 1.31452
Total Iteration Time: 24.38732

Cumulative Model Updates: 3,372
Cumulative Timesteps: 28,151,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.99810
Policy Entropy: 1.41115
Value Function Loss: 0.27243

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01481
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 3,349.74200
Overall Steps per Second: 2,040.05943

Timestep Collection Time: 14.92742
Timestep Consumption Time: 9.58314
PPO Batch Consumption Time: 1.35183
Total Iteration Time: 24.51056

Cumulative Model Updates: 3,378
Cumulative Timesteps: 28,201,241

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 28201241...
Checkpoint 28201241 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.08984
Policy Entropy: 1.41133
Value Function Loss: 0.27762

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02219
Policy Update Magnitude: 0.06962
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 3,338.64552
Overall Steps per Second: 2,063.26813

Timestep Collection Time: 14.97733
Timestep Consumption Time: 9.25801
PPO Batch Consumption Time: 1.31041
Total Iteration Time: 24.23534

Cumulative Model Updates: 3,384
Cumulative Timesteps: 28,251,245

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.60046
Policy Entropy: 1.41126
Value Function Loss: 0.28330

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.07191
Value Function Update Magnitude: 0.10338

Collected Steps per Second: 3,333.81416
Overall Steps per Second: 2,043.10049

Timestep Collection Time: 14.99904
Timestep Consumption Time: 9.47553
PPO Batch Consumption Time: 1.33275
Total Iteration Time: 24.47457

Cumulative Model Updates: 3,390
Cumulative Timesteps: 28,301,249

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 28301249...
Checkpoint 28301249 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.08793
Policy Entropy: 1.41085
Value Function Loss: 0.27716

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.06804
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 3,373.55216
Overall Steps per Second: 2,058.84277

Timestep Collection Time: 14.82177
Timestep Consumption Time: 9.46469
PPO Batch Consumption Time: 1.34131
Total Iteration Time: 24.28646

Cumulative Model Updates: 3,396
Cumulative Timesteps: 28,351,251

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.77943
Policy Entropy: 1.41183
Value Function Loss: 0.26923

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01789
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.10808

Collected Steps per Second: 3,375.17273
Overall Steps per Second: 2,042.51611

Timestep Collection Time: 14.81495
Timestep Consumption Time: 9.66613
PPO Batch Consumption Time: 1.37088
Total Iteration Time: 24.48108

Cumulative Model Updates: 3,402
Cumulative Timesteps: 28,401,254

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 28401254...
Checkpoint 28401254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.58188
Policy Entropy: 1.41141
Value Function Loss: 0.26562

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.06409
Value Function Update Magnitude: 0.10820

Collected Steps per Second: 3,359.75678
Overall Steps per Second: 2,067.38320

Timestep Collection Time: 14.88233
Timestep Consumption Time: 9.30332
PPO Batch Consumption Time: 1.31755
Total Iteration Time: 24.18565

Cumulative Model Updates: 3,408
Cumulative Timesteps: 28,451,255

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.50434
Policy Entropy: 1.41222
Value Function Loss: 0.27188

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.10793

Collected Steps per Second: 3,353.08012
Overall Steps per Second: 2,036.62500

Timestep Collection Time: 14.91286
Timestep Consumption Time: 9.63953
PPO Batch Consumption Time: 1.36049
Total Iteration Time: 24.55238

Cumulative Model Updates: 3,414
Cumulative Timesteps: 28,501,259

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 28501259...
Checkpoint 28501259 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.93641
Policy Entropy: 1.41211
Value Function Loss: 0.27282

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 0.07000
Value Function Update Magnitude: 0.10998

Collected Steps per Second: 3,327.62167
Overall Steps per Second: 2,037.66510

Timestep Collection Time: 15.02605
Timestep Consumption Time: 9.51233
PPO Batch Consumption Time: 1.35262
Total Iteration Time: 24.53838

Cumulative Model Updates: 3,420
Cumulative Timesteps: 28,551,260

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.87411
Policy Entropy: 1.41235
Value Function Loss: 0.26867

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01572
Policy Update Magnitude: 0.07029
Value Function Update Magnitude: 0.10843

Collected Steps per Second: 3,349.42519
Overall Steps per Second: 2,033.62110

Timestep Collection Time: 14.92823
Timestep Consumption Time: 9.65894
PPO Batch Consumption Time: 1.35994
Total Iteration Time: 24.58718

Cumulative Model Updates: 3,426
Cumulative Timesteps: 28,601,261

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 28601261...
Checkpoint 28601261 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.38382
Policy Entropy: 1.41199
Value Function Loss: 0.27384

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01411
Policy Update Magnitude: 0.07464
Value Function Update Magnitude: 0.11113

Collected Steps per Second: 3,360.93964
Overall Steps per Second: 2,054.76464

Timestep Collection Time: 14.87739
Timestep Consumption Time: 9.45727
PPO Batch Consumption Time: 1.32633
Total Iteration Time: 24.33466

Cumulative Model Updates: 3,432
Cumulative Timesteps: 28,651,263

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.36106
Policy Entropy: 1.41187
Value Function Loss: 0.27439

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01228
Policy Update Magnitude: 0.07708
Value Function Update Magnitude: 0.11155

Collected Steps per Second: 3,356.79557
Overall Steps per Second: 2,042.82581

Timestep Collection Time: 14.89665
Timestep Consumption Time: 9.58170
PPO Batch Consumption Time: 1.36155
Total Iteration Time: 24.47835

Cumulative Model Updates: 3,438
Cumulative Timesteps: 28,701,268

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 28701268...
Checkpoint 28701268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.33536
Policy Entropy: 1.41160
Value Function Loss: 0.27678

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01569
Policy Update Magnitude: 0.07579
Value Function Update Magnitude: 0.11007

Collected Steps per Second: 3,348.36277
Overall Steps per Second: 2,063.71099

Timestep Collection Time: 14.93327
Timestep Consumption Time: 9.29590
PPO Batch Consumption Time: 1.31573
Total Iteration Time: 24.22917

Cumulative Model Updates: 3,444
Cumulative Timesteps: 28,751,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.42320
Policy Entropy: 1.41167
Value Function Loss: 0.27509

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01523
Policy Update Magnitude: 0.07643
Value Function Update Magnitude: 0.11330

Collected Steps per Second: 3,332.52790
Overall Steps per Second: 2,034.91956

Timestep Collection Time: 15.00393
Timestep Consumption Time: 9.56756
PPO Batch Consumption Time: 1.35293
Total Iteration Time: 24.57149

Cumulative Model Updates: 3,450
Cumulative Timesteps: 28,801,271

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 28801271...
Checkpoint 28801271 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.12790
Policy Entropy: 1.41126
Value Function Loss: 0.28495

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02114
Policy Update Magnitude: 0.08014
Value Function Update Magnitude: 0.10959

Collected Steps per Second: 3,370.73649
Overall Steps per Second: 2,065.22005

Timestep Collection Time: 14.83355
Timestep Consumption Time: 9.37694
PPO Batch Consumption Time: 1.32291
Total Iteration Time: 24.21050

Cumulative Model Updates: 3,456
Cumulative Timesteps: 28,851,271

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.06132
Policy Entropy: 1.41105
Value Function Loss: 0.28147

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.08019
Value Function Update Magnitude: 0.11525

Collected Steps per Second: 3,333.69497
Overall Steps per Second: 2,038.85549

Timestep Collection Time: 14.99867
Timestep Consumption Time: 9.52538
PPO Batch Consumption Time: 1.34537
Total Iteration Time: 24.52405

Cumulative Model Updates: 3,462
Cumulative Timesteps: 28,901,272

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 28901272...
Checkpoint 28901272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.99846
Policy Entropy: 1.41100
Value Function Loss: 0.27144

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.08726
Value Function Update Magnitude: 0.11608

Collected Steps per Second: 3,352.98051
Overall Steps per Second: 2,064.56180

Timestep Collection Time: 14.91300
Timestep Consumption Time: 9.30667
PPO Batch Consumption Time: 1.30994
Total Iteration Time: 24.21967

Cumulative Model Updates: 3,468
Cumulative Timesteps: 28,951,275

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.18620
Policy Entropy: 1.41133
Value Function Loss: 0.25944

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01907
Policy Update Magnitude: 0.07666
Value Function Update Magnitude: 0.11140

Collected Steps per Second: 3,356.05891
Overall Steps per Second: 2,053.21300

Timestep Collection Time: 14.89932
Timestep Consumption Time: 9.45422
PPO Batch Consumption Time: 1.32429
Total Iteration Time: 24.35354

Cumulative Model Updates: 3,474
Cumulative Timesteps: 29,001,278

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 29001278...
Checkpoint 29001278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.01845
Policy Entropy: 1.41098
Value Function Loss: 0.25954

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 3,357.86474
Overall Steps per Second: 2,066.67309

Timestep Collection Time: 14.89161
Timestep Consumption Time: 9.30380
PPO Batch Consumption Time: 1.31276
Total Iteration Time: 24.19541

Cumulative Model Updates: 3,480
Cumulative Timesteps: 29,051,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.14055
Policy Entropy: 1.41118
Value Function Loss: 0.26889

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02178
Policy Update Magnitude: 0.07215
Value Function Update Magnitude: 0.10357

Collected Steps per Second: 3,378.50879
Overall Steps per Second: 2,063.84861

Timestep Collection Time: 14.79972
Timestep Consumption Time: 9.42734
PPO Batch Consumption Time: 1.32316
Total Iteration Time: 24.22707

Cumulative Model Updates: 3,486
Cumulative Timesteps: 29,101,283

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 29101283...
Checkpoint 29101283 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.73564
Policy Entropy: 1.41121
Value Function Loss: 0.26995

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.11404

Collected Steps per Second: 3,353.78497
Overall Steps per Second: 2,051.80435

Timestep Collection Time: 14.90913
Timestep Consumption Time: 9.46064
PPO Batch Consumption Time: 1.34120
Total Iteration Time: 24.36977

Cumulative Model Updates: 3,492
Cumulative Timesteps: 29,151,285

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.24636
Policy Entropy: 1.41123
Value Function Loss: 0.26496

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01663
Policy Update Magnitude: 0.07107
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 3,338.94235
Overall Steps per Second: 2,063.93513

Timestep Collection Time: 14.97510
Timestep Consumption Time: 9.25095
PPO Batch Consumption Time: 1.31244
Total Iteration Time: 24.22605

Cumulative Model Updates: 3,498
Cumulative Timesteps: 29,201,286

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 29201286...
Checkpoint 29201286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.97110
Policy Entropy: 1.41183
Value Function Loss: 0.25447

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01798
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.11240

Collected Steps per Second: 3,358.65273
Overall Steps per Second: 2,066.58872

Timestep Collection Time: 14.88811
Timestep Consumption Time: 9.30828
PPO Batch Consumption Time: 1.31634
Total Iteration Time: 24.19640

Cumulative Model Updates: 3,504
Cumulative Timesteps: 29,251,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.69441
Policy Entropy: 1.41121
Value Function Loss: 0.25561

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01773
Policy Update Magnitude: 0.07106
Value Function Update Magnitude: 0.11052

Collected Steps per Second: 3,346.07330
Overall Steps per Second: 2,057.70164

Timestep Collection Time: 14.94319
Timestep Consumption Time: 9.35625
PPO Batch Consumption Time: 1.30853
Total Iteration Time: 24.29944

Cumulative Model Updates: 3,510
Cumulative Timesteps: 29,301,291

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 29301291...
Checkpoint 29301291 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.58089
Policy Entropy: 1.41138
Value Function Loss: 0.26053

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01708
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 3,348.52259
Overall Steps per Second: 2,051.88277

Timestep Collection Time: 14.93285
Timestep Consumption Time: 9.43647
PPO Batch Consumption Time: 1.32364
Total Iteration Time: 24.36933

Cumulative Model Updates: 3,516
Cumulative Timesteps: 29,351,294

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.07172
Policy Entropy: 1.41085
Value Function Loss: 0.26631

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01754
Policy Update Magnitude: 0.07126
Value Function Update Magnitude: 0.11285

Collected Steps per Second: 3,358.00254
Overall Steps per Second: 2,034.45569

Timestep Collection Time: 14.89070
Timestep Consumption Time: 9.68738
PPO Batch Consumption Time: 1.38071
Total Iteration Time: 24.57807

Cumulative Model Updates: 3,522
Cumulative Timesteps: 29,401,297

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 29401297...
Checkpoint 29401297 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.25263
Policy Entropy: 1.41052
Value Function Loss: 0.26510

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01696
Policy Update Magnitude: 0.07302
Value Function Update Magnitude: 0.11451

Collected Steps per Second: 3,369.47174
Overall Steps per Second: 2,060.96336

Timestep Collection Time: 14.84001
Timestep Consumption Time: 9.42194
PPO Batch Consumption Time: 1.32061
Total Iteration Time: 24.26195

Cumulative Model Updates: 3,528
Cumulative Timesteps: 29,451,300

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.73046
Policy Entropy: 1.41100
Value Function Loss: 0.26324

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.07251
Value Function Update Magnitude: 0.11153

Collected Steps per Second: 3,368.40118
Overall Steps per Second: 2,046.22251

Timestep Collection Time: 14.84473
Timestep Consumption Time: 9.59201
PPO Batch Consumption Time: 1.35926
Total Iteration Time: 24.43674

Cumulative Model Updates: 3,534
Cumulative Timesteps: 29,501,303

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 29501303...
Checkpoint 29501303 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.18349
Policy Entropy: 1.41201
Value Function Loss: 0.25921

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.07003
Value Function Update Magnitude: 0.11447

Collected Steps per Second: 3,355.20281
Overall Steps per Second: 2,083.52857

Timestep Collection Time: 14.90223
Timestep Consumption Time: 9.09552
PPO Batch Consumption Time: 1.27731
Total Iteration Time: 23.99775

Cumulative Model Updates: 3,540
Cumulative Timesteps: 29,551,303

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.39723
Policy Entropy: 1.41195
Value Function Loss: 0.26549

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.04131
Policy Update Magnitude: 0.06880
Value Function Update Magnitude: 0.11267

Collected Steps per Second: 3,380.91528
Overall Steps per Second: 2,045.63168

Timestep Collection Time: 14.79008
Timestep Consumption Time: 9.65421
PPO Batch Consumption Time: 1.36397
Total Iteration Time: 24.44428

Cumulative Model Updates: 3,546
Cumulative Timesteps: 29,601,307

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 29601307...
Checkpoint 29601307 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.78823
Policy Entropy: 1.41148
Value Function Loss: 0.27322

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.11779

Collected Steps per Second: 3,327.89499
Overall Steps per Second: 2,056.11198

Timestep Collection Time: 15.02541
Timestep Consumption Time: 9.29379
PPO Batch Consumption Time: 1.30238
Total Iteration Time: 24.31920

Cumulative Model Updates: 3,552
Cumulative Timesteps: 29,651,310

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.01151
Policy Entropy: 1.41161
Value Function Loss: 0.27768

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02176
Policy Update Magnitude: 0.07192
Value Function Update Magnitude: 0.13272

Collected Steps per Second: 3,332.71400
Overall Steps per Second: 2,050.93010

Timestep Collection Time: 15.00369
Timestep Consumption Time: 9.37696
PPO Batch Consumption Time: 1.30681
Total Iteration Time: 24.38065

Cumulative Model Updates: 3,558
Cumulative Timesteps: 29,701,313

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 29701313...
Checkpoint 29701313 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.90937
Policy Entropy: 1.41170
Value Function Loss: 0.27956

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.07238
Value Function Update Magnitude: 0.12434

Collected Steps per Second: 3,374.02770
Overall Steps per Second: 2,068.29212

Timestep Collection Time: 14.81968
Timestep Consumption Time: 9.35583
PPO Batch Consumption Time: 1.31729
Total Iteration Time: 24.17550

Cumulative Model Updates: 3,564
Cumulative Timesteps: 29,751,315

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.57516
Policy Entropy: 1.41153
Value Function Loss: 0.27427

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.07224
Value Function Update Magnitude: 0.11782

Collected Steps per Second: 3,364.45073
Overall Steps per Second: 2,060.79644

Timestep Collection Time: 14.86216
Timestep Consumption Time: 9.40176
PPO Batch Consumption Time: 1.32760
Total Iteration Time: 24.26392

Cumulative Model Updates: 3,570
Cumulative Timesteps: 29,801,318

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 29801318...
Checkpoint 29801318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.83608
Policy Entropy: 1.41080
Value Function Loss: 0.26707

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.07033
Value Function Update Magnitude: 0.12163

Collected Steps per Second: 3,385.20669
Overall Steps per Second: 2,077.36346

Timestep Collection Time: 14.77103
Timestep Consumption Time: 9.29938
PPO Batch Consumption Time: 1.31138
Total Iteration Time: 24.07041

Cumulative Model Updates: 3,576
Cumulative Timesteps: 29,851,321

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.90858
Policy Entropy: 1.41065
Value Function Loss: 0.26297

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 3,344.83531
Overall Steps per Second: 2,037.79657

Timestep Collection Time: 14.94842
Timestep Consumption Time: 9.58789
PPO Batch Consumption Time: 1.36106
Total Iteration Time: 24.53631

Cumulative Model Updates: 3,582
Cumulative Timesteps: 29,901,321

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 29901321...
Checkpoint 29901321 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.66507
Policy Entropy: 1.41053
Value Function Loss: 0.27217

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.06904
Value Function Update Magnitude: 0.11756

Collected Steps per Second: 3,352.20077
Overall Steps per Second: 2,065.50797

Timestep Collection Time: 14.91587
Timestep Consumption Time: 9.29173
PPO Batch Consumption Time: 1.29978
Total Iteration Time: 24.20760

Cumulative Model Updates: 3,588
Cumulative Timesteps: 29,951,322

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.28985
Policy Entropy: 1.41102
Value Function Loss: 0.28265

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.07287
Value Function Update Magnitude: 0.11983

Collected Steps per Second: 3,361.83119
Overall Steps per Second: 2,065.64222

Timestep Collection Time: 14.87374
Timestep Consumption Time: 9.33326
PPO Batch Consumption Time: 1.31733
Total Iteration Time: 24.20700

Cumulative Model Updates: 3,594
Cumulative Timesteps: 30,001,325

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 30001325...
Checkpoint 30001325 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.03552
Policy Entropy: 1.41136
Value Function Loss: 0.27997

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.07448
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 3,349.88047
Overall Steps per Second: 2,062.21973

Timestep Collection Time: 14.92591
Timestep Consumption Time: 9.31981
PPO Batch Consumption Time: 1.32080
Total Iteration Time: 24.24572

Cumulative Model Updates: 3,600
Cumulative Timesteps: 30,051,325

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.10535
Policy Entropy: 1.41197
Value Function Loss: 0.27590

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.07358
Value Function Update Magnitude: 0.11865

Collected Steps per Second: 3,393.75355
Overall Steps per Second: 2,070.00897

Timestep Collection Time: 14.73442
Timestep Consumption Time: 9.42248
PPO Batch Consumption Time: 1.34495
Total Iteration Time: 24.15690

Cumulative Model Updates: 3,606
Cumulative Timesteps: 30,101,330

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 30101330...
Checkpoint 30101330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.42500
Policy Entropy: 1.41146
Value Function Loss: 0.27769

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.11932

Collected Steps per Second: 3,343.42365
Overall Steps per Second: 2,050.23941

Timestep Collection Time: 14.95473
Timestep Consumption Time: 9.43267
PPO Batch Consumption Time: 1.33266
Total Iteration Time: 24.38740

Cumulative Model Updates: 3,612
Cumulative Timesteps: 30,151,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.95838
Policy Entropy: 1.41190
Value Function Loss: 0.27205

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.06900
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 3,409.00414
Overall Steps per Second: 2,063.36895

Timestep Collection Time: 14.66792
Timestep Consumption Time: 9.56575
PPO Batch Consumption Time: 1.35039
Total Iteration Time: 24.23367

Cumulative Model Updates: 3,618
Cumulative Timesteps: 30,201,333

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 30201333...
Checkpoint 30201333 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.98947
Policy Entropy: 1.41232
Value Function Loss: 0.26804

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02828
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 3,362.25815
Overall Steps per Second: 2,067.38998

Timestep Collection Time: 14.87126
Timestep Consumption Time: 9.31431
PPO Batch Consumption Time: 1.30378
Total Iteration Time: 24.18557

Cumulative Model Updates: 3,624
Cumulative Timesteps: 30,251,334

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.97232
Policy Entropy: 1.41297
Value Function Loss: 0.26221

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 3,383.94999
Overall Steps per Second: 2,080.63587

Timestep Collection Time: 14.77593
Timestep Consumption Time: 9.25567
PPO Batch Consumption Time: 1.30379
Total Iteration Time: 24.03160

Cumulative Model Updates: 3,630
Cumulative Timesteps: 30,301,335

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 30301335...
Checkpoint 30301335 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.91344
Policy Entropy: 1.41297
Value Function Loss: 0.26188

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02026
Policy Update Magnitude: 0.06601
Value Function Update Magnitude: 0.11749

Collected Steps per Second: 3,333.64957
Overall Steps per Second: 2,038.20626

Timestep Collection Time: 14.99948
Timestep Consumption Time: 9.53337
PPO Batch Consumption Time: 1.35658
Total Iteration Time: 24.53285

Cumulative Model Updates: 3,636
Cumulative Timesteps: 30,351,338

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.57111
Policy Entropy: 1.41206
Value Function Loss: 0.26951

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.11188

Collected Steps per Second: 3,377.18158
Overall Steps per Second: 2,061.75965

Timestep Collection Time: 14.80554
Timestep Consumption Time: 9.44607
PPO Batch Consumption Time: 1.34440
Total Iteration Time: 24.25161

Cumulative Model Updates: 3,642
Cumulative Timesteps: 30,401,339

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 30401339...
Checkpoint 30401339 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.49110
Policy Entropy: 1.41223
Value Function Loss: 0.27248

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.06652
Value Function Update Magnitude: 0.11550

Collected Steps per Second: 3,391.39011
Overall Steps per Second: 2,077.97914

Timestep Collection Time: 14.74410
Timestep Consumption Time: 9.31918
PPO Batch Consumption Time: 1.30915
Total Iteration Time: 24.06328

Cumulative Model Updates: 3,648
Cumulative Timesteps: 30,451,342

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.46320
Policy Entropy: 1.41190
Value Function Loss: 0.28213

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 3,348.75391
Overall Steps per Second: 2,045.12969

Timestep Collection Time: 14.93182
Timestep Consumption Time: 9.51797
PPO Batch Consumption Time: 1.34167
Total Iteration Time: 24.44979

Cumulative Model Updates: 3,654
Cumulative Timesteps: 30,501,345

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 30501345...
Checkpoint 30501345 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.52614
Policy Entropy: 1.41278
Value Function Loss: 0.28155

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.08367
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 3,295.29758
Overall Steps per Second: 2,045.75445

Timestep Collection Time: 15.17465
Timestep Consumption Time: 9.26865
PPO Batch Consumption Time: 1.28739
Total Iteration Time: 24.44331

Cumulative Model Updates: 3,660
Cumulative Timesteps: 30,551,350

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.24643
Policy Entropy: 1.41247
Value Function Loss: 0.27945

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03020
Policy Update Magnitude: 0.09270
Value Function Update Magnitude: 0.12166

Collected Steps per Second: 3,343.63425
Overall Steps per Second: 2,033.07478

Timestep Collection Time: 14.95379
Timestep Consumption Time: 9.63950
PPO Batch Consumption Time: 1.36770
Total Iteration Time: 24.59329

Cumulative Model Updates: 3,666
Cumulative Timesteps: 30,601,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 30601350...
Checkpoint 30601350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.42250
Policy Entropy: 1.41241
Value Function Loss: 0.27716

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.07503
Value Function Update Magnitude: 0.11585

Collected Steps per Second: 3,239.64426
Overall Steps per Second: 1,987.77145

Timestep Collection Time: 15.43410
Timestep Consumption Time: 9.72020
PPO Batch Consumption Time: 1.38222
Total Iteration Time: 25.15430

Cumulative Model Updates: 3,672
Cumulative Timesteps: 30,651,351

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.14349
Policy Entropy: 1.41210
Value Function Loss: 0.26995

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02162
Policy Update Magnitude: 0.06766
Value Function Update Magnitude: 0.11840

Collected Steps per Second: 3,376.25369
Overall Steps per Second: 2,039.54111

Timestep Collection Time: 14.80961
Timestep Consumption Time: 9.70620
PPO Batch Consumption Time: 1.37479
Total Iteration Time: 24.51581

Cumulative Model Updates: 3,678
Cumulative Timesteps: 30,701,352

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 30701352...
Checkpoint 30701352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.30397
Policy Entropy: 1.41243
Value Function Loss: 0.27376

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01841
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.11522

Collected Steps per Second: 3,302.71480
Overall Steps per Second: 2,050.47357

Timestep Collection Time: 15.13997
Timestep Consumption Time: 9.24610
PPO Batch Consumption Time: 1.30270
Total Iteration Time: 24.38607

Cumulative Model Updates: 3,684
Cumulative Timesteps: 30,751,355

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.48250
Policy Entropy: 1.41223
Value Function Loss: 0.27263

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.07180
Value Function Update Magnitude: 0.11227

Collected Steps per Second: 3,319.94703
Overall Steps per Second: 2,055.97415

Timestep Collection Time: 15.06199
Timestep Consumption Time: 9.25982
PPO Batch Consumption Time: 1.30424
Total Iteration Time: 24.32180

Cumulative Model Updates: 3,690
Cumulative Timesteps: 30,801,360

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 30801360...
Checkpoint 30801360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.83853
Policy Entropy: 1.41243
Value Function Loss: 0.27347

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.06759
Value Function Update Magnitude: 0.12003

Collected Steps per Second: 3,326.24177
Overall Steps per Second: 2,056.99371

Timestep Collection Time: 15.03228
Timestep Consumption Time: 9.27552
PPO Batch Consumption Time: 1.30202
Total Iteration Time: 24.30780

Cumulative Model Updates: 3,696
Cumulative Timesteps: 30,851,361

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.49052
Policy Entropy: 1.41231
Value Function Loss: 0.26871

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.11882

Collected Steps per Second: 3,356.36685
Overall Steps per Second: 2,060.30560

Timestep Collection Time: 14.89795
Timestep Consumption Time: 9.37175
PPO Batch Consumption Time: 1.32670
Total Iteration Time: 24.26970

Cumulative Model Updates: 3,702
Cumulative Timesteps: 30,901,364

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 30901364...
Checkpoint 30901364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.23869
Policy Entropy: 1.41248
Value Function Loss: 0.26451

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02050
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.12542

Collected Steps per Second: 3,392.76418
Overall Steps per Second: 2,078.16040

Timestep Collection Time: 14.73725
Timestep Consumption Time: 9.32249
PPO Batch Consumption Time: 1.30811
Total Iteration Time: 24.05974

Cumulative Model Updates: 3,708
Cumulative Timesteps: 30,951,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.16639
Policy Entropy: 1.41277
Value Function Loss: 0.26089

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01561
Policy Update Magnitude: 0.07258
Value Function Update Magnitude: 0.13183

Collected Steps per Second: 3,369.80672
Overall Steps per Second: 2,064.74813

Timestep Collection Time: 14.83854
Timestep Consumption Time: 9.37895
PPO Batch Consumption Time: 1.32033
Total Iteration Time: 24.21748

Cumulative Model Updates: 3,714
Cumulative Timesteps: 31,001,367

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 31001367...
Checkpoint 31001367 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.74671
Policy Entropy: 1.41206
Value Function Loss: 0.25303

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.07474
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 3,341.60791
Overall Steps per Second: 2,061.09359

Timestep Collection Time: 14.96375
Timestep Consumption Time: 9.29667
PPO Batch Consumption Time: 1.30699
Total Iteration Time: 24.26042

Cumulative Model Updates: 3,720
Cumulative Timesteps: 31,051,370

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.98248
Policy Entropy: 1.41302
Value Function Loss: 0.25970

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03197
Policy Update Magnitude: 0.07127
Value Function Update Magnitude: 0.13680

Collected Steps per Second: 3,362.13437
Overall Steps per Second: 2,051.69305

Timestep Collection Time: 14.87270
Timestep Consumption Time: 9.49937
PPO Batch Consumption Time: 1.35535
Total Iteration Time: 24.37207

Cumulative Model Updates: 3,726
Cumulative Timesteps: 31,101,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 31101374...
Checkpoint 31101374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.97383
Policy Entropy: 1.41279
Value Function Loss: 0.26581

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.04288
Policy Update Magnitude: 0.07269
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 3,353.02722
Overall Steps per Second: 2,066.70700

Timestep Collection Time: 14.91249
Timestep Consumption Time: 9.28155
PPO Batch Consumption Time: 1.31396
Total Iteration Time: 24.19404

Cumulative Model Updates: 3,732
Cumulative Timesteps: 31,151,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.11717
Policy Entropy: 1.41278
Value Function Loss: 0.27948

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.08245
Value Function Update Magnitude: 0.11741

Collected Steps per Second: 3,377.16043
Overall Steps per Second: 2,079.83901

Timestep Collection Time: 14.80563
Timestep Consumption Time: 9.23517
PPO Batch Consumption Time: 1.28488
Total Iteration Time: 24.04080

Cumulative Model Updates: 3,738
Cumulative Timesteps: 31,201,377

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 31201377...
Checkpoint 31201377 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.97754
Policy Entropy: 1.41276
Value Function Loss: 0.27758

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.08213
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 3,370.96056
Overall Steps per Second: 2,068.71444

Timestep Collection Time: 14.83257
Timestep Consumption Time: 9.33703
PPO Batch Consumption Time: 1.31931
Total Iteration Time: 24.16960

Cumulative Model Updates: 3,744
Cumulative Timesteps: 31,251,377

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.88605
Policy Entropy: 1.41330
Value Function Loss: 0.28007

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02425
Policy Update Magnitude: 0.07469
Value Function Update Magnitude: 0.11941

Collected Steps per Second: 3,371.68934
Overall Steps per Second: 2,069.26377

Timestep Collection Time: 14.83084
Timestep Consumption Time: 9.33476
PPO Batch Consumption Time: 1.31523
Total Iteration Time: 24.16560

Cumulative Model Updates: 3,750
Cumulative Timesteps: 31,301,382

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 31301382...
Checkpoint 31301382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.45081
Policy Entropy: 1.41374
Value Function Loss: 0.27597

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.07668
Value Function Update Magnitude: 0.13255

Collected Steps per Second: 3,340.20266
Overall Steps per Second: 2,051.16270

Timestep Collection Time: 14.96915
Timestep Consumption Time: 9.40727
PPO Batch Consumption Time: 1.33003
Total Iteration Time: 24.37642

Cumulative Model Updates: 3,756
Cumulative Timesteps: 31,351,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.22338
Policy Entropy: 1.41344
Value Function Loss: 0.27120

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02203
Policy Update Magnitude: 0.07669
Value Function Update Magnitude: 0.13934

Collected Steps per Second: 3,363.65688
Overall Steps per Second: 2,067.30112

Timestep Collection Time: 14.86477
Timestep Consumption Time: 9.32135
PPO Batch Consumption Time: 1.32312
Total Iteration Time: 24.18612

Cumulative Model Updates: 3,762
Cumulative Timesteps: 31,401,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 31401382...
Checkpoint 31401382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.43560
Policy Entropy: 1.41364
Value Function Loss: 0.26624

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.07867
Value Function Update Magnitude: 0.12827

Collected Steps per Second: 3,302.11953
Overall Steps per Second: 2,057.86815

Timestep Collection Time: 15.14300
Timestep Consumption Time: 9.15593
PPO Batch Consumption Time: 1.28884
Total Iteration Time: 24.29893

Cumulative Model Updates: 3,768
Cumulative Timesteps: 31,451,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.90624
Policy Entropy: 1.41311
Value Function Loss: 0.25836

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.08472
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 3,339.18372
Overall Steps per Second: 2,056.24464

Timestep Collection Time: 14.97372
Timestep Consumption Time: 9.34245
PPO Batch Consumption Time: 1.31057
Total Iteration Time: 24.31617

Cumulative Model Updates: 3,774
Cumulative Timesteps: 31,501,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 31501386...
Checkpoint 31501386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.91292
Policy Entropy: 1.41311
Value Function Loss: 0.26334

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.08468
Value Function Update Magnitude: 0.11517

Collected Steps per Second: 3,279.86196
Overall Steps per Second: 2,045.90787

Timestep Collection Time: 15.24485
Timestep Consumption Time: 9.19467
PPO Batch Consumption Time: 1.28692
Total Iteration Time: 24.43952

Cumulative Model Updates: 3,780
Cumulative Timesteps: 31,551,387

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.21231
Policy Entropy: 1.41327
Value Function Loss: 0.26636

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02092
Policy Update Magnitude: 0.07756
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 3,320.38118
Overall Steps per Second: 2,053.18906

Timestep Collection Time: 15.05881
Timestep Consumption Time: 9.29403
PPO Batch Consumption Time: 1.32338
Total Iteration Time: 24.35285

Cumulative Model Updates: 3,786
Cumulative Timesteps: 31,601,388

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 31601388...
Checkpoint 31601388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.08925
Policy Entropy: 1.41325
Value Function Loss: 0.26106

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01662
Policy Update Magnitude: 0.07773
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 3,369.11237
Overall Steps per Second: 2,055.62203

Timestep Collection Time: 14.84130
Timestep Consumption Time: 9.48321
PPO Batch Consumption Time: 1.33240
Total Iteration Time: 24.32451

Cumulative Model Updates: 3,792
Cumulative Timesteps: 31,651,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.98585
Policy Entropy: 1.41323
Value Function Loss: 0.25595

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01593
Policy Update Magnitude: 0.07727
Value Function Update Magnitude: 0.13335

Collected Steps per Second: 3,353.75527
Overall Steps per Second: 2,039.73868

Timestep Collection Time: 14.90956
Timestep Consumption Time: 9.60486
PPO Batch Consumption Time: 1.36420
Total Iteration Time: 24.51441

Cumulative Model Updates: 3,798
Cumulative Timesteps: 31,701,393

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 31701393...
Checkpoint 31701393 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.34451
Policy Entropy: 1.41298
Value Function Loss: 0.25923

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01705
Policy Update Magnitude: 0.07678
Value Function Update Magnitude: 0.14069

Collected Steps per Second: 3,312.31701
Overall Steps per Second: 2,053.66184

Timestep Collection Time: 15.09578
Timestep Consumption Time: 9.25195
PPO Batch Consumption Time: 1.30241
Total Iteration Time: 24.34773

Cumulative Model Updates: 3,804
Cumulative Timesteps: 31,751,395

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.15075
Policy Entropy: 1.41302
Value Function Loss: 0.26883

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02018
Policy Update Magnitude: 0.07192
Value Function Update Magnitude: 0.13429

Collected Steps per Second: 3,321.89265
Overall Steps per Second: 2,026.24695

Timestep Collection Time: 15.05166
Timestep Consumption Time: 9.62450
PPO Batch Consumption Time: 1.37208
Total Iteration Time: 24.67616

Cumulative Model Updates: 3,810
Cumulative Timesteps: 31,801,395

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 31801395...
Checkpoint 31801395 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.00759
Policy Entropy: 1.41285
Value Function Loss: 0.27050

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01596
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.13319

Collected Steps per Second: 3,382.98678
Overall Steps per Second: 2,072.70667

Timestep Collection Time: 14.77984
Timestep Consumption Time: 9.34321
PPO Batch Consumption Time: 1.31854
Total Iteration Time: 24.12305

Cumulative Model Updates: 3,816
Cumulative Timesteps: 31,851,395

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.93409
Policy Entropy: 1.41281
Value Function Loss: 0.26507

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02122
Policy Update Magnitude: 0.07248
Value Function Update Magnitude: 0.14103

Collected Steps per Second: 3,344.82725
Overall Steps per Second: 2,057.68579

Timestep Collection Time: 14.94846
Timestep Consumption Time: 9.35069
PPO Batch Consumption Time: 1.32312
Total Iteration Time: 24.29914

Cumulative Model Updates: 3,822
Cumulative Timesteps: 31,901,395

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 31901395...
Checkpoint 31901395 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.07345
Policy Entropy: 1.41247
Value Function Loss: 0.26614

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02365
Policy Update Magnitude: 0.06861
Value Function Update Magnitude: 0.14313

Collected Steps per Second: 3,358.32470
Overall Steps per Second: 2,071.92175

Timestep Collection Time: 14.88897
Timestep Consumption Time: 9.24418
PPO Batch Consumption Time: 1.30688
Total Iteration Time: 24.13315

Cumulative Model Updates: 3,828
Cumulative Timesteps: 31,951,397

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.95714
Policy Entropy: 1.41236
Value Function Loss: 0.26379

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.13809

Collected Steps per Second: 3,310.93839
Overall Steps per Second: 2,030.09328

Timestep Collection Time: 15.10236
Timestep Consumption Time: 9.52852
PPO Batch Consumption Time: 1.35709
Total Iteration Time: 24.63089

Cumulative Model Updates: 3,834
Cumulative Timesteps: 32,001,400

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 32001400...
Checkpoint 32001400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.15898
Policy Entropy: 1.41213
Value Function Loss: 0.26145

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01813
Policy Update Magnitude: 0.06977
Value Function Update Magnitude: 0.14572

Collected Steps per Second: 3,337.80022
Overall Steps per Second: 2,061.34986

Timestep Collection Time: 14.98023
Timestep Consumption Time: 9.27621
PPO Batch Consumption Time: 1.30058
Total Iteration Time: 24.25644

Cumulative Model Updates: 3,840
Cumulative Timesteps: 32,051,401

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.67436
Policy Entropy: 1.41194
Value Function Loss: 0.26146

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01888
Policy Update Magnitude: 0.07288
Value Function Update Magnitude: 0.13392

Collected Steps per Second: 3,377.61168
Overall Steps per Second: 2,066.08606

Timestep Collection Time: 14.80425
Timestep Consumption Time: 9.39755
PPO Batch Consumption Time: 1.32727
Total Iteration Time: 24.20180

Cumulative Model Updates: 3,846
Cumulative Timesteps: 32,101,404

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 32101404...
Checkpoint 32101404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.76783
Policy Entropy: 1.41216
Value Function Loss: 0.27305

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02036
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.13073

Collected Steps per Second: 3,343.97748
Overall Steps per Second: 2,058.84897

Timestep Collection Time: 14.95225
Timestep Consumption Time: 9.33316
PPO Batch Consumption Time: 1.32563
Total Iteration Time: 24.28541

Cumulative Model Updates: 3,852
Cumulative Timesteps: 32,151,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.59120
Policy Entropy: 1.41179
Value Function Loss: 0.27772

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01619
Policy Update Magnitude: 0.07156
Value Function Update Magnitude: 0.13178

Collected Steps per Second: 3,326.88458
Overall Steps per Second: 2,062.08052

Timestep Collection Time: 15.02998
Timestep Consumption Time: 9.21883
PPO Batch Consumption Time: 1.30537
Total Iteration Time: 24.24881

Cumulative Model Updates: 3,858
Cumulative Timesteps: 32,201,407

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 32201407...
Checkpoint 32201407 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.28736
Policy Entropy: 1.41106
Value Function Loss: 0.27388

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01617
Policy Update Magnitude: 0.07428
Value Function Update Magnitude: 0.12582

Collected Steps per Second: 3,345.05596
Overall Steps per Second: 2,068.17864

Timestep Collection Time: 14.94773
Timestep Consumption Time: 9.22861
PPO Batch Consumption Time: 1.29123
Total Iteration Time: 24.17634

Cumulative Model Updates: 3,864
Cumulative Timesteps: 32,251,408

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.08184
Policy Entropy: 1.41107
Value Function Loss: 0.26589

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01945
Policy Update Magnitude: 0.07430
Value Function Update Magnitude: 0.12310

Collected Steps per Second: 3,358.94382
Overall Steps per Second: 2,048.19715

Timestep Collection Time: 14.88712
Timestep Consumption Time: 9.52703
PPO Batch Consumption Time: 1.33961
Total Iteration Time: 24.41415

Cumulative Model Updates: 3,870
Cumulative Timesteps: 32,301,413

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 32301413...
Checkpoint 32301413 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.60139
Policy Entropy: 1.41153
Value Function Loss: 0.27521

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01973
Policy Update Magnitude: 0.07569
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 3,359.99419
Overall Steps per Second: 2,066.16313

Timestep Collection Time: 14.88247
Timestep Consumption Time: 9.31940
PPO Batch Consumption Time: 1.32329
Total Iteration Time: 24.20186

Cumulative Model Updates: 3,876
Cumulative Timesteps: 32,351,418

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.23512
Policy Entropy: 1.41170
Value Function Loss: 0.27965

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.07864
Value Function Update Magnitude: 0.12372

Collected Steps per Second: 3,348.13463
Overall Steps per Second: 2,059.96431

Timestep Collection Time: 14.93369
Timestep Consumption Time: 9.33858
PPO Batch Consumption Time: 1.31707
Total Iteration Time: 24.27227

Cumulative Model Updates: 3,882
Cumulative Timesteps: 32,401,418

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 32401418...
Checkpoint 32401418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.14875
Policy Entropy: 1.41088
Value Function Loss: 0.27417

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.07243
Value Function Update Magnitude: 0.13296

Collected Steps per Second: 3,347.99019
Overall Steps per Second: 2,052.81580

Timestep Collection Time: 14.93583
Timestep Consumption Time: 9.42340
PPO Batch Consumption Time: 1.34160
Total Iteration Time: 24.35922

Cumulative Model Updates: 3,888
Cumulative Timesteps: 32,451,423

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.28329
Policy Entropy: 1.41079
Value Function Loss: 0.26070

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.12724

Collected Steps per Second: 3,339.07322
Overall Steps per Second: 2,061.10483

Timestep Collection Time: 14.97421
Timestep Consumption Time: 9.28462
PPO Batch Consumption Time: 1.29756
Total Iteration Time: 24.25883

Cumulative Model Updates: 3,894
Cumulative Timesteps: 32,501,423

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 32501423...
Checkpoint 32501423 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.51168
Policy Entropy: 1.41138
Value Function Loss: 0.25533

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.07153
Value Function Update Magnitude: 0.13466

Collected Steps per Second: 3,380.71552
Overall Steps per Second: 2,071.75502

Timestep Collection Time: 14.79066
Timestep Consumption Time: 9.34492
PPO Batch Consumption Time: 1.31217
Total Iteration Time: 24.13558

Cumulative Model Updates: 3,900
Cumulative Timesteps: 32,551,426

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.44181
Policy Entropy: 1.41180
Value Function Loss: 0.25805

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.01921
Policy Update Magnitude: 0.07428
Value Function Update Magnitude: 0.13629

Collected Steps per Second: 3,332.02474
Overall Steps per Second: 2,029.36570

Timestep Collection Time: 15.00649
Timestep Consumption Time: 9.63273
PPO Batch Consumption Time: 1.35882
Total Iteration Time: 24.63923

Cumulative Model Updates: 3,906
Cumulative Timesteps: 32,601,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 32601428...
Checkpoint 32601428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.37968
Policy Entropy: 1.41177
Value Function Loss: 0.25379

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01717
Policy Update Magnitude: 0.07360
Value Function Update Magnitude: 0.12735

Collected Steps per Second: 3,372.19145
Overall Steps per Second: 2,064.06587

Timestep Collection Time: 14.82834
Timestep Consumption Time: 9.39763
PPO Batch Consumption Time: 1.33450
Total Iteration Time: 24.22597

Cumulative Model Updates: 3,912
Cumulative Timesteps: 32,651,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.30539
Policy Entropy: 1.41156
Value Function Loss: 0.25640

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.01866
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.11731

Collected Steps per Second: 3,351.70708
Overall Steps per Second: 2,077.64805

Timestep Collection Time: 14.91896
Timestep Consumption Time: 9.14863
PPO Batch Consumption Time: 1.28176
Total Iteration Time: 24.06760

Cumulative Model Updates: 3,918
Cumulative Timesteps: 32,701,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 32701436...
Checkpoint 32701436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.03359
Policy Entropy: 1.41075
Value Function Loss: 0.25687

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01608
Policy Update Magnitude: 0.07354
Value Function Update Magnitude: 0.11990

Collected Steps per Second: 3,349.19611
Overall Steps per Second: 2,062.10454

Timestep Collection Time: 14.92896
Timestep Consumption Time: 9.31812
PPO Batch Consumption Time: 1.31177
Total Iteration Time: 24.24707

Cumulative Model Updates: 3,924
Cumulative Timesteps: 32,751,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.73268
Policy Entropy: 1.41049
Value Function Loss: 0.26758

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01836
Policy Update Magnitude: 0.07461
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 3,371.05452
Overall Steps per Second: 2,070.02249

Timestep Collection Time: 14.83304
Timestep Consumption Time: 9.32273
PPO Batch Consumption Time: 1.30715
Total Iteration Time: 24.15578

Cumulative Model Updates: 3,930
Cumulative Timesteps: 32,801,439

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 32801439...
Checkpoint 32801439 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.58228
Policy Entropy: 1.41040
Value Function Loss: 0.27135

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01922
Policy Update Magnitude: 0.07684
Value Function Update Magnitude: 0.11967

Collected Steps per Second: 3,368.44527
Overall Steps per Second: 2,061.74779

Timestep Collection Time: 14.84453
Timestep Consumption Time: 9.40819
PPO Batch Consumption Time: 1.34098
Total Iteration Time: 24.25272

Cumulative Model Updates: 3,936
Cumulative Timesteps: 32,851,442

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.62495
Policy Entropy: 1.41074
Value Function Loss: 0.26295

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02112
Policy Update Magnitude: 0.07942
Value Function Update Magnitude: 0.13447

Collected Steps per Second: 3,376.85968
Overall Steps per Second: 2,041.28386

Timestep Collection Time: 14.80754
Timestep Consumption Time: 9.68831
PPO Batch Consumption Time: 1.37650
Total Iteration Time: 24.49586

Cumulative Model Updates: 3,942
Cumulative Timesteps: 32,901,445

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 32901445...
Checkpoint 32901445 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.00721
Policy Entropy: 1.41144
Value Function Loss: 0.25630

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.08132
Value Function Update Magnitude: 0.13426

Collected Steps per Second: 3,316.16809
Overall Steps per Second: 2,065.45834

Timestep Collection Time: 15.07855
Timestep Consumption Time: 9.13061
PPO Batch Consumption Time: 1.28290
Total Iteration Time: 24.20915

Cumulative Model Updates: 3,948
Cumulative Timesteps: 32,951,448

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.07202
Policy Entropy: 1.41118
Value Function Loss: 0.24915

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 0.09863
Value Function Update Magnitude: 0.13128

Collected Steps per Second: 3,348.98147
Overall Steps per Second: 2,057.51323

Timestep Collection Time: 14.92991
Timestep Consumption Time: 9.37127
PPO Batch Consumption Time: 1.31815
Total Iteration Time: 24.30118

Cumulative Model Updates: 3,954
Cumulative Timesteps: 33,001,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 33001448...
Checkpoint 33001448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.20124
Policy Entropy: 1.41134
Value Function Loss: 0.25382

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.09002
Value Function Update Magnitude: 0.12951

Collected Steps per Second: 3,389.70998
Overall Steps per Second: 2,082.47264

Timestep Collection Time: 14.75141
Timestep Consumption Time: 9.25995
PPO Batch Consumption Time: 1.30888
Total Iteration Time: 24.01136

Cumulative Model Updates: 3,960
Cumulative Timesteps: 33,051,451

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.24605
Policy Entropy: 1.41097
Value Function Loss: 0.25591

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.08757
Value Function Update Magnitude: 0.12465

Collected Steps per Second: 3,383.55440
Overall Steps per Second: 2,062.61884

Timestep Collection Time: 14.77766
Timestep Consumption Time: 9.46386
PPO Batch Consumption Time: 1.34253
Total Iteration Time: 24.24151

Cumulative Model Updates: 3,966
Cumulative Timesteps: 33,101,452

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 33101452...
Checkpoint 33101452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.23578
Policy Entropy: 1.41122
Value Function Loss: 0.26190

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01857
Policy Update Magnitude: 0.08796
Value Function Update Magnitude: 0.11993

Collected Steps per Second: 3,386.93072
Overall Steps per Second: 2,079.24419

Timestep Collection Time: 14.76381
Timestep Consumption Time: 9.28531
PPO Batch Consumption Time: 1.31552
Total Iteration Time: 24.04912

Cumulative Model Updates: 3,972
Cumulative Timesteps: 33,151,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.94256
Policy Entropy: 1.41114
Value Function Loss: 0.25776

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01947
Policy Update Magnitude: 0.11390
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 3,353.05228
Overall Steps per Second: 2,056.98643

Timestep Collection Time: 14.91179
Timestep Consumption Time: 9.39562
PPO Batch Consumption Time: 1.33011
Total Iteration Time: 24.30740

Cumulative Model Updates: 3,978
Cumulative Timesteps: 33,201,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 33201456...
Checkpoint 33201456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.47730
Policy Entropy: 1.41153
Value Function Loss: 0.26434

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01689
Policy Update Magnitude: 0.10051
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 3,307.31546
Overall Steps per Second: 2,056.35658

Timestep Collection Time: 15.11921
Timestep Consumption Time: 9.19758
PPO Batch Consumption Time: 1.27611
Total Iteration Time: 24.31679

Cumulative Model Updates: 3,984
Cumulative Timesteps: 33,251,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.30757
Policy Entropy: 1.41150
Value Function Loss: 0.25826

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01668
Policy Update Magnitude: 0.09339
Value Function Update Magnitude: 0.12127

Collected Steps per Second: 3,364.28339
Overall Steps per Second: 2,038.78722

Timestep Collection Time: 14.86260
Timestep Consumption Time: 9.66276
PPO Batch Consumption Time: 1.37799
Total Iteration Time: 24.52536

Cumulative Model Updates: 3,990
Cumulative Timesteps: 33,301,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 33301462...
Checkpoint 33301462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.37439
Policy Entropy: 1.41201
Value Function Loss: 0.25847

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01539
Policy Update Magnitude: 0.08708
Value Function Update Magnitude: 0.12768

Collected Steps per Second: 3,391.28156
Overall Steps per Second: 2,079.55326

Timestep Collection Time: 14.74398
Timestep Consumption Time: 9.30012
PPO Batch Consumption Time: 1.30469
Total Iteration Time: 24.04411

Cumulative Model Updates: 3,996
Cumulative Timesteps: 33,351,463

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.63494
Policy Entropy: 1.41147
Value Function Loss: 0.25261

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.08472
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 3,358.52982
Overall Steps per Second: 2,069.80674

Timestep Collection Time: 14.88776
Timestep Consumption Time: 9.26956
PPO Batch Consumption Time: 1.31984
Total Iteration Time: 24.15733

Cumulative Model Updates: 4,002
Cumulative Timesteps: 33,401,464

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 33401464...
Checkpoint 33401464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.62012
Policy Entropy: 1.41139
Value Function Loss: 0.26158

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.08158
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 3,329.01327
Overall Steps per Second: 2,062.37520

Timestep Collection Time: 15.01977
Timestep Consumption Time: 9.22461
PPO Batch Consumption Time: 1.31046
Total Iteration Time: 24.24438

Cumulative Model Updates: 4,008
Cumulative Timesteps: 33,451,465

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.63200
Policy Entropy: 1.41122
Value Function Loss: 0.26520

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02149
Policy Update Magnitude: 0.07355
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 3,328.41345
Overall Steps per Second: 2,039.70797

Timestep Collection Time: 15.02217
Timestep Consumption Time: 9.49114
PPO Batch Consumption Time: 1.33322
Total Iteration Time: 24.51331

Cumulative Model Updates: 4,014
Cumulative Timesteps: 33,501,465

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 33501465...
Checkpoint 33501465 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.79234
Policy Entropy: 1.41144
Value Function Loss: 0.25481

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02339
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 3,345.98992
Overall Steps per Second: 2,058.68218

Timestep Collection Time: 14.94326
Timestep Consumption Time: 9.34412
PPO Batch Consumption Time: 1.30991
Total Iteration Time: 24.28738

Cumulative Model Updates: 4,020
Cumulative Timesteps: 33,551,465

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.18276
Policy Entropy: 1.41154
Value Function Loss: 0.25008

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.07086
Value Function Update Magnitude: 0.12803

Collected Steps per Second: 3,363.21329
Overall Steps per Second: 2,059.66630

Timestep Collection Time: 14.86763
Timestep Consumption Time: 9.40961
PPO Batch Consumption Time: 1.33274
Total Iteration Time: 24.27723

Cumulative Model Updates: 4,026
Cumulative Timesteps: 33,601,468

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 33601468...
Checkpoint 33601468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.05942
Policy Entropy: 1.41148
Value Function Loss: 0.24835

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.07472
Value Function Update Magnitude: 0.12658

Collected Steps per Second: 3,373.57871
Overall Steps per Second: 2,073.79144

Timestep Collection Time: 14.82106
Timestep Consumption Time: 9.28937
PPO Batch Consumption Time: 1.31158
Total Iteration Time: 24.11043

Cumulative Model Updates: 4,032
Cumulative Timesteps: 33,651,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.81285
Policy Entropy: 1.41180
Value Function Loss: 0.25467

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01596
Policy Update Magnitude: 0.07441
Value Function Update Magnitude: 0.12013

Collected Steps per Second: 3,339.24687
Overall Steps per Second: 2,068.95991

Timestep Collection Time: 14.97374
Timestep Consumption Time: 9.19348
PPO Batch Consumption Time: 1.30043
Total Iteration Time: 24.16722

Cumulative Model Updates: 4,038
Cumulative Timesteps: 33,701,469

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 33701469...
Checkpoint 33701469 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.89889
Policy Entropy: 1.41189
Value Function Loss: 0.25088

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.07400
Value Function Update Magnitude: 0.11617

Collected Steps per Second: 3,314.59032
Overall Steps per Second: 2,068.72513

Timestep Collection Time: 15.08512
Timestep Consumption Time: 9.08484
PPO Batch Consumption Time: 1.27307
Total Iteration Time: 24.16996

Cumulative Model Updates: 4,044
Cumulative Timesteps: 33,751,470

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.41213
Policy Entropy: 1.41304
Value Function Loss: 0.24874

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02621
Policy Update Magnitude: 0.07339
Value Function Update Magnitude: 0.11992

Collected Steps per Second: 3,344.20281
Overall Steps per Second: 2,046.63678

Timestep Collection Time: 14.95184
Timestep Consumption Time: 9.47946
PPO Batch Consumption Time: 1.33979
Total Iteration Time: 24.43130

Cumulative Model Updates: 4,050
Cumulative Timesteps: 33,801,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 33801472...
Checkpoint 33801472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.83772
Policy Entropy: 1.41247
Value Function Loss: 0.25471

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03376
Policy Update Magnitude: 0.07233
Value Function Update Magnitude: 0.11846

Collected Steps per Second: 3,362.48903
Overall Steps per Second: 2,059.05864

Timestep Collection Time: 14.87142
Timestep Consumption Time: 9.41395
PPO Batch Consumption Time: 1.31929
Total Iteration Time: 24.28537

Cumulative Model Updates: 4,056
Cumulative Timesteps: 33,851,477

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.79621
Policy Entropy: 1.41286
Value Function Loss: 0.25825

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.07484
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 3,362.92333
Overall Steps per Second: 2,068.53293

Timestep Collection Time: 14.86891
Timestep Consumption Time: 9.30426
PPO Batch Consumption Time: 1.31204
Total Iteration Time: 24.17317

Cumulative Model Updates: 4,062
Cumulative Timesteps: 33,901,480

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 33901480...
Checkpoint 33901480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.48611
Policy Entropy: 1.41213
Value Function Loss: 0.26676

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.07425
Value Function Update Magnitude: 0.12466

Collected Steps per Second: 3,347.50103
Overall Steps per Second: 2,070.45281

Timestep Collection Time: 14.93652
Timestep Consumption Time: 9.21279
PPO Batch Consumption Time: 1.28922
Total Iteration Time: 24.14931

Cumulative Model Updates: 4,068
Cumulative Timesteps: 33,951,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.26353
Policy Entropy: 1.41170
Value Function Loss: 0.25999

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.07311
Value Function Update Magnitude: 0.12317

Collected Steps per Second: 3,329.22939
Overall Steps per Second: 2,058.39802

Timestep Collection Time: 15.01879
Timestep Consumption Time: 9.27243
PPO Batch Consumption Time: 1.29698
Total Iteration Time: 24.29122

Cumulative Model Updates: 4,074
Cumulative Timesteps: 34,001,481

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 34001481...
Checkpoint 34001481 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.73019
Policy Entropy: 1.41126
Value Function Loss: 0.25779

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 0.07092
Value Function Update Magnitude: 0.12087

Collected Steps per Second: 3,361.49445
Overall Steps per Second: 2,076.73367

Timestep Collection Time: 14.87493
Timestep Consumption Time: 9.20230
PPO Batch Consumption Time: 1.29709
Total Iteration Time: 24.07723

Cumulative Model Updates: 4,080
Cumulative Timesteps: 34,051,483

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.92965
Policy Entropy: 1.41112
Value Function Loss: 0.24942

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.06917
Value Function Update Magnitude: 0.11842

Collected Steps per Second: 3,373.32187
Overall Steps per Second: 2,050.04809

Timestep Collection Time: 14.82248
Timestep Consumption Time: 9.56768
PPO Batch Consumption Time: 1.35613
Total Iteration Time: 24.39016

Cumulative Model Updates: 4,086
Cumulative Timesteps: 34,101,484

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 34101484...
Checkpoint 34101484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.95854
Policy Entropy: 1.41078
Value Function Loss: 0.25622

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.06940
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 3,359.25197
Overall Steps per Second: 2,070.37567

Timestep Collection Time: 14.88486
Timestep Consumption Time: 9.26631
PPO Batch Consumption Time: 1.29964
Total Iteration Time: 24.15117

Cumulative Model Updates: 4,092
Cumulative Timesteps: 34,151,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.80373
Policy Entropy: 1.41099
Value Function Loss: 0.25994

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03334
Policy Update Magnitude: 0.07133
Value Function Update Magnitude: 0.13465

Collected Steps per Second: 3,341.91441
Overall Steps per Second: 2,003.53015

Timestep Collection Time: 14.96148
Timestep Consumption Time: 9.99447
PPO Batch Consumption Time: 1.41803
Total Iteration Time: 24.95595

Cumulative Model Updates: 4,098
Cumulative Timesteps: 34,201,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 34201486...
Checkpoint 34201486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.95152
Policy Entropy: 1.41111
Value Function Loss: 0.25966

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.04025
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 3,340.25026
Overall Steps per Second: 2,070.41974

Timestep Collection Time: 14.97014
Timestep Consumption Time: 9.18149
PPO Batch Consumption Time: 1.29107
Total Iteration Time: 24.15162

Cumulative Model Updates: 4,104
Cumulative Timesteps: 34,251,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.90123
Policy Entropy: 1.41164
Value Function Loss: 0.25843

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.06899
Value Function Update Magnitude: 0.13251

Collected Steps per Second: 3,348.20464
Overall Steps per Second: 2,069.45570

Timestep Collection Time: 14.93397
Timestep Consumption Time: 9.22794
PPO Batch Consumption Time: 1.28870
Total Iteration Time: 24.16191

Cumulative Model Updates: 4,110
Cumulative Timesteps: 34,301,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 34301492...
Checkpoint 34301492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.32070
Policy Entropy: 1.41128
Value Function Loss: 0.25573

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02131
Policy Update Magnitude: 0.07518
Value Function Update Magnitude: 0.12779

Collected Steps per Second: 3,371.84066
Overall Steps per Second: 2,065.29251

Timestep Collection Time: 14.82929
Timestep Consumption Time: 9.38132
PPO Batch Consumption Time: 1.32127
Total Iteration Time: 24.21061

Cumulative Model Updates: 4,116
Cumulative Timesteps: 34,351,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.81733
Policy Entropy: 1.41125
Value Function Loss: 0.25729

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.07344
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 3,395.89222
Overall Steps per Second: 2,070.28464

Timestep Collection Time: 14.72455
Timestep Consumption Time: 9.42816
PPO Batch Consumption Time: 1.34074
Total Iteration Time: 24.15272

Cumulative Model Updates: 4,122
Cumulative Timesteps: 34,401,497

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 34401497...
Checkpoint 34401497 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.13120
Policy Entropy: 1.41101
Value Function Loss: 0.25136

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03140
Policy Update Magnitude: 0.07064
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 3,337.94510
Overall Steps per Second: 2,057.49773

Timestep Collection Time: 14.97958
Timestep Consumption Time: 9.32227
PPO Batch Consumption Time: 1.30361
Total Iteration Time: 24.30185

Cumulative Model Updates: 4,128
Cumulative Timesteps: 34,451,498

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.37644
Policy Entropy: 1.41109
Value Function Loss: 0.24372

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.12627

Collected Steps per Second: 3,367.17145
Overall Steps per Second: 2,069.34228

Timestep Collection Time: 14.84985
Timestep Consumption Time: 9.31338
PPO Batch Consumption Time: 1.30255
Total Iteration Time: 24.16323

Cumulative Model Updates: 4,134
Cumulative Timesteps: 34,501,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 34501500...
Checkpoint 34501500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.34438
Policy Entropy: 1.41114
Value Function Loss: 0.23832

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01872
Policy Update Magnitude: 0.06847
Value Function Update Magnitude: 0.12624

Collected Steps per Second: 3,364.52871
Overall Steps per Second: 2,071.22276

Timestep Collection Time: 14.86092
Timestep Consumption Time: 9.27941
PPO Batch Consumption Time: 1.31043
Total Iteration Time: 24.14033

Cumulative Model Updates: 4,140
Cumulative Timesteps: 34,551,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.78469
Policy Entropy: 1.41107
Value Function Loss: 0.24376

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01912
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.12577

Collected Steps per Second: 3,368.47767
Overall Steps per Second: 2,069.27778

Timestep Collection Time: 14.84469
Timestep Consumption Time: 9.32026
PPO Batch Consumption Time: 1.31696
Total Iteration Time: 24.16495

Cumulative Model Updates: 4,146
Cumulative Timesteps: 34,601,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 34601504...
Checkpoint 34601504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.08316
Policy Entropy: 1.41082
Value Function Loss: 0.25869

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02136
Policy Update Magnitude: 0.06846
Value Function Update Magnitude: 0.12527

Collected Steps per Second: 3,372.71905
Overall Steps per Second: 2,075.93139

Timestep Collection Time: 14.82543
Timestep Consumption Time: 9.26111
PPO Batch Consumption Time: 1.30583
Total Iteration Time: 24.08654

Cumulative Model Updates: 4,152
Cumulative Timesteps: 34,651,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.66749
Policy Entropy: 1.41143
Value Function Loss: 0.26059

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01640
Policy Update Magnitude: 0.06891
Value Function Update Magnitude: 0.12673

Collected Steps per Second: 3,387.97447
Overall Steps per Second: 2,067.57949

Timestep Collection Time: 14.75897
Timestep Consumption Time: 9.42535
PPO Batch Consumption Time: 1.33776
Total Iteration Time: 24.18432

Cumulative Model Updates: 4,158
Cumulative Timesteps: 34,701,509

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 34701509...
Checkpoint 34701509 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.09100
Policy Entropy: 1.41085
Value Function Loss: 0.25763

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01886
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.13075

Collected Steps per Second: 3,339.37020
Overall Steps per Second: 2,063.89283

Timestep Collection Time: 14.97438
Timestep Consumption Time: 9.25411
PPO Batch Consumption Time: 1.29694
Total Iteration Time: 24.22849

Cumulative Model Updates: 4,164
Cumulative Timesteps: 34,751,514

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.13999
Policy Entropy: 1.41079
Value Function Loss: 0.24878

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02004
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.12920

Collected Steps per Second: 3,350.10965
Overall Steps per Second: 2,074.21321

Timestep Collection Time: 14.92608
Timestep Consumption Time: 9.18138
PPO Batch Consumption Time: 1.29505
Total Iteration Time: 24.10745

Cumulative Model Updates: 4,170
Cumulative Timesteps: 34,801,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 34801518...
Checkpoint 34801518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.74873
Policy Entropy: 1.41035
Value Function Loss: 0.25002

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.06635
Value Function Update Magnitude: 0.12654

Collected Steps per Second: 3,362.86513
Overall Steps per Second: 2,058.63511

Timestep Collection Time: 14.86857
Timestep Consumption Time: 9.41985
PPO Batch Consumption Time: 1.34196
Total Iteration Time: 24.28842

Cumulative Model Updates: 4,176
Cumulative Timesteps: 34,851,519

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.38773
Policy Entropy: 1.41072
Value Function Loss: 0.24854

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.13859

Collected Steps per Second: 3,376.28906
Overall Steps per Second: 2,061.54196

Timestep Collection Time: 14.81005
Timestep Consumption Time: 9.44510
PPO Batch Consumption Time: 1.34036
Total Iteration Time: 24.25515

Cumulative Model Updates: 4,182
Cumulative Timesteps: 34,901,522

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 34901522...
Checkpoint 34901522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.79431
Policy Entropy: 1.41093
Value Function Loss: 0.24623

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.12332

Collected Steps per Second: 3,328.01771
Overall Steps per Second: 2,064.75748

Timestep Collection Time: 15.02546
Timestep Consumption Time: 9.19288
PPO Batch Consumption Time: 1.30166
Total Iteration Time: 24.21834

Cumulative Model Updates: 4,188
Cumulative Timesteps: 34,951,527

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.12786
Policy Entropy: 1.41051
Value Function Loss: 0.25543

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.11442

Collected Steps per Second: 3,312.67623
Overall Steps per Second: 2,058.64278

Timestep Collection Time: 15.09474
Timestep Consumption Time: 9.19505
PPO Batch Consumption Time: 1.28976
Total Iteration Time: 24.28979

Cumulative Model Updates: 4,194
Cumulative Timesteps: 35,001,531

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35001531...
Checkpoint 35001531 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.63125
Policy Entropy: 1.41048
Value Function Loss: 0.25910

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.06809
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 3,349.82556
Overall Steps per Second: 2,068.71300

Timestep Collection Time: 14.92675
Timestep Consumption Time: 9.24384
PPO Batch Consumption Time: 1.30706
Total Iteration Time: 24.17058

Cumulative Model Updates: 4,200
Cumulative Timesteps: 35,051,533

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.76278
Policy Entropy: 1.40996
Value Function Loss: 0.26819

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 0.06957
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 3,155.35111
Overall Steps per Second: 1,963.22491

Timestep Collection Time: 15.84641
Timestep Consumption Time: 9.62239
PPO Batch Consumption Time: 1.37823
Total Iteration Time: 25.46881

Cumulative Model Updates: 4,206
Cumulative Timesteps: 35,101,534

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 35101534...
Checkpoint 35101534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.51191
Policy Entropy: 1.41018
Value Function Loss: 0.26003

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.07114
Value Function Update Magnitude: 0.12048

Collected Steps per Second: 3,365.08220
Overall Steps per Second: 2,070.01397

Timestep Collection Time: 14.85878
Timestep Consumption Time: 9.29613
PPO Batch Consumption Time: 1.30389
Total Iteration Time: 24.15491

Cumulative Model Updates: 4,212
Cumulative Timesteps: 35,151,535

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.72489
Policy Entropy: 1.40955
Value Function Loss: 0.26385

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.07035
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 3,354.12283
Overall Steps per Second: 2,066.11212

Timestep Collection Time: 14.90822
Timestep Consumption Time: 9.29376
PPO Batch Consumption Time: 1.31543
Total Iteration Time: 24.20198

Cumulative Model Updates: 4,218
Cumulative Timesteps: 35,201,539

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35201539...
Checkpoint 35201539 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.83450
Policy Entropy: 1.40992
Value Function Loss: 0.25654

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.06919
Value Function Update Magnitude: 0.14336

Collected Steps per Second: 3,351.00536
Overall Steps per Second: 2,072.75099

Timestep Collection Time: 14.92179
Timestep Consumption Time: 9.20219
PPO Batch Consumption Time: 1.30467
Total Iteration Time: 24.12398

Cumulative Model Updates: 4,224
Cumulative Timesteps: 35,251,542

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.18651
Policy Entropy: 1.40996
Value Function Loss: 0.26304

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01461
Policy Update Magnitude: 0.07437
Value Function Update Magnitude: 0.14516

Collected Steps per Second: 3,363.08340
Overall Steps per Second: 2,039.64211

Timestep Collection Time: 14.86761
Timestep Consumption Time: 9.64699
PPO Batch Consumption Time: 1.36043
Total Iteration Time: 24.51459

Cumulative Model Updates: 4,230
Cumulative Timesteps: 35,301,543

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 35301543...
Checkpoint 35301543 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.42605
Policy Entropy: 1.41065
Value Function Loss: 0.25451

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01452
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 3,369.17155
Overall Steps per Second: 2,055.01802

Timestep Collection Time: 14.84104
Timestep Consumption Time: 9.49062
PPO Batch Consumption Time: 1.33381
Total Iteration Time: 24.33166

Cumulative Model Updates: 4,236
Cumulative Timesteps: 35,351,545

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.72248
Policy Entropy: 1.41073
Value Function Loss: 0.25362

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.07308
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 3,379.11930
Overall Steps per Second: 2,063.63464

Timestep Collection Time: 14.79675
Timestep Consumption Time: 9.43234
PPO Batch Consumption Time: 1.33207
Total Iteration Time: 24.22910

Cumulative Model Updates: 4,242
Cumulative Timesteps: 35,401,545

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 35401545...
Checkpoint 35401545 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.67680
Policy Entropy: 1.41029
Value Function Loss: 0.24962

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 3,321.34348
Overall Steps per Second: 2,051.13939

Timestep Collection Time: 15.05475
Timestep Consumption Time: 9.32292
PPO Batch Consumption Time: 1.31700
Total Iteration Time: 24.37767

Cumulative Model Updates: 4,248
Cumulative Timesteps: 35,451,547

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.22763
Policy Entropy: 1.40995
Value Function Loss: 0.24912

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 3,359.40473
Overall Steps per Second: 2,066.69808

Timestep Collection Time: 14.88389
Timestep Consumption Time: 9.30978
PPO Batch Consumption Time: 1.32100
Total Iteration Time: 24.19366

Cumulative Model Updates: 4,254
Cumulative Timesteps: 35,501,548

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 35501548...
Checkpoint 35501548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.83624
Policy Entropy: 1.41085
Value Function Loss: 0.25506

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02409
Policy Update Magnitude: 0.06957
Value Function Update Magnitude: 0.11934

Collected Steps per Second: 3,356.59930
Overall Steps per Second: 2,066.60237

Timestep Collection Time: 14.89692
Timestep Consumption Time: 9.29883
PPO Batch Consumption Time: 1.31371
Total Iteration Time: 24.19575

Cumulative Model Updates: 4,260
Cumulative Timesteps: 35,551,551

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.71693
Policy Entropy: 1.41096
Value Function Loss: 0.24995

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.12090

Collected Steps per Second: 3,374.76484
Overall Steps per Second: 2,068.86993

Timestep Collection Time: 14.81674
Timestep Consumption Time: 9.35250
PPO Batch Consumption Time: 1.32676
Total Iteration Time: 24.16923

Cumulative Model Updates: 4,266
Cumulative Timesteps: 35,601,554

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 35601554...
Checkpoint 35601554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.49560
Policy Entropy: 1.41040
Value Function Loss: 0.25569

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.06982
Value Function Update Magnitude: 0.12078

Collected Steps per Second: 3,387.53775
Overall Steps per Second: 2,084.58728

Timestep Collection Time: 14.76057
Timestep Consumption Time: 9.22595
PPO Batch Consumption Time: 1.29581
Total Iteration Time: 23.98652

Cumulative Model Updates: 4,272
Cumulative Timesteps: 35,651,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.24940
Policy Entropy: 1.41012
Value Function Loss: 0.25060

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 3,322.99488
Overall Steps per Second: 2,051.43296

Timestep Collection Time: 15.04667
Timestep Consumption Time: 9.32654
PPO Batch Consumption Time: 1.32271
Total Iteration Time: 24.37321

Cumulative Model Updates: 4,278
Cumulative Timesteps: 35,701,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 35701556...
Checkpoint 35701556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.85877
Policy Entropy: 1.41066
Value Function Loss: 0.25201

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.11956

Collected Steps per Second: 3,339.12474
Overall Steps per Second: 2,063.26883

Timestep Collection Time: 14.97488
Timestep Consumption Time: 9.25996
PPO Batch Consumption Time: 1.29514
Total Iteration Time: 24.23484

Cumulative Model Updates: 4,284
Cumulative Timesteps: 35,751,559

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.99950
Policy Entropy: 1.41037
Value Function Loss: 0.24499

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.13152

Collected Steps per Second: 3,381.98605
Overall Steps per Second: 2,069.94163

Timestep Collection Time: 14.78540
Timestep Consumption Time: 9.37181
PPO Batch Consumption Time: 1.30904
Total Iteration Time: 24.15720

Cumulative Model Updates: 4,290
Cumulative Timesteps: 35,801,563

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35801563...
Checkpoint 35801563 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.33779
Policy Entropy: 1.40950
Value Function Loss: 0.24429

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.06822
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 3,377.65651
Overall Steps per Second: 2,065.21672

Timestep Collection Time: 14.80346
Timestep Consumption Time: 9.40756
PPO Batch Consumption Time: 1.32017
Total Iteration Time: 24.21102

Cumulative Model Updates: 4,296
Cumulative Timesteps: 35,851,564

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.21027
Policy Entropy: 1.40972
Value Function Loss: 0.24330

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02742
Policy Update Magnitude: 0.06650
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 3,350.69403
Overall Steps per Second: 2,048.00640

Timestep Collection Time: 14.92348
Timestep Consumption Time: 9.49246
PPO Batch Consumption Time: 1.34256
Total Iteration Time: 24.41594

Cumulative Model Updates: 4,302
Cumulative Timesteps: 35,901,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35901568...
Checkpoint 35901568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.57944
Policy Entropy: 1.41006
Value Function Loss: 0.24995

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01713
Policy Update Magnitude: 0.06904
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 3,326.49993
Overall Steps per Second: 2,056.20520

Timestep Collection Time: 15.03111
Timestep Consumption Time: 9.28601
PPO Batch Consumption Time: 1.31613
Total Iteration Time: 24.31713

Cumulative Model Updates: 4,308
Cumulative Timesteps: 35,951,569

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.18358
Policy Entropy: 1.41074
Value Function Loss: 0.24682

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.07012
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 3,353.25591
Overall Steps per Second: 2,068.55750

Timestep Collection Time: 14.91207
Timestep Consumption Time: 9.26129
PPO Batch Consumption Time: 1.31566
Total Iteration Time: 24.17337

Cumulative Model Updates: 4,314
Cumulative Timesteps: 36,001,573

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 36001573...
Checkpoint 36001573 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.48775
Policy Entropy: 1.41055
Value Function Loss: 0.25735

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.11248

Collected Steps per Second: 3,360.78618
Overall Steps per Second: 2,072.26993

Timestep Collection Time: 14.87747
Timestep Consumption Time: 9.25066
PPO Batch Consumption Time: 1.30453
Total Iteration Time: 24.12813

Cumulative Model Updates: 4,320
Cumulative Timesteps: 36,051,573

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.72908
Policy Entropy: 1.41080
Value Function Loss: 0.25306

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02121
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 3,308.25752
Overall Steps per Second: 2,039.96643

Timestep Collection Time: 15.11460
Timestep Consumption Time: 9.39707
PPO Batch Consumption Time: 1.32785
Total Iteration Time: 24.51168

Cumulative Model Updates: 4,326
Cumulative Timesteps: 36,101,576

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 36101576...
Checkpoint 36101576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.81388
Policy Entropy: 1.41147
Value Function Loss: 0.25934

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.06608
Value Function Update Magnitude: 0.11731

Collected Steps per Second: 3,357.12344
Overall Steps per Second: 2,048.94275

Timestep Collection Time: 14.89430
Timestep Consumption Time: 9.50951
PPO Batch Consumption Time: 1.35636
Total Iteration Time: 24.40381

Cumulative Model Updates: 4,332
Cumulative Timesteps: 36,151,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.48903
Policy Entropy: 1.41153
Value Function Loss: 0.24823

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.01777
Policy Update Magnitude: 0.06759
Value Function Update Magnitude: 0.11451

Collected Steps per Second: 3,341.87048
Overall Steps per Second: 2,028.13308

Timestep Collection Time: 14.96198
Timestep Consumption Time: 9.69173
PPO Batch Consumption Time: 1.37262
Total Iteration Time: 24.65371

Cumulative Model Updates: 4,338
Cumulative Timesteps: 36,201,579

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 36201579...
Checkpoint 36201579 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.61175
Policy Entropy: 1.41095
Value Function Loss: 0.25333

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.11267

Collected Steps per Second: 3,349.04795
Overall Steps per Second: 2,076.95286

Timestep Collection Time: 14.93051
Timestep Consumption Time: 9.14466
PPO Batch Consumption Time: 1.29299
Total Iteration Time: 24.07517

Cumulative Model Updates: 4,344
Cumulative Timesteps: 36,251,582

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.37507
Policy Entropy: 1.41115
Value Function Loss: 0.25458

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02603
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.10792

Collected Steps per Second: 3,358.03287
Overall Steps per Second: 1,990.13288

Timestep Collection Time: 14.88967
Timestep Consumption Time: 10.23428
PPO Batch Consumption Time: 1.46356
Total Iteration Time: 25.12395

Cumulative Model Updates: 4,350
Cumulative Timesteps: 36,301,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 36301582...
Checkpoint 36301582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.08316
Policy Entropy: 1.41063
Value Function Loss: 0.25705

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.06813
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 3,351.21737
Overall Steps per Second: 2,060.49728

Timestep Collection Time: 14.92085
Timestep Consumption Time: 9.34660
PPO Batch Consumption Time: 1.32101
Total Iteration Time: 24.26744

Cumulative Model Updates: 4,356
Cumulative Timesteps: 36,351,585

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.82733
Policy Entropy: 1.41045
Value Function Loss: 0.25830

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.06800
Value Function Update Magnitude: 0.11833

Collected Steps per Second: 3,350.55606
Overall Steps per Second: 2,063.90555

Timestep Collection Time: 14.92290
Timestep Consumption Time: 9.30302
PPO Batch Consumption Time: 1.30961
Total Iteration Time: 24.22591

Cumulative Model Updates: 4,362
Cumulative Timesteps: 36,401,585

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 36401585...
Checkpoint 36401585 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.82197
Policy Entropy: 1.41014
Value Function Loss: 0.25551

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02949
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.11650

Collected Steps per Second: 3,325.22480
Overall Steps per Second: 2,050.04722

Timestep Collection Time: 15.03778
Timestep Consumption Time: 9.35385
PPO Batch Consumption Time: 1.31606
Total Iteration Time: 24.39163

Cumulative Model Updates: 4,368
Cumulative Timesteps: 36,451,589

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.84164
Policy Entropy: 1.41065
Value Function Loss: 0.25222

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.11579

Collected Steps per Second: 3,356.49625
Overall Steps per Second: 2,055.73122

Timestep Collection Time: 14.89678
Timestep Consumption Time: 9.42595
PPO Batch Consumption Time: 1.32135
Total Iteration Time: 24.32273

Cumulative Model Updates: 4,374
Cumulative Timesteps: 36,501,590

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 36501590...
Checkpoint 36501590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.25386
Policy Entropy: 1.41089
Value Function Loss: 0.24678

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.11989

Collected Steps per Second: 3,340.35897
Overall Steps per Second: 2,056.74163

Timestep Collection Time: 14.96965
Timestep Consumption Time: 9.34259
PPO Batch Consumption Time: 1.31456
Total Iteration Time: 24.31224

Cumulative Model Updates: 4,380
Cumulative Timesteps: 36,551,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.13580
Policy Entropy: 1.41113
Value Function Loss: 0.24061

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03252
Policy Update Magnitude: 0.06292
Value Function Update Magnitude: 0.12006

Collected Steps per Second: 3,326.45791
Overall Steps per Second: 2,043.28918

Timestep Collection Time: 15.03191
Timestep Consumption Time: 9.43991
PPO Batch Consumption Time: 1.32709
Total Iteration Time: 24.47182

Cumulative Model Updates: 4,386
Cumulative Timesteps: 36,601,597

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 36601597...
Checkpoint 36601597 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.16577
Policy Entropy: 1.41073
Value Function Loss: 0.25377

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.11617

Collected Steps per Second: 3,297.44915
Overall Steps per Second: 2,045.03949

Timestep Collection Time: 15.16324
Timestep Consumption Time: 9.28617
PPO Batch Consumption Time: 1.31915
Total Iteration Time: 24.44941

Cumulative Model Updates: 4,392
Cumulative Timesteps: 36,651,597

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.45247
Policy Entropy: 1.41024
Value Function Loss: 0.25819

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02179
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.11249

Collected Steps per Second: 3,295.86696
Overall Steps per Second: 2,042.94878

Timestep Collection Time: 15.17143
Timestep Consumption Time: 9.30447
PPO Batch Consumption Time: 1.31893
Total Iteration Time: 24.47590

Cumulative Model Updates: 4,398
Cumulative Timesteps: 36,701,600

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 36701600...
Checkpoint 36701600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.47051
Policy Entropy: 1.41090
Value Function Loss: 0.26654

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.07022
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 3,337.26899
Overall Steps per Second: 2,044.33323

Timestep Collection Time: 14.98351
Timestep Consumption Time: 9.47630
PPO Batch Consumption Time: 1.33639
Total Iteration Time: 24.45981

Cumulative Model Updates: 4,404
Cumulative Timesteps: 36,751,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.19249
Policy Entropy: 1.41151
Value Function Loss: 0.25220

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 3,323.09047
Overall Steps per Second: 2,041.76842

Timestep Collection Time: 15.04684
Timestep Consumption Time: 9.44272
PPO Batch Consumption Time: 1.34402
Total Iteration Time: 24.48955

Cumulative Model Updates: 4,410
Cumulative Timesteps: 36,801,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 36801606...
Checkpoint 36801606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.62396
Policy Entropy: 1.41150
Value Function Loss: 0.24094

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.11354

Collected Steps per Second: 3,274.81311
Overall Steps per Second: 2,032.68030

Timestep Collection Time: 15.26927
Timestep Consumption Time: 9.33076
PPO Batch Consumption Time: 1.31489
Total Iteration Time: 24.60003

Cumulative Model Updates: 4,416
Cumulative Timesteps: 36,851,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.92898
Policy Entropy: 1.41161
Value Function Loss: 0.23672

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02174
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.11093

Collected Steps per Second: 3,286.00537
Overall Steps per Second: 2,038.10772

Timestep Collection Time: 15.21635
Timestep Consumption Time: 9.31670
PPO Batch Consumption Time: 1.30516
Total Iteration Time: 24.53305

Cumulative Model Updates: 4,422
Cumulative Timesteps: 36,901,611

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 36901611...
Checkpoint 36901611 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.71332
Policy Entropy: 1.41198
Value Function Loss: 0.24405

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01837
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 3,294.99114
Overall Steps per Second: 2,037.31074

Timestep Collection Time: 15.17485
Timestep Consumption Time: 9.36780
PPO Batch Consumption Time: 1.33763
Total Iteration Time: 24.54265

Cumulative Model Updates: 4,428
Cumulative Timesteps: 36,951,612

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.22929
Policy Entropy: 1.41178
Value Function Loss: 0.25670

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.11347

Collected Steps per Second: 3,319.08657
Overall Steps per Second: 2,037.11954

Timestep Collection Time: 15.06439
Timestep Consumption Time: 9.48007
PPO Batch Consumption Time: 1.32937
Total Iteration Time: 24.54446

Cumulative Model Updates: 4,434
Cumulative Timesteps: 37,001,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 37001612...
Checkpoint 37001612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.74918
Policy Entropy: 1.41112
Value Function Loss: 0.26320

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01994
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 3,287.50535
Overall Steps per Second: 2,036.86223

Timestep Collection Time: 15.20971
Timestep Consumption Time: 9.33883
PPO Batch Consumption Time: 1.31054
Total Iteration Time: 24.54854

Cumulative Model Updates: 4,440
Cumulative Timesteps: 37,051,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.59445
Policy Entropy: 1.41125
Value Function Loss: 0.26275

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 3,294.63373
Overall Steps per Second: 2,023.52531

Timestep Collection Time: 15.17741
Timestep Consumption Time: 9.53392
PPO Batch Consumption Time: 1.34997
Total Iteration Time: 24.71133

Cumulative Model Updates: 4,446
Cumulative Timesteps: 37,101,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 37101618...
Checkpoint 37101618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.66352
Policy Entropy: 1.41068
Value Function Loss: 0.25209

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.12618

Collected Steps per Second: 3,312.05525
Overall Steps per Second: 2,027.14523

Timestep Collection Time: 15.09697
Timestep Consumption Time: 9.56924
PPO Batch Consumption Time: 1.34450
Total Iteration Time: 24.66622

Cumulative Model Updates: 4,452
Cumulative Timesteps: 37,151,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.07287
Policy Entropy: 1.41094
Value Function Loss: 0.24414

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.12185

Collected Steps per Second: 3,320.36736
Overall Steps per Second: 2,046.29247

Timestep Collection Time: 15.05978
Timestep Consumption Time: 9.37661
PPO Batch Consumption Time: 1.31083
Total Iteration Time: 24.43639

Cumulative Model Updates: 4,458
Cumulative Timesteps: 37,201,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 37201624...
Checkpoint 37201624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.62487
Policy Entropy: 1.41055
Value Function Loss: 0.24187

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02306
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 3,312.00886
Overall Steps per Second: 2,046.86141

Timestep Collection Time: 15.09779
Timestep Consumption Time: 9.33181
PPO Batch Consumption Time: 1.31096
Total Iteration Time: 24.42960

Cumulative Model Updates: 4,464
Cumulative Timesteps: 37,251,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.87362
Policy Entropy: 1.41070
Value Function Loss: 0.24335

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01828
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.12320

Collected Steps per Second: 3,287.65151
Overall Steps per Second: 2,025.88391

Timestep Collection Time: 15.20903
Timestep Consumption Time: 9.47254
PPO Batch Consumption Time: 1.33463
Total Iteration Time: 24.68157

Cumulative Model Updates: 4,470
Cumulative Timesteps: 37,301,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 37301630...
Checkpoint 37301630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.76218
Policy Entropy: 1.41085
Value Function Loss: 0.25023

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02127
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.11935

Collected Steps per Second: 3,285.11065
Overall Steps per Second: 2,014.26033

Timestep Collection Time: 15.22019
Timestep Consumption Time: 9.60282
PPO Batch Consumption Time: 1.36011
Total Iteration Time: 24.82301

Cumulative Model Updates: 4,476
Cumulative Timesteps: 37,351,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.42382
Policy Entropy: 1.41093
Value Function Loss: 0.25502

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03713
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.11856

Collected Steps per Second: 3,334.21051
Overall Steps per Second: 2,039.30996

Timestep Collection Time: 14.99695
Timestep Consumption Time: 9.52261
PPO Batch Consumption Time: 1.34617
Total Iteration Time: 24.51957

Cumulative Model Updates: 4,482
Cumulative Timesteps: 37,401,633

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 37401633...
Checkpoint 37401633 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.57202
Policy Entropy: 1.41140
Value Function Loss: 0.25695

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.05003
Policy Update Magnitude: 0.08289
Value Function Update Magnitude: 0.14063

Collected Steps per Second: 3,285.50781
Overall Steps per Second: 2,033.26932

Timestep Collection Time: 15.21957
Timestep Consumption Time: 9.37334
PPO Batch Consumption Time: 1.32508
Total Iteration Time: 24.59291

Cumulative Model Updates: 4,488
Cumulative Timesteps: 37,451,637

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.52675
Policy Entropy: 1.41278
Value Function Loss: 0.25643

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.10522
Value Function Update Magnitude: 0.14067

Collected Steps per Second: 3,294.25583
Overall Steps per Second: 2,031.25444

Timestep Collection Time: 15.17824
Timestep Consumption Time: 9.43758
PPO Batch Consumption Time: 1.32746
Total Iteration Time: 24.61582

Cumulative Model Updates: 4,494
Cumulative Timesteps: 37,501,638

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 37501638...
Checkpoint 37501638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.51068
Policy Entropy: 1.41199
Value Function Loss: 0.25549

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.05672
Policy Update Magnitude: 0.07595
Value Function Update Magnitude: 0.13313

Collected Steps per Second: 3,263.51792
Overall Steps per Second: 2,027.92482

Timestep Collection Time: 15.32089
Timestep Consumption Time: 9.33486
PPO Batch Consumption Time: 1.31146
Total Iteration Time: 24.65575

Cumulative Model Updates: 4,500
Cumulative Timesteps: 37,551,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.88000
Policy Entropy: 1.41274
Value Function Loss: 0.25644

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.04422
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.12935

Collected Steps per Second: 3,281.85704
Overall Steps per Second: 2,023.30938

Timestep Collection Time: 15.23619
Timestep Consumption Time: 9.47728
PPO Batch Consumption Time: 1.32615
Total Iteration Time: 24.71347

Cumulative Model Updates: 4,506
Cumulative Timesteps: 37,601,641

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 37601641...
Checkpoint 37601641 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.74193
Policy Entropy: 1.41213
Value Function Loss: 0.24689

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.13107

Collected Steps per Second: 3,270.65527
Overall Steps per Second: 2,026.40815

Timestep Collection Time: 15.28776
Timestep Consumption Time: 9.38693
PPO Batch Consumption Time: 1.33779
Total Iteration Time: 24.67469

Cumulative Model Updates: 4,512
Cumulative Timesteps: 37,651,642

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.71760
Policy Entropy: 1.41220
Value Function Loss: 0.25031

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 3,306.48728
Overall Steps per Second: 2,030.13739

Timestep Collection Time: 15.12179
Timestep Consumption Time: 9.50709
PPO Batch Consumption Time: 1.32884
Total Iteration Time: 24.62887

Cumulative Model Updates: 4,518
Cumulative Timesteps: 37,701,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 37701642...
Checkpoint 37701642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.85212
Policy Entropy: 1.41192
Value Function Loss: 0.24852

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.06295
Value Function Update Magnitude: 0.13046

Collected Steps per Second: 3,253.98495
Overall Steps per Second: 2,022.81326

Timestep Collection Time: 15.36700
Timestep Consumption Time: 9.35302
PPO Batch Consumption Time: 1.31657
Total Iteration Time: 24.72003

Cumulative Model Updates: 4,524
Cumulative Timesteps: 37,751,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.35582
Policy Entropy: 1.41184
Value Function Loss: 0.25255

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01744
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.12892

Collected Steps per Second: 3,258.70817
Overall Steps per Second: 2,026.93159

Timestep Collection Time: 15.34381
Timestep Consumption Time: 9.32451
PPO Batch Consumption Time: 1.32527
Total Iteration Time: 24.66832

Cumulative Model Updates: 4,530
Cumulative Timesteps: 37,801,647

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 37801647...
Checkpoint 37801647 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.11792
Policy Entropy: 1.41144
Value Function Loss: 0.24872

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.12427

Collected Steps per Second: 3,266.72342
Overall Steps per Second: 2,026.99335

Timestep Collection Time: 15.30708
Timestep Consumption Time: 9.36197
PPO Batch Consumption Time: 1.32369
Total Iteration Time: 24.66905

Cumulative Model Updates: 4,536
Cumulative Timesteps: 37,851,651

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.24471
Policy Entropy: 1.41163
Value Function Loss: 0.25132

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01581
Policy Update Magnitude: 0.06584
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 3,294.60871
Overall Steps per Second: 2,026.92076

Timestep Collection Time: 15.17661
Timestep Consumption Time: 9.49184
PPO Batch Consumption Time: 1.35202
Total Iteration Time: 24.66845

Cumulative Model Updates: 4,542
Cumulative Timesteps: 37,901,652

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 37901652...
Checkpoint 37901652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.80647
Policy Entropy: 1.41180
Value Function Loss: 0.24424

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.12649

Collected Steps per Second: 3,269.03080
Overall Steps per Second: 2,025.25967

Timestep Collection Time: 15.29628
Timestep Consumption Time: 9.39389
PPO Batch Consumption Time: 1.32974
Total Iteration Time: 24.69017

Cumulative Model Updates: 4,548
Cumulative Timesteps: 37,951,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.65133
Policy Entropy: 1.41212
Value Function Loss: 0.24696

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.12822

Collected Steps per Second: 3,233.01529
Overall Steps per Second: 1,989.69538

Timestep Collection Time: 15.46637
Timestep Consumption Time: 9.66462
PPO Batch Consumption Time: 1.36484
Total Iteration Time: 25.13098

Cumulative Model Updates: 4,554
Cumulative Timesteps: 38,001,659

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 38001659...
Checkpoint 38001659 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.31942
Policy Entropy: 1.41176
Value Function Loss: 0.24098

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01981
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 3,167.82540
Overall Steps per Second: 1,989.60115

Timestep Collection Time: 15.78370
Timestep Consumption Time: 9.34697
PPO Batch Consumption Time: 1.32921
Total Iteration Time: 25.13067

Cumulative Model Updates: 4,560
Cumulative Timesteps: 38,051,659

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.61518
Policy Entropy: 1.41176
Value Function Loss: 0.24912

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02068
Policy Update Magnitude: 0.06391
Value Function Update Magnitude: 0.12387

Collected Steps per Second: 3,249.45462
Overall Steps per Second: 1,990.33703

Timestep Collection Time: 15.38874
Timestep Consumption Time: 9.73515
PPO Batch Consumption Time: 1.38146
Total Iteration Time: 25.12389

Cumulative Model Updates: 4,566
Cumulative Timesteps: 38,101,664

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 38101664...
Checkpoint 38101664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.58862
Policy Entropy: 1.41205
Value Function Loss: 0.24588

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01398
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 3,258.66256
Overall Steps per Second: 2,010.92190

Timestep Collection Time: 15.34495
Timestep Consumption Time: 9.52126
PPO Batch Consumption Time: 1.33772
Total Iteration Time: 24.86621

Cumulative Model Updates: 4,572
Cumulative Timesteps: 38,151,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.90640
Policy Entropy: 1.41196
Value Function Loss: 0.23912

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01405
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.12260

Collected Steps per Second: 3,259.31779
Overall Steps per Second: 2,012.45907

Timestep Collection Time: 15.34094
Timestep Consumption Time: 9.50478
PPO Batch Consumption Time: 1.34569
Total Iteration Time: 24.84572

Cumulative Model Updates: 4,578
Cumulative Timesteps: 38,201,669

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 38201669...
Checkpoint 38201669 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.78358
Policy Entropy: 1.41161
Value Function Loss: 0.24037

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.12061

Collected Steps per Second: 3,286.90938
Overall Steps per Second: 2,051.04779

Timestep Collection Time: 15.21277
Timestep Consumption Time: 9.16648
PPO Batch Consumption Time: 1.27686
Total Iteration Time: 24.37925

Cumulative Model Updates: 4,584
Cumulative Timesteps: 38,251,672

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.00667
Policy Entropy: 1.41152
Value Function Loss: 0.23826

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.11979

Collected Steps per Second: 3,269.62561
Overall Steps per Second: 2,032.06368

Timestep Collection Time: 15.29349
Timestep Consumption Time: 9.31400
PPO Batch Consumption Time: 1.31040
Total Iteration Time: 24.60750

Cumulative Model Updates: 4,590
Cumulative Timesteps: 38,301,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 38301676...
Checkpoint 38301676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.27627
Policy Entropy: 1.41153
Value Function Loss: 0.24936

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01891
Policy Update Magnitude: 0.06682
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 3,229.41589
Overall Steps per Second: 2,010.71170

Timestep Collection Time: 15.48422
Timestep Consumption Time: 9.38508
PPO Batch Consumption Time: 1.32660
Total Iteration Time: 24.86930

Cumulative Model Updates: 4,596
Cumulative Timesteps: 38,351,681

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.40098
Policy Entropy: 1.41180
Value Function Loss: 0.24648

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.12073

Collected Steps per Second: 3,286.45872
Overall Steps per Second: 2,031.42346

Timestep Collection Time: 15.21455
Timestep Consumption Time: 9.39971
PPO Batch Consumption Time: 1.31616
Total Iteration Time: 24.61427

Cumulative Model Updates: 4,602
Cumulative Timesteps: 38,401,683

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 38401683...
Checkpoint 38401683 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.70053
Policy Entropy: 1.41171
Value Function Loss: 0.24198

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 3,299.71731
Overall Steps per Second: 2,029.11657

Timestep Collection Time: 15.15281
Timestep Consumption Time: 9.48845
PPO Batch Consumption Time: 1.34206
Total Iteration Time: 24.64127

Cumulative Model Updates: 4,608
Cumulative Timesteps: 38,451,683

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.51213
Policy Entropy: 1.41223
Value Function Loss: 0.23532

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.11810

Collected Steps per Second: 3,271.31917
Overall Steps per Second: 2,026.95156

Timestep Collection Time: 15.28497
Timestep Consumption Time: 9.38361
PPO Batch Consumption Time: 1.31041
Total Iteration Time: 24.66857

Cumulative Model Updates: 4,614
Cumulative Timesteps: 38,501,685

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 38501685...
Checkpoint 38501685 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.76029
Policy Entropy: 1.41201
Value Function Loss: 0.23477

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.08663
Value Function Update Magnitude: 0.11737

Collected Steps per Second: 3,235.35282
Overall Steps per Second: 2,018.55385

Timestep Collection Time: 15.45488
Timestep Consumption Time: 9.31632
PPO Batch Consumption Time: 1.31620
Total Iteration Time: 24.77120

Cumulative Model Updates: 4,620
Cumulative Timesteps: 38,551,687

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.12696
Policy Entropy: 1.41298
Value Function Loss: 0.24028

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.07889
Value Function Update Magnitude: 0.12170

Collected Steps per Second: 3,260.61772
Overall Steps per Second: 2,000.32069

Timestep Collection Time: 15.33574
Timestep Consumption Time: 9.66225
PPO Batch Consumption Time: 1.38583
Total Iteration Time: 24.99799

Cumulative Model Updates: 4,626
Cumulative Timesteps: 38,601,691

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 38601691...
Checkpoint 38601691 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.10520
Policy Entropy: 1.41288
Value Function Loss: 0.24203

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.07057
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 3,302.91858
Overall Steps per Second: 2,039.07044

Timestep Collection Time: 15.13813
Timestep Consumption Time: 9.38285
PPO Batch Consumption Time: 1.29809
Total Iteration Time: 24.52098

Cumulative Model Updates: 4,632
Cumulative Timesteps: 38,651,691

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.92491
Policy Entropy: 1.41252
Value Function Loss: 0.24864

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.12062

Collected Steps per Second: 3,272.85680
Overall Steps per Second: 2,010.66720

Timestep Collection Time: 15.27748
Timestep Consumption Time: 9.59039
PPO Batch Consumption Time: 1.34777
Total Iteration Time: 24.86786

Cumulative Model Updates: 4,638
Cumulative Timesteps: 38,701,692

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 38701692...
Checkpoint 38701692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.23572
Policy Entropy: 1.41223
Value Function Loss: 0.24996

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 3,280.46783
Overall Steps per Second: 2,024.09793

Timestep Collection Time: 15.24173
Timestep Consumption Time: 9.46063
PPO Batch Consumption Time: 1.32881
Total Iteration Time: 24.70236

Cumulative Model Updates: 4,644
Cumulative Timesteps: 38,751,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.95792
Policy Entropy: 1.41167
Value Function Loss: 0.24828

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01867
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.13433

Collected Steps per Second: 3,269.33298
Overall Steps per Second: 2,023.36601

Timestep Collection Time: 15.29486
Timestep Consumption Time: 9.41841
PPO Batch Consumption Time: 1.31335
Total Iteration Time: 24.71327

Cumulative Model Updates: 4,650
Cumulative Timesteps: 38,801,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 38801696...
Checkpoint 38801696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.82046
Policy Entropy: 1.41190
Value Function Loss: 0.24920

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 3,274.67174
Overall Steps per Second: 2,043.09562

Timestep Collection Time: 15.26871
Timestep Consumption Time: 9.20396
PPO Batch Consumption Time: 1.29672
Total Iteration Time: 24.47267

Cumulative Model Updates: 4,656
Cumulative Timesteps: 38,851,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.35671
Policy Entropy: 1.41187
Value Function Loss: 0.25086

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 3,241.20962
Overall Steps per Second: 2,000.24880

Timestep Collection Time: 15.42757
Timestep Consumption Time: 9.57132
PPO Batch Consumption Time: 1.35358
Total Iteration Time: 24.99889

Cumulative Model Updates: 4,662
Cumulative Timesteps: 38,901,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 38901700...
Checkpoint 38901700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.20550
Policy Entropy: 1.41207
Value Function Loss: 0.25517

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02830
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.13534

Collected Steps per Second: 3,292.14653
Overall Steps per Second: 2,040.15490

Timestep Collection Time: 15.18796
Timestep Consumption Time: 9.32047
PPO Batch Consumption Time: 1.31782
Total Iteration Time: 24.50843

Cumulative Model Updates: 4,668
Cumulative Timesteps: 38,951,701

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.88611
Policy Entropy: 1.41201
Value Function Loss: 0.25629

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03216
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 3,311.13676
Overall Steps per Second: 2,039.68200

Timestep Collection Time: 15.10176
Timestep Consumption Time: 9.41382
PPO Batch Consumption Time: 1.33076
Total Iteration Time: 24.51559

Cumulative Model Updates: 4,674
Cumulative Timesteps: 39,001,705

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 39001705...
Checkpoint 39001705 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.65178
Policy Entropy: 1.41227
Value Function Loss: 0.25978

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 3,314.95180
Overall Steps per Second: 2,055.51239

Timestep Collection Time: 15.08378
Timestep Consumption Time: 9.24203
PPO Batch Consumption Time: 1.31024
Total Iteration Time: 24.32581

Cumulative Model Updates: 4,680
Cumulative Timesteps: 39,051,707

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.47983
Policy Entropy: 1.41274
Value Function Loss: 0.25906

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02876
Policy Update Magnitude: 0.06547
Value Function Update Magnitude: 0.12513

Collected Steps per Second: 3,272.44643
Overall Steps per Second: 2,033.67800

Timestep Collection Time: 15.27939
Timestep Consumption Time: 9.30709
PPO Batch Consumption Time: 1.31766
Total Iteration Time: 24.58649

Cumulative Model Updates: 4,686
Cumulative Timesteps: 39,101,708

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 39101708...
Checkpoint 39101708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.64197
Policy Entropy: 1.41231
Value Function Loss: 0.26406

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.12886

Collected Steps per Second: 3,272.97018
Overall Steps per Second: 2,047.41761

Timestep Collection Time: 15.27726
Timestep Consumption Time: 9.14473
PPO Batch Consumption Time: 1.27878
Total Iteration Time: 24.42198

Cumulative Model Updates: 4,692
Cumulative Timesteps: 39,151,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.27225
Policy Entropy: 1.41195
Value Function Loss: 0.25670

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01671
Policy Update Magnitude: 0.06852
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 3,296.54739
Overall Steps per Second: 2,033.65545

Timestep Collection Time: 15.16769
Timestep Consumption Time: 9.41907
PPO Batch Consumption Time: 1.33078
Total Iteration Time: 24.58676

Cumulative Model Updates: 4,698
Cumulative Timesteps: 39,201,711

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 39201711...
Checkpoint 39201711 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.90020
Policy Entropy: 1.41212
Value Function Loss: 0.25509

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01958
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.12408

Collected Steps per Second: 3,335.65648
Overall Steps per Second: 2,054.68729

Timestep Collection Time: 14.98955
Timestep Consumption Time: 9.34505
PPO Batch Consumption Time: 1.31453
Total Iteration Time: 24.33460

Cumulative Model Updates: 4,704
Cumulative Timesteps: 39,251,711

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.13611
Policy Entropy: 1.41255
Value Function Loss: 0.25166

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03095
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.12747

Collected Steps per Second: 3,292.57322
Overall Steps per Second: 2,045.37530

Timestep Collection Time: 15.18691
Timestep Consumption Time: 9.26044
PPO Batch Consumption Time: 1.30655
Total Iteration Time: 24.44735

Cumulative Model Updates: 4,710
Cumulative Timesteps: 39,301,715

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 39301715...
Checkpoint 39301715 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.80329
Policy Entropy: 1.41244
Value Function Loss: 0.25772

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 3,286.42651
Overall Steps per Second: 2,045.79128

Timestep Collection Time: 15.21470
Timestep Consumption Time: 9.22670
PPO Batch Consumption Time: 1.30839
Total Iteration Time: 24.44140

Cumulative Model Updates: 4,716
Cumulative Timesteps: 39,351,717

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.85713
Policy Entropy: 1.41288
Value Function Loss: 0.25456

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 3,309.84099
Overall Steps per Second: 2,043.74299

Timestep Collection Time: 15.10677
Timestep Consumption Time: 9.35864
PPO Batch Consumption Time: 1.31884
Total Iteration Time: 24.46541

Cumulative Model Updates: 4,722
Cumulative Timesteps: 39,401,718

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 39401718...
Checkpoint 39401718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.20512
Policy Entropy: 1.41247
Value Function Loss: 0.25011

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.12823

Collected Steps per Second: 3,336.06623
Overall Steps per Second: 2,066.26774

Timestep Collection Time: 14.98861
Timestep Consumption Time: 9.21106
PPO Batch Consumption Time: 1.30252
Total Iteration Time: 24.19967

Cumulative Model Updates: 4,728
Cumulative Timesteps: 39,451,721

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.21400
Policy Entropy: 1.41311
Value Function Loss: 0.25137

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02846
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.12163

Collected Steps per Second: 3,287.99303
Overall Steps per Second: 2,007.83108

Timestep Collection Time: 15.20776
Timestep Consumption Time: 9.69623
PPO Batch Consumption Time: 1.36673
Total Iteration Time: 24.90399

Cumulative Model Updates: 4,734
Cumulative Timesteps: 39,501,724

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 39501724...
Checkpoint 39501724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.33976
Policy Entropy: 1.41187
Value Function Loss: 0.25223

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.06645
Value Function Update Magnitude: 0.12500

Collected Steps per Second: 3,227.17726
Overall Steps per Second: 2,012.78109

Timestep Collection Time: 15.49404
Timestep Consumption Time: 9.34821
PPO Batch Consumption Time: 1.31651
Total Iteration Time: 24.84224

Cumulative Model Updates: 4,740
Cumulative Timesteps: 39,551,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.36327
Policy Entropy: 1.41233
Value Function Loss: 0.24880

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02217
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.13169

Collected Steps per Second: 3,302.61996
Overall Steps per Second: 2,046.54787

Timestep Collection Time: 15.13950
Timestep Consumption Time: 9.29189
PPO Batch Consumption Time: 1.31253
Total Iteration Time: 24.43139

Cumulative Model Updates: 4,746
Cumulative Timesteps: 39,601,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 39601726...
Checkpoint 39601726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.14979
Policy Entropy: 1.41175
Value Function Loss: 0.23699

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02190
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.13225

Collected Steps per Second: 3,320.88143
Overall Steps per Second: 2,050.23660

Timestep Collection Time: 15.05654
Timestep Consumption Time: 9.33137
PPO Batch Consumption Time: 1.29863
Total Iteration Time: 24.38792

Cumulative Model Updates: 4,752
Cumulative Timesteps: 39,651,727

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.54713
Policy Entropy: 1.41230
Value Function Loss: 0.24400

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.13910

Collected Steps per Second: 3,300.87561
Overall Steps per Second: 2,054.10918

Timestep Collection Time: 15.14840
Timestep Consumption Time: 9.19451
PPO Batch Consumption Time: 1.29770
Total Iteration Time: 24.34291

Cumulative Model Updates: 4,758
Cumulative Timesteps: 39,701,730

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 39701730...
Checkpoint 39701730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.14550
Policy Entropy: 1.41226
Value Function Loss: 0.24675

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01538
Policy Update Magnitude: 0.06639
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 3,318.59445
Overall Steps per Second: 2,059.44863

Timestep Collection Time: 15.06813
Timestep Consumption Time: 9.21264
PPO Batch Consumption Time: 1.28925
Total Iteration Time: 24.28077

Cumulative Model Updates: 4,764
Cumulative Timesteps: 39,751,735

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.28629
Policy Entropy: 1.41212
Value Function Loss: 0.25229

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02010
Policy Update Magnitude: 0.06828
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 3,314.15482
Overall Steps per Second: 2,041.30958

Timestep Collection Time: 15.08801
Timestep Consumption Time: 9.40803
PPO Batch Consumption Time: 1.33777
Total Iteration Time: 24.49604

Cumulative Model Updates: 4,770
Cumulative Timesteps: 39,801,739

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 39801739...
Checkpoint 39801739 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.30305
Policy Entropy: 1.41172
Value Function Loss: 0.25111

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 3,298.34742
Overall Steps per Second: 2,050.14371

Timestep Collection Time: 15.15971
Timestep Consumption Time: 9.22980
PPO Batch Consumption Time: 1.31189
Total Iteration Time: 24.38951

Cumulative Model Updates: 4,776
Cumulative Timesteps: 39,851,741

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.12906
Policy Entropy: 1.41124
Value Function Loss: 0.24993

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.06481
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 3,319.65285
Overall Steps per Second: 2,054.88611

Timestep Collection Time: 15.06302
Timestep Consumption Time: 9.27117
PPO Batch Consumption Time: 1.29107
Total Iteration Time: 24.33420

Cumulative Model Updates: 4,782
Cumulative Timesteps: 39,901,745

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 39901745...
Checkpoint 39901745 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.31087
Policy Entropy: 1.41138
Value Function Loss: 0.24704

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.12272

Collected Steps per Second: 3,322.22463
Overall Steps per Second: 2,052.33930

Timestep Collection Time: 15.05046
Timestep Consumption Time: 9.31247
PPO Batch Consumption Time: 1.31474
Total Iteration Time: 24.36293

Cumulative Model Updates: 4,788
Cumulative Timesteps: 39,951,746

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.08844
Policy Entropy: 1.41132
Value Function Loss: 0.24276

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01828
Policy Update Magnitude: 0.06961
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 3,299.11414
Overall Steps per Second: 2,028.72281

Timestep Collection Time: 15.15649
Timestep Consumption Time: 9.49103
PPO Batch Consumption Time: 1.34533
Total Iteration Time: 24.64753

Cumulative Model Updates: 4,794
Cumulative Timesteps: 40,001,749

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 40001749...
Checkpoint 40001749 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.14303
Policy Entropy: 1.41158
Value Function Loss: 0.23683

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.11454

Collected Steps per Second: 3,324.30153
Overall Steps per Second: 2,055.82928

Timestep Collection Time: 15.04166
Timestep Consumption Time: 9.28089
PPO Batch Consumption Time: 1.31542
Total Iteration Time: 24.32254

Cumulative Model Updates: 4,800
Cumulative Timesteps: 40,051,752

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.93244
Policy Entropy: 1.41112
Value Function Loss: 0.24499

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02220
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.11876

Collected Steps per Second: 3,337.41769
Overall Steps per Second: 2,057.23467

Timestep Collection Time: 14.98194
Timestep Consumption Time: 9.32301
PPO Batch Consumption Time: 1.30736
Total Iteration Time: 24.30496

Cumulative Model Updates: 4,806
Cumulative Timesteps: 40,101,753

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 40101753...
Checkpoint 40101753 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.61419
Policy Entropy: 1.41064
Value Function Loss: 0.25104

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.06764
Value Function Update Magnitude: 0.11979

Collected Steps per Second: 3,302.44879
Overall Steps per Second: 2,054.94418

Timestep Collection Time: 15.14028
Timestep Consumption Time: 9.19128
PPO Batch Consumption Time: 1.29755
Total Iteration Time: 24.33156

Cumulative Model Updates: 4,812
Cumulative Timesteps: 40,151,753

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.83157
Policy Entropy: 1.40996
Value Function Loss: 0.25323

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02287
Policy Update Magnitude: 0.06888
Value Function Update Magnitude: 0.13034

Collected Steps per Second: 3,318.35607
Overall Steps per Second: 2,053.70177

Timestep Collection Time: 15.06770
Timestep Consumption Time: 9.27858
PPO Batch Consumption Time: 1.31421
Total Iteration Time: 24.34628

Cumulative Model Updates: 4,818
Cumulative Timesteps: 40,201,753

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 40201753...
Checkpoint 40201753 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.84119
Policy Entropy: 1.41038
Value Function Loss: 0.25194

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.07299
Value Function Update Magnitude: 0.12793

Collected Steps per Second: 3,322.93201
Overall Steps per Second: 2,049.60789

Timestep Collection Time: 15.04725
Timestep Consumption Time: 9.34814
PPO Batch Consumption Time: 1.32953
Total Iteration Time: 24.39540

Cumulative Model Updates: 4,824
Cumulative Timesteps: 40,251,754

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.19602
Policy Entropy: 1.41064
Value Function Loss: 0.25486

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.07716
Value Function Update Magnitude: 0.14597

Collected Steps per Second: 3,310.78493
Overall Steps per Second: 2,049.49579

Timestep Collection Time: 15.10246
Timestep Consumption Time: 9.29427
PPO Batch Consumption Time: 1.31926
Total Iteration Time: 24.39673

Cumulative Model Updates: 4,830
Cumulative Timesteps: 40,301,755

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 40301755...
Checkpoint 40301755 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.31881
Policy Entropy: 1.41139
Value Function Loss: 0.25941

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.07899
Value Function Update Magnitude: 0.13575

Collected Steps per Second: 3,339.46785
Overall Steps per Second: 2,065.22778

Timestep Collection Time: 14.97304
Timestep Consumption Time: 9.23833
PPO Batch Consumption Time: 1.29457
Total Iteration Time: 24.21137

Cumulative Model Updates: 4,836
Cumulative Timesteps: 40,351,757

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.11089
Policy Entropy: 1.41080
Value Function Loss: 0.25404

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.03636
Policy Update Magnitude: 0.08015
Value Function Update Magnitude: 0.13183

Collected Steps per Second: 3,288.94470
Overall Steps per Second: 2,036.96705

Timestep Collection Time: 15.20305
Timestep Consumption Time: 9.34423
PPO Batch Consumption Time: 1.31494
Total Iteration Time: 24.54728

Cumulative Model Updates: 4,842
Cumulative Timesteps: 40,401,759

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 40401759...
Checkpoint 40401759 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.05070
Policy Entropy: 1.41193
Value Function Loss: 0.24646

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.05715
Policy Update Magnitude: 0.09967
Value Function Update Magnitude: 0.13097

Collected Steps per Second: 3,277.40487
Overall Steps per Second: 2,040.18444

Timestep Collection Time: 15.25719
Timestep Consumption Time: 9.25236
PPO Batch Consumption Time: 1.30379
Total Iteration Time: 24.50955

Cumulative Model Updates: 4,848
Cumulative Timesteps: 40,451,763

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.13862
Policy Entropy: 1.41270
Value Function Loss: 0.24983

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.04794
Policy Update Magnitude: 0.08098
Value Function Update Magnitude: 0.14335

Collected Steps per Second: 3,292.53125
Overall Steps per Second: 2,031.17302

Timestep Collection Time: 15.18710
Timestep Consumption Time: 9.43119
PPO Batch Consumption Time: 1.33318
Total Iteration Time: 24.61829

Cumulative Model Updates: 4,854
Cumulative Timesteps: 40,501,767

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 40501767...
Checkpoint 40501767 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.91637
Policy Entropy: 1.41292
Value Function Loss: 0.24864

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.16894

Collected Steps per Second: 3,320.05358
Overall Steps per Second: 2,045.56752

Timestep Collection Time: 15.06030
Timestep Consumption Time: 9.38328
PPO Batch Consumption Time: 1.33158
Total Iteration Time: 24.44358

Cumulative Model Updates: 4,860
Cumulative Timesteps: 40,551,768

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.46869
Policy Entropy: 1.41267
Value Function Loss: 0.23708

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.07606
Value Function Update Magnitude: 0.16526

Collected Steps per Second: 3,334.87166
Overall Steps per Second: 2,058.78428

Timestep Collection Time: 14.99398
Timestep Consumption Time: 9.29365
PPO Batch Consumption Time: 1.30007
Total Iteration Time: 24.28763

Cumulative Model Updates: 4,866
Cumulative Timesteps: 40,601,771

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 40601771...
Checkpoint 40601771 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.25151
Policy Entropy: 1.41335
Value Function Loss: 0.21843

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.06818
Value Function Update Magnitude: 0.20190

Collected Steps per Second: 3,321.53718
Overall Steps per Second: 2,051.68303

Timestep Collection Time: 15.05417
Timestep Consumption Time: 9.31752
PPO Batch Consumption Time: 1.31731
Total Iteration Time: 24.37170

Cumulative Model Updates: 4,872
Cumulative Timesteps: 40,651,774

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.65565
Policy Entropy: 1.41271
Value Function Loss: 0.22303

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02846
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.19972

Collected Steps per Second: 3,309.35035
Overall Steps per Second: 2,024.34049

Timestep Collection Time: 15.11022
Timestep Consumption Time: 9.59166
PPO Batch Consumption Time: 1.36885
Total Iteration Time: 24.70187

Cumulative Model Updates: 4,878
Cumulative Timesteps: 40,701,779

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 40701779...
Checkpoint 40701779 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.79235
Policy Entropy: 1.41237
Value Function Loss: 0.22337

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01989
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.18461

Collected Steps per Second: 3,329.15470
Overall Steps per Second: 2,052.51518

Timestep Collection Time: 15.01973
Timestep Consumption Time: 9.34209
PPO Batch Consumption Time: 1.31982
Total Iteration Time: 24.36182

Cumulative Model Updates: 4,884
Cumulative Timesteps: 40,751,782

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.72084
Policy Entropy: 1.41187
Value Function Loss: 0.21949

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01738
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.21820

Collected Steps per Second: 3,333.23916
Overall Steps per Second: 2,047.06927

Timestep Collection Time: 15.00102
Timestep Consumption Time: 9.42512
PPO Batch Consumption Time: 1.32760
Total Iteration Time: 24.42614

Cumulative Model Updates: 4,890
Cumulative Timesteps: 40,801,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 40801784...
Checkpoint 40801784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.16349
Policy Entropy: 1.41176
Value Function Loss: 0.22007

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01505
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.20582

Collected Steps per Second: 3,344.72319
Overall Steps per Second: 2,052.12550

Timestep Collection Time: 14.95012
Timestep Consumption Time: 9.41681
PPO Batch Consumption Time: 1.33023
Total Iteration Time: 24.36693

Cumulative Model Updates: 4,896
Cumulative Timesteps: 40,851,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.17921
Policy Entropy: 1.41191
Value Function Loss: 0.23356

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01689
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.15734

Collected Steps per Second: 3,333.34540
Overall Steps per Second: 2,034.45654

Timestep Collection Time: 15.00055
Timestep Consumption Time: 9.57703
PPO Batch Consumption Time: 1.34969
Total Iteration Time: 24.57757

Cumulative Model Updates: 4,902
Cumulative Timesteps: 40,901,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 40901790...
Checkpoint 40901790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.46678
Policy Entropy: 1.41165
Value Function Loss: 0.23220

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.16665

Collected Steps per Second: 3,326.88268
Overall Steps per Second: 2,056.27528

Timestep Collection Time: 15.02938
Timestep Consumption Time: 9.28691
PPO Batch Consumption Time: 1.30480
Total Iteration Time: 24.31630

Cumulative Model Updates: 4,908
Cumulative Timesteps: 40,951,791

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.23419
Policy Entropy: 1.41178
Value Function Loss: 0.22754

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.22471

Collected Steps per Second: 3,323.18216
Overall Steps per Second: 2,024.41709

Timestep Collection Time: 15.04582
Timestep Consumption Time: 9.65265
PPO Batch Consumption Time: 1.36406
Total Iteration Time: 24.69847

Cumulative Model Updates: 4,914
Cumulative Timesteps: 41,001,791

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 41001791...
Checkpoint 41001791 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.93420
Policy Entropy: 1.41130
Value Function Loss: 0.21773

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02967
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.23027

Collected Steps per Second: 3,303.27500
Overall Steps per Second: 2,040.21363

Timestep Collection Time: 15.13740
Timestep Consumption Time: 9.37131
PPO Batch Consumption Time: 1.31049
Total Iteration Time: 24.50871

Cumulative Model Updates: 4,920
Cumulative Timesteps: 41,051,794

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.84229
Policy Entropy: 1.41159
Value Function Loss: 0.22489

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02164
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.21431

Collected Steps per Second: 3,341.36379
Overall Steps per Second: 2,030.86101

Timestep Collection Time: 14.96515
Timestep Consumption Time: 9.65692
PPO Batch Consumption Time: 1.37421
Total Iteration Time: 24.62207

Cumulative Model Updates: 4,926
Cumulative Timesteps: 41,101,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 41101798...
Checkpoint 41101798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.46372
Policy Entropy: 1.41092
Value Function Loss: 0.22817

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.03526
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.15905

Collected Steps per Second: 3,334.56878
Overall Steps per Second: 2,050.79474

Timestep Collection Time: 14.99534
Timestep Consumption Time: 9.38691
PPO Batch Consumption Time: 1.32992
Total Iteration Time: 24.38225

Cumulative Model Updates: 4,932
Cumulative Timesteps: 41,151,801

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.14022
Policy Entropy: 1.41134
Value Function Loss: 0.22880

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03013
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.14481

Collected Steps per Second: 3,325.75314
Overall Steps per Second: 2,034.72819

Timestep Collection Time: 15.03419
Timestep Consumption Time: 9.53912
PPO Batch Consumption Time: 1.34463
Total Iteration Time: 24.57331

Cumulative Model Updates: 4,938
Cumulative Timesteps: 41,201,801

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 41201801...
Checkpoint 41201801 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.49664
Policy Entropy: 1.41144
Value Function Loss: 0.23162

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02172
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 3,296.54702
Overall Steps per Second: 2,034.19529

Timestep Collection Time: 15.16830
Timestep Consumption Time: 9.41292
PPO Batch Consumption Time: 1.33333
Total Iteration Time: 24.58122

Cumulative Model Updates: 4,944
Cumulative Timesteps: 41,251,804

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.72842
Policy Entropy: 1.41143
Value Function Loss: 0.23420

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02192
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.12564

Collected Steps per Second: 3,304.00332
Overall Steps per Second: 2,010.07549

Timestep Collection Time: 15.13467
Timestep Consumption Time: 9.74251
PPO Batch Consumption Time: 1.37819
Total Iteration Time: 24.87718

Cumulative Model Updates: 4,950
Cumulative Timesteps: 41,301,809

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 41301809...
Checkpoint 41301809 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.41828
Policy Entropy: 1.41110
Value Function Loss: 0.24073

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01868
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.12170

Collected Steps per Second: 3,353.40211
Overall Steps per Second: 2,062.92120

Timestep Collection Time: 14.91113
Timestep Consumption Time: 9.32780
PPO Batch Consumption Time: 1.31366
Total Iteration Time: 24.23893

Cumulative Model Updates: 4,956
Cumulative Timesteps: 41,351,812

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.86495
Policy Entropy: 1.41145
Value Function Loss: 0.24126

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02129
Policy Update Magnitude: 0.06399
Value Function Update Magnitude: 0.12759

Collected Steps per Second: 3,334.16943
Overall Steps per Second: 2,049.97014

Timestep Collection Time: 14.99714
Timestep Consumption Time: 9.39492
PPO Batch Consumption Time: 1.32844
Total Iteration Time: 24.39206

Cumulative Model Updates: 4,962
Cumulative Timesteps: 41,401,815

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 41401815...
Checkpoint 41401815 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.47266
Policy Entropy: 1.41125
Value Function Loss: 0.23709

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.06287
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 3,302.45110
Overall Steps per Second: 2,041.77854

Timestep Collection Time: 15.14027
Timestep Consumption Time: 9.34818
PPO Batch Consumption Time: 1.32345
Total Iteration Time: 24.48845

Cumulative Model Updates: 4,968
Cumulative Timesteps: 41,451,815

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.36183
Policy Entropy: 1.41062
Value Function Loss: 0.22973

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.10998

Collected Steps per Second: 3,312.92676
Overall Steps per Second: 2,043.76613

Timestep Collection Time: 15.09240
Timestep Consumption Time: 9.37224
PPO Batch Consumption Time: 1.32497
Total Iteration Time: 24.46464

Cumulative Model Updates: 4,974
Cumulative Timesteps: 41,501,815

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 41501815...
Checkpoint 41501815 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.60288
Policy Entropy: 1.41068
Value Function Loss: 0.23477

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02898
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.11287

Collected Steps per Second: 3,346.06427
Overall Steps per Second: 2,054.87079

Timestep Collection Time: 14.94323
Timestep Consumption Time: 9.38969
PPO Batch Consumption Time: 1.32383
Total Iteration Time: 24.33292

Cumulative Model Updates: 4,980
Cumulative Timesteps: 41,551,816

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.98426
Policy Entropy: 1.41015
Value Function Loss: 0.24151

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.10597

Collected Steps per Second: 3,331.87382
Overall Steps per Second: 2,030.72444

Timestep Collection Time: 15.00657
Timestep Consumption Time: 9.61518
PPO Batch Consumption Time: 1.35511
Total Iteration Time: 24.62176

Cumulative Model Updates: 4,986
Cumulative Timesteps: 41,601,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 41601816...
Checkpoint 41601816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.17787
Policy Entropy: 1.41049
Value Function Loss: 0.24975

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.01942
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 3,306.54444
Overall Steps per Second: 2,046.96067

Timestep Collection Time: 15.12243
Timestep Consumption Time: 9.30549
PPO Batch Consumption Time: 1.30367
Total Iteration Time: 24.42792

Cumulative Model Updates: 4,992
Cumulative Timesteps: 41,651,819

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.98624
Policy Entropy: 1.41077
Value Function Loss: 0.24878

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.11228

Collected Steps per Second: 3,299.35849
Overall Steps per Second: 2,019.01080

Timestep Collection Time: 15.15476
Timestep Consumption Time: 9.61033
PPO Batch Consumption Time: 1.37140
Total Iteration Time: 24.76510

Cumulative Model Updates: 4,998
Cumulative Timesteps: 41,701,820

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 41701820...
Checkpoint 41701820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.74373
Policy Entropy: 1.41097
Value Function Loss: 0.24851

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 3,312.65862
Overall Steps per Second: 2,052.05599

Timestep Collection Time: 15.09513
Timestep Consumption Time: 9.27312
PPO Batch Consumption Time: 1.31544
Total Iteration Time: 24.36824

Cumulative Model Updates: 5,004
Cumulative Timesteps: 41,751,825

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.95953
Policy Entropy: 1.41079
Value Function Loss: 0.25219

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.11545

Collected Steps per Second: 3,353.30511
Overall Steps per Second: 2,040.04639

Timestep Collection Time: 14.91156
Timestep Consumption Time: 9.59916
PPO Batch Consumption Time: 1.35592
Total Iteration Time: 24.51072

Cumulative Model Updates: 5,010
Cumulative Timesteps: 41,801,828

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 41801828...
Checkpoint 41801828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.09300
Policy Entropy: 1.41045
Value Function Loss: 0.24699

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01912
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.11753

Collected Steps per Second: 3,245.82298
Overall Steps per Second: 2,030.37215

Timestep Collection Time: 15.40472
Timestep Consumption Time: 9.22180
PPO Batch Consumption Time: 1.29391
Total Iteration Time: 24.62652

Cumulative Model Updates: 5,016
Cumulative Timesteps: 41,851,829

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.50436
Policy Entropy: 1.41043
Value Function Loss: 0.23679

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.06767
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 3,304.40775
Overall Steps per Second: 2,041.31049

Timestep Collection Time: 15.13221
Timestep Consumption Time: 9.36333
PPO Batch Consumption Time: 1.31959
Total Iteration Time: 24.49554

Cumulative Model Updates: 5,022
Cumulative Timesteps: 41,901,832

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 41901832...
Checkpoint 41901832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.15271
Policy Entropy: 1.41045
Value Function Loss: 0.23363

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.11987

Collected Steps per Second: 3,295.21095
Overall Steps per Second: 2,044.10823

Timestep Collection Time: 15.17354
Timestep Consumption Time: 9.28701
PPO Batch Consumption Time: 1.30925
Total Iteration Time: 24.46054

Cumulative Model Updates: 5,028
Cumulative Timesteps: 41,951,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.80893
Policy Entropy: 1.41050
Value Function Loss: 0.23641

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 3,326.58173
Overall Steps per Second: 2,023.19144

Timestep Collection Time: 15.03165
Timestep Consumption Time: 9.68376
PPO Batch Consumption Time: 1.38343
Total Iteration Time: 24.71541

Cumulative Model Updates: 5,034
Cumulative Timesteps: 42,001,836

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 42001836...
Checkpoint 42001836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.39344
Policy Entropy: 1.41071
Value Function Loss: 0.24914

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.06718
Value Function Update Magnitude: 0.12379

Collected Steps per Second: 3,355.30958
Overall Steps per Second: 2,052.10777

Timestep Collection Time: 14.90175
Timestep Consumption Time: 9.46344
PPO Batch Consumption Time: 1.33706
Total Iteration Time: 24.36519

Cumulative Model Updates: 5,040
Cumulative Timesteps: 42,051,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.23071
Policy Entropy: 1.41068
Value Function Loss: 0.25110

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.07351
Value Function Update Magnitude: 0.12398

Collected Steps per Second: 3,311.66796
Overall Steps per Second: 2,045.47116

Timestep Collection Time: 15.09904
Timestep Consumption Time: 9.34667
PPO Batch Consumption Time: 1.31351
Total Iteration Time: 24.44571

Cumulative Model Updates: 5,046
Cumulative Timesteps: 42,101,839

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 42101839...
Checkpoint 42101839 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.38438
Policy Entropy: 1.41102
Value Function Loss: 0.25092

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.07504
Value Function Update Magnitude: 0.11806

Collected Steps per Second: 3,332.88773
Overall Steps per Second: 2,049.13814

Timestep Collection Time: 15.00201
Timestep Consumption Time: 9.39850
PPO Batch Consumption Time: 1.31768
Total Iteration Time: 24.40050

Cumulative Model Updates: 5,052
Cumulative Timesteps: 42,151,839

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.80493
Policy Entropy: 1.41075
Value Function Loss: 0.24323

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.07559
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 3,322.16084
Overall Steps per Second: 2,023.85314

Timestep Collection Time: 15.05105
Timestep Consumption Time: 9.65529
PPO Batch Consumption Time: 1.37311
Total Iteration Time: 24.70634

Cumulative Model Updates: 5,058
Cumulative Timesteps: 42,201,841

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 42201841...
Checkpoint 42201841 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.45152
Policy Entropy: 1.41093
Value Function Loss: 0.24333

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02865
Policy Update Magnitude: 0.07325
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 3,305.28365
Overall Steps per Second: 2,044.82058

Timestep Collection Time: 15.12760
Timestep Consumption Time: 9.32491
PPO Batch Consumption Time: 1.29460
Total Iteration Time: 24.45251

Cumulative Model Updates: 5,064
Cumulative Timesteps: 42,251,842

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.11799
Policy Entropy: 1.41070
Value Function Loss: 0.24301

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.12556

Collected Steps per Second: 3,342.98862
Overall Steps per Second: 2,031.63572

Timestep Collection Time: 14.95757
Timestep Consumption Time: 9.65461
PPO Batch Consumption Time: 1.37022
Total Iteration Time: 24.61219

Cumulative Model Updates: 5,070
Cumulative Timesteps: 42,301,845

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 42301845...
Checkpoint 42301845 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.67350
Policy Entropy: 1.41062
Value Function Loss: 0.23947

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02010
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 3,331.57170
Overall Steps per Second: 2,039.76568

Timestep Collection Time: 15.00823
Timestep Consumption Time: 9.50488
PPO Batch Consumption Time: 1.32514
Total Iteration Time: 24.51311

Cumulative Model Updates: 5,076
Cumulative Timesteps: 42,351,846

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.75303
Policy Entropy: 1.41088
Value Function Loss: 0.24442

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01896
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.12001

Collected Steps per Second: 3,344.80601
Overall Steps per Second: 2,065.67937

Timestep Collection Time: 14.95004
Timestep Consumption Time: 9.25749
PPO Batch Consumption Time: 1.30937
Total Iteration Time: 24.20753

Cumulative Model Updates: 5,082
Cumulative Timesteps: 42,401,851

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 42401851...
Checkpoint 42401851 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.38682
Policy Entropy: 1.41042
Value Function Loss: 0.23488

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01631
Policy Update Magnitude: 0.07881
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 3,336.21007
Overall Steps per Second: 2,052.08898

Timestep Collection Time: 14.98737
Timestep Consumption Time: 9.37854
PPO Batch Consumption Time: 1.33487
Total Iteration Time: 24.36590

Cumulative Model Updates: 5,088
Cumulative Timesteps: 42,451,852

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.73446
Policy Entropy: 1.41061
Value Function Loss: 0.24433

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01265
Policy Update Magnitude: 0.08272
Value Function Update Magnitude: 0.12039

Collected Steps per Second: 3,333.85172
Overall Steps per Second: 2,040.23897

Timestep Collection Time: 14.99857
Timestep Consumption Time: 9.50984
PPO Batch Consumption Time: 1.33430
Total Iteration Time: 24.50840

Cumulative Model Updates: 5,094
Cumulative Timesteps: 42,501,855

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 42501855...
Checkpoint 42501855 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.82694
Policy Entropy: 1.41079
Value Function Loss: 0.23756

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02068
Policy Update Magnitude: 0.07212
Value Function Update Magnitude: 0.11860

Collected Steps per Second: 3,305.54889
Overall Steps per Second: 2,033.46433

Timestep Collection Time: 15.12729
Timestep Consumption Time: 9.46326
PPO Batch Consumption Time: 1.32267
Total Iteration Time: 24.59055

Cumulative Model Updates: 5,100
Cumulative Timesteps: 42,551,859

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.04804
Policy Entropy: 1.41111
Value Function Loss: 0.24322

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 0.07020
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 3,324.03393
Overall Steps per Second: 2,020.58196

Timestep Collection Time: 15.04287
Timestep Consumption Time: 9.70396
PPO Batch Consumption Time: 1.37605
Total Iteration Time: 24.74683

Cumulative Model Updates: 5,106
Cumulative Timesteps: 42,601,862

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 42601862...
Checkpoint 42601862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.09962
Policy Entropy: 1.41024
Value Function Loss: 0.23907

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.04759
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.11323

Collected Steps per Second: 3,339.05141
Overall Steps per Second: 2,054.50058

Timestep Collection Time: 14.97491
Timestep Consumption Time: 9.36288
PPO Batch Consumption Time: 1.31545
Total Iteration Time: 24.33779

Cumulative Model Updates: 5,112
Cumulative Timesteps: 42,651,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.01905
Policy Entropy: 1.41044
Value Function Loss: 0.24480

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 0.06704
Value Function Update Magnitude: 0.11232

Collected Steps per Second: 3,305.56388
Overall Steps per Second: 2,041.91874

Timestep Collection Time: 15.12692
Timestep Consumption Time: 9.36132
PPO Batch Consumption Time: 1.32599
Total Iteration Time: 24.48824

Cumulative Model Updates: 5,118
Cumulative Timesteps: 42,701,867

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 42701867...
Checkpoint 42701867 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.77425
Policy Entropy: 1.41030
Value Function Loss: 0.25392

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03840
Policy Update Magnitude: 0.06746
Value Function Update Magnitude: 0.12567

Collected Steps per Second: 3,305.70148
Overall Steps per Second: 2,036.71189

Timestep Collection Time: 15.12599
Timestep Consumption Time: 9.42437
PPO Batch Consumption Time: 1.32738
Total Iteration Time: 24.55036

Cumulative Model Updates: 5,124
Cumulative Timesteps: 42,751,869

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.79853
Policy Entropy: 1.41095
Value Function Loss: 0.25507

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.13679

Collected Steps per Second: 3,355.58805
Overall Steps per Second: 2,033.66115

Timestep Collection Time: 14.90171
Timestep Consumption Time: 9.68646
PPO Batch Consumption Time: 1.38122
Total Iteration Time: 24.58817

Cumulative Model Updates: 5,130
Cumulative Timesteps: 42,801,873

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 42801873...
Checkpoint 42801873 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.46061
Policy Entropy: 1.41102
Value Function Loss: 0.25148

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.03639
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 3,305.63712
Overall Steps per Second: 2,035.27527

Timestep Collection Time: 15.12568
Timestep Consumption Time: 9.44102
PPO Batch Consumption Time: 1.32916
Total Iteration Time: 24.56670

Cumulative Model Updates: 5,136
Cumulative Timesteps: 42,851,873

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.75869
Policy Entropy: 1.41133
Value Function Loss: 0.25199

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.04506
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.12186

Collected Steps per Second: 3,308.33420
Overall Steps per Second: 2,041.41698

Timestep Collection Time: 15.11486
Timestep Consumption Time: 9.38038
PPO Batch Consumption Time: 1.33046
Total Iteration Time: 24.49524

Cumulative Model Updates: 5,142
Cumulative Timesteps: 42,901,878

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 42901878...
Checkpoint 42901878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.52353
Policy Entropy: 1.41124
Value Function Loss: 0.24977

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.04254
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.12434

Collected Steps per Second: 3,262.50635
Overall Steps per Second: 2,006.15816

Timestep Collection Time: 15.32595
Timestep Consumption Time: 9.59781
PPO Batch Consumption Time: 1.35687
Total Iteration Time: 24.92376

Cumulative Model Updates: 5,148
Cumulative Timesteps: 42,951,879

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.76716
Policy Entropy: 1.41103
Value Function Loss: 0.23911

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.12222

Collected Steps per Second: 3,330.27809
Overall Steps per Second: 2,045.76685

Timestep Collection Time: 15.01526
Timestep Consumption Time: 9.42789
PPO Batch Consumption Time: 1.33750
Total Iteration Time: 24.44316

Cumulative Model Updates: 5,154
Cumulative Timesteps: 43,001,884

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 43001884...
Checkpoint 43001884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.08103
Policy Entropy: 1.41044
Value Function Loss: 0.23428

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.11984

Collected Steps per Second: 3,364.53176
Overall Steps per Second: 2,054.61316

Timestep Collection Time: 14.86210
Timestep Consumption Time: 9.47533
PPO Batch Consumption Time: 1.34148
Total Iteration Time: 24.33743

Cumulative Model Updates: 5,160
Cumulative Timesteps: 43,051,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.70463
Policy Entropy: 1.41036
Value Function Loss: 0.23333

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 3,339.05874
Overall Steps per Second: 2,020.59554

Timestep Collection Time: 14.97518
Timestep Consumption Time: 9.77149
PPO Batch Consumption Time: 1.39231
Total Iteration Time: 24.74666

Cumulative Model Updates: 5,166
Cumulative Timesteps: 43,101,891

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 43101891...
Checkpoint 43101891 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.99357
Policy Entropy: 1.41054
Value Function Loss: 0.24108

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.12186

Collected Steps per Second: 3,337.54435
Overall Steps per Second: 2,055.47063

Timestep Collection Time: 14.98227
Timestep Consumption Time: 9.34500
PPO Batch Consumption Time: 1.30508
Total Iteration Time: 24.32728

Cumulative Model Updates: 5,172
Cumulative Timesteps: 43,151,895

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.39977
Policy Entropy: 1.41150
Value Function Loss: 0.24179

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 3,332.89830
Overall Steps per Second: 2,048.11464

Timestep Collection Time: 15.00256
Timestep Consumption Time: 9.41111
PPO Batch Consumption Time: 1.32904
Total Iteration Time: 24.41367

Cumulative Model Updates: 5,178
Cumulative Timesteps: 43,201,897

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 43201897...
Checkpoint 43201897 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.96235
Policy Entropy: 1.41109
Value Function Loss: 0.23896

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 3,337.06286
Overall Steps per Second: 2,055.75176

Timestep Collection Time: 14.98324
Timestep Consumption Time: 9.33877
PPO Batch Consumption Time: 1.32501
Total Iteration Time: 24.32200

Cumulative Model Updates: 5,184
Cumulative Timesteps: 43,251,897

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.77623
Policy Entropy: 1.41096
Value Function Loss: 0.23479

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 3,340.51919
Overall Steps per Second: 2,058.96783

Timestep Collection Time: 14.96773
Timestep Consumption Time: 9.31628
PPO Batch Consumption Time: 1.31196
Total Iteration Time: 24.28401

Cumulative Model Updates: 5,190
Cumulative Timesteps: 43,301,897

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 43301897...
Checkpoint 43301897 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.84836
Policy Entropy: 1.41131
Value Function Loss: 0.23936

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01892
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 3,315.37694
Overall Steps per Second: 2,036.82723

Timestep Collection Time: 15.08245
Timestep Consumption Time: 9.46750
PPO Batch Consumption Time: 1.33696
Total Iteration Time: 24.54995

Cumulative Model Updates: 5,196
Cumulative Timesteps: 43,351,901

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.50403
Policy Entropy: 1.41152
Value Function Loss: 0.24034

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.12492

Collected Steps per Second: 3,344.40179
Overall Steps per Second: 2,040.78334

Timestep Collection Time: 14.95066
Timestep Consumption Time: 9.55023
PPO Batch Consumption Time: 1.36173
Total Iteration Time: 24.50089

Cumulative Model Updates: 5,202
Cumulative Timesteps: 43,401,902

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 43401902...
Checkpoint 43401902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.66768
Policy Entropy: 1.41202
Value Function Loss: 0.23777

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.12481

Collected Steps per Second: 3,290.80150
Overall Steps per Second: 2,046.93524

Timestep Collection Time: 15.19417
Timestep Consumption Time: 9.23308
PPO Batch Consumption Time: 1.31116
Total Iteration Time: 24.42725

Cumulative Model Updates: 5,208
Cumulative Timesteps: 43,451,903

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.19915
Policy Entropy: 1.41119
Value Function Loss: 0.22811

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 3,332.83335
Overall Steps per Second: 2,047.89542

Timestep Collection Time: 15.00315
Timestep Consumption Time: 9.41362
PPO Batch Consumption Time: 1.32676
Total Iteration Time: 24.41677

Cumulative Model Updates: 5,214
Cumulative Timesteps: 43,501,906

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 43501906...
Checkpoint 43501906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.40227
Policy Entropy: 1.41151
Value Function Loss: 0.22722

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.06836
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 3,307.04635
Overall Steps per Second: 2,024.63418

Timestep Collection Time: 15.11923
Timestep Consumption Time: 9.57659
PPO Batch Consumption Time: 1.35715
Total Iteration Time: 24.69582

Cumulative Model Updates: 5,220
Cumulative Timesteps: 43,551,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.16200
Policy Entropy: 1.41148
Value Function Loss: 0.22192

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02120
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 3,357.74686
Overall Steps per Second: 2,042.93155

Timestep Collection Time: 14.89094
Timestep Consumption Time: 9.58370
PPO Batch Consumption Time: 1.34623
Total Iteration Time: 24.47463

Cumulative Model Updates: 5,226
Cumulative Timesteps: 43,601,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 43601906...
Checkpoint 43601906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.47349
Policy Entropy: 1.41119
Value Function Loss: 0.23242

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01758
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.11574

Collected Steps per Second: 3,344.75925
Overall Steps per Second: 2,021.68760

Timestep Collection Time: 14.94906
Timestep Consumption Time: 9.78325
PPO Batch Consumption Time: 1.39642
Total Iteration Time: 24.73231

Cumulative Model Updates: 5,232
Cumulative Timesteps: 43,651,907

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.13221
Policy Entropy: 1.41081
Value Function Loss: 0.23112

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01591
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.11546

Collected Steps per Second: 3,252.15637
Overall Steps per Second: 2,027.48594

Timestep Collection Time: 15.37441
Timestep Consumption Time: 9.28667
PPO Batch Consumption Time: 1.32128
Total Iteration Time: 24.66108

Cumulative Model Updates: 5,238
Cumulative Timesteps: 43,701,907

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 43701907...
Checkpoint 43701907 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.16955
Policy Entropy: 1.41128
Value Function Loss: 0.24455

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01905
Policy Update Magnitude: 0.06524
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 3,276.99218
Overall Steps per Second: 2,053.22767

Timestep Collection Time: 15.25881
Timestep Consumption Time: 9.09455
PPO Batch Consumption Time: 1.27731
Total Iteration Time: 24.35336

Cumulative Model Updates: 5,244
Cumulative Timesteps: 43,751,910

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.89068
Policy Entropy: 1.41143
Value Function Loss: 0.24029

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.12314

Collected Steps per Second: 3,288.73682
Overall Steps per Second: 2,033.99529

Timestep Collection Time: 15.20401
Timestep Consumption Time: 9.37913
PPO Batch Consumption Time: 1.32619
Total Iteration Time: 24.58314

Cumulative Model Updates: 5,250
Cumulative Timesteps: 43,801,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 43801912...
Checkpoint 43801912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.44577
Policy Entropy: 1.41076
Value Function Loss: 0.24688

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.11875

Collected Steps per Second: 3,334.88735
Overall Steps per Second: 2,045.91329

Timestep Collection Time: 14.99451
Timestep Consumption Time: 9.44690
PPO Batch Consumption Time: 1.32938
Total Iteration Time: 24.44141

Cumulative Model Updates: 5,256
Cumulative Timesteps: 43,851,917

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.15227
Policy Entropy: 1.41016
Value Function Loss: 0.23930

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.06509
Value Function Update Magnitude: 0.11941

Collected Steps per Second: 3,331.73922
Overall Steps per Second: 2,063.53358

Timestep Collection Time: 15.00838
Timestep Consumption Time: 9.22384
PPO Batch Consumption Time: 1.30530
Total Iteration Time: 24.23222

Cumulative Model Updates: 5,262
Cumulative Timesteps: 43,901,921

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 43901921...
Checkpoint 43901921 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.67731
Policy Entropy: 1.41031
Value Function Loss: 0.23748

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.06694
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 3,282.80065
Overall Steps per Second: 2,033.85145

Timestep Collection Time: 15.23212
Timestep Consumption Time: 9.35375
PPO Batch Consumption Time: 1.32386
Total Iteration Time: 24.58587

Cumulative Model Updates: 5,268
Cumulative Timesteps: 43,951,925

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.79210
Policy Entropy: 1.41057
Value Function Loss: 0.24192

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.06363
Value Function Update Magnitude: 0.12788

Collected Steps per Second: 3,313.39116
Overall Steps per Second: 2,048.80533

Timestep Collection Time: 15.09149
Timestep Consumption Time: 9.31493
PPO Batch Consumption Time: 1.31416
Total Iteration Time: 24.40642

Cumulative Model Updates: 5,274
Cumulative Timesteps: 44,001,929

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 44001929...
Checkpoint 44001929 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.97884
Policy Entropy: 1.41093
Value Function Loss: 0.24620

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01990
Policy Update Magnitude: 0.06279
Value Function Update Magnitude: 0.12648

Collected Steps per Second: 3,321.53911
Overall Steps per Second: 2,048.10118

Timestep Collection Time: 15.05386
Timestep Consumption Time: 9.35997
PPO Batch Consumption Time: 1.30762
Total Iteration Time: 24.41383

Cumulative Model Updates: 5,280
Cumulative Timesteps: 44,051,931

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.07205
Policy Entropy: 1.41088
Value Function Loss: 0.24964

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01899
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.12264

Collected Steps per Second: 3,327.06266
Overall Steps per Second: 2,036.77372

Timestep Collection Time: 15.02917
Timestep Consumption Time: 9.52093
PPO Batch Consumption Time: 1.34122
Total Iteration Time: 24.55010

Cumulative Model Updates: 5,286
Cumulative Timesteps: 44,101,934

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 44101934...
Checkpoint 44101934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.01585
Policy Entropy: 1.41080
Value Function Loss: 0.24721

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01945
Policy Update Magnitude: 0.06532
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 3,315.99125
Overall Steps per Second: 2,055.09881

Timestep Collection Time: 15.07965
Timestep Consumption Time: 9.25202
PPO Batch Consumption Time: 1.30919
Total Iteration Time: 24.33168

Cumulative Model Updates: 5,292
Cumulative Timesteps: 44,151,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.09081
Policy Entropy: 1.41060
Value Function Loss: 0.24801

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01923
Policy Update Magnitude: 0.06893
Value Function Update Magnitude: 0.14173

Collected Steps per Second: 3,303.15130
Overall Steps per Second: 2,052.67439

Timestep Collection Time: 15.13736
Timestep Consumption Time: 9.22159
PPO Batch Consumption Time: 1.29563
Total Iteration Time: 24.35895

Cumulative Model Updates: 5,298
Cumulative Timesteps: 44,201,939

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 44201939...
Checkpoint 44201939 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.60735
Policy Entropy: 1.41055
Value Function Loss: 0.24935

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01578
Policy Update Magnitude: 0.07117
Value Function Update Magnitude: 0.15791

Collected Steps per Second: 3,338.19441
Overall Steps per Second: 2,063.37783

Timestep Collection Time: 14.97906
Timestep Consumption Time: 9.25451
PPO Batch Consumption Time: 1.30670
Total Iteration Time: 24.23356

Cumulative Model Updates: 5,304
Cumulative Timesteps: 44,251,942

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.10023
Policy Entropy: 1.41105
Value Function Loss: 0.24788

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.06895
Value Function Update Magnitude: 0.14547

Collected Steps per Second: 3,331.83159
Overall Steps per Second: 2,055.75491

Timestep Collection Time: 15.00766
Timestep Consumption Time: 9.31576
PPO Batch Consumption Time: 1.30079
Total Iteration Time: 24.32342

Cumulative Model Updates: 5,310
Cumulative Timesteps: 44,301,945

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 44301945...
Checkpoint 44301945 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.68529
Policy Entropy: 1.41071
Value Function Loss: 0.23913

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.01954
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.16276

Collected Steps per Second: 3,310.38504
Overall Steps per Second: 2,045.82759

Timestep Collection Time: 15.10398
Timestep Consumption Time: 9.33600
PPO Batch Consumption Time: 1.31598
Total Iteration Time: 24.43999

Cumulative Model Updates: 5,316
Cumulative Timesteps: 44,351,945

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.81263
Policy Entropy: 1.41065
Value Function Loss: 0.23156

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.21607

Collected Steps per Second: 3,327.84474
Overall Steps per Second: 2,053.68587

Timestep Collection Time: 15.02504
Timestep Consumption Time: 9.32192
PPO Batch Consumption Time: 1.32303
Total Iteration Time: 24.34696

Cumulative Model Updates: 5,322
Cumulative Timesteps: 44,401,946

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 44401946...
Checkpoint 44401946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.12553
Policy Entropy: 1.41053
Value Function Loss: 0.22383

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.06868
Value Function Update Magnitude: 0.19337

Collected Steps per Second: 3,331.74483
Overall Steps per Second: 2,062.19732

Timestep Collection Time: 15.00805
Timestep Consumption Time: 9.23939
PPO Batch Consumption Time: 1.31411
Total Iteration Time: 24.24744

Cumulative Model Updates: 5,328
Cumulative Timesteps: 44,451,949

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.44518
Policy Entropy: 1.40997
Value Function Loss: 0.21951

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.23539

Collected Steps per Second: 3,320.05466
Overall Steps per Second: 2,053.87425

Timestep Collection Time: 15.06029
Timestep Consumption Time: 9.28443
PPO Batch Consumption Time: 1.31173
Total Iteration Time: 24.34472

Cumulative Model Updates: 5,334
Cumulative Timesteps: 44,501,950

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 44501950...
Checkpoint 44501950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.29104
Policy Entropy: 1.41020
Value Function Loss: 0.22381

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.03131
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.26905

Collected Steps per Second: 3,315.76461
Overall Steps per Second: 2,057.89087

Timestep Collection Time: 15.08068
Timestep Consumption Time: 9.21798
PPO Batch Consumption Time: 1.29635
Total Iteration Time: 24.29866

Cumulative Model Updates: 5,340
Cumulative Timesteps: 44,551,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.70936
Policy Entropy: 1.40944
Value Function Loss: 0.21962

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.03890
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.23919

Collected Steps per Second: 3,316.79794
Overall Steps per Second: 2,044.47511

Timestep Collection Time: 15.07599
Timestep Consumption Time: 9.38213
PPO Batch Consumption Time: 1.31086
Total Iteration Time: 24.45811

Cumulative Model Updates: 5,346
Cumulative Timesteps: 44,601,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 44601958...
Checkpoint 44601958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.84573
Policy Entropy: 1.41015
Value Function Loss: 0.22893

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03297
Policy Update Magnitude: 0.06734
Value Function Update Magnitude: 0.21977

Collected Steps per Second: 3,336.21922
Overall Steps per Second: 2,058.06010

Timestep Collection Time: 14.98822
Timestep Consumption Time: 9.30844
PPO Batch Consumption Time: 1.31056
Total Iteration Time: 24.29667

Cumulative Model Updates: 5,352
Cumulative Timesteps: 44,651,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.17508
Policy Entropy: 1.40998
Value Function Loss: 0.22688

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.20802

Collected Steps per Second: 3,349.06846
Overall Steps per Second: 2,062.19772

Timestep Collection Time: 14.93012
Timestep Consumption Time: 9.31683
PPO Batch Consumption Time: 1.30838
Total Iteration Time: 24.24695

Cumulative Model Updates: 5,358
Cumulative Timesteps: 44,701,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 44701964...
Checkpoint 44701964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.54969
Policy Entropy: 1.40916
Value Function Loss: 0.22139

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.23263

Collected Steps per Second: 3,345.53119
Overall Steps per Second: 2,064.78655

Timestep Collection Time: 14.94591
Timestep Consumption Time: 9.27064
PPO Batch Consumption Time: 1.30403
Total Iteration Time: 24.21655

Cumulative Model Updates: 5,364
Cumulative Timesteps: 44,751,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.33828
Policy Entropy: 1.40857
Value Function Loss: 0.21894

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01890
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.26929

Collected Steps per Second: 3,316.35194
Overall Steps per Second: 2,060.12583

Timestep Collection Time: 15.07711
Timestep Consumption Time: 9.19374
PPO Batch Consumption Time: 1.29069
Total Iteration Time: 24.27085

Cumulative Model Updates: 5,370
Cumulative Timesteps: 44,801,967

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 44801967...
Checkpoint 44801967 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.91607
Policy Entropy: 1.40870
Value Function Loss: 0.21988

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02069
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.27615

Collected Steps per Second: 3,360.90173
Overall Steps per Second: 2,066.55928

Timestep Collection Time: 14.87815
Timestep Consumption Time: 9.31859
PPO Batch Consumption Time: 1.31625
Total Iteration Time: 24.19674

Cumulative Model Updates: 5,376
Cumulative Timesteps: 44,851,971

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.76250
Policy Entropy: 1.40912
Value Function Loss: 0.22283

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.26494

Collected Steps per Second: 3,357.57600
Overall Steps per Second: 2,067.50170

Timestep Collection Time: 14.89199
Timestep Consumption Time: 9.29227
PPO Batch Consumption Time: 1.31057
Total Iteration Time: 24.18426

Cumulative Model Updates: 5,382
Cumulative Timesteps: 44,901,972

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 44901972...
Checkpoint 44901972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.95897
Policy Entropy: 1.40929
Value Function Loss: 0.21374

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.27578

Collected Steps per Second: 3,339.77856
Overall Steps per Second: 2,061.17512

Timestep Collection Time: 14.97195
Timestep Consumption Time: 9.28751
PPO Batch Consumption Time: 1.29666
Total Iteration Time: 24.25946

Cumulative Model Updates: 5,388
Cumulative Timesteps: 44,951,975

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.62474
Policy Entropy: 1.40943
Value Function Loss: 0.21489

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01659
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.24082

Collected Steps per Second: 3,317.36736
Overall Steps per Second: 2,068.74697

Timestep Collection Time: 15.07310
Timestep Consumption Time: 9.09757
PPO Batch Consumption Time: 1.28803
Total Iteration Time: 24.17067

Cumulative Model Updates: 5,394
Cumulative Timesteps: 45,001,978

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 45001978...
Checkpoint 45001978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.52650
Policy Entropy: 1.40913
Value Function Loss: 0.22687

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01825
Policy Update Magnitude: 0.07057
Value Function Update Magnitude: 0.16768

Collected Steps per Second: 3,316.96155
Overall Steps per Second: 2,054.54294

Timestep Collection Time: 15.07464
Timestep Consumption Time: 9.26265
PPO Batch Consumption Time: 1.30238
Total Iteration Time: 24.33729

Cumulative Model Updates: 5,400
Cumulative Timesteps: 45,051,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.76855
Policy Entropy: 1.40842
Value Function Loss: 0.22928

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.07218
Value Function Update Magnitude: 0.14290

Collected Steps per Second: 3,363.52669
Overall Steps per Second: 2,062.55468

Timestep Collection Time: 14.86624
Timestep Consumption Time: 9.37699
PPO Batch Consumption Time: 1.31689
Total Iteration Time: 24.24324

Cumulative Model Updates: 5,406
Cumulative Timesteps: 45,101,983

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 45101983...
Checkpoint 45101983 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241.53643
Policy Entropy: 1.40776
Value Function Loss: 0.22540

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.07450
Value Function Update Magnitude: 0.12959

Collected Steps per Second: 3,320.41862
Overall Steps per Second: 2,049.03871

Timestep Collection Time: 15.05894
Timestep Consumption Time: 9.34372
PPO Batch Consumption Time: 1.30698
Total Iteration Time: 24.40266

Cumulative Model Updates: 5,412
Cumulative Timesteps: 45,151,985

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.42281
Policy Entropy: 1.40627
Value Function Loss: 0.22070

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.03915
Policy Update Magnitude: 0.07321
Value Function Update Magnitude: 0.11917

Collected Steps per Second: 3,312.37338
Overall Steps per Second: 2,027.51851

Timestep Collection Time: 15.09552
Timestep Consumption Time: 9.56615
PPO Batch Consumption Time: 1.36158
Total Iteration Time: 24.66167

Cumulative Model Updates: 5,418
Cumulative Timesteps: 45,201,987

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 45201987...
Checkpoint 45201987 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.24020
Policy Entropy: 1.40695
Value Function Loss: 0.21836

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.08190
Value Function Update Magnitude: 0.10785

Collected Steps per Second: 3,318.03301
Overall Steps per Second: 2,076.85021

Timestep Collection Time: 15.06977
Timestep Consumption Time: 9.00611
PPO Batch Consumption Time: 1.25873
Total Iteration Time: 24.07588

Cumulative Model Updates: 5,424
Cumulative Timesteps: 45,251,989

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.79997
Policy Entropy: 1.40622
Value Function Loss: 0.21519

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.03245
Policy Update Magnitude: 0.08170
Value Function Update Magnitude: 0.10729

Collected Steps per Second: 3,330.62662
Overall Steps per Second: 2,055.44757

Timestep Collection Time: 15.01279
Timestep Consumption Time: 9.31378
PPO Batch Consumption Time: 1.29901
Total Iteration Time: 24.32658

Cumulative Model Updates: 5,430
Cumulative Timesteps: 45,301,991

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 45301991...
Checkpoint 45301991 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.25279
Policy Entropy: 1.40683
Value Function Loss: 0.21761

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02841
Policy Update Magnitude: 0.08326
Value Function Update Magnitude: 0.11151

Collected Steps per Second: 3,357.71629
Overall Steps per Second: 2,054.91983

Timestep Collection Time: 14.89137
Timestep Consumption Time: 9.44096
PPO Batch Consumption Time: 1.31556
Total Iteration Time: 24.33234

Cumulative Model Updates: 5,436
Cumulative Timesteps: 45,351,992

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.83934
Policy Entropy: 1.40644
Value Function Loss: 0.22278

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.08634
Value Function Update Magnitude: 0.11044

Collected Steps per Second: 3,215.90207
Overall Steps per Second: 1,984.76021

Timestep Collection Time: 15.54929
Timestep Consumption Time: 9.64519
PPO Batch Consumption Time: 1.36962
Total Iteration Time: 25.19448

Cumulative Model Updates: 5,442
Cumulative Timesteps: 45,401,997

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 45401997...
Checkpoint 45401997 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.10241
Policy Entropy: 1.40583
Value Function Loss: 0.21984

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 0.08744
Value Function Update Magnitude: 0.11047

Collected Steps per Second: 3,309.92194
Overall Steps per Second: 2,048.79325

Timestep Collection Time: 15.10730
Timestep Consumption Time: 9.29926
PPO Batch Consumption Time: 1.30628
Total Iteration Time: 24.40656

Cumulative Model Updates: 5,448
Cumulative Timesteps: 45,452,001

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.55626
Policy Entropy: 1.40496
Value Function Loss: 0.21378

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.04336
Policy Update Magnitude: 0.08057
Value Function Update Magnitude: 0.11313

Collected Steps per Second: 3,314.44959
Overall Steps per Second: 2,047.66894

Timestep Collection Time: 15.08606
Timestep Consumption Time: 9.33292
PPO Batch Consumption Time: 1.32030
Total Iteration Time: 24.41899

Cumulative Model Updates: 5,454
Cumulative Timesteps: 45,502,003

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 45502003...
Checkpoint 45502003 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.63676
Policy Entropy: 1.40373
Value Function Loss: 0.20021

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.04020
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.11152

Collected Steps per Second: 3,277.42003
Overall Steps per Second: 2,034.38957

Timestep Collection Time: 15.25682
Timestep Consumption Time: 9.32205
PPO Batch Consumption Time: 1.30594
Total Iteration Time: 24.57887

Cumulative Model Updates: 5,460
Cumulative Timesteps: 45,552,006

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.89018
Policy Entropy: 1.40352
Value Function Loss: 0.19917

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.08046
Value Function Update Magnitude: 0.11074

Collected Steps per Second: 3,347.76995
Overall Steps per Second: 2,060.22113

Timestep Collection Time: 14.93591
Timestep Consumption Time: 9.33430
PPO Batch Consumption Time: 1.31139
Total Iteration Time: 24.27021

Cumulative Model Updates: 5,466
Cumulative Timesteps: 45,602,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 45602008...
Checkpoint 45602008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.64423
Policy Entropy: 1.40349
Value Function Loss: 0.20200

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.04395
Policy Update Magnitude: 0.07894
Value Function Update Magnitude: 0.10977

Collected Steps per Second: 3,299.81803
Overall Steps per Second: 2,050.38338

Timestep Collection Time: 15.15235
Timestep Consumption Time: 9.23333
PPO Batch Consumption Time: 1.30467
Total Iteration Time: 24.38568

Cumulative Model Updates: 5,472
Cumulative Timesteps: 45,652,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.03607
Policy Entropy: 1.40299
Value Function Loss: 0.20604

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 0.07909
Value Function Update Magnitude: 0.11492

Collected Steps per Second: 3,328.22940
Overall Steps per Second: 2,071.55311

Timestep Collection Time: 15.02300
Timestep Consumption Time: 9.11348
PPO Batch Consumption Time: 1.27707
Total Iteration Time: 24.13648

Cumulative Model Updates: 5,478
Cumulative Timesteps: 45,702,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 45702008...
Checkpoint 45702008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.02020
Policy Entropy: 1.40267
Value Function Loss: 0.20842

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.07820
Value Function Update Magnitude: 0.12335

Collected Steps per Second: 3,338.49500
Overall Steps per Second: 2,017.21576

Timestep Collection Time: 14.97681
Timestep Consumption Time: 9.80983
PPO Batch Consumption Time: 1.37529
Total Iteration Time: 24.78664

Cumulative Model Updates: 5,484
Cumulative Timesteps: 45,752,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.25934
Policy Entropy: 1.40205
Value Function Loss: 0.20458

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.03190
Policy Update Magnitude: 0.07995
Value Function Update Magnitude: 0.11926

Collected Steps per Second: 3,290.64134
Overall Steps per Second: 2,011.79848

Timestep Collection Time: 15.19491
Timestep Consumption Time: 9.65897
PPO Batch Consumption Time: 1.35575
Total Iteration Time: 24.85388

Cumulative Model Updates: 5,490
Cumulative Timesteps: 45,802,009

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 45802009...
Checkpoint 45802009 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.66254
Policy Entropy: 1.40174
Value Function Loss: 0.20786

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.05328
Policy Update Magnitude: 0.07570
Value Function Update Magnitude: 0.11347

Collected Steps per Second: 3,364.57500
Overall Steps per Second: 2,063.18795

Timestep Collection Time: 14.86072
Timestep Consumption Time: 9.37362
PPO Batch Consumption Time: 1.30790
Total Iteration Time: 24.23434

Cumulative Model Updates: 5,496
Cumulative Timesteps: 45,852,009

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.78709
Policy Entropy: 1.40180
Value Function Loss: 0.20427

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 0.07533
Value Function Update Magnitude: 0.10903

Collected Steps per Second: 3,359.56910
Overall Steps per Second: 2,069.63712

Timestep Collection Time: 14.88375
Timestep Consumption Time: 9.27652
PPO Batch Consumption Time: 1.31457
Total Iteration Time: 24.16027

Cumulative Model Updates: 5,502
Cumulative Timesteps: 45,902,012

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 45902012...
Checkpoint 45902012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.47519
Policy Entropy: 1.40196
Value Function Loss: 0.20786

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 0.08265
Value Function Update Magnitude: 0.11130

Collected Steps per Second: 3,338.01045
Overall Steps per Second: 2,092.24537

Timestep Collection Time: 14.98018
Timestep Consumption Time: 8.91950
PPO Batch Consumption Time: 1.25452
Total Iteration Time: 23.89968

Cumulative Model Updates: 5,508
Cumulative Timesteps: 45,952,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.21355
Policy Entropy: 1.40223
Value Function Loss: 0.20683

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.09299
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 3,357.76099
Overall Steps per Second: 2,061.02322

Timestep Collection Time: 14.89207
Timestep Consumption Time: 9.36967
PPO Batch Consumption Time: 1.31205
Total Iteration Time: 24.26174

Cumulative Model Updates: 5,514
Cumulative Timesteps: 46,002,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 46002020...
Checkpoint 46002020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.03449
Policy Entropy: 1.39890
Value Function Loss: 0.20781

Mean KL Divergence: 0.02961
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.11104
Value Function Update Magnitude: 0.11027

Collected Steps per Second: 3,327.47926
Overall Steps per Second: 2,053.10450

Timestep Collection Time: 15.02759
Timestep Consumption Time: 9.32772
PPO Batch Consumption Time: 1.30655
Total Iteration Time: 24.35531

Cumulative Model Updates: 5,520
Cumulative Timesteps: 46,052,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.18759
Policy Entropy: 1.40146
Value Function Loss: 0.21070

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.08421
Value Function Update Magnitude: 0.11238

Collected Steps per Second: 3,332.48718
Overall Steps per Second: 2,049.94169

Timestep Collection Time: 15.00441
Timestep Consumption Time: 9.38750
PPO Batch Consumption Time: 1.32101
Total Iteration Time: 24.39191

Cumulative Model Updates: 5,526
Cumulative Timesteps: 46,102,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 46102026...
Checkpoint 46102026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.60738
Policy Entropy: 1.40125
Value Function Loss: 0.20760

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.08535
Value Function Update Magnitude: 0.11286

Collected Steps per Second: 3,344.66266
Overall Steps per Second: 2,065.27553

Timestep Collection Time: 14.94979
Timestep Consumption Time: 9.26102
PPO Batch Consumption Time: 1.30937
Total Iteration Time: 24.21081

Cumulative Model Updates: 5,532
Cumulative Timesteps: 46,152,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.54102
Policy Entropy: 1.39733
Value Function Loss: 0.21550

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.08433
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 3,346.40869
Overall Steps per Second: 2,068.30873

Timestep Collection Time: 14.94139
Timestep Consumption Time: 9.23295
PPO Batch Consumption Time: 1.28859
Total Iteration Time: 24.17434

Cumulative Model Updates: 5,538
Cumulative Timesteps: 46,202,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 46202028...
Checkpoint 46202028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.53467
Policy Entropy: 1.40216
Value Function Loss: 0.20388

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.08666
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 3,329.94853
Overall Steps per Second: 2,069.99276

Timestep Collection Time: 15.01555
Timestep Consumption Time: 9.13961
PPO Batch Consumption Time: 1.28928
Total Iteration Time: 24.15516

Cumulative Model Updates: 5,544
Cumulative Timesteps: 46,252,029

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.40722
Policy Entropy: 1.39927
Value Function Loss: 0.21208

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.09235
Value Function Update Magnitude: 0.10800

Collected Steps per Second: 3,297.98278
Overall Steps per Second: 2,036.26497

Timestep Collection Time: 15.16200
Timestep Consumption Time: 9.39473
PPO Batch Consumption Time: 1.33343
Total Iteration Time: 24.55673

Cumulative Model Updates: 5,550
Cumulative Timesteps: 46,302,033

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 46302033...
Checkpoint 46302033 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.82417
Policy Entropy: 1.39919
Value Function Loss: 0.21115

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.05474
Policy Update Magnitude: 0.08675
Value Function Update Magnitude: 0.10723

Collected Steps per Second: 3,364.11829
Overall Steps per Second: 2,060.60040

Timestep Collection Time: 14.86392
Timestep Consumption Time: 9.40279
PPO Batch Consumption Time: 1.31878
Total Iteration Time: 24.26671

Cumulative Model Updates: 5,556
Cumulative Timesteps: 46,352,037

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.38644
Policy Entropy: 1.39761
Value Function Loss: 0.21463

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.04451
Policy Update Magnitude: 0.08649
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 3,356.17388
Overall Steps per Second: 2,029.51454

Timestep Collection Time: 14.89881
Timestep Consumption Time: 9.73910
PPO Batch Consumption Time: 1.37678
Total Iteration Time: 24.63791

Cumulative Model Updates: 5,562
Cumulative Timesteps: 46,402,040

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 46402040...
Checkpoint 46402040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.93111
Policy Entropy: 1.39654
Value Function Loss: 0.21298

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.04434
Policy Update Magnitude: 0.08492
Value Function Update Magnitude: 0.11431

Collected Steps per Second: 3,373.17230
Overall Steps per Second: 2,065.65899

Timestep Collection Time: 14.82284
Timestep Consumption Time: 9.38251
PPO Batch Consumption Time: 1.32303
Total Iteration Time: 24.20535

Cumulative Model Updates: 5,568
Cumulative Timesteps: 46,452,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.17011
Policy Entropy: 1.39524
Value Function Loss: 0.21314

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.03851
Policy Update Magnitude: 0.08284
Value Function Update Magnitude: 0.11485

Collected Steps per Second: 3,341.50934
Overall Steps per Second: 2,050.54549

Timestep Collection Time: 14.96330
Timestep Consumption Time: 9.42046
PPO Batch Consumption Time: 1.32708
Total Iteration Time: 24.38376

Cumulative Model Updates: 5,574
Cumulative Timesteps: 46,502,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 46502040...
Checkpoint 46502040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.50132
Policy Entropy: 1.39436
Value Function Loss: 0.22008

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.04041
Policy Update Magnitude: 0.08683
Value Function Update Magnitude: 0.10633

Collected Steps per Second: 3,291.14548
Overall Steps per Second: 2,044.63315

Timestep Collection Time: 15.19289
Timestep Consumption Time: 9.26236
PPO Batch Consumption Time: 1.30949
Total Iteration Time: 24.45524

Cumulative Model Updates: 5,580
Cumulative Timesteps: 46,552,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.20537
Policy Entropy: 1.39192
Value Function Loss: 0.22411

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.06462
Policy Update Magnitude: 0.08555
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 3,314.37621
Overall Steps per Second: 2,046.86175

Timestep Collection Time: 15.08640
Timestep Consumption Time: 9.34222
PPO Batch Consumption Time: 1.31730
Total Iteration Time: 24.42862

Cumulative Model Updates: 5,586
Cumulative Timesteps: 46,602,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 46602044...
Checkpoint 46602044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.06265
Policy Entropy: 1.38996
Value Function Loss: 0.22587

Mean KL Divergence: 0.02104
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.08049
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 3,328.66902
Overall Steps per Second: 2,050.47963

Timestep Collection Time: 15.02192
Timestep Consumption Time: 9.36408
PPO Batch Consumption Time: 1.33584
Total Iteration Time: 24.38600

Cumulative Model Updates: 5,592
Cumulative Timesteps: 46,652,047

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.01134
Policy Entropy: 1.39109
Value Function Loss: 0.22329

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.07368
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 3,369.42931
Overall Steps per Second: 2,060.65772

Timestep Collection Time: 14.83931
Timestep Consumption Time: 9.42479
PPO Batch Consumption Time: 1.33509
Total Iteration Time: 24.26410

Cumulative Model Updates: 5,598
Cumulative Timesteps: 46,702,047

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 46702047...
Checkpoint 46702047 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.13060
Policy Entropy: 1.38676
Value Function Loss: 0.21738

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.05444
Policy Update Magnitude: 0.08750
Value Function Update Magnitude: 0.11608

Collected Steps per Second: 3,338.57142
Overall Steps per Second: 2,061.30697

Timestep Collection Time: 14.97736
Timestep Consumption Time: 9.28055
PPO Batch Consumption Time: 1.29615
Total Iteration Time: 24.25791

Cumulative Model Updates: 5,604
Cumulative Timesteps: 46,752,050

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.44070
Policy Entropy: 1.38468
Value Function Loss: 0.21254

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.06812
Policy Update Magnitude: 0.08909
Value Function Update Magnitude: 0.11147

Collected Steps per Second: 3,308.50796
Overall Steps per Second: 2,047.20166

Timestep Collection Time: 15.11285
Timestep Consumption Time: 9.31122
PPO Batch Consumption Time: 1.32259
Total Iteration Time: 24.42407

Cumulative Model Updates: 5,610
Cumulative Timesteps: 46,802,051

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 46802051...
Checkpoint 46802051 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.68744
Policy Entropy: 1.38611
Value Function Loss: 0.21746

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.08242
Value Function Update Magnitude: 0.11312

Collected Steps per Second: 3,357.33883
Overall Steps per Second: 2,058.22283

Timestep Collection Time: 14.89394
Timestep Consumption Time: 9.40081
PPO Batch Consumption Time: 1.33341
Total Iteration Time: 24.29475

Cumulative Model Updates: 5,616
Cumulative Timesteps: 46,852,055

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.19172
Policy Entropy: 1.38596
Value Function Loss: 0.21693

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.08518
Value Function Update Magnitude: 0.11574

Collected Steps per Second: 3,367.88485
Overall Steps per Second: 2,054.90409

Timestep Collection Time: 14.84611
Timestep Consumption Time: 9.48592
PPO Batch Consumption Time: 1.32027
Total Iteration Time: 24.33204

Cumulative Model Updates: 5,622
Cumulative Timesteps: 46,902,055

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 46902055...
Checkpoint 46902055 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.33767
Policy Entropy: 1.39082
Value Function Loss: 0.21626

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.07283
Policy Update Magnitude: 0.08289
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 3,382.43477
Overall Steps per Second: 2,067.19516

Timestep Collection Time: 14.78255
Timestep Consumption Time: 9.40530
PPO Batch Consumption Time: 1.31776
Total Iteration Time: 24.18785

Cumulative Model Updates: 5,628
Cumulative Timesteps: 46,952,056

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.26469
Policy Entropy: 1.38691
Value Function Loss: 0.20924

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.08566
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 3,373.46982
Overall Steps per Second: 2,076.27802

Timestep Collection Time: 14.82153
Timestep Consumption Time: 9.26002
PPO Batch Consumption Time: 1.30167
Total Iteration Time: 24.08155

Cumulative Model Updates: 5,634
Cumulative Timesteps: 47,002,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 47002056...
Checkpoint 47002056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.15384
Policy Entropy: 1.38645
Value Function Loss: 0.21005

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.08619
Value Function Update Magnitude: 0.12260

Collected Steps per Second: 3,310.94159
Overall Steps per Second: 2,051.17823

Timestep Collection Time: 15.10144
Timestep Consumption Time: 9.27479
PPO Batch Consumption Time: 1.29552
Total Iteration Time: 24.37623

Cumulative Model Updates: 5,640
Cumulative Timesteps: 47,052,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.74374
Policy Entropy: 1.38711
Value Function Loss: 0.21166

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.08536
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 3,366.62763
Overall Steps per Second: 2,070.15715

Timestep Collection Time: 14.85195
Timestep Consumption Time: 9.30128
PPO Batch Consumption Time: 1.31756
Total Iteration Time: 24.15324

Cumulative Model Updates: 5,646
Cumulative Timesteps: 47,102,057

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 47102057...
Checkpoint 47102057 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.82483
Policy Entropy: 1.38654
Value Function Loss: 0.21233

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.09298
Value Function Update Magnitude: 0.11782

Collected Steps per Second: 3,350.89479
Overall Steps per Second: 2,057.31792

Timestep Collection Time: 14.92258
Timestep Consumption Time: 9.38285
PPO Batch Consumption Time: 1.32013
Total Iteration Time: 24.30543

Cumulative Model Updates: 5,652
Cumulative Timesteps: 47,152,061

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.00076
Policy Entropy: 1.38433
Value Function Loss: 0.21591

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.08730
Value Function Update Magnitude: 0.10861

Collected Steps per Second: 3,408.36896
Overall Steps per Second: 2,087.92311

Timestep Collection Time: 14.66977
Timestep Consumption Time: 9.27747
PPO Batch Consumption Time: 1.31124
Total Iteration Time: 23.94724

Cumulative Model Updates: 5,658
Cumulative Timesteps: 47,202,061

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 47202061...
Checkpoint 47202061 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.73874
Policy Entropy: 1.38126
Value Function Loss: 0.21615

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.09251
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 3,327.57787
Overall Steps per Second: 2,057.81190

Timestep Collection Time: 15.02655
Timestep Consumption Time: 9.27208
PPO Batch Consumption Time: 1.30287
Total Iteration Time: 24.29863

Cumulative Model Updates: 5,664
Cumulative Timesteps: 47,252,063

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.40395
Policy Entropy: 1.38041
Value Function Loss: 0.21727

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.09749
Value Function Update Magnitude: 0.12168

Collected Steps per Second: 3,291.35656
Overall Steps per Second: 2,038.15872

Timestep Collection Time: 15.19161
Timestep Consumption Time: 9.34083
PPO Batch Consumption Time: 1.32869
Total Iteration Time: 24.53244

Cumulative Model Updates: 5,670
Cumulative Timesteps: 47,302,064

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 47302064...
Checkpoint 47302064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.18505
Policy Entropy: 1.37932
Value Function Loss: 0.22131

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.08938
Value Function Update Magnitude: 0.14001

Collected Steps per Second: 3,329.25516
Overall Steps per Second: 2,057.60004

Timestep Collection Time: 15.01897
Timestep Consumption Time: 9.28215
PPO Batch Consumption Time: 1.30159
Total Iteration Time: 24.30113

Cumulative Model Updates: 5,676
Cumulative Timesteps: 47,352,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.40962
Policy Entropy: 1.37740
Value Function Loss: 0.21775

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.09117
Value Function Update Magnitude: 0.14118

Collected Steps per Second: 3,291.25974
Overall Steps per Second: 2,037.80025

Timestep Collection Time: 15.19297
Timestep Consumption Time: 9.34526
PPO Batch Consumption Time: 1.31211
Total Iteration Time: 24.53822

Cumulative Model Updates: 5,682
Cumulative Timesteps: 47,402,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 47402070...
Checkpoint 47402070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.00741
Policy Entropy: 1.37362
Value Function Loss: 0.22343

Mean KL Divergence: 0.03354
SB3 Clip Fraction: 0.16865
Policy Update Magnitude: 0.08766
Value Function Update Magnitude: 0.15290

Collected Steps per Second: 3,363.22746
Overall Steps per Second: 2,078.06043

Timestep Collection Time: 14.86697
Timestep Consumption Time: 9.19441
PPO Batch Consumption Time: 1.28380
Total Iteration Time: 24.06138

Cumulative Model Updates: 5,688
Cumulative Timesteps: 47,452,071

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.75619
Policy Entropy: 1.37689
Value Function Loss: 0.21938

Mean KL Divergence: 0.03283
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.07814
Value Function Update Magnitude: 0.14972

Collected Steps per Second: 3,333.16456
Overall Steps per Second: 2,052.54921

Timestep Collection Time: 15.00076
Timestep Consumption Time: 9.35919
PPO Batch Consumption Time: 1.32589
Total Iteration Time: 24.35995

Cumulative Model Updates: 5,694
Cumulative Timesteps: 47,502,071

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 47502071...
Checkpoint 47502071 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.29545
Policy Entropy: 1.37953
Value Function Loss: 0.22440

Mean KL Divergence: 0.02941
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.13821

Collected Steps per Second: 3,348.59850
Overall Steps per Second: 2,097.21203

Timestep Collection Time: 14.93162
Timestep Consumption Time: 8.90956
PPO Batch Consumption Time: 1.25164
Total Iteration Time: 23.84118

Cumulative Model Updates: 5,700
Cumulative Timesteps: 47,552,071

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.84810
Policy Entropy: 1.37992
Value Function Loss: 0.22488

Mean KL Divergence: 0.02993
SB3 Clip Fraction: 0.15946
Policy Update Magnitude: 0.07417
Value Function Update Magnitude: 0.14142

Collected Steps per Second: 3,335.70396
Overall Steps per Second: 2,050.24238

Timestep Collection Time: 14.99054
Timestep Consumption Time: 9.39877
PPO Batch Consumption Time: 1.33887
Total Iteration Time: 24.38931

Cumulative Model Updates: 5,706
Cumulative Timesteps: 47,602,075

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 47602075...
Checkpoint 47602075 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.28272
Policy Entropy: 1.38327
Value Function Loss: 0.22608

Mean KL Divergence: 0.02358
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.07265
Value Function Update Magnitude: 0.14171

Collected Steps per Second: 3,354.92108
Overall Steps per Second: 2,061.81844

Timestep Collection Time: 14.90378
Timestep Consumption Time: 9.34714
PPO Batch Consumption Time: 1.32025
Total Iteration Time: 24.25092

Cumulative Model Updates: 5,712
Cumulative Timesteps: 47,652,076

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.88275
Policy Entropy: 1.38679
Value Function Loss: 0.22349

Mean KL Divergence: 0.01884
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.07561
Value Function Update Magnitude: 0.15880

Collected Steps per Second: 3,360.34904
Overall Steps per Second: 2,065.01500

Timestep Collection Time: 14.87941
Timestep Consumption Time: 9.33349
PPO Batch Consumption Time: 1.31117
Total Iteration Time: 24.21290

Cumulative Model Updates: 5,718
Cumulative Timesteps: 47,702,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 47702076...
Checkpoint 47702076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.70622
Policy Entropy: 1.38687
Value Function Loss: 0.22267

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.08091
Value Function Update Magnitude: 0.14388

Collected Steps per Second: 3,302.79888
Overall Steps per Second: 2,050.25887

Timestep Collection Time: 15.13928
Timestep Consumption Time: 9.24886
PPO Batch Consumption Time: 1.31082
Total Iteration Time: 24.38814

Cumulative Model Updates: 5,724
Cumulative Timesteps: 47,752,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.69915
Policy Entropy: 1.38938
Value Function Loss: 0.21436

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.11471
Policy Update Magnitude: 0.08095
Value Function Update Magnitude: 0.12194

Collected Steps per Second: 3,327.02737
Overall Steps per Second: 2,056.12405

Timestep Collection Time: 15.02843
Timestep Consumption Time: 9.28917
PPO Batch Consumption Time: 1.31988
Total Iteration Time: 24.31760

Cumulative Model Updates: 5,730
Cumulative Timesteps: 47,802,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 47802078...
Checkpoint 47802078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.56973
Policy Entropy: 1.38963
Value Function Loss: 0.21293

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.08128
Value Function Update Magnitude: 0.12199

Collected Steps per Second: 3,355.42415
Overall Steps per Second: 2,056.09640

Timestep Collection Time: 14.90244
Timestep Consumption Time: 9.41743
PPO Batch Consumption Time: 1.32244
Total Iteration Time: 24.31987

Cumulative Model Updates: 5,736
Cumulative Timesteps: 47,852,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.48880
Policy Entropy: 1.38974
Value Function Loss: 0.21465

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.08167
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 3,354.88713
Overall Steps per Second: 2,058.71089

Timestep Collection Time: 14.90423
Timestep Consumption Time: 9.38379
PPO Batch Consumption Time: 1.31522
Total Iteration Time: 24.28801

Cumulative Model Updates: 5,742
Cumulative Timesteps: 47,902,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 47902084...
Checkpoint 47902084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.38874
Policy Entropy: 1.38727
Value Function Loss: 0.22304

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.08355
Value Function Update Magnitude: 0.11539

Collected Steps per Second: 3,341.32680
Overall Steps per Second: 2,065.96898

Timestep Collection Time: 14.96501
Timestep Consumption Time: 9.23816
PPO Batch Consumption Time: 1.31230
Total Iteration Time: 24.20317

Cumulative Model Updates: 5,748
Cumulative Timesteps: 47,952,087

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.80603
Policy Entropy: 1.38435
Value Function Loss: 0.23446

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.09302
Value Function Update Magnitude: 0.11598

Collected Steps per Second: 3,327.18405
Overall Steps per Second: 2,064.60505

Timestep Collection Time: 15.02862
Timestep Consumption Time: 9.19054
PPO Batch Consumption Time: 1.28462
Total Iteration Time: 24.21916

Cumulative Model Updates: 5,754
Cumulative Timesteps: 48,002,090

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 48002090...
Checkpoint 48002090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.10943
Policy Entropy: 1.38050
Value Function Loss: 0.23208

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.10976
Value Function Update Magnitude: 0.12659

Collected Steps per Second: 3,373.76681
Overall Steps per Second: 2,078.27135

Timestep Collection Time: 14.82142
Timestep Consumption Time: 9.23897
PPO Batch Consumption Time: 1.30258
Total Iteration Time: 24.06038

Cumulative Model Updates: 5,760
Cumulative Timesteps: 48,052,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.59036
Policy Entropy: 1.37582
Value Function Loss: 0.22969

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.11142
Value Function Update Magnitude: 0.12167

Collected Steps per Second: 3,377.33396
Overall Steps per Second: 2,065.18843

Timestep Collection Time: 14.80487
Timestep Consumption Time: 9.40648
PPO Batch Consumption Time: 1.32254
Total Iteration Time: 24.21135

Cumulative Model Updates: 5,766
Cumulative Timesteps: 48,102,095

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 48102095...
Checkpoint 48102095 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.72568
Policy Entropy: 1.37255
Value Function Loss: 0.22370

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.11255
Value Function Update Magnitude: 0.11952

Collected Steps per Second: 3,365.48886
Overall Steps per Second: 2,065.50428

Timestep Collection Time: 14.85698
Timestep Consumption Time: 9.35067
PPO Batch Consumption Time: 1.31509
Total Iteration Time: 24.20765

Cumulative Model Updates: 5,772
Cumulative Timesteps: 48,152,096

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.32605
Policy Entropy: 1.37031
Value Function Loss: 0.22039

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.10941
Value Function Update Magnitude: 0.11367

Collected Steps per Second: 3,344.11153
Overall Steps per Second: 2,068.40044

Timestep Collection Time: 14.95225
Timestep Consumption Time: 9.22198
PPO Batch Consumption Time: 1.29882
Total Iteration Time: 24.17424

Cumulative Model Updates: 5,778
Cumulative Timesteps: 48,202,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 48202098...
Checkpoint 48202098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.38532
Policy Entropy: 1.36972
Value Function Loss: 0.22164

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.10805
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 3,361.39861
Overall Steps per Second: 2,065.71410

Timestep Collection Time: 14.87506
Timestep Consumption Time: 9.33013
PPO Batch Consumption Time: 1.29310
Total Iteration Time: 24.20519

Cumulative Model Updates: 5,784
Cumulative Timesteps: 48,252,099

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.61521
Policy Entropy: 1.36486
Value Function Loss: 0.22086

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.11366
Value Function Update Magnitude: 0.12225

Collected Steps per Second: 3,376.75465
Overall Steps per Second: 2,079.90374

Timestep Collection Time: 14.80830
Timestep Consumption Time: 9.23320
PPO Batch Consumption Time: 1.29570
Total Iteration Time: 24.04150

Cumulative Model Updates: 5,790
Cumulative Timesteps: 48,302,103

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48302103...
Checkpoint 48302103 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.60216
Policy Entropy: 1.36235
Value Function Loss: 0.22947

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.11270
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 3,368.42128
Overall Steps per Second: 2,071.12455

Timestep Collection Time: 14.84494
Timestep Consumption Time: 9.29847
PPO Batch Consumption Time: 1.32246
Total Iteration Time: 24.14341

Cumulative Model Updates: 5,796
Cumulative Timesteps: 48,352,107

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.69021
Policy Entropy: 1.35380
Value Function Loss: 0.23120

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.11658
Value Function Update Magnitude: 0.12518

Collected Steps per Second: 3,369.99802
Overall Steps per Second: 2,072.66216

Timestep Collection Time: 14.83799
Timestep Consumption Time: 9.28750
PPO Batch Consumption Time: 1.31688
Total Iteration Time: 24.12549

Cumulative Model Updates: 5,802
Cumulative Timesteps: 48,402,111

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48402111...
Checkpoint 48402111 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.23241
Policy Entropy: 1.35122
Value Function Loss: 0.22981

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.13006
Value Function Update Magnitude: 0.12912

Collected Steps per Second: 3,390.92680
Overall Steps per Second: 2,111.13989

Timestep Collection Time: 14.74553
Timestep Consumption Time: 8.93884
PPO Batch Consumption Time: 1.25855
Total Iteration Time: 23.68436

Cumulative Model Updates: 5,808
Cumulative Timesteps: 48,452,112

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.07746
Policy Entropy: 1.34509
Value Function Loss: 0.22081

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.15021
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 3,343.68993
Overall Steps per Second: 2,054.42217

Timestep Collection Time: 14.95444
Timestep Consumption Time: 9.38477
PPO Batch Consumption Time: 1.33000
Total Iteration Time: 24.33920

Cumulative Model Updates: 5,814
Cumulative Timesteps: 48,502,115

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 48502115...
Checkpoint 48502115 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.48288
Policy Entropy: 1.34253
Value Function Loss: 0.20964

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.16389
Value Function Update Magnitude: 0.12627

Collected Steps per Second: 3,339.84368
Overall Steps per Second: 2,059.14612

Timestep Collection Time: 14.97136
Timestep Consumption Time: 9.31152
PPO Batch Consumption Time: 1.30280
Total Iteration Time: 24.28288

Cumulative Model Updates: 5,820
Cumulative Timesteps: 48,552,117

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.54485
Policy Entropy: 1.33745
Value Function Loss: 0.21245

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.16416
Value Function Update Magnitude: 0.11745

Collected Steps per Second: 3,376.74587
Overall Steps per Second: 2,064.22956

Timestep Collection Time: 14.80804
Timestep Consumption Time: 9.41552
PPO Batch Consumption Time: 1.32590
Total Iteration Time: 24.22357

Cumulative Model Updates: 5,826
Cumulative Timesteps: 48,602,120

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 48602120...
Checkpoint 48602120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.53789
Policy Entropy: 1.32872
Value Function Loss: 0.21351

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.15499
Value Function Update Magnitude: 0.11373

Collected Steps per Second: 3,352.48212
Overall Steps per Second: 2,075.16530

Timestep Collection Time: 14.91552
Timestep Consumption Time: 9.18088
PPO Batch Consumption Time: 1.29970
Total Iteration Time: 24.09639

Cumulative Model Updates: 5,832
Cumulative Timesteps: 48,652,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.66768
Policy Entropy: 1.32574
Value Function Loss: 0.22248

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.13963
Value Function Update Magnitude: 0.11986

Collected Steps per Second: 3,351.35070
Overall Steps per Second: 2,068.57260

Timestep Collection Time: 14.92055
Timestep Consumption Time: 9.25264
PPO Batch Consumption Time: 1.28999
Total Iteration Time: 24.17319

Cumulative Model Updates: 5,838
Cumulative Timesteps: 48,702,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48702128...
Checkpoint 48702128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.37298
Policy Entropy: 1.31767
Value Function Loss: 0.22040

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.15955
Policy Update Magnitude: 0.12663
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 3,313.64523
Overall Steps per Second: 2,049.91027

Timestep Collection Time: 15.09033
Timestep Consumption Time: 9.30293
PPO Batch Consumption Time: 1.30270
Total Iteration Time: 24.39326

Cumulative Model Updates: 5,844
Cumulative Timesteps: 48,752,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.03506
Policy Entropy: 1.30789
Value Function Loss: 0.22403

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.16172
Policy Update Magnitude: 0.12875
Value Function Update Magnitude: 0.12663

Collected Steps per Second: 3,350.86061
Overall Steps per Second: 2,050.90918

Timestep Collection Time: 14.92244
Timestep Consumption Time: 9.45846
PPO Batch Consumption Time: 1.32483
Total Iteration Time: 24.38089

Cumulative Model Updates: 5,850
Cumulative Timesteps: 48,802,135

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 48802135...
Checkpoint 48802135 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.33417
Policy Entropy: 1.29365
Value Function Loss: 0.22184

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15441
Policy Update Magnitude: 0.13124
Value Function Update Magnitude: 0.12310

Collected Steps per Second: 3,312.78971
Overall Steps per Second: 2,048.80371

Timestep Collection Time: 15.09302
Timestep Consumption Time: 9.31147
PPO Batch Consumption Time: 1.31863
Total Iteration Time: 24.40449

Cumulative Model Updates: 5,856
Cumulative Timesteps: 48,852,135

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.62814
Policy Entropy: 1.29069
Value Function Loss: 0.22267

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.14147
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 3,364.75465
Overall Steps per Second: 2,072.50165

Timestep Collection Time: 14.86022
Timestep Consumption Time: 9.26569
PPO Batch Consumption Time: 1.29294
Total Iteration Time: 24.12592

Cumulative Model Updates: 5,862
Cumulative Timesteps: 48,902,136

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 48902136...
Checkpoint 48902136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.71207
Policy Entropy: 1.27926
Value Function Loss: 0.22151

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.15432
Value Function Update Magnitude: 0.11927

Collected Steps per Second: 3,337.72536
Overall Steps per Second: 2,076.01998

Timestep Collection Time: 14.98026
Timestep Consumption Time: 9.10428
PPO Batch Consumption Time: 1.28510
Total Iteration Time: 24.08455

Cumulative Model Updates: 5,868
Cumulative Timesteps: 48,952,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.21262
Policy Entropy: 1.27131
Value Function Loss: 0.22878

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.15222
Value Function Update Magnitude: 0.11773

Collected Steps per Second: 3,318.06470
Overall Steps per Second: 2,056.24649

Timestep Collection Time: 15.06963
Timestep Consumption Time: 9.24750
PPO Batch Consumption Time: 1.29561
Total Iteration Time: 24.31712

Cumulative Model Updates: 5,874
Cumulative Timesteps: 49,002,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 49002138...
Checkpoint 49002138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.48025
Policy Entropy: 1.25480
Value Function Loss: 0.22313

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.22350
Policy Update Magnitude: 0.14276
Value Function Update Magnitude: 0.11680

Collected Steps per Second: 3,335.25718
Overall Steps per Second: 2,064.53681

Timestep Collection Time: 14.99165
Timestep Consumption Time: 9.22734
PPO Batch Consumption Time: 1.30239
Total Iteration Time: 24.21899

Cumulative Model Updates: 5,880
Cumulative Timesteps: 49,052,139

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.70981
Policy Entropy: 1.24737
Value Function Loss: 0.22509

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.23730
Policy Update Magnitude: 0.12285
Value Function Update Magnitude: 0.11631

Collected Steps per Second: 3,346.11749
Overall Steps per Second: 2,037.33965

Timestep Collection Time: 14.94269
Timestep Consumption Time: 9.59912
PPO Batch Consumption Time: 1.35514
Total Iteration Time: 24.54181

Cumulative Model Updates: 5,886
Cumulative Timesteps: 49,102,139

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 49102139...
Checkpoint 49102139 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.73976
Policy Entropy: 1.22428
Value Function Loss: 0.22272

Mean KL Divergence: 0.02324
SB3 Clip Fraction: 0.24344
Policy Update Magnitude: 0.12913
Value Function Update Magnitude: 0.10800

Collected Steps per Second: 3,352.20525
Overall Steps per Second: 2,074.52422

Timestep Collection Time: 14.91615
Timestep Consumption Time: 9.18672
PPO Batch Consumption Time: 1.29288
Total Iteration Time: 24.10288

Cumulative Model Updates: 5,892
Cumulative Timesteps: 49,152,141

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.79870
Policy Entropy: 1.23060
Value Function Loss: 0.22951

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.20912
Policy Update Magnitude: 0.11358
Value Function Update Magnitude: 0.11281

Collected Steps per Second: 3,298.51549
Overall Steps per Second: 2,034.75421

Timestep Collection Time: 15.15864
Timestep Consumption Time: 9.41485
PPO Batch Consumption Time: 1.33166
Total Iteration Time: 24.57348

Cumulative Model Updates: 5,898
Cumulative Timesteps: 49,202,142

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 49202142...
Checkpoint 49202142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.88629
Policy Entropy: 1.20405
Value Function Loss: 0.21932

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.23342
Policy Update Magnitude: 0.11418
Value Function Update Magnitude: 0.11178

Collected Steps per Second: 3,277.73129
Overall Steps per Second: 2,036.47413

Timestep Collection Time: 15.25567
Timestep Consumption Time: 9.29853
PPO Batch Consumption Time: 1.30052
Total Iteration Time: 24.55420

Cumulative Model Updates: 5,904
Cumulative Timesteps: 49,252,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.97191
Policy Entropy: 1.20423
Value Function Loss: 0.21206

Mean KL Divergence: 0.01845
SB3 Clip Fraction: 0.19622
Policy Update Magnitude: 0.11095
Value Function Update Magnitude: 0.11898

Collected Steps per Second: 3,369.79314
Overall Steps per Second: 2,070.58964

Timestep Collection Time: 14.83800
Timestep Consumption Time: 9.31019
PPO Batch Consumption Time: 1.30862
Total Iteration Time: 24.14819

Cumulative Model Updates: 5,910
Cumulative Timesteps: 49,302,147

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 49302147...
Checkpoint 49302147 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.90728
Policy Entropy: 1.18831
Value Function Loss: 0.20377

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.18632
Policy Update Magnitude: 0.10764
Value Function Update Magnitude: 0.12481

Collected Steps per Second: 3,346.53301
Overall Steps per Second: 2,071.02618

Timestep Collection Time: 14.94203
Timestep Consumption Time: 9.20252
PPO Batch Consumption Time: 1.29204
Total Iteration Time: 24.14455

Cumulative Model Updates: 5,916
Cumulative Timesteps: 49,352,151

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.48157
Policy Entropy: 1.18278
Value Function Loss: 0.21048

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.12970
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 3,278.39825
Overall Steps per Second: 2,042.88561

Timestep Collection Time: 15.25166
Timestep Consumption Time: 9.22402
PPO Batch Consumption Time: 1.30165
Total Iteration Time: 24.47567

Cumulative Model Updates: 5,922
Cumulative Timesteps: 49,402,152

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 49402152...
Checkpoint 49402152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.45330
Policy Entropy: 1.17218
Value Function Loss: 0.21913

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.17182
Policy Update Magnitude: 0.14099
Value Function Update Magnitude: 0.12311

Collected Steps per Second: 3,317.87121
Overall Steps per Second: 2,065.03293

Timestep Collection Time: 15.07051
Timestep Consumption Time: 9.14315
PPO Batch Consumption Time: 1.28120
Total Iteration Time: 24.21366

Cumulative Model Updates: 5,928
Cumulative Timesteps: 49,452,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.87407
Policy Entropy: 1.16307
Value Function Loss: 0.21983

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.22728
Policy Update Magnitude: 0.12207
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 3,343.28549
Overall Steps per Second: 2,072.26975

Timestep Collection Time: 14.95595
Timestep Consumption Time: 9.17315
PPO Batch Consumption Time: 1.29629
Total Iteration Time: 24.12910

Cumulative Model Updates: 5,934
Cumulative Timesteps: 49,502,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 49502156...
Checkpoint 49502156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.15776
Policy Entropy: 1.16141
Value Function Loss: 0.22565

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.21533
Policy Update Magnitude: 0.11812
Value Function Update Magnitude: 0.12036

Collected Steps per Second: 3,358.89723
Overall Steps per Second: 2,081.09769

Timestep Collection Time: 14.88584
Timestep Consumption Time: 9.13994
PPO Batch Consumption Time: 1.27044
Total Iteration Time: 24.02578

Cumulative Model Updates: 5,940
Cumulative Timesteps: 49,552,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.00932
Policy Entropy: 1.14662
Value Function Loss: 0.22202

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.23840
Policy Update Magnitude: 0.12702
Value Function Update Magnitude: 0.11434

Collected Steps per Second: 3,325.05649
Overall Steps per Second: 2,061.89917

Timestep Collection Time: 15.03794
Timestep Consumption Time: 9.21252
PPO Batch Consumption Time: 1.29211
Total Iteration Time: 24.25046

Cumulative Model Updates: 5,946
Cumulative Timesteps: 49,602,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 49602158...
Checkpoint 49602158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.38870
Policy Entropy: 1.14217
Value Function Loss: 0.22391

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.19655
Policy Update Magnitude: 0.12521
Value Function Update Magnitude: 0.10752

Collected Steps per Second: 3,310.96354
Overall Steps per Second: 2,068.08052

Timestep Collection Time: 15.10134
Timestep Consumption Time: 9.07566
PPO Batch Consumption Time: 1.28023
Total Iteration Time: 24.17701

Cumulative Model Updates: 5,952
Cumulative Timesteps: 49,652,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.90771
Policy Entropy: 1.11854
Value Function Loss: 0.21529

Mean KL Divergence: 0.02110
SB3 Clip Fraction: 0.24035
Policy Update Magnitude: 0.13882
Value Function Update Magnitude: 0.11107

Collected Steps per Second: 3,339.63375
Overall Steps per Second: 2,051.39415

Timestep Collection Time: 14.97230
Timestep Consumption Time: 9.40234
PPO Batch Consumption Time: 1.32097
Total Iteration Time: 24.37464

Cumulative Model Updates: 5,958
Cumulative Timesteps: 49,702,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 49702160...
Checkpoint 49702160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.53544
Policy Entropy: 1.11998
Value Function Loss: 0.21862

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.24269
Policy Update Magnitude: 0.13098
Value Function Update Magnitude: 0.12144

Collected Steps per Second: 3,351.07844
Overall Steps per Second: 2,079.24312

Timestep Collection Time: 14.92087
Timestep Consumption Time: 9.12682
PPO Batch Consumption Time: 1.28756
Total Iteration Time: 24.04769

Cumulative Model Updates: 5,964
Cumulative Timesteps: 49,752,161

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.44856
Policy Entropy: 1.10297
Value Function Loss: 0.21602

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.20940
Policy Update Magnitude: 0.12477
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 3,368.93712
Overall Steps per Second: 2,057.60102

Timestep Collection Time: 14.84266
Timestep Consumption Time: 9.45942
PPO Batch Consumption Time: 1.32560
Total Iteration Time: 24.30209

Cumulative Model Updates: 5,970
Cumulative Timesteps: 49,802,165

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 49802165...
Checkpoint 49802165 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.77806
Policy Entropy: 1.09160
Value Function Loss: 0.22259

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.23774
Policy Update Magnitude: 0.11301
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 3,319.27708
Overall Steps per Second: 2,046.83138

Timestep Collection Time: 15.06442
Timestep Consumption Time: 9.36504
PPO Batch Consumption Time: 1.31384
Total Iteration Time: 24.42947

Cumulative Model Updates: 5,976
Cumulative Timesteps: 49,852,168

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.04894
Policy Entropy: 1.09616
Value Function Loss: 0.21394

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.21660
Policy Update Magnitude: 0.10952
Value Function Update Magnitude: 0.12253

Collected Steps per Second: 3,355.45944
Overall Steps per Second: 2,072.16502

Timestep Collection Time: 14.90139
Timestep Consumption Time: 9.22845
PPO Batch Consumption Time: 1.29033
Total Iteration Time: 24.12984

Cumulative Model Updates: 5,982
Cumulative Timesteps: 49,902,169

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 49902169...
Checkpoint 49902169 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.69536
Policy Entropy: 1.07426
Value Function Loss: 0.22318

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.20437
Policy Update Magnitude: 0.11781
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 3,336.38608
Overall Steps per Second: 2,066.63492

Timestep Collection Time: 14.98717
Timestep Consumption Time: 9.20820
PPO Batch Consumption Time: 1.29359
Total Iteration Time: 24.19537

Cumulative Model Updates: 5,988
Cumulative Timesteps: 49,952,172

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.80827
Policy Entropy: 1.06526
Value Function Loss: 0.22224

Mean KL Divergence: 0.02172
SB3 Clip Fraction: 0.26595
Policy Update Magnitude: 0.10702
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 3,375.93031
Overall Steps per Second: 2,056.56029

Timestep Collection Time: 14.81132
Timestep Consumption Time: 9.50209
PPO Batch Consumption Time: 1.33537
Total Iteration Time: 24.31341

Cumulative Model Updates: 5,994
Cumulative Timesteps: 50,002,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 50002174...
Checkpoint 50002174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.27385
Policy Entropy: 1.06161
Value Function Loss: 0.22625

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.20431
Policy Update Magnitude: 0.10962
Value Function Update Magnitude: 0.11404

Collected Steps per Second: 3,395.62014
Overall Steps per Second: 2,090.77057

Timestep Collection Time: 14.72573
Timestep Consumption Time: 9.19033
PPO Batch Consumption Time: 1.29557
Total Iteration Time: 23.91606

Cumulative Model Updates: 6,000
Cumulative Timesteps: 50,052,177

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.15963
Policy Entropy: 1.04155
Value Function Loss: 0.21618

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.19843
Policy Update Magnitude: 0.13630
Value Function Update Magnitude: 0.10943

Collected Steps per Second: 3,363.17408
Overall Steps per Second: 2,048.68246

Timestep Collection Time: 14.86691
Timestep Consumption Time: 9.53902
PPO Batch Consumption Time: 1.35421
Total Iteration Time: 24.40593

Cumulative Model Updates: 6,006
Cumulative Timesteps: 50,102,177

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 50102177...
Checkpoint 50102177 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.72332
Policy Entropy: 1.03211
Value Function Loss: 0.20656

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.23104
Policy Update Magnitude: 0.15442
Value Function Update Magnitude: 0.10967

Collected Steps per Second: 3,321.43134
Overall Steps per Second: 2,057.26736

Timestep Collection Time: 15.05465
Timestep Consumption Time: 9.25089
PPO Batch Consumption Time: 1.30761
Total Iteration Time: 24.30554

Cumulative Model Updates: 6,012
Cumulative Timesteps: 50,152,180

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.78486
Policy Entropy: 1.01392
Value Function Loss: 0.20500

Mean KL Divergence: 0.02424
SB3 Clip Fraction: 0.27557
Policy Update Magnitude: 0.13582
Value Function Update Magnitude: 0.11074

Collected Steps per Second: 3,343.53005
Overall Steps per Second: 2,069.10579

Timestep Collection Time: 14.95425
Timestep Consumption Time: 9.21077
PPO Batch Consumption Time: 1.28763
Total Iteration Time: 24.16503

Cumulative Model Updates: 6,018
Cumulative Timesteps: 50,202,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 50202180...
Checkpoint 50202180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.61320
Policy Entropy: 1.01931
Value Function Loss: 0.20740

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.23659
Policy Update Magnitude: 0.10707
Value Function Update Magnitude: 0.11822

Collected Steps per Second: 3,364.45319
Overall Steps per Second: 2,070.26913

Timestep Collection Time: 14.86185
Timestep Consumption Time: 9.29057
PPO Batch Consumption Time: 1.29682
Total Iteration Time: 24.15242

Cumulative Model Updates: 6,024
Cumulative Timesteps: 50,252,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.97552
Policy Entropy: 1.01244
Value Function Loss: 0.21462

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.20100
Policy Update Magnitude: 0.10857
Value Function Update Magnitude: 0.11232

Collected Steps per Second: 3,375.42442
Overall Steps per Second: 2,055.56797

Timestep Collection Time: 14.81443
Timestep Consumption Time: 9.51218
PPO Batch Consumption Time: 1.35700
Total Iteration Time: 24.32661

Cumulative Model Updates: 6,030
Cumulative Timesteps: 50,302,187

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 50302187...
Checkpoint 50302187 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.20749
Policy Entropy: 1.00152
Value Function Loss: 0.22590

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.24246
Policy Update Magnitude: 0.10636
Value Function Update Magnitude: 0.12053

Collected Steps per Second: 3,348.12356
Overall Steps per Second: 2,076.09962

Timestep Collection Time: 14.93493
Timestep Consumption Time: 9.15062
PPO Batch Consumption Time: 1.29499
Total Iteration Time: 24.08555

Cumulative Model Updates: 6,036
Cumulative Timesteps: 50,352,191

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.89297
Policy Entropy: 0.98746
Value Function Loss: 0.22183

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.19091
Policy Update Magnitude: 0.12035
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 3,347.76737
Overall Steps per Second: 2,048.79615

Timestep Collection Time: 14.93622
Timestep Consumption Time: 9.46982
PPO Batch Consumption Time: 1.34239
Total Iteration Time: 24.40604

Cumulative Model Updates: 6,042
Cumulative Timesteps: 50,402,194

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 50402194...
Checkpoint 50402194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.60848
Policy Entropy: 0.98847
Value Function Loss: 0.21859

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.19850
Policy Update Magnitude: 0.12783
Value Function Update Magnitude: 0.11323

Collected Steps per Second: 3,318.44960
Overall Steps per Second: 2,064.70647

Timestep Collection Time: 15.06728
Timestep Consumption Time: 9.14924
PPO Batch Consumption Time: 1.27360
Total Iteration Time: 24.21652

Cumulative Model Updates: 6,048
Cumulative Timesteps: 50,452,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.42216
Policy Entropy: 0.95297
Value Function Loss: 0.21213

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.26556
Policy Update Magnitude: 0.10575
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 3,358.33612
Overall Steps per Second: 2,055.87134

Timestep Collection Time: 14.88922
Timestep Consumption Time: 9.43283
PPO Batch Consumption Time: 1.32308
Total Iteration Time: 24.32205

Cumulative Model Updates: 6,054
Cumulative Timesteps: 50,502,197

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 50502197...
Checkpoint 50502197 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.33943
Policy Entropy: 0.94437
Value Function Loss: 0.22022

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.23115
Policy Update Magnitude: 0.11440
Value Function Update Magnitude: 0.11493

Collected Steps per Second: 3,373.23317
Overall Steps per Second: 2,077.67007

Timestep Collection Time: 14.82376
Timestep Consumption Time: 9.24358
PPO Batch Consumption Time: 1.30311
Total Iteration Time: 24.06734

Cumulative Model Updates: 6,060
Cumulative Timesteps: 50,552,201

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.57818
Policy Entropy: 0.93959
Value Function Loss: 0.22217

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.23263
Policy Update Magnitude: 0.10849
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 3,382.64223
Overall Steps per Second: 2,059.67606

Timestep Collection Time: 14.78164
Timestep Consumption Time: 9.49451
PPO Batch Consumption Time: 1.33742
Total Iteration Time: 24.27615

Cumulative Model Updates: 6,066
Cumulative Timesteps: 50,602,202

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 50602202...
Checkpoint 50602202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.72644
Policy Entropy: 0.91963
Value Function Loss: 0.22408

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.28546
Policy Update Magnitude: 0.09862
Value Function Update Magnitude: 0.11534

Collected Steps per Second: 3,337.43007
Overall Steps per Second: 2,080.01372

Timestep Collection Time: 14.98159
Timestep Consumption Time: 9.05672
PPO Batch Consumption Time: 1.27983
Total Iteration Time: 24.03830

Cumulative Model Updates: 6,072
Cumulative Timesteps: 50,652,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.81802
Policy Entropy: 0.90712
Value Function Loss: 0.22278

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.24914
Policy Update Magnitude: 0.11078
Value Function Update Magnitude: 0.12075

Collected Steps per Second: 3,333.46502
Overall Steps per Second: 2,062.40112

Timestep Collection Time: 15.00001
Timestep Consumption Time: 9.24455
PPO Batch Consumption Time: 1.29308
Total Iteration Time: 24.24456

Cumulative Model Updates: 6,078
Cumulative Timesteps: 50,702,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 50702204...
Checkpoint 50702204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.25809
Policy Entropy: 0.88911
Value Function Loss: 0.21766

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.28231
Policy Update Magnitude: 0.10363
Value Function Update Magnitude: 0.12390

Collected Steps per Second: 3,339.48027
Overall Steps per Second: 2,050.26727

Timestep Collection Time: 14.97359
Timestep Consumption Time: 9.41543
PPO Batch Consumption Time: 1.33541
Total Iteration Time: 24.38902

Cumulative Model Updates: 6,084
Cumulative Timesteps: 50,752,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.12606
Policy Entropy: 0.88851
Value Function Loss: 0.21938

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.21565
Policy Update Magnitude: 0.10682
Value Function Update Magnitude: 0.11833

Collected Steps per Second: 3,373.57857
Overall Steps per Second: 2,059.92975

Timestep Collection Time: 14.82224
Timestep Consumption Time: 9.45237
PPO Batch Consumption Time: 1.33333
Total Iteration Time: 24.27461

Cumulative Model Updates: 6,090
Cumulative Timesteps: 50,802,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 50802212...
Checkpoint 50802212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.72334
Policy Entropy: 0.88632
Value Function Loss: 0.21582

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.19490
Policy Update Magnitude: 0.10687
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 3,325.17508
Overall Steps per Second: 2,061.78557

Timestep Collection Time: 15.03740
Timestep Consumption Time: 9.21439
PPO Batch Consumption Time: 1.30054
Total Iteration Time: 24.25179

Cumulative Model Updates: 6,096
Cumulative Timesteps: 50,852,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.21417
Policy Entropy: 0.86982
Value Function Loss: 0.22370

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.22461
Policy Update Magnitude: 0.10847
Value Function Update Magnitude: 0.12708

Collected Steps per Second: 3,374.47073
Overall Steps per Second: 2,070.79157

Timestep Collection Time: 14.81743
Timestep Consumption Time: 9.32840
PPO Batch Consumption Time: 1.31689
Total Iteration Time: 24.14584

Cumulative Model Updates: 6,102
Cumulative Timesteps: 50,902,215

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 50902215...
Checkpoint 50902215 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.33025
Policy Entropy: 0.86043
Value Function Loss: 0.22594

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.24736
Policy Update Magnitude: 0.11227
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 3,303.60044
Overall Steps per Second: 2,068.03772

Timestep Collection Time: 15.13500
Timestep Consumption Time: 9.04251
PPO Batch Consumption Time: 1.26321
Total Iteration Time: 24.17751

Cumulative Model Updates: 6,108
Cumulative Timesteps: 50,952,215

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.44021
Policy Entropy: 0.84092
Value Function Loss: 0.23669

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.23190
Policy Update Magnitude: 0.11357
Value Function Update Magnitude: 0.13633

Collected Steps per Second: 3,328.74363
Overall Steps per Second: 2,046.72430

Timestep Collection Time: 15.02188
Timestep Consumption Time: 9.40935
PPO Batch Consumption Time: 1.34149
Total Iteration Time: 24.43123

Cumulative Model Updates: 6,114
Cumulative Timesteps: 51,002,219

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 51002219...
Checkpoint 51002219 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.49803
Policy Entropy: 0.83903
Value Function Loss: 0.23554

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.23888
Policy Update Magnitude: 0.11192
Value Function Update Magnitude: 0.13239

Collected Steps per Second: 3,366.85419
Overall Steps per Second: 2,082.08064

Timestep Collection Time: 14.85095
Timestep Consumption Time: 9.16397
PPO Batch Consumption Time: 1.29398
Total Iteration Time: 24.01492

Cumulative Model Updates: 6,120
Cumulative Timesteps: 51,052,220

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.05752
Policy Entropy: 0.82842
Value Function Loss: 0.23224

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.20926
Policy Update Magnitude: 0.11324
Value Function Update Magnitude: 0.12164

Collected Steps per Second: 3,326.86588
Overall Steps per Second: 2,068.86149

Timestep Collection Time: 15.02976
Timestep Consumption Time: 9.13909
PPO Batch Consumption Time: 1.29600
Total Iteration Time: 24.16885

Cumulative Model Updates: 6,126
Cumulative Timesteps: 51,102,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 51102222...
Checkpoint 51102222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.81855
Policy Entropy: 0.82359
Value Function Loss: 0.22195

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.24146
Policy Update Magnitude: 0.11510
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 3,364.52453
Overall Steps per Second: 2,084.97361

Timestep Collection Time: 14.86154
Timestep Consumption Time: 9.12054
PPO Batch Consumption Time: 1.28389
Total Iteration Time: 23.98208

Cumulative Model Updates: 6,132
Cumulative Timesteps: 51,152,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.13131
Policy Entropy: 0.81075
Value Function Loss: 0.22917

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.23877
Policy Update Magnitude: 0.11326
Value Function Update Magnitude: 0.11060

Collected Steps per Second: 3,329.97204
Overall Steps per Second: 2,059.44497

Timestep Collection Time: 15.01634
Timestep Consumption Time: 9.26399
PPO Batch Consumption Time: 1.30630
Total Iteration Time: 24.28033

Cumulative Model Updates: 6,138
Cumulative Timesteps: 51,202,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 51202228...
Checkpoint 51202228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.69771
Policy Entropy: 0.79712
Value Function Loss: 0.22894

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.27461
Policy Update Magnitude: 0.09941
Value Function Update Magnitude: 0.10996

Collected Steps per Second: 3,312.86281
Overall Steps per Second: 2,066.82171

Timestep Collection Time: 15.09299
Timestep Consumption Time: 9.09923
PPO Batch Consumption Time: 1.28291
Total Iteration Time: 24.19222

Cumulative Model Updates: 6,144
Cumulative Timesteps: 51,252,229

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.01240
Policy Entropy: 0.79580
Value Function Loss: 0.23497

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.22897
Policy Update Magnitude: 0.09621
Value Function Update Magnitude: 0.11289

Collected Steps per Second: 3,360.89806
Overall Steps per Second: 2,072.85222

Timestep Collection Time: 14.87787
Timestep Consumption Time: 9.24493
PPO Batch Consumption Time: 1.31597
Total Iteration Time: 24.12280

Cumulative Model Updates: 6,150
Cumulative Timesteps: 51,302,232

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 51302232...
Checkpoint 51302232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.59153
Policy Entropy: 0.77781
Value Function Loss: 0.23565

Mean KL Divergence: 0.03000
SB3 Clip Fraction: 0.33092
Policy Update Magnitude: 0.09202
Value Function Update Magnitude: 0.12329

Collected Steps per Second: 3,373.50772
Overall Steps per Second: 2,084.87666

Timestep Collection Time: 14.82166
Timestep Consumption Time: 9.16105
PPO Batch Consumption Time: 1.28998
Total Iteration Time: 23.98271

Cumulative Model Updates: 6,156
Cumulative Timesteps: 51,352,233

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.14552
Policy Entropy: 0.78215
Value Function Loss: 0.23681

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.23841
Policy Update Magnitude: 0.08809
Value Function Update Magnitude: 0.12186

Collected Steps per Second: 3,371.77367
Overall Steps per Second: 2,091.70386

Timestep Collection Time: 14.83018
Timestep Consumption Time: 9.07569
PPO Batch Consumption Time: 1.27583
Total Iteration Time: 23.90587

Cumulative Model Updates: 6,162
Cumulative Timesteps: 51,402,237

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 51402237...
Checkpoint 51402237 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.84566
Policy Entropy: 0.77280
Value Function Loss: 0.23376

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.21259
Policy Update Magnitude: 0.09541
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 3,332.02248
Overall Steps per Second: 2,070.71904

Timestep Collection Time: 15.00680
Timestep Consumption Time: 9.14085
PPO Batch Consumption Time: 1.28782
Total Iteration Time: 24.14765

Cumulative Model Updates: 6,168
Cumulative Timesteps: 51,452,240

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.10128
Policy Entropy: 0.76346
Value Function Loss: 0.23203

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.21884
Policy Update Magnitude: 0.11709
Value Function Update Magnitude: 0.12127

Collected Steps per Second: 3,335.66723
Overall Steps per Second: 2,045.73594

Timestep Collection Time: 14.98950
Timestep Consumption Time: 9.45158
PPO Batch Consumption Time: 1.34346
Total Iteration Time: 24.44108

Cumulative Model Updates: 6,174
Cumulative Timesteps: 51,502,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 51502240...
Checkpoint 51502240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.10153
Policy Entropy: 0.75555
Value Function Loss: 0.23316

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.21611
Policy Update Magnitude: 0.11748
Value Function Update Magnitude: 0.11550

Collected Steps per Second: 3,352.61169
Overall Steps per Second: 2,067.30329

Timestep Collection Time: 14.91404
Timestep Consumption Time: 9.27254
PPO Batch Consumption Time: 1.31335
Total Iteration Time: 24.18658

Cumulative Model Updates: 6,180
Cumulative Timesteps: 51,552,241

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.52250
Policy Entropy: 0.73973
Value Function Loss: 0.23710

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.24229
Policy Update Magnitude: 0.12125
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 3,390.73281
Overall Steps per Second: 2,081.96406

Timestep Collection Time: 14.74755
Timestep Consumption Time: 9.27064
PPO Batch Consumption Time: 1.29429
Total Iteration Time: 24.01819

Cumulative Model Updates: 6,186
Cumulative Timesteps: 51,602,246

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 51602246...
Checkpoint 51602246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.61336
Policy Entropy: 0.72582
Value Function Loss: 0.23917

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.23709
Policy Update Magnitude: 0.12426
Value Function Update Magnitude: 0.11703

Collected Steps per Second: 3,324.03022
Overall Steps per Second: 2,046.64615

Timestep Collection Time: 15.04228
Timestep Consumption Time: 9.38842
PPO Batch Consumption Time: 1.32441
Total Iteration Time: 24.43070

Cumulative Model Updates: 6,192
Cumulative Timesteps: 51,652,247

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.63806
Policy Entropy: 0.70659
Value Function Loss: 0.23597

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.20700
Policy Update Magnitude: 0.12542
Value Function Update Magnitude: 0.12226

Collected Steps per Second: 3,276.29874
Overall Steps per Second: 2,050.04179

Timestep Collection Time: 15.26143
Timestep Consumption Time: 9.12881
PPO Batch Consumption Time: 1.29453
Total Iteration Time: 24.39023

Cumulative Model Updates: 6,198
Cumulative Timesteps: 51,702,248

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 51702248...
Checkpoint 51702248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.35326
Policy Entropy: 0.69960
Value Function Loss: 0.23807

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.20064
Policy Update Magnitude: 0.13851
Value Function Update Magnitude: 0.11251

Collected Steps per Second: 3,332.71514
Overall Steps per Second: 2,075.23898

Timestep Collection Time: 15.00278
Timestep Consumption Time: 9.09083
PPO Batch Consumption Time: 1.27434
Total Iteration Time: 24.09361

Cumulative Model Updates: 6,204
Cumulative Timesteps: 51,752,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.95362
Policy Entropy: 0.68730
Value Function Loss: 0.23995

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.22780
Policy Update Magnitude: 0.11076
Value Function Update Magnitude: 0.10671

Collected Steps per Second: 3,365.97589
Overall Steps per Second: 2,063.09044

Timestep Collection Time: 14.85483
Timestep Consumption Time: 9.38114
PPO Batch Consumption Time: 1.32598
Total Iteration Time: 24.23597

Cumulative Model Updates: 6,210
Cumulative Timesteps: 51,802,249

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 51802249...
Checkpoint 51802249 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.89750
Policy Entropy: 0.67405
Value Function Loss: 0.25017

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.23597
Policy Update Magnitude: 0.10024
Value Function Update Magnitude: 0.10948

Collected Steps per Second: 3,354.88353
Overall Steps per Second: 2,081.95960

Timestep Collection Time: 14.90424
Timestep Consumption Time: 9.11255
PPO Batch Consumption Time: 1.28156
Total Iteration Time: 24.01680

Cumulative Model Updates: 6,216
Cumulative Timesteps: 51,852,251

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.10339
Policy Entropy: 0.65562
Value Function Loss: 0.24523

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.20821
Policy Update Magnitude: 0.11142
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 3,306.70930
Overall Steps per Second: 2,048.72677

Timestep Collection Time: 15.12108
Timestep Consumption Time: 9.28481
PPO Batch Consumption Time: 1.29855
Total Iteration Time: 24.40589

Cumulative Model Updates: 6,222
Cumulative Timesteps: 51,902,252

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 51902252...
Checkpoint 51902252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.45746
Policy Entropy: 0.65312
Value Function Loss: 0.23822

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.22594
Policy Update Magnitude: 0.11453
Value Function Update Magnitude: 0.10964

Collected Steps per Second: 3,337.39599
Overall Steps per Second: 2,081.05123

Timestep Collection Time: 14.98174
Timestep Consumption Time: 9.04458
PPO Batch Consumption Time: 1.27773
Total Iteration Time: 24.02632

Cumulative Model Updates: 6,228
Cumulative Timesteps: 51,952,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.21926
Policy Entropy: 0.63223
Value Function Loss: 0.23689

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.27048
Policy Update Magnitude: 0.08936
Value Function Update Magnitude: 0.10827

Collected Steps per Second: 3,364.13609
Overall Steps per Second: 2,062.84874

Timestep Collection Time: 14.86295
Timestep Consumption Time: 9.37586
PPO Batch Consumption Time: 1.31947
Total Iteration Time: 24.23881

Cumulative Model Updates: 6,234
Cumulative Timesteps: 52,002,253

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 52002253...
Checkpoint 52002253 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.98430
Policy Entropy: 0.63538
Value Function Loss: 0.24278

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.24251
Policy Update Magnitude: 0.09435
Value Function Update Magnitude: 0.10771

Collected Steps per Second: 3,364.18171
Overall Steps per Second: 2,087.57485

Timestep Collection Time: 14.86364
Timestep Consumption Time: 9.08951
PPO Batch Consumption Time: 1.27785
Total Iteration Time: 23.95315

Cumulative Model Updates: 6,240
Cumulative Timesteps: 52,052,257

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.67866
Policy Entropy: 0.62885
Value Function Loss: 0.24526

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.26052
Policy Update Magnitude: 0.09454
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 3,384.93365
Overall Steps per Second: 2,065.74450

Timestep Collection Time: 14.77252
Timestep Consumption Time: 9.43377
PPO Batch Consumption Time: 1.32843
Total Iteration Time: 24.20629

Cumulative Model Updates: 6,246
Cumulative Timesteps: 52,102,261

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 52102261...
Checkpoint 52102261 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.08170
Policy Entropy: 0.62427
Value Function Loss: 0.24241

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.27634
Policy Update Magnitude: 0.08955
Value Function Update Magnitude: 0.11486

Collected Steps per Second: 3,355.55976
Overall Steps per Second: 2,092.45778

Timestep Collection Time: 14.90124
Timestep Consumption Time: 8.99506
PPO Batch Consumption Time: 1.26708
Total Iteration Time: 23.89630

Cumulative Model Updates: 6,252
Cumulative Timesteps: 52,152,263

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.34142
Policy Entropy: 0.62720
Value Function Loss: 0.23399

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.23560
Policy Update Magnitude: 0.09492
Value Function Update Magnitude: 0.11667

Collected Steps per Second: 3,352.00274
Overall Steps per Second: 2,056.83819

Timestep Collection Time: 14.91675
Timestep Consumption Time: 9.39289
PPO Batch Consumption Time: 1.32103
Total Iteration Time: 24.30964

Cumulative Model Updates: 6,258
Cumulative Timesteps: 52,202,264

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 52202264...
Checkpoint 52202264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.12217
Policy Entropy: 0.62307
Value Function Loss: 0.23951

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.21269
Policy Update Magnitude: 0.10508
Value Function Update Magnitude: 0.11625

Collected Steps per Second: 3,359.45809
Overall Steps per Second: 2,079.64052

Timestep Collection Time: 14.88335
Timestep Consumption Time: 9.15926
PPO Batch Consumption Time: 1.29277
Total Iteration Time: 24.04262

Cumulative Model Updates: 6,264
Cumulative Timesteps: 52,252,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.51442
Policy Entropy: 0.62009
Value Function Loss: 0.23011

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.18112
Policy Update Magnitude: 0.11738
Value Function Update Magnitude: 0.11734

Collected Steps per Second: 3,375.37614
Overall Steps per Second: 2,048.41443

Timestep Collection Time: 14.81405
Timestep Consumption Time: 9.59654
PPO Batch Consumption Time: 1.35048
Total Iteration Time: 24.41059

Cumulative Model Updates: 6,270
Cumulative Timesteps: 52,302,267

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 52302267...
Checkpoint 52302267 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.88386
Policy Entropy: 0.61483
Value Function Loss: 0.23054

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.19030
Policy Update Magnitude: 0.12830
Value Function Update Magnitude: 0.11517

Collected Steps per Second: 3,379.98374
Overall Steps per Second: 2,092.45806

Timestep Collection Time: 14.79356
Timestep Consumption Time: 9.10273
PPO Batch Consumption Time: 1.28208
Total Iteration Time: 23.89630

Cumulative Model Updates: 6,276
Cumulative Timesteps: 52,352,269

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.24642
Policy Entropy: 0.60583
Value Function Loss: 0.22956

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.23618
Policy Update Magnitude: 0.12215
Value Function Update Magnitude: 0.10998

Collected Steps per Second: 3,373.25406
Overall Steps per Second: 2,065.87547

Timestep Collection Time: 14.82367
Timestep Consumption Time: 9.38108
PPO Batch Consumption Time: 1.31199
Total Iteration Time: 24.20475

Cumulative Model Updates: 6,282
Cumulative Timesteps: 52,402,273

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 52402273...
Checkpoint 52402273 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.29579
Policy Entropy: 0.59593
Value Function Loss: 0.23344

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.24313
Policy Update Magnitude: 0.09540
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 3,356.63426
Overall Steps per Second: 2,084.78748

Timestep Collection Time: 14.89736
Timestep Consumption Time: 9.08829
PPO Batch Consumption Time: 1.28439
Total Iteration Time: 23.98566

Cumulative Model Updates: 6,288
Cumulative Timesteps: 52,452,278

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.53214
Policy Entropy: 0.59050
Value Function Loss: 0.24122

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.22518
Policy Update Magnitude: 0.09064
Value Function Update Magnitude: 0.10684

Collected Steps per Second: 3,352.66521
Overall Steps per Second: 2,047.09337

Timestep Collection Time: 14.91410
Timestep Consumption Time: 9.51175
PPO Batch Consumption Time: 1.34623
Total Iteration Time: 24.42585

Cumulative Model Updates: 6,294
Cumulative Timesteps: 52,502,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 52502280...
Checkpoint 52502280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.34583
Policy Entropy: 0.57917
Value Function Loss: 0.23180

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.24928
Policy Update Magnitude: 0.09613
Value Function Update Magnitude: 0.13352

Collected Steps per Second: 3,396.36923
Overall Steps per Second: 2,079.84030

Timestep Collection Time: 14.72278
Timestep Consumption Time: 9.31945
PPO Batch Consumption Time: 1.30341
Total Iteration Time: 24.04223

Cumulative Model Updates: 6,300
Cumulative Timesteps: 52,552,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.04791
Policy Entropy: 0.56759
Value Function Loss: 0.24064

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.22950
Policy Update Magnitude: 0.09268
Value Function Update Magnitude: 0.13220

Collected Steps per Second: 3,385.39236
Overall Steps per Second: 2,066.77820

Timestep Collection Time: 14.76963
Timestep Consumption Time: 9.42309
PPO Batch Consumption Time: 1.31700
Total Iteration Time: 24.19273

Cumulative Model Updates: 6,306
Cumulative Timesteps: 52,602,285

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 52602285...
Checkpoint 52602285 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.76651
Policy Entropy: 0.55803
Value Function Loss: 0.23867

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.23233
Policy Update Magnitude: 0.09002
Value Function Update Magnitude: 0.11831

Collected Steps per Second: 3,346.53486
Overall Steps per Second: 2,053.96116

Timestep Collection Time: 14.94083
Timestep Consumption Time: 9.40238
PPO Batch Consumption Time: 1.32479
Total Iteration Time: 24.34321

Cumulative Model Updates: 6,312
Cumulative Timesteps: 52,652,285

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.57648
Policy Entropy: 0.55276
Value Function Loss: 0.24358

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.18614
Policy Update Magnitude: 0.09916
Value Function Update Magnitude: 0.11447

Collected Steps per Second: 3,354.55841
Overall Steps per Second: 2,080.10177

Timestep Collection Time: 14.90658
Timestep Consumption Time: 9.13311
PPO Batch Consumption Time: 1.28018
Total Iteration Time: 24.03969

Cumulative Model Updates: 6,318
Cumulative Timesteps: 52,702,290

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 52702290...
Checkpoint 52702290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.85210
Policy Entropy: 0.54414
Value Function Loss: 0.24004

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.20703
Policy Update Magnitude: 0.10419
Value Function Update Magnitude: 0.10790

Collected Steps per Second: 3,341.02228
Overall Steps per Second: 2,069.74754

Timestep Collection Time: 14.96668
Timestep Consumption Time: 9.19279
PPO Batch Consumption Time: 1.29249
Total Iteration Time: 24.15947

Cumulative Model Updates: 6,324
Cumulative Timesteps: 52,752,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.78605
Policy Entropy: 0.53523
Value Function Loss: 0.23868

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.22235
Policy Update Magnitude: 0.08754
Value Function Update Magnitude: 0.10695

Collected Steps per Second: 3,144.31668
Overall Steps per Second: 1,918.25331

Timestep Collection Time: 15.90171
Timestep Consumption Time: 10.16367
PPO Batch Consumption Time: 1.42938
Total Iteration Time: 26.06538

Cumulative Model Updates: 6,330
Cumulative Timesteps: 52,802,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 52802294...
Checkpoint 52802294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372.50739
Policy Entropy: 0.53406
Value Function Loss: 0.22633

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.18676
Policy Update Magnitude: 0.08708
Value Function Update Magnitude: 0.14975

Collected Steps per Second: 3,191.65877
Overall Steps per Second: 2,020.65374

Timestep Collection Time: 15.66615
Timestep Consumption Time: 9.07881
PPO Batch Consumption Time: 1.28055
Total Iteration Time: 24.74496

Cumulative Model Updates: 6,336
Cumulative Timesteps: 52,852,295

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.57464
Policy Entropy: 0.53535
Value Function Loss: 0.22510

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.19268
Policy Update Magnitude: 0.09618
Value Function Update Magnitude: 0.16040

Collected Steps per Second: 3,339.12407
Overall Steps per Second: 2,079.35021

Timestep Collection Time: 14.97518
Timestep Consumption Time: 9.07271
PPO Batch Consumption Time: 1.26719
Total Iteration Time: 24.04790

Cumulative Model Updates: 6,342
Cumulative Timesteps: 52,902,299

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 52902299...
Checkpoint 52902299 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.59999
Policy Entropy: 0.53173
Value Function Loss: 0.22537

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.20423
Policy Update Magnitude: 0.10525
Value Function Update Magnitude: 0.13121

Collected Steps per Second: 3,348.73261
Overall Steps per Second: 2,081.74670

Timestep Collection Time: 14.93192
Timestep Consumption Time: 9.08782
PPO Batch Consumption Time: 1.25932
Total Iteration Time: 24.01973

Cumulative Model Updates: 6,348
Cumulative Timesteps: 52,952,302

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.02201
Policy Entropy: 0.52600
Value Function Loss: 0.23627

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.24056
Policy Update Magnitude: 0.09463
Value Function Update Magnitude: 0.11984

Collected Steps per Second: 3,337.11299
Overall Steps per Second: 2,089.45292

Timestep Collection Time: 14.98391
Timestep Consumption Time: 8.94723
PPO Batch Consumption Time: 1.24093
Total Iteration Time: 23.93114

Cumulative Model Updates: 6,354
Cumulative Timesteps: 53,002,305

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 53002305...
Checkpoint 53002305 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.09987
Policy Entropy: 0.51551
Value Function Loss: 0.24461

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.26041
Policy Update Magnitude: 0.08916
Value Function Update Magnitude: 0.14524

Collected Steps per Second: 3,368.95489
Overall Steps per Second: 2,098.85300

Timestep Collection Time: 14.84259
Timestep Consumption Time: 8.98186
PPO Batch Consumption Time: 1.25514
Total Iteration Time: 23.82444

Cumulative Model Updates: 6,360
Cumulative Timesteps: 53,052,309

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.82680
Policy Entropy: 0.51667
Value Function Loss: 0.25856

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.21780
Policy Update Magnitude: 0.09406
Value Function Update Magnitude: 0.16052

Collected Steps per Second: 3,374.42295
Overall Steps per Second: 2,086.32006

Timestep Collection Time: 14.81764
Timestep Consumption Time: 9.14848
PPO Batch Consumption Time: 1.29090
Total Iteration Time: 23.96612

Cumulative Model Updates: 6,366
Cumulative Timesteps: 53,102,310

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 53102310...
Checkpoint 53102310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.24471
Policy Entropy: 0.51182
Value Function Loss: 0.25916

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.20229
Policy Update Magnitude: 0.10026
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 3,338.27027
Overall Steps per Second: 2,099.75046

Timestep Collection Time: 14.97872
Timestep Consumption Time: 8.83507
PPO Batch Consumption Time: 1.24684
Total Iteration Time: 23.81378

Cumulative Model Updates: 6,372
Cumulative Timesteps: 53,152,313

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.15314
Policy Entropy: 0.50508
Value Function Loss: 0.25250

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.23361
Policy Update Magnitude: 0.09179
Value Function Update Magnitude: 0.11749

Collected Steps per Second: 3,334.35118
Overall Steps per Second: 2,093.43640

Timestep Collection Time: 14.99602
Timestep Consumption Time: 8.88911
PPO Batch Consumption Time: 1.24125
Total Iteration Time: 23.88513

Cumulative Model Updates: 6,378
Cumulative Timesteps: 53,202,315

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 53202315...
Checkpoint 53202315 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.05671
Policy Entropy: 0.49975
Value Function Loss: 0.25161

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.19171
Policy Update Magnitude: 0.09949
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 3,359.37592
Overall Steps per Second: 2,096.86572

Timestep Collection Time: 14.88431
Timestep Consumption Time: 8.96175
PPO Batch Consumption Time: 1.25004
Total Iteration Time: 23.84607

Cumulative Model Updates: 6,384
Cumulative Timesteps: 53,252,317

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.40702
Policy Entropy: 0.49230
Value Function Loss: 0.25793

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16878
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.11466

Collected Steps per Second: 3,362.35510
Overall Steps per Second: 2,082.76757

Timestep Collection Time: 14.87053
Timestep Consumption Time: 9.13599
PPO Batch Consumption Time: 1.28268
Total Iteration Time: 24.00652

Cumulative Model Updates: 6,390
Cumulative Timesteps: 53,302,317

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 53302317...
Checkpoint 53302317 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.59650
Policy Entropy: 0.48559
Value Function Loss: 0.26252

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.13141
Value Function Update Magnitude: 0.11358

Collected Steps per Second: 3,355.59820
Overall Steps per Second: 2,099.35718

Timestep Collection Time: 14.90137
Timestep Consumption Time: 8.91688
PPO Batch Consumption Time: 1.24140
Total Iteration Time: 23.81824

Cumulative Model Updates: 6,396
Cumulative Timesteps: 53,352,320

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.90155
Policy Entropy: 0.47712
Value Function Loss: 0.26189

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.19964
Policy Update Magnitude: 0.13593
Value Function Update Magnitude: 0.10896

Collected Steps per Second: 3,343.01878
Overall Steps per Second: 2,100.99773

Timestep Collection Time: 14.95684
Timestep Consumption Time: 8.84185
PPO Batch Consumption Time: 1.25426
Total Iteration Time: 23.79869

Cumulative Model Updates: 6,402
Cumulative Timesteps: 53,402,321

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 53402321...
Checkpoint 53402321 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.75028
Policy Entropy: 0.47916
Value Function Loss: 0.25330

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.18455
Policy Update Magnitude: 0.12693
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 3,334.60079
Overall Steps per Second: 2,090.39533

Timestep Collection Time: 14.99490
Timestep Consumption Time: 8.92498
PPO Batch Consumption Time: 1.25287
Total Iteration Time: 23.91988

Cumulative Model Updates: 6,408
Cumulative Timesteps: 53,452,323

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.08570
Policy Entropy: 0.47534
Value Function Loss: 0.25302

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.19513
Policy Update Magnitude: 0.10598
Value Function Update Magnitude: 0.11434

Collected Steps per Second: 3,339.47706
Overall Steps per Second: 2,092.39882

Timestep Collection Time: 14.97240
Timestep Consumption Time: 8.92361
PPO Batch Consumption Time: 1.25162
Total Iteration Time: 23.89602

Cumulative Model Updates: 6,414
Cumulative Timesteps: 53,502,323

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 53502323...
Checkpoint 53502323 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.61725
Policy Entropy: 0.47049
Value Function Loss: 0.25599

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.16038
Policy Update Magnitude: 0.11719
Value Function Update Magnitude: 0.11288

Collected Steps per Second: 3,330.54427
Overall Steps per Second: 2,099.72196

Timestep Collection Time: 15.01256
Timestep Consumption Time: 8.80012
PPO Batch Consumption Time: 1.23272
Total Iteration Time: 23.81268

Cumulative Model Updates: 6,420
Cumulative Timesteps: 53,552,323

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.89111
Policy Entropy: 0.45376
Value Function Loss: 0.25460

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.22770
Policy Update Magnitude: 0.12003
Value Function Update Magnitude: 0.11359

Collected Steps per Second: 3,334.90569
Overall Steps per Second: 2,067.75108

Timestep Collection Time: 14.99383
Timestep Consumption Time: 9.18848
PPO Batch Consumption Time: 1.28136
Total Iteration Time: 24.18231

Cumulative Model Updates: 6,426
Cumulative Timesteps: 53,602,326

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 53602326...
Checkpoint 53602326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.46028
Policy Entropy: 0.45688
Value Function Loss: 0.24918

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.17852
Policy Update Magnitude: 0.10874
Value Function Update Magnitude: 0.11012

Collected Steps per Second: 3,333.11663
Overall Steps per Second: 2,103.49701

Timestep Collection Time: 15.00188
Timestep Consumption Time: 8.76949
PPO Batch Consumption Time: 1.22252
Total Iteration Time: 23.77137

Cumulative Model Updates: 6,432
Cumulative Timesteps: 53,652,329

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.98921
Policy Entropy: 0.46185
Value Function Loss: 0.24574

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.15138
Policy Update Magnitude: 0.10992
Value Function Update Magnitude: 0.11899

Collected Steps per Second: 3,384.88433
Overall Steps per Second: 2,098.38518

Timestep Collection Time: 14.77155
Timestep Consumption Time: 9.05629
PPO Batch Consumption Time: 1.27079
Total Iteration Time: 23.82785

Cumulative Model Updates: 6,438
Cumulative Timesteps: 53,702,329

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 53702329...
Checkpoint 53702329 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.50565
Policy Entropy: 0.46603
Value Function Loss: 0.24260

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.11193
Value Function Update Magnitude: 0.11798

Collected Steps per Second: 3,347.99631
Overall Steps per Second: 2,068.25494

Timestep Collection Time: 14.93431
Timestep Consumption Time: 9.24066
PPO Batch Consumption Time: 1.30217
Total Iteration Time: 24.17497

Cumulative Model Updates: 6,444
Cumulative Timesteps: 53,752,329

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.91856
Policy Entropy: 0.45948
Value Function Loss: 0.25339

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.18134
Policy Update Magnitude: 0.10867
Value Function Update Magnitude: 0.11289

Collected Steps per Second: 3,331.35833
Overall Steps per Second: 2,093.14490

Timestep Collection Time: 15.00889
Timestep Consumption Time: 8.87861
PPO Batch Consumption Time: 1.25068
Total Iteration Time: 23.88750

Cumulative Model Updates: 6,450
Cumulative Timesteps: 53,802,329

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 53802329...
Checkpoint 53802329 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.64204
Policy Entropy: 0.45689
Value Function Loss: 0.25994

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.21272
Policy Update Magnitude: 0.09083
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 3,343.64788
Overall Steps per Second: 2,092.33313

Timestep Collection Time: 14.95492
Timestep Consumption Time: 8.94376
PPO Batch Consumption Time: 1.24430
Total Iteration Time: 23.89868

Cumulative Model Updates: 6,456
Cumulative Timesteps: 53,852,333

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.59067
Policy Entropy: 0.45075
Value Function Loss: 0.26523

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.19135
Policy Update Magnitude: 0.08795
Value Function Update Magnitude: 0.12072

Collected Steps per Second: 3,347.07900
Overall Steps per Second: 2,097.65960

Timestep Collection Time: 14.93959
Timestep Consumption Time: 8.89840
PPO Batch Consumption Time: 1.25492
Total Iteration Time: 23.83800

Cumulative Model Updates: 6,462
Cumulative Timesteps: 53,902,337

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 53902337...
Checkpoint 53902337 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.32169
Policy Entropy: 0.44994
Value Function Loss: 0.25463

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.19392
Policy Update Magnitude: 0.08808
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 3,361.52518
Overall Steps per Second: 2,086.99756

Timestep Collection Time: 14.87509
Timestep Consumption Time: 9.08421
PPO Batch Consumption Time: 1.24907
Total Iteration Time: 23.95930

Cumulative Model Updates: 6,468
Cumulative Timesteps: 53,952,340

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.26256
Policy Entropy: 0.43347
Value Function Loss: 0.25885

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.20216
Policy Update Magnitude: 0.08740
Value Function Update Magnitude: 0.14213

Collected Steps per Second: 3,346.23461
Overall Steps per Second: 2,070.27939

Timestep Collection Time: 14.94217
Timestep Consumption Time: 9.20916
PPO Batch Consumption Time: 1.29064
Total Iteration Time: 24.15133

Cumulative Model Updates: 6,474
Cumulative Timesteps: 54,002,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 54002340...
Checkpoint 54002340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.36155
Policy Entropy: 0.42723
Value Function Loss: 0.25559

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.19647
Policy Update Magnitude: 0.08431
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 3,338.45408
Overall Steps per Second: 2,089.98985

Timestep Collection Time: 14.97789
Timestep Consumption Time: 8.94711
PPO Batch Consumption Time: 1.25512
Total Iteration Time: 23.92500

Cumulative Model Updates: 6,480
Cumulative Timesteps: 54,052,343

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.57477
Policy Entropy: 0.42178
Value Function Loss: 0.26442

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.17630
Policy Update Magnitude: 0.08767
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 3,347.88325
Overall Steps per Second: 2,076.53149

Timestep Collection Time: 14.93600
Timestep Consumption Time: 9.14454
PPO Batch Consumption Time: 1.29237
Total Iteration Time: 24.08054

Cumulative Model Updates: 6,486
Cumulative Timesteps: 54,102,347

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 54102347...
Checkpoint 54102347 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.84144
Policy Entropy: 0.42137
Value Function Loss: 0.25428

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.09622
Value Function Update Magnitude: 0.16506

Collected Steps per Second: 3,346.69165
Overall Steps per Second: 2,088.13014

Timestep Collection Time: 14.94013
Timestep Consumption Time: 9.00474
PPO Batch Consumption Time: 1.25717
Total Iteration Time: 23.94487

Cumulative Model Updates: 6,492
Cumulative Timesteps: 54,152,347

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.73006
Policy Entropy: 0.41560
Value Function Loss: 0.25316

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.09646
Value Function Update Magnitude: 0.14827

Collected Steps per Second: 3,384.74250
Overall Steps per Second: 2,091.69222

Timestep Collection Time: 14.77247
Timestep Consumption Time: 9.13210
PPO Batch Consumption Time: 1.27003
Total Iteration Time: 23.90457

Cumulative Model Updates: 6,498
Cumulative Timesteps: 54,202,348

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 54202348...
Checkpoint 54202348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.86475
Policy Entropy: 0.41098
Value Function Loss: 0.24505

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.15414
Policy Update Magnitude: 0.09618
Value Function Update Magnitude: 0.13612

Collected Steps per Second: 3,372.87990
Overall Steps per Second: 2,094.15899

Timestep Collection Time: 14.82561
Timestep Consumption Time: 9.05271
PPO Batch Consumption Time: 1.26711
Total Iteration Time: 23.87832

Cumulative Model Updates: 6,504
Cumulative Timesteps: 54,252,353

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.67086
Policy Entropy: 0.41030
Value Function Loss: 0.25042

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.09474
Value Function Update Magnitude: 0.12916

Collected Steps per Second: 3,341.84028
Overall Steps per Second: 2,079.93317

Timestep Collection Time: 14.96182
Timestep Consumption Time: 9.07742
PPO Batch Consumption Time: 1.26935
Total Iteration Time: 24.03923

Cumulative Model Updates: 6,510
Cumulative Timesteps: 54,302,353

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 54302353...
Checkpoint 54302353 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.74481
Policy Entropy: 0.40456
Value Function Loss: 0.25400

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.10558
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 3,333.33149
Overall Steps per Second: 2,075.44240

Timestep Collection Time: 15.00091
Timestep Consumption Time: 9.09179
PPO Batch Consumption Time: 1.26727
Total Iteration Time: 24.09269

Cumulative Model Updates: 6,516
Cumulative Timesteps: 54,352,356

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.11383
Policy Entropy: 0.40796
Value Function Loss: 0.25787

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.19185
Policy Update Magnitude: 0.09991
Value Function Update Magnitude: 0.10745

Collected Steps per Second: 3,402.52909
Overall Steps per Second: 2,106.11613

Timestep Collection Time: 14.69613
Timestep Consumption Time: 9.04615
PPO Batch Consumption Time: 1.26790
Total Iteration Time: 23.74228

Cumulative Model Updates: 6,522
Cumulative Timesteps: 54,402,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 54402360...
Checkpoint 54402360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451.85106
Policy Entropy: 0.39723
Value Function Loss: 0.26252

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.19087
Policy Update Magnitude: 0.09397
Value Function Update Magnitude: 0.10522

Collected Steps per Second: 3,374.68302
Overall Steps per Second: 2,092.62743

Timestep Collection Time: 14.81680
Timestep Consumption Time: 9.07756
PPO Batch Consumption Time: 1.27246
Total Iteration Time: 23.89436

Cumulative Model Updates: 6,528
Cumulative Timesteps: 54,452,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.03558
Policy Entropy: 0.40045
Value Function Loss: 0.25552

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.19478
Policy Update Magnitude: 0.09888
Value Function Update Magnitude: 0.11305

Collected Steps per Second: 3,358.85128
Overall Steps per Second: 2,085.87413

Timestep Collection Time: 14.88693
Timestep Consumption Time: 9.08527
PPO Batch Consumption Time: 1.28226
Total Iteration Time: 23.97220

Cumulative Model Updates: 6,534
Cumulative Timesteps: 54,502,365

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 54502365...
Checkpoint 54502365 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 485.83596
Policy Entropy: 0.40478
Value Function Loss: 0.26112

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.17729
Policy Update Magnitude: 0.08951
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 3,351.42655
Overall Steps per Second: 2,103.66946

Timestep Collection Time: 14.92021
Timestep Consumption Time: 8.84968
PPO Batch Consumption Time: 1.23949
Total Iteration Time: 23.76989

Cumulative Model Updates: 6,540
Cumulative Timesteps: 54,552,369

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.30305
Policy Entropy: 0.39222
Value Function Loss: 0.26288

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.18368
Policy Update Magnitude: 0.08844
Value Function Update Magnitude: 0.10679

Collected Steps per Second: 3,326.63684
Overall Steps per Second: 2,079.01636

Timestep Collection Time: 15.03110
Timestep Consumption Time: 9.02018
PPO Batch Consumption Time: 1.26125
Total Iteration Time: 24.05128

Cumulative Model Updates: 6,546
Cumulative Timesteps: 54,602,372

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 54602372...
Checkpoint 54602372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.56003
Policy Entropy: 0.38173
Value Function Loss: 0.26696

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.09343
Value Function Update Magnitude: 0.10675

Collected Steps per Second: 3,375.94308
Overall Steps per Second: 2,096.84337

Timestep Collection Time: 14.81127
Timestep Consumption Time: 9.03505
PPO Batch Consumption Time: 1.26732
Total Iteration Time: 23.84632

Cumulative Model Updates: 6,552
Cumulative Timesteps: 54,652,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.52178
Policy Entropy: 0.37573
Value Function Loss: 0.26210

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16588
Policy Update Magnitude: 0.10610
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 3,353.75189
Overall Steps per Second: 2,074.79935

Timestep Collection Time: 14.90987
Timestep Consumption Time: 9.19078
PPO Batch Consumption Time: 1.29069
Total Iteration Time: 24.10064

Cumulative Model Updates: 6,558
Cumulative Timesteps: 54,702,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 54702378...
Checkpoint 54702378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.90829
Policy Entropy: 0.37904
Value Function Loss: 0.25818

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.20000
Policy Update Magnitude: 0.09148
Value Function Update Magnitude: 0.10521

Collected Steps per Second: 3,321.48949
Overall Steps per Second: 2,086.52077

Timestep Collection Time: 15.05379
Timestep Consumption Time: 8.91003
PPO Batch Consumption Time: 1.24807
Total Iteration Time: 23.96382

Cumulative Model Updates: 6,564
Cumulative Timesteps: 54,752,379

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.40268
Policy Entropy: 0.37254
Value Function Loss: 0.25585

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.18378
Policy Update Magnitude: 0.08389
Value Function Update Magnitude: 0.10420

Collected Steps per Second: 3,311.90412
Overall Steps per Second: 2,063.37489

Timestep Collection Time: 15.09766
Timestep Consumption Time: 9.13546
PPO Batch Consumption Time: 1.27597
Total Iteration Time: 24.23311

Cumulative Model Updates: 6,570
Cumulative Timesteps: 54,802,381

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 54802381...
Checkpoint 54802381 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.25453
Policy Entropy: 0.37502
Value Function Loss: 0.25528

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.18340
Policy Update Magnitude: 0.08301
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 3,290.81654
Overall Steps per Second: 2,075.72179

Timestep Collection Time: 15.19471
Timestep Consumption Time: 8.89474
PPO Batch Consumption Time: 1.24943
Total Iteration Time: 24.08945

Cumulative Model Updates: 6,576
Cumulative Timesteps: 54,852,384

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.02582
Policy Entropy: 0.36933
Value Function Loss: 0.24153

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.17986
Policy Update Magnitude: 0.07638
Value Function Update Magnitude: 0.12256

Collected Steps per Second: 3,369.62947
Overall Steps per Second: 2,075.34415

Timestep Collection Time: 14.83961
Timestep Consumption Time: 9.25470
PPO Batch Consumption Time: 1.30899
Total Iteration Time: 24.09432

Cumulative Model Updates: 6,582
Cumulative Timesteps: 54,902,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 54902388...
Checkpoint 54902388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.71733
Policy Entropy: 0.36460
Value Function Loss: 0.23318

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.18475
Policy Update Magnitude: 0.07158
Value Function Update Magnitude: 0.13323

Collected Steps per Second: 3,334.72313
Overall Steps per Second: 2,087.40102

Timestep Collection Time: 14.99375
Timestep Consumption Time: 8.95948
PPO Batch Consumption Time: 1.25366
Total Iteration Time: 23.95323

Cumulative Model Updates: 6,588
Cumulative Timesteps: 54,952,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.32672
Policy Entropy: 0.36507
Value Function Loss: 0.23265

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.18645
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 3,342.29060
Overall Steps per Second: 2,093.99572

Timestep Collection Time: 14.96070
Timestep Consumption Time: 8.91853
PPO Batch Consumption Time: 1.25447
Total Iteration Time: 23.87923

Cumulative Model Updates: 6,594
Cumulative Timesteps: 55,002,391

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 55002391...
Checkpoint 55002391 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.15029
Policy Entropy: 0.37577
Value Function Loss: 0.24220

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.19544
Policy Update Magnitude: 0.08469
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 3,384.05705
Overall Steps per Second: 2,111.50982

Timestep Collection Time: 14.77516
Timestep Consumption Time: 8.90457
PPO Batch Consumption Time: 1.23653
Total Iteration Time: 23.67974

Cumulative Model Updates: 6,600
Cumulative Timesteps: 55,052,391

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.99450
Policy Entropy: 0.36724
Value Function Loss: 0.26064

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.22752
Policy Update Magnitude: 0.07827
Value Function Update Magnitude: 0.11841

Collected Steps per Second: 3,372.10072
Overall Steps per Second: 2,079.89579

Timestep Collection Time: 14.82785
Timestep Consumption Time: 9.21230
PPO Batch Consumption Time: 1.28937
Total Iteration Time: 24.04015

Cumulative Model Updates: 6,606
Cumulative Timesteps: 55,102,392

Timesteps Collected: 50,001
--------END ITERATION REPORT--------


Saving checkpoint 55102392...
Checkpoint 55102392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.39263
Policy Entropy: 0.35366
Value Function Loss: 0.26037

Mean KL Divergence: 0.03086
SB3 Clip Fraction: 0.31009
Policy Update Magnitude: 0.07613
Value Function Update Magnitude: 0.11453

Collected Steps per Second: 3,348.73123
Overall Steps per Second: 2,088.71649

Timestep Collection Time: 14.93163
Timestep Consumption Time: 9.00748
PPO Batch Consumption Time: 1.26448
Total Iteration Time: 23.93910

Cumulative Model Updates: 6,612
Cumulative Timesteps: 55,152,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.62367
Policy Entropy: 0.35730
Value Function Loss: 0.25776

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.19308
Policy Update Magnitude: 0.07041
Value Function Update Magnitude: 0.11702

Collected Steps per Second: 3,387.48178
Overall Steps per Second: 2,086.17372

Timestep Collection Time: 14.76023
Timestep Consumption Time: 9.20710
PPO Batch Consumption Time: 1.29611
Total Iteration Time: 23.96732

Cumulative Model Updates: 6,618
Cumulative Timesteps: 55,202,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 55202394...
Checkpoint 55202394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.97411
Policy Entropy: 0.35676
Value Function Loss: 0.24331

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.17729
Policy Update Magnitude: 0.07239
Value Function Update Magnitude: 0.11181

Collected Steps per Second: 3,358.23390
Overall Steps per Second: 2,095.82571

Timestep Collection Time: 14.88967
Timestep Consumption Time: 8.96871
PPO Batch Consumption Time: 1.26240
Total Iteration Time: 23.85838

Cumulative Model Updates: 6,624
Cumulative Timesteps: 55,252,397

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.27414
Policy Entropy: 0.33756
Value Function Loss: 0.24580

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.20331
Policy Update Magnitude: 0.07454
Value Function Update Magnitude: 0.13392

Collected Steps per Second: 3,353.04221
Overall Steps per Second: 2,093.31325

Timestep Collection Time: 14.91302
Timestep Consumption Time: 8.97447
PPO Batch Consumption Time: 1.25502
Total Iteration Time: 23.88749

Cumulative Model Updates: 6,630
Cumulative Timesteps: 55,302,401

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 55302401...
Checkpoint 55302401 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.76664
Policy Entropy: 0.33603
Value Function Loss: 0.24659

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.22632
Policy Update Magnitude: 0.07517
Value Function Update Magnitude: 0.12024

Collected Steps per Second: 3,358.44120
Overall Steps per Second: 2,088.63086

Timestep Collection Time: 14.88786
Timestep Consumption Time: 9.05127
PPO Batch Consumption Time: 1.27268
Total Iteration Time: 23.93913

Cumulative Model Updates: 6,636
Cumulative Timesteps: 55,352,401

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.99260
Policy Entropy: 0.34841
Value Function Loss: 0.24926

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.20568
Policy Update Magnitude: 0.08144
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 3,367.68919
Overall Steps per Second: 2,073.20889

Timestep Collection Time: 14.84757
Timestep Consumption Time: 9.27060
PPO Batch Consumption Time: 1.30623
Total Iteration Time: 24.11817

Cumulative Model Updates: 6,642
Cumulative Timesteps: 55,402,403

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 55402403...
Checkpoint 55402403 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.75348
Policy Entropy: 0.33810
Value Function Loss: 0.25052

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.18870
Policy Update Magnitude: 0.07741
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 3,302.85989
Overall Steps per Second: 2,077.61846

Timestep Collection Time: 15.13930
Timestep Consumption Time: 8.92816
PPO Batch Consumption Time: 1.25139
Total Iteration Time: 24.06746

Cumulative Model Updates: 6,648
Cumulative Timesteps: 55,452,406

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.56291
Policy Entropy: 0.32589
Value Function Loss: 0.25846

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.19481
Policy Update Magnitude: 0.09055
Value Function Update Magnitude: 0.11469

Collected Steps per Second: 3,330.18293
Overall Steps per Second: 2,066.94098

Timestep Collection Time: 15.01479
Timestep Consumption Time: 9.17651
PPO Batch Consumption Time: 1.28995
Total Iteration Time: 24.19131

Cumulative Model Updates: 6,654
Cumulative Timesteps: 55,502,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 55502408...
Checkpoint 55502408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.84875
Policy Entropy: 0.32605
Value Function Loss: 0.25916

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.19541
Policy Update Magnitude: 0.08482
Value Function Update Magnitude: 0.11527

Collected Steps per Second: 3,360.61355
Overall Steps per Second: 2,097.55508

Timestep Collection Time: 14.87943
Timestep Consumption Time: 8.95976
PPO Batch Consumption Time: 1.26041
Total Iteration Time: 23.83918

Cumulative Model Updates: 6,660
Cumulative Timesteps: 55,552,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.90082
Policy Entropy: 0.32785
Value Function Loss: 0.25571

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.18466
Policy Update Magnitude: 0.08033
Value Function Update Magnitude: 0.11245

Collected Steps per Second: 2,773.90162
Overall Steps per Second: 1,732.75864

Timestep Collection Time: 18.02659
Timestep Consumption Time: 10.83143
PPO Batch Consumption Time: 1.55018
Total Iteration Time: 28.85803

Cumulative Model Updates: 6,666
Cumulative Timesteps: 55,602,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 55602416...
Checkpoint 55602416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.47837
Policy Entropy: 0.32373
Value Function Loss: 0.25518

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.08053
Value Function Update Magnitude: 0.11189

Collected Steps per Second: 2,300.78726
Overall Steps per Second: 1,442.24006

Timestep Collection Time: 21.73169
Timestep Consumption Time: 12.93660
PPO Batch Consumption Time: 1.87738
Total Iteration Time: 34.66829

Cumulative Model Updates: 6,672
Cumulative Timesteps: 55,652,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.86219
Policy Entropy: 0.31056
Value Function Loss: 0.25965

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.17563
Policy Update Magnitude: 0.08405
Value Function Update Magnitude: 0.11061

Collected Steps per Second: 2,603.69669
Overall Steps per Second: 1,628.76985

Timestep Collection Time: 19.20462
Timestep Consumption Time: 11.49524
PPO Batch Consumption Time: 1.65216
Total Iteration Time: 30.69986

Cumulative Model Updates: 6,678
Cumulative Timesteps: 55,702,419

Timesteps Collected: 50,003
--------END ITERATION REPORT--------


Saving checkpoint 55702419...
Checkpoint 55702419 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.79940
Policy Entropy: 0.30424
Value Function Loss: 0.26274

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.23686
Policy Update Magnitude: 0.08231
Value Function Update Magnitude: 0.11264

Collected Steps per Second: 2,831.03772
Overall Steps per Second: 1,734.09321

Timestep Collection Time: 17.66313
Timestep Consumption Time: 11.17326
PPO Batch Consumption Time: 1.58771
Total Iteration Time: 28.83640

Cumulative Model Updates: 6,684
Cumulative Timesteps: 55,752,424

Timesteps Collected: 50,005
--------END ITERATION REPORT--------


Saving checkpoint 55752424...
Checkpoint 55752424 saved!
