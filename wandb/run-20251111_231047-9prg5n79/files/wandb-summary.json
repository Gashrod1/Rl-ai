{"Cumulative Model Updates":18336,"Total Iteration Time":7.175107093062252,"SB3 Clip Fraction":0.008943333135296902,"z_vel":-23.901295792107415,"Timestep Consumption Time":2.0573165100067854,"Value Function Loss":0.003267976959856848,"episode_touches":0,"_step":6272,"_wandb":{"runtime":50941},"_runtime":50941,"episode_goals":0,"Cumulative Timesteps":153234978,"Policy Entropy":1.417140583197276,"PPO Batch Consumption Time":0.02767765522003174,"y_vel":29.91479031111098,"total_touches":0,"Collected Steps per Second":9777.852217259757,"Policy Reward":45.83517950150722,"x_vel":-1.8460971668612156,"Overall Steps per Second":6974.251303982013,"Timestep Collection Time":5.117790583055466,"Mean KL Divergence":0.0008537918717289964,"Value Function Update Magnitude":0.05488350987434387,"_timestamp":1.762898887687652e+09,"Timesteps Collected":50041,"total_goals":0,"Policy Update Magnitude":0.0427231527864933}