{"Timestep Consumption Time":4.839169199985918,"Policy Reward":133.50104317276413,"Cumulative Model Updates":144,"_wandb":{"runtime":549},"Cumulative Timesteps":1300086,"Value Function Update Magnitude":0.19357812404632568,"PPO Batch Consumption Time":0.6016199191411337,"Timesteps Collected":50002,"Timestep Collection Time":18.94153670000378,"x_vel":2.6069568460856005,"Total Iteration Time":23.780705899989698,"Overall Steps per Second":2102.6289215418815,"_runtime":549,"_step":53,"Policy Update Magnitude":0.05850595235824585,"Value Function Loss":0.3641201655069987,"Mean KL Divergence":0.0012505213962867856,"z_vel":-29.286690807538978,"Collected Steps per Second":2639.8069381556575,"_timestamp":1.7628088002761219e+09,"SB3 Clip Fraction":0.0024000000460849455,"y_vel":15.979472373438298,"Policy Entropy":0.7176457047462463}