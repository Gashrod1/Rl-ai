{"Mean KL Divergence":0.0008537918717289964,"z_vel":-23.901295792107415,"Cumulative Timesteps":153234978,"Total Iteration Time":7.175107093062252,"Overall Steps per Second":6974.251303982013,"Policy Update Magnitude":0.0427231527864933,"Timesteps Collected":50041,"Collected Steps per Second":9777.852217259757,"total_goals":0,"Value Function Update Magnitude":0.05488350987434387,"_wandb":{"runtime":50209},"Policy Reward":45.83517950150722,"Timestep Collection Time":5.117790583055466,"x_vel":-1.8460971668612156,"Value Function Loss":0.0032679769598568478,"PPO Batch Consumption Time":0.02767765522003174,"_step":6272,"_timestamp":1.7628988876876519e+09,"episode_touches":0,"SB3 Clip Fraction":0.008943333135296902,"Timestep Consumption Time":2.0573165100067854,"_runtime":50209,"Policy Entropy":1.4171405831972759,"total_touches":0,"y_vel":29.91479031111098,"Cumulative Model Updates":18336,"episode_goals":0}