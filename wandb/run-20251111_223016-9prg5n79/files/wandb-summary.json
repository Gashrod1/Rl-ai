{"total_goals":0,"_step":13654,"_timestamp":1.7629271582519517e+09,"x_vel":9.559250721379717,"episode_goals":0,"Value Function Update Magnitude":0.18998688459396362,"Value Function Loss":0.027106002594033878,"Collected Steps per Second":10636.823886284454,"Mean KL Divergence":0.012430582816402117,"SB3 Clip Fraction":0.09266666571299235,"episode_touches":0,"z_vel":-20.560258798776886,"Policy Update Magnitude":0.13505996763706207,"Total Iteration Time":6.608306520851329,"Overall Steps per Second":7570.623402855549,"Timestep Consumption Time":1.9049288458190858,"total_touches":0,"y_vel":105.4430881812447,"_wandb":{"runtime":77882},"Cumulative Timesteps":337867946,"Timesteps Collected":50029,"PPO Batch Consumption Time":0.024239738782246906,"Timestep Collection Time":4.703377675032243,"_runtime":77882,"Policy Entropy":1.2644917368888855,"Policy Reward":78.91305069309485,"Cumulative Model Updates":40476}