Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: -49.51237
Policy Entropy: 1.41693
Value Function Loss: 0.00894

Mean KL Divergence: 0.00008
SB3 Clip Fraction: 0.00009
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.03787

Collected Steps per Second: 9745.27608
Overall Steps per Second: 5409.93655

Timestep Collection Time: 5.13120
Timestep Consumption Time: 4.11197
PPO Batch Consumption Time: 0.18738
Total Iteration Time: 9.24318

Cumulative Model Updates: 18338
Cumulative Timesteps: 153284983

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -47.20389
Policy Entropy: 1.41727
Value Function Loss: 0.00959

Mean KL Divergence: 0.00133
SB3 Clip Fraction: 0.01514
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.08911

Collected Steps per Second: 9951.89361
Overall Steps per Second: 2401.73295

Timestep Collection Time: 5.02728
Timestep Consumption Time: 15.80392
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 20.83121

Cumulative Model Updates: 18342
Cumulative Timesteps: 153335014

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.24527
Policy Entropy: 1.41717
Value Function Loss: 0.01010

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01519
Policy Update Magnitude: 0.07155
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 10705.18409
Overall Steps per Second: 7414.96981

Timestep Collection Time: 4.67129
Timestep Consumption Time: 2.07277
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 6.74406

Cumulative Model Updates: 18348
Cumulative Timesteps: 153385021

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -11.00019
Policy Entropy: 1.41716
Value Function Loss: 0.01039

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.06885
Value Function Update Magnitude: 0.08529

Collected Steps per Second: 9845.84283
Overall Steps per Second: 7031.80187

Timestep Collection Time: 5.07961
Timestep Consumption Time: 2.03280
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 7.11240

Cumulative Model Updates: 18354
Cumulative Timesteps: 153435034

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.30103
Policy Entropy: 1.41700
Value Function Loss: 0.01071

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01565
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 9739.61521
Overall Steps per Second: 6950.80987

Timestep Collection Time: 5.13491
Timestep Consumption Time: 2.06023
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.19513

Cumulative Model Updates: 18360
Cumulative Timesteps: 153485046

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -10.81002
Policy Entropy: 1.41706
Value Function Loss: 0.01107

Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.01301
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.08344

Collected Steps per Second: 10517.03997
Overall Steps per Second: 7263.21027

Timestep Collection Time: 4.75695
Timestep Consumption Time: 2.13105
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 6.88800

Cumulative Model Updates: 18366
Cumulative Timesteps: 153535075

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02143
Policy Entropy: 1.41704
Value Function Loss: 0.01102

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.01097
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.07944

Collected Steps per Second: 9186.16959
Overall Steps per Second: 6712.87493

Timestep Collection Time: 5.44351
Timestep Consumption Time: 2.00561
PPO Batch Consumption Time: 0.02455
Total Iteration Time: 7.44912

Cumulative Model Updates: 18372
Cumulative Timesteps: 153585080

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.88552
Policy Entropy: 1.41726
Value Function Loss: 0.01126

Mean KL Divergence: 0.00096
SB3 Clip Fraction: 0.01041
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.07829

Collected Steps per Second: 9495.83094
Overall Steps per Second: 6869.71760

Timestep Collection Time: 5.26736
Timestep Consumption Time: 2.01358
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.28094

Cumulative Model Updates: 18378
Cumulative Timesteps: 153635098

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.96226
Policy Entropy: 1.41710
Value Function Loss: 0.01149

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.01095
Policy Update Magnitude: 0.06311
Value Function Update Magnitude: 0.08080

Collected Steps per Second: 10288.29847
Overall Steps per Second: 7237.18231

Timestep Collection Time: 4.86193
Timestep Consumption Time: 2.04974
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 6.91167

Cumulative Model Updates: 18384
Cumulative Timesteps: 153685119

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.10454
Policy Entropy: 1.41727
Value Function Loss: 0.01141

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01404
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.07468

Collected Steps per Second: 9263.08998
Overall Steps per Second: 6576.14625

Timestep Collection Time: 5.39841
Timestep Consumption Time: 2.20574
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.60415

Cumulative Model Updates: 18390
Cumulative Timesteps: 153735125

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 153735125...
Checkpoint 153735125 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.42093
Policy Entropy: 1.41722
Value Function Loss: 0.01158

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.01400
Policy Update Magnitude: 0.06144
Value Function Update Magnitude: 0.07193

Collected Steps per Second: 9521.63776
Overall Steps per Second: 6761.17699

Timestep Collection Time: 5.25477
Timestep Consumption Time: 2.14542
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.40019

Cumulative Model Updates: 18396
Cumulative Timesteps: 153785159

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.10239
Policy Entropy: 1.41707
Value Function Loss: 0.01159

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.06912

Collected Steps per Second: 9781.96182
Overall Steps per Second: 6744.10658

Timestep Collection Time: 5.11247
Timestep Consumption Time: 2.30289
PPO Batch Consumption Time: 0.02453
Total Iteration Time: 7.41536

Cumulative Model Updates: 18402
Cumulative Timesteps: 153835169

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.21285
Policy Entropy: 1.41686
Value Function Loss: 0.01233

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.01064
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.06945

Collected Steps per Second: 8998.21018
Overall Steps per Second: 6501.06864

Timestep Collection Time: 5.55966
Timestep Consumption Time: 2.13554
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.69520

Cumulative Model Updates: 18408
Cumulative Timesteps: 153885196

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -10.79586
Policy Entropy: 1.41689
Value Function Loss: 0.01277

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01420
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.07007

Collected Steps per Second: 9456.30906
Overall Steps per Second: 6740.58898

Timestep Collection Time: 5.29202
Timestep Consumption Time: 2.13211
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.42413

Cumulative Model Updates: 18414
Cumulative Timesteps: 153935239

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.06802
Policy Entropy: 1.41677
Value Function Loss: 0.01271

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01467
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.07419

Collected Steps per Second: 9741.15962
Overall Steps per Second: 6754.03341

Timestep Collection Time: 5.13348
Timestep Consumption Time: 2.27040
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.40387

Cumulative Model Updates: 18420
Cumulative Timesteps: 153985245

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.38255
Policy Entropy: 1.41715
Value Function Loss: 0.01166

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01754
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.07553

Collected Steps per Second: 9240.50750
Overall Steps per Second: 6722.32474

Timestep Collection Time: 5.41529
Timestep Consumption Time: 2.02857
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.44385

Cumulative Model Updates: 18426
Cumulative Timesteps: 154035285

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -13.29601
Policy Entropy: 1.41718
Value Function Loss: 0.01134

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.08066

Collected Steps per Second: 9533.41853
Overall Steps per Second: 6878.62386

Timestep Collection Time: 5.24691
Timestep Consumption Time: 2.02504
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 7.27195

Cumulative Model Updates: 18432
Cumulative Timesteps: 154085306

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -12.96903
Policy Entropy: 1.41728
Value Function Loss: 0.01103

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.01326
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.07932

Collected Steps per Second: 9314.45231
Overall Steps per Second: 6611.10386

Timestep Collection Time: 5.37004
Timestep Consumption Time: 2.19587
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.56591

Cumulative Model Updates: 18438
Cumulative Timesteps: 154135325

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.28050
Policy Entropy: 1.41720
Value Function Loss: 0.01000

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.01164
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.08178

Collected Steps per Second: 8983.73931
Overall Steps per Second: 6581.85242

Timestep Collection Time: 5.56806
Timestep Consumption Time: 2.03193
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.59999

Cumulative Model Updates: 18444
Cumulative Timesteps: 154185347

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.13440
Policy Entropy: 1.41725
Value Function Loss: 0.00989

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.01245
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.08748

Collected Steps per Second: 9494.25800
Overall Steps per Second: 6956.15694

Timestep Collection Time: 5.26961
Timestep Consumption Time: 1.92273
PPO Batch Consumption Time: 0.02381
Total Iteration Time: 7.19233

Cumulative Model Updates: 18450
Cumulative Timesteps: 154235378

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 154235378...
Checkpoint 154235378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -18.63938
Policy Entropy: 1.41720
Value Function Loss: 0.00910

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.00953
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 10155.88020
Overall Steps per Second: 7166.37427

Timestep Collection Time: 4.92355
Timestep Consumption Time: 2.05390
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 6.97745

Cumulative Model Updates: 18456
Cumulative Timesteps: 154285381

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -21.51693
Policy Entropy: 1.41741
Value Function Loss: 0.00898

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.01092
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.08802

Collected Steps per Second: 10125.76292
Overall Steps per Second: 7246.69693

Timestep Collection Time: 4.93889
Timestep Consumption Time: 1.96219
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 6.90108

Cumulative Model Updates: 18462
Cumulative Timesteps: 154335391

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.87624
Policy Entropy: 1.41740
Value Function Loss: 0.00898

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.01259
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 9448.53831
Overall Steps per Second: 6810.95836

Timestep Collection Time: 5.29288
Timestep Consumption Time: 2.04970
PPO Batch Consumption Time: 0.02438
Total Iteration Time: 7.34258

Cumulative Model Updates: 18468
Cumulative Timesteps: 154385401

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -27.43900
Policy Entropy: 1.41724
Value Function Loss: 0.00954

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01369
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.09292

Collected Steps per Second: 9919.26984
Overall Steps per Second: 7002.14062

Timestep Collection Time: 5.04321
Timestep Consumption Time: 2.10103
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.14424

Cumulative Model Updates: 18474
Cumulative Timesteps: 154435426

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.29120
Policy Entropy: 1.41730
Value Function Loss: 0.00964

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.01067
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.09699

Collected Steps per Second: 9806.42094
Overall Steps per Second: 7015.51504

Timestep Collection Time: 5.09870
Timestep Consumption Time: 2.02836
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.12706

Cumulative Model Updates: 18480
Cumulative Timesteps: 154485426

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97225
Policy Entropy: 1.41724
Value Function Loss: 0.01000

Mean KL Divergence: 0.00105
SB3 Clip Fraction: 0.01151
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.09866

Collected Steps per Second: 9542.20759
Overall Steps per Second: 6883.49930

Timestep Collection Time: 5.24313
Timestep Consumption Time: 2.02512
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.26825

Cumulative Model Updates: 18486
Cumulative Timesteps: 154535457

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.64398
Policy Entropy: 1.41720
Value Function Loss: 0.01042

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.01206
Policy Update Magnitude: 0.06238
Value Function Update Magnitude: 0.09982

Collected Steps per Second: 10386.74167
Overall Steps per Second: 7201.35927

Timestep Collection Time: 4.81421
Timestep Consumption Time: 2.12947
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 6.94369

Cumulative Model Updates: 18492
Cumulative Timesteps: 154585461

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -36.52377
Policy Entropy: 1.41730
Value Function Loss: 0.00980

Mean KL Divergence: 0.00115
SB3 Clip Fraction: 0.01182
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.10095

Collected Steps per Second: 9932.55702
Overall Steps per Second: 7086.55785

Timestep Collection Time: 5.03506
Timestep Consumption Time: 2.02211
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 7.05716

Cumulative Model Updates: 18498
Cumulative Timesteps: 154635472

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.92131
Policy Entropy: 1.41738
Value Function Loss: 0.00934

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.01251
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.10392

Collected Steps per Second: 9222.68284
Overall Steps per Second: 6571.92685

Timestep Collection Time: 5.42250
Timestep Consumption Time: 2.18714
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.60964

Cumulative Model Updates: 18504
Cumulative Timesteps: 154685482

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.36087
Policy Entropy: 1.41734
Value Function Loss: 0.00855

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.01257
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.10138

Collected Steps per Second: 9755.28647
Overall Steps per Second: 6883.27102

Timestep Collection Time: 5.12584
Timestep Consumption Time: 2.13873
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 7.26457

Cumulative Model Updates: 18510
Cumulative Timesteps: 154735486

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 154735486...
Checkpoint 154735486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.91530
Policy Entropy: 1.41736
Value Function Loss: 0.00914

Mean KL Divergence: 0.00094
SB3 Clip Fraction: 0.01023
Policy Update Magnitude: 0.06399
Value Function Update Magnitude: 0.10326

Collected Steps per Second: 9476.51990
Overall Steps per Second: 6816.58230

Timestep Collection Time: 5.27863
Timestep Consumption Time: 2.05980
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 7.33843

Cumulative Model Updates: 18516
Cumulative Timesteps: 154785509

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -7.42198
Policy Entropy: 1.41726
Value Function Loss: 0.00956

Mean KL Divergence: 0.00100
SB3 Clip Fraction: 0.01101
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.10252

Collected Steps per Second: 9614.82516
Overall Steps per Second: 6898.80959

Timestep Collection Time: 5.20030
Timestep Consumption Time: 2.04732
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.24763

Cumulative Model Updates: 18522
Cumulative Timesteps: 154835509

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -4.44375
Policy Entropy: 1.41729
Value Function Loss: 0.00938

Mean KL Divergence: 0.00110
SB3 Clip Fraction: 0.01234
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.10138

Collected Steps per Second: 10020.20513
Overall Steps per Second: 6893.75148

Timestep Collection Time: 4.99181
Timestep Consumption Time: 2.26389
PPO Batch Consumption Time: 0.02935
Total Iteration Time: 7.25570

Cumulative Model Updates: 18528
Cumulative Timesteps: 154885528

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.50793
Policy Entropy: 1.41731
Value Function Loss: 0.00948

Mean KL Divergence: 0.00121
SB3 Clip Fraction: 0.01380
Policy Update Magnitude: 0.06566
Value Function Update Magnitude: 0.09809

Collected Steps per Second: 8979.90245
Overall Steps per Second: 6434.92372

Timestep Collection Time: 5.57278
Timestep Consumption Time: 2.20400
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.77678

Cumulative Model Updates: 18534
Cumulative Timesteps: 154935571

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.08573
Policy Entropy: 1.41736
Value Function Loss: 0.00951

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01450
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.10406

Collected Steps per Second: 9194.69096
Overall Steps per Second: 6634.06105

Timestep Collection Time: 5.43879
Timestep Consumption Time: 2.09928
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.53807

Cumulative Model Updates: 18540
Cumulative Timesteps: 154985579

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44868
Policy Entropy: 1.41729
Value Function Loss: 0.00967

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.01207
Policy Update Magnitude: 0.06417
Value Function Update Magnitude: 0.10502

Collected Steps per Second: 10649.06428
Overall Steps per Second: 7282.32043

Timestep Collection Time: 4.69694
Timestep Consumption Time: 2.17148
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 6.86842

Cumulative Model Updates: 18546
Cumulative Timesteps: 155035597

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.40624
Policy Entropy: 1.41722
Value Function Loss: 0.00950

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01290
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.10266

Collected Steps per Second: 9346.63443
Overall Steps per Second: 6689.59649

Timestep Collection Time: 5.34995
Timestep Consumption Time: 2.12494
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.47489

Cumulative Model Updates: 18552
Cumulative Timesteps: 155085601

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -38.89983
Policy Entropy: 1.41720
Value Function Loss: 0.00892

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01416
Policy Update Magnitude: 0.06393
Value Function Update Magnitude: 0.10062

Collected Steps per Second: 9894.99211
Overall Steps per Second: 7032.07525

Timestep Collection Time: 5.05751
Timestep Consumption Time: 2.05903
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.11653

Cumulative Model Updates: 18558
Cumulative Timesteps: 155135645

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -16.36460
Policy Entropy: 1.41725
Value Function Loss: 0.00863

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.01171
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.09887

Collected Steps per Second: 9973.81580
Overall Steps per Second: 6957.83008

Timestep Collection Time: 5.01483
Timestep Consumption Time: 2.17376
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 7.18859

Cumulative Model Updates: 18564
Cumulative Timesteps: 155185662

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.36017
Policy Entropy: 1.41704
Value Function Loss: 0.00903

Mean KL Divergence: 0.00098
SB3 Clip Fraction: 0.01089
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.10305

Collected Steps per Second: 9911.55783
Overall Steps per Second: 6934.05049

Timestep Collection Time: 5.04603
Timestep Consumption Time: 2.16678
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 7.21281

Cumulative Model Updates: 18570
Cumulative Timesteps: 155235676

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 155235676...
Checkpoint 155235676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.75499
Policy Entropy: 1.41700
Value Function Loss: 0.00973

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.01053
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.10413

Collected Steps per Second: 9915.20258
Overall Steps per Second: 7068.86552

Timestep Collection Time: 5.04407
Timestep Consumption Time: 2.03104
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.07511

Cumulative Model Updates: 18576
Cumulative Timesteps: 155285689

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.70114
Policy Entropy: 1.41716
Value Function Loss: 0.01012

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01445
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 10449.28716
Overall Steps per Second: 7211.49877

Timestep Collection Time: 4.78817
Timestep Consumption Time: 2.14977
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.93795

Cumulative Model Updates: 18582
Cumulative Timesteps: 155335722

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -3.31137
Policy Entropy: 1.41707
Value Function Loss: 0.01046

Mean KL Divergence: 0.00095
SB3 Clip Fraction: 0.01054
Policy Update Magnitude: 0.06901
Value Function Update Magnitude: 0.10707

Collected Steps per Second: 9718.31355
Overall Steps per Second: 6992.72753

Timestep Collection Time: 5.14544
Timestep Consumption Time: 2.00556
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.15100

Cumulative Model Updates: 18588
Cumulative Timesteps: 155385727

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -45.31092
Policy Entropy: 1.41706
Value Function Loss: 0.00998

Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.01005
Policy Update Magnitude: 0.06991
Value Function Update Magnitude: 0.10619

Collected Steps per Second: 9719.58005
Overall Steps per Second: 6939.00598

Timestep Collection Time: 5.14446
Timestep Consumption Time: 2.06147
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.20593

Cumulative Model Updates: 18594
Cumulative Timesteps: 155435729

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.48366
Policy Entropy: 1.41705
Value Function Loss: 0.00956

Mean KL Divergence: 0.00109
SB3 Clip Fraction: 0.01142
Policy Update Magnitude: 0.06975
Value Function Update Magnitude: 0.10402

Collected Steps per Second: 10474.82120
Overall Steps per Second: 7275.53003

Timestep Collection Time: 4.77679
Timestep Consumption Time: 2.10051
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 6.87730

Cumulative Model Updates: 18600
Cumulative Timesteps: 155485765

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10595
Policy Entropy: 1.41696
Value Function Loss: 0.00888

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.01092
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.10167

Collected Steps per Second: 9956.03273
Overall Steps per Second: 7096.09208

Timestep Collection Time: 5.02399
Timestep Consumption Time: 2.02482
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 7.04881

Cumulative Model Updates: 18606
Cumulative Timesteps: 155535784

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.27151
Policy Entropy: 1.41696
Value Function Loss: 0.00885

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.01045
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.09666

Collected Steps per Second: 9778.91816
Overall Steps per Second: 7017.89652

Timestep Collection Time: 5.11519
Timestep Consumption Time: 2.01245
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.12763

Cumulative Model Updates: 18612
Cumulative Timesteps: 155585805

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.16497
Policy Entropy: 1.41669
Value Function Loss: 0.00938

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.01096
Policy Update Magnitude: 0.07029
Value Function Update Magnitude: 0.09670

Collected Steps per Second: 10325.89842
Overall Steps per Second: 7087.25349

Timestep Collection Time: 4.84452
Timestep Consumption Time: 2.21379
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 7.05831

Cumulative Model Updates: 18618
Cumulative Timesteps: 155635829

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.34863
Policy Entropy: 1.41672
Value Function Loss: 0.00945

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.01101
Policy Update Magnitude: 0.07259
Value Function Update Magnitude: 0.10106

Collected Steps per Second: 9904.81257
Overall Steps per Second: 7038.15961

Timestep Collection Time: 5.05219
Timestep Consumption Time: 2.05776
PPO Batch Consumption Time: 0.02843
Total Iteration Time: 7.10996

Cumulative Model Updates: 18624
Cumulative Timesteps: 155685870

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.33869
Policy Entropy: 1.41656
Value Function Loss: 0.00964

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01493
Policy Update Magnitude: 0.06589
Value Function Update Magnitude: 0.10323

Collected Steps per Second: 9236.00453
Overall Steps per Second: 6477.35736

Timestep Collection Time: 5.41760
Timestep Consumption Time: 2.30731
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.72491

Cumulative Model Updates: 18630
Cumulative Timesteps: 155735907

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 155735907...
Checkpoint 155735907 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.70795
Policy Entropy: 1.41678
Value Function Loss: 0.00999

Mean KL Divergence: 0.00127
SB3 Clip Fraction: 0.01366
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.10493

Collected Steps per Second: 9749.94984
Overall Steps per Second: 6887.71295

Timestep Collection Time: 5.13080
Timestep Consumption Time: 2.13214
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 7.26293

Cumulative Model Updates: 18636
Cumulative Timesteps: 155785932

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.83398
Policy Entropy: 1.41669
Value Function Loss: 0.01021

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.07171
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 9589.76310
Overall Steps per Second: 6892.77320

Timestep Collection Time: 5.21765
Timestep Consumption Time: 2.04155
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.25920

Cumulative Model Updates: 18642
Cumulative Timesteps: 155835968

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11764
Policy Entropy: 1.41643
Value Function Loss: 0.00993

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02046
Policy Update Magnitude: 0.06947
Value Function Update Magnitude: 0.10315

Collected Steps per Second: 9714.34010
Overall Steps per Second: 6971.52019

Timestep Collection Time: 5.14878
Timestep Consumption Time: 2.02570
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 7.17448

Cumulative Model Updates: 18648
Cumulative Timesteps: 155885985

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -36.36885
Policy Entropy: 1.41629
Value Function Loss: 0.00980

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01379
Policy Update Magnitude: 0.07088
Value Function Update Magnitude: 0.09884

Collected Steps per Second: 10493.12818
Overall Steps per Second: 7276.18365

Timestep Collection Time: 4.76588
Timestep Consumption Time: 2.10709
PPO Batch Consumption Time: 0.02854
Total Iteration Time: 6.87297

Cumulative Model Updates: 18654
Cumulative Timesteps: 155935994

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.41917
Policy Entropy: 1.41639
Value Function Loss: 0.00956

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.01429
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.09654

Collected Steps per Second: 9896.30703
Overall Steps per Second: 6970.70940

Timestep Collection Time: 5.05401
Timestep Consumption Time: 2.12116
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.17517

Cumulative Model Updates: 18660
Cumulative Timesteps: 155986010

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -8.29459
Policy Entropy: 1.41653
Value Function Loss: 0.00942

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01380
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.09705

Collected Steps per Second: 9123.57774
Overall Steps per Second: 6497.31764

Timestep Collection Time: 5.48085
Timestep Consumption Time: 2.21540
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 7.69625

Cumulative Model Updates: 18666
Cumulative Timesteps: 156036015

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.73380
Policy Entropy: 1.41640
Value Function Loss: 0.00955

Mean KL Divergence: 0.00120
SB3 Clip Fraction: 0.01214
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.09748

Collected Steps per Second: 10069.19867
Overall Steps per Second: 6994.57892

Timestep Collection Time: 4.96772
Timestep Consumption Time: 2.18367
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.15140

Cumulative Model Updates: 18672
Cumulative Timesteps: 156086036

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75114
Policy Entropy: 1.41635
Value Function Loss: 0.01015

Mean KL Divergence: 0.00104
SB3 Clip Fraction: 0.01102
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.10191

Collected Steps per Second: 9605.78516
Overall Steps per Second: 6887.40239

Timestep Collection Time: 5.21009
Timestep Consumption Time: 2.05637
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.26646

Cumulative Model Updates: 18678
Cumulative Timesteps: 156136083

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.82847
Policy Entropy: 1.41618
Value Function Loss: 0.01048

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.01149
Policy Update Magnitude: 0.07341
Value Function Update Magnitude: 0.10728

Collected Steps per Second: 9740.48749
Overall Steps per Second: 6970.98149

Timestep Collection Time: 5.13681
Timestep Consumption Time: 2.04081
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.17761

Cumulative Model Updates: 18684
Cumulative Timesteps: 156186118

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.21834
Policy Entropy: 1.41632
Value Function Loss: 0.01073

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01301
Policy Update Magnitude: 0.07280
Value Function Update Magnitude: 0.11093

Collected Steps per Second: 10508.59828
Overall Steps per Second: 7306.67925

Timestep Collection Time: 4.76077
Timestep Consumption Time: 2.08625
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 6.84702

Cumulative Model Updates: 18690
Cumulative Timesteps: 156236147

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 156236147...
Checkpoint 156236147 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.34410
Policy Entropy: 1.41637
Value Function Loss: 0.01081

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.01455
Policy Update Magnitude: 0.07045
Value Function Update Magnitude: 0.10696

Collected Steps per Second: 9394.94425
Overall Steps per Second: 6769.58116

Timestep Collection Time: 5.32446
Timestep Consumption Time: 2.06492
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.38938

Cumulative Model Updates: 18696
Cumulative Timesteps: 156286170

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.83783
Policy Entropy: 1.41626
Value Function Loss: 0.01068

Mean KL Divergence: 0.00107
SB3 Clip Fraction: 0.01104
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.10568

Collected Steps per Second: 9148.53153
Overall Steps per Second: 6578.58767

Timestep Collection Time: 5.46656
Timestep Consumption Time: 2.13553
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.60209

Cumulative Model Updates: 18702
Cumulative Timesteps: 156336181

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.75368
Policy Entropy: 1.41611
Value Function Loss: 0.00991

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.00944
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 10142.62763
Overall Steps per Second: 7026.39605

Timestep Collection Time: 4.93038
Timestep Consumption Time: 2.18664
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.11702

Cumulative Model Updates: 18708
Cumulative Timesteps: 156386188

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.75371
Policy Entropy: 1.41617
Value Function Loss: 0.00911

Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.01083
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.10446

Collected Steps per Second: 9872.71693
Overall Steps per Second: 7055.23260

Timestep Collection Time: 5.06639
Timestep Consumption Time: 2.02325
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.08963

Cumulative Model Updates: 18714
Cumulative Timesteps: 156436207

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.78078
Policy Entropy: 1.41603
Value Function Loss: 0.00942

Mean KL Divergence: 0.00124
SB3 Clip Fraction: 0.01307
Policy Update Magnitude: 0.06748
Value Function Update Magnitude: 0.10526

Collected Steps per Second: 9840.69522
Overall Steps per Second: 6990.56774

Timestep Collection Time: 5.08155
Timestep Consumption Time: 2.07180
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 7.15335

Cumulative Model Updates: 18720
Cumulative Timesteps: 156486213

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -21.01495
Policy Entropy: 1.41597
Value Function Loss: 0.00945

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01546
Policy Update Magnitude: 0.06928
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 10297.57869
Overall Steps per Second: 7227.84560

Timestep Collection Time: 4.85852
Timestep Consumption Time: 2.06346
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.92198

Cumulative Model Updates: 18726
Cumulative Timesteps: 156536244

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.77006
Policy Entropy: 1.41571
Value Function Loss: 0.01003

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.01407
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.10333

Collected Steps per Second: 10013.09112
Overall Steps per Second: 7148.68667

Timestep Collection Time: 4.99496
Timestep Consumption Time: 2.00143
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 6.99639

Cumulative Model Updates: 18732
Cumulative Timesteps: 156586259

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.12147
Policy Entropy: 1.41551
Value Function Loss: 0.00987

Mean KL Divergence: 0.00102
SB3 Clip Fraction: 0.01081
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.10748

Collected Steps per Second: 9809.54443
Overall Steps per Second: 6972.13310

Timestep Collection Time: 5.10013
Timestep Consumption Time: 2.07557
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.17571

Cumulative Model Updates: 18738
Cumulative Timesteps: 156636289

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -22.37981
Policy Entropy: 1.41547
Value Function Loss: 0.00989

Mean KL Divergence: 0.00099
SB3 Clip Fraction: 0.01048
Policy Update Magnitude: 0.06880
Value Function Update Magnitude: 0.10889

Collected Steps per Second: 10439.90182
Overall Steps per Second: 7381.37064

Timestep Collection Time: 4.78999
Timestep Consumption Time: 1.98477
PPO Batch Consumption Time: 0.02448
Total Iteration Time: 6.77476

Cumulative Model Updates: 18744
Cumulative Timesteps: 156686296

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -3.91495
Policy Entropy: 1.41573
Value Function Loss: 0.00944

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.01188
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.10306

Collected Steps per Second: 9841.16918
Overall Steps per Second: 6926.59547

Timestep Collection Time: 5.08263
Timestep Consumption Time: 2.13867
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 7.22130

Cumulative Model Updates: 18750
Cumulative Timesteps: 156736315

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 156736315...
Checkpoint 156736315 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.42775
Policy Entropy: 1.41573
Value Function Loss: 0.01003

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.01217
Policy Update Magnitude: 0.06893
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 9275.52579
Overall Steps per Second: 6593.99701

Timestep Collection Time: 5.39398
Timestep Consumption Time: 2.19353
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.58751

Cumulative Model Updates: 18756
Cumulative Timesteps: 156786347

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.12229
Policy Entropy: 1.41562
Value Function Loss: 0.00998

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01658
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.09744

Collected Steps per Second: 9612.32399
Overall Steps per Second: 6749.23555

Timestep Collection Time: 5.20446
Timestep Consumption Time: 2.20778
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 7.41225

Cumulative Model Updates: 18762
Cumulative Timesteps: 156836374

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.35226
Policy Entropy: 1.41549
Value Function Loss: 0.01021

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01625
Policy Update Magnitude: 0.06821
Value Function Update Magnitude: 0.09982

Collected Steps per Second: 9523.12926
Overall Steps per Second: 6836.27037

Timestep Collection Time: 5.25374
Timestep Consumption Time: 2.06488
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.31861

Cumulative Model Updates: 18768
Cumulative Timesteps: 156886406

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.37132
Policy Entropy: 1.41537
Value Function Loss: 0.01023

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01546
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.09902

Collected Steps per Second: 9677.35465
Overall Steps per Second: 6949.88568

Timestep Collection Time: 5.16680
Timestep Consumption Time: 2.02770
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.19451

Cumulative Model Updates: 18774
Cumulative Timesteps: 156936407

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.67729
Policy Entropy: 1.41535
Value Function Loss: 0.01085

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01566
Policy Update Magnitude: 0.06924
Value Function Update Magnitude: 0.10114

Collected Steps per Second: 10367.70681
Overall Steps per Second: 7239.41783

Timestep Collection Time: 4.82267
Timestep Consumption Time: 2.08397
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 6.90663

Cumulative Model Updates: 18780
Cumulative Timesteps: 156986407

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.10049
Policy Entropy: 1.41540
Value Function Loss: 0.01071

Mean KL Divergence: 0.00117
SB3 Clip Fraction: 0.01294
Policy Update Magnitude: 0.07224
Value Function Update Magnitude: 0.10195

Collected Steps per Second: 9897.11537
Overall Steps per Second: 7076.65815

Timestep Collection Time: 5.05450
Timestep Consumption Time: 2.01451
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 7.06901

Cumulative Model Updates: 18786
Cumulative Timesteps: 157036432

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -33.79245
Policy Entropy: 1.41502
Value Function Loss: 0.01104

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.01149
Policy Update Magnitude: 0.07026
Value Function Update Magnitude: 0.10123

Collected Steps per Second: 9733.25764
Overall Steps per Second: 6943.01454

Timestep Collection Time: 5.14114
Timestep Consumption Time: 2.06611
PPO Batch Consumption Time: 0.02460
Total Iteration Time: 7.20724

Cumulative Model Updates: 18792
Cumulative Timesteps: 157086472

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.70236
Policy Entropy: 1.41491
Value Function Loss: 0.01068

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01692
Policy Update Magnitude: 0.07149
Value Function Update Magnitude: 0.10188

Collected Steps per Second: 10530.29630
Overall Steps per Second: 7270.19053

Timestep Collection Time: 4.75048
Timestep Consumption Time: 2.13022
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 6.88070

Cumulative Model Updates: 18798
Cumulative Timesteps: 157136496

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.51394
Policy Entropy: 1.41499
Value Function Loss: 0.01010

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.01517
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.09700

Collected Steps per Second: 9974.67656
Overall Steps per Second: 7062.90563

Timestep Collection Time: 5.01520
Timestep Consumption Time: 2.06758
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.08278

Cumulative Model Updates: 18804
Cumulative Timesteps: 157186521

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -34.29719
Policy Entropy: 1.41539
Value Function Loss: 0.00935

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01629
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.09676

Collected Steps per Second: 9846.93018
Overall Steps per Second: 7044.42923

Timestep Collection Time: 5.08128
Timestep Consumption Time: 2.02150
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 7.10278

Cumulative Model Updates: 18810
Cumulative Timesteps: 157236556

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 157236556...
Checkpoint 157236556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -4.03648
Policy Entropy: 1.41476
Value Function Loss: 0.00974

Mean KL Divergence: 0.00146
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.06590
Value Function Update Magnitude: 0.09999

Collected Steps per Second: 10490.67567
Overall Steps per Second: 7236.54671

Timestep Collection Time: 4.76642
Timestep Consumption Time: 2.14336
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 6.90979

Cumulative Model Updates: 18816
Cumulative Timesteps: 157286559

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -35.76545
Policy Entropy: 1.41468
Value Function Loss: 0.01045

Mean KL Divergence: 0.00125
SB3 Clip Fraction: 0.01329
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.10150

Collected Steps per Second: 9814.87676
Overall Steps per Second: 7016.99214

Timestep Collection Time: 5.09645
Timestep Consumption Time: 2.03211
PPO Batch Consumption Time: 0.02431
Total Iteration Time: 7.12855

Cumulative Model Updates: 18822
Cumulative Timesteps: 157336580

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.53424
Policy Entropy: 1.41470
Value Function Loss: 0.01086

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01655
Policy Update Magnitude: 0.07378
Value Function Update Magnitude: 0.10468

Collected Steps per Second: 9677.80635
Overall Steps per Second: 6924.46619

Timestep Collection Time: 5.17070
Timestep Consumption Time: 2.05600
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.22669

Cumulative Model Updates: 18828
Cumulative Timesteps: 157386621

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.34131
Policy Entropy: 1.41462
Value Function Loss: 0.01068

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02186
Policy Update Magnitude: 0.07343
Value Function Update Magnitude: 0.10264

Collected Steps per Second: 10568.08916
Overall Steps per Second: 7300.28601

Timestep Collection Time: 4.73236
Timestep Consumption Time: 2.11833
PPO Batch Consumption Time: 0.02451
Total Iteration Time: 6.85069

Cumulative Model Updates: 18834
Cumulative Timesteps: 157436633

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.88883
Policy Entropy: 1.41440
Value Function Loss: 0.01029

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01864
Policy Update Magnitude: 0.07026
Value Function Update Magnitude: 0.09943

Collected Steps per Second: 9621.89589
Overall Steps per Second: 6899.55241

Timestep Collection Time: 5.20022
Timestep Consumption Time: 2.05184
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.25206

Cumulative Model Updates: 18840
Cumulative Timesteps: 157486669

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -11.86530
Policy Entropy: 1.41431
Value Function Loss: 0.01018

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01904
Policy Update Magnitude: 0.07187
Value Function Update Magnitude: 0.09705

Collected Steps per Second: 9795.63951
Overall Steps per Second: 7011.50046

Timestep Collection Time: 5.10778
Timestep Consumption Time: 2.02821
PPO Batch Consumption Time: 0.02437
Total Iteration Time: 7.13599

Cumulative Model Updates: 18846
Cumulative Timesteps: 157536703

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.42668
Policy Entropy: 1.41427
Value Function Loss: 0.00973

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01838
Policy Update Magnitude: 0.07015
Value Function Update Magnitude: 0.09432

Collected Steps per Second: 10486.08880
Overall Steps per Second: 7443.93977

Timestep Collection Time: 4.76898
Timestep Consumption Time: 1.94896
PPO Batch Consumption Time: 0.02490
Total Iteration Time: 6.71795

Cumulative Model Updates: 18852
Cumulative Timesteps: 157586711

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.67303
Policy Entropy: 1.41390
Value Function Loss: 0.00991

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01642
Policy Update Magnitude: 0.07036
Value Function Update Magnitude: 0.09332

Collected Steps per Second: 9904.23992
Overall Steps per Second: 7060.13104

Timestep Collection Time: 5.05208
Timestep Consumption Time: 2.03518
PPO Batch Consumption Time: 0.02422
Total Iteration Time: 7.08726

Cumulative Model Updates: 18858
Cumulative Timesteps: 157636748

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.48533
Policy Entropy: 1.41374
Value Function Loss: 0.00975

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.07080
Value Function Update Magnitude: 0.09628

Collected Steps per Second: 9806.67865
Overall Steps per Second: 7036.07368

Timestep Collection Time: 5.10071
Timestep Consumption Time: 2.00851
PPO Batch Consumption Time: 0.02420
Total Iteration Time: 7.10922

Cumulative Model Updates: 18864
Cumulative Timesteps: 157686769

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.04547
Policy Entropy: 1.41356
Value Function Loss: 0.01048

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01844
Policy Update Magnitude: 0.07164
Value Function Update Magnitude: 0.09897

Collected Steps per Second: 10412.72340
Overall Steps per Second: 7239.99309

Timestep Collection Time: 4.80211
Timestep Consumption Time: 2.10439
PPO Batch Consumption Time: 0.02418
Total Iteration Time: 6.90650

Cumulative Model Updates: 18870
Cumulative Timesteps: 157736772

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 157736772...
Checkpoint 157736772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.62090
Policy Entropy: 1.41387
Value Function Loss: 0.01017

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01476
Policy Update Magnitude: 0.07035
Value Function Update Magnitude: 0.10218

Collected Steps per Second: 9759.01933
Overall Steps per Second: 6962.34182

Timestep Collection Time: 5.12582
Timestep Consumption Time: 2.05897
PPO Batch Consumption Time: 0.02424
Total Iteration Time: 7.18480

Cumulative Model Updates: 18876
Cumulative Timesteps: 157786795

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.01019
Policy Entropy: 1.41347
Value Function Loss: 0.01018

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01467
Policy Update Magnitude: 0.06986
Value Function Update Magnitude: 0.10028

Collected Steps per Second: 9664.90577
Overall Steps per Second: 6813.40410

Timestep Collection Time: 5.17398
Timestep Consumption Time: 2.16538
PPO Batch Consumption Time: 0.02403
Total Iteration Time: 7.33936

Cumulative Model Updates: 18882
Cumulative Timesteps: 157836801

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.35628
Policy Entropy: 1.41327
Value Function Loss: 0.01053

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01817
Policy Update Magnitude: 0.07215
Value Function Update Magnitude: 0.09733

Collected Steps per Second: 10253.79357
Overall Steps per Second: 7166.94260

Timestep Collection Time: 4.87663
Timestep Consumption Time: 2.10040
PPO Batch Consumption Time: 0.02444
Total Iteration Time: 6.97703

Cumulative Model Updates: 18888
Cumulative Timesteps: 157886805

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.58274
Policy Entropy: 1.41303
Value Function Loss: 0.01050

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01864
Policy Update Magnitude: 0.07237
Value Function Update Magnitude: 0.09896

Collected Steps per Second: 9901.77631
Overall Steps per Second: 7056.09529

Timestep Collection Time: 5.04990
Timestep Consumption Time: 2.03660
PPO Batch Consumption Time: 0.02471
Total Iteration Time: 7.08650

Cumulative Model Updates: 18894
Cumulative Timesteps: 157936808

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -24.77149
Policy Entropy: 1.41285
Value Function Loss: 0.01016

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.01427
Policy Update Magnitude: 0.07380
Value Function Update Magnitude: 0.09602

Collected Steps per Second: 9961.01255
Overall Steps per Second: 7055.70066

Timestep Collection Time: 5.02088
Timestep Consumption Time: 2.06744
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 7.08831

Cumulative Model Updates: 18900
Cumulative Timesteps: 157986821

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.61042
Policy Entropy: 1.41289
Value Function Loss: 0.00999

Mean KL Divergence: 0.00135
SB3 Clip Fraction: 0.01451
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.09774

Collected Steps per Second: 10409.51123
Overall Steps per Second: 7225.77420

Timestep Collection Time: 4.80695
Timestep Consumption Time: 2.11798
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.92493

Cumulative Model Updates: 18906
Cumulative Timesteps: 158036859

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.81519
Policy Entropy: 1.41281
Value Function Loss: 0.01004

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01437
Policy Update Magnitude: 0.07626
Value Function Update Magnitude: 0.09939

Collected Steps per Second: 9981.40610
Overall Steps per Second: 7030.08472

Timestep Collection Time: 5.01022
Timestep Consumption Time: 2.10335
PPO Batch Consumption Time: 0.02399
Total Iteration Time: 7.11357

Cumulative Model Updates: 18912
Cumulative Timesteps: 158086868

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.98965
Policy Entropy: 1.41264
Value Function Loss: 0.01060

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01423
Policy Update Magnitude: 0.07748
Value Function Update Magnitude: 0.10455

Collected Steps per Second: 9706.19767
Overall Steps per Second: 6973.09484

Timestep Collection Time: 5.15155
Timestep Consumption Time: 2.01915
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.17070

Cumulative Model Updates: 18918
Cumulative Timesteps: 158136870

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.41945
Policy Entropy: 1.41273
Value Function Loss: 0.01025

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.07434
Value Function Update Magnitude: 0.10794

Collected Steps per Second: 10485.15161
Overall Steps per Second: 7248.58694

Timestep Collection Time: 4.77208
Timestep Consumption Time: 2.13078
PPO Batch Consumption Time: 0.02440
Total Iteration Time: 6.90286

Cumulative Model Updates: 18924
Cumulative Timesteps: 158186906

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.84965
Policy Entropy: 1.41291
Value Function Loss: 0.01065

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.07160
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 9800.23544
Overall Steps per Second: 7018.09896

Timestep Collection Time: 5.10396
Timestep Consumption Time: 2.02333
PPO Batch Consumption Time: 0.02440
Total Iteration Time: 7.12729

Cumulative Model Updates: 18930
Cumulative Timesteps: 158236926

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 158236926...
Checkpoint 158236926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.04265
Policy Entropy: 1.41295
Value Function Loss: 0.01023

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01946
Policy Update Magnitude: 0.07246
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 9964.73866
Overall Steps per Second: 7063.10466

Timestep Collection Time: 5.02000
Timestep Consumption Time: 2.06230
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 7.08230

Cumulative Model Updates: 18936
Cumulative Timesteps: 158286949

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.47364
Policy Entropy: 1.41290
Value Function Loss: 0.01059

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01540
Policy Update Magnitude: 0.07318
Value Function Update Magnitude: 0.09676

Collected Steps per Second: 10356.17563
Overall Steps per Second: 7250.73864

Timestep Collection Time: 4.83045
Timestep Consumption Time: 2.06885
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 6.89930

Cumulative Model Updates: 18942
Cumulative Timesteps: 158336974

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -19.34398
Policy Entropy: 1.41250
Value Function Loss: 0.00992

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01847
Policy Update Magnitude: 0.07240
Value Function Update Magnitude: 0.09507

Collected Steps per Second: 10200.88839
Overall Steps per Second: 7231.92237

Timestep Collection Time: 4.90291
Timestep Consumption Time: 2.01282
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 6.91573

Cumulative Model Updates: 18948
Cumulative Timesteps: 158386988

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.83629
Policy Entropy: 1.41210
Value Function Loss: 0.00984

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.07037
Value Function Update Magnitude: 0.09431

Collected Steps per Second: 9919.89941
Overall Steps per Second: 7169.06250

Timestep Collection Time: 5.04269
Timestep Consumption Time: 1.93493
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 6.97762

Cumulative Model Updates: 18954
Cumulative Timesteps: 158437011

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.75802
Policy Entropy: 1.41173
Value Function Loss: 0.00984

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01637
Policy Update Magnitude: 0.07131
Value Function Update Magnitude: 0.09378

Collected Steps per Second: 10592.01714
Overall Steps per Second: 7344.35035

Timestep Collection Time: 4.72384
Timestep Consumption Time: 2.08888
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 6.81272

Cumulative Model Updates: 18960
Cumulative Timesteps: 158487046

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.43506
Policy Entropy: 1.41191
Value Function Loss: 0.01023

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01678
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.09529

Collected Steps per Second: 10002.39493
Overall Steps per Second: 7070.53338

Timestep Collection Time: 4.99890
Timestep Consumption Time: 2.07284
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 7.07174

Cumulative Model Updates: 18966
Cumulative Timesteps: 158537047

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.73411
Policy Entropy: 1.41220
Value Function Loss: 0.01001

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01749
Policy Update Magnitude: 0.07202
Value Function Update Magnitude: 0.09474

Collected Steps per Second: 9767.91640
Overall Steps per Second: 7009.27224

Timestep Collection Time: 5.12136
Timestep Consumption Time: 2.01562
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.13697

Cumulative Model Updates: 18972
Cumulative Timesteps: 158587072

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.09295
Policy Entropy: 1.41225
Value Function Loss: 0.01019

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.07263
Value Function Update Magnitude: 0.09284

Collected Steps per Second: 10348.76123
Overall Steps per Second: 7190.32633

Timestep Collection Time: 4.83150
Timestep Consumption Time: 2.12229
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 6.95379

Cumulative Model Updates: 18978
Cumulative Timesteps: 158637072

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -9.26043
Policy Entropy: 1.41199
Value Function Loss: 0.00979

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.09376

Collected Steps per Second: 9752.51010
Overall Steps per Second: 6998.69897

Timestep Collection Time: 5.13037
Timestep Consumption Time: 2.01867
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 7.14904

Cumulative Model Updates: 18984
Cumulative Timesteps: 158687106

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.47338
Policy Entropy: 1.41173
Value Function Loss: 0.01037

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.07054
Value Function Update Magnitude: 0.09180

Collected Steps per Second: 9846.40229
Overall Steps per Second: 6991.96798

Timestep Collection Time: 5.07922
Timestep Consumption Time: 2.07356
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.15278

Cumulative Model Updates: 18990
Cumulative Timesteps: 158737118

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 158737118...
Checkpoint 158737118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.19637
Policy Entropy: 1.41181
Value Function Loss: 0.01031

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02008
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.09758

Collected Steps per Second: 10463.50358
Overall Steps per Second: 7250.34724

Timestep Collection Time: 4.78243
Timestep Consumption Time: 2.11944
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 6.90188

Cumulative Model Updates: 18996
Cumulative Timesteps: 158787159

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.30361
Policy Entropy: 1.41169
Value Function Loss: 0.01078

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.07363
Value Function Update Magnitude: 0.09945

Collected Steps per Second: 9780.53958
Overall Steps per Second: 6972.48914

Timestep Collection Time: 5.11393
Timestep Consumption Time: 2.05955
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.17348

Cumulative Model Updates: 19002
Cumulative Timesteps: 158837176

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.79708
Policy Entropy: 1.41115
Value Function Loss: 0.01072

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01592
Policy Update Magnitude: 0.07495
Value Function Update Magnitude: 0.09901

Collected Steps per Second: 9714.76602
Overall Steps per Second: 6971.57185

Timestep Collection Time: 5.15000
Timestep Consumption Time: 2.02644
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.17643

Cumulative Model Updates: 19008
Cumulative Timesteps: 158887207

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -6.73713
Policy Entropy: 1.41097
Value Function Loss: 0.01064

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01720
Policy Update Magnitude: 0.07732
Value Function Update Magnitude: 0.09901

Collected Steps per Second: 10276.07979
Overall Steps per Second: 7181.24623

Timestep Collection Time: 4.86820
Timestep Consumption Time: 2.09800
PPO Batch Consumption Time: 0.02431
Total Iteration Time: 6.96620

Cumulative Model Updates: 19014
Cumulative Timesteps: 158937233

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.44057
Policy Entropy: 1.41093
Value Function Loss: 0.01025

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01725
Policy Update Magnitude: 0.07669
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 9933.80302
Overall Steps per Second: 7080.39142

Timestep Collection Time: 5.03493
Timestep Consumption Time: 2.02909
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.06402

Cumulative Model Updates: 19020
Cumulative Timesteps: 158987249

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.98509
Policy Entropy: 1.41139
Value Function Loss: 0.01032

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01441
Policy Update Magnitude: 0.07612
Value Function Update Magnitude: 0.10133

Collected Steps per Second: 9766.80647
Overall Steps per Second: 6924.11943

Timestep Collection Time: 5.12358
Timestep Consumption Time: 2.10348
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 7.22706

Cumulative Model Updates: 19026
Cumulative Timesteps: 159037290

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.46103
Policy Entropy: 1.41143
Value Function Loss: 0.01047

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01629
Policy Update Magnitude: 0.07667
Value Function Update Magnitude: 0.10017

Collected Steps per Second: 10342.43132
Overall Steps per Second: 6691.11015

Timestep Collection Time: 4.83474
Timestep Consumption Time: 2.63831
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.47305

Cumulative Model Updates: 19032
Cumulative Timesteps: 159087293

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.49093
Policy Entropy: 1.41081
Value Function Loss: 0.01103

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01689
Policy Update Magnitude: 0.07671
Value Function Update Magnitude: 0.09837

Collected Steps per Second: 10060.36280
Overall Steps per Second: 7168.20684

Timestep Collection Time: 4.97119
Timestep Consumption Time: 2.00573
PPO Batch Consumption Time: 0.02465
Total Iteration Time: 6.97692

Cumulative Model Updates: 19038
Cumulative Timesteps: 159137305

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09292
Policy Entropy: 1.41048
Value Function Loss: 0.01077

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02108
Policy Update Magnitude: 0.07638
Value Function Update Magnitude: 0.10013

Collected Steps per Second: 9791.65048
Overall Steps per Second: 7000.80340

Timestep Collection Time: 5.10660
Timestep Consumption Time: 2.03573
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.14232

Cumulative Model Updates: 19044
Cumulative Timesteps: 159187307

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.56954
Policy Entropy: 1.41032
Value Function Loss: 0.01111

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.01920
Policy Update Magnitude: 0.07830
Value Function Update Magnitude: 0.09815

Collected Steps per Second: 10316.25728
Overall Steps per Second: 7200.63915

Timestep Collection Time: 4.85031
Timestep Consumption Time: 2.09866
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.94897

Cumulative Model Updates: 19050
Cumulative Timesteps: 159237344

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 159237344...
Checkpoint 159237344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.84331
Policy Entropy: 1.41005
Value Function Loss: 0.01080

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.07694
Value Function Update Magnitude: 0.09438

Collected Steps per Second: 9984.77745
Overall Steps per Second: 7040.36149

Timestep Collection Time: 5.01063
Timestep Consumption Time: 2.09554
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.10617

Cumulative Model Updates: 19056
Cumulative Timesteps: 159287374

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35807
Policy Entropy: 1.40952
Value Function Loss: 0.01077

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.07528
Value Function Update Magnitude: 0.09730

Collected Steps per Second: 10272.72862
Overall Steps per Second: 7305.51492

Timestep Collection Time: 4.86745
Timestep Consumption Time: 1.97697
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 6.84442

Cumulative Model Updates: 19062
Cumulative Timesteps: 159337376

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.90106
Policy Entropy: 1.40968
Value Function Loss: 0.01054

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.07565
Value Function Update Magnitude: 0.10170

Collected Steps per Second: 10379.19538
Overall Steps per Second: 7218.56245

Timestep Collection Time: 4.81974
Timestep Consumption Time: 2.11031
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 6.93005

Cumulative Model Updates: 19068
Cumulative Timesteps: 159387401

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -7.96312
Policy Entropy: 1.40952
Value Function Loss: 0.01062

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.07910
Value Function Update Magnitude: 0.10267

Collected Steps per Second: 9782.61719
Overall Steps per Second: 7010.28072

Timestep Collection Time: 5.11509
Timestep Consumption Time: 2.02285
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.13795

Cumulative Model Updates: 19074
Cumulative Timesteps: 159437440

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.52940
Policy Entropy: 1.40968
Value Function Loss: 0.01103

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.08015
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 9824.05357
Overall Steps per Second: 7029.45552

Timestep Collection Time: 5.09036
Timestep Consumption Time: 2.02370
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 7.11406

Cumulative Model Updates: 19080
Cumulative Timesteps: 159487448

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.08709
Policy Entropy: 1.40938
Value Function Loss: 0.01035

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02319
Policy Update Magnitude: 0.07761
Value Function Update Magnitude: 0.10309

Collected Steps per Second: 10498.90712
Overall Steps per Second: 7282.99051

Timestep Collection Time: 4.76440
Timestep Consumption Time: 2.10379
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.86820

Cumulative Model Updates: 19086
Cumulative Timesteps: 159537469

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.36257
Policy Entropy: 1.40925
Value Function Loss: 0.00977

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02042
Policy Update Magnitude: 0.07682
Value Function Update Magnitude: 0.09931

Collected Steps per Second: 9767.89020
Overall Steps per Second: 6968.32861

Timestep Collection Time: 5.12229
Timestep Consumption Time: 2.05791
PPO Batch Consumption Time: 0.02344
Total Iteration Time: 7.18020

Cumulative Model Updates: 19092
Cumulative Timesteps: 159587503

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.82814
Policy Entropy: 1.40872
Value Function Loss: 0.00996

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.01803
Policy Update Magnitude: 0.07921
Value Function Update Magnitude: 0.09631

Collected Steps per Second: 9739.76446
Overall Steps per Second: 6934.00047

Timestep Collection Time: 5.13585
Timestep Consumption Time: 2.07816
PPO Batch Consumption Time: 0.02386
Total Iteration Time: 7.21402

Cumulative Model Updates: 19098
Cumulative Timesteps: 159637525

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.22207
Policy Entropy: 1.40869
Value Function Loss: 0.01049

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02135
Policy Update Magnitude: 0.07811
Value Function Update Magnitude: 0.09899

Collected Steps per Second: 10368.99756
Overall Steps per Second: 7266.43821

Timestep Collection Time: 4.82236
Timestep Consumption Time: 2.05901
PPO Batch Consumption Time: 0.02353
Total Iteration Time: 6.88136

Cumulative Model Updates: 19104
Cumulative Timesteps: 159687528

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.37300
Policy Entropy: 1.40846
Value Function Loss: 0.01096

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01883
Policy Update Magnitude: 0.07880
Value Function Update Magnitude: 0.09968

Collected Steps per Second: 9813.67757
Overall Steps per Second: 7055.79950

Timestep Collection Time: 5.09503
Timestep Consumption Time: 1.99148
PPO Batch Consumption Time: 0.02314
Total Iteration Time: 7.08651

Cumulative Model Updates: 19110
Cumulative Timesteps: 159737529

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 159737529...
Checkpoint 159737529 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.13824
Policy Entropy: 1.40812
Value Function Loss: 0.01085

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01993
Policy Update Magnitude: 0.08459
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 9726.90242
Overall Steps per Second: 7003.42911

Timestep Collection Time: 5.14213
Timestep Consumption Time: 1.99966
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.14179

Cumulative Model Updates: 19116
Cumulative Timesteps: 159787546

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -12.80581
Policy Entropy: 1.40788
Value Function Loss: 0.01073

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.08248
Value Function Update Magnitude: 0.09856

Collected Steps per Second: 10376.73109
Overall Steps per Second: 7243.15105

Timestep Collection Time: 4.82194
Timestep Consumption Time: 2.08610
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.90804

Cumulative Model Updates: 19122
Cumulative Timesteps: 159837582

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.87380
Policy Entropy: 1.40657
Value Function Loss: 0.01178

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.03861
Policy Update Magnitude: 0.08492
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 9912.05068
Overall Steps per Second: 7009.03120

Timestep Collection Time: 5.04618
Timestep Consumption Time: 2.09004
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.13622

Cumulative Model Updates: 19128
Cumulative Timesteps: 159887600

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.11488
Policy Entropy: 1.40688
Value Function Loss: 0.01181

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.03991
Policy Update Magnitude: 0.08584
Value Function Update Magnitude: 0.11007

Collected Steps per Second: 9632.06048
Overall Steps per Second: 6864.83264

Timestep Collection Time: 5.19307
Timestep Consumption Time: 2.09334
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.28641

Cumulative Model Updates: 19134
Cumulative Timesteps: 159937620

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.84297
Policy Entropy: 1.40506
Value Function Loss: 0.01149

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.03742
Policy Update Magnitude: 0.08263
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 9657.88623
Overall Steps per Second: 6688.65630

Timestep Collection Time: 5.17805
Timestep Consumption Time: 2.29864
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.47669

Cumulative Model Updates: 19140
Cumulative Timesteps: 159987629

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.95285
Policy Entropy: 1.40494
Value Function Loss: 0.01120

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.08692
Value Function Update Magnitude: 0.10437

Collected Steps per Second: 9390.76075
Overall Steps per Second: 6879.61617

Timestep Collection Time: 5.32822
Timestep Consumption Time: 1.94486
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.27308

Cumulative Model Updates: 19146
Cumulative Timesteps: 160037665

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.56634
Policy Entropy: 1.40474
Value Function Loss: 0.01074

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04189
Policy Update Magnitude: 0.08879
Value Function Update Magnitude: 0.10540

Collected Steps per Second: 9392.88652
Overall Steps per Second: 6861.82199

Timestep Collection Time: 5.32531
Timestep Consumption Time: 1.96430
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.28961

Cumulative Model Updates: 19152
Cumulative Timesteps: 160087685

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.12843
Policy Entropy: 1.40467
Value Function Loss: 0.01112

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04083
Policy Update Magnitude: 0.08251
Value Function Update Magnitude: 0.10177

Collected Steps per Second: 10338.78639
Overall Steps per Second: 7225.27777

Timestep Collection Time: 4.83712
Timestep Consumption Time: 2.08441
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 6.92153

Cumulative Model Updates: 19158
Cumulative Timesteps: 160137695

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.09925
Policy Entropy: 1.40531
Value Function Loss: 0.01046

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.07820
Value Function Update Magnitude: 0.09891

Collected Steps per Second: 9711.92960
Overall Steps per Second: 6945.86615

Timestep Collection Time: 5.15160
Timestep Consumption Time: 2.05153
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.20313

Cumulative Model Updates: 19164
Cumulative Timesteps: 160187727

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.02828
Policy Entropy: 1.40411
Value Function Loss: 0.01140

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03751
Policy Update Magnitude: 0.08205
Value Function Update Magnitude: 0.09668

Collected Steps per Second: 9803.48412
Overall Steps per Second: 6941.38719

Timestep Collection Time: 5.10278
Timestep Consumption Time: 2.10400
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.20677

Cumulative Model Updates: 19170
Cumulative Timesteps: 160237752

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 160237752...
Checkpoint 160237752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -3.81707
Policy Entropy: 1.40429
Value Function Loss: 0.01189

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 0.08220
Value Function Update Magnitude: 0.10184

Collected Steps per Second: 10332.06813
Overall Steps per Second: 7181.52150

Timestep Collection Time: 4.84075
Timestep Consumption Time: 2.12365
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 6.96440

Cumulative Model Updates: 19176
Cumulative Timesteps: 160287767

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -16.26927
Policy Entropy: 1.40428
Value Function Loss: 0.01174

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.09185
Value Function Update Magnitude: 0.10671

Collected Steps per Second: 9748.06780
Overall Steps per Second: 6965.92835

Timestep Collection Time: 5.13189
Timestep Consumption Time: 2.04964
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.18153

Cumulative Model Updates: 19182
Cumulative Timesteps: 160337793

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.78187
Policy Entropy: 1.40304
Value Function Loss: 0.01186

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03171
Policy Update Magnitude: 0.08904
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 9675.67381
Overall Steps per Second: 6898.55453

Timestep Collection Time: 5.17060
Timestep Consumption Time: 2.08150
PPO Batch Consumption Time: 0.02445
Total Iteration Time: 7.25210

Cumulative Model Updates: 19188
Cumulative Timesteps: 160387822

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -19.51511
Policy Entropy: 1.40335
Value Function Loss: 0.01132

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03006
Policy Update Magnitude: 0.08638
Value Function Update Magnitude: 0.10081

Collected Steps per Second: 10289.35658
Overall Steps per Second: 7288.73553

Timestep Collection Time: 4.86124
Timestep Consumption Time: 2.00127
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.86251

Cumulative Model Updates: 19194
Cumulative Timesteps: 160437841

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.71795
Policy Entropy: 1.40456
Value Function Loss: 0.01157

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.03586
Policy Update Magnitude: 0.08413
Value Function Update Magnitude: 0.10262

Collected Steps per Second: 9963.49573
Overall Steps per Second: 7082.90561

Timestep Collection Time: 5.02294
Timestep Consumption Time: 2.04281
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.06574

Cumulative Model Updates: 19200
Cumulative Timesteps: 160487887

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -19.30724
Policy Entropy: 1.40466
Value Function Loss: 0.01160

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.03796
Policy Update Magnitude: 0.08379
Value Function Update Magnitude: 0.10200

Collected Steps per Second: 9696.19649
Overall Steps per Second: 6954.29465

Timestep Collection Time: 5.15872
Timestep Consumption Time: 2.03395
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 7.19268

Cumulative Model Updates: 19206
Cumulative Timesteps: 160537907

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.95575
Policy Entropy: 1.40440
Value Function Loss: 0.01183

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.08641
Value Function Update Magnitude: 0.09883

Collected Steps per Second: 10360.40725
Overall Steps per Second: 7275.31150

Timestep Collection Time: 4.82626
Timestep Consumption Time: 2.04657
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 6.87283

Cumulative Model Updates: 19212
Cumulative Timesteps: 160587909

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.45840
Policy Entropy: 1.40456
Value Function Loss: 0.01234

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.04885
Policy Update Magnitude: 0.08416
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 9997.71333
Overall Steps per Second: 7109.09238

Timestep Collection Time: 5.00244
Timestep Consumption Time: 2.03263
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.03508

Cumulative Model Updates: 19218
Cumulative Timesteps: 160637922

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.38118
Policy Entropy: 1.40459
Value Function Loss: 0.01186

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04362
Policy Update Magnitude: 0.08314
Value Function Update Magnitude: 0.10772

Collected Steps per Second: 9814.83599
Overall Steps per Second: 6981.99250

Timestep Collection Time: 5.09902
Timestep Consumption Time: 2.06885
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.16787

Cumulative Model Updates: 19224
Cumulative Timesteps: 160687968

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -35.54876
Policy Entropy: 1.40507
Value Function Loss: 0.01181

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03420
Policy Update Magnitude: 0.08351
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 10405.17184
Overall Steps per Second: 7245.32425

Timestep Collection Time: 4.80588
Timestep Consumption Time: 2.09595
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 6.90183

Cumulative Model Updates: 19230
Cumulative Timesteps: 160737974

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 160737974...
Checkpoint 160737974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.93289
Policy Entropy: 1.40470
Value Function Loss: 0.01093

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04271
Policy Update Magnitude: 0.08019
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 9922.86312
Overall Steps per Second: 6999.60060

Timestep Collection Time: 5.04008
Timestep Consumption Time: 2.10490
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 7.14498

Cumulative Model Updates: 19236
Cumulative Timesteps: 160787986

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.50065
Policy Entropy: 1.40493
Value Function Loss: 0.01102

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.10378

Collected Steps per Second: 9861.36289
Overall Steps per Second: 6933.86751

Timestep Collection Time: 5.07060
Timestep Consumption Time: 2.14082
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.21142

Cumulative Model Updates: 19242
Cumulative Timesteps: 160837989

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.89593
Policy Entropy: 1.40406
Value Function Loss: 0.01136

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.08386
Value Function Update Magnitude: 0.10508

Collected Steps per Second: 10399.07327
Overall Steps per Second: 7240.73756

Timestep Collection Time: 4.81149
Timestep Consumption Time: 2.09872
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.91021

Cumulative Model Updates: 19248
Cumulative Timesteps: 160888024

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.23324
Policy Entropy: 1.40305
Value Function Loss: 0.01107

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03231
Policy Update Magnitude: 0.08405
Value Function Update Magnitude: 0.10300

Collected Steps per Second: 10146.25004
Overall Steps per Second: 7206.18847

Timestep Collection Time: 4.92803
Timestep Consumption Time: 2.01059
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.93862

Cumulative Model Updates: 19254
Cumulative Timesteps: 160938025

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16031
Policy Entropy: 1.40144
Value Function Loss: 0.01128

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.08520
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 9686.11907
Overall Steps per Second: 6914.39878

Timestep Collection Time: 5.16285
Timestep Consumption Time: 2.06959
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.23244

Cumulative Model Updates: 19260
Cumulative Timesteps: 160988033

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.17178
Policy Entropy: 1.40140
Value Function Loss: 0.01169

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.08431
Value Function Update Magnitude: 0.10753

Collected Steps per Second: 10374.63738
Overall Steps per Second: 7223.68475

Timestep Collection Time: 4.82282
Timestep Consumption Time: 2.10370
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 6.92652

Cumulative Model Updates: 19266
Cumulative Timesteps: 161038068

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.76659
Policy Entropy: 1.40047
Value Function Loss: 0.01199

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.08967
Value Function Update Magnitude: 0.11248

Collected Steps per Second: 9835.63040
Overall Steps per Second: 6981.56901

Timestep Collection Time: 5.08508
Timestep Consumption Time: 2.07878
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.16386

Cumulative Model Updates: 19272
Cumulative Timesteps: 161088083

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.78920
Policy Entropy: 1.40060
Value Function Loss: 0.01126

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02680
Policy Update Magnitude: 0.08827
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 9762.96322
Overall Steps per Second: 6980.30363

Timestep Collection Time: 5.12375
Timestep Consumption Time: 2.04256
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.16631

Cumulative Model Updates: 19278
Cumulative Timesteps: 161138106

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.01410
Policy Entropy: 1.39959
Value Function Loss: 0.01043

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02876
Policy Update Magnitude: 0.08558
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 10540.91276
Overall Steps per Second: 7264.62124

Timestep Collection Time: 4.74750
Timestep Consumption Time: 2.14109
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 6.88859

Cumulative Model Updates: 19284
Cumulative Timesteps: 161188149

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.40497
Policy Entropy: 1.39904
Value Function Loss: 0.01063

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.08856
Value Function Update Magnitude: 0.10980

Collected Steps per Second: 9937.61532
Overall Steps per Second: 7079.35417

Timestep Collection Time: 5.03189
Timestep Consumption Time: 2.03161
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.06350

Cumulative Model Updates: 19290
Cumulative Timesteps: 161238154

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 161238154...
Checkpoint 161238154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.69659
Policy Entropy: 1.39819
Value Function Loss: 0.01118

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.03944
Policy Update Magnitude: 0.09051
Value Function Update Magnitude: 0.11291

Collected Steps per Second: 9734.62258
Overall Steps per Second: 6964.47961

Timestep Collection Time: 5.14011
Timestep Consumption Time: 2.04449
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.18460

Cumulative Model Updates: 19296
Cumulative Timesteps: 161288191

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.44887
Policy Entropy: 1.39874
Value Function Loss: 0.01113

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.04867
Policy Update Magnitude: 0.09735
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 10360.70910
Overall Steps per Second: 7244.92596

Timestep Collection Time: 4.82872
Timestep Consumption Time: 2.07666
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.90538

Cumulative Model Updates: 19302
Cumulative Timesteps: 161338220

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.82272
Policy Entropy: 1.39821
Value Function Loss: 0.01157

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.09822
Value Function Update Magnitude: 0.11485

Collected Steps per Second: 9772.47049
Overall Steps per Second: 6994.90624

Timestep Collection Time: 5.11928
Timestep Consumption Time: 2.03278
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.15206

Cumulative Model Updates: 19308
Cumulative Timesteps: 161388248

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.50991
Policy Entropy: 1.39905
Value Function Loss: 0.01143

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.05885
Policy Update Magnitude: 0.08961
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 10009.73840
Overall Steps per Second: 7123.71956

Timestep Collection Time: 4.99773
Timestep Consumption Time: 2.02472
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.02245

Cumulative Model Updates: 19314
Cumulative Timesteps: 161438274

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.05805
Policy Entropy: 1.39961
Value Function Loss: 0.01126

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.04587
Policy Update Magnitude: 0.08647
Value Function Update Magnitude: 0.11023

Collected Steps per Second: 10557.20885
Overall Steps per Second: 7313.75460

Timestep Collection Time: 4.73714
Timestep Consumption Time: 2.10080
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.83794

Cumulative Model Updates: 19320
Cumulative Timesteps: 161488285

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.57611
Policy Entropy: 1.39962
Value Function Loss: 0.01104

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.03582
Policy Update Magnitude: 0.08774
Value Function Update Magnitude: 0.10994

Collected Steps per Second: 9772.24754
Overall Steps per Second: 6985.26431

Timestep Collection Time: 5.11919
Timestep Consumption Time: 2.04246
PPO Batch Consumption Time: 0.02450
Total Iteration Time: 7.16165

Cumulative Model Updates: 19326
Cumulative Timesteps: 161538311

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -36.40201
Policy Entropy: 1.39991
Value Function Loss: 0.01062

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03849
Policy Update Magnitude: 0.08416
Value Function Update Magnitude: 0.11117

Collected Steps per Second: 9698.34348
Overall Steps per Second: 6962.87965

Timestep Collection Time: 5.15933
Timestep Consumption Time: 2.02692
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 7.18625

Cumulative Model Updates: 19332
Cumulative Timesteps: 161588348

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97387
Policy Entropy: 1.39862
Value Function Loss: 0.01095

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 0.08428
Value Function Update Magnitude: 0.11142

Collected Steps per Second: 10340.49881
Overall Steps per Second: 7193.52309

Timestep Collection Time: 4.83864
Timestep Consumption Time: 2.11678
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 6.95542

Cumulative Model Updates: 19338
Cumulative Timesteps: 161638382

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.70358
Policy Entropy: 1.39827
Value Function Loss: 0.01072

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03572
Policy Update Magnitude: 0.08735
Value Function Update Magnitude: 0.10517

Collected Steps per Second: 9980.43748
Overall Steps per Second: 7059.70039

Timestep Collection Time: 5.01431
Timestep Consumption Time: 2.07452
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.08883

Cumulative Model Updates: 19344
Cumulative Timesteps: 161688427

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.78005
Policy Entropy: 1.39824
Value Function Loss: 0.01144

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03257
Policy Update Magnitude: 0.08843
Value Function Update Magnitude: 0.10640

Collected Steps per Second: 9743.75254
Overall Steps per Second: 6958.05288

Timestep Collection Time: 5.13293
Timestep Consumption Time: 2.05500
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.18793

Cumulative Model Updates: 19350
Cumulative Timesteps: 161738441

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 161738441...
Checkpoint 161738441 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -8.04426
Policy Entropy: 1.39784
Value Function Loss: 0.01178

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 0.08793
Value Function Update Magnitude: 0.11208

Collected Steps per Second: 10345.62901
Overall Steps per Second: 7234.70395

Timestep Collection Time: 4.83451
Timestep Consumption Time: 2.07884
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 6.91334

Cumulative Model Updates: 19356
Cumulative Timesteps: 161788457

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -21.41647
Policy Entropy: 1.39617
Value Function Loss: 0.01210

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03507
Policy Update Magnitude: 0.08970
Value Function Update Magnitude: 0.11165

Collected Steps per Second: 9812.79516
Overall Steps per Second: 7019.97837

Timestep Collection Time: 5.09845
Timestep Consumption Time: 2.02836
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.12680

Cumulative Model Updates: 19362
Cumulative Timesteps: 161838487

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.66554
Policy Entropy: 1.39519
Value Function Loss: 0.01251

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.03963
Policy Update Magnitude: 0.09425
Value Function Update Magnitude: 0.11648

Collected Steps per Second: 9757.44165
Overall Steps per Second: 6985.65320

Timestep Collection Time: 5.12593
Timestep Consumption Time: 2.03388
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 7.15982

Cumulative Model Updates: 19368
Cumulative Timesteps: 161888503

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -17.97751
Policy Entropy: 1.39599
Value Function Loss: 0.01265

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04122
Policy Update Magnitude: 0.09517
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 10379.41834
Overall Steps per Second: 1520.81144

Timestep Collection Time: 4.82060
Timestep Consumption Time: 28.07960
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 32.90020

Cumulative Model Updates: 19374
Cumulative Timesteps: 161938538

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.87270
Policy Entropy: 1.39658
Value Function Loss: 0.01218

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04100
Policy Update Magnitude: 0.09090
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 9857.26009
Overall Steps per Second: 6940.50235

Timestep Collection Time: 5.07636
Timestep Consumption Time: 2.13335
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 7.20971

Cumulative Model Updates: 19380
Cumulative Timesteps: 161988577

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.47336
Policy Entropy: 1.39397
Value Function Loss: 0.01196

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.04578
Policy Update Magnitude: 0.08940
Value Function Update Magnitude: 0.11652

Collected Steps per Second: 9805.41179
Overall Steps per Second: 6971.02446

Timestep Collection Time: 5.10188
Timestep Consumption Time: 2.07440
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.17628

Cumulative Model Updates: 19386
Cumulative Timesteps: 162038603

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.15650
Policy Entropy: 1.39318
Value Function Loss: 0.01171

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04174
Policy Update Magnitude: 0.09259
Value Function Update Magnitude: 0.10859

Collected Steps per Second: 10319.02124
Overall Steps per Second: 7148.55970

Timestep Collection Time: 4.84959
Timestep Consumption Time: 2.15084
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.00043

Cumulative Model Updates: 19392
Cumulative Timesteps: 162088646

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.34856
Policy Entropy: 1.39161
Value Function Loss: 0.01255

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05035
Policy Update Magnitude: 0.09665
Value Function Update Magnitude: 0.10614

Collected Steps per Second: 9856.28045
Overall Steps per Second: 6955.04633

Timestep Collection Time: 5.07311
Timestep Consumption Time: 2.11620
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.18931

Cumulative Model Updates: 19398
Cumulative Timesteps: 162138648

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.81425
Policy Entropy: 1.39067
Value Function Loss: 0.01579

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.04876
Policy Update Magnitude: 0.09459
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 9917.20078
Overall Steps per Second: 7045.00498

Timestep Collection Time: 5.04447
Timestep Consumption Time: 2.05659
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 7.10106

Cumulative Model Updates: 19404
Cumulative Timesteps: 162188675

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.49723
Policy Entropy: 1.38943
Value Function Loss: 0.01511

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.05797
Policy Update Magnitude: 0.09533
Value Function Update Magnitude: 0.08887

Collected Steps per Second: 10473.83773
Overall Steps per Second: 7268.18694

Timestep Collection Time: 4.77456
Timestep Consumption Time: 2.10583
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 6.88040

Cumulative Model Updates: 19410
Cumulative Timesteps: 162238683

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 162238683...
Checkpoint 162238683 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -7.94957
Policy Entropy: 1.38829
Value Function Loss: 0.01456

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06084
Policy Update Magnitude: 0.09515
Value Function Update Magnitude: 0.08298

Collected Steps per Second: 9811.75020
Overall Steps per Second: 6915.27150

Timestep Collection Time: 5.09746
Timestep Consumption Time: 2.13508
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.23254

Cumulative Model Updates: 19416
Cumulative Timesteps: 162288698

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.27050
Policy Entropy: 1.38806
Value Function Loss: 0.01410

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.09488
Value Function Update Magnitude: 0.08291

Collected Steps per Second: 9079.53893
Overall Steps per Second: 6487.75065

Timestep Collection Time: 5.50986
Timestep Consumption Time: 2.20113
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 7.71099

Cumulative Model Updates: 19422
Cumulative Timesteps: 162338725

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.38058
Policy Entropy: 1.38891
Value Function Loss: 0.01350

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04138
Policy Update Magnitude: 0.09393
Value Function Update Magnitude: 0.08410

Collected Steps per Second: 9840.56560
Overall Steps per Second: 6901.50887

Timestep Collection Time: 5.08324
Timestep Consumption Time: 2.16474
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 7.24798

Cumulative Model Updates: 19428
Cumulative Timesteps: 162388747

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.53549
Policy Entropy: 1.38669
Value Function Loss: 0.01285

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.04459
Policy Update Magnitude: 0.10012
Value Function Update Magnitude: 0.09287

Collected Steps per Second: 9619.78533
Overall Steps per Second: 6895.82689

Timestep Collection Time: 5.20126
Timestep Consumption Time: 2.05458
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.25584

Cumulative Model Updates: 19434
Cumulative Timesteps: 162438782

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.23513
Policy Entropy: 1.38502
Value Function Loss: 0.01245

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05216
Policy Update Magnitude: 0.10095
Value Function Update Magnitude: 0.10358

Collected Steps per Second: 9709.73838
Overall Steps per Second: 6958.88203

Timestep Collection Time: 5.14947
Timestep Consumption Time: 2.03559
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.18506

Cumulative Model Updates: 19440
Cumulative Timesteps: 162488782

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.43926
Policy Entropy: 1.38412
Value Function Loss: 0.01219

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06221
Policy Update Magnitude: 0.10091
Value Function Update Magnitude: 0.10379

Collected Steps per Second: 10271.64260
Overall Steps per Second: 7193.31382

Timestep Collection Time: 4.87128
Timestep Consumption Time: 2.08463
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 6.95590

Cumulative Model Updates: 19446
Cumulative Timesteps: 162538818

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.38789
Policy Entropy: 1.38834
Value Function Loss: 0.01138

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.04690
Policy Update Magnitude: 0.09653
Value Function Update Magnitude: 0.09775

Collected Steps per Second: 9866.75151
Overall Steps per Second: 7048.49846

Timestep Collection Time: 5.06884
Timestep Consumption Time: 2.02671
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.09555

Cumulative Model Updates: 19452
Cumulative Timesteps: 162588831

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.00188
Policy Entropy: 1.38453
Value Function Loss: 0.01149

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.09399
Value Function Update Magnitude: 0.10138

Collected Steps per Second: 9752.91602
Overall Steps per Second: 6945.80233

Timestep Collection Time: 5.12872
Timestep Consumption Time: 2.07275
PPO Batch Consumption Time: 0.02908
Total Iteration Time: 7.20147

Cumulative Model Updates: 19458
Cumulative Timesteps: 162638851

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.37406
Policy Entropy: 1.38557
Value Function Loss: 0.01175

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.05709
Policy Update Magnitude: 0.09125
Value Function Update Magnitude: 0.10805

Collected Steps per Second: 10179.07869
Overall Steps per Second: 7138.42710

Timestep Collection Time: 4.91538
Timestep Consumption Time: 2.09373
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.00911

Cumulative Model Updates: 19464
Cumulative Timesteps: 162688885

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.19904
Policy Entropy: 1.38176
Value Function Loss: 0.01241

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.05706
Policy Update Magnitude: 0.09554
Value Function Update Magnitude: 0.10869

Collected Steps per Second: 9930.65533
Overall Steps per Second: 7053.68597

Timestep Collection Time: 5.03562
Timestep Consumption Time: 2.05387
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.08948

Cumulative Model Updates: 19470
Cumulative Timesteps: 162738892

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 162738892...
Checkpoint 162738892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.46318
Policy Entropy: 1.38344
Value Function Loss: 0.01267

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04291
Policy Update Magnitude: 0.09671
Value Function Update Magnitude: 0.10802

Collected Steps per Second: 9651.33051
Overall Steps per Second: 6962.34848

Timestep Collection Time: 5.18177
Timestep Consumption Time: 2.00129
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.18306

Cumulative Model Updates: 19476
Cumulative Timesteps: 162788903

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.65380
Policy Entropy: 1.38198
Value Function Loss: 0.01202

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.04792
Policy Update Magnitude: 0.09677
Value Function Update Magnitude: 0.10399

Collected Steps per Second: 10284.50697
Overall Steps per Second: 7120.19337

Timestep Collection Time: 4.86363
Timestep Consumption Time: 2.16146
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.02509

Cumulative Model Updates: 19482
Cumulative Timesteps: 162838923

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.26067
Policy Entropy: 1.38193
Value Function Loss: 0.01215

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04103
Policy Update Magnitude: 0.09894
Value Function Update Magnitude: 0.09799

Collected Steps per Second: 9970.93528
Overall Steps per Second: 7105.33665

Timestep Collection Time: 5.01488
Timestep Consumption Time: 2.02251
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.03739

Cumulative Model Updates: 19488
Cumulative Timesteps: 162888926

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.82436
Policy Entropy: 1.37950
Value Function Loss: 0.01211

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.04856
Policy Update Magnitude: 0.09906
Value Function Update Magnitude: 0.10016

Collected Steps per Second: 9787.00007
Overall Steps per Second: 7005.81813

Timestep Collection Time: 5.10964
Timestep Consumption Time: 2.02843
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.13807

Cumulative Model Updates: 19494
Cumulative Timesteps: 162938934

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -3.68404
Policy Entropy: 1.38115
Value Function Loss: 0.01264

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.03921
Policy Update Magnitude: 0.10159
Value Function Update Magnitude: 0.10244

Collected Steps per Second: 10386.30980
Overall Steps per Second: 7234.23677

Timestep Collection Time: 4.81576
Timestep Consumption Time: 2.09830
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 6.91407

Cumulative Model Updates: 19500
Cumulative Timesteps: 162988952

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.37134
Policy Entropy: 1.37735
Value Function Loss: 0.01185

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.04893
Policy Update Magnitude: 0.09638
Value Function Update Magnitude: 0.10031

Collected Steps per Second: 9795.53440
Overall Steps per Second: 6987.79805

Timestep Collection Time: 5.10539
Timestep Consumption Time: 2.05137
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.15676

Cumulative Model Updates: 19506
Cumulative Timesteps: 163038962

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.19516
Policy Entropy: 1.38146
Value Function Loss: 0.01190

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04332
Policy Update Magnitude: 0.09631
Value Function Update Magnitude: 0.10504

Collected Steps per Second: 9777.17162
Overall Steps per Second: 6984.08695

Timestep Collection Time: 5.11477
Timestep Consumption Time: 2.04551
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.16028

Cumulative Model Updates: 19512
Cumulative Timesteps: 163088970

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.80511
Policy Entropy: 1.37977
Value Function Loss: 0.01191

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 0.10085
Value Function Update Magnitude: 0.11064

Collected Steps per Second: 10413.67146
Overall Steps per Second: 7252.53321

Timestep Collection Time: 4.80493
Timestep Consumption Time: 2.09431
PPO Batch Consumption Time: 0.02859
Total Iteration Time: 6.89924

Cumulative Model Updates: 19518
Cumulative Timesteps: 163139007

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -4.12537
Policy Entropy: 1.38173
Value Function Loss: 0.01188

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03600
Policy Update Magnitude: 0.10269
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 10039.56259
Overall Steps per Second: 7168.19293

Timestep Collection Time: 4.98259
Timestep Consumption Time: 1.99588
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 6.97847

Cumulative Model Updates: 19524
Cumulative Timesteps: 163189030

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.14775
Policy Entropy: 1.38248
Value Function Loss: 0.01251

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04477
Policy Update Magnitude: 0.09992
Value Function Update Magnitude: 0.11493

Collected Steps per Second: 9716.72642
Overall Steps per Second: 6902.24449

Timestep Collection Time: 5.14906
Timestep Consumption Time: 2.09960
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 7.24866

Cumulative Model Updates: 19530
Cumulative Timesteps: 163239062

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 163239062...
Checkpoint 163239062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.15743
Policy Entropy: 1.38235
Value Function Loss: 0.01234

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 0.10012
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 9675.99388
Overall Steps per Second: 6745.97422

Timestep Collection Time: 5.16836
Timestep Consumption Time: 2.24480
PPO Batch Consumption Time: 0.02439
Total Iteration Time: 7.41316

Cumulative Model Updates: 19536
Cumulative Timesteps: 163289071

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.95436
Policy Entropy: 1.38169
Value Function Loss: 0.01228

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03526
Policy Update Magnitude: 0.09972
Value Function Update Magnitude: 0.11055

Collected Steps per Second: 9216.55444
Overall Steps per Second: 6703.67211

Timestep Collection Time: 5.42524
Timestep Consumption Time: 2.03366
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.45890

Cumulative Model Updates: 19542
Cumulative Timesteps: 163339073

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.60247
Policy Entropy: 1.38448
Value Function Loss: 0.01139

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.04660
Policy Update Magnitude: 0.09691
Value Function Update Magnitude: 0.10675

Collected Steps per Second: 10022.50957
Overall Steps per Second: 7077.98067

Timestep Collection Time: 4.99087
Timestep Consumption Time: 2.07626
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.06713

Cumulative Model Updates: 19548
Cumulative Timesteps: 163389094

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.45613
Policy Entropy: 1.38251
Value Function Loss: 0.01211

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.04354
Policy Update Magnitude: 0.09811
Value Function Update Magnitude: 0.10599

Collected Steps per Second: 10731.85264
Overall Steps per Second: 7446.75608

Timestep Collection Time: 4.66145
Timestep Consumption Time: 2.05637
PPO Batch Consumption Time: 0.02432
Total Iteration Time: 6.71782

Cumulative Model Updates: 19554
Cumulative Timesteps: 163439120

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.71511
Policy Entropy: 1.38481
Value Function Loss: 0.01255

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.04650
Policy Update Magnitude: 0.10058
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 9867.43923
Overall Steps per Second: 7007.11731

Timestep Collection Time: 5.06768
Timestep Consumption Time: 2.06864
PPO Batch Consumption Time: 0.02846
Total Iteration Time: 7.13632

Cumulative Model Updates: 19560
Cumulative Timesteps: 163489125

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.69795
Policy Entropy: 1.38255
Value Function Loss: 0.01292

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.04957
Policy Update Magnitude: 0.10396
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 9992.60783
Overall Steps per Second: 7109.29056

Timestep Collection Time: 5.00820
Timestep Consumption Time: 2.03118
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 7.03938

Cumulative Model Updates: 19566
Cumulative Timesteps: 163539170

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.29228
Policy Entropy: 1.38388
Value Function Loss: 0.01289

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04217
Policy Update Magnitude: 0.10561
Value Function Update Magnitude: 0.11151

Collected Steps per Second: 10566.37261
Overall Steps per Second: 7302.71376

Timestep Collection Time: 4.73266
Timestep Consumption Time: 2.11507
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 6.84773

Cumulative Model Updates: 19572
Cumulative Timesteps: 163589177

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.62132
Policy Entropy: 1.38290
Value Function Loss: 0.01232

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05140
Policy Update Magnitude: 0.10221
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 9798.46795
Overall Steps per Second: 6988.87299

Timestep Collection Time: 5.10447
Timestep Consumption Time: 2.05205
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 7.15652

Cumulative Model Updates: 19578
Cumulative Timesteps: 163639193

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.76370
Policy Entropy: 1.38262
Value Function Loss: 0.01223

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.04264
Policy Update Magnitude: 0.10196
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 9696.78247
Overall Steps per Second: 6973.35497

Timestep Collection Time: 5.15944
Timestep Consumption Time: 2.01501
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.17445

Cumulative Model Updates: 19584
Cumulative Timesteps: 163689223

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.95015
Policy Entropy: 1.38190
Value Function Loss: 0.01209

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05499
Policy Update Magnitude: 0.10002
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 10289.78335
Overall Steps per Second: 7182.35267

Timestep Collection Time: 4.86094
Timestep Consumption Time: 2.10308
PPO Batch Consumption Time: 0.02977
Total Iteration Time: 6.96401

Cumulative Model Updates: 19590
Cumulative Timesteps: 163739241

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 163739241...
Checkpoint 163739241 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.25347
Policy Entropy: 1.38084
Value Function Loss: 0.01220

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.03939
Policy Update Magnitude: 0.10604
Value Function Update Magnitude: 0.10848

Collected Steps per Second: 9781.91252
Overall Steps per Second: 6916.42700

Timestep Collection Time: 5.11454
Timestep Consumption Time: 2.11896
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.23350

Cumulative Model Updates: 19596
Cumulative Timesteps: 163789271

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.53732
Policy Entropy: 1.37775
Value Function Loss: 0.01260

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07671
Policy Update Magnitude: 0.10678
Value Function Update Magnitude: 0.11098

Collected Steps per Second: 9713.05451
Overall Steps per Second: 6925.37463

Timestep Collection Time: 5.14987
Timestep Consumption Time: 2.07299
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.22286

Cumulative Model Updates: 19602
Cumulative Timesteps: 163839292

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.68426
Policy Entropy: 1.37614
Value Function Loss: 0.01257

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.10238
Value Function Update Magnitude: 0.11160

Collected Steps per Second: 10312.14455
Overall Steps per Second: 7211.89472

Timestep Collection Time: 4.84875
Timestep Consumption Time: 2.08438
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 6.93313

Cumulative Model Updates: 19608
Cumulative Timesteps: 163889293

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.27036
Policy Entropy: 1.37652
Value Function Loss: 0.01270

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06602
Policy Update Magnitude: 0.10219
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 9770.57719
Overall Steps per Second: 7003.79310

Timestep Collection Time: 5.11935
Timestep Consumption Time: 2.02235
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.14170

Cumulative Model Updates: 19614
Cumulative Timesteps: 163939312

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.27247
Policy Entropy: 1.37572
Value Function Loss: 0.01249

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.09935
Value Function Update Magnitude: 0.10889

Collected Steps per Second: 9893.40407
Overall Steps per Second: 7040.75512

Timestep Collection Time: 5.05822
Timestep Consumption Time: 2.04940
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.10762

Cumulative Model Updates: 19620
Cumulative Timesteps: 163989355

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.44349
Policy Entropy: 1.37542
Value Function Loss: 0.01254

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05757
Policy Update Magnitude: 0.09863
Value Function Update Magnitude: 0.10806

Collected Steps per Second: 10604.56506
Overall Steps per Second: 7360.96048

Timestep Collection Time: 4.71570
Timestep Consumption Time: 2.07797
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 6.79368

Cumulative Model Updates: 19626
Cumulative Timesteps: 164039363

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.32059
Policy Entropy: 1.37521
Value Function Loss: 0.01255

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05359
Policy Update Magnitude: 0.10223
Value Function Update Magnitude: 0.11027

Collected Steps per Second: 9864.95389
Overall Steps per Second: 6993.91461

Timestep Collection Time: 5.07149
Timestep Consumption Time: 2.08187
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.15336

Cumulative Model Updates: 19632
Cumulative Timesteps: 164089393

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.43420
Policy Entropy: 1.37298
Value Function Loss: 0.01231

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.10158
Value Function Update Magnitude: 0.10599

Collected Steps per Second: 9662.21617
Overall Steps per Second: 6915.11505

Timestep Collection Time: 5.17718
Timestep Consumption Time: 2.05669
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 7.23386

Cumulative Model Updates: 19638
Cumulative Timesteps: 164139416

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.07778
Policy Entropy: 1.37233
Value Function Loss: 0.01212

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05576
Policy Update Magnitude: 0.10168
Value Function Update Magnitude: 0.10745

Collected Steps per Second: 10368.96357
Overall Steps per Second: 7217.27666

Timestep Collection Time: 4.82285
Timestep Consumption Time: 2.10608
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 6.92893

Cumulative Model Updates: 19644
Cumulative Timesteps: 164189424

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -20.47272
Policy Entropy: 1.37259
Value Function Loss: 0.01204

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.04804
Policy Update Magnitude: 0.10238
Value Function Update Magnitude: 0.11132

Collected Steps per Second: 9827.19121
Overall Steps per Second: 7025.96309

Timestep Collection Time: 5.08803
Timestep Consumption Time: 2.02858
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 7.11660

Cumulative Model Updates: 19650
Cumulative Timesteps: 164239425

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 164239425...
Checkpoint 164239425 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -2.56269
Policy Entropy: 1.36958
Value Function Loss: 0.01206

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04546
Policy Update Magnitude: 0.10256
Value Function Update Magnitude: 0.11180

Collected Steps per Second: 9692.77669
Overall Steps per Second: 6930.70928

Timestep Collection Time: 5.15879
Timestep Consumption Time: 2.05591
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.21470

Cumulative Model Updates: 19656
Cumulative Timesteps: 164289428

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.49147
Policy Entropy: 1.36763
Value Function Loss: 0.01245

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.05726
Policy Update Magnitude: 0.10687
Value Function Update Magnitude: 0.10756

Collected Steps per Second: 10480.92114
Overall Steps per Second: 7270.91486

Timestep Collection Time: 4.77153
Timestep Consumption Time: 2.10656
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 6.87809

Cumulative Model Updates: 19662
Cumulative Timesteps: 164339438

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.40740
Policy Entropy: 1.37019
Value Function Loss: 0.01206

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06622
Policy Update Magnitude: 0.10333
Value Function Update Magnitude: 0.10857

Collected Steps per Second: 9937.11710
Overall Steps per Second: 7052.55171

Timestep Collection Time: 5.03315
Timestep Consumption Time: 2.05861
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.09176

Cumulative Model Updates: 19668
Cumulative Timesteps: 164389453

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.49931
Policy Entropy: 1.37561
Value Function Loss: 0.01170

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.04756
Policy Update Magnitude: 0.10078
Value Function Update Magnitude: 0.10936

Collected Steps per Second: 9860.74549
Overall Steps per Second: 7028.26291

Timestep Collection Time: 5.07264
Timestep Consumption Time: 2.04434
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.11698

Cumulative Model Updates: 19674
Cumulative Timesteps: 164439473

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.54646
Policy Entropy: 1.37797
Value Function Loss: 0.01098

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 0.09939
Value Function Update Magnitude: 0.10538

Collected Steps per Second: 10328.12087
Overall Steps per Second: 7250.67811

Timestep Collection Time: 4.84222
Timestep Consumption Time: 2.05521
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 6.89742

Cumulative Model Updates: 19680
Cumulative Timesteps: 164489484

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.75323
Policy Entropy: 1.37949
Value Function Loss: 0.01140

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03104
Policy Update Magnitude: 0.09765
Value Function Update Magnitude: 0.10468

Collected Steps per Second: 9838.32212
Overall Steps per Second: 6981.58039

Timestep Collection Time: 5.08227
Timestep Consumption Time: 2.07958
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.16185

Cumulative Model Updates: 19686
Cumulative Timesteps: 164539485

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.36176
Policy Entropy: 1.38096
Value Function Loss: 0.01142

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03438
Policy Update Magnitude: 0.09966
Value Function Update Magnitude: 0.10816

Collected Steps per Second: 9836.87106
Overall Steps per Second: 7013.28409

Timestep Collection Time: 5.08587
Timestep Consumption Time: 2.04760
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 7.13346

Cumulative Model Updates: 19692
Cumulative Timesteps: 164589514

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.59875
Policy Entropy: 1.38110
Value Function Loss: 0.01148

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03187
Policy Update Magnitude: 0.09973
Value Function Update Magnitude: 0.10817

Collected Steps per Second: 10191.56443
Overall Steps per Second: 7108.86775

Timestep Collection Time: 4.90690
Timestep Consumption Time: 2.12783
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.03473

Cumulative Model Updates: 19698
Cumulative Timesteps: 164639523

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.51322
Policy Entropy: 1.37958
Value Function Loss: 0.01123

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.09814
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 9911.49397
Overall Steps per Second: 7080.18985

Timestep Collection Time: 5.04495
Timestep Consumption Time: 2.01743
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.06238

Cumulative Model Updates: 19704
Cumulative Timesteps: 164689526

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58052
Policy Entropy: 1.38001
Value Function Loss: 0.01142

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.09818
Value Function Update Magnitude: 0.10857

Collected Steps per Second: 9837.30304
Overall Steps per Second: 7015.07114

Timestep Collection Time: 5.08361
Timestep Consumption Time: 2.04519
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.12879

Cumulative Model Updates: 19710
Cumulative Timesteps: 164739535

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 164739535...
Checkpoint 164739535 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55005
Policy Entropy: 1.37809
Value Function Loss: 0.01220

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 0.10074
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 10328.64058
Overall Steps per Second: 7201.80386

Timestep Collection Time: 4.84304
Timestep Consumption Time: 2.10272
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 6.94576

Cumulative Model Updates: 19716
Cumulative Timesteps: 164789557

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.69254
Policy Entropy: 1.37772
Value Function Loss: 0.01266

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03551
Policy Update Magnitude: 0.10077
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 9823.06164
Overall Steps per Second: 6933.18421

Timestep Collection Time: 5.09098
Timestep Consumption Time: 2.12201
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 7.21299

Cumulative Model Updates: 19722
Cumulative Timesteps: 164839566

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.07584
Policy Entropy: 1.37531
Value Function Loss: 0.01313

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03941
Policy Update Magnitude: 0.10452
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 10121.78956
Overall Steps per Second: 7130.45458

Timestep Collection Time: 4.94251
Timestep Consumption Time: 2.07346
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 7.01596

Cumulative Model Updates: 19728
Cumulative Timesteps: 164889593

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.67150
Policy Entropy: 1.37484
Value Function Loss: 0.01247

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 0.10450
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 10393.91709
Overall Steps per Second: 7196.10980

Timestep Collection Time: 4.81397
Timestep Consumption Time: 2.13923
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.95320

Cumulative Model Updates: 19734
Cumulative Timesteps: 164939629

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.37356
Policy Entropy: 1.37396
Value Function Loss: 0.01208

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.04476
Policy Update Magnitude: 0.10177
Value Function Update Magnitude: 0.12240

Collected Steps per Second: 9936.28300
Overall Steps per Second: 3876.88696

Timestep Collection Time: 5.03377
Timestep Consumption Time: 7.86756
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 12.90133

Cumulative Model Updates: 19740
Cumulative Timesteps: 164989646

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.64267
Policy Entropy: 1.37382
Value Function Loss: 0.01191

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.04917
Policy Update Magnitude: 0.10151
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 9772.52236
Overall Steps per Second: 6982.66816

Timestep Collection Time: 5.11915
Timestep Consumption Time: 2.04530
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.16445

Cumulative Model Updates: 19746
Cumulative Timesteps: 165039673

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.92530
Policy Entropy: 1.37172
Value Function Loss: 0.01170

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.10140
Value Function Update Magnitude: 0.11265

Collected Steps per Second: 10401.86524
Overall Steps per Second: 7200.86322

Timestep Collection Time: 4.80895
Timestep Consumption Time: 2.13772
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 6.94667

Cumulative Model Updates: 19752
Cumulative Timesteps: 165089695

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.89683
Policy Entropy: 1.37078
Value Function Loss: 0.01173

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.09714
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 10122.00672
Overall Steps per Second: 7174.38219

Timestep Collection Time: 4.94368
Timestep Consumption Time: 2.03113
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 6.97482

Cumulative Model Updates: 19758
Cumulative Timesteps: 165139735

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.38775
Policy Entropy: 1.36966
Value Function Loss: 0.01192

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06528
Policy Update Magnitude: 0.09906
Value Function Update Magnitude: 0.11376

Collected Steps per Second: 9789.20261
Overall Steps per Second: 6976.94785

Timestep Collection Time: 5.11012
Timestep Consumption Time: 2.05978
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.16990

Cumulative Model Updates: 19764
Cumulative Timesteps: 165189759

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -16.82113
Policy Entropy: 1.37122
Value Function Loss: 0.01251

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05259
Policy Update Magnitude: 0.10226
Value Function Update Magnitude: 0.11189

Collected Steps per Second: 10331.74843
Overall Steps per Second: 7149.17705

Timestep Collection Time: 4.84052
Timestep Consumption Time: 2.15483
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 6.99535

Cumulative Model Updates: 19770
Cumulative Timesteps: 165239770

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 165239770...
Checkpoint 165239770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.50548
Policy Entropy: 1.36677
Value Function Loss: 0.01288

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.09851
Value Function Update Magnitude: 0.12003

Collected Steps per Second: 10301.58693
Overall Steps per Second: 7241.02235

Timestep Collection Time: 4.85615
Timestep Consumption Time: 2.05255
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 6.90869

Cumulative Model Updates: 19776
Cumulative Timesteps: 165289796

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.98493
Policy Entropy: 1.36842
Value Function Loss: 0.01213

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05686
Policy Update Magnitude: 0.09912
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 9834.78832
Overall Steps per Second: 6970.27648

Timestep Collection Time: 5.08786
Timestep Consumption Time: 2.09091
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 7.17877

Cumulative Model Updates: 19782
Cumulative Timesteps: 165339834

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.04779
Policy Entropy: 1.36631
Value Function Loss: 0.01133

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05892
Policy Update Magnitude: 0.09807
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 10323.51762
Overall Steps per Second: 7152.60507

Timestep Collection Time: 4.84438
Timestep Consumption Time: 2.14762
PPO Batch Consumption Time: 0.02843
Total Iteration Time: 6.99200

Cumulative Model Updates: 19788
Cumulative Timesteps: 165389845

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.78966
Policy Entropy: 1.37038
Value Function Loss: 0.01117

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.04702
Policy Update Magnitude: 0.09929
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10168.41997
Overall Steps per Second: 7112.13151

Timestep Collection Time: 4.91718
Timestep Consumption Time: 2.11306
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.03024

Cumulative Model Updates: 19794
Cumulative Timesteps: 165439845

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.66228
Policy Entropy: 1.36944
Value Function Loss: 0.01156

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.04619
Policy Update Magnitude: 0.09761
Value Function Update Magnitude: 0.12443

Collected Steps per Second: 9950.67255
Overall Steps per Second: 7109.39810

Timestep Collection Time: 5.02780
Timestep Consumption Time: 2.00936
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.03716

Cumulative Model Updates: 19800
Cumulative Timesteps: 165489875

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.93920
Policy Entropy: 1.36826
Value Function Loss: 0.01193

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04035
Policy Update Magnitude: 0.10004
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 10481.16744
Overall Steps per Second: 7275.04009

Timestep Collection Time: 4.77294
Timestep Consumption Time: 2.10345
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 6.87639

Cumulative Model Updates: 19806
Cumulative Timesteps: 165539901

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00516
Policy Entropy: 1.36633
Value Function Loss: 0.01202

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.04898
Policy Update Magnitude: 0.10178
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 9895.50825
Overall Steps per Second: 6980.66948

Timestep Collection Time: 5.05654
Timestep Consumption Time: 2.11140
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.16794

Cumulative Model Updates: 19812
Cumulative Timesteps: 165589938

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.32721
Policy Entropy: 1.36701
Value Function Loss: 0.01265

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04362
Policy Update Magnitude: 0.10034
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 9823.68466
Overall Steps per Second: 6998.96942

Timestep Collection Time: 5.08994
Timestep Consumption Time: 2.05425
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.14419

Cumulative Model Updates: 19818
Cumulative Timesteps: 165639940

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.39668
Policy Entropy: 1.36827
Value Function Loss: 0.01270

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04106
Policy Update Magnitude: 0.10129
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 10340.34479
Overall Steps per Second: 7205.95569

Timestep Collection Time: 4.83688
Timestep Consumption Time: 2.10391
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 6.94079

Cumulative Model Updates: 19824
Cumulative Timesteps: 165689955

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.28804
Policy Entropy: 1.36761
Value Function Loss: 0.01317

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03884
Policy Update Magnitude: 0.10539
Value Function Update Magnitude: 0.12064

Collected Steps per Second: 10232.89287
Overall Steps per Second: 7236.79460

Timestep Collection Time: 4.88962
Timestep Consumption Time: 2.02435
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 6.91397

Cumulative Model Updates: 19830
Cumulative Timesteps: 165739990

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 165739990...
Checkpoint 165739990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1.38396
Policy Entropy: 1.36688
Value Function Loss: 0.01365

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.04490
Policy Update Magnitude: 0.10700
Value Function Update Magnitude: 0.11961

Collected Steps per Second: 9786.64845
Overall Steps per Second: 7036.41619

Timestep Collection Time: 5.11237
Timestep Consumption Time: 1.99821
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.11058

Cumulative Model Updates: 19836
Cumulative Timesteps: 165790023

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.24109
Policy Entropy: 1.36890
Value Function Loss: 0.01325

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04538
Policy Update Magnitude: 0.10509
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 10391.69808
Overall Steps per Second: 7239.13724

Timestep Collection Time: 4.81307
Timestep Consumption Time: 2.09604
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 6.90911

Cumulative Model Updates: 19842
Cumulative Timesteps: 165840039

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.03115
Policy Entropy: 1.36897
Value Function Loss: 0.01311

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05136
Policy Update Magnitude: 0.10670
Value Function Update Magnitude: 0.13047

Collected Steps per Second: 9839.92091
Overall Steps per Second: 7030.39234

Timestep Collection Time: 5.08165
Timestep Consumption Time: 2.03076
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.11241

Cumulative Model Updates: 19848
Cumulative Timesteps: 165890042

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.26393
Policy Entropy: 1.36516
Value Function Loss: 0.01268

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.10902
Value Function Update Magnitude: 0.13693

Collected Steps per Second: 9704.00430
Overall Steps per Second: 6943.67577

Timestep Collection Time: 5.15694
Timestep Consumption Time: 2.05005
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.20699

Cumulative Model Updates: 19854
Cumulative Timesteps: 165940085

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.07623
Policy Entropy: 1.36660
Value Function Loss: 0.01259

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.10949
Value Function Update Magnitude: 0.13436

Collected Steps per Second: 10358.96532
Overall Steps per Second: 7241.51276

Timestep Collection Time: 4.82674
Timestep Consumption Time: 2.07790
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.90463

Cumulative Model Updates: 19860
Cumulative Timesteps: 165990085

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.24246
Policy Entropy: 1.36648
Value Function Loss: 0.01181

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.05273
Policy Update Magnitude: 0.10302
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 9924.39590
Overall Steps per Second: 7015.77542

Timestep Collection Time: 5.04252
Timestep Consumption Time: 2.09054
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 7.13307

Cumulative Model Updates: 19866
Cumulative Timesteps: 166040129

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.98468
Policy Entropy: 1.36587
Value Function Loss: 0.01197

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.04802
Policy Update Magnitude: 0.10388
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 9823.71086
Overall Steps per Second: 6997.40352

Timestep Collection Time: 5.09278
Timestep Consumption Time: 2.05701
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.14979

Cumulative Model Updates: 19872
Cumulative Timesteps: 166090159

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.74724
Policy Entropy: 1.36675
Value Function Loss: 0.01193

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04677
Policy Update Magnitude: 0.10432
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 10593.79411
Overall Steps per Second: 7334.52395

Timestep Collection Time: 4.72333
Timestep Consumption Time: 2.09892
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 6.82226

Cumulative Model Updates: 19878
Cumulative Timesteps: 166140197

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.72458
Policy Entropy: 1.36462
Value Function Loss: 0.01243

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05646
Policy Update Magnitude: 0.10496
Value Function Update Magnitude: 0.12264

Collected Steps per Second: 9959.64171
Overall Steps per Second: 7100.98506

Timestep Collection Time: 5.02287
Timestep Consumption Time: 2.02207
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.04494

Cumulative Model Updates: 19884
Cumulative Timesteps: 166190223

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.41260
Policy Entropy: 1.36753
Value Function Loss: 0.01176

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.04408
Policy Update Magnitude: 0.10559
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 9747.35790
Overall Steps per Second: 6950.39063

Timestep Collection Time: 5.13298
Timestep Consumption Time: 2.06561
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.19859

Cumulative Model Updates: 19890
Cumulative Timesteps: 166240256

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 166240256...
Checkpoint 166240256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.43915
Policy Entropy: 1.36777
Value Function Loss: 0.01203

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.03888
Policy Update Magnitude: 0.10395
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 10276.87006
Overall Steps per Second: 7179.51742

Timestep Collection Time: 4.86831
Timestep Consumption Time: 2.10026
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 6.96857

Cumulative Model Updates: 19896
Cumulative Timesteps: 166290287

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.84804
Policy Entropy: 1.37034
Value Function Loss: 0.01212

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02842
Policy Update Magnitude: 0.10207
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 9814.90273
Overall Steps per Second: 6991.19177

Timestep Collection Time: 5.09837
Timestep Consumption Time: 2.05921
PPO Batch Consumption Time: 0.02834
Total Iteration Time: 7.15758

Cumulative Model Updates: 19902
Cumulative Timesteps: 166340327

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.08270
Policy Entropy: 1.36792
Value Function Loss: 0.01214

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03002
Policy Update Magnitude: 0.10201
Value Function Update Magnitude: 0.11748

Collected Steps per Second: 9944.02485
Overall Steps per Second: 7047.00647

Timestep Collection Time: 5.03166
Timestep Consumption Time: 2.06851
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.10018

Cumulative Model Updates: 19908
Cumulative Timesteps: 166390362

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.90972
Policy Entropy: 1.36845
Value Function Loss: 0.01193

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 0.10116
Value Function Update Magnitude: 0.11557

Collected Steps per Second: 10597.31561
Overall Steps per Second: 7450.41228

Timestep Collection Time: 4.72044
Timestep Consumption Time: 1.99382
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 6.71426

Cumulative Model Updates: 19914
Cumulative Timesteps: 166440386

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.74109
Policy Entropy: 1.36845
Value Function Loss: 0.01142

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03050
Policy Update Magnitude: 0.09827
Value Function Update Magnitude: 0.11565

Collected Steps per Second: 9781.34134
Overall Steps per Second: 6942.33545

Timestep Collection Time: 5.11290
Timestep Consumption Time: 2.09087
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 7.20377

Cumulative Model Updates: 19920
Cumulative Timesteps: 166490397

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.03375
Policy Entropy: 1.36612
Value Function Loss: 0.01200

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03248
Policy Update Magnitude: 0.10118
Value Function Update Magnitude: 0.11951

Collected Steps per Second: 9928.87396
Overall Steps per Second: 7074.89180

Timestep Collection Time: 5.03582
Timestep Consumption Time: 2.03143
PPO Batch Consumption Time: 0.02842
Total Iteration Time: 7.06725

Cumulative Model Updates: 19926
Cumulative Timesteps: 166540397

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.45429
Policy Entropy: 1.36229
Value Function Loss: 0.01232

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04439
Policy Update Magnitude: 0.10396
Value Function Update Magnitude: 0.11868

Collected Steps per Second: 10465.99434
Overall Steps per Second: 7271.18439

Timestep Collection Time: 4.78120
Timestep Consumption Time: 2.10076
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 6.88196

Cumulative Model Updates: 19932
Cumulative Timesteps: 166590437

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -6.16235
Policy Entropy: 1.35887
Value Function Loss: 0.01236

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.10603
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 9718.88498
Overall Steps per Second: 6966.64596

Timestep Collection Time: 5.14730
Timestep Consumption Time: 2.03349
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.18079

Cumulative Model Updates: 19938
Cumulative Timesteps: 166640463

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.92118
Policy Entropy: 1.36237
Value Function Loss: 0.01170

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03999
Policy Update Magnitude: 0.10379
Value Function Update Magnitude: 0.12315

Collected Steps per Second: 9818.51048
Overall Steps per Second: 7057.95761

Timestep Collection Time: 5.09527
Timestep Consumption Time: 1.99290
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.08817

Cumulative Model Updates: 19944
Cumulative Timesteps: 166690491

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.84780
Policy Entropy: 1.36262
Value Function Loss: 0.01104

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05098
Policy Update Magnitude: 0.10291
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 10411.21006
Overall Steps per Second: 7268.13141

Timestep Collection Time: 4.80376
Timestep Consumption Time: 2.07737
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 6.88114

Cumulative Model Updates: 19950
Cumulative Timesteps: 166740504

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 166740504...
Checkpoint 166740504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.36815
Policy Entropy: 1.36283
Value Function Loss: 0.01237

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04461
Policy Update Magnitude: 0.10261
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 9724.83150
Overall Steps per Second: 6938.51723

Timestep Collection Time: 5.14580
Timestep Consumption Time: 2.06641
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.21220

Cumulative Model Updates: 19956
Cumulative Timesteps: 166790546

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.17860
Policy Entropy: 1.36085
Value Function Loss: 0.01296

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04417
Policy Update Magnitude: 0.10729
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 9752.62333
Overall Steps per Second: 6986.50285

Timestep Collection Time: 5.12754
Timestep Consumption Time: 2.03011
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 7.15766

Cumulative Model Updates: 19962
Cumulative Timesteps: 166840553

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.07298
Policy Entropy: 1.35872
Value Function Loss: 0.01352

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05092
Policy Update Magnitude: 0.11030
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 10290.41857
Overall Steps per Second: 7212.43104

Timestep Collection Time: 4.86219
Timestep Consumption Time: 2.07500
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.93719

Cumulative Model Updates: 19968
Cumulative Timesteps: 166890587

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.75280
Policy Entropy: 1.35783
Value Function Loss: 0.01305

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05066
Policy Update Magnitude: 0.11149
Value Function Update Magnitude: 0.12048

Collected Steps per Second: 9868.99534
Overall Steps per Second: 7088.50012

Timestep Collection Time: 5.07042
Timestep Consumption Time: 1.98890
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.05932

Cumulative Model Updates: 19974
Cumulative Timesteps: 166940627

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.13092
Policy Entropy: 1.35891
Value Function Loss: 0.01346

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05070
Policy Update Magnitude: 0.11357
Value Function Update Magnitude: 0.12139

Collected Steps per Second: 9788.02668
Overall Steps per Second: 6989.07966

Timestep Collection Time: 5.11114
Timestep Consumption Time: 2.04688
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.15802

Cumulative Model Updates: 19980
Cumulative Timesteps: 166990655

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.09173
Policy Entropy: 1.36062
Value Function Loss: 0.01315

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.04507
Policy Update Magnitude: 0.11023
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 10305.67160
Overall Steps per Second: 7204.81403

Timestep Collection Time: 4.85276
Timestep Consumption Time: 2.08857
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 6.94133

Cumulative Model Updates: 19986
Cumulative Timesteps: 167040666

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.11792
Policy Entropy: 1.36314
Value Function Loss: 0.01355

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03689
Policy Update Magnitude: 0.11134
Value Function Update Magnitude: 0.12465

Collected Steps per Second: 9623.15387
Overall Steps per Second: 6958.24214

Timestep Collection Time: 5.19694
Timestep Consumption Time: 1.99036
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 7.18730

Cumulative Model Updates: 19992
Cumulative Timesteps: 167090677

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.71678
Policy Entropy: 1.36213
Value Function Loss: 0.01288

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03624
Policy Update Magnitude: 0.11258
Value Function Update Magnitude: 0.12476

Collected Steps per Second: 9769.76284
Overall Steps per Second: 6988.29746

Timestep Collection Time: 5.12008
Timestep Consumption Time: 2.03788
PPO Batch Consumption Time: 0.02471
Total Iteration Time: 7.15797

Cumulative Model Updates: 19998
Cumulative Timesteps: 167140699

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.31671
Policy Entropy: 1.36036
Value Function Loss: 0.01322

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.04556
Policy Update Magnitude: 0.10846
Value Function Update Magnitude: 0.12817

Collected Steps per Second: 10338.55253
Overall Steps per Second: 7203.72116

Timestep Collection Time: 4.83839
Timestep Consumption Time: 2.10552
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 6.94391

Cumulative Model Updates: 20004
Cumulative Timesteps: 167190721

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92234
Policy Entropy: 1.35688
Value Function Loss: 0.01264

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04408
Policy Update Magnitude: 0.10953
Value Function Update Magnitude: 0.12375

Collected Steps per Second: 9695.68677
Overall Steps per Second: 6971.58781

Timestep Collection Time: 5.15848
Timestep Consumption Time: 2.01564
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.17412

Cumulative Model Updates: 20010
Cumulative Timesteps: 167240736

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 167240736...
Checkpoint 167240736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.13919
Policy Entropy: 1.35785
Value Function Loss: 0.01280

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06652
Policy Update Magnitude: 0.10623
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 9606.25788
Overall Steps per Second: 6978.14239

Timestep Collection Time: 5.20900
Timestep Consumption Time: 1.96182
PPO Batch Consumption Time: 0.02464
Total Iteration Time: 7.17082

Cumulative Model Updates: 20016
Cumulative Timesteps: 167290775

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.49245
Policy Entropy: 1.35659
Value Function Loss: 0.01224

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05292
Policy Update Magnitude: 0.10753
Value Function Update Magnitude: 0.12456

Collected Steps per Second: 10319.88732
Overall Steps per Second: 7230.04028

Timestep Collection Time: 4.84928
Timestep Consumption Time: 2.07240
PPO Batch Consumption Time: 0.02434
Total Iteration Time: 6.92168

Cumulative Model Updates: 20022
Cumulative Timesteps: 167340819

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.05688
Policy Entropy: 1.35506
Value Function Loss: 0.01229

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.04923
Policy Update Magnitude: 0.10926
Value Function Update Magnitude: 0.11942

Collected Steps per Second: 9787.50207
Overall Steps per Second: 7019.22494

Timestep Collection Time: 5.10978
Timestep Consumption Time: 2.01522
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 7.12500

Cumulative Model Updates: 20028
Cumulative Timesteps: 167390831

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.21616
Policy Entropy: 1.35137
Value Function Loss: 0.01262

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.04747
Policy Update Magnitude: 0.10979
Value Function Update Magnitude: 0.12090

Collected Steps per Second: 9886.20094
Overall Steps per Second: 7044.03930

Timestep Collection Time: 5.05816
Timestep Consumption Time: 2.04089
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.09905

Cumulative Model Updates: 20034
Cumulative Timesteps: 167440837

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.27204
Policy Entropy: 1.35180
Value Function Loss: 0.01347

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.11074
Value Function Update Magnitude: 0.11996

Collected Steps per Second: 10331.01165
Overall Steps per Second: 7202.38301

Timestep Collection Time: 4.84144
Timestep Consumption Time: 2.10306
PPO Batch Consumption Time: 0.02811
Total Iteration Time: 6.94451

Cumulative Model Updates: 20040
Cumulative Timesteps: 167490854

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.10331
Policy Entropy: 1.36351
Value Function Loss: 0.01316

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.11031
Value Function Update Magnitude: 0.11880

Collected Steps per Second: 9948.24043
Overall Steps per Second: 7086.01772

Timestep Collection Time: 5.02813
Timestep Consumption Time: 2.03099
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.05911

Cumulative Model Updates: 20046
Cumulative Timesteps: 167540875

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.97049
Policy Entropy: 1.36078
Value Function Loss: 0.01241

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.10250
Value Function Update Magnitude: 0.12069

Collected Steps per Second: 9832.93020
Overall Steps per Second: 7025.28847

Timestep Collection Time: 5.08973
Timestep Consumption Time: 2.03410
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.12384

Cumulative Model Updates: 20052
Cumulative Timesteps: 167590922

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.24171
Policy Entropy: 1.36562
Value Function Loss: 0.01239

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.09903
Value Function Update Magnitude: 0.12340

Collected Steps per Second: 10460.78331
Overall Steps per Second: 7301.85360

Timestep Collection Time: 4.78320
Timestep Consumption Time: 2.06931
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.85251

Cumulative Model Updates: 20058
Cumulative Timesteps: 167640958

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.53132
Policy Entropy: 1.36241
Value Function Loss: 0.01229

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.10023
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 9979.27928
Overall Steps per Second: 6993.19142

Timestep Collection Time: 5.01199
Timestep Consumption Time: 2.14011
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.15210

Cumulative Model Updates: 20064
Cumulative Timesteps: 167690974

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.12172
Policy Entropy: 1.36944
Value Function Loss: 0.01261

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.04652
Policy Update Magnitude: 0.10079
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 10070.66579
Overall Steps per Second: 7127.32276

Timestep Collection Time: 4.96909
Timestep Consumption Time: 2.05206
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.02115

Cumulative Model Updates: 20070
Cumulative Timesteps: 167741016

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 167741016...
Checkpoint 167741016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.68526
Policy Entropy: 1.37007
Value Function Loss: 0.01283

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05190
Policy Update Magnitude: 0.10388
Value Function Update Magnitude: 0.12219

Collected Steps per Second: 10354.95836
Overall Steps per Second: 7211.60979

Timestep Collection Time: 4.83179
Timestep Consumption Time: 2.10605
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 6.93784

Cumulative Model Updates: 20076
Cumulative Timesteps: 167791049

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -4.27818
Policy Entropy: 1.37115
Value Function Loss: 0.01264

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04072
Policy Update Magnitude: 0.10130
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10338.58310
Overall Steps per Second: 7198.00459

Timestep Collection Time: 4.83886
Timestep Consumption Time: 2.11126
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 6.95012

Cumulative Model Updates: 20082
Cumulative Timesteps: 167841076

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.47093
Policy Entropy: 1.36773
Value Function Loss: 0.01176

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04223
Policy Update Magnitude: 0.10499
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 9601.43663
Overall Steps per Second: 6991.61719

Timestep Collection Time: 5.21078
Timestep Consumption Time: 1.94507
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.15586

Cumulative Model Updates: 20088
Cumulative Timesteps: 167891107

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.88200
Policy Entropy: 1.36799
Value Function Loss: 0.01192

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04204
Policy Update Magnitude: 0.10361
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 10003.99691
Overall Steps per Second: 7001.35147

Timestep Collection Time: 4.99920
Timestep Consumption Time: 2.14399
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 7.14319

Cumulative Model Updates: 20094
Cumulative Timesteps: 167941119

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.25507
Policy Entropy: 1.36646
Value Function Loss: 0.01234

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.04997
Policy Update Magnitude: 0.10351
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 9560.69335
Overall Steps per Second: 6944.36991

Timestep Collection Time: 5.23445
Timestep Consumption Time: 1.97210
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.20656

Cumulative Model Updates: 20100
Cumulative Timesteps: 167991164

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.21144
Policy Entropy: 1.36889
Value Function Loss: 0.01237

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04433
Policy Update Magnitude: 0.10283
Value Function Update Magnitude: 0.12134

Collected Steps per Second: 9447.33311
Overall Steps per Second: 6873.26091

Timestep Collection Time: 5.29250
Timestep Consumption Time: 1.98207
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.27457

Cumulative Model Updates: 20106
Cumulative Timesteps: 168041164

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.39189
Policy Entropy: 1.36767
Value Function Loss: 0.01279

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04428
Policy Update Magnitude: 0.10104
Value Function Update Magnitude: 0.11929

Collected Steps per Second: 9967.46028
Overall Steps per Second: 6957.46378

Timestep Collection Time: 5.01682
Timestep Consumption Time: 2.17042
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 7.18725

Cumulative Model Updates: 20112
Cumulative Timesteps: 168091169

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.88374
Policy Entropy: 1.36908
Value Function Loss: 0.01237

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 0.10410
Value Function Update Magnitude: 0.11228

Collected Steps per Second: 9549.12152
Overall Steps per Second: 6880.94764

Timestep Collection Time: 5.23619
Timestep Consumption Time: 2.03040
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.26659

Cumulative Model Updates: 20118
Cumulative Timesteps: 168141170

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -6.82272
Policy Entropy: 1.36860
Value Function Loss: 0.01221

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03818
Policy Update Magnitude: 0.10522
Value Function Update Magnitude: 0.11367

Collected Steps per Second: 9765.53578
Overall Steps per Second: 7026.74115

Timestep Collection Time: 5.12435
Timestep Consumption Time: 1.99730
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 7.12165

Cumulative Model Updates: 20124
Cumulative Timesteps: 168191212

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.03190
Policy Entropy: 1.36694
Value Function Loss: 0.01159

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04123
Policy Update Magnitude: 0.09961
Value Function Update Magnitude: 0.11215

Collected Steps per Second: 10364.33789
Overall Steps per Second: 7243.02796

Timestep Collection Time: 4.82578
Timestep Consumption Time: 2.07962
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.90540

Cumulative Model Updates: 20130
Cumulative Timesteps: 168241228

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 168241228...
Checkpoint 168241228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -2.25412
Policy Entropy: 1.36564
Value Function Loss: 0.01205

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03664
Policy Update Magnitude: 0.10142
Value Function Update Magnitude: 0.11315

Collected Steps per Second: 9959.10497
Overall Steps per Second: 7014.16228

Timestep Collection Time: 5.02354
Timestep Consumption Time: 2.10917
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 7.13271

Cumulative Model Updates: 20136
Cumulative Timesteps: 168291258

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.04662
Policy Entropy: 1.36154
Value Function Loss: 0.01248

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.04299
Policy Update Magnitude: 0.10367
Value Function Update Magnitude: 0.11592

Collected Steps per Second: 9700.28367
Overall Steps per Second: 6975.85233

Timestep Collection Time: 5.15830
Timestep Consumption Time: 2.01458
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 7.17289

Cumulative Model Updates: 20142
Cumulative Timesteps: 168341295

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.30482
Policy Entropy: 1.36012
Value Function Loss: 0.01245

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.10777
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 10494.67041
Overall Steps per Second: 7250.00150

Timestep Collection Time: 4.76728
Timestep Consumption Time: 2.13355
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 6.90083

Cumulative Model Updates: 20148
Cumulative Timesteps: 168391326

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.50432
Policy Entropy: 1.36202
Value Function Loss: 0.01124

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04317
Policy Update Magnitude: 0.10801
Value Function Update Magnitude: 0.12011

Collected Steps per Second: 9825.81125
Overall Steps per Second: 7030.06799

Timestep Collection Time: 5.09200
Timestep Consumption Time: 2.02500
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 7.11700

Cumulative Model Updates: 20154
Cumulative Timesteps: 168441359

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.32346
Policy Entropy: 1.36218
Value Function Loss: 0.01147

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04298
Policy Update Magnitude: 0.10411
Value Function Update Magnitude: 0.11253

Collected Steps per Second: 9895.77296
Overall Steps per Second: 7070.66124

Timestep Collection Time: 5.05670
Timestep Consumption Time: 2.02043
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.07713

Cumulative Model Updates: 20160
Cumulative Timesteps: 168491399

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.47610
Policy Entropy: 1.36006
Value Function Loss: 0.01182

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 0.10450
Value Function Update Magnitude: 0.11469

Collected Steps per Second: 10469.14195
Overall Steps per Second: 7281.24592

Timestep Collection Time: 4.77833
Timestep Consumption Time: 2.09206
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 6.87039

Cumulative Model Updates: 20166
Cumulative Timesteps: 168541424

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.70170
Policy Entropy: 1.35723
Value Function Loss: 0.01254

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04198
Policy Update Magnitude: 0.10893
Value Function Update Magnitude: 0.11730

Collected Steps per Second: 9948.59035
Overall Steps per Second: 6989.71074

Timestep Collection Time: 5.02644
Timestep Consumption Time: 2.12779
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.15423

Cumulative Model Updates: 20172
Cumulative Timesteps: 168591430

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.06405
Policy Entropy: 1.35930
Value Function Loss: 0.01265

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.04317
Policy Update Magnitude: 0.11082
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 9714.23073
Overall Steps per Second: 6950.91839

Timestep Collection Time: 5.14976
Timestep Consumption Time: 2.04727
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.19703

Cumulative Model Updates: 20178
Cumulative Timesteps: 168641456

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.81605
Policy Entropy: 1.36381
Value Function Loss: 0.01311

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03907
Policy Update Magnitude: 0.11229
Value Function Update Magnitude: 0.12188

Collected Steps per Second: 10893.29977
Overall Steps per Second: 7482.05390

Timestep Collection Time: 4.59218
Timestep Consumption Time: 2.09368
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 6.68586

Cumulative Model Updates: 20184
Cumulative Timesteps: 168691480

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89718
Policy Entropy: 1.36096
Value Function Loss: 0.01239

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05296
Policy Update Magnitude: 0.11305
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 9874.90152
Overall Steps per Second: 7050.05024

Timestep Collection Time: 5.06658
Timestep Consumption Time: 2.03010
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.09669

Cumulative Model Updates: 20190
Cumulative Timesteps: 168741512

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 168741512...
Checkpoint 168741512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.67327
Policy Entropy: 1.35574
Value Function Loss: 0.01225

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.10909
Value Function Update Magnitude: 0.11945

Collected Steps per Second: 9578.31579
Overall Steps per Second: 6871.83300

Timestep Collection Time: 5.22472
Timestep Consumption Time: 2.05776
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.28248

Cumulative Model Updates: 20196
Cumulative Timesteps: 168791556

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.21448
Policy Entropy: 1.35422
Value Function Loss: 0.01216

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07045
Policy Update Magnitude: 0.10627
Value Function Update Magnitude: 0.11477

Collected Steps per Second: 10603.20333
Overall Steps per Second: 7285.48919

Timestep Collection Time: 4.71895
Timestep Consumption Time: 2.14895
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 6.86790

Cumulative Model Updates: 20202
Cumulative Timesteps: 168841592

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.49887
Policy Entropy: 1.35569
Value Function Loss: 0.01311

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.10863
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 9907.04095
Overall Steps per Second: 6973.43374

Timestep Collection Time: 5.05126
Timestep Consumption Time: 2.12498
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.17624

Cumulative Model Updates: 20208
Cumulative Timesteps: 168891635

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.69530
Policy Entropy: 1.36105
Value Function Loss: 0.01333

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.04953
Policy Update Magnitude: 0.10872
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 9769.79629
Overall Steps per Second: 6989.83355

Timestep Collection Time: 5.11925
Timestep Consumption Time: 2.03600
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.15525

Cumulative Model Updates: 20214
Cumulative Timesteps: 168941649

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.66403
Policy Entropy: 1.35847
Value Function Loss: 0.01340

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05016
Policy Update Magnitude: 0.11085
Value Function Update Magnitude: 0.12431

Collected Steps per Second: 10491.44594
Overall Steps per Second: 7263.76760

Timestep Collection Time: 4.76598
Timestep Consumption Time: 2.11778
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 6.88376

Cumulative Model Updates: 20220
Cumulative Timesteps: 168991651

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.28605
Policy Entropy: 1.35615
Value Function Loss: 0.01288

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.05430
Policy Update Magnitude: 0.11549
Value Function Update Magnitude: 0.12776

Collected Steps per Second: 9766.89404
Overall Steps per Second: 7000.07230

Timestep Collection Time: 5.12005
Timestep Consumption Time: 2.02373
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.14378

Cumulative Model Updates: 20226
Cumulative Timesteps: 169041658

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.00858
Policy Entropy: 1.35565
Value Function Loss: 0.01221

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05376
Policy Update Magnitude: 0.11026
Value Function Update Magnitude: 0.12518

Collected Steps per Second: 9849.86047
Overall Steps per Second: 6999.05922

Timestep Collection Time: 5.07967
Timestep Consumption Time: 2.06901
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 7.14868

Cumulative Model Updates: 20232
Cumulative Timesteps: 169091692

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.60257
Policy Entropy: 1.35855
Value Function Loss: 0.01157

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04340
Policy Update Magnitude: 0.10735
Value Function Update Magnitude: 0.12054

Collected Steps per Second: 10336.47514
Overall Steps per Second: 7170.38569

Timestep Collection Time: 4.83782
Timestep Consumption Time: 2.13614
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 6.97396

Cumulative Model Updates: 20238
Cumulative Timesteps: 169141698

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -7.19521
Policy Entropy: 1.35932
Value Function Loss: 0.01204

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 0.10702
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 9653.86094
Overall Steps per Second: 6924.85962

Timestep Collection Time: 5.18052
Timestep Consumption Time: 2.04158
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.22210

Cumulative Model Updates: 20244
Cumulative Timesteps: 169191710

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -12.56269
Policy Entropy: 1.35674
Value Function Loss: 0.01293

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04048
Policy Update Magnitude: 0.10830
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 9819.86163
Overall Steps per Second: 7122.45652

Timestep Collection Time: 5.09254
Timestep Consumption Time: 1.92864
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.02117

Cumulative Model Updates: 20250
Cumulative Timesteps: 169241718

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 169241718...
Checkpoint 169241718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.21798
Policy Entropy: 1.35450
Value Function Loss: 0.01336

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04477
Policy Update Magnitude: 0.10842
Value Function Update Magnitude: 0.11949

Collected Steps per Second: 10898.19295
Overall Steps per Second: 7505.96695

Timestep Collection Time: 4.59177
Timestep Consumption Time: 2.07519
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 6.66696

Cumulative Model Updates: 20256
Cumulative Timesteps: 169291760

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.13792
Policy Entropy: 1.35526
Value Function Loss: 0.01199

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04407
Policy Update Magnitude: 0.10963
Value Function Update Magnitude: 0.12172

Collected Steps per Second: 9876.84086
Overall Steps per Second: 7033.06350

Timestep Collection Time: 5.06538
Timestep Consumption Time: 2.04816
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.11354

Cumulative Model Updates: 20262
Cumulative Timesteps: 169341790

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.89047
Policy Entropy: 1.35702
Value Function Loss: 0.01165

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03578
Policy Update Magnitude: 0.11167
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 9842.72322
Overall Steps per Second: 7031.31565

Timestep Collection Time: 5.08386
Timestep Consumption Time: 2.03273
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.11659

Cumulative Model Updates: 20268
Cumulative Timesteps: 169391829

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.33837
Policy Entropy: 1.35628
Value Function Loss: 0.01191

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.04720
Policy Update Magnitude: 0.10783
Value Function Update Magnitude: 0.11846

Collected Steps per Second: 10416.72857
Overall Steps per Second: 7210.03315

Timestep Collection Time: 4.80247
Timestep Consumption Time: 2.13592
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 6.93839

Cumulative Model Updates: 20274
Cumulative Timesteps: 169441855

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.20617
Policy Entropy: 1.35587
Value Function Loss: 0.01321

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.04474
Policy Update Magnitude: 0.10888
Value Function Update Magnitude: 0.12284

Collected Steps per Second: 9855.87520
Overall Steps per Second: 7062.33867

Timestep Collection Time: 5.07657
Timestep Consumption Time: 2.00806
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.08462

Cumulative Model Updates: 20280
Cumulative Timesteps: 169491889

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.16035
Policy Entropy: 1.35538
Value Function Loss: 0.01357

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.05094
Policy Update Magnitude: 0.11299
Value Function Update Magnitude: 0.13309

Collected Steps per Second: 10146.41284
Overall Steps per Second: 4319.87189

Timestep Collection Time: 4.93140
Timestep Consumption Time: 6.65135
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 11.58275

Cumulative Model Updates: 20286
Cumulative Timesteps: 169541925

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.61853
Policy Entropy: 1.35621
Value Function Loss: 0.01358

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.05540
Policy Update Magnitude: 0.11269
Value Function Update Magnitude: 0.13724

Collected Steps per Second: 10422.19369
Overall Steps per Second: 7242.26522

Timestep Collection Time: 4.79784
Timestep Consumption Time: 2.10663
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 6.90447

Cumulative Model Updates: 20292
Cumulative Timesteps: 169591929

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.05778
Policy Entropy: 1.35434
Value Function Loss: 0.01333

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.05912
Policy Update Magnitude: 0.11049
Value Function Update Magnitude: 0.14014

Collected Steps per Second: 9949.63742
Overall Steps per Second: 7020.80538

Timestep Collection Time: 5.02943
Timestep Consumption Time: 2.09810
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.12753

Cumulative Model Updates: 20298
Cumulative Timesteps: 169641970

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.30381
Policy Entropy: 1.35470
Value Function Loss: 0.01318

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.04403
Policy Update Magnitude: 0.11227
Value Function Update Magnitude: 0.13634

Collected Steps per Second: 11075.71427
Overall Steps per Second: 7320.34222

Timestep Collection Time: 4.51528
Timestep Consumption Time: 2.31636
PPO Batch Consumption Time: 0.02913
Total Iteration Time: 6.83165

Cumulative Model Updates: 20304
Cumulative Timesteps: 169691980

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.54650
Policy Entropy: 1.35081
Value Function Loss: 0.01317

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05325
Policy Update Magnitude: 0.11592
Value Function Update Magnitude: 0.12732

Collected Steps per Second: 10514.04551
Overall Steps per Second: 7433.30854

Timestep Collection Time: 4.75573
Timestep Consumption Time: 1.97102
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.72675

Cumulative Model Updates: 20310
Cumulative Timesteps: 169741982

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 169741982...
Checkpoint 169741982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18126
Policy Entropy: 1.35125
Value Function Loss: 0.01328

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.04915
Policy Update Magnitude: 0.11906
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 9744.56638
Overall Steps per Second: 7014.39682

Timestep Collection Time: 5.13476
Timestep Consumption Time: 1.99857
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.13333

Cumulative Model Updates: 20316
Cumulative Timesteps: 169792018

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.73905
Policy Entropy: 1.35143
Value Function Loss: 0.01351

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.05342
Policy Update Magnitude: 0.11549
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 9596.89007
Overall Steps per Second: 6898.75373

Timestep Collection Time: 5.21336
Timestep Consumption Time: 2.03897
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.25232

Cumulative Model Updates: 20322
Cumulative Timesteps: 169842050

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.61148
Policy Entropy: 1.35346
Value Function Loss: 0.01332

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.11473
Value Function Update Magnitude: 0.12752

Collected Steps per Second: 10264.47662
Overall Steps per Second: 7185.13478

Timestep Collection Time: 4.87156
Timestep Consumption Time: 2.08781
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 6.95937

Cumulative Model Updates: 20328
Cumulative Timesteps: 169892054

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.84912
Policy Entropy: 1.35718
Value Function Loss: 0.01323

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.11638
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 9826.51260
Overall Steps per Second: 7018.07676

Timestep Collection Time: 5.09031
Timestep Consumption Time: 2.03700
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.12731

Cumulative Model Updates: 20334
Cumulative Timesteps: 169942074

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.00111
Policy Entropy: 1.35643
Value Function Loss: 0.01250

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04504
Policy Update Magnitude: 0.11369
Value Function Update Magnitude: 0.12032

Collected Steps per Second: 10419.88519
Overall Steps per Second: 7014.06476

Timestep Collection Time: 4.80053
Timestep Consumption Time: 2.33100
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.13153

Cumulative Model Updates: 20340
Cumulative Timesteps: 169992095

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.79364
Policy Entropy: 1.35296
Value Function Loss: 0.01269

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05175
Policy Update Magnitude: 0.11469
Value Function Update Magnitude: 0.11858

Collected Steps per Second: 10378.09501
Overall Steps per Second: 4494.49822

Timestep Collection Time: 4.82025
Timestep Consumption Time: 6.31003
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 11.13027

Cumulative Model Updates: 20346
Cumulative Timesteps: 170042120

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.60632
Policy Entropy: 1.35078
Value Function Loss: 0.01239

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.11074
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 9898.21473
Overall Steps per Second: 7039.99396

Timestep Collection Time: 5.05424
Timestep Consumption Time: 2.05201
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.10626

Cumulative Model Updates: 20352
Cumulative Timesteps: 170092148

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.18056
Policy Entropy: 1.35315
Value Function Loss: 0.01212

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.10857
Value Function Update Magnitude: 0.12352

Collected Steps per Second: 10339.01116
Overall Steps per Second: 6980.12469

Timestep Collection Time: 4.83895
Timestep Consumption Time: 2.32854
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.16749

Cumulative Model Updates: 20358
Cumulative Timesteps: 170142178

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.68477
Policy Entropy: 1.35575
Value Function Loss: 0.01246

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.04874
Policy Update Magnitude: 0.10720
Value Function Update Magnitude: 0.12620

Collected Steps per Second: 10354.20708
Overall Steps per Second: 7222.97019

Timestep Collection Time: 4.83011
Timestep Consumption Time: 2.09391
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 6.92402

Cumulative Model Updates: 20364
Cumulative Timesteps: 170192190

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.84506
Policy Entropy: 1.35687
Value Function Loss: 0.01276

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.04753
Policy Update Magnitude: 0.11099
Value Function Update Magnitude: 0.12229

Collected Steps per Second: 9739.26719
Overall Steps per Second: 6957.83124

Timestep Collection Time: 5.13509
Timestep Consumption Time: 2.05278
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.18787

Cumulative Model Updates: 20370
Cumulative Timesteps: 170242202

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 170242202...
Checkpoint 170242202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.96590
Policy Entropy: 1.35473
Value Function Loss: 0.01351

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05740
Policy Update Magnitude: 0.11176
Value Function Update Magnitude: 0.12414

Collected Steps per Second: 9572.17009
Overall Steps per Second: 6854.56120

Timestep Collection Time: 5.22818
Timestep Consumption Time: 2.07280
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 7.30098

Cumulative Model Updates: 20376
Cumulative Timesteps: 170292247

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.85246
Policy Entropy: 1.35574
Value Function Loss: 0.01287

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05523
Policy Update Magnitude: 0.11341
Value Function Update Magnitude: 0.12766

Collected Steps per Second: 10889.52551
Overall Steps per Second: 7528.20551

Timestep Collection Time: 4.59157
Timestep Consumption Time: 2.05012
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 6.64169

Cumulative Model Updates: 20382
Cumulative Timesteps: 170342247

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.57486
Policy Entropy: 1.35516
Value Function Loss: 0.01328

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04319
Policy Update Magnitude: 0.11739
Value Function Update Magnitude: 0.12731

Collected Steps per Second: 9846.23384
Overall Steps per Second: 7064.79606

Timestep Collection Time: 5.08184
Timestep Consumption Time: 2.00074
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.08258

Cumulative Model Updates: 20388
Cumulative Timesteps: 170392284

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.39732
Policy Entropy: 1.35296
Value Function Loss: 0.01240

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.04520
Policy Update Magnitude: 0.11886
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 9716.24151
Overall Steps per Second: 6931.10725

Timestep Collection Time: 5.14839
Timestep Consumption Time: 2.06878
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.21717

Cumulative Model Updates: 20394
Cumulative Timesteps: 170442307

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.76880
Policy Entropy: 1.35233
Value Function Loss: 0.01233

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05407
Policy Update Magnitude: 0.11641
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 10470.93659
Overall Steps per Second: 7286.32205

Timestep Collection Time: 4.77512
Timestep Consumption Time: 2.08705
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.86217

Cumulative Model Updates: 20400
Cumulative Timesteps: 170492307

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.06276
Policy Entropy: 1.35551
Value Function Loss: 0.01216

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.11973
Value Function Update Magnitude: 0.13060

Collected Steps per Second: 9782.90947
Overall Steps per Second: 7003.44451

Timestep Collection Time: 5.11300
Timestep Consumption Time: 2.02920
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.14220

Cumulative Model Updates: 20406
Cumulative Timesteps: 170542327

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.76113
Policy Entropy: 1.35038
Value Function Loss: 0.01310

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.11872
Value Function Update Magnitude: 0.13190

Collected Steps per Second: 9943.46258
Overall Steps per Second: 7074.30906

Timestep Collection Time: 5.02923
Timestep Consumption Time: 2.03972
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.06896

Cumulative Model Updates: 20412
Cumulative Timesteps: 170592335

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.11211
Policy Entropy: 1.35430
Value Function Loss: 0.01248

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.11421
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 10445.19730
Overall Steps per Second: 7286.17509

Timestep Collection Time: 4.79034
Timestep Consumption Time: 2.07692
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.86725

Cumulative Model Updates: 20418
Cumulative Timesteps: 170642371

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.30117
Policy Entropy: 1.35323
Value Function Loss: 0.01283

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.11263
Value Function Update Magnitude: 0.12404

Collected Steps per Second: 9821.36257
Overall Steps per Second: 7035.63171

Timestep Collection Time: 5.09196
Timestep Consumption Time: 2.01614
PPO Batch Consumption Time: 0.02390
Total Iteration Time: 7.10810

Cumulative Model Updates: 20424
Cumulative Timesteps: 170692381

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.88458
Policy Entropy: 1.35803
Value Function Loss: 0.01319

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05440
Policy Update Magnitude: 0.11284
Value Function Update Magnitude: 0.12352

Collected Steps per Second: 9900.59464
Overall Steps per Second: 7051.83629

Timestep Collection Time: 5.05141
Timestep Consumption Time: 2.04064
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.09205

Cumulative Model Updates: 20430
Cumulative Timesteps: 170742393

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 170742393...
Checkpoint 170742393 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.35203
Policy Entropy: 1.35656
Value Function Loss: 0.01374

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.05916
Policy Update Magnitude: 0.11511
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 10731.81468
Overall Steps per Second: 7435.44131

Timestep Collection Time: 4.66184
Timestep Consumption Time: 2.06675
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.72859

Cumulative Model Updates: 20436
Cumulative Timesteps: 170792423

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.71702
Policy Entropy: 1.35897
Value Function Loss: 0.01287

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.05162
Policy Update Magnitude: 0.11285
Value Function Update Magnitude: 0.12715

Collected Steps per Second: 9928.62987
Overall Steps per Second: 6982.12616

Timestep Collection Time: 5.03755
Timestep Consumption Time: 2.12588
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.16343

Cumulative Model Updates: 20442
Cumulative Timesteps: 170842439

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.93503
Policy Entropy: 1.36303
Value Function Loss: 0.01199

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.03900
Policy Update Magnitude: 0.11211
Value Function Update Magnitude: 0.12985

Collected Steps per Second: 9774.48765
Overall Steps per Second: 7010.00680

Timestep Collection Time: 5.11812
Timestep Consumption Time: 2.01839
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.13651

Cumulative Model Updates: 20448
Cumulative Timesteps: 170892466

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.66321
Policy Entropy: 1.36520
Value Function Loss: 0.01137

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03844
Policy Update Magnitude: 0.10597
Value Function Update Magnitude: 0.12709

Collected Steps per Second: 10411.53656
Overall Steps per Second: 7172.34554

Timestep Collection Time: 4.80313
Timestep Consumption Time: 2.16920
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 6.97234

Cumulative Model Updates: 20454
Cumulative Timesteps: 170942474

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.12241
Policy Entropy: 1.36335
Value Function Loss: 0.01254

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.03904
Policy Update Magnitude: 0.10557
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 9795.36544
Overall Steps per Second: 1169.79799

Timestep Collection Time: 5.10854
Timestep Consumption Time: 37.66808
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 42.77662

Cumulative Model Updates: 20460
Cumulative Timesteps: 170992514

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.83360
Policy Entropy: 1.36507
Value Function Loss: 0.01254

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03496
Policy Update Magnitude: 0.10992
Value Function Update Magnitude: 0.13469

Collected Steps per Second: 9840.02594
Overall Steps per Second: 7012.70705

Timestep Collection Time: 5.08220
Timestep Consumption Time: 2.04900
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.13120

Cumulative Model Updates: 20466
Cumulative Timesteps: 171042523

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.57855
Policy Entropy: 1.35997
Value Function Loss: 0.01288

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.04771
Policy Update Magnitude: 0.11131
Value Function Update Magnitude: 0.14051

Collected Steps per Second: 10287.34095
Overall Steps per Second: 7126.89458

Timestep Collection Time: 4.86073
Timestep Consumption Time: 2.15551
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.01624

Cumulative Model Updates: 20472
Cumulative Timesteps: 171092527

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.71732
Policy Entropy: 1.35997
Value Function Loss: 0.01210

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04172
Policy Update Magnitude: 0.10935
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 9874.01094
Overall Steps per Second: 7076.21863

Timestep Collection Time: 5.06704
Timestep Consumption Time: 2.00340
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.07044

Cumulative Model Updates: 20478
Cumulative Timesteps: 171142559

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.65703
Policy Entropy: 1.35576
Value Function Loss: 0.01213

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.04548
Policy Update Magnitude: 0.11405
Value Function Update Magnitude: 0.13442

Collected Steps per Second: 9985.29020
Overall Steps per Second: 7120.74057

Timestep Collection Time: 5.01077
Timestep Consumption Time: 2.01575
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.02652

Cumulative Model Updates: 20484
Cumulative Timesteps: 171192593

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.07335
Policy Entropy: 1.35790
Value Function Loss: 0.01184

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.05206
Policy Update Magnitude: 0.11594
Value Function Update Magnitude: 0.13081

Collected Steps per Second: 10510.96317
Overall Steps per Second: 7282.16228

Timestep Collection Time: 4.76131
Timestep Consumption Time: 2.11109
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 6.87241

Cumulative Model Updates: 20490
Cumulative Timesteps: 171242639

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 171242639...
Checkpoint 171242639 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.57791
Policy Entropy: 1.35786
Value Function Loss: 0.01223

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05682
Policy Update Magnitude: 0.11261
Value Function Update Magnitude: 0.12895

Collected Steps per Second: 9928.06240
Overall Steps per Second: 7020.27166

Timestep Collection Time: 5.04016
Timestep Consumption Time: 2.08763
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.12779

Cumulative Model Updates: 20496
Cumulative Timesteps: 171292678

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.20664
Policy Entropy: 1.35854
Value Function Loss: 0.01208

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.05899
Policy Update Magnitude: 0.10913
Value Function Update Magnitude: 0.12393

Collected Steps per Second: 9781.03664
Overall Steps per Second: 7003.12727

Timestep Collection Time: 5.11193
Timestep Consumption Time: 2.02773
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.13967

Cumulative Model Updates: 20502
Cumulative Timesteps: 171342678

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.04723
Policy Entropy: 1.36117
Value Function Loss: 0.01243

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03967
Policy Update Magnitude: 0.11079
Value Function Update Magnitude: 0.12231

Collected Steps per Second: 10319.74479
Overall Steps per Second: 7164.07633

Timestep Collection Time: 4.84712
Timestep Consumption Time: 2.13508
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 6.98220

Cumulative Model Updates: 20508
Cumulative Timesteps: 171392699

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -10.20320
Policy Entropy: 1.36308
Value Function Loss: 0.01236

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.04342
Policy Update Magnitude: 0.11508
Value Function Update Magnitude: 0.12969

Collected Steps per Second: 9844.83059
Overall Steps per Second: 6975.44150

Timestep Collection Time: 5.07891
Timestep Consumption Time: 2.08924
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 7.16815

Cumulative Model Updates: 20514
Cumulative Timesteps: 171442700

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.41966
Policy Entropy: 1.36430
Value Function Loss: 0.01266

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04508
Policy Update Magnitude: 0.11562
Value Function Update Magnitude: 0.12977

Collected Steps per Second: 10649.59502
Overall Steps per Second: 7128.33484

Timestep Collection Time: 4.69802
Timestep Consumption Time: 2.32073
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.01875

Cumulative Model Updates: 20520
Cumulative Timesteps: 171492732

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.71664
Policy Entropy: 1.36910
Value Function Loss: 0.01196

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.04609
Policy Update Magnitude: 0.11049
Value Function Update Magnitude: 0.12788

Collected Steps per Second: 10386.07896
Overall Steps per Second: 7195.11007

Timestep Collection Time: 4.81789
Timestep Consumption Time: 2.13669
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 6.95458

Cumulative Model Updates: 20526
Cumulative Timesteps: 171542771

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.27322
Policy Entropy: 1.36650
Value Function Loss: 0.01202

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.04638
Policy Update Magnitude: 0.10408
Value Function Update Magnitude: 0.12442

Collected Steps per Second: 9730.04094
Overall Steps per Second: 7044.13634

Timestep Collection Time: 5.14068
Timestep Consumption Time: 1.96012
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.10080

Cumulative Model Updates: 20532
Cumulative Timesteps: 171592790

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.30323
Policy Entropy: 1.36461
Value Function Loss: 0.01183

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.10467
Value Function Update Magnitude: 0.12214

Collected Steps per Second: 10816.98395
Overall Steps per Second: 7207.70247

Timestep Collection Time: 4.62384
Timestep Consumption Time: 2.31540
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 6.93924

Cumulative Model Updates: 20538
Cumulative Timesteps: 171642806

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.05024
Policy Entropy: 1.36367
Value Function Loss: 0.01251

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.03895
Policy Update Magnitude: 0.10899
Value Function Update Magnitude: 0.12231

Collected Steps per Second: 10442.30631
Overall Steps per Second: 7161.00850

Timestep Collection Time: 4.78917
Timestep Consumption Time: 2.19448
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.98365

Cumulative Model Updates: 20544
Cumulative Timesteps: 171692816

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.06519
Policy Entropy: 1.36409
Value Function Loss: 0.01228

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03699
Policy Update Magnitude: 0.12216
Value Function Update Magnitude: 0.12534

Collected Steps per Second: 9842.89791
Overall Steps per Second: 6929.77189

Timestep Collection Time: 5.08082
Timestep Consumption Time: 2.13587
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 7.21669

Cumulative Model Updates: 20550
Cumulative Timesteps: 171742826

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 171742826...
Checkpoint 171742826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43259
Policy Entropy: 1.36151
Value Function Loss: 0.01210

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05818
Policy Update Magnitude: 0.12485
Value Function Update Magnitude: 0.12720

Collected Steps per Second: 9939.33339
Overall Steps per Second: 6742.51158

Timestep Collection Time: 5.03505
Timestep Consumption Time: 2.38726
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.42231

Cumulative Model Updates: 20556
Cumulative Timesteps: 171792871

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.01446
Policy Entropy: 1.35653
Value Function Loss: 0.01209

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05011
Policy Update Magnitude: 0.12427
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 10291.19194
Overall Steps per Second: 7205.96839

Timestep Collection Time: 4.86212
Timestep Consumption Time: 2.08171
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 6.94383

Cumulative Model Updates: 20562
Cumulative Timesteps: 171842908

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.87989
Policy Entropy: 1.35492
Value Function Loss: 0.01223

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.12858
Value Function Update Magnitude: 0.12256

Collected Steps per Second: 9861.80709
Overall Steps per Second: 7015.13466

Timestep Collection Time: 5.07108
Timestep Consumption Time: 2.05779
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.12887

Cumulative Model Updates: 20568
Cumulative Timesteps: 171892918

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.66529
Policy Entropy: 1.35522
Value Function Loss: 0.01187

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.05756
Policy Update Magnitude: 0.13570
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 10348.73667
Overall Steps per Second: 6957.50356

Timestep Collection Time: 4.83450
Timestep Consumption Time: 2.35644
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.19094

Cumulative Model Updates: 20574
Cumulative Timesteps: 171942949

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.71094
Policy Entropy: 1.35769
Value Function Loss: 0.01174

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05082
Policy Update Magnitude: 0.12740
Value Function Update Magnitude: 0.12195

Collected Steps per Second: 10193.08350
Overall Steps per Second: 7114.85193

Timestep Collection Time: 4.90637
Timestep Consumption Time: 2.12273
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.02910

Cumulative Model Updates: 20580
Cumulative Timesteps: 171992960

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -13.32111
Policy Entropy: 1.35253
Value Function Loss: 0.01196

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05169
Policy Update Magnitude: 0.11783
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 9752.25349
Overall Steps per Second: 7004.77778

Timestep Collection Time: 5.12774
Timestep Consumption Time: 2.01125
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.13898

Cumulative Model Updates: 20586
Cumulative Timesteps: 172042967

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.60244
Policy Entropy: 1.35232
Value Function Loss: 0.01250

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.04591
Policy Update Magnitude: 0.12087
Value Function Update Magnitude: 0.12331

Collected Steps per Second: 10631.84444
Overall Steps per Second: 7054.46697

Timestep Collection Time: 4.70379
Timestep Consumption Time: 2.38533
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 7.08913

Cumulative Model Updates: 20592
Cumulative Timesteps: 172092977

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.55785
Policy Entropy: 1.34883
Value Function Loss: 0.01204

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.12143
Value Function Update Magnitude: 0.12098

Collected Steps per Second: 10155.48591
Overall Steps per Second: 7116.78974

Timestep Collection Time: 4.92670
Timestep Consumption Time: 2.10358
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.03028

Cumulative Model Updates: 20598
Cumulative Timesteps: 172143010

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.36359
Policy Entropy: 1.34992
Value Function Loss: 0.01208

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05976
Policy Update Magnitude: 0.11658
Value Function Update Magnitude: 0.11936

Collected Steps per Second: 9940.27768
Overall Steps per Second: 7098.70395

Timestep Collection Time: 5.03074
Timestep Consumption Time: 2.01378
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.04453

Cumulative Model Updates: 20604
Cumulative Timesteps: 172193017

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.75190
Policy Entropy: 1.35018
Value Function Loss: 0.01221

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05213
Policy Update Magnitude: 0.11748
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 10011.19347
Overall Steps per Second: 7101.27133

Timestep Collection Time: 4.99441
Timestep Consumption Time: 2.04658
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.04099

Cumulative Model Updates: 20610
Cumulative Timesteps: 172243017

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 172243017...
Checkpoint 172243017 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.81601
Policy Entropy: 1.34876
Value Function Loss: 0.01248

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04948
Policy Update Magnitude: 0.11996
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 10606.46679
Overall Steps per Second: 7355.87313

Timestep Collection Time: 4.71759
Timestep Consumption Time: 2.08473
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 6.80232

Cumulative Model Updates: 20616
Cumulative Timesteps: 172293054

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.88492
Policy Entropy: 1.34687
Value Function Loss: 0.01253

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05731
Policy Update Magnitude: 0.11987
Value Function Update Magnitude: 0.12334

Collected Steps per Second: 9933.34836
Overall Steps per Second: 7034.01174

Timestep Collection Time: 5.03828
Timestep Consumption Time: 2.07672
PPO Batch Consumption Time: 0.02999
Total Iteration Time: 7.11500

Cumulative Model Updates: 20622
Cumulative Timesteps: 172343101

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.08813
Policy Entropy: 1.35009
Value Function Loss: 0.01216

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05162
Policy Update Magnitude: 0.11485
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 10424.96949
Overall Steps per Second: 7029.28268

Timestep Collection Time: 4.79925
Timestep Consumption Time: 2.31841
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.11765

Cumulative Model Updates: 20628
Cumulative Timesteps: 172393133

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.24279
Policy Entropy: 1.35182
Value Function Loss: 0.01300

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.04583
Policy Update Magnitude: 0.11530
Value Function Update Magnitude: 0.12479

Collected Steps per Second: 10366.50028
Overall Steps per Second: 7229.82799

Timestep Collection Time: 4.82429
Timestep Consumption Time: 2.09303
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 6.91732

Cumulative Model Updates: 20634
Cumulative Timesteps: 172443144

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.84516
Policy Entropy: 1.35426
Value Function Loss: 0.01348

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.04770
Policy Update Magnitude: 0.11724
Value Function Update Magnitude: 0.13073

Collected Steps per Second: 9751.52517
Overall Steps per Second: 6978.64485

Timestep Collection Time: 5.12863
Timestep Consumption Time: 2.03780
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.16643

Cumulative Model Updates: 20640
Cumulative Timesteps: 172493156

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.27139
Policy Entropy: 1.35315
Value Function Loss: 0.01341

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.11321
Value Function Update Magnitude: 0.13243

Collected Steps per Second: 10565.79380
Overall Steps per Second: 7074.85207

Timestep Collection Time: 4.73405
Timestep Consumption Time: 2.33592
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.06997

Cumulative Model Updates: 20646
Cumulative Timesteps: 172543175

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.30088
Policy Entropy: 1.35496
Value Function Loss: 0.01277

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.04424
Policy Update Magnitude: 0.11413
Value Function Update Magnitude: 0.12854

Collected Steps per Second: 10410.99250
Overall Steps per Second: 7234.61911

Timestep Collection Time: 4.80684
Timestep Consumption Time: 2.11045
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.91730

Cumulative Model Updates: 20652
Cumulative Timesteps: 172593219

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.19341
Policy Entropy: 1.35314
Value Function Loss: 0.01205

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.03696
Policy Update Magnitude: 0.11497
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 9806.73646
Overall Steps per Second: 6991.66922

Timestep Collection Time: 5.10241
Timestep Consumption Time: 2.05439
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.15680

Cumulative Model Updates: 20658
Cumulative Timesteps: 172643257

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.03725
Policy Entropy: 1.35266
Value Function Loss: 0.01297

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.03921
Policy Update Magnitude: 0.11885
Value Function Update Magnitude: 0.12712

Collected Steps per Second: 10260.80747
Overall Steps per Second: 7012.06126

Timestep Collection Time: 4.87467
Timestep Consumption Time: 2.25847
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 7.13314

Cumulative Model Updates: 20664
Cumulative Timesteps: 172693275

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.37551
Policy Entropy: 1.34797
Value Function Loss: 0.01305

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.04853
Policy Update Magnitude: 0.11644
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10313.03002
Overall Steps per Second: 6957.61440

Timestep Collection Time: 4.84998
Timestep Consumption Time: 2.33898
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.18896

Cumulative Model Updates: 20670
Cumulative Timesteps: 172743293

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 172743293...
Checkpoint 172743293 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.81859
Policy Entropy: 1.34674
Value Function Loss: 0.01345

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05727
Policy Update Magnitude: 0.11612
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 10650.38113
Overall Steps per Second: 7399.10559

Timestep Collection Time: 4.69871
Timestep Consumption Time: 2.06468
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.76339

Cumulative Model Updates: 20676
Cumulative Timesteps: 172793336

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.43810
Policy Entropy: 1.34666
Value Function Loss: 0.01238

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05665
Policy Update Magnitude: 0.11741
Value Function Update Magnitude: 0.13102

Collected Steps per Second: 9886.57789
Overall Steps per Second: 7074.67388

Timestep Collection Time: 5.05989
Timestep Consumption Time: 2.01111
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.07100

Cumulative Model Updates: 20682
Cumulative Timesteps: 172843361

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.60795
Policy Entropy: 1.34888
Value Function Loss: 0.01230

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.11528
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 10416.13457
Overall Steps per Second: 7263.74973

Timestep Collection Time: 4.80466
Timestep Consumption Time: 2.08517
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 6.88983

Cumulative Model Updates: 20688
Cumulative Timesteps: 172893407

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.57834
Policy Entropy: 1.35491
Value Function Loss: 0.01198

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05041
Policy Update Magnitude: 0.11326
Value Function Update Magnitude: 0.11863

Collected Steps per Second: 9834.66709
Overall Steps per Second: 7000.93633

Timestep Collection Time: 5.08751
Timestep Consumption Time: 2.05924
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.14676

Cumulative Model Updates: 20694
Cumulative Timesteps: 172943441

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.85800
Policy Entropy: 1.35233
Value Function Loss: 0.01292

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.10996
Value Function Update Magnitude: 0.12389

Collected Steps per Second: 10450.64716
Overall Steps per Second: 7055.03658

Timestep Collection Time: 4.78516
Timestep Consumption Time: 2.30311
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.08827

Cumulative Model Updates: 20700
Cumulative Timesteps: 172993449

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.08526
Policy Entropy: 1.35357
Value Function Loss: 0.01333

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.04535
Policy Update Magnitude: 0.11306
Value Function Update Magnitude: 0.12519

Collected Steps per Second: 10327.04539
Overall Steps per Second: 7143.36855

Timestep Collection Time: 4.84572
Timestep Consumption Time: 2.15966
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.00538

Cumulative Model Updates: 20706
Cumulative Timesteps: 173043491

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.30652
Policy Entropy: 1.35064
Value Function Loss: 0.01331

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.05242
Policy Update Magnitude: 0.11828
Value Function Update Magnitude: 0.12703

Collected Steps per Second: 9905.00447
Overall Steps per Second: 7072.07460

Timestep Collection Time: 5.05139
Timestep Consumption Time: 2.02348
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.07487

Cumulative Model Updates: 20712
Cumulative Timesteps: 173093525

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.16084
Policy Entropy: 1.35221
Value Function Loss: 0.01303

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.11846
Value Function Update Magnitude: 0.13034

Collected Steps per Second: 9880.95680
Overall Steps per Second: 7079.01647

Timestep Collection Time: 5.06287
Timestep Consumption Time: 2.00393
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.06680

Cumulative Model Updates: 20718
Cumulative Timesteps: 173143551

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.55254
Policy Entropy: 1.35124
Value Function Loss: 0.01288

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05628
Policy Update Magnitude: 0.11831
Value Function Update Magnitude: 0.12667

Collected Steps per Second: 10445.60742
Overall Steps per Second: 7280.16598

Timestep Collection Time: 4.79043
Timestep Consumption Time: 2.08290
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 6.87333

Cumulative Model Updates: 20724
Cumulative Timesteps: 173193590

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.77834
Policy Entropy: 1.35084
Value Function Loss: 0.01304

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.04811
Policy Update Magnitude: 0.12152
Value Function Update Magnitude: 0.12422

Collected Steps per Second: 9783.40028
Overall Steps per Second: 6984.23743

Timestep Collection Time: 5.11366
Timestep Consumption Time: 2.04947
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.16313

Cumulative Model Updates: 20730
Cumulative Timesteps: 173243619

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 173243619...
Checkpoint 173243619 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.20348
Policy Entropy: 1.34993
Value Function Loss: 0.01323

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.05258
Policy Update Magnitude: 0.12619
Value Function Update Magnitude: 0.12772

Collected Steps per Second: 10489.55837
Overall Steps per Second: 7055.88523

Timestep Collection Time: 4.76941
Timestep Consumption Time: 2.32098
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.09039

Cumulative Model Updates: 20736
Cumulative Timesteps: 173293648

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.22920
Policy Entropy: 1.35024
Value Function Loss: 0.01376

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06305
Policy Update Magnitude: 0.13937
Value Function Update Magnitude: 0.13497

Collected Steps per Second: 10252.92017
Overall Steps per Second: 7183.02445

Timestep Collection Time: 4.87802
Timestep Consumption Time: 2.08478
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.96281

Cumulative Model Updates: 20742
Cumulative Timesteps: 173343662

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.28798
Policy Entropy: 1.35098
Value Function Loss: 0.01387

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06278
Policy Update Magnitude: 0.13877
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 9817.37662
Overall Steps per Second: 7007.71882

Timestep Collection Time: 5.09617
Timestep Consumption Time: 2.04325
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 7.13941

Cumulative Model Updates: 20748
Cumulative Timesteps: 173393693

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.09672
Policy Entropy: 1.35526
Value Function Loss: 0.01309

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.04473
Policy Update Magnitude: 0.12762
Value Function Update Magnitude: 0.13717

Collected Steps per Second: 10402.99196
Overall Steps per Second: 7265.05938

Timestep Collection Time: 4.80948
Timestep Consumption Time: 2.07732
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 6.88680

Cumulative Model Updates: 20754
Cumulative Timesteps: 173443726

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.09273
Policy Entropy: 1.35254
Value Function Loss: 0.01259

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.04791
Policy Update Magnitude: 0.11529
Value Function Update Magnitude: 0.13682

Collected Steps per Second: 10179.49292
Overall Steps per Second: 7150.35068

Timestep Collection Time: 4.91351
Timestep Consumption Time: 2.08154
PPO Batch Consumption Time: 0.02454
Total Iteration Time: 6.99504

Cumulative Model Updates: 20760
Cumulative Timesteps: 173493743

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.38238
Policy Entropy: 1.34972
Value Function Loss: 0.01265

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.11258
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 9750.96195
Overall Steps per Second: 6971.19861

Timestep Collection Time: 5.12924
Timestep Consumption Time: 2.04528
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.17452

Cumulative Model Updates: 20766
Cumulative Timesteps: 173543758

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.56776
Policy Entropy: 1.34962
Value Function Loss: 0.01295

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.04750
Policy Update Magnitude: 0.11496
Value Function Update Magnitude: 0.13067

Collected Steps per Second: 10362.09452
Overall Steps per Second: 7137.56673

Timestep Collection Time: 4.82731
Timestep Consumption Time: 2.18082
PPO Batch Consumption Time: 0.02875
Total Iteration Time: 7.00813

Cumulative Model Updates: 20772
Cumulative Timesteps: 173593779

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.93570
Policy Entropy: 1.34993
Value Function Loss: 0.01260

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.11715
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 9893.86759
Overall Steps per Second: 6960.44401

Timestep Collection Time: 5.05525
Timestep Consumption Time: 2.13050
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.18575

Cumulative Model Updates: 20778
Cumulative Timesteps: 173643795

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.32822
Policy Entropy: 1.35058
Value Function Loss: 0.01253

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.04681
Policy Update Magnitude: 0.11794
Value Function Update Magnitude: 0.12639

Collected Steps per Second: 9617.76615
Overall Steps per Second: 6907.59689

Timestep Collection Time: 5.20277
Timestep Consumption Time: 2.04129
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.24405

Cumulative Model Updates: 20784
Cumulative Timesteps: 173693834

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.29053
Policy Entropy: 1.34893
Value Function Loss: 0.01285

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05746
Policy Update Magnitude: 0.11684
Value Function Update Magnitude: 0.12799

Collected Steps per Second: 10330.42762
Overall Steps per Second: 7202.71098

Timestep Collection Time: 4.84114
Timestep Consumption Time: 2.10222
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 6.94336

Cumulative Model Updates: 20790
Cumulative Timesteps: 173743845

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 173743845...
Checkpoint 173743845 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.41727
Policy Entropy: 1.35010
Value Function Loss: 0.01287

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.05375
Policy Update Magnitude: 0.11916
Value Function Update Magnitude: 0.12739

Collected Steps per Second: 9865.01341
Overall Steps per Second: 7084.48237

Timestep Collection Time: 5.07065
Timestep Consumption Time: 1.99014
PPO Batch Consumption Time: 0.02418
Total Iteration Time: 7.06078

Cumulative Model Updates: 20796
Cumulative Timesteps: 173793867

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.23149
Policy Entropy: 1.34952
Value Function Loss: 0.01234

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05105
Policy Update Magnitude: 0.12067
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 9752.72634
Overall Steps per Second: 6977.09386

Timestep Collection Time: 5.12831
Timestep Consumption Time: 2.04015
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 7.16846

Cumulative Model Updates: 20802
Cumulative Timesteps: 173843882

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.91286
Policy Entropy: 1.35083
Value Function Loss: 0.01197

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06093
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 10429.08899
Overall Steps per Second: 7232.97563

Timestep Collection Time: 4.79476
Timestep Consumption Time: 2.11871
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 6.91348

Cumulative Model Updates: 20808
Cumulative Timesteps: 173893887

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.56358
Policy Entropy: 1.35046
Value Function Loss: 0.01167

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05479
Policy Update Magnitude: 0.12871
Value Function Update Magnitude: 0.12611

Collected Steps per Second: 9904.41778
Overall Steps per Second: 7048.71067

Timestep Collection Time: 5.05290
Timestep Consumption Time: 2.04713
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.10002

Cumulative Model Updates: 20814
Cumulative Timesteps: 173943933

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.82480
Policy Entropy: 1.35318
Value Function Loss: 0.01194

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.04653
Policy Update Magnitude: 0.12646
Value Function Update Magnitude: 0.12407

Collected Steps per Second: 9739.18137
Overall Steps per Second: 6967.50316

Timestep Collection Time: 5.13791
Timestep Consumption Time: 2.04386
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 7.18177

Cumulative Model Updates: 20820
Cumulative Timesteps: 173993972

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16739
Policy Entropy: 1.35302
Value Function Loss: 0.01268

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05764
Policy Update Magnitude: 0.12302
Value Function Update Magnitude: 0.11875

Collected Steps per Second: 10362.82181
Overall Steps per Second: 7249.15877

Timestep Collection Time: 4.82784
Timestep Consumption Time: 2.07365
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 6.90149

Cumulative Model Updates: 20826
Cumulative Timesteps: 174044002

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.24396
Policy Entropy: 1.35204
Value Function Loss: 0.01320

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.05849
Policy Update Magnitude: 0.12195
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 10018.02153
Overall Steps per Second: 7142.19387

Timestep Collection Time: 4.99320
Timestep Consumption Time: 2.01053
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.00373

Cumulative Model Updates: 20832
Cumulative Timesteps: 174094024

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.80660
Policy Entropy: 1.35780
Value Function Loss: 0.01322

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.12071
Value Function Update Magnitude: 0.13010

Collected Steps per Second: 9823.24217
Overall Steps per Second: 6996.54533

Timestep Collection Time: 5.09312
Timestep Consumption Time: 2.05769
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 7.15081

Cumulative Model Updates: 20838
Cumulative Timesteps: 174144055

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.24348
Policy Entropy: 1.35045
Value Function Loss: 0.01260

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06618
Policy Update Magnitude: 0.12259
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 10427.00820
Overall Steps per Second: 7223.29736

Timestep Collection Time: 4.79725
Timestep Consumption Time: 2.12770
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 6.92495

Cumulative Model Updates: 20844
Cumulative Timesteps: 174194076

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.97113
Policy Entropy: 1.35363
Value Function Loss: 0.01253

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07604
Policy Update Magnitude: 0.12311
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 9918.73628
Overall Steps per Second: 7087.51453

Timestep Collection Time: 5.04157
Timestep Consumption Time: 2.01394
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.05551

Cumulative Model Updates: 20850
Cumulative Timesteps: 174244082

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 174244082...
Checkpoint 174244082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.81090
Policy Entropy: 1.34812
Value Function Loss: 0.01305

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.12227
Value Function Update Magnitude: 0.12612

Collected Steps per Second: 9988.10895
Overall Steps per Second: 7085.31593

Timestep Collection Time: 5.00856
Timestep Consumption Time: 2.05196
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 7.06052

Cumulative Model Updates: 20856
Cumulative Timesteps: 174294108

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.15012
Policy Entropy: 1.35105
Value Function Loss: 0.01378

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.05870
Policy Update Magnitude: 0.12092
Value Function Update Magnitude: 0.12614

Collected Steps per Second: 10678.75511
Overall Steps per Second: 7350.40169

Timestep Collection Time: 4.68444
Timestep Consumption Time: 2.12117
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 6.80561

Cumulative Model Updates: 20862
Cumulative Timesteps: 174344132

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.61933
Policy Entropy: 1.34570
Value Function Loss: 0.01391

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06537
Policy Update Magnitude: 0.12644
Value Function Update Magnitude: 0.13354

Collected Steps per Second: 9892.74139
Overall Steps per Second: 7018.73098

Timestep Collection Time: 5.05886
Timestep Consumption Time: 2.07149
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 7.13035

Cumulative Model Updates: 20868
Cumulative Timesteps: 174394178

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.83667
Policy Entropy: 1.34431
Value Function Loss: 0.01359

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06744
Policy Update Magnitude: 0.12319
Value Function Update Magnitude: 0.13960

Collected Steps per Second: 9567.34257
Overall Steps per Second: 6849.45714

Timestep Collection Time: 5.22799
Timestep Consumption Time: 2.07448
PPO Batch Consumption Time: 0.02881
Total Iteration Time: 7.30248

Cumulative Model Updates: 20874
Cumulative Timesteps: 174444196

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.72006
Policy Entropy: 1.34928
Value Function Loss: 0.01334

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.12096
Value Function Update Magnitude: 0.13754

Collected Steps per Second: 10309.24226
Overall Steps per Second: 7167.85131

Timestep Collection Time: 4.85089
Timestep Consumption Time: 2.12596
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 6.97685

Cumulative Model Updates: 20880
Cumulative Timesteps: 174494205

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.34218
Policy Entropy: 1.35049
Value Function Loss: 0.01324

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.11729
Value Function Update Magnitude: 0.13705

Collected Steps per Second: 9834.37476
Overall Steps per Second: 7039.89574

Timestep Collection Time: 5.08461
Timestep Consumption Time: 2.01833
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.10295

Cumulative Model Updates: 20886
Cumulative Timesteps: 174544209

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.40871
Policy Entropy: 1.34670
Value Function Loss: 0.01321

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.05694
Policy Update Magnitude: 0.11840
Value Function Update Magnitude: 0.13654

Collected Steps per Second: 9680.92386
Overall Steps per Second: 6934.99301

Timestep Collection Time: 5.16645
Timestep Consumption Time: 2.04567
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.21212

Cumulative Model Updates: 20892
Cumulative Timesteps: 174594225

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.12819
Policy Entropy: 1.34552
Value Function Loss: 0.01381

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.11922
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 10373.74267
Overall Steps per Second: 7214.80941

Timestep Collection Time: 4.82324
Timestep Consumption Time: 2.11181
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 6.93504

Cumulative Model Updates: 20898
Cumulative Timesteps: 174644260

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.50012
Policy Entropy: 1.34639
Value Function Loss: 0.01429

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05001
Policy Update Magnitude: 0.11913
Value Function Update Magnitude: 0.13891

Collected Steps per Second: 9840.32355
Overall Steps per Second: 6953.14456

Timestep Collection Time: 5.08286
Timestep Consumption Time: 2.11057
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.19344

Cumulative Model Updates: 20904
Cumulative Timesteps: 174694277

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.41880
Policy Entropy: 1.34688
Value Function Loss: 0.01406

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05037
Policy Update Magnitude: 0.12463
Value Function Update Magnitude: 0.13973

Collected Steps per Second: 9862.78928
Overall Steps per Second: 7031.84165

Timestep Collection Time: 5.07037
Timestep Consumption Time: 2.04128
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.11165

Cumulative Model Updates: 20910
Cumulative Timesteps: 174744285

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 174744285...
Checkpoint 174744285 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.92906
Policy Entropy: 1.34290
Value Function Loss: 0.01359

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05596
Policy Update Magnitude: 0.12359
Value Function Update Magnitude: 0.13819

Collected Steps per Second: 10715.72000
Overall Steps per Second: 7511.28520

Timestep Collection Time: 4.66670
Timestep Consumption Time: 1.99089
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 6.65758

Cumulative Model Updates: 20916
Cumulative Timesteps: 174794292

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.02798
Policy Entropy: 1.34209
Value Function Loss: 0.01290

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05745
Policy Update Magnitude: 0.12356
Value Function Update Magnitude: 0.13165

Collected Steps per Second: 9893.63759
Overall Steps per Second: 7078.27432

Timestep Collection Time: 5.05648
Timestep Consumption Time: 2.01120
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.06768

Cumulative Model Updates: 20922
Cumulative Timesteps: 174844319

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.75329
Policy Entropy: 1.34155
Value Function Loss: 0.01273

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05323
Policy Update Magnitude: 0.12265
Value Function Update Magnitude: 0.13784

Collected Steps per Second: 9721.09736
Overall Steps per Second: 6961.79918

Timestep Collection Time: 5.14469
Timestep Consumption Time: 2.03909
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.18378

Cumulative Model Updates: 20928
Cumulative Timesteps: 174894331

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.14309
Policy Entropy: 1.34098
Value Function Loss: 0.01307

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.05511
Policy Update Magnitude: 0.12428
Value Function Update Magnitude: 0.13668

Collected Steps per Second: 10425.76069
Overall Steps per Second: 7253.57671

Timestep Collection Time: 4.79658
Timestep Consumption Time: 2.09767
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 6.89425

Cumulative Model Updates: 20934
Cumulative Timesteps: 174944339

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.87550
Policy Entropy: 1.33943
Value Function Loss: 0.01260

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05649
Policy Update Magnitude: 0.12519
Value Function Update Magnitude: 0.13563

Collected Steps per Second: 9926.81779
Overall Steps per Second: 7049.16745

Timestep Collection Time: 5.03918
Timestep Consumption Time: 2.05712
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.09630

Cumulative Model Updates: 20940
Cumulative Timesteps: 174994362

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.01634
Policy Entropy: 1.35082
Value Function Loss: 0.01273

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07079
Policy Update Magnitude: 0.12021
Value Function Update Magnitude: 0.13891

Collected Steps per Second: 9833.88386
Overall Steps per Second: 6982.40964

Timestep Collection Time: 5.08670
Timestep Consumption Time: 2.07730
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 7.16400

Cumulative Model Updates: 20946
Cumulative Timesteps: 175044384

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.25162
Policy Entropy: 1.35201
Value Function Loss: 0.01259

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.11399
Value Function Update Magnitude: 0.13760

Collected Steps per Second: 10308.57466
Overall Steps per Second: 7114.72662

Timestep Collection Time: 4.85120
Timestep Consumption Time: 2.17774
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.02894

Cumulative Model Updates: 20952
Cumulative Timesteps: 175094393

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.84809
Policy Entropy: 1.35431
Value Function Loss: 0.01301

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.05441
Policy Update Magnitude: 0.11450
Value Function Update Magnitude: 0.14043

Collected Steps per Second: 9818.53247
Overall Steps per Second: 7008.25883

Timestep Collection Time: 5.09312
Timestep Consumption Time: 2.04231
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 7.13544

Cumulative Model Updates: 20958
Cumulative Timesteps: 175144400

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.60661
Policy Entropy: 1.35054
Value Function Loss: 0.01330

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.04563
Policy Update Magnitude: 0.11957
Value Function Update Magnitude: 0.13681

Collected Steps per Second: 9879.07548
Overall Steps per Second: 7032.33937

Timestep Collection Time: 5.06424
Timestep Consumption Time: 2.05004
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.11428

Cumulative Model Updates: 20964
Cumulative Timesteps: 175194430

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.20413
Policy Entropy: 1.35187
Value Function Loss: 0.01306

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.04936
Policy Update Magnitude: 0.11918
Value Function Update Magnitude: 0.13265

Collected Steps per Second: 10353.74180
Overall Steps per Second: 7177.19772

Timestep Collection Time: 4.83207
Timestep Consumption Time: 2.13862
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 6.97069

Cumulative Model Updates: 20970
Cumulative Timesteps: 175244460

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 175244460...
Checkpoint 175244460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50849
Policy Entropy: 1.34758
Value Function Loss: 0.01403

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.04882
Policy Update Magnitude: 0.11879
Value Function Update Magnitude: 0.13527

Collected Steps per Second: 9755.27235
Overall Steps per Second: 6898.57987

Timestep Collection Time: 5.12861
Timestep Consumption Time: 2.12375
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.25236

Cumulative Model Updates: 20976
Cumulative Timesteps: 175294491

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.61999
Policy Entropy: 1.34534
Value Function Loss: 0.01418

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04312
Policy Update Magnitude: 0.12043
Value Function Update Magnitude: 0.13415

Collected Steps per Second: 9631.50472
Overall Steps per Second: 2894.04756

Timestep Collection Time: 5.19607
Timestep Consumption Time: 12.09666
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 17.29274

Cumulative Model Updates: 20982
Cumulative Timesteps: 175344537

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.44353
Policy Entropy: 1.34210
Value Function Loss: 0.01426

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.12082
Value Function Update Magnitude: 0.13670

Collected Steps per Second: 10332.66456
Overall Steps per Second: 7219.27072

Timestep Collection Time: 4.84154
Timestep Consumption Time: 2.08797
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 6.92951

Cumulative Model Updates: 20988
Cumulative Timesteps: 175394563

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.91267
Policy Entropy: 1.34487
Value Function Loss: 0.01345

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.11923
Value Function Update Magnitude: 0.14288

Collected Steps per Second: 9880.22270
Overall Steps per Second: 7017.60938

Timestep Collection Time: 5.06193
Timestep Consumption Time: 2.06486
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.12679

Cumulative Model Updates: 20994
Cumulative Timesteps: 175444576

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.98957
Policy Entropy: 1.35218
Value Function Loss: 0.01336

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05839
Policy Update Magnitude: 0.12049
Value Function Update Magnitude: 0.13853

Collected Steps per Second: 9734.50901
Overall Steps per Second: 6933.41736

Timestep Collection Time: 5.13739
Timestep Consumption Time: 2.07550
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.21289

Cumulative Model Updates: 21000
Cumulative Timesteps: 175494586

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.53746
Policy Entropy: 1.35074
Value Function Loss: 0.01295

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06305
Policy Update Magnitude: 0.11921
Value Function Update Magnitude: 0.13819

Collected Steps per Second: 10389.98436
Overall Steps per Second: 7212.92643

Timestep Collection Time: 4.81531
Timestep Consumption Time: 2.12099
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 6.93630

Cumulative Model Updates: 21006
Cumulative Timesteps: 175544617

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.35742
Policy Entropy: 1.35127
Value Function Loss: 0.01300

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.05195
Policy Update Magnitude: 0.11911
Value Function Update Magnitude: 0.13399

Collected Steps per Second: 9798.02281
Overall Steps per Second: 6989.99525

Timestep Collection Time: 5.10521
Timestep Consumption Time: 2.05087
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.15608

Cumulative Model Updates: 21012
Cumulative Timesteps: 175594638

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.07526
Policy Entropy: 1.34701
Value Function Loss: 0.01303

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.05628
Policy Update Magnitude: 0.11399
Value Function Update Magnitude: 0.13328

Collected Steps per Second: 9835.75222
Overall Steps per Second: 7064.25684

Timestep Collection Time: 5.08675
Timestep Consumption Time: 1.99567
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.08242

Cumulative Model Updates: 21018
Cumulative Timesteps: 175644670

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.09893
Policy Entropy: 1.34881
Value Function Loss: 0.01381

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.04719
Policy Update Magnitude: 0.11976
Value Function Update Magnitude: 0.13543

Collected Steps per Second: 10441.13221
Overall Steps per Second: 7233.38338

Timestep Collection Time: 4.79249
Timestep Consumption Time: 2.12530
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.91779

Cumulative Model Updates: 21024
Cumulative Timesteps: 175694709

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.90146
Policy Entropy: 1.34733
Value Function Loss: 0.01347

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.04665
Policy Update Magnitude: 0.12116
Value Function Update Magnitude: 0.13501

Collected Steps per Second: 9351.36357
Overall Steps per Second: 6788.99277

Timestep Collection Time: 5.35013
Timestep Consumption Time: 2.01930
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.36943

Cumulative Model Updates: 21030
Cumulative Timesteps: 175744740

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 175744740...
Checkpoint 175744740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.83584
Policy Entropy: 1.34439
Value Function Loss: 0.01278

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.04413
Policy Update Magnitude: 0.12154
Value Function Update Magnitude: 0.13187

Collected Steps per Second: 9561.22476
Overall Steps per Second: 6852.44824

Timestep Collection Time: 5.23280
Timestep Consumption Time: 2.06853
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.30133

Cumulative Model Updates: 21036
Cumulative Timesteps: 175794772

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87803
Policy Entropy: 1.35081
Value Function Loss: 0.01197

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04210
Policy Update Magnitude: 0.11636
Value Function Update Magnitude: 0.13226

Collected Steps per Second: 10142.57890
Overall Steps per Second: 7069.31583

Timestep Collection Time: 4.93178
Timestep Consumption Time: 2.14401
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.07579

Cumulative Model Updates: 21042
Cumulative Timesteps: 175844793

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.74494
Policy Entropy: 1.34549
Value Function Loss: 0.01214

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06497
Policy Update Magnitude: 0.11399
Value Function Update Magnitude: 0.13075

Collected Steps per Second: 9282.41671
Overall Steps per Second: 6681.23081

Timestep Collection Time: 5.38804
Timestep Consumption Time: 2.09771
PPO Batch Consumption Time: 0.02983
Total Iteration Time: 7.48575

Cumulative Model Updates: 21048
Cumulative Timesteps: 175894807

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.01714
Policy Entropy: 1.35023
Value Function Loss: 0.01276

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.05060
Policy Update Magnitude: 0.11316
Value Function Update Magnitude: 0.13595

Collected Steps per Second: 9364.79142
Overall Steps per Second: 6695.51883

Timestep Collection Time: 5.34342
Timestep Consumption Time: 2.13024
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.47366

Cumulative Model Updates: 21054
Cumulative Timesteps: 175944847

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.36173
Policy Entropy: 1.34174
Value Function Loss: 0.01328

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.11461
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 9695.25646
Overall Steps per Second: 6765.81552

Timestep Collection Time: 5.15953
Timestep Consumption Time: 2.23396
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 7.39349

Cumulative Model Updates: 21060
Cumulative Timesteps: 175994870

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.20578
Policy Entropy: 1.34655
Value Function Loss: 0.01379

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06158
Policy Update Magnitude: 0.11363
Value Function Update Magnitude: 0.13645

Collected Steps per Second: 9300.97640
Overall Steps per Second: 6727.82227

Timestep Collection Time: 5.37825
Timestep Consumption Time: 2.05699
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.43524

Cumulative Model Updates: 21066
Cumulative Timesteps: 176044893

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.48060
Policy Entropy: 1.34103
Value Function Loss: 0.01388

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.11251
Value Function Update Magnitude: 0.14325

Collected Steps per Second: 9142.07494
Overall Steps per Second: 6581.04541

Timestep Collection Time: 5.47195
Timestep Consumption Time: 2.12942
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.60138

Cumulative Model Updates: 21072
Cumulative Timesteps: 176094918

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.14698
Policy Entropy: 1.34868
Value Function Loss: 0.01355

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06706
Policy Update Magnitude: 0.11176
Value Function Update Magnitude: 0.14450

Collected Steps per Second: 9974.92833
Overall Steps per Second: 6901.90039

Timestep Collection Time: 5.01578
Timestep Consumption Time: 2.23324
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.24902

Cumulative Model Updates: 21078
Cumulative Timesteps: 176144950

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.90224
Policy Entropy: 1.34729
Value Function Loss: 0.01354

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05712
Policy Update Magnitude: 0.11513
Value Function Update Magnitude: 0.14668

Collected Steps per Second: 9592.90832
Overall Steps per Second: 6757.86058

Timestep Collection Time: 5.21364
Timestep Consumption Time: 2.18722
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.40086

Cumulative Model Updates: 21084
Cumulative Timesteps: 176194964

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.47878
Policy Entropy: 1.34882
Value Function Loss: 0.01364

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05113
Policy Update Magnitude: 0.11741
Value Function Update Magnitude: 0.14953

Collected Steps per Second: 9367.60004
Overall Steps per Second: 6814.52583

Timestep Collection Time: 5.34128
Timestep Consumption Time: 2.00112
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.34240

Cumulative Model Updates: 21090
Cumulative Timesteps: 176244999

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 176244999...
Checkpoint 176244999 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -14.22366
Policy Entropy: 1.34801
Value Function Loss: 0.01318

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.04789
Policy Update Magnitude: 0.11703
Value Function Update Magnitude: 0.14752

Collected Steps per Second: 9721.18471
Overall Steps per Second: 6953.16972

Timestep Collection Time: 5.14732
Timestep Consumption Time: 2.04912
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.19643

Cumulative Model Updates: 21096
Cumulative Timesteps: 176295037

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.15933
Policy Entropy: 1.34626
Value Function Loss: 0.01294

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.11495
Value Function Update Magnitude: 0.14113

Collected Steps per Second: 9771.98267
Overall Steps per Second: 7006.07891

Timestep Collection Time: 5.11810
Timestep Consumption Time: 2.02056
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.13866

Cumulative Model Updates: 21102
Cumulative Timesteps: 176345051

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.23220
Policy Entropy: 1.34765
Value Function Loss: 0.01331

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.05104
Policy Update Magnitude: 0.11554
Value Function Update Magnitude: 0.13826

Collected Steps per Second: 10026.91392
Overall Steps per Second: 7174.60656

Timestep Collection Time: 4.98987
Timestep Consumption Time: 1.98375
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.97362

Cumulative Model Updates: 21108
Cumulative Timesteps: 176395084

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.50379
Policy Entropy: 1.34586
Value Function Loss: 0.01389

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.05442
Policy Update Magnitude: 0.11326
Value Function Update Magnitude: 0.14086

Collected Steps per Second: 10071.05329
Overall Steps per Second: 7195.60345

Timestep Collection Time: 4.96582
Timestep Consumption Time: 1.98440
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 6.95022

Cumulative Model Updates: 21114
Cumulative Timesteps: 176445095

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.42189
Policy Entropy: 1.34376
Value Function Loss: 0.01438

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.04716
Policy Update Magnitude: 0.11757
Value Function Update Magnitude: 0.14364

Collected Steps per Second: 10111.64214
Overall Steps per Second: 7205.92104

Timestep Collection Time: 4.94578
Timestep Consumption Time: 1.99434
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.94013

Cumulative Model Updates: 21120
Cumulative Timesteps: 176495105

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.47990
Policy Entropy: 1.34357
Value Function Loss: 0.01401

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04203
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.14039

Collected Steps per Second: 9980.54790
Overall Steps per Second: 7206.57250

Timestep Collection Time: 5.01285
Timestep Consumption Time: 1.92956
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 6.94241

Cumulative Model Updates: 21126
Cumulative Timesteps: 176545136

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.51936
Policy Entropy: 1.34113
Value Function Loss: 0.01368

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05150
Policy Update Magnitude: 0.12109
Value Function Update Magnitude: 0.14076

Collected Steps per Second: 10675.15834
Overall Steps per Second: 7371.92438

Timestep Collection Time: 4.68639
Timestep Consumption Time: 2.09989
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.78629

Cumulative Model Updates: 21132
Cumulative Timesteps: 176595164

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.14435
Policy Entropy: 1.34277
Value Function Loss: 0.01285

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05046
Policy Update Magnitude: 0.11739
Value Function Update Magnitude: 0.13764

Collected Steps per Second: 10063.39110
Overall Steps per Second: 7078.50067

Timestep Collection Time: 4.97317
Timestep Consumption Time: 2.09711
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.07028

Cumulative Model Updates: 21138
Cumulative Timesteps: 176645211

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81401
Policy Entropy: 1.34347
Value Function Loss: 0.01350

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05324
Policy Update Magnitude: 0.11878
Value Function Update Magnitude: 0.13502

Collected Steps per Second: 9111.69648
Overall Steps per Second: 6510.03472

Timestep Collection Time: 5.49118
Timestep Consumption Time: 2.19449
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 7.68567

Cumulative Model Updates: 21144
Cumulative Timesteps: 176695245

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.40109
Policy Entropy: 1.35072
Value Function Loss: 0.01321

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05426
Policy Update Magnitude: 0.11969
Value Function Update Magnitude: 0.13756

Collected Steps per Second: 9786.54388
Overall Steps per Second: 6900.77712

Timestep Collection Time: 5.10906
Timestep Consumption Time: 2.13650
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 7.24556

Cumulative Model Updates: 21150
Cumulative Timesteps: 176745245

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 176745245...
Checkpoint 176745245 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.94598
Policy Entropy: 1.34747
Value Function Loss: 0.01354

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05630
Policy Update Magnitude: 0.12033
Value Function Update Magnitude: 0.14819

Collected Steps per Second: 9673.13142
Overall Steps per Second: 6899.97196

Timestep Collection Time: 5.17175
Timestep Consumption Time: 2.07857
PPO Batch Consumption Time: 0.02986
Total Iteration Time: 7.25032

Cumulative Model Updates: 21156
Cumulative Timesteps: 176795272

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.75946
Policy Entropy: 1.34698
Value Function Loss: 0.01222

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.05896
Policy Update Magnitude: 0.11606
Value Function Update Magnitude: 0.15158

Collected Steps per Second: 8714.67738
Overall Steps per Second: 6251.45432

Timestep Collection Time: 5.74261
Timestep Consumption Time: 2.26273
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 8.00534

Cumulative Model Updates: 21162
Cumulative Timesteps: 176845317

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.07528
Policy Entropy: 1.34188
Value Function Loss: 0.01204

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06264
Policy Update Magnitude: 0.11337
Value Function Update Magnitude: 0.14317

Collected Steps per Second: 9674.46440
Overall Steps per Second: 6884.63132

Timestep Collection Time: 5.17073
Timestep Consumption Time: 2.09531
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.26604

Cumulative Model Updates: 21168
Cumulative Timesteps: 176895341

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.93907
Policy Entropy: 1.33992
Value Function Loss: 0.01235

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05501
Policy Update Magnitude: 0.11718
Value Function Update Magnitude: 0.13556

Collected Steps per Second: 9625.29800
Overall Steps per Second: 6991.55104

Timestep Collection Time: 5.19890
Timestep Consumption Time: 1.95845
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 7.15735

Cumulative Model Updates: 21174
Cumulative Timesteps: 176945382

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.16531
Policy Entropy: 1.34021
Value Function Loss: 0.01239

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.04857
Policy Update Magnitude: 0.11791
Value Function Update Magnitude: 0.13361

Collected Steps per Second: 8915.08283
Overall Steps per Second: 6311.25395

Timestep Collection Time: 5.61206
Timestep Consumption Time: 2.31536
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 7.92743

Cumulative Model Updates: 21180
Cumulative Timesteps: 176995414

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.50922
Policy Entropy: 1.33805
Value Function Loss: 0.01302

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.12259
Value Function Update Magnitude: 0.13195

Collected Steps per Second: 9601.42955
Overall Steps per Second: 6867.83493

Timestep Collection Time: 5.21047
Timestep Consumption Time: 2.07392
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.28439

Cumulative Model Updates: 21186
Cumulative Timesteps: 177045442

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.37299
Policy Entropy: 1.34664
Value Function Loss: 0.01240

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.11180
Value Function Update Magnitude: 0.13126

Collected Steps per Second: 9238.73232
Overall Steps per Second: 6641.48706

Timestep Collection Time: 5.41460
Timestep Consumption Time: 2.11745
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 7.53205

Cumulative Model Updates: 21192
Cumulative Timesteps: 177095466

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -10.08798
Policy Entropy: 1.34307
Value Function Loss: 0.01220

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.11063
Value Function Update Magnitude: 0.12935

Collected Steps per Second: 8856.43998
Overall Steps per Second: 6332.41205

Timestep Collection Time: 5.64798
Timestep Consumption Time: 2.25122
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 7.89920

Cumulative Model Updates: 21198
Cumulative Timesteps: 177145487

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.89563
Policy Entropy: 1.34903
Value Function Loss: 0.01181

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.05370
Policy Update Magnitude: 0.11047
Value Function Update Magnitude: 0.12960

Collected Steps per Second: 10374.68312
Overall Steps per Second: 7215.60472

Timestep Collection Time: 4.82126
Timestep Consumption Time: 2.11080
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.93206

Cumulative Model Updates: 21204
Cumulative Timesteps: 177195506

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.53935
Policy Entropy: 1.35002
Value Function Loss: 0.01223

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.05223
Policy Update Magnitude: 0.10734
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 9735.95196
Overall Steps per Second: 7127.55751

Timestep Collection Time: 5.13694
Timestep Consumption Time: 1.87991
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.01685

Cumulative Model Updates: 21210
Cumulative Timesteps: 177245519

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 177245519...
Checkpoint 177245519 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.03107
Policy Entropy: 1.34682
Value Function Loss: 0.01370

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.10931
Value Function Update Magnitude: 0.13323

Collected Steps per Second: 9362.65446
Overall Steps per Second: 6853.69971

Timestep Collection Time: 5.34133
Timestep Consumption Time: 1.95532
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.29664

Cumulative Model Updates: 21216
Cumulative Timesteps: 177295528

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.57408
Policy Entropy: 1.34774
Value Function Loss: 0.01360

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.05775
Policy Update Magnitude: 0.11128
Value Function Update Magnitude: 0.13613

Collected Steps per Second: 10012.86514
Overall Steps per Second: 7080.48938

Timestep Collection Time: 4.99378
Timestep Consumption Time: 2.06817
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.06194

Cumulative Model Updates: 21222
Cumulative Timesteps: 177345530

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.92300
Policy Entropy: 1.34970
Value Function Loss: 0.01317

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.04831
Policy Update Magnitude: 0.11623
Value Function Update Magnitude: 0.13918

Collected Steps per Second: 9952.05547
Overall Steps per Second: 7102.07284

Timestep Collection Time: 5.02670
Timestep Consumption Time: 2.01716
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.04386

Cumulative Model Updates: 21228
Cumulative Timesteps: 177395556

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.65324
Policy Entropy: 1.35105
Value Function Loss: 0.01252

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.05975
Policy Update Magnitude: 0.11295
Value Function Update Magnitude: 0.14035

Collected Steps per Second: 9145.02660
Overall Steps per Second: 6609.32844

Timestep Collection Time: 5.47030
Timestep Consumption Time: 2.09870
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.56900

Cumulative Model Updates: 21234
Cumulative Timesteps: 177445582

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.72576
Policy Entropy: 1.35119
Value Function Loss: 0.01246

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05116
Policy Update Magnitude: 0.10974
Value Function Update Magnitude: 0.14285

Collected Steps per Second: 10150.68426
Overall Steps per Second: 7106.90700

Timestep Collection Time: 4.92991
Timestep Consumption Time: 2.11141
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.04132

Cumulative Model Updates: 21240
Cumulative Timesteps: 177495624

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.44480
Policy Entropy: 1.34912
Value Function Loss: 0.01244

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04801
Policy Update Magnitude: 0.10982
Value Function Update Magnitude: 0.14244

Collected Steps per Second: 9609.55328
Overall Steps per Second: 6759.54028

Timestep Collection Time: 5.20399
Timestep Consumption Time: 2.19415
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 7.39814

Cumulative Model Updates: 21246
Cumulative Timesteps: 177545632

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.75558
Policy Entropy: 1.34480
Value Function Loss: 0.01325

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04365
Policy Update Magnitude: 0.11101
Value Function Update Magnitude: 0.14773

Collected Steps per Second: 8728.00375
Overall Steps per Second: 6180.89014

Timestep Collection Time: 5.73281
Timestep Consumption Time: 2.36246
PPO Batch Consumption Time: 0.03200
Total Iteration Time: 8.09527

Cumulative Model Updates: 21252
Cumulative Timesteps: 177595668

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42393
Policy Entropy: 1.34816
Value Function Loss: 0.01382

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04383
Policy Update Magnitude: 0.11492
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 9934.05447
Overall Steps per Second: 6905.56222

Timestep Collection Time: 5.03722
Timestep Consumption Time: 2.20911
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.24633

Cumulative Model Updates: 21258
Cumulative Timesteps: 177645708

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.43023
Policy Entropy: 1.34720
Value Function Loss: 0.01376

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.04459
Policy Update Magnitude: 0.11789
Value Function Update Magnitude: 0.14487

Collected Steps per Second: 9627.76368
Overall Steps per Second: 6877.41769

Timestep Collection Time: 5.19664
Timestep Consumption Time: 2.07819
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.27482

Cumulative Model Updates: 21264
Cumulative Timesteps: 177695740

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.77008
Policy Entropy: 1.35060
Value Function Loss: 0.01312

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.03790
Policy Update Magnitude: 0.11756
Value Function Update Magnitude: 0.14727

Collected Steps per Second: 9154.77195
Overall Steps per Second: 6361.08982

Timestep Collection Time: 5.46425
Timestep Consumption Time: 2.39981
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.86406

Cumulative Model Updates: 21270
Cumulative Timesteps: 177745764

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 177745764...
Checkpoint 177745764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.97425
Policy Entropy: 1.34817
Value Function Loss: 0.01317

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.04426
Policy Update Magnitude: 0.11828
Value Function Update Magnitude: 0.14480

Collected Steps per Second: 10233.40003
Overall Steps per Second: 7078.49373

Timestep Collection Time: 4.88684
Timestep Consumption Time: 2.17808
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.06492

Cumulative Model Updates: 21276
Cumulative Timesteps: 177795773

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.36036
Policy Entropy: 1.35070
Value Function Loss: 0.01245

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.04743
Policy Update Magnitude: 0.11994
Value Function Update Magnitude: 0.14354

Collected Steps per Second: 9071.66306
Overall Steps per Second: 6406.73559

Timestep Collection Time: 5.51509
Timestep Consumption Time: 2.29404
PPO Batch Consumption Time: 0.02974
Total Iteration Time: 7.80913

Cumulative Model Updates: 21282
Cumulative Timesteps: 177845804

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.10644
Policy Entropy: 1.35080
Value Function Loss: 0.01244

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.04574
Policy Update Magnitude: 0.11782
Value Function Update Magnitude: 0.14378

Collected Steps per Second: 8845.07054
Overall Steps per Second: 6431.80689

Timestep Collection Time: 5.65581
Timestep Consumption Time: 2.12210
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.77791

Cumulative Model Updates: 21288
Cumulative Timesteps: 177895830

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.76177
Policy Entropy: 1.35283
Value Function Loss: 0.01196

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.04837
Policy Update Magnitude: 0.11718
Value Function Update Magnitude: 0.14024

Collected Steps per Second: 10029.25665
Overall Steps per Second: 7190.60343

Timestep Collection Time: 4.98841
Timestep Consumption Time: 1.96929
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.95769

Cumulative Model Updates: 21294
Cumulative Timesteps: 177945860

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.48393
Policy Entropy: 1.34838
Value Function Loss: 0.01261

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05613
Policy Update Magnitude: 0.11731
Value Function Update Magnitude: 0.14281

Collected Steps per Second: 9840.93250
Overall Steps per Second: 6857.49276

Timestep Collection Time: 5.08458
Timestep Consumption Time: 2.21211
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.29669

Cumulative Model Updates: 21300
Cumulative Timesteps: 177995897

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.49133
Policy Entropy: 1.34889
Value Function Loss: 0.01249

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05179
Policy Update Magnitude: 0.11530
Value Function Update Magnitude: 0.14725

Collected Steps per Second: 9071.03236
Overall Steps per Second: 6544.69184

Timestep Collection Time: 5.51404
Timestep Consumption Time: 2.12849
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 7.64253

Cumulative Model Updates: 21306
Cumulative Timesteps: 178045915

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.61502
Policy Entropy: 1.34758
Value Function Loss: 0.01263

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04291
Policy Update Magnitude: 0.11712
Value Function Update Magnitude: 0.14036

Collected Steps per Second: 10110.05836
Overall Steps per Second: 7046.42942

Timestep Collection Time: 4.94794
Timestep Consumption Time: 2.15125
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.09920

Cumulative Model Updates: 21312
Cumulative Timesteps: 178095939

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.98050
Policy Entropy: 1.34995
Value Function Loss: 0.01262

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.05079
Policy Update Magnitude: 0.11539
Value Function Update Magnitude: 0.13950

Collected Steps per Second: 9910.32687
Overall Steps per Second: 7188.20132

Timestep Collection Time: 5.04817
Timestep Consumption Time: 1.91171
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 6.95988

Cumulative Model Updates: 21318
Cumulative Timesteps: 178145968

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.12156
Policy Entropy: 1.35181
Value Function Loss: 0.01196

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.11270
Value Function Update Magnitude: 0.13716

Collected Steps per Second: 9930.74367
Overall Steps per Second: 7160.09592

Timestep Collection Time: 5.03900
Timestep Consumption Time: 1.94987
PPO Batch Consumption Time: 0.02431
Total Iteration Time: 6.98887

Cumulative Model Updates: 21324
Cumulative Timesteps: 178196009

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.07309
Policy Entropy: 1.35026
Value Function Loss: 0.01199

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04638
Policy Update Magnitude: 0.11557
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 10420.82671
Overall Steps per Second: 7407.95624

Timestep Collection Time: 4.80115
Timestep Consumption Time: 1.95266
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 6.75382

Cumulative Model Updates: 21330
Cumulative Timesteps: 178246041

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 178246041...
Checkpoint 178246041 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.24764
Policy Entropy: 1.34884
Value Function Loss: 0.01258

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05435
Policy Update Magnitude: 0.11785
Value Function Update Magnitude: 0.13499

Collected Steps per Second: 9804.15880
Overall Steps per Second: 7159.30725

Timestep Collection Time: 5.10355
Timestep Consumption Time: 1.88540
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.98894

Cumulative Model Updates: 21336
Cumulative Timesteps: 178296077

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.25660
Policy Entropy: 1.34656
Value Function Loss: 0.01315

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.05227
Policy Update Magnitude: 0.11909
Value Function Update Magnitude: 0.14066

Collected Steps per Second: 9874.73389
Overall Steps per Second: 7113.79854

Timestep Collection Time: 5.06363
Timestep Consumption Time: 1.96524
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 7.02887

Cumulative Model Updates: 21342
Cumulative Timesteps: 178346079

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -7.84724
Policy Entropy: 1.34860
Value Function Loss: 0.01371

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.04614
Policy Update Magnitude: 0.11900
Value Function Update Magnitude: 0.14310

Collected Steps per Second: 10545.95129
Overall Steps per Second: 7434.46623

Timestep Collection Time: 4.74429
Timestep Consumption Time: 1.98559
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 6.72987

Cumulative Model Updates: 21348
Cumulative Timesteps: 178396112

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.96914
Policy Entropy: 1.35270
Value Function Loss: 0.01341

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03692
Policy Update Magnitude: 0.11883
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 9950.42721
Overall Steps per Second: 6930.59058

Timestep Collection Time: 5.02813
Timestep Consumption Time: 2.19088
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 7.21901

Cumulative Model Updates: 21354
Cumulative Timesteps: 178446144

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.91984
Policy Entropy: 1.35224
Value Function Loss: 0.01424

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03741
Policy Update Magnitude: 0.11551
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 10273.26714
Overall Steps per Second: 7233.42162

Timestep Collection Time: 4.87002
Timestep Consumption Time: 2.04663
PPO Batch Consumption Time: 0.02459
Total Iteration Time: 6.91664

Cumulative Model Updates: 21360
Cumulative Timesteps: 178496175

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -11.97551
Policy Entropy: 1.35212
Value Function Loss: 0.01362

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03438
Policy Update Magnitude: 0.11686
Value Function Update Magnitude: 0.13866

Collected Steps per Second: 10804.77573
Overall Steps per Second: 7438.41812

Timestep Collection Time: 4.63054
Timestep Consumption Time: 2.09562
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.72616

Cumulative Model Updates: 21366
Cumulative Timesteps: 178546207

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.81514
Policy Entropy: 1.34865
Value Function Loss: 0.01388

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04045
Policy Update Magnitude: 0.12001
Value Function Update Magnitude: 0.13859

Collected Steps per Second: 9994.36685
Overall Steps per Second: 6868.69653

Timestep Collection Time: 5.00712
Timestep Consumption Time: 2.27854
PPO Batch Consumption Time: 0.02851
Total Iteration Time: 7.28566

Cumulative Model Updates: 21372
Cumulative Timesteps: 178596250

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.65811
Policy Entropy: 1.34721
Value Function Loss: 0.01297

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.04803
Policy Update Magnitude: 0.12003
Value Function Update Magnitude: 0.13750

Collected Steps per Second: 8887.95696
Overall Steps per Second: 6399.37693

Timestep Collection Time: 5.62626
Timestep Consumption Time: 2.18793
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.81420

Cumulative Model Updates: 21378
Cumulative Timesteps: 178646256

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.41771
Policy Entropy: 1.34820
Value Function Loss: 0.01276

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.04887
Policy Update Magnitude: 0.11630
Value Function Update Magnitude: 0.13181

Collected Steps per Second: 10909.13266
Overall Steps per Second: 7468.18152

Timestep Collection Time: 4.58607
Timestep Consumption Time: 2.11302
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.69909

Cumulative Model Updates: 21384
Cumulative Timesteps: 178696286

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.84352
Policy Entropy: 1.34775
Value Function Loss: 0.01309

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.04642
Policy Update Magnitude: 0.11913
Value Function Update Magnitude: 0.12874

Collected Steps per Second: 10277.39403
Overall Steps per Second: 7035.15483

Timestep Collection Time: 4.86835
Timestep Consumption Time: 2.24364
PPO Batch Consumption Time: 0.03129
Total Iteration Time: 7.11200

Cumulative Model Updates: 21390
Cumulative Timesteps: 178746320

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 178746320...
Checkpoint 178746320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.37577
Policy Entropy: 1.35357
Value Function Loss: 0.01329

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.04760
Policy Update Magnitude: 0.11784
Value Function Update Magnitude: 0.13455

Collected Steps per Second: 8854.75019
Overall Steps per Second: 6433.15097

Timestep Collection Time: 5.64736
Timestep Consumption Time: 2.12581
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.77317

Cumulative Model Updates: 21396
Cumulative Timesteps: 178796326

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.97664
Policy Entropy: 1.35459
Value Function Loss: 0.01305

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.04813
Policy Update Magnitude: 0.11667
Value Function Update Magnitude: 0.14274

Collected Steps per Second: 10487.96632
Overall Steps per Second: 7169.13302

Timestep Collection Time: 4.77118
Timestep Consumption Time: 2.20874
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 6.97992

Cumulative Model Updates: 21402
Cumulative Timesteps: 178846366

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.00178
Policy Entropy: 1.35046
Value Function Loss: 0.01244

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.11365
Value Function Update Magnitude: 0.13940

Collected Steps per Second: 9597.02301
Overall Steps per Second: 6823.78140

Timestep Collection Time: 5.21287
Timestep Consumption Time: 2.11855
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.33142

Cumulative Model Updates: 21408
Cumulative Timesteps: 178896394

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.90226
Policy Entropy: 1.34969
Value Function Loss: 0.01225

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.11505
Value Function Update Magnitude: 0.13762

Collected Steps per Second: 8740.57765
Overall Steps per Second: 6340.69536

Timestep Collection Time: 5.72170
Timestep Consumption Time: 2.16560
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.88731

Cumulative Model Updates: 21414
Cumulative Timesteps: 178946405

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.66589
Policy Entropy: 1.34720
Value Function Loss: 0.01232

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.11421
Value Function Update Magnitude: 0.13557

Collected Steps per Second: 9946.93014
Overall Steps per Second: 6956.70944

Timestep Collection Time: 5.03100
Timestep Consumption Time: 2.16249
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 7.19349

Cumulative Model Updates: 21420
Cumulative Timesteps: 178996448

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.87510
Policy Entropy: 1.34997
Value Function Loss: 0.01216

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.05303
Policy Update Magnitude: 0.11055
Value Function Update Magnitude: 0.13364

Collected Steps per Second: 9839.62480
Overall Steps per Second: 7011.01066

Timestep Collection Time: 5.08576
Timestep Consumption Time: 2.05187
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.13763

Cumulative Model Updates: 21426
Cumulative Timesteps: 179046490

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.01368
Policy Entropy: 1.34955
Value Function Loss: 0.01247

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.04715
Policy Update Magnitude: 0.11148
Value Function Update Magnitude: 0.13655

Collected Steps per Second: 9333.63364
Overall Steps per Second: 6739.67783

Timestep Collection Time: 5.35997
Timestep Consumption Time: 2.06294
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.42291

Cumulative Model Updates: 21432
Cumulative Timesteps: 179096518

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.61993
Policy Entropy: 1.35047
Value Function Loss: 0.01190

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.04187
Policy Update Magnitude: 0.11040
Value Function Update Magnitude: 0.13528

Collected Steps per Second: 10006.73222
Overall Steps per Second: 7124.66996

Timestep Collection Time: 5.00103
Timestep Consumption Time: 2.02301
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.02404

Cumulative Model Updates: 21438
Cumulative Timesteps: 179146562

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.12861
Policy Entropy: 1.35012
Value Function Loss: 0.01238

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03679
Policy Update Magnitude: 0.11212
Value Function Update Magnitude: 0.12956

Collected Steps per Second: 9467.45195
Overall Steps per Second: 6705.40403

Timestep Collection Time: 5.28495
Timestep Consumption Time: 2.17694
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.46189

Cumulative Model Updates: 21444
Cumulative Timesteps: 179196597

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.20189
Policy Entropy: 1.34666
Value Function Loss: 0.01263

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04168
Policy Update Magnitude: 0.11278
Value Function Update Magnitude: 0.12882

Collected Steps per Second: 9337.48408
Overall Steps per Second: 6804.01608

Timestep Collection Time: 5.35615
Timestep Consumption Time: 1.99436
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.35051

Cumulative Model Updates: 21450
Cumulative Timesteps: 179246610

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 179246610...
Checkpoint 179246610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -3.27956
Policy Entropy: 1.34549
Value Function Loss: 0.01302

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.04479
Policy Update Magnitude: 0.11624
Value Function Update Magnitude: 0.13490

Collected Steps per Second: 10521.88309
Overall Steps per Second: 7322.54027

Timestep Collection Time: 4.75229
Timestep Consumption Time: 2.07635
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 6.82864

Cumulative Model Updates: 21456
Cumulative Timesteps: 179296613

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.20300
Policy Entropy: 1.34507
Value Function Loss: 0.01252

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05582
Policy Update Magnitude: 0.11624
Value Function Update Magnitude: 0.13401

Collected Steps per Second: 9889.52344
Overall Steps per Second: 6822.69074

Timestep Collection Time: 5.05828
Timestep Consumption Time: 2.27372
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.33200

Cumulative Model Updates: 21462
Cumulative Timesteps: 179346637

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.24861
Policy Entropy: 1.34343
Value Function Loss: 0.01231

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.04957
Policy Update Magnitude: 0.11595
Value Function Update Magnitude: 0.13366

Collected Steps per Second: 8729.59980
Overall Steps per Second: 6329.79608

Timestep Collection Time: 5.72993
Timestep Consumption Time: 2.17238
PPO Batch Consumption Time: 0.02411
Total Iteration Time: 7.90231

Cumulative Model Updates: 21468
Cumulative Timesteps: 179396657

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.68322
Policy Entropy: 1.33979
Value Function Loss: 0.01309

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.04676
Policy Update Magnitude: 0.11747
Value Function Update Magnitude: 0.14134

Collected Steps per Second: 9757.51623
Overall Steps per Second: 6861.54104

Timestep Collection Time: 5.12723
Timestep Consumption Time: 2.16399
PPO Batch Consumption Time: 0.02849
Total Iteration Time: 7.29122

Cumulative Model Updates: 21474
Cumulative Timesteps: 179446686

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.93580
Policy Entropy: 1.34050
Value Function Loss: 0.01314

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.05375
Policy Update Magnitude: 0.11843
Value Function Update Magnitude: 0.14145

Collected Steps per Second: 9658.91401
Overall Steps per Second: 6851.17691

Timestep Collection Time: 5.17812
Timestep Consumption Time: 2.12209
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 7.30021

Cumulative Model Updates: 21480
Cumulative Timesteps: 179496701

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.52423
Policy Entropy: 1.34250
Value Function Loss: 0.01423

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.11887
Value Function Update Magnitude: 0.14095

Collected Steps per Second: 8868.35449
Overall Steps per Second: 6339.31966

Timestep Collection Time: 5.64220
Timestep Consumption Time: 2.25092
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.89312

Cumulative Model Updates: 21486
Cumulative Timesteps: 179546738

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.99776
Policy Entropy: 1.34078
Value Function Loss: 0.01338

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05316
Policy Update Magnitude: 0.11631
Value Function Update Magnitude: 0.14040

Collected Steps per Second: 9780.09409
Overall Steps per Second: 6826.03002

Timestep Collection Time: 5.11508
Timestep Consumption Time: 2.21363
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 7.32871

Cumulative Model Updates: 21492
Cumulative Timesteps: 179596764

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.54962
Policy Entropy: 1.33439
Value Function Loss: 0.01361

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05439
Policy Update Magnitude: 0.12060
Value Function Update Magnitude: 0.14634

Collected Steps per Second: 8973.53931
Overall Steps per Second: 6307.50564

Timestep Collection Time: 5.57684
Timestep Consumption Time: 2.35720
PPO Batch Consumption Time: 0.02879
Total Iteration Time: 7.93404

Cumulative Model Updates: 21498
Cumulative Timesteps: 179646808

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.07903
Policy Entropy: 1.33421
Value Function Loss: 0.01378

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.12490
Value Function Update Magnitude: 0.15209

Collected Steps per Second: 9121.50442
Overall Steps per Second: 6533.08813

Timestep Collection Time: 5.48385
Timestep Consumption Time: 2.17271
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 7.65656

Cumulative Model Updates: 21504
Cumulative Timesteps: 179696829

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.20337
Policy Entropy: 1.33840
Value Function Loss: 0.01410

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.12704
Value Function Update Magnitude: 0.15350

Collected Steps per Second: 10377.56275
Overall Steps per Second: 7237.66160

Timestep Collection Time: 4.81876
Timestep Consumption Time: 2.09051
PPO Batch Consumption Time: 0.03018
Total Iteration Time: 6.90928

Cumulative Model Updates: 21510
Cumulative Timesteps: 179746836

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 179746836...
Checkpoint 179746836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.40565
Policy Entropy: 1.34641
Value Function Loss: 0.01422

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.05968
Policy Update Magnitude: 0.12811
Value Function Update Magnitude: 0.15153

Collected Steps per Second: 9773.28284
Overall Steps per Second: 6999.84232

Timestep Collection Time: 5.11660
Timestep Consumption Time: 2.02727
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 7.14388

Cumulative Model Updates: 21516
Cumulative Timesteps: 179796842

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.75592
Policy Entropy: 1.34295
Value Function Loss: 0.01376

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.12246
Value Function Update Magnitude: 0.14590

Collected Steps per Second: 9301.07163
Overall Steps per Second: 6603.83888

Timestep Collection Time: 5.37734
Timestep Consumption Time: 2.19629
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 7.57363

Cumulative Model Updates: 21522
Cumulative Timesteps: 179846857

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.71510
Policy Entropy: 1.34893
Value Function Loss: 0.01358

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06708
Policy Update Magnitude: 0.11797
Value Function Update Magnitude: 0.14496

Collected Steps per Second: 10300.56664
Overall Steps per Second: 7210.88357

Timestep Collection Time: 4.85604
Timestep Consumption Time: 2.08069
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 6.93674

Cumulative Model Updates: 21528
Cumulative Timesteps: 179896877

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.71082
Policy Entropy: 1.34237
Value Function Loss: 0.01353

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.12386
Value Function Update Magnitude: 0.15117

Collected Steps per Second: 10092.14037
Overall Steps per Second: 7346.82862

Timestep Collection Time: 4.95603
Timestep Consumption Time: 1.85194
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.80797

Cumulative Model Updates: 21534
Cumulative Timesteps: 179946894

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -4.51410
Policy Entropy: 1.34901
Value Function Loss: 0.01377

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06554
Policy Update Magnitude: 0.12540
Value Function Update Magnitude: 0.14869

Collected Steps per Second: 9859.91979
Overall Steps per Second: 7143.00722

Timestep Collection Time: 5.07266
Timestep Consumption Time: 1.92943
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.00209

Cumulative Model Updates: 21540
Cumulative Timesteps: 179996910

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.31660
Policy Entropy: 1.34405
Value Function Loss: 0.01386

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.11973
Value Function Update Magnitude: 0.14868

Collected Steps per Second: 10619.90914
Overall Steps per Second: 7359.01233

Timestep Collection Time: 4.70993
Timestep Consumption Time: 2.08704
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 6.79697

Cumulative Model Updates: 21546
Cumulative Timesteps: 180046929

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.74381
Policy Entropy: 1.35046
Value Function Loss: 0.01406

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05094
Policy Update Magnitude: 0.11973
Value Function Update Magnitude: 0.15198

Collected Steps per Second: 10269.18594
Overall Steps per Second: 7329.59284

Timestep Collection Time: 4.86923
Timestep Consumption Time: 1.95284
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 6.82207

Cumulative Model Updates: 21552
Cumulative Timesteps: 180096932

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.14200
Policy Entropy: 1.34705
Value Function Loss: 0.01437

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06384
Policy Update Magnitude: 0.12219
Value Function Update Magnitude: 0.15673

Collected Steps per Second: 9968.82666
Overall Steps per Second: 7234.15486

Timestep Collection Time: 5.01834
Timestep Consumption Time: 1.89705
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 6.91539

Cumulative Model Updates: 21558
Cumulative Timesteps: 180146959

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.97026
Policy Entropy: 1.35492
Value Function Loss: 0.01417

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.11860
Value Function Update Magnitude: 0.15972

Collected Steps per Second: 10292.75119
Overall Steps per Second: 7328.80971

Timestep Collection Time: 4.85934
Timestep Consumption Time: 1.96523
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 6.82457

Cumulative Model Updates: 21564
Cumulative Timesteps: 180196975

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.42019
Policy Entropy: 1.35278
Value Function Loss: 0.01365

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.05677
Policy Update Magnitude: 0.11373
Value Function Update Magnitude: 0.15750

Collected Steps per Second: 9470.50093
Overall Steps per Second: 6667.48021

Timestep Collection Time: 5.28135
Timestep Consumption Time: 2.22029
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.50163

Cumulative Model Updates: 21570
Cumulative Timesteps: 180246992

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 180246992...
Checkpoint 180246992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.19529
Policy Entropy: 1.35792
Value Function Loss: 0.01315

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.04513
Policy Update Magnitude: 0.11148
Value Function Update Magnitude: 0.15573

Collected Steps per Second: 9276.99388
Overall Steps per Second: 6743.42238

Timestep Collection Time: 5.39194
Timestep Consumption Time: 2.02581
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.41775

Cumulative Model Updates: 21576
Cumulative Timesteps: 180297013

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.71075
Policy Entropy: 1.35789
Value Function Loss: 0.01257

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05094
Policy Update Magnitude: 0.11400
Value Function Update Magnitude: 0.14886

Collected Steps per Second: 10290.60829
Overall Steps per Second: 7120.09124

Timestep Collection Time: 4.86191
Timestep Consumption Time: 2.16497
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 7.02688

Cumulative Model Updates: 21582
Cumulative Timesteps: 180347045

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -3.52633
Policy Entropy: 1.35923
Value Function Loss: 0.01237

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04064
Policy Update Magnitude: 0.11257
Value Function Update Magnitude: 0.14182

Collected Steps per Second: 8734.28117
Overall Steps per Second: 6384.24997

Timestep Collection Time: 5.72503
Timestep Consumption Time: 2.10737
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.83240

Cumulative Model Updates: 21588
Cumulative Timesteps: 180397049

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.65806
Policy Entropy: 1.35804
Value Function Loss: 0.01237

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04069
Policy Update Magnitude: 0.11317
Value Function Update Magnitude: 0.14052

Collected Steps per Second: 9156.95637
Overall Steps per Second: 6627.45904

Timestep Collection Time: 5.46142
Timestep Consumption Time: 2.08446
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.54588

Cumulative Model Updates: 21594
Cumulative Timesteps: 180447059

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.10794
Policy Entropy: 1.35670
Value Function Loss: 0.01274

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03868
Policy Update Magnitude: 0.11718
Value Function Update Magnitude: 0.13788

Collected Steps per Second: 10298.90409
Overall Steps per Second: 7079.15924

Timestep Collection Time: 4.85887
Timestep Consumption Time: 2.20991
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.06878

Cumulative Model Updates: 21600
Cumulative Timesteps: 180497100

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.52464
Policy Entropy: 1.35617
Value Function Loss: 0.01295

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.04733
Policy Update Magnitude: 0.11511
Value Function Update Magnitude: 0.14031

Collected Steps per Second: 9064.22645
Overall Steps per Second: 6436.86840

Timestep Collection Time: 5.51785
Timestep Consumption Time: 2.25224
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 7.77008

Cumulative Model Updates: 21606
Cumulative Timesteps: 180547115

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -9.96610
Policy Entropy: 1.35516
Value Function Loss: 0.01277

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04343
Policy Update Magnitude: 0.11568
Value Function Update Magnitude: 0.14143

Collected Steps per Second: 9532.62084
Overall Steps per Second: 6863.12327

Timestep Collection Time: 5.24882
Timestep Consumption Time: 2.04159
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 7.29041

Cumulative Model Updates: 21612
Cumulative Timesteps: 180597150

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.08178
Policy Entropy: 1.35201
Value Function Loss: 0.01282

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.04792
Policy Update Magnitude: 0.11822
Value Function Update Magnitude: 0.13625

Collected Steps per Second: 10285.54533
Overall Steps per Second: 6977.30213

Timestep Collection Time: 4.86284
Timestep Consumption Time: 2.30569
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 7.16853

Cumulative Model Updates: 21618
Cumulative Timesteps: 180647167

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.72773
Policy Entropy: 1.34965
Value Function Loss: 0.01287

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.06422
Policy Update Magnitude: 0.11917
Value Function Update Magnitude: 0.14265

Collected Steps per Second: 8929.23458
Overall Steps per Second: 6328.22551

Timestep Collection Time: 5.60104
Timestep Consumption Time: 2.30212
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.90316

Cumulative Model Updates: 21624
Cumulative Timesteps: 180697180

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.68545
Policy Entropy: 1.34894
Value Function Loss: 0.01249

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06665
Policy Update Magnitude: 0.11670
Value Function Update Magnitude: 0.14165

Collected Steps per Second: 9646.59588
Overall Steps per Second: 6891.07716

Timestep Collection Time: 5.18670
Timestep Consumption Time: 2.07399
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.26069

Cumulative Model Updates: 21630
Cumulative Timesteps: 180747214

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 180747214...
Checkpoint 180747214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.05306
Policy Entropy: 1.35134
Value Function Loss: 0.01232

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.04948
Policy Update Magnitude: 0.11522
Value Function Update Magnitude: 0.14007

Collected Steps per Second: 10231.03596
Overall Steps per Second: 6884.21187

Timestep Collection Time: 4.89041
Timestep Consumption Time: 2.37752
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.26793

Cumulative Model Updates: 21636
Cumulative Timesteps: 180797248

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.39972
Policy Entropy: 1.34900
Value Function Loss: 0.01185

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06322
Policy Update Magnitude: 0.11008
Value Function Update Magnitude: 0.14150

Collected Steps per Second: 9300.07800
Overall Steps per Second: 6667.38163

Timestep Collection Time: 5.37823
Timestep Consumption Time: 2.12366
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.50190

Cumulative Model Updates: 21642
Cumulative Timesteps: 180847266

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.11472
Policy Entropy: 1.34923
Value Function Loss: 0.01200

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.04757
Policy Update Magnitude: 0.11394
Value Function Update Magnitude: 0.14256

Collected Steps per Second: 9752.16325
Overall Steps per Second: 7015.80516

Timestep Collection Time: 5.12902
Timestep Consumption Time: 2.00046
PPO Batch Consumption Time: 0.02490
Total Iteration Time: 7.12947

Cumulative Model Updates: 21648
Cumulative Timesteps: 180897285

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.60420
Policy Entropy: 1.34829
Value Function Loss: 0.01218

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.05231
Policy Update Magnitude: 0.11641
Value Function Update Magnitude: 0.14301

Collected Steps per Second: 10761.58896
Overall Steps per Second: 7503.85564

Timestep Collection Time: 4.64848
Timestep Consumption Time: 2.01810
PPO Batch Consumption Time: 0.02453
Total Iteration Time: 6.66657

Cumulative Model Updates: 21654
Cumulative Timesteps: 180947310

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.02766
Policy Entropy: 1.34969
Value Function Loss: 0.01285

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.05472
Policy Update Magnitude: 0.11723
Value Function Update Magnitude: 0.14687

Collected Steps per Second: 9429.79749
Overall Steps per Second: 6740.32278

Timestep Collection Time: 5.30584
Timestep Consumption Time: 2.11710
PPO Batch Consumption Time: 0.02445
Total Iteration Time: 7.42294

Cumulative Model Updates: 21660
Cumulative Timesteps: 180997343

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.36791
Policy Entropy: 1.34840
Value Function Loss: 0.01277

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05465
Policy Update Magnitude: 0.11870
Value Function Update Magnitude: 0.14541

Collected Steps per Second: 9695.51205
Overall Steps per Second: 6927.06090

Timestep Collection Time: 5.15764
Timestep Consumption Time: 2.06129
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.21893

Cumulative Model Updates: 21666
Cumulative Timesteps: 181047349

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.26974
Policy Entropy: 1.34714
Value Function Loss: 0.01264

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.06200
Policy Update Magnitude: 0.11907
Value Function Update Magnitude: 0.13773

Collected Steps per Second: 9526.88646
Overall Steps per Second: 6593.20316

Timestep Collection Time: 5.25282
Timestep Consumption Time: 2.33727
PPO Batch Consumption Time: 0.02898
Total Iteration Time: 7.59009

Cumulative Model Updates: 21672
Cumulative Timesteps: 181097392

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.36446
Policy Entropy: 1.34507
Value Function Loss: 0.01295

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.05616
Policy Update Magnitude: 0.11452
Value Function Update Magnitude: 0.14299

Collected Steps per Second: 9027.13517
Overall Steps per Second: 6508.02164

Timestep Collection Time: 5.54140
Timestep Consumption Time: 2.14496
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.68636

Cumulative Model Updates: 21678
Cumulative Timesteps: 181147415

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.56125
Policy Entropy: 1.34516
Value Function Loss: 0.01254

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 0.11722
Value Function Update Magnitude: 0.14810

Collected Steps per Second: 8993.38356
Overall Steps per Second: 6507.47987

Timestep Collection Time: 5.56031
Timestep Consumption Time: 2.12408
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.68439

Cumulative Model Updates: 21684
Cumulative Timesteps: 181197421

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.32730
Policy Entropy: 1.34767
Value Function Loss: 0.01331

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06034
Policy Update Magnitude: 0.11901
Value Function Update Magnitude: 0.14891

Collected Steps per Second: 9599.61841
Overall Steps per Second: 6578.33855

Timestep Collection Time: 5.21135
Timestep Consumption Time: 2.39345
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 7.60481

Cumulative Model Updates: 21690
Cumulative Timesteps: 181247448

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 181247448...
Checkpoint 181247448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.54922
Policy Entropy: 1.35325
Value Function Loss: 0.01241

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.04419
Policy Update Magnitude: 0.11788
Value Function Update Magnitude: 0.14651

Collected Steps per Second: 9001.85772
Overall Steps per Second: 6438.04601

Timestep Collection Time: 5.55674
Timestep Consumption Time: 2.21285
PPO Batch Consumption Time: 0.03193
Total Iteration Time: 7.76959

Cumulative Model Updates: 21696
Cumulative Timesteps: 181297469

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.96355
Policy Entropy: 1.35307
Value Function Loss: 0.01332

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.04469
Policy Update Magnitude: 0.12006
Value Function Update Magnitude: 0.14075

Collected Steps per Second: 9198.52681
Overall Steps per Second: 6516.05490

Timestep Collection Time: 5.43815
Timestep Consumption Time: 2.23873
PPO Batch Consumption Time: 0.02969
Total Iteration Time: 7.67688

Cumulative Model Updates: 21702
Cumulative Timesteps: 181347492

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.63505
Policy Entropy: 1.35702
Value Function Loss: 0.01281

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.04170
Policy Update Magnitude: 0.11938
Value Function Update Magnitude: 0.13436

Collected Steps per Second: 9786.96053
Overall Steps per Second: 6803.27751

Timestep Collection Time: 5.10884
Timestep Consumption Time: 2.24056
PPO Batch Consumption Time: 0.02940
Total Iteration Time: 7.34940

Cumulative Model Updates: 21708
Cumulative Timesteps: 181397492

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.06719
Policy Entropy: 1.35365
Value Function Loss: 0.01299

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.04827
Policy Update Magnitude: 0.11714
Value Function Update Magnitude: 0.13476

Collected Steps per Second: 9141.07127
Overall Steps per Second: 6513.27144

Timestep Collection Time: 5.47332
Timestep Consumption Time: 2.20823
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.68155

Cumulative Model Updates: 21714
Cumulative Timesteps: 181447524

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.48321
Policy Entropy: 1.35100
Value Function Loss: 0.01280

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.04939
Policy Update Magnitude: 0.11665
Value Function Update Magnitude: 0.13660

Collected Steps per Second: 9595.91946
Overall Steps per Second: 6697.35603

Timestep Collection Time: 5.21242
Timestep Consumption Time: 2.25590
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.46832

Cumulative Model Updates: 21720
Cumulative Timesteps: 181497542

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.08611
Policy Entropy: 1.34854
Value Function Loss: 0.01282

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05253
Policy Update Magnitude: 0.11892
Value Function Update Magnitude: 0.13781

Collected Steps per Second: 9983.98345
Overall Steps per Second: 7037.95093

Timestep Collection Time: 5.01153
Timestep Consumption Time: 2.09779
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.10931

Cumulative Model Updates: 21726
Cumulative Timesteps: 181547577

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.83811
Policy Entropy: 1.34888
Value Function Loss: 0.01355

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05049
Policy Update Magnitude: 0.12228
Value Function Update Magnitude: 0.13869

Collected Steps per Second: 9886.23870
Overall Steps per Second: 7135.25935

Timestep Collection Time: 5.05834
Timestep Consumption Time: 1.95023
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.00857

Cumulative Model Updates: 21732
Cumulative Timesteps: 181597585

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.91100
Policy Entropy: 1.34855
Value Function Loss: 0.01277

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05126
Policy Update Magnitude: 0.11648
Value Function Update Magnitude: 0.14092

Collected Steps per Second: 10107.37083
Overall Steps per Second: 7138.94071

Timestep Collection Time: 4.95035
Timestep Consumption Time: 2.05840
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 7.00874

Cumulative Model Updates: 21738
Cumulative Timesteps: 181647620

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.97596
Policy Entropy: 1.34566
Value Function Loss: 0.01293

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.04544
Policy Update Magnitude: 0.11940
Value Function Update Magnitude: 0.14245

Collected Steps per Second: 10550.07619
Overall Steps per Second: 7463.98143

Timestep Collection Time: 4.74177
Timestep Consumption Time: 1.96055
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 6.70232

Cumulative Model Updates: 21744
Cumulative Timesteps: 181697646

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.78868
Policy Entropy: 1.34631
Value Function Loss: 0.01220

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.04769
Policy Update Magnitude: 0.12037
Value Function Update Magnitude: 0.13852

Collected Steps per Second: 10232.20522
Overall Steps per Second: 7301.83297

Timestep Collection Time: 4.89064
Timestep Consumption Time: 1.96271
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 6.85335

Cumulative Model Updates: 21750
Cumulative Timesteps: 181747688

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 181747688...
Checkpoint 181747688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.44270
Policy Entropy: 1.34486
Value Function Loss: 0.01273

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.05256
Policy Update Magnitude: 0.11760
Value Function Update Magnitude: 0.13419

Collected Steps per Second: 9867.43553
Overall Steps per Second: 7186.60368

Timestep Collection Time: 5.06738
Timestep Consumption Time: 1.89029
PPO Batch Consumption Time: 0.02464
Total Iteration Time: 6.95767

Cumulative Model Updates: 21756
Cumulative Timesteps: 181797690

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.84610
Policy Entropy: 1.34647
Value Function Loss: 0.01266

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05426
Policy Update Magnitude: 0.11741
Value Function Update Magnitude: 0.13581

Collected Steps per Second: 11290.65079
Overall Steps per Second: 7697.06304

Timestep Collection Time: 4.43190
Timestep Consumption Time: 2.06915
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 6.50105

Cumulative Model Updates: 21762
Cumulative Timesteps: 181847729

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.65005
Policy Entropy: 1.34446
Value Function Loss: 0.01373

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05805
Policy Update Magnitude: 0.11666
Value Function Update Magnitude: 0.13374

Collected Steps per Second: 10451.03414
Overall Steps per Second: 7411.33772

Timestep Collection Time: 4.78556
Timestep Consumption Time: 1.96275
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 6.74831

Cumulative Model Updates: 21768
Cumulative Timesteps: 181897743

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.36461
Policy Entropy: 1.34496
Value Function Loss: 0.01425

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.11780
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 9611.16403
Overall Steps per Second: 6733.88053

Timestep Collection Time: 5.20478
Timestep Consumption Time: 2.22392
PPO Batch Consumption Time: 0.02934
Total Iteration Time: 7.42870

Cumulative Model Updates: 21774
Cumulative Timesteps: 181947767

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93528
Policy Entropy: 1.34468
Value Function Loss: 0.01478

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05698
Policy Update Magnitude: 0.12082
Value Function Update Magnitude: 0.13048

Collected Steps per Second: 9754.88853
Overall Steps per Second: 6749.02563

Timestep Collection Time: 5.12656
Timestep Consumption Time: 2.28325
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.40981

Cumulative Model Updates: 21780
Cumulative Timesteps: 181997776

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.18991
Policy Entropy: 1.34447
Value Function Loss: 0.01419

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.05973
Policy Update Magnitude: 0.12341
Value Function Update Magnitude: 0.13514

Collected Steps per Second: 9507.53879
Overall Steps per Second: 6846.69432

Timestep Collection Time: 5.25941
Timestep Consumption Time: 2.04397
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.30338

Cumulative Model Updates: 21786
Cumulative Timesteps: 182047780

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.58520
Policy Entropy: 1.34905
Value Function Loss: 0.01375

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.04822
Policy Update Magnitude: 0.12219
Value Function Update Magnitude: 0.13085

Collected Steps per Second: 8994.27747
Overall Steps per Second: 6394.49002

Timestep Collection Time: 5.55998
Timestep Consumption Time: 2.26050
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 7.82048

Cumulative Model Updates: 21792
Cumulative Timesteps: 182097788

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.48294
Policy Entropy: 1.34177
Value Function Loss: 0.01342

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.12366
Value Function Update Magnitude: 0.13074

Collected Steps per Second: 9451.20178
Overall Steps per Second: 6658.27926

Timestep Collection Time: 5.29351
Timestep Consumption Time: 2.22045
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.51395

Cumulative Model Updates: 21798
Cumulative Timesteps: 182147818

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.43275
Policy Entropy: 1.34142
Value Function Loss: 0.01322

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.05996
Policy Update Magnitude: 0.12320
Value Function Update Magnitude: 0.14147

Collected Steps per Second: 9828.67493
Overall Steps per Second: 7097.30510

Timestep Collection Time: 5.08868
Timestep Consumption Time: 1.95836
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.04704

Cumulative Model Updates: 21804
Cumulative Timesteps: 182197833

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.22066
Policy Entropy: 1.33424
Value Function Loss: 0.01330

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.12566
Value Function Update Magnitude: 0.14788

Collected Steps per Second: 9827.75652
Overall Steps per Second: 6913.68755

Timestep Collection Time: 5.09068
Timestep Consumption Time: 2.14569
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.23637

Cumulative Model Updates: 21810
Cumulative Timesteps: 182247863

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 182247863...
Checkpoint 182247863 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.33585
Policy Entropy: 1.34288
Value Function Loss: 0.01297

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.12021
Value Function Update Magnitude: 0.14583

Collected Steps per Second: 9164.72510
Overall Steps per Second: 6425.90553

Timestep Collection Time: 5.46017
Timestep Consumption Time: 2.32721
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 7.78738

Cumulative Model Updates: 21816
Cumulative Timesteps: 182297904

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.72061
Policy Entropy: 1.34473
Value Function Loss: 0.01334

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.11976
Value Function Update Magnitude: 0.14862

Collected Steps per Second: 9546.92484
Overall Steps per Second: 6815.27334

Timestep Collection Time: 5.23938
Timestep Consumption Time: 2.10001
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 7.33940

Cumulative Model Updates: 21822
Cumulative Timesteps: 182347924

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12096
Policy Entropy: 1.34593
Value Function Loss: 0.01338

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.11630
Value Function Update Magnitude: 0.15340

Collected Steps per Second: 9227.56903
Overall Steps per Second: 6558.21267

Timestep Collection Time: 5.42017
Timestep Consumption Time: 2.20614
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 7.62632

Cumulative Model Updates: 21828
Cumulative Timesteps: 182397939

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.18088
Policy Entropy: 1.34712
Value Function Loss: 0.01349

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06761
Policy Update Magnitude: 0.11627
Value Function Update Magnitude: 0.15203

Collected Steps per Second: 9264.75471
Overall Steps per Second: 6421.41810

Timestep Collection Time: 5.40068
Timestep Consumption Time: 2.39137
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 7.79205

Cumulative Model Updates: 21834
Cumulative Timesteps: 182447975

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.16393
Policy Entropy: 1.34335
Value Function Loss: 0.01353

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05540
Policy Update Magnitude: 0.11994
Value Function Update Magnitude: 0.15186

Collected Steps per Second: 9502.40504
Overall Steps per Second: 6773.13776

Timestep Collection Time: 5.26530
Timestep Consumption Time: 2.12168
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.38698

Cumulative Model Updates: 21840
Cumulative Timesteps: 182498008

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.34987
Policy Entropy: 1.34443
Value Function Loss: 0.01290

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05100
Policy Update Magnitude: 0.12125
Value Function Update Magnitude: 0.14855

Collected Steps per Second: 9262.40353
Overall Steps per Second: 6746.61137

Timestep Collection Time: 5.40259
Timestep Consumption Time: 2.01461
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.41721

Cumulative Model Updates: 21846
Cumulative Timesteps: 182548049

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.61878
Policy Entropy: 1.34227
Value Function Loss: 0.01366

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.05101
Policy Update Magnitude: 0.12344
Value Function Update Magnitude: 0.14530

Collected Steps per Second: 9820.88582
Overall Steps per Second: 6969.38332

Timestep Collection Time: 5.09587
Timestep Consumption Time: 2.08496
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.18084

Cumulative Model Updates: 21852
Cumulative Timesteps: 182598095

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.25749
Policy Entropy: 1.34454
Value Function Loss: 0.01403

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05408
Policy Update Magnitude: 0.12475
Value Function Update Magnitude: 0.14606

Collected Steps per Second: 9789.18080
Overall Steps per Second: 7071.73125

Timestep Collection Time: 5.10942
Timestep Consumption Time: 1.96339
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 7.07281

Cumulative Model Updates: 21858
Cumulative Timesteps: 182648112

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.19745
Policy Entropy: 1.34536
Value Function Loss: 0.01393

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.04344
Policy Update Magnitude: 0.12899
Value Function Update Magnitude: 0.14690

Collected Steps per Second: 9935.44181
Overall Steps per Second: 7111.02440

Timestep Collection Time: 5.03420
Timestep Consumption Time: 1.99953
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.03373

Cumulative Model Updates: 21864
Cumulative Timesteps: 182698129

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.85715
Policy Entropy: 1.34218
Value Function Loss: 0.01389

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05075
Policy Update Magnitude: 0.13195
Value Function Update Magnitude: 0.14175

Collected Steps per Second: 10430.54718
Overall Steps per Second: 7308.67480

Timestep Collection Time: 4.79582
Timestep Consumption Time: 2.04852
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.84433

Cumulative Model Updates: 21870
Cumulative Timesteps: 182748152

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 182748152...
Checkpoint 182748152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.31243
Policy Entropy: 1.34510
Value Function Loss: 0.01354

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.05678
Policy Update Magnitude: 0.13086
Value Function Update Magnitude: 0.14264

Collected Steps per Second: 9925.02858
Overall Steps per Second: 7039.62725

Timestep Collection Time: 5.03938
Timestep Consumption Time: 2.06554
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.10492

Cumulative Model Updates: 21876
Cumulative Timesteps: 182798168

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.51717
Policy Entropy: 1.34469
Value Function Loss: 0.01360

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.12564
Value Function Update Magnitude: 0.14996

Collected Steps per Second: 9850.09444
Overall Steps per Second: 7117.75585

Timestep Collection Time: 5.07833
Timestep Consumption Time: 1.94945
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.02778

Cumulative Model Updates: 21882
Cumulative Timesteps: 182848190

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.11461
Policy Entropy: 1.34287
Value Function Loss: 0.01387

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.12411
Value Function Update Magnitude: 0.14672

Collected Steps per Second: 10426.93998
Overall Steps per Second: 7144.21143

Timestep Collection Time: 4.79930
Timestep Consumption Time: 2.20525
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.00455

Cumulative Model Updates: 21888
Cumulative Timesteps: 182898232

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.69562
Policy Entropy: 1.33756
Value Function Loss: 0.01378

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06063
Policy Update Magnitude: 0.12520
Value Function Update Magnitude: 0.14599

Collected Steps per Second: 10339.33522
Overall Steps per Second: 7295.87616

Timestep Collection Time: 4.83948
Timestep Consumption Time: 2.01878
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 6.85826

Cumulative Model Updates: 21894
Cumulative Timesteps: 182948269

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.69377
Policy Entropy: 1.33781
Value Function Loss: 0.01425

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.12837
Value Function Update Magnitude: 0.14638

Collected Steps per Second: 9486.73229
Overall Steps per Second: 6721.76759

Timestep Collection Time: 5.27410
Timestep Consumption Time: 2.16948
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.44358

Cumulative Model Updates: 21900
Cumulative Timesteps: 182998303

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.44376
Policy Entropy: 1.34250
Value Function Loss: 0.01383

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06314
Policy Update Magnitude: 0.12671
Value Function Update Magnitude: 0.14299

Collected Steps per Second: 9470.37999
Overall Steps per Second: 6679.18239

Timestep Collection Time: 5.28405
Timestep Consumption Time: 2.20818
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.49223

Cumulative Model Updates: 21906
Cumulative Timesteps: 183048345

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.87432
Policy Entropy: 1.34522
Value Function Loss: 0.01375

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05382
Policy Update Magnitude: 0.12322
Value Function Update Magnitude: 0.14423

Collected Steps per Second: 9264.93218
Overall Steps per Second: 6521.11696

Timestep Collection Time: 5.39734
Timestep Consumption Time: 2.27098
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.66832

Cumulative Model Updates: 21912
Cumulative Timesteps: 183098351

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.15831
Policy Entropy: 1.34688
Value Function Loss: 0.01393

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.04549
Policy Update Magnitude: 0.12390
Value Function Update Magnitude: 0.14451

Collected Steps per Second: 8695.14005
Overall Steps per Second: 6284.72645

Timestep Collection Time: 5.75080
Timestep Consumption Time: 2.20563
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 7.95643

Cumulative Model Updates: 21918
Cumulative Timesteps: 183148355

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.82889
Policy Entropy: 1.34423
Value Function Loss: 0.01357

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05642
Policy Update Magnitude: 0.12321
Value Function Update Magnitude: 0.14794

Collected Steps per Second: 9804.19992
Overall Steps per Second: 6864.38986

Timestep Collection Time: 5.10281
Timestep Consumption Time: 2.18538
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.28819

Cumulative Model Updates: 21924
Cumulative Timesteps: 183198384

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52794
Policy Entropy: 1.34249
Value Function Loss: 0.01357

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05190
Policy Update Magnitude: 0.12140
Value Function Update Magnitude: 0.14252

Collected Steps per Second: 9217.59908
Overall Steps per Second: 6649.03467

Timestep Collection Time: 5.42658
Timestep Consumption Time: 2.09632
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.52290

Cumulative Model Updates: 21930
Cumulative Timesteps: 183248404

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 183248404...
Checkpoint 183248404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.98500
Policy Entropy: 1.33862
Value Function Loss: 0.01335

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.11886
Value Function Update Magnitude: 0.13959

Collected Steps per Second: 9240.32250
Overall Steps per Second: 6504.49885

Timestep Collection Time: 5.41291
Timestep Consumption Time: 2.27669
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.68960

Cumulative Model Updates: 21936
Cumulative Timesteps: 183298421

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.65426
Policy Entropy: 1.34084
Value Function Loss: 0.01323

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06002
Policy Update Magnitude: 0.12048
Value Function Update Magnitude: 0.14287

Collected Steps per Second: 10038.55199
Overall Steps per Second: 6939.64648

Timestep Collection Time: 4.98389
Timestep Consumption Time: 2.22556
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.20945

Cumulative Model Updates: 21942
Cumulative Timesteps: 183348452

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.47815
Policy Entropy: 1.34598
Value Function Loss: 0.01268

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05336
Policy Update Magnitude: 0.12087
Value Function Update Magnitude: 0.14855

Collected Steps per Second: 9124.27286
Overall Steps per Second: 6415.92845

Timestep Collection Time: 5.48252
Timestep Consumption Time: 2.31433
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.79685

Cumulative Model Updates: 21948
Cumulative Timesteps: 183398476

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.18006
Policy Entropy: 1.34553
Value Function Loss: 0.01281

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06080
Policy Update Magnitude: 0.11997
Value Function Update Magnitude: 0.14802

Collected Steps per Second: 9157.51361
Overall Steps per Second: 6572.18274

Timestep Collection Time: 5.46447
Timestep Consumption Time: 2.14959
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.61406

Cumulative Model Updates: 21954
Cumulative Timesteps: 183448517

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.54710
Policy Entropy: 1.34481
Value Function Loss: 0.01275

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05329
Policy Update Magnitude: 0.11872
Value Function Update Magnitude: 0.15017

Collected Steps per Second: 9663.03890
Overall Steps per Second: 6677.10897

Timestep Collection Time: 5.17653
Timestep Consumption Time: 2.31489
PPO Batch Consumption Time: 0.02993
Total Iteration Time: 7.49142

Cumulative Model Updates: 21960
Cumulative Timesteps: 183498538

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -9.67167
Policy Entropy: 1.34005
Value Function Loss: 0.01286

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.04446
Policy Update Magnitude: 0.11954
Value Function Update Magnitude: 0.15545

Collected Steps per Second: 9550.74593
Overall Steps per Second: 6784.29318

Timestep Collection Time: 5.23844
Timestep Consumption Time: 2.13609
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.37453

Cumulative Model Updates: 21966
Cumulative Timesteps: 183548569

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.61525
Policy Entropy: 1.34154
Value Function Loss: 0.01310

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05059
Policy Update Magnitude: 0.12059
Value Function Update Magnitude: 0.15743

Collected Steps per Second: 10246.66952
Overall Steps per Second: 7141.75371

Timestep Collection Time: 4.88334
Timestep Consumption Time: 2.12306
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.00640

Cumulative Model Updates: 21972
Cumulative Timesteps: 183598607

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.43727
Policy Entropy: 1.34125
Value Function Loss: 0.01370

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.05724
Policy Update Magnitude: 0.12528
Value Function Update Magnitude: 0.15318

Collected Steps per Second: 10966.37671
Overall Steps per Second: 7561.20169

Timestep Collection Time: 4.56094
Timestep Consumption Time: 2.05401
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.61495

Cumulative Model Updates: 21978
Cumulative Timesteps: 183648624

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.69842
Policy Entropy: 1.34620
Value Function Loss: 0.01385

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05449
Policy Update Magnitude: 0.12498
Value Function Update Magnitude: 0.15562

Collected Steps per Second: 10224.91498
Overall Steps per Second: 7392.06402

Timestep Collection Time: 4.89246
Timestep Consumption Time: 1.87493
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 6.76739

Cumulative Model Updates: 21984
Cumulative Timesteps: 183698649

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.82569
Policy Entropy: 1.34934
Value Function Loss: 0.01295

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.04538
Policy Update Magnitude: 0.12012
Value Function Update Magnitude: 0.14928

Collected Steps per Second: 10266.75902
Overall Steps per Second: 7403.60589

Timestep Collection Time: 4.87311
Timestep Consumption Time: 1.88455
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 6.75765

Cumulative Model Updates: 21990
Cumulative Timesteps: 183748680

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 183748680...
Checkpoint 183748680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.14711
Policy Entropy: 1.34807
Value Function Loss: 0.01195

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.04757
Policy Update Magnitude: 0.11883
Value Function Update Magnitude: 0.14527

Collected Steps per Second: 10536.85997
Overall Steps per Second: 7209.70631

Timestep Collection Time: 4.74923
Timestep Consumption Time: 2.19169
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.94092

Cumulative Model Updates: 21996
Cumulative Timesteps: 183798722

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.58007
Policy Entropy: 1.34673
Value Function Loss: 0.01262

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05074
Policy Update Magnitude: 0.12291
Value Function Update Magnitude: 0.14460

Collected Steps per Second: 9397.86382
Overall Steps per Second: 6749.49599

Timestep Collection Time: 5.32217
Timestep Consumption Time: 2.08831
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 7.41048

Cumulative Model Updates: 22002
Cumulative Timesteps: 183848739

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.72328
Policy Entropy: 1.34466
Value Function Loss: 0.01248

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.05078
Policy Update Magnitude: 0.12122
Value Function Update Magnitude: 0.15028

Collected Steps per Second: 9797.30173
Overall Steps per Second: 6925.94030

Timestep Collection Time: 5.10467
Timestep Consumption Time: 2.11630
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.22097

Cumulative Model Updates: 22008
Cumulative Timesteps: 183898751

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.41666
Policy Entropy: 1.33891
Value Function Loss: 0.01359

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06362
Policy Update Magnitude: 0.11909
Value Function Update Magnitude: 0.14367

Collected Steps per Second: 9991.44455
Overall Steps per Second: 6896.46288

Timestep Collection Time: 5.00848
Timestep Consumption Time: 2.24770
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.25618

Cumulative Model Updates: 22014
Cumulative Timesteps: 183948793

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.73100
Policy Entropy: 1.33570
Value Function Loss: 0.01316

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05853
Policy Update Magnitude: 0.12235
Value Function Update Magnitude: 0.14086

Collected Steps per Second: 9123.42587
Overall Steps per Second: 6656.99284

Timestep Collection Time: 5.48051
Timestep Consumption Time: 2.03054
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.51105

Cumulative Model Updates: 22020
Cumulative Timesteps: 183998794

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.92562
Policy Entropy: 1.33603
Value Function Loss: 0.01357

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.12495
Value Function Update Magnitude: 0.14685

Collected Steps per Second: 8923.98118
Overall Steps per Second: 6414.82984

Timestep Collection Time: 5.60714
Timestep Consumption Time: 2.19322
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 7.80036

Cumulative Model Updates: 22026
Cumulative Timesteps: 184048832

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.76257
Policy Entropy: 1.33748
Value Function Loss: 0.01344

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.12751
Value Function Update Magnitude: 0.14609

Collected Steps per Second: 9617.24740
Overall Steps per Second: 6654.82032

Timestep Collection Time: 5.20336
Timestep Consumption Time: 2.31630
PPO Batch Consumption Time: 0.02952
Total Iteration Time: 7.51966

Cumulative Model Updates: 22032
Cumulative Timesteps: 184098874

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.64681
Policy Entropy: 1.33546
Value Function Loss: 0.01365

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.06764
Policy Update Magnitude: 0.12501
Value Function Update Magnitude: 0.15078

Collected Steps per Second: 8764.37049
Overall Steps per Second: 6402.06029

Timestep Collection Time: 5.71016
Timestep Consumption Time: 2.10701
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 7.81717

Cumulative Model Updates: 22038
Cumulative Timesteps: 184148920

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.72956
Policy Entropy: 1.33792
Value Function Loss: 0.01302

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.12548
Value Function Update Magnitude: 0.15305

Collected Steps per Second: 8932.58649
Overall Steps per Second: 6467.24153

Timestep Collection Time: 5.60107
Timestep Consumption Time: 2.13515
PPO Batch Consumption Time: 0.02909
Total Iteration Time: 7.73622

Cumulative Model Updates: 22044
Cumulative Timesteps: 184198952

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.48241
Policy Entropy: 1.34169
Value Function Loss: 0.01297

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.12402
Value Function Update Magnitude: 0.15035

Collected Steps per Second: 9355.83316
Overall Steps per Second: 6588.69474

Timestep Collection Time: 5.34725
Timestep Consumption Time: 2.24575
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.59301

Cumulative Model Updates: 22050
Cumulative Timesteps: 184248980

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 184248980...
Checkpoint 184248980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.94001
Policy Entropy: 1.34230
Value Function Loss: 0.01274

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.12534
Value Function Update Magnitude: 0.15097

Collected Steps per Second: 9514.75932
Overall Steps per Second: 6653.63972

Timestep Collection Time: 5.25951
Timestep Consumption Time: 2.26163
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 7.52115

Cumulative Model Updates: 22056
Cumulative Timesteps: 184299023

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.64459
Policy Entropy: 1.34391
Value Function Loss: 0.01304

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.06426
Policy Update Magnitude: 0.13011
Value Function Update Magnitude: 0.15155

Collected Steps per Second: 9140.82217
Overall Steps per Second: 6683.66923

Timestep Collection Time: 5.47030
Timestep Consumption Time: 2.01107
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 7.48137

Cumulative Model Updates: 22062
Cumulative Timesteps: 184349026

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.29320
Policy Entropy: 1.33538
Value Function Loss: 0.01443

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.13057
Value Function Update Magnitude: 0.15021

Collected Steps per Second: 10394.57365
Overall Steps per Second: 7296.56776

Timestep Collection Time: 4.81367
Timestep Consumption Time: 2.04381
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 6.85747

Cumulative Model Updates: 22068
Cumulative Timesteps: 184399062

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.48393
Policy Entropy: 1.33754
Value Function Loss: 0.01465

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.13129
Value Function Update Magnitude: 0.15425

Collected Steps per Second: 10257.36709
Overall Steps per Second: 7233.00488

Timestep Collection Time: 4.87776
Timestep Consumption Time: 2.03956
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.91732

Cumulative Model Updates: 22074
Cumulative Timesteps: 184449095

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.66117
Policy Entropy: 1.33560
Value Function Loss: 0.01525

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06267
Policy Update Magnitude: 0.13743
Value Function Update Magnitude: 0.15422

Collected Steps per Second: 9241.85306
Overall Steps per Second: 6708.13763

Timestep Collection Time: 5.41093
Timestep Consumption Time: 2.04375
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 7.45468

Cumulative Model Updates: 22080
Cumulative Timesteps: 184499102

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.15074
Policy Entropy: 1.33744
Value Function Loss: 0.01407

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05826
Policy Update Magnitude: 0.14232
Value Function Update Magnitude: 0.15371

Collected Steps per Second: 10316.24519
Overall Steps per Second: 7129.41310

Timestep Collection Time: 4.84711
Timestep Consumption Time: 2.16665
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.01376

Cumulative Model Updates: 22086
Cumulative Timesteps: 184549106

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.81023
Policy Entropy: 1.33554
Value Function Loss: 0.01379

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06252
Policy Update Magnitude: 0.13533
Value Function Update Magnitude: 0.15564

Collected Steps per Second: 10577.25960
Overall Steps per Second: 7502.12721

Timestep Collection Time: 4.72892
Timestep Consumption Time: 1.93839
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.66731

Cumulative Model Updates: 22092
Cumulative Timesteps: 184599125

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.53149
Policy Entropy: 1.33631
Value Function Loss: 0.01368

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.13228
Value Function Update Magnitude: 0.15122

Collected Steps per Second: 9862.69369
Overall Steps per Second: 7053.04647

Timestep Collection Time: 5.07245
Timestep Consumption Time: 2.02066
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.09311

Cumulative Model Updates: 22098
Cumulative Timesteps: 184649153

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.76395
Policy Entropy: 1.33766
Value Function Loss: 0.01389

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.13257
Value Function Update Magnitude: 0.15225

Collected Steps per Second: 10397.58184
Overall Steps per Second: 7382.85522

Timestep Collection Time: 4.80987
Timestep Consumption Time: 1.96407
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.77394

Cumulative Model Updates: 22104
Cumulative Timesteps: 184699164

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.33645
Policy Entropy: 1.33433
Value Function Loss: 0.01460

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07668
Policy Update Magnitude: 0.13219
Value Function Update Magnitude: 0.15247

Collected Steps per Second: 9779.42431
Overall Steps per Second: 7088.91804

Timestep Collection Time: 5.11318
Timestep Consumption Time: 1.94064
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.05383

Cumulative Model Updates: 22110
Cumulative Timesteps: 184749168

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 184749168...
Checkpoint 184749168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.57636
Policy Entropy: 1.33479
Value Function Loss: 0.01467

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.13036
Value Function Update Magnitude: 0.15648

Collected Steps per Second: 9816.47402
Overall Steps per Second: 7072.62846

Timestep Collection Time: 5.09704
Timestep Consumption Time: 1.97741
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.07446

Cumulative Model Updates: 22116
Cumulative Timesteps: 184799203

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.09805
Policy Entropy: 1.33607
Value Function Loss: 0.01421

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06062
Policy Update Magnitude: 0.12982
Value Function Update Magnitude: 0.15741

Collected Steps per Second: 10087.27454
Overall Steps per Second: 6900.02954

Timestep Collection Time: 4.95724
Timestep Consumption Time: 2.28983
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.24707

Cumulative Model Updates: 22122
Cumulative Timesteps: 184849208

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.27121
Policy Entropy: 1.33838
Value Function Loss: 0.01359

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.04927
Policy Update Magnitude: 0.12974
Value Function Update Magnitude: 0.15076

Collected Steps per Second: 9427.20106
Overall Steps per Second: 6771.01091

Timestep Collection Time: 5.30762
Timestep Consumption Time: 2.08212
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.38974

Cumulative Model Updates: 22128
Cumulative Timesteps: 184899244

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.91659
Policy Entropy: 1.33732
Value Function Loss: 0.01400

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.12928
Value Function Update Magnitude: 0.14723

Collected Steps per Second: 9746.40246
Overall Steps per Second: 7027.47600

Timestep Collection Time: 5.13041
Timestep Consumption Time: 1.98495
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.11536

Cumulative Model Updates: 22134
Cumulative Timesteps: 184949247

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.81830
Policy Entropy: 1.33657
Value Function Loss: 0.01372

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06074
Policy Update Magnitude: 0.12890
Value Function Update Magnitude: 0.14906

Collected Steps per Second: 9732.88280
Overall Steps per Second: 6869.20151

Timestep Collection Time: 5.14123
Timestep Consumption Time: 2.14331
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.28454

Cumulative Model Updates: 22140
Cumulative Timesteps: 184999286

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.60424
Policy Entropy: 1.33898
Value Function Loss: 0.01372

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05876
Policy Update Magnitude: 0.12932
Value Function Update Magnitude: 0.15630

Collected Steps per Second: 9023.03778
Overall Steps per Second: 6589.20632

Timestep Collection Time: 5.54425
Timestep Consumption Time: 2.04786
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.59211

Cumulative Model Updates: 22146
Cumulative Timesteps: 185049312

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.81342
Policy Entropy: 1.34010
Value Function Loss: 0.01365

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05096
Policy Update Magnitude: 0.13051
Value Function Update Magnitude: 0.15434

Collected Steps per Second: 9650.32624
Overall Steps per Second: 6511.46367

Timestep Collection Time: 5.18532
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.68491

Cumulative Model Updates: 22152
Cumulative Timesteps: 185099352

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.91861
Policy Entropy: 1.33945
Value Function Loss: 0.01373

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.05756
Policy Update Magnitude: 0.13083
Value Function Update Magnitude: 0.14950

Collected Steps per Second: 9535.83306
Overall Steps per Second: 6542.20466

Timestep Collection Time: 5.24401
Timestep Consumption Time: 2.39959
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.64360

Cumulative Model Updates: 22158
Cumulative Timesteps: 185149358

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -16.98028
Policy Entropy: 1.33766
Value Function Loss: 0.01418

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06103
Policy Update Magnitude: 0.13373
Value Function Update Magnitude: 0.15112

Collected Steps per Second: 9083.37958
Overall Steps per Second: 6659.98265

Timestep Collection Time: 5.50632
Timestep Consumption Time: 2.00361
PPO Batch Consumption Time: 0.02499
Total Iteration Time: 7.50993

Cumulative Model Updates: 22164
Cumulative Timesteps: 185199374

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.67590
Policy Entropy: 1.33816
Value Function Loss: 0.01383

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.05923
Policy Update Magnitude: 0.13313
Value Function Update Magnitude: 0.15069

Collected Steps per Second: 9082.11664
Overall Steps per Second: 6589.34315

Timestep Collection Time: 5.50643
Timestep Consumption Time: 2.08310
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.58953

Cumulative Model Updates: 22170
Cumulative Timesteps: 185249384

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 185249384...
Checkpoint 185249384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.87893
Policy Entropy: 1.33747
Value Function Loss: 0.01453

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05257
Policy Update Magnitude: 0.13422
Value Function Update Magnitude: 0.15079

Collected Steps per Second: 9395.60015
Overall Steps per Second: 6624.37214

Timestep Collection Time: 5.32526
Timestep Consumption Time: 2.22776
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.55302

Cumulative Model Updates: 22176
Cumulative Timesteps: 185299418

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.49384
Policy Entropy: 1.33384
Value Function Loss: 0.01490

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.05908
Policy Update Magnitude: 0.13634
Value Function Update Magnitude: 0.15778

Collected Steps per Second: 9451.18543
Overall Steps per Second: 6788.66769

Timestep Collection Time: 5.29087
Timestep Consumption Time: 2.07508
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 7.36595

Cumulative Model Updates: 22182
Cumulative Timesteps: 185349423

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.32659
Policy Entropy: 1.33557
Value Function Loss: 0.01437

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.05988
Policy Update Magnitude: 0.13459
Value Function Update Magnitude: 0.15761

Collected Steps per Second: 9201.42018
Overall Steps per Second: 6583.91257

Timestep Collection Time: 5.43753
Timestep Consumption Time: 2.16175
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.59928

Cumulative Model Updates: 22188
Cumulative Timesteps: 185399456

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.13513
Policy Entropy: 1.33907
Value Function Loss: 0.01385

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.13203
Value Function Update Magnitude: 0.14967

Collected Steps per Second: 9983.69179
Overall Steps per Second: 7141.68278

Timestep Collection Time: 5.00967
Timestep Consumption Time: 1.99358
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.00325

Cumulative Model Updates: 22194
Cumulative Timesteps: 185449471

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.31018
Policy Entropy: 1.34170
Value Function Loss: 0.01288

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.05423
Policy Update Magnitude: 0.12801
Value Function Update Magnitude: 0.15063

Collected Steps per Second: 9958.97228
Overall Steps per Second: 7139.11190

Timestep Collection Time: 5.02301
Timestep Consumption Time: 1.98403
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 7.00703

Cumulative Model Updates: 22200
Cumulative Timesteps: 185499495

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.55336
Policy Entropy: 1.33800
Value Function Loss: 0.01318

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.06494
Policy Update Magnitude: 0.12248
Value Function Update Magnitude: 0.15130

Collected Steps per Second: 9354.86043
Overall Steps per Second: 6743.16537

Timestep Collection Time: 5.34770
Timestep Consumption Time: 2.07122
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 7.41892

Cumulative Model Updates: 22206
Cumulative Timesteps: 185549522

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.17978
Policy Entropy: 1.34340
Value Function Loss: 0.01329

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.12213
Value Function Update Magnitude: 0.15158

Collected Steps per Second: 9833.70976
Overall Steps per Second: 6906.45009

Timestep Collection Time: 5.08496
Timestep Consumption Time: 2.15523
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.24019

Cumulative Model Updates: 22212
Cumulative Timesteps: 185599526

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30882
Policy Entropy: 1.34313
Value Function Loss: 0.01379

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.12427
Value Function Update Magnitude: 0.15388

Collected Steps per Second: 10069.15821
Overall Steps per Second: 7204.97157

Timestep Collection Time: 4.96943
Timestep Consumption Time: 1.97549
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 6.94493

Cumulative Model Updates: 22218
Cumulative Timesteps: 185649564

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.52577
Policy Entropy: 1.34148
Value Function Loss: 0.01337

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06339
Policy Update Magnitude: 0.12100
Value Function Update Magnitude: 0.14994

Collected Steps per Second: 10351.77692
Overall Steps per Second: 7144.24355

Timestep Collection Time: 4.83163
Timestep Consumption Time: 2.16925
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 7.00088

Cumulative Model Updates: 22224
Cumulative Timesteps: 185699580

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.83928
Policy Entropy: 1.33395
Value Function Loss: 0.01283

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.11846
Value Function Update Magnitude: 0.14998

Collected Steps per Second: 10514.95298
Overall Steps per Second: 7354.26163

Timestep Collection Time: 4.75589
Timestep Consumption Time: 2.04397
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 6.79987

Cumulative Model Updates: 22230
Cumulative Timesteps: 185749588

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 185749588...
Checkpoint 185749588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.16566
Policy Entropy: 1.34032
Value Function Loss: 0.01296

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.11940
Value Function Update Magnitude: 0.14973

Collected Steps per Second: 10100.48628
Overall Steps per Second: 7267.29195

Timestep Collection Time: 4.95243
Timestep Consumption Time: 1.93073
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 6.88317

Cumulative Model Updates: 22236
Cumulative Timesteps: 185799610

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.34453
Policy Entropy: 1.33502
Value Function Loss: 0.01310

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.12088
Value Function Update Magnitude: 0.15758

Collected Steps per Second: 10176.34929
Overall Steps per Second: 7259.92222

Timestep Collection Time: 4.91345
Timestep Consumption Time: 1.97381
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 6.88726

Cumulative Model Updates: 22242
Cumulative Timesteps: 185849611

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.89207
Policy Entropy: 1.33896
Value Function Loss: 0.01382

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.12517
Value Function Update Magnitude: 0.16102

Collected Steps per Second: 10613.98588
Overall Steps per Second: 7251.14896

Timestep Collection Time: 4.71152
Timestep Consumption Time: 2.18504
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.89656

Cumulative Model Updates: 22248
Cumulative Timesteps: 185899619

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.73278
Policy Entropy: 1.33351
Value Function Loss: 0.01406

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.12570
Value Function Update Magnitude: 0.15564

Collected Steps per Second: 9921.03720
Overall Steps per Second: 6950.15055

Timestep Collection Time: 5.04342
Timestep Consumption Time: 2.15584
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.19927

Cumulative Model Updates: 22254
Cumulative Timesteps: 185949655

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.96877
Policy Entropy: 1.33535
Value Function Loss: 0.01414

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.12718
Value Function Update Magnitude: 0.15387

Collected Steps per Second: 10037.11775
Overall Steps per Second: 7155.75841

Timestep Collection Time: 4.98490
Timestep Consumption Time: 2.00723
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 6.99213

Cumulative Model Updates: 22260
Cumulative Timesteps: 185999689

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.96696
Policy Entropy: 1.32952
Value Function Loss: 0.01393

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.05901
Policy Update Magnitude: 0.12799
Value Function Update Magnitude: 0.15008

Collected Steps per Second: 10476.97616
Overall Steps per Second: 7259.88740

Timestep Collection Time: 4.77561
Timestep Consumption Time: 2.11623
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 6.89184

Cumulative Model Updates: 22266
Cumulative Timesteps: 186049723

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.13229
Policy Entropy: 1.33524
Value Function Loss: 0.01344

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.05390
Policy Update Magnitude: 0.12547
Value Function Update Magnitude: 0.14695

Collected Steps per Second: 9881.55875
Overall Steps per Second: 7021.40713

Timestep Collection Time: 5.06195
Timestep Consumption Time: 2.06197
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.12393

Cumulative Model Updates: 22272
Cumulative Timesteps: 186099743

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.88738
Policy Entropy: 1.33768
Value Function Loss: 0.01405

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.04518
Policy Update Magnitude: 0.12363
Value Function Update Magnitude: 0.14704

Collected Steps per Second: 9730.32657
Overall Steps per Second: 6852.85151

Timestep Collection Time: 5.13960
Timestep Consumption Time: 2.15809
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.29769

Cumulative Model Updates: 22278
Cumulative Timesteps: 186149753

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.84449
Policy Entropy: 1.33557
Value Function Loss: 0.01405

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.04693
Policy Update Magnitude: 0.12512
Value Function Update Magnitude: 0.14996

Collected Steps per Second: 9663.61144
Overall Steps per Second: 6610.46948

Timestep Collection Time: 5.17498
Timestep Consumption Time: 2.39014
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.56512

Cumulative Model Updates: 22284
Cumulative Timesteps: 186199762

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.88453
Policy Entropy: 1.33663
Value Function Loss: 0.01394

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.05239
Policy Update Magnitude: 0.12631
Value Function Update Magnitude: 0.15019

Collected Steps per Second: 9339.63420
Overall Steps per Second: 6727.66232

Timestep Collection Time: 5.35417
Timestep Consumption Time: 2.07872
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.43289

Cumulative Model Updates: 22290
Cumulative Timesteps: 186249768

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 186249768...
Checkpoint 186249768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.58955
Policy Entropy: 1.33866
Value Function Loss: 0.01328

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05696
Policy Update Magnitude: 0.12699
Value Function Update Magnitude: 0.14920

Collected Steps per Second: 9752.51160
Overall Steps per Second: 6790.81997

Timestep Collection Time: 5.12924
Timestep Consumption Time: 2.23703
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 7.36627

Cumulative Model Updates: 22296
Cumulative Timesteps: 186299791

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.32819
Policy Entropy: 1.34632
Value Function Loss: 0.01317

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05919
Policy Update Magnitude: 0.12232
Value Function Update Magnitude: 0.14445

Collected Steps per Second: 9774.78933
Overall Steps per Second: 6750.11073

Timestep Collection Time: 5.11827
Timestep Consumption Time: 2.29346
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 7.41173

Cumulative Model Updates: 22302
Cumulative Timesteps: 186349821

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.51973
Policy Entropy: 1.34114
Value Function Loss: 0.01367

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.12364
Value Function Update Magnitude: 0.14573

Collected Steps per Second: 9495.55695
Overall Steps per Second: 6792.58123

Timestep Collection Time: 5.26878
Timestep Consumption Time: 2.09661
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.36539

Cumulative Model Updates: 22308
Cumulative Timesteps: 186399851

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.39579
Policy Entropy: 1.34113
Value Function Loss: 0.01331

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.11922
Value Function Update Magnitude: 0.14285

Collected Steps per Second: 9592.81424
Overall Steps per Second: 6899.87845

Timestep Collection Time: 5.21713
Timestep Consumption Time: 2.03618
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.25332

Cumulative Model Updates: 22314
Cumulative Timesteps: 186449898

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.70607
Policy Entropy: 1.33666
Value Function Loss: 0.01325

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.12297
Value Function Update Magnitude: 0.14433

Collected Steps per Second: 9551.41943
Overall Steps per Second: 6621.82554

Timestep Collection Time: 5.23629
Timestep Consumption Time: 2.31661
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 7.55290

Cumulative Model Updates: 22320
Cumulative Timesteps: 186499912

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.71422
Policy Entropy: 1.34022
Value Function Loss: 0.01370

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05257
Policy Update Magnitude: 0.12386
Value Function Update Magnitude: 0.14297

Collected Steps per Second: 9109.47556
Overall Steps per Second: 6600.95443

Timestep Collection Time: 5.49132
Timestep Consumption Time: 2.08683
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.57815

Cumulative Model Updates: 22326
Cumulative Timesteps: 186549935

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.83642
Policy Entropy: 1.33807
Value Function Loss: 0.01349

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.05636
Policy Update Magnitude: 0.12331
Value Function Update Magnitude: 0.14348

Collected Steps per Second: 9533.42499
Overall Steps per Second: 6774.76760

Timestep Collection Time: 5.24533
Timestep Consumption Time: 2.13588
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 7.38121

Cumulative Model Updates: 22332
Cumulative Timesteps: 186599941

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.74936
Policy Entropy: 1.33974
Value Function Loss: 0.01321

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05631
Policy Update Magnitude: 0.12367
Value Function Update Magnitude: 0.14504

Collected Steps per Second: 9848.88009
Overall Steps per Second: 6759.74956

Timestep Collection Time: 5.07784
Timestep Consumption Time: 2.32051
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.39835

Cumulative Model Updates: 22338
Cumulative Timesteps: 186649952

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.26824
Policy Entropy: 1.33682
Value Function Loss: 0.01298

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06054
Policy Update Magnitude: 0.11842
Value Function Update Magnitude: 0.14465

Collected Steps per Second: 9165.77932
Overall Steps per Second: 6650.71018

Timestep Collection Time: 5.45846
Timestep Consumption Time: 2.06420
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.52266

Cumulative Model Updates: 22344
Cumulative Timesteps: 186699983

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.47001
Policy Entropy: 1.33975
Value Function Loss: 0.01345

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.04970
Policy Update Magnitude: 0.12260
Value Function Update Magnitude: 0.14347

Collected Steps per Second: 9444.41938
Overall Steps per Second: 6882.24305

Timestep Collection Time: 5.29805
Timestep Consumption Time: 1.97240
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.27045

Cumulative Model Updates: 22350
Cumulative Timesteps: 186750020

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 186750020...
Checkpoint 186750020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.72148
Policy Entropy: 1.33624
Value Function Loss: 0.01407

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06330
Policy Update Magnitude: 0.12448
Value Function Update Magnitude: 0.14599

Collected Steps per Second: 10387.14255
Overall Steps per Second: 7324.92749

Timestep Collection Time: 4.81682
Timestep Consumption Time: 2.01369
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 6.83051

Cumulative Model Updates: 22356
Cumulative Timesteps: 186800053

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.28636
Policy Entropy: 1.34026
Value Function Loss: 0.01433

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06429
Policy Update Magnitude: 0.12343
Value Function Update Magnitude: 0.14670

Collected Steps per Second: 9592.33381
Overall Steps per Second: 6884.92394

Timestep Collection Time: 5.21270
Timestep Consumption Time: 2.04983
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.26253

Cumulative Model Updates: 22362
Cumulative Timesteps: 186850055

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.66660
Policy Entropy: 1.33927
Value Function Loss: 0.01446

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.12391
Value Function Update Magnitude: 0.15020

Collected Steps per Second: 9537.49727
Overall Steps per Second: 6819.46219

Timestep Collection Time: 5.24456
Timestep Consumption Time: 2.09033
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.33489

Cumulative Model Updates: 22368
Cumulative Timesteps: 186900075

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -3.19475
Policy Entropy: 1.33963
Value Function Loss: 0.01367

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.05495
Policy Update Magnitude: 0.12308
Value Function Update Magnitude: 0.14611

Collected Steps per Second: 9414.15047
Overall Steps per Second: 6685.88155

Timestep Collection Time: 5.31530
Timestep Consumption Time: 2.16898
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 7.48428

Cumulative Model Updates: 22374
Cumulative Timesteps: 186950114

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.22355
Policy Entropy: 1.33840
Value Function Loss: 0.01316

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.05640
Policy Update Magnitude: 0.12037
Value Function Update Magnitude: 0.14094

Collected Steps per Second: 9009.96668
Overall Steps per Second: 6369.45528

Timestep Collection Time: 5.55241
Timestep Consumption Time: 2.30180
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.85420

Cumulative Model Updates: 22380
Cumulative Timesteps: 187000141

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.83050
Policy Entropy: 1.34096
Value Function Loss: 0.01300

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05372
Policy Update Magnitude: 0.11830
Value Function Update Magnitude: 0.14661

Collected Steps per Second: 9172.75326
Overall Steps per Second: 6524.09758

Timestep Collection Time: 5.45452
Timestep Consumption Time: 2.21443
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 7.66895

Cumulative Model Updates: 22386
Cumulative Timesteps: 187050174

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.79548
Policy Entropy: 1.33945
Value Function Loss: 0.01394

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.04934
Policy Update Magnitude: 0.12109
Value Function Update Magnitude: 0.14939

Collected Steps per Second: 9809.83613
Overall Steps per Second: 6887.68576

Timestep Collection Time: 5.09927
Timestep Consumption Time: 2.16340
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 7.26267

Cumulative Model Updates: 22392
Cumulative Timesteps: 187100197

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.54725
Policy Entropy: 1.33840
Value Function Loss: 0.01378

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04441
Policy Update Magnitude: 0.12347
Value Function Update Magnitude: 0.14915

Collected Steps per Second: 9211.45441
Overall Steps per Second: 6576.49734

Timestep Collection Time: 5.43052
Timestep Consumption Time: 2.17581
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.60633

Cumulative Model Updates: 22398
Cumulative Timesteps: 187150220

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.71626
Policy Entropy: 1.33610
Value Function Loss: 0.01338

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.04827
Policy Update Magnitude: 0.12442
Value Function Update Magnitude: 0.15192

Collected Steps per Second: 9335.19415
Overall Steps per Second: 6671.08078

Timestep Collection Time: 5.36004
Timestep Consumption Time: 2.14055
PPO Batch Consumption Time: 0.02457
Total Iteration Time: 7.50058

Cumulative Model Updates: 22404
Cumulative Timesteps: 187200257

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.04810
Policy Entropy: 1.33882
Value Function Loss: 0.01234

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.05245
Policy Update Magnitude: 0.12174
Value Function Update Magnitude: 0.14927

Collected Steps per Second: 10168.68642
Overall Steps per Second: 7188.77729

Timestep Collection Time: 4.91814
Timestep Consumption Time: 2.03868
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 6.95682

Cumulative Model Updates: 22410
Cumulative Timesteps: 187250268

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 187250268...
Checkpoint 187250268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.30479
Policy Entropy: 1.34069
Value Function Loss: 0.01283

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.04817
Policy Update Magnitude: 0.12046
Value Function Update Magnitude: 0.14255

Collected Steps per Second: 9823.11856
Overall Steps per Second: 7200.14832

Timestep Collection Time: 5.09299
Timestep Consumption Time: 1.85534
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 6.94833

Cumulative Model Updates: 22416
Cumulative Timesteps: 187300297

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.85019
Policy Entropy: 1.34055
Value Function Loss: 0.01264

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.04774
Policy Update Magnitude: 0.12098
Value Function Update Magnitude: 0.14338

Collected Steps per Second: 9438.69129
Overall Steps per Second: 6723.84334

Timestep Collection Time: 5.30126
Timestep Consumption Time: 2.14046
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.44173

Cumulative Model Updates: 22422
Cumulative Timesteps: 187350334

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.47433
Policy Entropy: 1.33883
Value Function Loss: 0.01328

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.05370
Policy Update Magnitude: 0.12085
Value Function Update Magnitude: 0.14993

Collected Steps per Second: 9739.79280
Overall Steps per Second: 6798.02626

Timestep Collection Time: 5.13574
Timestep Consumption Time: 2.22243
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.35817

Cumulative Model Updates: 22428
Cumulative Timesteps: 187400355

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.73624
Policy Entropy: 1.33531
Value Function Loss: 0.01360

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05719
Policy Update Magnitude: 0.12189
Value Function Update Magnitude: 0.14397

Collected Steps per Second: 9286.60909
Overall Steps per Second: 6858.12913

Timestep Collection Time: 5.38711
Timestep Consumption Time: 1.90759
PPO Batch Consumption Time: 0.02391
Total Iteration Time: 7.29470

Cumulative Model Updates: 22434
Cumulative Timesteps: 187450383

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.90198
Policy Entropy: 1.33823
Value Function Loss: 0.01429

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.05065
Policy Update Magnitude: 0.12366
Value Function Update Magnitude: 0.14034

Collected Steps per Second: 9909.35858
Overall Steps per Second: 6947.27968

Timestep Collection Time: 5.04876
Timestep Consumption Time: 2.15262
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 7.20138

Cumulative Model Updates: 22440
Cumulative Timesteps: 187500413

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.63505
Policy Entropy: 1.33989
Value Function Loss: 0.01458

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05410
Policy Update Magnitude: 0.12269
Value Function Update Magnitude: 0.14455

Collected Steps per Second: 10526.89626
Overall Steps per Second: 7260.71014

Timestep Collection Time: 4.75306
Timestep Consumption Time: 2.13814
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 6.89120

Cumulative Model Updates: 22446
Cumulative Timesteps: 187550448

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.30517
Policy Entropy: 1.34089
Value Function Loss: 0.01409

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.04933
Policy Update Magnitude: 0.12351
Value Function Update Magnitude: 0.15006

Collected Steps per Second: 9294.40283
Overall Steps per Second: 6644.73767

Timestep Collection Time: 5.38281
Timestep Consumption Time: 2.14646
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.52927

Cumulative Model Updates: 22452
Cumulative Timesteps: 187600478

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.92968
Policy Entropy: 1.33694
Value Function Loss: 0.01377

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05718
Policy Update Magnitude: 0.12198
Value Function Update Magnitude: 0.14741

Collected Steps per Second: 9534.69633
Overall Steps per Second: 6944.45219

Timestep Collection Time: 5.24778
Timestep Consumption Time: 1.95739
PPO Batch Consumption Time: 0.02448
Total Iteration Time: 7.20518

Cumulative Model Updates: 22458
Cumulative Timesteps: 187650514

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.29196
Policy Entropy: 1.33409
Value Function Loss: 0.01390

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.07444
Policy Update Magnitude: 0.12087
Value Function Update Magnitude: 0.14397

Collected Steps per Second: 10441.31337
Overall Steps per Second: 7130.71043

Timestep Collection Time: 4.79308
Timestep Consumption Time: 2.22530
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.01838

Cumulative Model Updates: 22464
Cumulative Timesteps: 187700560

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.49133
Policy Entropy: 1.33725
Value Function Loss: 0.01362

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.05851
Policy Update Magnitude: 0.11967
Value Function Update Magnitude: 0.14173

Collected Steps per Second: 9299.58128
Overall Steps per Second: 6759.07103

Timestep Collection Time: 5.37981
Timestep Consumption Time: 2.02209
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.40190

Cumulative Model Updates: 22470
Cumulative Timesteps: 187750590

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 187750590...
Checkpoint 187750590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.71887
Policy Entropy: 1.33873
Value Function Loss: 0.01442

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.04920
Policy Update Magnitude: 0.12050
Value Function Update Magnitude: 0.14439

Collected Steps per Second: 9347.74407
Overall Steps per Second: 6713.40101

Timestep Collection Time: 5.35295
Timestep Consumption Time: 2.10050
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.45345

Cumulative Model Updates: 22476
Cumulative Timesteps: 187800628

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.80024
Policy Entropy: 1.34022
Value Function Loss: 0.01386

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.04931
Policy Update Magnitude: 0.12270
Value Function Update Magnitude: 0.14794

Collected Steps per Second: 9782.01822
Overall Steps per Second: 6976.59377

Timestep Collection Time: 5.11418
Timestep Consumption Time: 2.05651
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 7.17069

Cumulative Model Updates: 22482
Cumulative Timesteps: 187850655

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.60123
Policy Entropy: 1.34301
Value Function Loss: 0.01398

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05055
Policy Update Magnitude: 0.12278
Value Function Update Magnitude: 0.14725

Collected Steps per Second: 9067.49218
Overall Steps per Second: 6535.23300

Timestep Collection Time: 5.51476
Timestep Consumption Time: 2.13685
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.65160

Cumulative Model Updates: 22488
Cumulative Timesteps: 187900660

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.54526
Policy Entropy: 1.34326
Value Function Loss: 0.01420

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.04569
Policy Update Magnitude: 0.12156
Value Function Update Magnitude: 0.14620

Collected Steps per Second: 9232.15078
Overall Steps per Second: 6677.93838

Timestep Collection Time: 5.41770
Timestep Consumption Time: 2.07219
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.48989

Cumulative Model Updates: 22494
Cumulative Timesteps: 187950677

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.18624
Policy Entropy: 1.34339
Value Function Loss: 0.01348

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.05203
Policy Update Magnitude: 0.12043
Value Function Update Magnitude: 0.14745

Collected Steps per Second: 11267.49269
Overall Steps per Second: 7595.44948

Timestep Collection Time: 4.43843
Timestep Consumption Time: 2.14577
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 6.58421

Cumulative Model Updates: 22500
Cumulative Timesteps: 188000687

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.89460
Policy Entropy: 1.34057
Value Function Loss: 0.01321

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06157
Policy Update Magnitude: 0.12370
Value Function Update Magnitude: 0.14882

Collected Steps per Second: 10379.41527
Overall Steps per Second: 7280.25781

Timestep Collection Time: 4.81964
Timestep Consumption Time: 2.05169
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 6.87132

Cumulative Model Updates: 22506
Cumulative Timesteps: 188050712

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.66194
Policy Entropy: 1.33892
Value Function Loss: 0.01336

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.12562
Value Function Update Magnitude: 0.14742

Collected Steps per Second: 9739.64543
Overall Steps per Second: 6970.62313

Timestep Collection Time: 5.13787
Timestep Consumption Time: 2.04097
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.17884

Cumulative Model Updates: 22512
Cumulative Timesteps: 188100753

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.47403
Policy Entropy: 1.34444
Value Function Loss: 0.01369

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.12029
Value Function Update Magnitude: 0.14824

Collected Steps per Second: 10135.40961
Overall Steps per Second: 7054.31924

Timestep Collection Time: 4.93655
Timestep Consumption Time: 2.15612
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.09268

Cumulative Model Updates: 22518
Cumulative Timesteps: 188150787

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.24733
Policy Entropy: 1.34188
Value Function Loss: 0.01368

Mean KL Divergence: 0.01771
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.11871
Value Function Update Magnitude: 0.15026

Collected Steps per Second: 9262.18723
Overall Steps per Second: 6569.85906

Timestep Collection Time: 5.39991
Timestep Consumption Time: 2.21288
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.61280

Cumulative Model Updates: 22524
Cumulative Timesteps: 188200802

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.37719
Policy Entropy: 1.34546
Value Function Loss: 0.01280

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.12403
Value Function Update Magnitude: 0.15064

Collected Steps per Second: 9851.05068
Overall Steps per Second: 7088.74411

Timestep Collection Time: 5.07753
Timestep Consumption Time: 1.97859
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 7.05612

Cumulative Model Updates: 22530
Cumulative Timesteps: 188250821

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 188250821...
Checkpoint 188250821 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.46274
Policy Entropy: 1.34762
Value Function Loss: 0.01320

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.12387
Value Function Update Magnitude: 0.15116

Collected Steps per Second: 9832.04281
Overall Steps per Second: 6743.35988

Timestep Collection Time: 5.08765
Timestep Consumption Time: 2.33031
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 7.41796

Cumulative Model Updates: 22536
Cumulative Timesteps: 188300843

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.01405
Policy Entropy: 1.34648
Value Function Loss: 0.01316

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.11867
Value Function Update Magnitude: 0.15751

Collected Steps per Second: 9146.66985
Overall Steps per Second: 6612.42788

Timestep Collection Time: 5.46953
Timestep Consumption Time: 2.09622
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 7.56575

Cumulative Model Updates: 22542
Cumulative Timesteps: 188350871

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.69953
Policy Entropy: 1.34561
Value Function Loss: 0.01436

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.05840
Policy Update Magnitude: 0.11556
Value Function Update Magnitude: 0.14863

Collected Steps per Second: 9987.18233
Overall Steps per Second: 7097.56896

Timestep Collection Time: 5.00982
Timestep Consumption Time: 2.03963
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.04946

Cumulative Model Updates: 22548
Cumulative Timesteps: 188400905

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.28673
Policy Entropy: 1.34316
Value Function Loss: 0.01427

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.11793
Value Function Update Magnitude: 0.14410

Collected Steps per Second: 9858.18596
Overall Steps per Second: 7013.74646

Timestep Collection Time: 5.07527
Timestep Consumption Time: 2.05829
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.13356

Cumulative Model Updates: 22554
Cumulative Timesteps: 188450938

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.76444
Policy Entropy: 1.34239
Value Function Loss: 0.01437

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.11956
Value Function Update Magnitude: 0.14561

Collected Steps per Second: 9735.06874
Overall Steps per Second: 6982.27997

Timestep Collection Time: 5.13823
Timestep Consumption Time: 2.02576
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.16399

Cumulative Model Updates: 22560
Cumulative Timesteps: 188500959

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.69093
Policy Entropy: 1.34479
Value Function Loss: 0.01325

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05034
Policy Update Magnitude: 0.12028
Value Function Update Magnitude: 0.14107

Collected Steps per Second: 9169.74380
Overall Steps per Second: 6736.12045

Timestep Collection Time: 5.45381
Timestep Consumption Time: 1.97035
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.42415

Cumulative Model Updates: 22566
Cumulative Timesteps: 188550969

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.35197
Policy Entropy: 1.34086
Value Function Loss: 0.01434

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.04986
Policy Update Magnitude: 0.12546
Value Function Update Magnitude: 0.14140

Collected Steps per Second: 9410.30140
Overall Steps per Second: 6600.24927

Timestep Collection Time: 5.31333
Timestep Consumption Time: 2.26215
PPO Batch Consumption Time: 0.02953
Total Iteration Time: 7.57547

Cumulative Model Updates: 22572
Cumulative Timesteps: 188600969

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.62156
Policy Entropy: 1.34170
Value Function Loss: 0.01374

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.04569
Policy Update Magnitude: 0.13014
Value Function Update Magnitude: 0.14657

Collected Steps per Second: 8916.76101
Overall Steps per Second: 6393.07128

Timestep Collection Time: 5.61033
Timestep Consumption Time: 2.21470
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 7.82503

Cumulative Model Updates: 22578
Cumulative Timesteps: 188650995

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.72543
Policy Entropy: 1.34218
Value Function Loss: 0.01424

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.05087
Policy Update Magnitude: 0.13861
Value Function Update Magnitude: 0.14475

Collected Steps per Second: 9047.75099
Overall Steps per Second: 6616.43226

Timestep Collection Time: 5.52944
Timestep Consumption Time: 2.03189
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 7.56133

Cumulative Model Updates: 22584
Cumulative Timesteps: 188701024

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.27819
Policy Entropy: 1.34137
Value Function Loss: 0.01327

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05798
Policy Update Magnitude: 0.13230
Value Function Update Magnitude: 0.14061

Collected Steps per Second: 10039.53896
Overall Steps per Second: 7046.24995

Timestep Collection Time: 4.98031
Timestep Consumption Time: 2.11566
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.09597

Cumulative Model Updates: 22590
Cumulative Timesteps: 188751024

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 188751024...
Checkpoint 188751024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.58956
Policy Entropy: 1.33874
Value Function Loss: 0.01353

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05024
Policy Update Magnitude: 0.13265
Value Function Update Magnitude: 0.13957

Collected Steps per Second: 9679.96771
Overall Steps per Second: 6751.02718

Timestep Collection Time: 5.16541
Timestep Consumption Time: 2.24102
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.40643

Cumulative Model Updates: 22596
Cumulative Timesteps: 188801025

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.59933
Policy Entropy: 1.33686
Value Function Loss: 0.01347

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05393
Policy Update Magnitude: 0.13027
Value Function Update Magnitude: 0.14206

Collected Steps per Second: 8873.02035
Overall Steps per Second: 6407.71894

Timestep Collection Time: 5.63968
Timestep Consumption Time: 2.16981
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 7.80949

Cumulative Model Updates: 22602
Cumulative Timesteps: 188851066

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.82003
Policy Entropy: 1.33718
Value Function Loss: 0.01385

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.04804
Policy Update Magnitude: 0.12741
Value Function Update Magnitude: 0.14356

Collected Steps per Second: 9866.65734
Overall Steps per Second: 6752.15167

Timestep Collection Time: 5.06940
Timestep Consumption Time: 2.33832
PPO Batch Consumption Time: 0.02966
Total Iteration Time: 7.40771

Cumulative Model Updates: 22608
Cumulative Timesteps: 188901084

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.97029
Policy Entropy: 1.33428
Value Function Loss: 0.01413

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05120
Policy Update Magnitude: 0.12726
Value Function Update Magnitude: 0.15247

Collected Steps per Second: 9017.09537
Overall Steps per Second: 6443.45542

Timestep Collection Time: 5.54824
Timestep Consumption Time: 2.21607
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.76431

Cumulative Model Updates: 22614
Cumulative Timesteps: 188951113

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.52050
Policy Entropy: 1.33674
Value Function Loss: 0.01411

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.12617
Value Function Update Magnitude: 0.15244

Collected Steps per Second: 9155.07460
Overall Steps per Second: 6580.78137

Timestep Collection Time: 5.46233
Timestep Consumption Time: 2.13677
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.59910

Cumulative Model Updates: 22620
Cumulative Timesteps: 189001121

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.97585
Policy Entropy: 1.33402
Value Function Loss: 0.01344

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.12592
Value Function Update Magnitude: 0.14943

Collected Steps per Second: 10263.54905
Overall Steps per Second: 7171.10594

Timestep Collection Time: 4.87366
Timestep Consumption Time: 2.10170
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 6.97535

Cumulative Model Updates: 22626
Cumulative Timesteps: 189051142

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.00464
Policy Entropy: 1.33553
Value Function Loss: 0.01330

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.05952
Policy Update Magnitude: 0.12304
Value Function Update Magnitude: 0.14989

Collected Steps per Second: 10304.04163
Overall Steps per Second: 7188.50202

Timestep Collection Time: 4.85538
Timestep Consumption Time: 2.10435
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 6.95973

Cumulative Model Updates: 22632
Cumulative Timesteps: 189101172

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.48903
Policy Entropy: 1.33565
Value Function Loss: 0.01369

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.12534
Value Function Update Magnitude: 0.14566

Collected Steps per Second: 10326.32288
Overall Steps per Second: 7247.04096

Timestep Collection Time: 4.84635
Timestep Consumption Time: 2.05922
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 6.90558

Cumulative Model Updates: 22638
Cumulative Timesteps: 189151217

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.06041
Policy Entropy: 1.33881
Value Function Loss: 0.01456

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.05733
Policy Update Magnitude: 0.13134
Value Function Update Magnitude: 0.14899

Collected Steps per Second: 10842.15346
Overall Steps per Second: 7593.17910

Timestep Collection Time: 4.61467
Timestep Consumption Time: 1.97453
PPO Batch Consumption Time: 0.02382
Total Iteration Time: 6.58920

Cumulative Model Updates: 22644
Cumulative Timesteps: 189201250

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35078
Policy Entropy: 1.33633
Value Function Loss: 0.01546

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.05497
Policy Update Magnitude: 0.13052
Value Function Update Magnitude: 0.15056

Collected Steps per Second: 9923.13323
Overall Steps per Second: 7131.87586

Timestep Collection Time: 5.04246
Timestep Consumption Time: 1.97351
PPO Batch Consumption Time: 0.02849
Total Iteration Time: 7.01597

Cumulative Model Updates: 22650
Cumulative Timesteps: 189251287

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 189251287...
Checkpoint 189251287 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.91050
Policy Entropy: 1.33346
Value Function Loss: 0.01491

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.13175
Value Function Update Magnitude: 0.15036

Collected Steps per Second: 9888.07813
Overall Steps per Second: 7173.44407

Timestep Collection Time: 5.06104
Timestep Consumption Time: 1.91524
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 6.97629

Cumulative Model Updates: 22656
Cumulative Timesteps: 189301331

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.00095
Policy Entropy: 1.33237
Value Function Loss: 0.01433

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.05849
Policy Update Magnitude: 0.13169
Value Function Update Magnitude: 0.14718

Collected Steps per Second: 10377.95129
Overall Steps per Second: 7292.02859

Timestep Collection Time: 4.81964
Timestep Consumption Time: 2.03963
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.85927

Cumulative Model Updates: 22662
Cumulative Timesteps: 189351349

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36637
Policy Entropy: 1.33663
Value Function Loss: 0.01457

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.05372
Policy Update Magnitude: 0.13333
Value Function Update Magnitude: 0.15104

Collected Steps per Second: 10021.41616
Overall Steps per Second: 7105.29472

Timestep Collection Time: 4.99181
Timestep Consumption Time: 2.04871
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.04052

Cumulative Model Updates: 22668
Cumulative Timesteps: 189401374

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.29817
Policy Entropy: 1.34168
Value Function Loss: 0.01464

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.04729
Policy Update Magnitude: 0.13367
Value Function Update Magnitude: 0.15837

Collected Steps per Second: 9545.56302
Overall Steps per Second: 6586.83278

Timestep Collection Time: 5.24160
Timestep Consumption Time: 2.35447
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.59606

Cumulative Model Updates: 22674
Cumulative Timesteps: 189451408

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.29170
Policy Entropy: 1.34263
Value Function Loss: 0.01519

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.04524
Policy Update Magnitude: 0.13010
Value Function Update Magnitude: 0.15451

Collected Steps per Second: 9580.23000
Overall Steps per Second: 6683.56722

Timestep Collection Time: 5.22221
Timestep Consumption Time: 2.26331
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.48552

Cumulative Model Updates: 22680
Cumulative Timesteps: 189501438

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.92286
Policy Entropy: 1.33957
Value Function Loss: 0.01505

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.05266
Policy Update Magnitude: 0.12751
Value Function Update Magnitude: 0.15718

Collected Steps per Second: 9805.66684
Overall Steps per Second: 6944.60153

Timestep Collection Time: 5.10389
Timestep Consumption Time: 2.10272
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.20660

Cumulative Model Updates: 22686
Cumulative Timesteps: 189551485

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.08566
Policy Entropy: 1.33517
Value Function Loss: 0.01459

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.05212
Policy Update Magnitude: 0.12745
Value Function Update Magnitude: 0.15248

Collected Steps per Second: 9940.21865
Overall Steps per Second: 6602.38392

Timestep Collection Time: 5.03299
Timestep Consumption Time: 2.54443
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 7.57741

Cumulative Model Updates: 22692
Cumulative Timesteps: 189601514

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.57976
Policy Entropy: 1.33409
Value Function Loss: 0.01465

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05315
Policy Update Magnitude: 0.13197
Value Function Update Magnitude: 0.14523

Collected Steps per Second: 9672.74133
Overall Steps per Second: 6895.17900

Timestep Collection Time: 5.16927
Timestep Consumption Time: 2.08232
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.25159

Cumulative Model Updates: 22698
Cumulative Timesteps: 189651515

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.49059
Policy Entropy: 1.33817
Value Function Loss: 0.01407

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.05389
Policy Update Magnitude: 0.13027
Value Function Update Magnitude: 0.14001

Collected Steps per Second: 9684.23141
Overall Steps per Second: 6768.76803

Timestep Collection Time: 5.16778
Timestep Consumption Time: 2.22588
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.39366

Cumulative Model Updates: 22704
Cumulative Timesteps: 189701561

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.61841
Policy Entropy: 1.34049
Value Function Loss: 0.01393

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.12478
Value Function Update Magnitude: 0.14266

Collected Steps per Second: 9406.75364
Overall Steps per Second: 6598.37939

Timestep Collection Time: 5.31820
Timestep Consumption Time: 2.26351
PPO Batch Consumption Time: 0.02990
Total Iteration Time: 7.58171

Cumulative Model Updates: 22710
Cumulative Timesteps: 189751588

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 189751588...
Checkpoint 189751588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.15753
Policy Entropy: 1.34276
Value Function Loss: 0.01313

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.04740
Policy Update Magnitude: 0.12566
Value Function Update Magnitude: 0.14339

Collected Steps per Second: 9649.50681
Overall Steps per Second: 6750.96733

Timestep Collection Time: 5.18617
Timestep Consumption Time: 2.22669
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.41286

Cumulative Model Updates: 22716
Cumulative Timesteps: 189801632

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.73810
Policy Entropy: 1.34000
Value Function Loss: 0.01351

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.05017
Policy Update Magnitude: 0.12485
Value Function Update Magnitude: 0.15059

Collected Steps per Second: 9569.25054
Overall Steps per Second: 6734.17880

Timestep Collection Time: 5.22528
Timestep Consumption Time: 2.19983
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.42511

Cumulative Model Updates: 22722
Cumulative Timesteps: 189851634

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -9.14653
Policy Entropy: 1.33907
Value Function Loss: 0.01438

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.04993
Policy Update Magnitude: 0.12225
Value Function Update Magnitude: 0.15353

Collected Steps per Second: 9146.82619
Overall Steps per Second: 6412.48971

Timestep Collection Time: 5.46758
Timestep Consumption Time: 2.33142
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 7.79900

Cumulative Model Updates: 22728
Cumulative Timesteps: 189901645

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.70028
Policy Entropy: 1.33689
Value Function Loss: 0.01406

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.04790
Policy Update Magnitude: 0.12551
Value Function Update Magnitude: 0.15140

Collected Steps per Second: 9607.66034
Overall Steps per Second: 6798.01511

Timestep Collection Time: 5.20449
Timestep Consumption Time: 2.15104
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 7.35553

Cumulative Model Updates: 22734
Cumulative Timesteps: 189951648

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.30746
Policy Entropy: 1.33377
Value Function Loss: 0.01346

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.12723
Value Function Update Magnitude: 0.15222

Collected Steps per Second: 9174.14723
Overall Steps per Second: 6680.09109

Timestep Collection Time: 5.45424
Timestep Consumption Time: 2.03638
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.49062

Cumulative Model Updates: 22740
Cumulative Timesteps: 190001686

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.85759
Policy Entropy: 1.33629
Value Function Loss: 0.01282

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.12564
Value Function Update Magnitude: 0.15060

Collected Steps per Second: 9603.72717
Overall Steps per Second: 6904.77295

Timestep Collection Time: 5.20683
Timestep Consumption Time: 2.03526
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.24209

Cumulative Model Updates: 22746
Cumulative Timesteps: 190051691

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.31314
Policy Entropy: 1.33808
Value Function Loss: 0.01375

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.05182
Policy Update Magnitude: 0.13065
Value Function Update Magnitude: 0.16662

Collected Steps per Second: 10818.47971
Overall Steps per Second: 7481.28056

Timestep Collection Time: 4.62385
Timestep Consumption Time: 2.06257
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 6.68642

Cumulative Model Updates: 22752
Cumulative Timesteps: 190101714

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.33197
Policy Entropy: 1.34355
Value Function Loss: 0.01388

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05912
Policy Update Magnitude: 0.13075
Value Function Update Magnitude: 0.16244

Collected Steps per Second: 10198.66018
Overall Steps per Second: 7231.31805

Timestep Collection Time: 4.90623
Timestep Consumption Time: 2.01325
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.91949

Cumulative Model Updates: 22758
Cumulative Timesteps: 190151751

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.07409
Policy Entropy: 1.34217
Value Function Loss: 0.01391

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05073
Policy Update Magnitude: 0.12923
Value Function Update Magnitude: 0.15715

Collected Steps per Second: 9615.45840
Overall Steps per Second: 6819.90476

Timestep Collection Time: 5.20402
Timestep Consumption Time: 2.13318
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.33720

Cumulative Model Updates: 22764
Cumulative Timesteps: 190201790

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.03750
Policy Entropy: 1.33668
Value Function Loss: 0.01371

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.06634
Policy Update Magnitude: 0.12681
Value Function Update Magnitude: 0.15201

Collected Steps per Second: 9857.69837
Overall Steps per Second: 6937.25456

Timestep Collection Time: 5.07248
Timestep Consumption Time: 2.13541
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.20789

Cumulative Model Updates: 22770
Cumulative Timesteps: 190251793

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 190251793...
Checkpoint 190251793 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.02856
Policy Entropy: 1.33326
Value Function Loss: 0.01380

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.12550
Value Function Update Magnitude: 0.15673

Collected Steps per Second: 9557.02211
Overall Steps per Second: 6939.40425

Timestep Collection Time: 5.23657
Timestep Consumption Time: 1.97529
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.21186

Cumulative Model Updates: 22776
Cumulative Timesteps: 190301839

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.90516
Policy Entropy: 1.33897
Value Function Loss: 0.01396

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.12928
Value Function Update Magnitude: 0.15109

Collected Steps per Second: 9370.05918
Overall Steps per Second: 6807.85994

Timestep Collection Time: 5.33732
Timestep Consumption Time: 2.00875
PPO Batch Consumption Time: 0.02967
Total Iteration Time: 7.34607

Cumulative Model Updates: 22782
Cumulative Timesteps: 190351850

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.23614
Policy Entropy: 1.33643
Value Function Loss: 0.01354

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.12801
Value Function Update Magnitude: 0.15222

Collected Steps per Second: 10056.62020
Overall Steps per Second: 7156.63878

Timestep Collection Time: 4.97483
Timestep Consumption Time: 2.01588
PPO Batch Consumption Time: 0.02451
Total Iteration Time: 6.99071

Cumulative Model Updates: 22788
Cumulative Timesteps: 190401880

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.21156
Policy Entropy: 1.33549
Value Function Loss: 0.01440

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.13207
Value Function Update Magnitude: 0.15157

Collected Steps per Second: 9716.17448
Overall Steps per Second: 7017.95096

Timestep Collection Time: 5.14678
Timestep Consumption Time: 1.97881
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.12558

Cumulative Model Updates: 22794
Cumulative Timesteps: 190451887

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.19576
Policy Entropy: 1.32875
Value Function Loss: 0.01433

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.13124
Value Function Update Magnitude: 0.15351

Collected Steps per Second: 9548.75986
Overall Steps per Second: 6761.93793

Timestep Collection Time: 5.23880
Timestep Consumption Time: 2.15908
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.39788

Cumulative Model Updates: 22800
Cumulative Timesteps: 190501911

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.78857
Policy Entropy: 1.32686
Value Function Loss: 0.01484

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.05813
Policy Update Magnitude: 0.13035
Value Function Update Magnitude: 0.15769

Collected Steps per Second: 10050.20842
Overall Steps per Second: 7058.06970

Timestep Collection Time: 4.97671
Timestep Consumption Time: 2.10979
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.08650

Cumulative Model Updates: 22806
Cumulative Timesteps: 190551928

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.50020
Policy Entropy: 1.32717
Value Function Loss: 0.01539

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.05987
Policy Update Magnitude: 0.13034
Value Function Update Magnitude: 0.16144

Collected Steps per Second: 9461.96926
Overall Steps per Second: 6558.38613

Timestep Collection Time: 5.28875
Timestep Consumption Time: 2.34148
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.63023

Cumulative Model Updates: 22812
Cumulative Timesteps: 190601970

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.78634
Policy Entropy: 1.32741
Value Function Loss: 0.01592

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06264
Policy Update Magnitude: 0.13226
Value Function Update Magnitude: 0.16226

Collected Steps per Second: 8869.45263
Overall Steps per Second: 6378.82534

Timestep Collection Time: 5.64184
Timestep Consumption Time: 2.20287
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.84470

Cumulative Model Updates: 22818
Cumulative Timesteps: 190652010

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.59059
Policy Entropy: 1.32864
Value Function Loss: 0.01559

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.05935
Policy Update Magnitude: 0.13062
Value Function Update Magnitude: 0.16191

Collected Steps per Second: 10693.49668
Overall Steps per Second: 7285.50576

Timestep Collection Time: 4.67789
Timestep Consumption Time: 2.18821
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 6.86610

Cumulative Model Updates: 22824
Cumulative Timesteps: 190702033

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.68109
Policy Entropy: 1.33167
Value Function Loss: 0.01475

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.13082
Value Function Update Magnitude: 0.16004

Collected Steps per Second: 10197.32369
Overall Steps per Second: 7234.58807

Timestep Collection Time: 4.90335
Timestep Consumption Time: 2.00804
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.91138

Cumulative Model Updates: 22830
Cumulative Timesteps: 190752034

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 190752034...
Checkpoint 190752034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.62283
Policy Entropy: 1.32845
Value Function Loss: 0.01451

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.13164
Value Function Update Magnitude: 0.15641

Collected Steps per Second: 9586.79469
Overall Steps per Second: 6901.26642

Timestep Collection Time: 5.22010
Timestep Consumption Time: 2.03133
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 7.25142

Cumulative Model Updates: 22836
Cumulative Timesteps: 190802078

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.12344
Policy Entropy: 1.33143
Value Function Loss: 0.01412

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06183
Policy Update Magnitude: 0.13222
Value Function Update Magnitude: 0.15739

Collected Steps per Second: 10948.67316
Overall Steps per Second: 7434.64533

Timestep Collection Time: 4.56768
Timestep Consumption Time: 2.15894
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 6.72662

Cumulative Model Updates: 22842
Cumulative Timesteps: 190852088

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.05837
Policy Entropy: 1.32432
Value Function Loss: 0.01491

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.07372
Policy Update Magnitude: 0.13187
Value Function Update Magnitude: 0.16096

Collected Steps per Second: 10142.61960
Overall Steps per Second: 7212.77331

Timestep Collection Time: 4.93285
Timestep Consumption Time: 2.00373
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 6.93658

Cumulative Model Updates: 22848
Cumulative Timesteps: 190902120

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.01073
Policy Entropy: 1.33092
Value Function Loss: 0.01466

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.13474
Value Function Update Magnitude: 0.16416

Collected Steps per Second: 9425.26221
Overall Steps per Second: 6616.19614

Timestep Collection Time: 5.30617
Timestep Consumption Time: 2.25286
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 7.55903

Cumulative Model Updates: 22854
Cumulative Timesteps: 190952132

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.19279
Policy Entropy: 1.33063
Value Function Loss: 0.01438

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.05991
Policy Update Magnitude: 0.13306
Value Function Update Magnitude: 0.15944

Collected Steps per Second: 10487.07589
Overall Steps per Second: 7375.13678

Timestep Collection Time: 4.76873
Timestep Consumption Time: 2.01216
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 6.78089

Cumulative Model Updates: 22860
Cumulative Timesteps: 191002142

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.20056
Policy Entropy: 1.33135
Value Function Loss: 0.01389

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.13190
Value Function Update Magnitude: 0.15397

Collected Steps per Second: 9627.49410
Overall Steps per Second: 6930.59278

Timestep Collection Time: 5.19803
Timestep Consumption Time: 2.02271
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.22074

Cumulative Model Updates: 22866
Cumulative Timesteps: 191052186

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.57981
Policy Entropy: 1.33153
Value Function Loss: 0.01392

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.12955
Value Function Update Magnitude: 0.15687

Collected Steps per Second: 9058.72396
Overall Steps per Second: 6405.87533

Timestep Collection Time: 5.52009
Timestep Consumption Time: 2.28602
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.80612

Cumulative Model Updates: 22872
Cumulative Timesteps: 191102191

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.25589
Policy Entropy: 1.33063
Value Function Loss: 0.01515

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.12617
Value Function Update Magnitude: 0.15722

Collected Steps per Second: 10198.02099
Overall Steps per Second: 7106.80137

Timestep Collection Time: 4.90674
Timestep Consumption Time: 2.13427
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.04100

Cumulative Model Updates: 22878
Cumulative Timesteps: 191152230

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.04946
Policy Entropy: 1.32990
Value Function Loss: 0.01498

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.05765
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.15633

Collected Steps per Second: 9407.61489
Overall Steps per Second: 6744.19630

Timestep Collection Time: 5.31654
Timestep Consumption Time: 2.09961
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.41615

Cumulative Model Updates: 22884
Cumulative Timesteps: 191202246

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.88891
Policy Entropy: 1.32670
Value Function Loss: 0.01432

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.05336
Policy Update Magnitude: 0.12799
Value Function Update Magnitude: 0.16375

Collected Steps per Second: 9560.46902
Overall Steps per Second: 6879.69509

Timestep Collection Time: 5.23154
Timestep Consumption Time: 2.03855
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.27009

Cumulative Model Updates: 22890
Cumulative Timesteps: 191252262

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 191252262...
Checkpoint 191252262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.97280
Policy Entropy: 1.32763
Value Function Loss: 0.01365

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05534
Policy Update Magnitude: 0.13048
Value Function Update Magnitude: 0.15981

Collected Steps per Second: 10145.42749
Overall Steps per Second: 7244.45119

Timestep Collection Time: 4.93010
Timestep Consumption Time: 1.97422
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 6.90432

Cumulative Model Updates: 22896
Cumulative Timesteps: 191302280

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.61659
Policy Entropy: 1.32760
Value Function Loss: 0.01359

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06206
Policy Update Magnitude: 0.12965
Value Function Update Magnitude: 0.15534

Collected Steps per Second: 9206.71794
Overall Steps per Second: 6560.16155

Timestep Collection Time: 5.43190
Timestep Consumption Time: 2.19138
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 7.62329

Cumulative Model Updates: 22902
Cumulative Timesteps: 191352290

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.35032
Policy Entropy: 1.32812
Value Function Loss: 0.01393

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.06544
Policy Update Magnitude: 0.12431
Value Function Update Magnitude: 0.15192

Collected Steps per Second: 9024.28179
Overall Steps per Second: 6475.27892

Timestep Collection Time: 5.54260
Timestep Consumption Time: 2.18185
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.72445

Cumulative Model Updates: 22908
Cumulative Timesteps: 191402308

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.81691
Policy Entropy: 1.33050
Value Function Loss: 0.01405

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05618
Policy Update Magnitude: 0.12505
Value Function Update Magnitude: 0.14592

Collected Steps per Second: 10403.87986
Overall Steps per Second: 7084.81353

Timestep Collection Time: 4.80888
Timestep Consumption Time: 2.25285
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.06172

Cumulative Model Updates: 22914
Cumulative Timesteps: 191452339

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.56482
Policy Entropy: 1.33051
Value Function Loss: 0.01459

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.05422
Policy Update Magnitude: 0.13001
Value Function Update Magnitude: 0.15028

Collected Steps per Second: 10091.49698
Overall Steps per Second: 6932.98259

Timestep Collection Time: 4.95595
Timestep Consumption Time: 2.25782
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.21378

Cumulative Model Updates: 22920
Cumulative Timesteps: 191502352

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.67168
Policy Entropy: 1.32965
Value Function Loss: 0.01498

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.05351
Policy Update Magnitude: 0.13395
Value Function Update Magnitude: 0.15936

Collected Steps per Second: 8814.10216
Overall Steps per Second: 6400.22871

Timestep Collection Time: 5.67443
Timestep Consumption Time: 2.14014
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.81456

Cumulative Model Updates: 22926
Cumulative Timesteps: 191552367

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.60118
Policy Entropy: 1.32961
Value Function Loss: 0.01486

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05626
Policy Update Magnitude: 0.13609
Value Function Update Magnitude: 0.16294

Collected Steps per Second: 10664.05901
Overall Steps per Second: 7220.83817

Timestep Collection Time: 4.69183
Timestep Consumption Time: 2.23728
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.92911

Cumulative Model Updates: 22932
Cumulative Timesteps: 191602401

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.84090
Policy Entropy: 1.32998
Value Function Loss: 0.01443

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05745
Policy Update Magnitude: 0.12815
Value Function Update Magnitude: 0.15959

Collected Steps per Second: 9235.47941
Overall Steps per Second: 6447.73857

Timestep Collection Time: 5.41564
Timestep Consumption Time: 2.34150
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 7.75714

Cumulative Model Updates: 22938
Cumulative Timesteps: 191652417

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.93583
Policy Entropy: 1.33523
Value Function Loss: 0.01394

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.05229
Policy Update Magnitude: 0.12677
Value Function Update Magnitude: 0.15770

Collected Steps per Second: 8744.51482
Overall Steps per Second: 6346.10279

Timestep Collection Time: 5.71787
Timestep Consumption Time: 2.16098
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 7.87885

Cumulative Model Updates: 22944
Cumulative Timesteps: 191702417

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.17393
Policy Entropy: 1.33760
Value Function Loss: 0.01362

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05088
Policy Update Magnitude: 0.12480
Value Function Update Magnitude: 0.15093

Collected Steps per Second: 10224.96869
Overall Steps per Second: 7158.31152

Timestep Collection Time: 4.89273
Timestep Consumption Time: 2.09607
PPO Batch Consumption Time: 0.02462
Total Iteration Time: 6.98880

Cumulative Model Updates: 22950
Cumulative Timesteps: 191752445

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 191752445...
Checkpoint 191752445 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.24516
Policy Entropy: 1.33638
Value Function Loss: 0.01348

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05019
Policy Update Magnitude: 0.12999
Value Function Update Magnitude: 0.14471

Collected Steps per Second: 9661.99034
Overall Steps per Second: 6910.04807

Timestep Collection Time: 5.17957
Timestep Consumption Time: 2.06278
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 7.24235

Cumulative Model Updates: 22956
Cumulative Timesteps: 191802490

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.43944
Policy Entropy: 1.33630
Value Function Loss: 0.01381

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.12948
Value Function Update Magnitude: 0.14432

Collected Steps per Second: 9528.36581
Overall Steps per Second: 6853.43831

Timestep Collection Time: 5.24980
Timestep Consumption Time: 2.04902
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.29882

Cumulative Model Updates: 22962
Cumulative Timesteps: 191852512

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.06298
Policy Entropy: 1.33304
Value Function Loss: 0.01406

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.05692
Policy Update Magnitude: 0.13237
Value Function Update Magnitude: 0.14696

Collected Steps per Second: 10718.71374
Overall Steps per Second: 7319.21464

Timestep Collection Time: 4.66549
Timestep Consumption Time: 2.16694
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 6.83243

Cumulative Model Updates: 22968
Cumulative Timesteps: 191902520

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.46380
Policy Entropy: 1.33403
Value Function Loss: 0.01427

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.13136
Value Function Update Magnitude: 0.15263

Collected Steps per Second: 9303.63190
Overall Steps per Second: 6692.55043

Timestep Collection Time: 5.37811
Timestep Consumption Time: 2.09826
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 7.47637

Cumulative Model Updates: 22974
Cumulative Timesteps: 191952556

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.83526
Policy Entropy: 1.33599
Value Function Loss: 0.01419

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.12704
Value Function Update Magnitude: 0.15407

Collected Steps per Second: 9389.48995
Overall Steps per Second: 6758.66831

Timestep Collection Time: 5.32777
Timestep Consumption Time: 2.07384
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 7.40161

Cumulative Model Updates: 22980
Cumulative Timesteps: 192002581

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.43655
Policy Entropy: 1.33297
Value Function Loss: 0.01410

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.12828
Value Function Update Magnitude: 0.14990

Collected Steps per Second: 10635.55766
Overall Steps per Second: 7305.12118

Timestep Collection Time: 4.70347
Timestep Consumption Time: 2.14433
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 6.84780

Cumulative Model Updates: 22986
Cumulative Timesteps: 192052605

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.39616
Policy Entropy: 1.33327
Value Function Loss: 0.01469

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.12683
Value Function Update Magnitude: 0.15804

Collected Steps per Second: 9327.97748
Overall Steps per Second: 6559.05229

Timestep Collection Time: 5.36504
Timestep Consumption Time: 2.26487
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 7.62991

Cumulative Model Updates: 22992
Cumulative Timesteps: 192102650

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.80316
Policy Entropy: 1.33160
Value Function Loss: 0.01438

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.12644
Value Function Update Magnitude: 0.16420

Collected Steps per Second: 9604.93026
Overall Steps per Second: 6898.89437

Timestep Collection Time: 5.20826
Timestep Consumption Time: 2.04290
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 7.25116

Cumulative Model Updates: 22998
Cumulative Timesteps: 192152675

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.23807
Policy Entropy: 1.33050
Value Function Loss: 0.01424

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05539
Policy Update Magnitude: 0.12606
Value Function Update Magnitude: 0.16638

Collected Steps per Second: 9845.47303
Overall Steps per Second: 6984.09895

Timestep Collection Time: 5.08183
Timestep Consumption Time: 2.08202
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.16384

Cumulative Model Updates: 23004
Cumulative Timesteps: 192202708

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.54328
Policy Entropy: 1.32705
Value Function Loss: 0.01316

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06554
Policy Update Magnitude: 0.12462
Value Function Update Magnitude: 0.16491

Collected Steps per Second: 9305.50078
Overall Steps per Second: 6760.83458

Timestep Collection Time: 5.37327
Timestep Consumption Time: 2.02241
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.39568

Cumulative Model Updates: 23010
Cumulative Timesteps: 192252709

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 192252709...
Checkpoint 192252709 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.14040
Policy Entropy: 1.32324
Value Function Loss: 0.01292

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07115
Policy Update Magnitude: 0.12239
Value Function Update Magnitude: 0.16279

Collected Steps per Second: 9734.32523
Overall Steps per Second: 6902.76586

Timestep Collection Time: 5.13780
Timestep Consumption Time: 2.10756
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.24536

Cumulative Model Updates: 23016
Cumulative Timesteps: 192302722

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.56856
Policy Entropy: 1.33037
Value Function Loss: 0.01290

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.11984
Value Function Update Magnitude: 0.16104

Collected Steps per Second: 9497.91637
Overall Steps per Second: 6630.99213

Timestep Collection Time: 5.26631
Timestep Consumption Time: 2.27690
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 7.54322

Cumulative Model Updates: 23022
Cumulative Timesteps: 192352741

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.22793
Policy Entropy: 1.32976
Value Function Loss: 0.01349

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05248
Policy Update Magnitude: 0.12061
Value Function Update Magnitude: 0.15092

Collected Steps per Second: 8894.85778
Overall Steps per Second: 6369.49287

Timestep Collection Time: 5.62336
Timestep Consumption Time: 2.22954
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.85290

Cumulative Model Updates: 23028
Cumulative Timesteps: 192402760

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.61197
Policy Entropy: 1.32758
Value Function Loss: 0.01456

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.05336
Policy Update Magnitude: 0.12641
Value Function Update Magnitude: 0.15178

Collected Steps per Second: 9735.41203
Overall Steps per Second: 7054.22048

Timestep Collection Time: 5.13712
Timestep Consumption Time: 1.95253
PPO Batch Consumption Time: 0.02849
Total Iteration Time: 7.08966

Cumulative Model Updates: 23034
Cumulative Timesteps: 192452772

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.88620
Policy Entropy: 1.32434
Value Function Loss: 0.01448

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06094
Policy Update Magnitude: 0.13465
Value Function Update Magnitude: 0.15541

Collected Steps per Second: 10532.06776
Overall Steps per Second: 7172.18878

Timestep Collection Time: 4.74817
Timestep Consumption Time: 2.22432
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 6.97249

Cumulative Model Updates: 23040
Cumulative Timesteps: 192502780

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.66400
Policy Entropy: 1.32270
Value Function Loss: 0.01433

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.13037
Value Function Update Magnitude: 0.15535

Collected Steps per Second: 9390.91042
Overall Steps per Second: 6851.39866

Timestep Collection Time: 5.32760
Timestep Consumption Time: 1.97471
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.30230

Cumulative Model Updates: 23046
Cumulative Timesteps: 192552811

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.26975
Policy Entropy: 1.32414
Value Function Loss: 0.01419

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.12865
Value Function Update Magnitude: 0.15504

Collected Steps per Second: 9799.46410
Overall Steps per Second: 6993.01245

Timestep Collection Time: 5.10426
Timestep Consumption Time: 2.04845
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.15271

Cumulative Model Updates: 23052
Cumulative Timesteps: 192602830

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.91854
Policy Entropy: 1.32477
Value Function Loss: 0.01386

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.12619
Value Function Update Magnitude: 0.15495

Collected Steps per Second: 10866.63626
Overall Steps per Second: 7356.63974

Timestep Collection Time: 4.60492
Timestep Consumption Time: 2.19710
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 6.80202

Cumulative Model Updates: 23058
Cumulative Timesteps: 192652870

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.80140
Policy Entropy: 1.32718
Value Function Loss: 0.01420

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06466
Policy Update Magnitude: 0.12208
Value Function Update Magnitude: 0.15341

Collected Steps per Second: 9255.18725
Overall Steps per Second: 6742.06880

Timestep Collection Time: 5.40551
Timestep Consumption Time: 2.01491
PPO Batch Consumption Time: 0.03040
Total Iteration Time: 7.42042

Cumulative Model Updates: 23064
Cumulative Timesteps: 192702899

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.95433
Policy Entropy: 1.32430
Value Function Loss: 0.01352

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.12012
Value Function Update Magnitude: 0.14968

Collected Steps per Second: 9497.02135
Overall Steps per Second: 6870.81561

Timestep Collection Time: 5.26713
Timestep Consumption Time: 2.01323
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.28036

Cumulative Model Updates: 23070
Cumulative Timesteps: 192752921

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 192752921...
Checkpoint 192752921 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.93996
Policy Entropy: 1.32566
Value Function Loss: 0.01396

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.05693
Policy Update Magnitude: 0.12003
Value Function Update Magnitude: 0.14909

Collected Steps per Second: 10191.06218
Overall Steps per Second: 7079.77402

Timestep Collection Time: 4.90763
Timestep Consumption Time: 2.15672
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.06435

Cumulative Model Updates: 23076
Cumulative Timesteps: 192802935

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.34375
Policy Entropy: 1.32570
Value Function Loss: 0.01394

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06479
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.15167

Collected Steps per Second: 9121.72209
Overall Steps per Second: 6591.04476

Timestep Collection Time: 5.48307
Timestep Consumption Time: 2.10526
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.58833

Cumulative Model Updates: 23082
Cumulative Timesteps: 192852950

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.68215
Policy Entropy: 1.32605
Value Function Loss: 0.01439

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.12489
Value Function Update Magnitude: 0.16105

Collected Steps per Second: 9190.15292
Overall Steps per Second: 6676.17481

Timestep Collection Time: 5.44528
Timestep Consumption Time: 2.05047
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.49576

Cumulative Model Updates: 23088
Cumulative Timesteps: 192902993

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.04447
Policy Entropy: 1.32483
Value Function Loss: 0.01342

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.12456
Value Function Update Magnitude: 0.16222

Collected Steps per Second: 9596.59185
Overall Steps per Second: 6882.42677

Timestep Collection Time: 5.21081
Timestep Consumption Time: 2.05494
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.26575

Cumulative Model Updates: 23094
Cumulative Timesteps: 192952999

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.32624
Policy Entropy: 1.32551
Value Function Loss: 0.01340

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.12510
Value Function Update Magnitude: 0.15648

Collected Steps per Second: 9558.42296
Overall Steps per Second: 6849.96595

Timestep Collection Time: 5.23486
Timestep Consumption Time: 2.06985
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 7.30471

Cumulative Model Updates: 23100
Cumulative Timesteps: 193003036

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.79245
Policy Entropy: 1.32477
Value Function Loss: 0.01348

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.12606
Value Function Update Magnitude: 0.15915

Collected Steps per Second: 10030.91936
Overall Steps per Second: 7254.60580

Timestep Collection Time: 4.98708
Timestep Consumption Time: 1.90854
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.89562

Cumulative Model Updates: 23106
Cumulative Timesteps: 193053061

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.62363
Policy Entropy: 1.32083
Value Function Loss: 0.01379

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05724
Policy Update Magnitude: 0.12924
Value Function Update Magnitude: 0.16354

Collected Steps per Second: 10016.92373
Overall Steps per Second: 7064.39541

Timestep Collection Time: 4.99445
Timestep Consumption Time: 2.08740
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.08185

Cumulative Model Updates: 23112
Cumulative Timesteps: 193103090

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.22123
Policy Entropy: 1.31989
Value Function Loss: 0.01398

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.13018
Value Function Update Magnitude: 0.16641

Collected Steps per Second: 9229.29858
Overall Steps per Second: 6712.08070

Timestep Collection Time: 5.41937
Timestep Consumption Time: 2.03242
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.45179

Cumulative Model Updates: 23118
Cumulative Timesteps: 193153107

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.91663
Policy Entropy: 1.31913
Value Function Loss: 0.01414

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.06681
Policy Update Magnitude: 0.13023
Value Function Update Magnitude: 0.16691

Collected Steps per Second: 9803.30225
Overall Steps per Second: 6969.32794

Timestep Collection Time: 5.10389
Timestep Consumption Time: 2.07542
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.17931

Cumulative Model Updates: 23124
Cumulative Timesteps: 193203142

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.58381
Policy Entropy: 1.32390
Value Function Loss: 0.01437

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.12543
Value Function Update Magnitude: 0.16405

Collected Steps per Second: 11005.61635
Overall Steps per Second: 7412.14315

Timestep Collection Time: 4.54313
Timestep Consumption Time: 2.20255
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 6.74569

Cumulative Model Updates: 23130
Cumulative Timesteps: 193253142

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 193253142...
Checkpoint 193253142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.81689
Policy Entropy: 1.32665
Value Function Loss: 0.01360

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.04609
Policy Update Magnitude: 0.12798
Value Function Update Magnitude: 0.15733

Collected Steps per Second: 9383.76077
Overall Steps per Second: 6747.64687

Timestep Collection Time: 5.32931
Timestep Consumption Time: 2.08201
PPO Batch Consumption Time: 0.02435
Total Iteration Time: 7.41132

Cumulative Model Updates: 23136
Cumulative Timesteps: 193303151

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.28178
Policy Entropy: 1.32732
Value Function Loss: 0.01320

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05227
Policy Update Magnitude: 0.12636
Value Function Update Magnitude: 0.15547

Collected Steps per Second: 9753.79324
Overall Steps per Second: 7022.28959

Timestep Collection Time: 5.13031
Timestep Consumption Time: 1.99557
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.12588

Cumulative Model Updates: 23142
Cumulative Timesteps: 193353191

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.14612
Policy Entropy: 1.32552
Value Function Loss: 0.01293

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.05723
Policy Update Magnitude: 0.12619
Value Function Update Magnitude: 0.15722

Collected Steps per Second: 9584.13502
Overall Steps per Second: 6658.06396

Timestep Collection Time: 5.21925
Timestep Consumption Time: 2.29374
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 7.51299

Cumulative Model Updates: 23148
Cumulative Timesteps: 193403213

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.59664
Policy Entropy: 1.32513
Value Function Loss: 0.01396

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05833
Policy Update Magnitude: 0.12723
Value Function Update Magnitude: 0.16510

Collected Steps per Second: 8944.95027
Overall Steps per Second: 6501.79760

Timestep Collection Time: 5.59019
Timestep Consumption Time: 2.10060
PPO Batch Consumption Time: 0.02431
Total Iteration Time: 7.69080

Cumulative Model Updates: 23154
Cumulative Timesteps: 193453217

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.82578
Policy Entropy: 1.32594
Value Function Loss: 0.01389

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.05647
Policy Update Magnitude: 0.12575
Value Function Update Magnitude: 0.16737

Collected Steps per Second: 9527.23728
Overall Steps per Second: 6821.94939

Timestep Collection Time: 5.24822
Timestep Consumption Time: 2.08121
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.32943

Cumulative Model Updates: 23160
Cumulative Timesteps: 193503218

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.69535
Policy Entropy: 1.32602
Value Function Loss: 0.01398

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.04489
Policy Update Magnitude: 0.12675
Value Function Update Magnitude: 0.16797

Collected Steps per Second: 10303.19235
Overall Steps per Second: 7191.21155

Timestep Collection Time: 4.85519
Timestep Consumption Time: 2.10107
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 6.95627

Cumulative Model Updates: 23166
Cumulative Timesteps: 193553242

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.29210
Policy Entropy: 1.32470
Value Function Loss: 0.01361

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.13007
Value Function Update Magnitude: 0.16694

Collected Steps per Second: 9336.70893
Overall Steps per Second: 6718.90562

Timestep Collection Time: 5.35724
Timestep Consumption Time: 2.08727
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.44452

Cumulative Model Updates: 23172
Cumulative Timesteps: 193603261

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.53925
Policy Entropy: 1.32222
Value Function Loss: 0.01379

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06108
Policy Update Magnitude: 0.13202
Value Function Update Magnitude: 0.16362

Collected Steps per Second: 9550.14081
Overall Steps per Second: 6837.90019

Timestep Collection Time: 5.24024
Timestep Consumption Time: 2.07853
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.31877

Cumulative Model Updates: 23178
Cumulative Timesteps: 193653306

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.55678
Policy Entropy: 1.32329
Value Function Loss: 0.01376

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.13140
Value Function Update Magnitude: 0.16486

Collected Steps per Second: 9581.71320
Overall Steps per Second: 6719.14512

Timestep Collection Time: 5.22099
Timestep Consumption Time: 2.22431
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.44529

Cumulative Model Updates: 23184
Cumulative Timesteps: 193703332

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.15594
Policy Entropy: 1.32609
Value Function Loss: 0.01307

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06292
Policy Update Magnitude: 0.13092
Value Function Update Magnitude: 0.16379

Collected Steps per Second: 8938.17006
Overall Steps per Second: 6339.88926

Timestep Collection Time: 5.59667
Timestep Consumption Time: 2.29369
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.89036

Cumulative Model Updates: 23190
Cumulative Timesteps: 193753356

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 193753356...
Checkpoint 193753356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.32559
Policy Entropy: 1.32661
Value Function Loss: 0.01354

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.05777
Policy Update Magnitude: 0.14197
Value Function Update Magnitude: 0.16368

Collected Steps per Second: 9071.07254
Overall Steps per Second: 6699.66110

Timestep Collection Time: 5.51434
Timestep Consumption Time: 1.95186
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 7.46620

Cumulative Model Updates: 23196
Cumulative Timesteps: 193803377

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.93326
Policy Entropy: 1.32413
Value Function Loss: 0.01408

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.15251
Value Function Update Magnitude: 0.16397

Collected Steps per Second: 9937.48001
Overall Steps per Second: 6895.73174

Timestep Collection Time: 5.03156
Timestep Consumption Time: 2.21945
PPO Batch Consumption Time: 0.02432
Total Iteration Time: 7.25101

Cumulative Model Updates: 23202
Cumulative Timesteps: 193853378

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.57107
Policy Entropy: 1.32106
Value Function Loss: 0.01535

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.14628
Value Function Update Magnitude: 0.16233

Collected Steps per Second: 9236.13209
Overall Steps per Second: 6507.54756

Timestep Collection Time: 5.41406
Timestep Consumption Time: 2.27009
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 7.68415

Cumulative Model Updates: 23208
Cumulative Timesteps: 193903383

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.72805
Policy Entropy: 1.32117
Value Function Loss: 0.01559

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.14372
Value Function Update Magnitude: 0.16804

Collected Steps per Second: 8910.80311
Overall Steps per Second: 6387.18895

Timestep Collection Time: 5.61532
Timestep Consumption Time: 2.21864
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.83396

Cumulative Model Updates: 23214
Cumulative Timesteps: 193953420

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.91088
Policy Entropy: 1.31596
Value Function Loss: 0.01523

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.14154
Value Function Update Magnitude: 0.16809

Collected Steps per Second: 9794.80925
Overall Steps per Second: 6917.75014

Timestep Collection Time: 5.10883
Timestep Consumption Time: 2.12474
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.23357

Cumulative Model Updates: 23220
Cumulative Timesteps: 194003460

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.49072
Policy Entropy: 1.31683
Value Function Loss: 0.01478

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.13886
Value Function Update Magnitude: 0.16563

Collected Steps per Second: 10166.99593
Overall Steps per Second: 7147.16542

Timestep Collection Time: 4.91984
Timestep Consumption Time: 2.07874
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 6.99858

Cumulative Model Updates: 23226
Cumulative Timesteps: 194053480

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.00380
Policy Entropy: 1.31454
Value Function Loss: 0.01494

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06684
Policy Update Magnitude: 0.14703
Value Function Update Magnitude: 0.16912

Collected Steps per Second: 9812.98035
Overall Steps per Second: 7094.82055

Timestep Collection Time: 5.09601
Timestep Consumption Time: 1.95238
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.04838

Cumulative Model Updates: 23232
Cumulative Timesteps: 194103487

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44855
Policy Entropy: 1.32075
Value Function Loss: 0.01542

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.15196
Value Function Update Magnitude: 0.16433

Collected Steps per Second: 10069.54437
Overall Steps per Second: 7085.50225

Timestep Collection Time: 4.96845
Timestep Consumption Time: 2.09245
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.06090

Cumulative Model Updates: 23238
Cumulative Timesteps: 194153517

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.72685
Policy Entropy: 1.31956
Value Function Loss: 0.01562

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.06606
Policy Update Magnitude: 0.15514
Value Function Update Magnitude: 0.16451

Collected Steps per Second: 9743.78839
Overall Steps per Second: 7029.64228

Timestep Collection Time: 5.13455
Timestep Consumption Time: 1.98245
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.11701

Cumulative Model Updates: 23244
Cumulative Timesteps: 194203547

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.36597
Policy Entropy: 1.32345
Value Function Loss: 0.01504

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.05456
Policy Update Magnitude: 0.15144
Value Function Update Magnitude: 0.16751

Collected Steps per Second: 9951.83266
Overall Steps per Second: 7147.08644

Timestep Collection Time: 5.02581
Timestep Consumption Time: 1.97229
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 6.99810

Cumulative Model Updates: 23250
Cumulative Timesteps: 194253563

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 194253563...
Checkpoint 194253563 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.82531
Policy Entropy: 1.31879
Value Function Loss: 0.01496

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.14680
Value Function Update Magnitude: 0.16725

Collected Steps per Second: 10494.42651
Overall Steps per Second: 7393.73216

Timestep Collection Time: 4.76624
Timestep Consumption Time: 1.99881
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.76505

Cumulative Model Updates: 23256
Cumulative Timesteps: 194303582

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.75435
Policy Entropy: 1.31752
Value Function Loss: 0.01441

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.14484
Value Function Update Magnitude: 0.16981

Collected Steps per Second: 10002.48788
Overall Steps per Second: 7143.61847

Timestep Collection Time: 4.99966
Timestep Consumption Time: 2.00086
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.00051

Cumulative Model Updates: 23262
Cumulative Timesteps: 194353591

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.61367
Policy Entropy: 1.31782
Value Function Loss: 0.01430

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.13852
Value Function Update Magnitude: 0.16780

Collected Steps per Second: 9896.50688
Overall Steps per Second: 7094.41948

Timestep Collection Time: 5.05552
Timestep Consumption Time: 1.99678
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.05230

Cumulative Model Updates: 23268
Cumulative Timesteps: 194403623

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.23754
Policy Entropy: 1.32100
Value Function Loss: 0.01373

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.13368
Value Function Update Magnitude: 0.16149

Collected Steps per Second: 9894.11579
Overall Steps per Second: 6895.80680

Timestep Collection Time: 5.05482
Timestep Consumption Time: 2.19785
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.25267

Cumulative Model Updates: 23274
Cumulative Timesteps: 194453636

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.84053
Policy Entropy: 1.31704
Value Function Loss: 0.01480

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.13567
Value Function Update Magnitude: 0.16392

Collected Steps per Second: 9432.89585
Overall Steps per Second: 6777.52986

Timestep Collection Time: 5.30463
Timestep Consumption Time: 2.07830
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 7.38293

Cumulative Model Updates: 23280
Cumulative Timesteps: 194503674

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.63831
Policy Entropy: 1.31986
Value Function Loss: 0.01441

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.14120
Value Function Update Magnitude: 0.16584

Collected Steps per Second: 9948.04340
Overall Steps per Second: 7012.69058

Timestep Collection Time: 5.02792
Timestep Consumption Time: 2.10457
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.13250

Cumulative Model Updates: 23286
Cumulative Timesteps: 194553692

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.91279
Policy Entropy: 1.32481
Value Function Loss: 0.01419

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.14146
Value Function Update Magnitude: 0.16568

Collected Steps per Second: 10516.65597
Overall Steps per Second: 7226.19696

Timestep Collection Time: 4.75541
Timestep Consumption Time: 2.16538
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 6.92079

Cumulative Model Updates: 23292
Cumulative Timesteps: 194603703

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.76016
Policy Entropy: 1.32849
Value Function Loss: 0.01476

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06128
Policy Update Magnitude: 0.13839
Value Function Update Magnitude: 0.16505

Collected Steps per Second: 9274.34585
Overall Steps per Second: 6497.32995

Timestep Collection Time: 5.39542
Timestep Consumption Time: 2.30605
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 7.70147

Cumulative Model Updates: 23298
Cumulative Timesteps: 194653742

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -27.46958
Policy Entropy: 1.32920
Value Function Loss: 0.01491

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05277
Policy Update Magnitude: 0.13635
Value Function Update Magnitude: 0.16300

Collected Steps per Second: 9089.74631
Overall Steps per Second: 6491.85417

Timestep Collection Time: 5.50125
Timestep Consumption Time: 2.20148
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.70273

Cumulative Model Updates: 23304
Cumulative Timesteps: 194703747

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.06762
Policy Entropy: 1.32754
Value Function Loss: 0.01537

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.13537
Value Function Update Magnitude: 0.16445

Collected Steps per Second: 9538.87170
Overall Steps per Second: 6701.27116

Timestep Collection Time: 5.24349
Timestep Consumption Time: 2.22032
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 7.46381

Cumulative Model Updates: 23310
Cumulative Timesteps: 194753764

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 194753764...
Checkpoint 194753764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.41768
Policy Entropy: 1.32929
Value Function Loss: 0.01443

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05266
Policy Update Magnitude: 0.12999
Value Function Update Magnitude: 0.16096

Collected Steps per Second: 8891.21936
Overall Steps per Second: 6455.79605

Timestep Collection Time: 5.62769
Timestep Consumption Time: 2.12302
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 7.75071

Cumulative Model Updates: 23316
Cumulative Timesteps: 194803801

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.39072
Policy Entropy: 1.32471
Value Function Loss: 0.01425

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.05920
Policy Update Magnitude: 0.14171
Value Function Update Magnitude: 0.16182

Collected Steps per Second: 9385.16487
Overall Steps per Second: 6745.27085

Timestep Collection Time: 5.32905
Timestep Consumption Time: 2.08563
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.41468

Cumulative Model Updates: 23322
Cumulative Timesteps: 194853815

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.83706
Policy Entropy: 1.32309
Value Function Loss: 0.01326

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.05603
Policy Update Magnitude: 0.14434
Value Function Update Magnitude: 0.16919

Collected Steps per Second: 9355.70449
Overall Steps per Second: 6583.65856

Timestep Collection Time: 5.34786
Timestep Consumption Time: 2.25171
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 7.59957

Cumulative Model Updates: 23328
Cumulative Timesteps: 194903848

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.72286
Policy Entropy: 1.32482
Value Function Loss: 0.01318

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.13957
Value Function Update Magnitude: 0.16639

Collected Steps per Second: 9208.75651
Overall Steps per Second: 6758.34618

Timestep Collection Time: 5.43298
Timestep Consumption Time: 1.96987
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.40285

Cumulative Model Updates: 23334
Cumulative Timesteps: 194953879

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.18913
Policy Entropy: 1.32687
Value Function Loss: 0.01325

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.04908
Policy Update Magnitude: 0.13243
Value Function Update Magnitude: 0.16498

Collected Steps per Second: 8967.17557
Overall Steps per Second: 6512.25635

Timestep Collection Time: 5.58102
Timestep Consumption Time: 2.10387
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.68489

Cumulative Model Updates: 23340
Cumulative Timesteps: 195003925

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.90466
Policy Entropy: 1.32091
Value Function Loss: 0.01390

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.05453
Policy Update Magnitude: 0.13544
Value Function Update Magnitude: 0.16903

Collected Steps per Second: 9658.31266
Overall Steps per Second: 6832.59002

Timestep Collection Time: 5.17741
Timestep Consumption Time: 2.14120
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.31860

Cumulative Model Updates: 23346
Cumulative Timesteps: 195053930

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.89142
Policy Entropy: 1.31819
Value Function Loss: 0.01384

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.13620
Value Function Update Magnitude: 0.16928

Collected Steps per Second: 9925.73343
Overall Steps per Second: 7122.83999

Timestep Collection Time: 5.03953
Timestep Consumption Time: 1.98309
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.02262

Cumulative Model Updates: 23352
Cumulative Timesteps: 195103951

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.91095
Policy Entropy: 1.31362
Value Function Loss: 0.01463

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06571
Policy Update Magnitude: 0.13452
Value Function Update Magnitude: 0.16759

Collected Steps per Second: 9337.30082
Overall Steps per Second: 6760.18036

Timestep Collection Time: 5.35572
Timestep Consumption Time: 2.04171
PPO Batch Consumption Time: 0.02419
Total Iteration Time: 7.39744

Cumulative Model Updates: 23358
Cumulative Timesteps: 195153959

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.95469
Policy Entropy: 1.31479
Value Function Loss: 0.01472

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.05856
Policy Update Magnitude: 0.13481
Value Function Update Magnitude: 0.17080

Collected Steps per Second: 9710.55788
Overall Steps per Second: 6951.67398

Timestep Collection Time: 5.15233
Timestep Consumption Time: 2.04479
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 7.19712

Cumulative Model Updates: 23364
Cumulative Timesteps: 195203991

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.94168
Policy Entropy: 1.31753
Value Function Loss: 0.01507

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.13421
Value Function Update Magnitude: 0.17530

Collected Steps per Second: 9915.09748
Overall Steps per Second: 6946.37951

Timestep Collection Time: 5.04735
Timestep Consumption Time: 2.15712
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.20447

Cumulative Model Updates: 23370
Cumulative Timesteps: 195254036

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 195254036...
Checkpoint 195254036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.22598
Policy Entropy: 1.32181
Value Function Loss: 0.01510

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.05854
Policy Update Magnitude: 0.12836
Value Function Update Magnitude: 0.17076

Collected Steps per Second: 10030.43049
Overall Steps per Second: 7138.53784

Timestep Collection Time: 4.98792
Timestep Consumption Time: 2.02066
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.00858

Cumulative Model Updates: 23376
Cumulative Timesteps: 195304067

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.83184
Policy Entropy: 1.32683
Value Function Loss: 0.01458

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05400
Policy Update Magnitude: 0.12907
Value Function Update Magnitude: 0.16875

Collected Steps per Second: 11007.11898
Overall Steps per Second: 7691.83876

Timestep Collection Time: 4.54533
Timestep Consumption Time: 1.95910
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 6.50443

Cumulative Model Updates: 23382
Cumulative Timesteps: 195354098

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.26619
Policy Entropy: 1.32267
Value Function Loss: 0.01477

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.05804
Policy Update Magnitude: 0.12882
Value Function Update Magnitude: 0.17102

Collected Steps per Second: 10112.71424
Overall Steps per Second: 7351.24375

Timestep Collection Time: 4.94664
Timestep Consumption Time: 1.85819
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 6.80483

Cumulative Model Updates: 23388
Cumulative Timesteps: 195404122

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.33391
Policy Entropy: 1.32864
Value Function Loss: 0.01373

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.12740
Value Function Update Magnitude: 0.17789

Collected Steps per Second: 9706.39339
Overall Steps per Second: 6897.17997

Timestep Collection Time: 5.15403
Timestep Consumption Time: 2.09923
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.25325

Cumulative Model Updates: 23394
Cumulative Timesteps: 195454149

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.36188
Policy Entropy: 1.31708
Value Function Loss: 0.01430

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.12760
Value Function Update Magnitude: 0.16772

Collected Steps per Second: 9333.24817
Overall Steps per Second: 6478.25204

Timestep Collection Time: 5.36030
Timestep Consumption Time: 2.36231
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.72261

Cumulative Model Updates: 23400
Cumulative Timesteps: 195504178

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.97842
Policy Entropy: 1.31908
Value Function Loss: 0.01453

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.06881
Policy Update Magnitude: 0.13068
Value Function Update Magnitude: 0.16065

Collected Steps per Second: 9098.53013
Overall Steps per Second: 6649.42781

Timestep Collection Time: 5.49814
Timestep Consumption Time: 2.02506
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 7.52320

Cumulative Model Updates: 23406
Cumulative Timesteps: 195554203

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.66244
Policy Entropy: 1.31808
Value Function Loss: 0.01553

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06260
Policy Update Magnitude: 0.13690
Value Function Update Magnitude: 0.16448

Collected Steps per Second: 9519.73526
Overall Steps per Second: 6787.22184

Timestep Collection Time: 5.25687
Timestep Consumption Time: 2.11640
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.37327

Cumulative Model Updates: 23412
Cumulative Timesteps: 195604247

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.80952
Policy Entropy: 1.31747
Value Function Loss: 0.01535

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05016
Policy Update Magnitude: 0.13793
Value Function Update Magnitude: 0.17093

Collected Steps per Second: 9345.00434
Overall Steps per Second: 6442.68391

Timestep Collection Time: 5.35398
Timestep Consumption Time: 2.41188
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.76586

Cumulative Model Updates: 23418
Cumulative Timesteps: 195654280

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.95723
Policy Entropy: 1.31454
Value Function Loss: 0.01504

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05950
Policy Update Magnitude: 0.13428
Value Function Update Magnitude: 0.16924

Collected Steps per Second: 9322.74350
Overall Steps per Second: 6684.65166

Timestep Collection Time: 5.36623
Timestep Consumption Time: 2.11778
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.48401

Cumulative Model Updates: 23424
Cumulative Timesteps: 195704308

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.49976
Policy Entropy: 1.31351
Value Function Loss: 0.01485

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.12855
Value Function Update Magnitude: 0.16260

Collected Steps per Second: 9707.98415
Overall Steps per Second: 6936.83634

Timestep Collection Time: 5.15194
Timestep Consumption Time: 2.05811
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.21006

Cumulative Model Updates: 23430
Cumulative Timesteps: 195754323

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 195754323...
Checkpoint 195754323 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.24336
Policy Entropy: 1.31614
Value Function Loss: 0.01420

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06413
Policy Update Magnitude: 0.12689
Value Function Update Magnitude: 0.16102

Collected Steps per Second: 9253.44572
Overall Steps per Second: 6474.31193

Timestep Collection Time: 5.40631
Timestep Consumption Time: 2.32069
PPO Batch Consumption Time: 0.02925
Total Iteration Time: 7.72700

Cumulative Model Updates: 23436
Cumulative Timesteps: 195804350

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.58108
Policy Entropy: 1.32132
Value Function Loss: 0.01368

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.05981
Policy Update Magnitude: 0.12722
Value Function Update Magnitude: 0.16922

Collected Steps per Second: 9157.71976
Overall Steps per Second: 6672.13052

Timestep Collection Time: 5.45998
Timestep Consumption Time: 2.03402
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.49401

Cumulative Model Updates: 23442
Cumulative Timesteps: 195854351

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.64945
Policy Entropy: 1.31790
Value Function Loss: 0.01318

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.12236
Value Function Update Magnitude: 0.17152

Collected Steps per Second: 10646.57633
Overall Steps per Second: 7030.90915

Timestep Collection Time: 4.69982
Timestep Consumption Time: 2.41690
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 7.11672

Cumulative Model Updates: 23448
Cumulative Timesteps: 195904388

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.18886
Policy Entropy: 1.31806
Value Function Loss: 0.01325

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06477
Policy Update Magnitude: 0.12190
Value Function Update Magnitude: 0.17125

Collected Steps per Second: 9442.89376
Overall Steps per Second: 6487.02504

Timestep Collection Time: 5.29785
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 7.71186

Cumulative Model Updates: 23454
Cumulative Timesteps: 195954415

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.93341
Policy Entropy: 1.31708
Value Function Loss: 0.01370

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06008
Policy Update Magnitude: 0.12535
Value Function Update Magnitude: 0.16396

Collected Steps per Second: 9545.06449
Overall Steps per Second: 6785.97346

Timestep Collection Time: 5.24093
Timestep Consumption Time: 2.13090
PPO Batch Consumption Time: 0.02849
Total Iteration Time: 7.37182

Cumulative Model Updates: 23460
Cumulative Timesteps: 196004440

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.72240
Policy Entropy: 1.31882
Value Function Loss: 0.01445

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05634
Policy Update Magnitude: 0.12708
Value Function Update Magnitude: 0.16994

Collected Steps per Second: 10583.03562
Overall Steps per Second: 7221.54565

Timestep Collection Time: 4.72776
Timestep Consumption Time: 2.20068
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 6.92843

Cumulative Model Updates: 23466
Cumulative Timesteps: 196054474

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.10132
Policy Entropy: 1.31916
Value Function Loss: 0.01529

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05462
Policy Update Magnitude: 0.13123
Value Function Update Magnitude: 0.17134

Collected Steps per Second: 10688.88095
Overall Steps per Second: 7525.29513

Timestep Collection Time: 4.67860
Timestep Consumption Time: 1.96685
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 6.64545

Cumulative Model Updates: 23472
Cumulative Timesteps: 196104483

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.32745
Policy Entropy: 1.31498
Value Function Loss: 0.01576

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.13085
Value Function Update Magnitude: 0.17315

Collected Steps per Second: 9972.28824
Overall Steps per Second: 7188.98668

Timestep Collection Time: 5.01700
Timestep Consumption Time: 1.94239
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.95940

Cumulative Model Updates: 23478
Cumulative Timesteps: 196154514

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.17522
Policy Entropy: 1.31472
Value Function Loss: 0.01471

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.05749
Policy Update Magnitude: 0.13051
Value Function Update Magnitude: 0.17290

Collected Steps per Second: 10618.37747
Overall Steps per Second: 7298.29500

Timestep Collection Time: 4.71277
Timestep Consumption Time: 2.14390
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 6.85667

Cumulative Model Updates: 23484
Cumulative Timesteps: 196204556

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.76390
Policy Entropy: 1.31829
Value Function Loss: 0.01530

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05489
Policy Update Magnitude: 0.12970
Value Function Update Magnitude: 0.17424

Collected Steps per Second: 10446.06696
Overall Steps per Second: 7321.55918

Timestep Collection Time: 4.78984
Timestep Consumption Time: 2.04409
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.83393

Cumulative Model Updates: 23490
Cumulative Timesteps: 196254591

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 196254591...
Checkpoint 196254591 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.72189
Policy Entropy: 1.31886
Value Function Loss: 0.01445

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.04998
Policy Update Magnitude: 0.12830
Value Function Update Magnitude: 0.17247

Collected Steps per Second: 9950.64692
Overall Steps per Second: 7248.11318

Timestep Collection Time: 5.02500
Timestep Consumption Time: 1.87362
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.89862

Cumulative Model Updates: 23496
Cumulative Timesteps: 196304593

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.78789
Policy Entropy: 1.31375
Value Function Loss: 0.01485

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.06822
Policy Update Magnitude: 0.13040
Value Function Update Magnitude: 0.16480

Collected Steps per Second: 9700.94822
Overall Steps per Second: 6959.00169

Timestep Collection Time: 5.15661
Timestep Consumption Time: 2.03178
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.18839

Cumulative Model Updates: 23502
Cumulative Timesteps: 196354617

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.39215
Policy Entropy: 1.31711
Value Function Loss: 0.01374

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07184
Policy Update Magnitude: 0.12724
Value Function Update Magnitude: 0.16591

Collected Steps per Second: 10417.68834
Overall Steps per Second: 7369.75354

Timestep Collection Time: 4.79982
Timestep Consumption Time: 1.98508
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 6.78489

Cumulative Model Updates: 23508
Cumulative Timesteps: 196404620

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.68924
Policy Entropy: 1.31734
Value Function Loss: 0.01366

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.12425
Value Function Update Magnitude: 0.16385

Collected Steps per Second: 9522.42848
Overall Steps per Second: 6743.77580

Timestep Collection Time: 5.25507
Timestep Consumption Time: 2.16526
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.42032

Cumulative Model Updates: 23514
Cumulative Timesteps: 196454661

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.52778
Policy Entropy: 1.32291
Value Function Loss: 0.01347

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.04708
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.15610

Collected Steps per Second: 9864.17855
Overall Steps per Second: 6768.63236

Timestep Collection Time: 5.07179
Timestep Consumption Time: 2.31952
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.39130

Cumulative Model Updates: 23520
Cumulative Timesteps: 196504690

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.91481
Policy Entropy: 1.31778
Value Function Loss: 0.01352

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.12841
Value Function Update Magnitude: 0.15432

Collected Steps per Second: 9635.73194
Overall Steps per Second: 6737.28774

Timestep Collection Time: 5.19348
Timestep Consumption Time: 2.23428
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.42777

Cumulative Model Updates: 23526
Cumulative Timesteps: 196554733

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.57622
Policy Entropy: 1.31495
Value Function Loss: 0.01408

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06061
Policy Update Magnitude: 0.12546
Value Function Update Magnitude: 0.15535

Collected Steps per Second: 9297.56674
Overall Steps per Second: 6594.67173

Timestep Collection Time: 5.37786
Timestep Consumption Time: 2.20417
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.58203

Cumulative Model Updates: 23532
Cumulative Timesteps: 196604734

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.11385
Policy Entropy: 1.31434
Value Function Loss: 0.01432

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05438
Policy Update Magnitude: 0.12352
Value Function Update Magnitude: 0.15736

Collected Steps per Second: 9698.74053
Overall Steps per Second: 6658.57780

Timestep Collection Time: 5.15562
Timestep Consumption Time: 2.35394
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.50956

Cumulative Model Updates: 23538
Cumulative Timesteps: 196654737

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.39282
Policy Entropy: 1.31221
Value Function Loss: 0.01397

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.12471
Value Function Update Magnitude: 0.15362

Collected Steps per Second: 9504.66347
Overall Steps per Second: 6675.29730

Timestep Collection Time: 5.26363
Timestep Consumption Time: 2.23102
PPO Batch Consumption Time: 0.02465
Total Iteration Time: 7.49465

Cumulative Model Updates: 23544
Cumulative Timesteps: 196704766

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.16069
Policy Entropy: 1.31420
Value Function Loss: 0.01372

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05055
Policy Update Magnitude: 0.12557
Value Function Update Magnitude: 0.15609

Collected Steps per Second: 9183.13220
Overall Steps per Second: 6471.15643

Timestep Collection Time: 5.44640
Timestep Consumption Time: 2.28251
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 7.72891

Cumulative Model Updates: 23550
Cumulative Timesteps: 196754781

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 196754781...
Checkpoint 196754781 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.71433
Policy Entropy: 1.31435
Value Function Loss: 0.01280

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.05181
Policy Update Magnitude: 0.12261
Value Function Update Magnitude: 0.15580

Collected Steps per Second: 8846.61457
Overall Steps per Second: 6407.43466

Timestep Collection Time: 5.65290
Timestep Consumption Time: 2.15194
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.80484

Cumulative Model Updates: 23556
Cumulative Timesteps: 196804790

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.34437
Policy Entropy: 1.30986
Value Function Loss: 0.01314

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06615
Policy Update Magnitude: 0.12559
Value Function Update Magnitude: 0.15514

Collected Steps per Second: 9688.92040
Overall Steps per Second: 6860.72719

Timestep Collection Time: 5.16219
Timestep Consumption Time: 2.12800
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.29019

Cumulative Model Updates: 23562
Cumulative Timesteps: 196854806

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.74153
Policy Entropy: 1.30979
Value Function Loss: 0.01360

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.12594
Value Function Update Magnitude: 0.15470

Collected Steps per Second: 9277.64089
Overall Steps per Second: 6589.93131

Timestep Collection Time: 5.39361
Timestep Consumption Time: 2.19979
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 7.59340

Cumulative Model Updates: 23568
Cumulative Timesteps: 196904846

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.95788
Policy Entropy: 1.30970
Value Function Loss: 0.01434

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.12887
Value Function Update Magnitude: 0.15469

Collected Steps per Second: 9243.01769
Overall Steps per Second: 6695.88206

Timestep Collection Time: 5.41198
Timestep Consumption Time: 2.05873
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.47071

Cumulative Model Updates: 23574
Cumulative Timesteps: 196954869

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.04824
Policy Entropy: 1.31583
Value Function Loss: 0.01467

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06436
Policy Update Magnitude: 0.12664
Value Function Update Magnitude: 0.15675

Collected Steps per Second: 9652.82055
Overall Steps per Second: 6882.21981

Timestep Collection Time: 5.18387
Timestep Consumption Time: 2.08689
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 7.27076

Cumulative Model Updates: 23580
Cumulative Timesteps: 197004908

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.11287
Policy Entropy: 1.32233
Value Function Loss: 0.01454

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.05350
Policy Update Magnitude: 0.12772
Value Function Update Magnitude: 0.16543

Collected Steps per Second: 9995.20025
Overall Steps per Second: 7128.85127

Timestep Collection Time: 5.00680
Timestep Consumption Time: 2.01312
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.01992

Cumulative Model Updates: 23586
Cumulative Timesteps: 197054952

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.42890
Policy Entropy: 1.32128
Value Function Loss: 0.01392

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06268
Policy Update Magnitude: 0.12468
Value Function Update Magnitude: 0.16943

Collected Steps per Second: 10051.91082
Overall Steps per Second: 7264.04493

Timestep Collection Time: 4.97716
Timestep Consumption Time: 1.91018
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 6.88735

Cumulative Model Updates: 23592
Cumulative Timesteps: 197104982

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.25128
Policy Entropy: 1.31830
Value Function Loss: 0.01390

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05227
Policy Update Magnitude: 0.12340
Value Function Update Magnitude: 0.16090

Collected Steps per Second: 10204.50225
Overall Steps per Second: 7213.21607

Timestep Collection Time: 4.90156
Timestep Consumption Time: 2.03265
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 6.93422

Cumulative Model Updates: 23598
Cumulative Timesteps: 197155000

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.59959
Policy Entropy: 1.31409
Value Function Loss: 0.01373

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05993
Policy Update Magnitude: 0.12615
Value Function Update Magnitude: 0.15469

Collected Steps per Second: 9311.06699
Overall Steps per Second: 6709.46890

Timestep Collection Time: 5.37393
Timestep Consumption Time: 2.08374
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 7.45767

Cumulative Model Updates: 23604
Cumulative Timesteps: 197205037

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.10675
Policy Entropy: 1.31161
Value Function Loss: 0.01369

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06487
Policy Update Magnitude: 0.12433
Value Function Update Magnitude: 0.15728

Collected Steps per Second: 9366.47347
Overall Steps per Second: 6817.06578

Timestep Collection Time: 5.34054
Timestep Consumption Time: 1.99722
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.33776

Cumulative Model Updates: 23610
Cumulative Timesteps: 197255059

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 197255059...
Checkpoint 197255059 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.08739
Policy Entropy: 1.31487
Value Function Loss: 0.01406

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.05973
Policy Update Magnitude: 0.12674
Value Function Update Magnitude: 0.15940

Collected Steps per Second: 10525.90171
Overall Steps per Second: 7367.77090

Timestep Collection Time: 4.75361
Timestep Consumption Time: 2.03759
PPO Batch Consumption Time: 0.02421
Total Iteration Time: 6.79120

Cumulative Model Updates: 23616
Cumulative Timesteps: 197305095

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.45280
Policy Entropy: 1.31551
Value Function Loss: 0.01393

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06039
Policy Update Magnitude: 0.12665
Value Function Update Magnitude: 0.16322

Collected Steps per Second: 9450.24932
Overall Steps per Second: 6670.31678

Timestep Collection Time: 5.29351
Timestep Consumption Time: 2.20613
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.49964

Cumulative Model Updates: 23622
Cumulative Timesteps: 197355120

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.42329
Policy Entropy: 1.32011
Value Function Loss: 0.01476

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05722
Policy Update Magnitude: 0.13062
Value Function Update Magnitude: 0.16453

Collected Steps per Second: 9812.73183
Overall Steps per Second: 6980.52403

Timestep Collection Time: 5.10021
Timestep Consumption Time: 2.06931
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.16952

Cumulative Model Updates: 23628
Cumulative Timesteps: 197405167

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.94322
Policy Entropy: 1.31488
Value Function Loss: 0.01434

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.05612
Policy Update Magnitude: 0.13005
Value Function Update Magnitude: 0.16000

Collected Steps per Second: 10314.12707
Overall Steps per Second: 7204.77576

Timestep Collection Time: 4.85170
Timestep Consumption Time: 2.09384
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 6.94553

Cumulative Model Updates: 23634
Cumulative Timesteps: 197455208

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.80508
Policy Entropy: 1.31183
Value Function Loss: 0.01433

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.05904
Policy Update Magnitude: 0.12835
Value Function Update Magnitude: 0.16543

Collected Steps per Second: 9348.36225
Overall Steps per Second: 6636.73099

Timestep Collection Time: 5.34907
Timestep Consumption Time: 2.18552
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.53458

Cumulative Model Updates: 23640
Cumulative Timesteps: 197505213

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.94196
Policy Entropy: 1.30674
Value Function Loss: 0.01377

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.12683
Value Function Update Magnitude: 0.16777

Collected Steps per Second: 9736.71917
Overall Steps per Second: 6993.10822

Timestep Collection Time: 5.13592
Timestep Consumption Time: 2.01498
PPO Batch Consumption Time: 0.02454
Total Iteration Time: 7.15090

Cumulative Model Updates: 23646
Cumulative Timesteps: 197555220

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.93768
Policy Entropy: 1.30651
Value Function Loss: 0.01402

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.12601
Value Function Update Magnitude: 0.17140

Collected Steps per Second: 9376.82793
Overall Steps per Second: 6493.84909

Timestep Collection Time: 5.33592
Timestep Consumption Time: 2.36891
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.70483

Cumulative Model Updates: 23652
Cumulative Timesteps: 197605254

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.86630
Policy Entropy: 1.31008
Value Function Loss: 0.01397

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.12811
Value Function Update Magnitude: 0.16274

Collected Steps per Second: 9105.18539
Overall Steps per Second: 6543.42453

Timestep Collection Time: 5.49610
Timestep Consumption Time: 2.15173
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.64783

Cumulative Model Updates: 23658
Cumulative Timesteps: 197655297

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.33361
Policy Entropy: 1.31318
Value Function Loss: 0.01438

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06716
Policy Update Magnitude: 0.13149
Value Function Update Magnitude: 0.16475

Collected Steps per Second: 9579.99015
Overall Steps per Second: 7052.76766

Timestep Collection Time: 5.22213
Timestep Consumption Time: 1.87125
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 7.09339

Cumulative Model Updates: 23664
Cumulative Timesteps: 197705325

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.46491
Policy Entropy: 1.31369
Value Function Loss: 0.01473

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06272
Policy Update Magnitude: 0.13225
Value Function Update Magnitude: 0.17490

Collected Steps per Second: 9659.45701
Overall Steps per Second: 6800.67920

Timestep Collection Time: 5.18062
Timestep Consumption Time: 2.17776
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.35838

Cumulative Model Updates: 23670
Cumulative Timesteps: 197755367

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 197755367...
Checkpoint 197755367 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.54690
Policy Entropy: 1.31193
Value Function Loss: 0.01443

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.13185
Value Function Update Magnitude: 0.16875

Collected Steps per Second: 9301.92824
Overall Steps per Second: 6733.95901

Timestep Collection Time: 5.37781
Timestep Consumption Time: 2.05081
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.42862

Cumulative Model Updates: 23676
Cumulative Timesteps: 197805391

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.39750
Policy Entropy: 1.31376
Value Function Loss: 0.01357

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.12678
Value Function Update Magnitude: 0.16417

Collected Steps per Second: 9704.25023
Overall Steps per Second: 6995.48554

Timestep Collection Time: 5.15393
Timestep Consumption Time: 1.99568
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.14961

Cumulative Model Updates: 23682
Cumulative Timesteps: 197855406

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.87563
Policy Entropy: 1.31623
Value Function Loss: 0.01366

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05823
Policy Update Magnitude: 0.12544
Value Function Update Magnitude: 0.15923

Collected Steps per Second: 10095.65703
Overall Steps per Second: 6963.48331

Timestep Collection Time: 4.95619
Timestep Consumption Time: 2.22929
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 7.18548

Cumulative Model Updates: 23688
Cumulative Timesteps: 197905442

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.91429
Policy Entropy: 1.31374
Value Function Loss: 0.01356

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06293
Policy Update Magnitude: 0.12732
Value Function Update Magnitude: 0.16301

Collected Steps per Second: 9491.24209
Overall Steps per Second: 6926.61935

Timestep Collection Time: 5.27202
Timestep Consumption Time: 1.95200
PPO Batch Consumption Time: 0.02427
Total Iteration Time: 7.22401

Cumulative Model Updates: 23694
Cumulative Timesteps: 197955480

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.13438
Policy Entropy: 1.31177
Value Function Loss: 0.01431

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.05858
Policy Update Magnitude: 0.12679
Value Function Update Magnitude: 0.16517

Collected Steps per Second: 9980.09840
Overall Steps per Second: 7101.22568

Timestep Collection Time: 5.01268
Timestep Consumption Time: 2.03216
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.04484

Cumulative Model Updates: 23700
Cumulative Timesteps: 198005507

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.73285
Policy Entropy: 1.31162
Value Function Loss: 0.01437

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05519
Policy Update Magnitude: 0.13052
Value Function Update Magnitude: 0.16661

Collected Steps per Second: 9960.15163
Overall Steps per Second: 6928.53360

Timestep Collection Time: 5.02141
Timestep Consumption Time: 2.19715
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.21855

Cumulative Model Updates: 23706
Cumulative Timesteps: 198055521

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.57516
Policy Entropy: 1.31344
Value Function Loss: 0.01494

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.13411
Value Function Update Magnitude: 0.17345

Collected Steps per Second: 9164.24550
Overall Steps per Second: 6533.55308

Timestep Collection Time: 5.46013
Timestep Consumption Time: 2.19849
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.65862

Cumulative Model Updates: 23712
Cumulative Timesteps: 198105559

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.15724
Policy Entropy: 1.31423
Value Function Loss: 0.01494

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06523
Policy Update Magnitude: 0.13548
Value Function Update Magnitude: 0.18275

Collected Steps per Second: 9175.52545
Overall Steps per Second: 6479.87180

Timestep Collection Time: 5.45168
Timestep Consumption Time: 2.26792
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.71960

Cumulative Model Updates: 23718
Cumulative Timesteps: 198155581

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.77705
Policy Entropy: 1.31234
Value Function Loss: 0.01540

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06525
Policy Update Magnitude: 0.13466
Value Function Update Magnitude: 0.18712

Collected Steps per Second: 9998.83724
Overall Steps per Second: 6976.04400

Timestep Collection Time: 5.00438
Timestep Consumption Time: 2.16845
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.17283

Cumulative Model Updates: 23724
Cumulative Timesteps: 198205619

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.88357
Policy Entropy: 1.31341
Value Function Loss: 0.01606

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.05881
Policy Update Magnitude: 0.13427
Value Function Update Magnitude: 0.18277

Collected Steps per Second: 9616.36985
Overall Steps per Second: 7019.24217

Timestep Collection Time: 5.20061
Timestep Consumption Time: 1.92423
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.12484

Cumulative Model Updates: 23730
Cumulative Timesteps: 198255630

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 198255630...
Checkpoint 198255630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.91561
Policy Entropy: 1.31245
Value Function Loss: 0.01554

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.13291
Value Function Update Magnitude: 0.18262

Collected Steps per Second: 9439.53989
Overall Steps per Second: 6854.90826

Timestep Collection Time: 5.30005
Timestep Consumption Time: 1.99837
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 7.29842

Cumulative Model Updates: 23736
Cumulative Timesteps: 198305660

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.78235
Policy Entropy: 1.31207
Value Function Loss: 0.01492

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06040
Policy Update Magnitude: 0.13040
Value Function Update Magnitude: 0.17738

Collected Steps per Second: 9678.34271
Overall Steps per Second: 6824.63482

Timestep Collection Time: 5.16938
Timestep Consumption Time: 2.16156
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 7.33094

Cumulative Model Updates: 23742
Cumulative Timesteps: 198355691

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.54868
Policy Entropy: 1.31192
Value Function Loss: 0.01428

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.12680
Value Function Update Magnitude: 0.17226

Collected Steps per Second: 9377.12655
Overall Steps per Second: 6721.76317

Timestep Collection Time: 5.33298
Timestep Consumption Time: 2.10674
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.43971

Cumulative Model Updates: 23748
Cumulative Timesteps: 198405699

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.00217
Policy Entropy: 1.31480
Value Function Loss: 0.01440

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06440
Policy Update Magnitude: 0.12600
Value Function Update Magnitude: 0.17865

Collected Steps per Second: 8980.70675
Overall Steps per Second: 6404.83621

Timestep Collection Time: 5.57228
Timestep Consumption Time: 2.24104
PPO Batch Consumption Time: 0.02920
Total Iteration Time: 7.81331

Cumulative Model Updates: 23754
Cumulative Timesteps: 198455742

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.64605
Policy Entropy: 1.31535
Value Function Loss: 0.01409

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.12294
Value Function Update Magnitude: 0.16866

Collected Steps per Second: 9399.17411
Overall Steps per Second: 6652.52275

Timestep Collection Time: 5.32068
Timestep Consumption Time: 2.19677
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.51745

Cumulative Model Updates: 23760
Cumulative Timesteps: 198505752

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.56586
Policy Entropy: 1.31694
Value Function Loss: 0.01439

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06542
Policy Update Magnitude: 0.12193
Value Function Update Magnitude: 0.16763

Collected Steps per Second: 9550.05707
Overall Steps per Second: 6898.60597

Timestep Collection Time: 5.23725
Timestep Consumption Time: 2.01291
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.25016

Cumulative Model Updates: 23766
Cumulative Timesteps: 198555768

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.25191
Policy Entropy: 1.31707
Value Function Loss: 0.01444

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06624
Policy Update Magnitude: 0.12320
Value Function Update Magnitude: 0.16388

Collected Steps per Second: 8876.89631
Overall Steps per Second: 6328.98230

Timestep Collection Time: 5.63744
Timestep Consumption Time: 2.26952
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 7.90696

Cumulative Model Updates: 23772
Cumulative Timesteps: 198605811

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.97905
Policy Entropy: 1.31486
Value Function Loss: 0.01407

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.12334
Value Function Update Magnitude: 0.15753

Collected Steps per Second: 9463.34838
Overall Steps per Second: 6736.25312

Timestep Collection Time: 5.28544
Timestep Consumption Time: 2.13975
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.42520

Cumulative Model Updates: 23778
Cumulative Timesteps: 198655829

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.04178
Policy Entropy: 1.31463
Value Function Loss: 0.01378

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.12474
Value Function Update Magnitude: 0.15279

Collected Steps per Second: 9809.81924
Overall Steps per Second: 7036.41654

Timestep Collection Time: 5.09918
Timestep Consumption Time: 2.00984
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.10902

Cumulative Model Updates: 23784
Cumulative Timesteps: 198705851

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -17.17991
Policy Entropy: 1.31797
Value Function Loss: 0.01315

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.05639
Policy Update Magnitude: 0.12763
Value Function Update Magnitude: 0.15525

Collected Steps per Second: 10169.79693
Overall Steps per Second: 7096.44629

Timestep Collection Time: 4.91770
Timestep Consumption Time: 2.12977
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 7.04747

Cumulative Model Updates: 23790
Cumulative Timesteps: 198755863

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 198755863...
Checkpoint 198755863 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.31100
Policy Entropy: 1.31898
Value Function Loss: 0.01377

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.06548
Policy Update Magnitude: 0.12260
Value Function Update Magnitude: 0.15640

Collected Steps per Second: 10084.30150
Overall Steps per Second: 7032.57029

Timestep Collection Time: 4.95959
Timestep Consumption Time: 2.15218
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 7.11177

Cumulative Model Updates: 23796
Cumulative Timesteps: 198805877

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.10766
Policy Entropy: 1.31947
Value Function Loss: 0.01312

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.05625
Policy Update Magnitude: 0.12007
Value Function Update Magnitude: 0.15442

Collected Steps per Second: 9765.67875
Overall Steps per Second: 7013.97600

Timestep Collection Time: 5.12192
Timestep Consumption Time: 2.00942
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 7.13133

Cumulative Model Updates: 23802
Cumulative Timesteps: 198855896

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.79117
Policy Entropy: 1.31844
Value Function Loss: 0.01383

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.05858
Policy Update Magnitude: 0.12213
Value Function Update Magnitude: 0.15612

Collected Steps per Second: 9589.84686
Overall Steps per Second: 7022.53738

Timestep Collection Time: 5.21750
Timestep Consumption Time: 1.90742
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 7.12492

Cumulative Model Updates: 23808
Cumulative Timesteps: 198905931

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.17377
Policy Entropy: 1.31928
Value Function Loss: 0.01365

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06239
Policy Update Magnitude: 0.12477
Value Function Update Magnitude: 0.15727

Collected Steps per Second: 10297.55641
Overall Steps per Second: 7304.20216

Timestep Collection Time: 4.85727
Timestep Consumption Time: 1.99057
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 6.84784

Cumulative Model Updates: 23814
Cumulative Timesteps: 198955949

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.43375
Policy Entropy: 1.32257
Value Function Loss: 0.01416

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06135
Policy Update Magnitude: 0.12602
Value Function Update Magnitude: 0.16125

Collected Steps per Second: 10132.03025
Overall Steps per Second: 7175.77998

Timestep Collection Time: 4.93633
Timestep Consumption Time: 2.03365
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 6.96997

Cumulative Model Updates: 23820
Cumulative Timesteps: 199005964

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.89888
Policy Entropy: 1.31959
Value Function Loss: 0.01335

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.12547
Value Function Update Magnitude: 0.17075

Collected Steps per Second: 9841.87964
Overall Steps per Second: 7049.45702

Timestep Collection Time: 5.08389
Timestep Consumption Time: 2.01382
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.09771

Cumulative Model Updates: 23826
Cumulative Timesteps: 199055999

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.18641
Policy Entropy: 1.31534
Value Function Loss: 0.01374

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.13101
Value Function Update Magnitude: 0.17289

Collected Steps per Second: 10285.14898
Overall Steps per Second: 7231.81963

Timestep Collection Time: 4.86342
Timestep Consumption Time: 2.05337
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 6.91679

Cumulative Model Updates: 23832
Cumulative Timesteps: 199106020

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.46307
Policy Entropy: 1.31554
Value Function Loss: 0.01382

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.13032
Value Function Update Magnitude: 0.16645

Collected Steps per Second: 9917.42476
Overall Steps per Second: 6956.23233

Timestep Collection Time: 5.04597
Timestep Consumption Time: 2.14801
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.19398

Cumulative Model Updates: 23838
Cumulative Timesteps: 199156063

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -8.23836
Policy Entropy: 1.31564
Value Function Loss: 0.01439

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06306
Policy Update Magnitude: 0.12725
Value Function Update Magnitude: 0.16741

Collected Steps per Second: 9154.73868
Overall Steps per Second: 6603.37559

Timestep Collection Time: 5.46548
Timestep Consumption Time: 2.11171
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.57719

Cumulative Model Updates: 23844
Cumulative Timesteps: 199206098

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.19553
Policy Entropy: 1.32290
Value Function Loss: 0.01373

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.12480
Value Function Update Magnitude: 0.16958

Collected Steps per Second: 9894.36496
Overall Steps per Second: 6970.93997

Timestep Collection Time: 5.05621
Timestep Consumption Time: 2.12044
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.17665

Cumulative Model Updates: 23850
Cumulative Timesteps: 199256126

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 199256126...
Checkpoint 199256126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.24090
Policy Entropy: 1.32085
Value Function Loss: 0.01350

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05543
Policy Update Magnitude: 0.12195
Value Function Update Magnitude: 0.17421

Collected Steps per Second: 9537.68055
Overall Steps per Second: 6764.11320

Timestep Collection Time: 5.24394
Timestep Consumption Time: 2.15023
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.39417

Cumulative Model Updates: 23856
Cumulative Timesteps: 199306141

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.33863
Policy Entropy: 1.32166
Value Function Loss: 0.01335

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.04515
Policy Update Magnitude: 0.12371
Value Function Update Magnitude: 0.17613

Collected Steps per Second: 9144.59010
Overall Steps per Second: 6563.14566

Timestep Collection Time: 5.46782
Timestep Consumption Time: 2.15063
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 7.61845

Cumulative Model Updates: 23862
Cumulative Timesteps: 199356142

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.21575
Policy Entropy: 1.31595
Value Function Loss: 0.01329

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05781
Policy Update Magnitude: 0.12571
Value Function Update Magnitude: 0.17548

Collected Steps per Second: 9961.79328
Overall Steps per Second: 6969.61683

Timestep Collection Time: 5.02369
Timestep Consumption Time: 2.15676
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 7.18045

Cumulative Model Updates: 23868
Cumulative Timesteps: 199406187

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.98674
Policy Entropy: 1.31632
Value Function Loss: 0.01355

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06320
Policy Update Magnitude: 0.12494
Value Function Update Magnitude: 0.17737

Collected Steps per Second: 9823.43110
Overall Steps per Second: 6961.97579

Timestep Collection Time: 5.09384
Timestep Consumption Time: 2.09363
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 7.18747

Cumulative Model Updates: 23874
Cumulative Timesteps: 199456226

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.43031
Policy Entropy: 1.31742
Value Function Loss: 0.01382

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.12492
Value Function Update Magnitude: 0.17591

Collected Steps per Second: 9209.77605
Overall Steps per Second: 6547.83940

Timestep Collection Time: 5.43249
Timestep Consumption Time: 2.20851
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.64099

Cumulative Model Updates: 23880
Cumulative Timesteps: 199506258

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.97143
Policy Entropy: 1.32213
Value Function Loss: 0.01436

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06173
Policy Update Magnitude: 0.12703
Value Function Update Magnitude: 0.18338

Collected Steps per Second: 9909.35630
Overall Steps per Second: 6867.69040

Timestep Collection Time: 5.04907
Timestep Consumption Time: 2.23621
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.28527

Cumulative Model Updates: 23886
Cumulative Timesteps: 199556291

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.23412
Policy Entropy: 1.31743
Value Function Loss: 0.01410

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.12853
Value Function Update Magnitude: 0.18524

Collected Steps per Second: 9520.98191
Overall Steps per Second: 6668.27818

Timestep Collection Time: 5.25187
Timestep Consumption Time: 2.24676
PPO Batch Consumption Time: 0.02954
Total Iteration Time: 7.49864

Cumulative Model Updates: 23892
Cumulative Timesteps: 199606294

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.94626
Policy Entropy: 1.32247
Value Function Loss: 0.01436

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.12686
Value Function Update Magnitude: 0.18626

Collected Steps per Second: 9180.64588
Overall Steps per Second: 6446.36916

Timestep Collection Time: 5.44668
Timestep Consumption Time: 2.31025
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.75692

Cumulative Model Updates: 23898
Cumulative Timesteps: 199656298

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.34602
Policy Entropy: 1.32130
Value Function Loss: 0.01477

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.06921
Policy Update Magnitude: 0.12716
Value Function Update Magnitude: 0.17701

Collected Steps per Second: 9679.50284
Overall Steps per Second: 6981.23141

Timestep Collection Time: 5.16907
Timestep Consumption Time: 1.99786
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 7.16693

Cumulative Model Updates: 23904
Cumulative Timesteps: 199706332

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.00309
Policy Entropy: 1.32830
Value Function Loss: 0.01468

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.05672
Policy Update Magnitude: 0.12908
Value Function Update Magnitude: 0.17479

Collected Steps per Second: 10085.20419
Overall Steps per Second: 7155.91293

Timestep Collection Time: 4.96123
Timestep Consumption Time: 2.03089
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 6.99212

Cumulative Model Updates: 23910
Cumulative Timesteps: 199756367

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 199756367...
Checkpoint 199756367 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.46238
Policy Entropy: 1.32743
Value Function Loss: 0.01405

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05095
Policy Update Magnitude: 0.12576
Value Function Update Magnitude: 0.16843

Collected Steps per Second: 9705.23247
Overall Steps per Second: 6835.18105

Timestep Collection Time: 5.15268
Timestep Consumption Time: 2.16358
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.31627

Cumulative Model Updates: 23916
Cumulative Timesteps: 199806375

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.20837
Policy Entropy: 1.32563
Value Function Loss: 0.01357

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.04961
Policy Update Magnitude: 0.12186
Value Function Update Magnitude: 0.16455

Collected Steps per Second: 9868.87600
Overall Steps per Second: 6962.25159

Timestep Collection Time: 5.06866
Timestep Consumption Time: 2.11608
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 7.18474

Cumulative Model Updates: 23922
Cumulative Timesteps: 199856397

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.72117
Policy Entropy: 1.32778
Value Function Loss: 0.01360

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.04399
Policy Update Magnitude: 0.12343
Value Function Update Magnitude: 0.16022

Collected Steps per Second: 10136.71230
Overall Steps per Second: 7259.18897

Timestep Collection Time: 4.93266
Timestep Consumption Time: 1.95530
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 6.88796

Cumulative Model Updates: 23928
Cumulative Timesteps: 199906398

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.58480
Policy Entropy: 1.32398
Value Function Loss: 0.01354

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.04471
Policy Update Magnitude: 0.12781
Value Function Update Magnitude: 0.16025

Collected Steps per Second: 9772.55221
Overall Steps per Second: 7065.27942

Timestep Collection Time: 5.11831
Timestep Consumption Time: 1.96124
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.07955

Cumulative Model Updates: 23934
Cumulative Timesteps: 199956417

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.74008
Policy Entropy: 1.32325
Value Function Loss: 0.01303

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.05022
Policy Update Magnitude: 0.12770
Value Function Update Magnitude: 0.15533

Collected Steps per Second: 10475.43566
Overall Steps per Second: 7345.09025

Timestep Collection Time: 4.77374
Timestep Consumption Time: 2.03448
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 6.80822

Cumulative Model Updates: 23940
Cumulative Timesteps: 200006424

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.59393
Policy Entropy: 1.32130
Value Function Loss: 0.01378

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05144
Policy Update Magnitude: 0.12796
Value Function Update Magnitude: 0.16080

Collected Steps per Second: 9866.41450
Overall Steps per Second: 7142.99442

Timestep Collection Time: 5.06851
Timestep Consumption Time: 1.93248
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.00099

Cumulative Model Updates: 23946
Cumulative Timesteps: 200056432

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.81885
Policy Entropy: 1.32607
Value Function Loss: 0.01425

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.04881
Policy Update Magnitude: 0.12602
Value Function Update Magnitude: 0.16658

Collected Steps per Second: 10036.10912
Overall Steps per Second: 6978.14294

Timestep Collection Time: 4.98669
Timestep Consumption Time: 2.18527
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.17197

Cumulative Model Updates: 23952
Cumulative Timesteps: 200106479

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.29185
Policy Entropy: 1.32896
Value Function Loss: 0.01480

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.04554
Policy Update Magnitude: 0.12464
Value Function Update Magnitude: 0.17232

Collected Steps per Second: 9672.33472
Overall Steps per Second: 6753.53188

Timestep Collection Time: 5.17424
Timestep Consumption Time: 2.23625
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 7.41049

Cumulative Model Updates: 23958
Cumulative Timesteps: 200156526

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.90837
Policy Entropy: 1.33071
Value Function Loss: 0.01421

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.04219
Policy Update Magnitude: 0.12802
Value Function Update Magnitude: 0.17368

Collected Steps per Second: 9446.08804
Overall Steps per Second: 6763.62091

Timestep Collection Time: 5.29796
Timestep Consumption Time: 2.10118
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 7.39914

Cumulative Model Updates: 23964
Cumulative Timesteps: 200206571

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.76414
Policy Entropy: 1.32889
Value Function Loss: 0.01448

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.05549
Policy Update Magnitude: 0.13081
Value Function Update Magnitude: 0.16967

Collected Steps per Second: 9039.93393
Overall Steps per Second: 6543.22820

Timestep Collection Time: 5.53301
Timestep Consumption Time: 2.11123
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.64424

Cumulative Model Updates: 23970
Cumulative Timesteps: 200256589

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 200256589...
Checkpoint 200256589 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.41924
Policy Entropy: 1.32605
Value Function Loss: 0.01390

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.12638
Value Function Update Magnitude: 0.16092

Collected Steps per Second: 10163.45230
Overall Steps per Second: 7063.68400

Timestep Collection Time: 4.92284
Timestep Consumption Time: 2.16030
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.08313

Cumulative Model Updates: 23976
Cumulative Timesteps: 200306622

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.58731
Policy Entropy: 1.32644
Value Function Loss: 0.01423

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.05938
Policy Update Magnitude: 0.12207
Value Function Update Magnitude: 0.15786

Collected Steps per Second: 10209.38005
Overall Steps per Second: 7044.45477

Timestep Collection Time: 4.89971
Timestep Consumption Time: 2.20134
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 7.10105

Cumulative Model Updates: 23982
Cumulative Timesteps: 200356645

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.11428
Policy Entropy: 1.32360
Value Function Loss: 0.01552

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.12355
Value Function Update Magnitude: 0.17307

Collected Steps per Second: 8974.04228
Overall Steps per Second: 6478.86580

Timestep Collection Time: 5.57497
Timestep Consumption Time: 2.14706
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.72203

Cumulative Model Updates: 23988
Cumulative Timesteps: 200406675

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.12578
Policy Entropy: 1.32736
Value Function Loss: 0.01567

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05337
Policy Update Magnitude: 0.12730
Value Function Update Magnitude: 0.17927

Collected Steps per Second: 9438.94820
Overall Steps per Second: 6742.92594

Timestep Collection Time: 5.29921
Timestep Consumption Time: 2.11878
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.41800

Cumulative Model Updates: 23994
Cumulative Timesteps: 200456694

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.55779
Policy Entropy: 1.32705
Value Function Loss: 0.01561

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.05276
Policy Update Magnitude: 0.12783
Value Function Update Magnitude: 0.17812

Collected Steps per Second: 9400.40727
Overall Steps per Second: 6748.84778

Timestep Collection Time: 5.32232
Timestep Consumption Time: 2.09109
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.41341

Cumulative Model Updates: 24000
Cumulative Timesteps: 200506726

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.08834
Policy Entropy: 1.33312
Value Function Loss: 0.01449

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.05733
Policy Update Magnitude: 0.12919
Value Function Update Magnitude: 0.17072

Collected Steps per Second: 8984.91689
Overall Steps per Second: 6372.14994

Timestep Collection Time: 5.56677
Timestep Consumption Time: 2.28254
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.84931

Cumulative Model Updates: 24006
Cumulative Timesteps: 200556743

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.81964
Policy Entropy: 1.33017
Value Function Loss: 0.01496

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.05526
Policy Update Magnitude: 0.12730
Value Function Update Magnitude: 0.16404

Collected Steps per Second: 9810.47167
Overall Steps per Second: 6896.13156

Timestep Collection Time: 5.09751
Timestep Consumption Time: 2.15423
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 7.25175

Cumulative Model Updates: 24012
Cumulative Timesteps: 200606752

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.61095
Policy Entropy: 1.33225
Value Function Loss: 0.01360

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05332
Policy Update Magnitude: 0.12651
Value Function Update Magnitude: 0.16484

Collected Steps per Second: 9230.92067
Overall Steps per Second: 6750.21493

Timestep Collection Time: 5.41777
Timestep Consumption Time: 1.99103
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.40880

Cumulative Model Updates: 24018
Cumulative Timesteps: 200656763

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.75792
Policy Entropy: 1.32413
Value Function Loss: 0.01360

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.12228
Value Function Update Magnitude: 0.16809

Collected Steps per Second: 9563.95458
Overall Steps per Second: 6881.26405

Timestep Collection Time: 5.23235
Timestep Consumption Time: 2.03986
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.27221

Cumulative Model Updates: 24024
Cumulative Timesteps: 200706805

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.67042
Policy Entropy: 1.32589
Value Function Loss: 0.01302

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.05516
Policy Update Magnitude: 0.12126
Value Function Update Magnitude: 0.16388

Collected Steps per Second: 10165.05922
Overall Steps per Second: 7302.84959

Timestep Collection Time: 4.91891
Timestep Consumption Time: 1.92787
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 6.84678

Cumulative Model Updates: 24030
Cumulative Timesteps: 200756806

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 200756806...
Checkpoint 200756806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.26759
Policy Entropy: 1.32199
Value Function Loss: 0.01439

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.12376
Value Function Update Magnitude: 0.16364

Collected Steps per Second: 10092.34244
Overall Steps per Second: 7128.16865

Timestep Collection Time: 4.95455
Timestep Consumption Time: 2.06030
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.01485

Cumulative Model Updates: 24036
Cumulative Timesteps: 200806809

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.93715
Policy Entropy: 1.32532
Value Function Loss: 0.01411

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.12420
Value Function Update Magnitude: 0.16604

Collected Steps per Second: 9757.29573
Overall Steps per Second: 7159.61627

Timestep Collection Time: 5.12755
Timestep Consumption Time: 1.86040
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 6.98794

Cumulative Model Updates: 24042
Cumulative Timesteps: 200856840

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.35400
Policy Entropy: 1.32734
Value Function Loss: 0.01380

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06542
Policy Update Magnitude: 0.12223
Value Function Update Magnitude: 0.17145

Collected Steps per Second: 10370.40975
Overall Steps per Second: 7281.10471

Timestep Collection Time: 4.82276
Timestep Consumption Time: 2.04625
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 6.86901

Cumulative Model Updates: 24048
Cumulative Timesteps: 200906854

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.79862
Policy Entropy: 1.33249
Value Function Loss: 0.01450

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.05351
Policy Update Magnitude: 0.12197
Value Function Update Magnitude: 0.16596

Collected Steps per Second: 10179.20731
Overall Steps per Second: 7346.78277

Timestep Collection Time: 4.91364
Timestep Consumption Time: 1.89437
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 6.80801

Cumulative Model Updates: 24054
Cumulative Timesteps: 200956871

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.08429
Policy Entropy: 1.32987
Value Function Loss: 0.01413

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05566
Policy Update Magnitude: 0.12581
Value Function Update Magnitude: 0.16215

Collected Steps per Second: 9804.07892
Overall Steps per Second: 7105.78966

Timestep Collection Time: 5.10267
Timestep Consumption Time: 1.93764
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.04032

Cumulative Model Updates: 24060
Cumulative Timesteps: 201006898

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.84893
Policy Entropy: 1.32844
Value Function Loss: 0.01473

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.05814
Policy Update Magnitude: 0.12493
Value Function Update Magnitude: 0.16854

Collected Steps per Second: 10395.39804
Overall Steps per Second: 7282.67701

Timestep Collection Time: 4.80992
Timestep Consumption Time: 2.05583
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 6.86574

Cumulative Model Updates: 24066
Cumulative Timesteps: 201056899

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.72275
Policy Entropy: 1.32777
Value Function Loss: 0.01408

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05295
Policy Update Magnitude: 0.12329
Value Function Update Magnitude: 0.17032

Collected Steps per Second: 10124.53184
Overall Steps per Second: 7085.62523

Timestep Collection Time: 4.94107
Timestep Consumption Time: 2.11914
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.06021

Cumulative Model Updates: 24072
Cumulative Timesteps: 201106925

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.99172
Policy Entropy: 1.33123
Value Function Loss: 0.01439

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.04686
Policy Update Magnitude: 0.12509
Value Function Update Magnitude: 0.16548

Collected Steps per Second: 9155.14366
Overall Steps per Second: 6640.60295

Timestep Collection Time: 5.46447
Timestep Consumption Time: 2.06918
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.53365

Cumulative Model Updates: 24078
Cumulative Timesteps: 201156953

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.44243
Policy Entropy: 1.33142
Value Function Loss: 0.01425

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.04557
Policy Update Magnitude: 0.12588
Value Function Update Magnitude: 0.16457

Collected Steps per Second: 9774.98148
Overall Steps per Second: 6837.83702

Timestep Collection Time: 5.11981
Timestep Consumption Time: 2.19918
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.31898

Cumulative Model Updates: 24084
Cumulative Timesteps: 201206999

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.21308
Policy Entropy: 1.33023
Value Function Loss: 0.01446

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.12374
Value Function Update Magnitude: 0.17135

Collected Steps per Second: 9028.41159
Overall Steps per Second: 6466.98735

Timestep Collection Time: 5.54173
Timestep Consumption Time: 2.19495
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.73668

Cumulative Model Updates: 24090
Cumulative Timesteps: 201257032

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 201257032...
Checkpoint 201257032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -1.19747
Policy Entropy: 1.33208
Value Function Loss: 0.01448

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05108
Policy Update Magnitude: 0.12297
Value Function Update Magnitude: 0.16877

Collected Steps per Second: 9061.18057
Overall Steps per Second: 6585.67307

Timestep Collection Time: 5.52279
Timestep Consumption Time: 2.07598
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.59877

Cumulative Model Updates: 24096
Cumulative Timesteps: 201307075

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.28739
Policy Entropy: 1.32679
Value Function Loss: 0.01428

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05061
Policy Update Magnitude: 0.12588
Value Function Update Magnitude: 0.17092

Collected Steps per Second: 9528.28709
Overall Steps per Second: 6726.78960

Timestep Collection Time: 5.24963
Timestep Consumption Time: 2.18631
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 7.43594

Cumulative Model Updates: 24102
Cumulative Timesteps: 201357095

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.38186
Policy Entropy: 1.32296
Value Function Loss: 0.01446

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.05873
Policy Update Magnitude: 0.12563
Value Function Update Magnitude: 0.17464

Collected Steps per Second: 9155.97810
Overall Steps per Second: 6650.91873

Timestep Collection Time: 5.46517
Timestep Consumption Time: 2.05845
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.52362

Cumulative Model Updates: 24108
Cumulative Timesteps: 201407134

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.23958
Policy Entropy: 1.32518
Value Function Loss: 0.01463

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.05355
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.17300

Collected Steps per Second: 9085.86428
Overall Steps per Second: 6421.73984

Timestep Collection Time: 5.50415
Timestep Consumption Time: 2.28345
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 7.78761

Cumulative Model Updates: 24114
Cumulative Timesteps: 201457144

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.57370
Policy Entropy: 1.32446
Value Function Loss: 0.01428

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.04968
Policy Update Magnitude: 0.12700
Value Function Update Magnitude: 0.17466

Collected Steps per Second: 9888.47098
Overall Steps per Second: 6822.51820

Timestep Collection Time: 5.05933
Timestep Consumption Time: 2.27360
PPO Batch Consumption Time: 0.02903
Total Iteration Time: 7.33292

Cumulative Model Updates: 24120
Cumulative Timesteps: 201507173

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.23930
Policy Entropy: 1.32531
Value Function Loss: 0.01415

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.05748
Policy Update Magnitude: 0.12611
Value Function Update Magnitude: 0.17397

Collected Steps per Second: 10136.56538
Overall Steps per Second: 7010.45997

Timestep Collection Time: 4.93412
Timestep Consumption Time: 2.20022
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.13434

Cumulative Model Updates: 24126
Cumulative Timesteps: 201557188

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.10378
Policy Entropy: 1.32032
Value Function Loss: 0.01480

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.05943
Policy Update Magnitude: 0.12598
Value Function Update Magnitude: 0.17270

Collected Steps per Second: 9364.57748
Overall Steps per Second: 6510.30841

Timestep Collection Time: 5.34173
Timestep Consumption Time: 2.34194
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 7.68366

Cumulative Model Updates: 24132
Cumulative Timesteps: 201607211

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09218
Policy Entropy: 1.32606
Value Function Loss: 0.01454

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05001
Policy Update Magnitude: 0.13112
Value Function Update Magnitude: 0.17237

Collected Steps per Second: 9593.44354
Overall Steps per Second: 6734.37477

Timestep Collection Time: 5.21658
Timestep Consumption Time: 2.21469
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 7.43128

Cumulative Model Updates: 24138
Cumulative Timesteps: 201657256

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.20586
Policy Entropy: 1.32630
Value Function Loss: 0.01414

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.04864
Policy Update Magnitude: 0.12747
Value Function Update Magnitude: 0.16527

Collected Steps per Second: 10025.28724
Overall Steps per Second: 6988.63399

Timestep Collection Time: 4.98998
Timestep Consumption Time: 2.16821
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.15819

Cumulative Model Updates: 24144
Cumulative Timesteps: 201707282

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.32611
Policy Entropy: 1.32249
Value Function Loss: 0.01336

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05371
Policy Update Magnitude: 0.12592
Value Function Update Magnitude: 0.16200

Collected Steps per Second: 9907.76105
Overall Steps per Second: 7112.51119

Timestep Collection Time: 5.05049
Timestep Consumption Time: 1.98486
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.03535

Cumulative Model Updates: 24150
Cumulative Timesteps: 201757321

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 201757321...
Checkpoint 201757321 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.14870
Policy Entropy: 1.31810
Value Function Loss: 0.01468

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.12753
Value Function Update Magnitude: 0.15932

Collected Steps per Second: 10442.64466
Overall Steps per Second: 7311.86696

Timestep Collection Time: 4.79112
Timestep Consumption Time: 2.05145
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 6.84258

Cumulative Model Updates: 24156
Cumulative Timesteps: 201807353

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -8.57040
Policy Entropy: 1.32010
Value Function Loss: 0.01427

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06527
Policy Update Magnitude: 0.12737
Value Function Update Magnitude: 0.16909

Collected Steps per Second: 9908.62791
Overall Steps per Second: 7073.10460

Timestep Collection Time: 5.04722
Timestep Consumption Time: 2.02337
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.07059

Cumulative Model Updates: 24162
Cumulative Timesteps: 201857364

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.36148
Policy Entropy: 1.32488
Value Function Loss: 0.01461

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.05856
Policy Update Magnitude: 0.12501
Value Function Update Magnitude: 0.17334

Collected Steps per Second: 9742.42968
Overall Steps per Second: 6962.38893

Timestep Collection Time: 5.13240
Timestep Consumption Time: 2.04934
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 7.18173

Cumulative Model Updates: 24168
Cumulative Timesteps: 201907366

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.31052
Policy Entropy: 1.32145
Value Function Loss: 0.01421

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.05654
Policy Update Magnitude: 0.12634
Value Function Update Magnitude: 0.16691

Collected Steps per Second: 10504.20324
Overall Steps per Second: 7364.49773

Timestep Collection Time: 4.76076
Timestep Consumption Time: 2.02965
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.79042

Cumulative Model Updates: 24174
Cumulative Timesteps: 201957374

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.90397
Policy Entropy: 1.31848
Value Function Loss: 0.01443

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06215
Policy Update Magnitude: 0.12639
Value Function Update Magnitude: 0.16514

Collected Steps per Second: 9810.27420
Overall Steps per Second: 7004.75644

Timestep Collection Time: 5.09955
Timestep Consumption Time: 2.04245
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.14200

Cumulative Model Updates: 24180
Cumulative Timesteps: 202007402

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.26694
Policy Entropy: 1.31985
Value Function Loss: 0.01437

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.12942
Value Function Update Magnitude: 0.16241

Collected Steps per Second: 9810.04777
Overall Steps per Second: 7007.30730

Timestep Collection Time: 5.09957
Timestep Consumption Time: 2.03969
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.13926

Cumulative Model Updates: 24186
Cumulative Timesteps: 202057429

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.38528
Policy Entropy: 1.32674
Value Function Loss: 0.01361

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.13635
Value Function Update Magnitude: 0.16145

Collected Steps per Second: 10192.68692
Overall Steps per Second: 7147.50457

Timestep Collection Time: 4.90695
Timestep Consumption Time: 2.09060
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 6.99755

Cumulative Model Updates: 24192
Cumulative Timesteps: 202107444

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.31150
Policy Entropy: 1.32718
Value Function Loss: 0.01342

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.12326
Value Function Update Magnitude: 0.15773

Collected Steps per Second: 9097.77539
Overall Steps per Second: 6549.02859

Timestep Collection Time: 5.49849
Timestep Consumption Time: 2.13990
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 7.63838

Cumulative Model Updates: 24198
Cumulative Timesteps: 202157468

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.02695
Policy Entropy: 1.32603
Value Function Loss: 0.01344

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.11886
Value Function Update Magnitude: 0.15701

Collected Steps per Second: 9250.45825
Overall Steps per Second: 6682.28057

Timestep Collection Time: 5.40611
Timestep Consumption Time: 2.07771
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.48382

Cumulative Model Updates: 24204
Cumulative Timesteps: 202207477

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.92415
Policy Entropy: 1.32925
Value Function Loss: 0.01362

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.06741
Policy Update Magnitude: 0.12047
Value Function Update Magnitude: 0.15650

Collected Steps per Second: 10229.92867
Overall Steps per Second: 7218.02247

Timestep Collection Time: 4.89026
Timestep Consumption Time: 2.04059
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 6.93085

Cumulative Model Updates: 24210
Cumulative Timesteps: 202257504

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 202257504...
Checkpoint 202257504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.07081
Policy Entropy: 1.33215
Value Function Loss: 0.01367

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.05970
Policy Update Magnitude: 0.12257
Value Function Update Magnitude: 0.15799

Collected Steps per Second: 9751.57668
Overall Steps per Second: 6977.22446

Timestep Collection Time: 5.12973
Timestep Consumption Time: 2.03974
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.16947

Cumulative Model Updates: 24216
Cumulative Timesteps: 202307527

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.37433
Policy Entropy: 1.33045
Value Function Loss: 0.01318

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.12212
Value Function Update Magnitude: 0.16211

Collected Steps per Second: 9772.24752
Overall Steps per Second: 6966.11444

Timestep Collection Time: 5.11817
Timestep Consumption Time: 2.06173
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 7.17990

Cumulative Model Updates: 24222
Cumulative Timesteps: 202357543

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.15232
Policy Entropy: 1.33014
Value Function Loss: 0.01374

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.05577
Policy Update Magnitude: 0.12202
Value Function Update Magnitude: 0.16137

Collected Steps per Second: 10861.28048
Overall Steps per Second: 7498.82996

Timestep Collection Time: 4.60461
Timestep Consumption Time: 2.06469
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.66931

Cumulative Model Updates: 24228
Cumulative Timesteps: 202407555

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.34130
Policy Entropy: 1.32883
Value Function Loss: 0.01378

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05419
Policy Update Magnitude: 0.12311
Value Function Update Magnitude: 0.16550

Collected Steps per Second: 9839.18793
Overall Steps per Second: 7050.67955

Timestep Collection Time: 5.08182
Timestep Consumption Time: 2.00984
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.09166

Cumulative Model Updates: 24234
Cumulative Timesteps: 202457556

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.59679
Policy Entropy: 1.33224
Value Function Loss: 0.01376

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.04831
Policy Update Magnitude: 0.12231
Value Function Update Magnitude: 0.16276

Collected Steps per Second: 9875.98208
Overall Steps per Second: 7031.20578

Timestep Collection Time: 5.06431
Timestep Consumption Time: 2.04898
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.11329

Cumulative Model Updates: 24240
Cumulative Timesteps: 202507571

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.81594
Policy Entropy: 1.33227
Value Function Loss: 0.01351

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.04733
Policy Update Magnitude: 0.12214
Value Function Update Magnitude: 0.16161

Collected Steps per Second: 10242.73182
Overall Steps per Second: 7275.62152

Timestep Collection Time: 4.88415
Timestep Consumption Time: 1.99183
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 6.87598

Cumulative Model Updates: 24246
Cumulative Timesteps: 202557598

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.01423
Policy Entropy: 1.33379
Value Function Loss: 0.01441

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.04835
Policy Update Magnitude: 0.12022
Value Function Update Magnitude: 0.16668

Collected Steps per Second: 9785.16844
Overall Steps per Second: 7032.89961

Timestep Collection Time: 5.11100
Timestep Consumption Time: 2.00015
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.11115

Cumulative Model Updates: 24252
Cumulative Timesteps: 202607610

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.00568
Policy Entropy: 1.33475
Value Function Loss: 0.01435

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.04613
Policy Update Magnitude: 0.12308
Value Function Update Magnitude: 0.18881

Collected Steps per Second: 9686.91742
Overall Steps per Second: 6929.41015

Timestep Collection Time: 5.16367
Timestep Consumption Time: 2.05484
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.21851

Cumulative Model Updates: 24258
Cumulative Timesteps: 202657630

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.74990
Policy Entropy: 1.33076
Value Function Loss: 0.01442

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.12692
Value Function Update Magnitude: 0.19620

Collected Steps per Second: 10565.90368
Overall Steps per Second: 7306.95021

Timestep Collection Time: 4.73485
Timestep Consumption Time: 2.11178
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 6.84663

Cumulative Model Updates: 24264
Cumulative Timesteps: 202707658

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.30293
Policy Entropy: 1.33463
Value Function Loss: 0.01330

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.12472
Value Function Update Magnitude: 0.19131

Collected Steps per Second: 9795.71810
Overall Steps per Second: 6992.74061

Timestep Collection Time: 5.10601
Timestep Consumption Time: 2.04670
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.15270

Cumulative Model Updates: 24270
Cumulative Timesteps: 202757675

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 202757675...
Checkpoint 202757675 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.63696
Policy Entropy: 1.33291
Value Function Loss: 0.01368

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.11812
Value Function Update Magnitude: 0.19802

Collected Steps per Second: 9928.96504
Overall Steps per Second: 7095.63426

Timestep Collection Time: 5.03980
Timestep Consumption Time: 2.01242
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 7.05222

Cumulative Model Updates: 24276
Cumulative Timesteps: 202807715

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.06050
Policy Entropy: 1.33458
Value Function Loss: 0.01419

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.11983
Value Function Update Magnitude: 0.19945

Collected Steps per Second: 10126.34894
Overall Steps per Second: 6802.04321

Timestep Collection Time: 4.93870
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.35235

Cumulative Model Updates: 24282
Cumulative Timesteps: 202857726

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.27868
Policy Entropy: 1.32932
Value Function Loss: 0.01463

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.05873
Policy Update Magnitude: 0.12359
Value Function Update Magnitude: 0.19282

Collected Steps per Second: 9299.33603
Overall Steps per Second: 6707.79672

Timestep Collection Time: 5.37748
Timestep Consumption Time: 2.07758
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 7.45506

Cumulative Model Updates: 24288
Cumulative Timesteps: 202907733

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.50451
Policy Entropy: 1.32897
Value Function Loss: 0.01511

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06090
Policy Update Magnitude: 0.12634
Value Function Update Magnitude: 0.20058

Collected Steps per Second: 9675.68644
Overall Steps per Second: 6915.57160

Timestep Collection Time: 5.16832
Timestep Consumption Time: 2.06276
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 7.23107

Cumulative Model Updates: 24294
Cumulative Timesteps: 202957740

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.83351
Policy Entropy: 1.32690
Value Function Loss: 0.01531

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05739
Policy Update Magnitude: 0.12950
Value Function Update Magnitude: 0.19784

Collected Steps per Second: 10207.97007
Overall Steps per Second: 7167.10017

Timestep Collection Time: 4.89941
Timestep Consumption Time: 2.07873
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 6.97814

Cumulative Model Updates: 24300
Cumulative Timesteps: 203007753

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.18982
Policy Entropy: 1.33436
Value Function Loss: 0.01532

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06615
Policy Update Magnitude: 0.13260
Value Function Update Magnitude: 0.18886

Collected Steps per Second: 9935.82028
Overall Steps per Second: 7086.93719

Timestep Collection Time: 5.03391
Timestep Consumption Time: 2.02358
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 7.05749

Cumulative Model Updates: 24306
Cumulative Timesteps: 203057769

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.46484
Policy Entropy: 1.33151
Value Function Loss: 0.01377

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.06449
Policy Update Magnitude: 0.12706
Value Function Update Magnitude: 0.17854

Collected Steps per Second: 9754.00054
Overall Steps per Second: 6975.90982

Timestep Collection Time: 5.12897
Timestep Consumption Time: 2.04257
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.17154

Cumulative Model Updates: 24312
Cumulative Timesteps: 203107797

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.55592
Policy Entropy: 1.33280
Value Function Loss: 0.01424

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.12644
Value Function Update Magnitude: 0.16647

Collected Steps per Second: 10468.78032
Overall Steps per Second: 7296.74743

Timestep Collection Time: 4.78050
Timestep Consumption Time: 2.07817
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 6.85867

Cumulative Model Updates: 24318
Cumulative Timesteps: 203157843

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.00384
Policy Entropy: 1.32445
Value Function Loss: 0.01467

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.13610
Value Function Update Magnitude: 0.16542

Collected Steps per Second: 9826.59713
Overall Steps per Second: 7000.25954

Timestep Collection Time: 5.09261
Timestep Consumption Time: 2.05613
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 7.14873

Cumulative Model Updates: 24324
Cumulative Timesteps: 203207886

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.85992
Policy Entropy: 1.32328
Value Function Loss: 0.01570

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.12509
Value Function Update Magnitude: 0.16067

Collected Steps per Second: 9734.29436
Overall Steps per Second: 6970.83316

Timestep Collection Time: 5.13730
Timestep Consumption Time: 2.03659
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.17389

Cumulative Model Updates: 24330
Cumulative Timesteps: 203257894

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 203257894...
Checkpoint 203257894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.47531
Policy Entropy: 1.31694
Value Function Loss: 0.01563

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.12699
Value Function Update Magnitude: 0.15923

Collected Steps per Second: 10371.85346
Overall Steps per Second: 7236.41473

Timestep Collection Time: 4.82238
Timestep Consumption Time: 2.08947
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 6.91185

Cumulative Model Updates: 24336
Cumulative Timesteps: 203307911

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.24417
Policy Entropy: 1.32819
Value Function Loss: 0.01458

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.12262
Value Function Update Magnitude: 0.15635

Collected Steps per Second: 10057.98774
Overall Steps per Second: 7124.68922

Timestep Collection Time: 4.97346
Timestep Consumption Time: 2.04762
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.02108

Cumulative Model Updates: 24342
Cumulative Timesteps: 203357934

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.00313
Policy Entropy: 1.32531
Value Function Loss: 0.01366

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.12377
Value Function Update Magnitude: 0.15783

Collected Steps per Second: 9567.39935
Overall Steps per Second: 6909.94922

Timestep Collection Time: 5.22744
Timestep Consumption Time: 2.01039
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.23782

Cumulative Model Updates: 24348
Cumulative Timesteps: 203407947

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.72730
Policy Entropy: 1.32466
Value Function Loss: 0.01303

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06731
Policy Update Magnitude: 0.12115
Value Function Update Magnitude: 0.15527

Collected Steps per Second: 10238.31640
Overall Steps per Second: 7205.49844

Timestep Collection Time: 4.88782
Timestep Consumption Time: 2.05730
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.94511

Cumulative Model Updates: 24354
Cumulative Timesteps: 203457990

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.70926
Policy Entropy: 1.32150
Value Function Loss: 0.01403

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06250
Policy Update Magnitude: 0.12363
Value Function Update Magnitude: 0.15307

Collected Steps per Second: 10213.02368
Overall Steps per Second: 7242.47034

Timestep Collection Time: 4.89894
Timestep Consumption Time: 2.00934
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 6.90828

Cumulative Model Updates: 24360
Cumulative Timesteps: 203508023

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.96968
Policy Entropy: 1.32081
Value Function Loss: 0.01446

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.12700
Value Function Update Magnitude: 0.15720

Collected Steps per Second: 9272.39584
Overall Steps per Second: 6559.52557

Timestep Collection Time: 5.39720
Timestep Consumption Time: 2.23216
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.62936

Cumulative Model Updates: 24366
Cumulative Timesteps: 203558068

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.11235
Policy Entropy: 1.32018
Value Function Loss: 0.01521

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.12922
Value Function Update Magnitude: 0.16162

Collected Steps per Second: 9926.30792
Overall Steps per Second: 6911.73172

Timestep Collection Time: 5.03803
Timestep Consumption Time: 2.19735
PPO Batch Consumption Time: 0.02834
Total Iteration Time: 7.23538

Cumulative Model Updates: 24372
Cumulative Timesteps: 203608077

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.15495
Policy Entropy: 1.32387
Value Function Loss: 0.01494

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.12774
Value Function Update Magnitude: 0.16133

Collected Steps per Second: 9890.51958
Overall Steps per Second: 6964.45388

Timestep Collection Time: 5.05858
Timestep Consumption Time: 2.12533
PPO Batch Consumption Time: 0.02925
Total Iteration Time: 7.18391

Cumulative Model Updates: 24378
Cumulative Timesteps: 203658109

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.21700
Policy Entropy: 1.32417
Value Function Loss: 0.01535

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06206
Policy Update Magnitude: 0.12808
Value Function Update Magnitude: 0.16287

Collected Steps per Second: 9765.18263
Overall Steps per Second: 7008.21733

Timestep Collection Time: 5.12248
Timestep Consumption Time: 2.01514
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.13762

Cumulative Model Updates: 24384
Cumulative Timesteps: 203708131

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.35624
Policy Entropy: 1.32652
Value Function Loss: 0.01432

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.05578
Policy Update Magnitude: 0.12604
Value Function Update Magnitude: 0.16434

Collected Steps per Second: 10336.67235
Overall Steps per Second: 7206.29716

Timestep Collection Time: 4.84034
Timestep Consumption Time: 2.10262
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 6.94296

Cumulative Model Updates: 24390
Cumulative Timesteps: 203758164

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 203758164...
Checkpoint 203758164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.17562
Policy Entropy: 1.32346
Value Function Loss: 0.01426

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.12578
Value Function Update Magnitude: 0.17449

Collected Steps per Second: 9872.70297
Overall Steps per Second: 7079.05887

Timestep Collection Time: 5.06680
Timestep Consumption Time: 1.99954
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.06633

Cumulative Model Updates: 24396
Cumulative Timesteps: 203808187

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.08891
Policy Entropy: 1.32389
Value Function Loss: 0.01454

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05450
Policy Update Magnitude: 0.12904
Value Function Update Magnitude: 0.18057

Collected Steps per Second: 9657.26001
Overall Steps per Second: 6920.90969

Timestep Collection Time: 5.17994
Timestep Consumption Time: 2.04801
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.22795

Cumulative Model Updates: 24402
Cumulative Timesteps: 203858211

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.23912
Policy Entropy: 1.32531
Value Function Loss: 0.01538

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.12723
Value Function Update Magnitude: 0.18528

Collected Steps per Second: 10322.84586
Overall Steps per Second: 7192.12011

Timestep Collection Time: 4.84411
Timestep Consumption Time: 2.10864
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 6.95275

Cumulative Model Updates: 24408
Cumulative Timesteps: 203908216

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.68775
Policy Entropy: 1.32360
Value Function Loss: 0.01640

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06594
Policy Update Magnitude: 0.12518
Value Function Update Magnitude: 0.18178

Collected Steps per Second: 9835.21161
Overall Steps per Second: 6887.52355

Timestep Collection Time: 5.08571
Timestep Consumption Time: 2.17656
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.26226

Cumulative Model Updates: 24414
Cumulative Timesteps: 203958235

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.17873
Policy Entropy: 1.32753
Value Function Loss: 0.01650

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.12975
Value Function Update Magnitude: 0.18110

Collected Steps per Second: 9773.85690
Overall Steps per Second: 6991.03820

Timestep Collection Time: 5.11855
Timestep Consumption Time: 2.03747
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.15602

Cumulative Model Updates: 24420
Cumulative Timesteps: 204008263

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.52402
Policy Entropy: 1.32651
Value Function Loss: 0.01597

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.12998
Value Function Update Magnitude: 0.18459

Collected Steps per Second: 10243.10365
Overall Steps per Second: 7185.33987

Timestep Collection Time: 4.88211
Timestep Consumption Time: 2.07761
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.95973

Cumulative Model Updates: 24426
Cumulative Timesteps: 204058271

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.53956
Policy Entropy: 1.33159
Value Function Loss: 0.01505

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.12751
Value Function Update Magnitude: 0.18563

Collected Steps per Second: 9892.91534
Overall Steps per Second: 7028.80024

Timestep Collection Time: 5.05513
Timestep Consumption Time: 2.05988
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.11501

Cumulative Model Updates: 24432
Cumulative Timesteps: 204108281

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.28036
Policy Entropy: 1.32630
Value Function Loss: 0.01520

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.12482
Value Function Update Magnitude: 0.17854

Collected Steps per Second: 9640.88571
Overall Steps per Second: 6938.72480

Timestep Collection Time: 5.18625
Timestep Consumption Time: 2.01969
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.20594

Cumulative Model Updates: 24438
Cumulative Timesteps: 204158281

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.46688
Policy Entropy: 1.32861
Value Function Loss: 0.01528

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.18059

Collected Steps per Second: 10278.12003
Overall Steps per Second: 7167.28506

Timestep Collection Time: 4.86801
Timestep Consumption Time: 2.11288
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.98089

Cumulative Model Updates: 24444
Cumulative Timesteps: 204208315

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.99377
Policy Entropy: 1.32626
Value Function Loss: 0.01506

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.12640
Value Function Update Magnitude: 0.17735

Collected Steps per Second: 9593.79220
Overall Steps per Second: 6754.94076

Timestep Collection Time: 5.21546
Timestep Consumption Time: 2.19186
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.40732

Cumulative Model Updates: 24450
Cumulative Timesteps: 204258351

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 204258351...
Checkpoint 204258351 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.80672
Policy Entropy: 1.32802
Value Function Loss: 0.01446

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05200
Policy Update Magnitude: 0.12384
Value Function Update Magnitude: 0.16932

Collected Steps per Second: 9350.09099
Overall Steps per Second: 6659.33187

Timestep Collection Time: 5.34786
Timestep Consumption Time: 2.16085
PPO Batch Consumption Time: 0.02846
Total Iteration Time: 7.50871

Cumulative Model Updates: 24456
Cumulative Timesteps: 204308354

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.13244
Policy Entropy: 1.32531
Value Function Loss: 0.01463

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.05970
Policy Update Magnitude: 0.12242
Value Function Update Magnitude: 0.16930

Collected Steps per Second: 10219.12135
Overall Steps per Second: 7117.89098

Timestep Collection Time: 4.89602
Timestep Consumption Time: 2.13317
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 7.02919

Cumulative Model Updates: 24462
Cumulative Timesteps: 204358387

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.93706
Policy Entropy: 1.33002
Value Function Loss: 0.01513

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05516
Policy Update Magnitude: 0.12629
Value Function Update Magnitude: 0.16804

Collected Steps per Second: 9631.90692
Overall Steps per Second: 6876.49798

Timestep Collection Time: 5.19264
Timestep Consumption Time: 2.08069
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.27332

Cumulative Model Updates: 24468
Cumulative Timesteps: 204408402

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.04711
Policy Entropy: 1.32794
Value Function Loss: 0.01581

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.06490
Policy Update Magnitude: 0.13034
Value Function Update Magnitude: 0.17140

Collected Steps per Second: 9872.19506
Overall Steps per Second: 7023.10093

Timestep Collection Time: 5.06716
Timestep Consumption Time: 2.05562
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 7.12278

Cumulative Model Updates: 24474
Cumulative Timesteps: 204458426

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.60452
Policy Entropy: 1.32740
Value Function Loss: 0.01534

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.12798
Value Function Update Magnitude: 0.17350

Collected Steps per Second: 10678.98894
Overall Steps per Second: 7407.45550

Timestep Collection Time: 4.68275
Timestep Consumption Time: 2.06815
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 6.75090

Cumulative Model Updates: 24480
Cumulative Timesteps: 204508433

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.89791
Policy Entropy: 1.32089
Value Function Loss: 0.01488

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.12706
Value Function Update Magnitude: 0.16740

Collected Steps per Second: 9731.16541
Overall Steps per Second: 6992.49700

Timestep Collection Time: 5.14060
Timestep Consumption Time: 2.01336
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 7.15395

Cumulative Model Updates: 24486
Cumulative Timesteps: 204558457

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.64126
Policy Entropy: 1.32090
Value Function Loss: 0.01405

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06190
Policy Update Magnitude: 0.12539
Value Function Update Magnitude: 0.15917

Collected Steps per Second: 9807.76592
Overall Steps per Second: 7076.73142

Timestep Collection Time: 5.09841
Timestep Consumption Time: 1.96757
PPO Batch Consumption Time: 0.02499
Total Iteration Time: 7.06597

Cumulative Model Updates: 24492
Cumulative Timesteps: 204608461

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.54210
Policy Entropy: 1.31786
Value Function Loss: 0.01468

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06057
Policy Update Magnitude: 0.12479
Value Function Update Magnitude: 0.15833

Collected Steps per Second: 9639.84457
Overall Steps per Second: 6592.62377

Timestep Collection Time: 5.19044
Timestep Consumption Time: 2.39911
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 7.58954

Cumulative Model Updates: 24498
Cumulative Timesteps: 204658496

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.43631
Policy Entropy: 1.32287
Value Function Loss: 0.01432

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.05281
Policy Update Magnitude: 0.12400
Value Function Update Magnitude: 0.16205

Collected Steps per Second: 8960.89693
Overall Steps per Second: 6477.49699

Timestep Collection Time: 5.58136
Timestep Consumption Time: 2.13983
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.72119

Cumulative Model Updates: 24504
Cumulative Timesteps: 204708510

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.93491
Policy Entropy: 1.32049
Value Function Loss: 0.01444

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07069
Policy Update Magnitude: 0.12372
Value Function Update Magnitude: 0.16473

Collected Steps per Second: 9402.86978
Overall Steps per Second: 6621.32918

Timestep Collection Time: 5.32029
Timestep Consumption Time: 2.23499
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 7.55528

Cumulative Model Updates: 24510
Cumulative Timesteps: 204758536

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 204758536...
Checkpoint 204758536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.99174
Policy Entropy: 1.32103
Value Function Loss: 0.01424

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06394
Policy Update Magnitude: 0.12296
Value Function Update Magnitude: 0.17204

Collected Steps per Second: 9706.86901
Overall Steps per Second: 6755.31418

Timestep Collection Time: 5.15346
Timestep Consumption Time: 2.25167
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.40513

Cumulative Model Updates: 24516
Cumulative Timesteps: 204808560

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.06897
Policy Entropy: 1.31594
Value Function Loss: 0.01440

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.12697
Value Function Update Magnitude: 0.17473

Collected Steps per Second: 9155.19006
Overall Steps per Second: 6622.91138

Timestep Collection Time: 5.46160
Timestep Consumption Time: 2.08825
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.54985

Cumulative Model Updates: 24522
Cumulative Timesteps: 204858562

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.60511
Policy Entropy: 1.31295
Value Function Loss: 0.01445

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.12750
Value Function Update Magnitude: 0.17158

Collected Steps per Second: 9354.79186
Overall Steps per Second: 6674.46381

Timestep Collection Time: 5.34528
Timestep Consumption Time: 2.14656
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 7.49184

Cumulative Model Updates: 24528
Cumulative Timesteps: 204908566

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.90248
Policy Entropy: 1.31157
Value Function Loss: 0.01449

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.12732
Value Function Update Magnitude: 0.17360

Collected Steps per Second: 10040.58248
Overall Steps per Second: 6839.21018

Timestep Collection Time: 4.98178
Timestep Consumption Time: 2.33193
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 7.31371

Cumulative Model Updates: 24534
Cumulative Timesteps: 204958586

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.15176
Policy Entropy: 1.31184
Value Function Loss: 0.01517

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.12677
Value Function Update Magnitude: 0.17516

Collected Steps per Second: 8692.81897
Overall Steps per Second: 6270.64621

Timestep Collection Time: 5.75429
Timestep Consumption Time: 2.22272
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 7.97701

Cumulative Model Updates: 24540
Cumulative Timesteps: 205008607

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.90004
Policy Entropy: 1.31740
Value Function Loss: 0.01540

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.12682
Value Function Update Magnitude: 0.17600

Collected Steps per Second: 9161.22648
Overall Steps per Second: 6527.91603

Timestep Collection Time: 5.46150
Timestep Consumption Time: 2.20312
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 7.66462

Cumulative Model Updates: 24546
Cumulative Timesteps: 205058641

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.65598
Policy Entropy: 1.31769
Value Function Loss: 0.01602

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06642
Policy Update Magnitude: 0.13054
Value Function Update Magnitude: 0.17272

Collected Steps per Second: 9341.43447
Overall Steps per Second: 6452.64852

Timestep Collection Time: 5.35475
Timestep Consumption Time: 2.39727
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 7.75201

Cumulative Model Updates: 24552
Cumulative Timesteps: 205108662

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.60731
Policy Entropy: 1.31216
Value Function Loss: 0.01600

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.06869
Policy Update Magnitude: 0.13592
Value Function Update Magnitude: 0.17301

Collected Steps per Second: 9108.83720
Overall Steps per Second: 6544.33331

Timestep Collection Time: 5.49093
Timestep Consumption Time: 2.15171
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.64264

Cumulative Model Updates: 24558
Cumulative Timesteps: 205158678

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.74327
Policy Entropy: 1.31178
Value Function Loss: 0.01583

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.13399
Value Function Update Magnitude: 0.18352

Collected Steps per Second: 9411.54123
Overall Steps per Second: 6824.42621

Timestep Collection Time: 5.31411
Timestep Consumption Time: 2.01456
PPO Batch Consumption Time: 0.02416
Total Iteration Time: 7.32867

Cumulative Model Updates: 24564
Cumulative Timesteps: 205208692

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.40487
Policy Entropy: 1.31370
Value Function Loss: 0.01570

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.13342
Value Function Update Magnitude: 0.18272

Collected Steps per Second: 9987.46696
Overall Steps per Second: 6960.18495

Timestep Collection Time: 5.00878
Timestep Consumption Time: 2.17853
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.18731

Cumulative Model Updates: 24570
Cumulative Timesteps: 205258717

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 205258717...
Checkpoint 205258717 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.87419
Policy Entropy: 1.32008
Value Function Loss: 0.01555

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.13119
Value Function Update Magnitude: 0.18189

Collected Steps per Second: 9716.71073
Overall Steps per Second: 6802.26279

Timestep Collection Time: 5.14711
Timestep Consumption Time: 2.20529
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.35241

Cumulative Model Updates: 24576
Cumulative Timesteps: 205308730

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.74023
Policy Entropy: 1.31702
Value Function Loss: 0.01586

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.12751
Value Function Update Magnitude: 0.18227

Collected Steps per Second: 9360.17740
Overall Steps per Second: 6720.52983

Timestep Collection Time: 5.34648
Timestep Consumption Time: 2.09996
PPO Batch Consumption Time: 0.02351
Total Iteration Time: 7.44644

Cumulative Model Updates: 24582
Cumulative Timesteps: 205358774

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.30212
Policy Entropy: 1.31867
Value Function Loss: 0.01513

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.12546
Value Function Update Magnitude: 0.17504

Collected Steps per Second: 9932.09875
Overall Steps per Second: 7017.21862

Timestep Collection Time: 5.03448
Timestep Consumption Time: 2.09127
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 7.12576

Cumulative Model Updates: 24588
Cumulative Timesteps: 205408777

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.07850
Policy Entropy: 1.31994
Value Function Loss: 0.01465

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06019
Policy Update Magnitude: 0.12504
Value Function Update Magnitude: 0.17234

Collected Steps per Second: 10046.53220
Overall Steps per Second: 7171.02702

Timestep Collection Time: 4.97694
Timestep Consumption Time: 1.99570
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.97264

Cumulative Model Updates: 24594
Cumulative Timesteps: 205458778

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.18714
Policy Entropy: 1.32122
Value Function Loss: 0.01588

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.05402
Policy Update Magnitude: 0.12719
Value Function Update Magnitude: 0.17758

Collected Steps per Second: 9377.10298
Overall Steps per Second: 6653.63290

Timestep Collection Time: 5.33224
Timestep Consumption Time: 2.18260
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.51484

Cumulative Model Updates: 24600
Cumulative Timesteps: 205508779

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.16142
Policy Entropy: 1.32001
Value Function Loss: 0.01549

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.12889
Value Function Update Magnitude: 0.18199

Collected Steps per Second: 9569.36779
Overall Steps per Second: 6744.44692

Timestep Collection Time: 5.22793
Timestep Consumption Time: 2.18973
PPO Batch Consumption Time: 0.02403
Total Iteration Time: 7.41766

Cumulative Model Updates: 24606
Cumulative Timesteps: 205558807

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.83091
Policy Entropy: 1.31674
Value Function Loss: 0.01553

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.12918
Value Function Update Magnitude: 0.17629

Collected Steps per Second: 8927.64665
Overall Steps per Second: 6379.60297

Timestep Collection Time: 5.60517
Timestep Consumption Time: 2.23873
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.84391

Cumulative Model Updates: 24612
Cumulative Timesteps: 205608848

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.79028
Policy Entropy: 1.31596
Value Function Loss: 0.01459

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.12844
Value Function Update Magnitude: 0.16936

Collected Steps per Second: 8844.44625
Overall Steps per Second: 6327.12869

Timestep Collection Time: 5.65349
Timestep Consumption Time: 2.24930
PPO Batch Consumption Time: 0.02869
Total Iteration Time: 7.90279

Cumulative Model Updates: 24618
Cumulative Timesteps: 205658850

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.80709
Policy Entropy: 1.31789
Value Function Loss: 0.01460

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06674
Policy Update Magnitude: 0.12595
Value Function Update Magnitude: 0.16569

Collected Steps per Second: 10106.12189
Overall Steps per Second: 6949.05490

Timestep Collection Time: 4.94898
Timestep Consumption Time: 2.24840
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.19738

Cumulative Model Updates: 24624
Cumulative Timesteps: 205708865

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.44114
Policy Entropy: 1.31915
Value Function Loss: 0.01520

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.05888
Policy Update Magnitude: 0.12485
Value Function Update Magnitude: 0.15791

Collected Steps per Second: 9001.20594
Overall Steps per Second: 6472.48682

Timestep Collection Time: 5.55826
Timestep Consumption Time: 2.17154
PPO Batch Consumption Time: 0.03013
Total Iteration Time: 7.72980

Cumulative Model Updates: 24630
Cumulative Timesteps: 205758896

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 205758896...
Checkpoint 205758896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.55521
Policy Entropy: 1.31829
Value Function Loss: 0.01435

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05500
Policy Update Magnitude: 0.12228
Value Function Update Magnitude: 0.15154

Collected Steps per Second: 9612.00998
Overall Steps per Second: 6716.77765

Timestep Collection Time: 5.20349
Timestep Consumption Time: 2.24294
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.44643

Cumulative Model Updates: 24636
Cumulative Timesteps: 205808912

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.52337
Policy Entropy: 1.31905
Value Function Loss: 0.01484

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05371
Policy Update Magnitude: 0.12902
Value Function Update Magnitude: 0.15897

Collected Steps per Second: 9512.65728
Overall Steps per Second: 6767.24811

Timestep Collection Time: 5.25826
Timestep Consumption Time: 2.13323
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.39148

Cumulative Model Updates: 24642
Cumulative Timesteps: 205858932

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.58348
Policy Entropy: 1.31890
Value Function Loss: 0.01545

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05855
Policy Update Magnitude: 0.12951
Value Function Update Magnitude: 0.17513

Collected Steps per Second: 9267.78553
Overall Steps per Second: 6796.83791

Timestep Collection Time: 5.39978
Timestep Consumption Time: 1.96306
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.36284

Cumulative Model Updates: 24648
Cumulative Timesteps: 205908976

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.08422
Policy Entropy: 1.31758
Value Function Loss: 0.01575

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.05510
Policy Update Magnitude: 0.13036
Value Function Update Magnitude: 0.18401

Collected Steps per Second: 9846.59614
Overall Steps per Second: 6872.03251

Timestep Collection Time: 5.08044
Timestep Consumption Time: 2.19907
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.27951

Cumulative Model Updates: 24654
Cumulative Timesteps: 205959001

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.47902
Policy Entropy: 1.31761
Value Function Loss: 0.01638

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05428
Policy Update Magnitude: 0.13206
Value Function Update Magnitude: 0.18530

Collected Steps per Second: 9142.42052
Overall Steps per Second: 6429.89807

Timestep Collection Time: 5.47109
Timestep Consumption Time: 2.30804
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.77913

Cumulative Model Updates: 24660
Cumulative Timesteps: 206009020

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -8.44807
Policy Entropy: 1.32075
Value Function Loss: 0.01605

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.13549
Value Function Update Magnitude: 0.17899

Collected Steps per Second: 9351.20363
Overall Steps per Second: 6748.50954

Timestep Collection Time: 5.34947
Timestep Consumption Time: 2.06313
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.41260

Cumulative Model Updates: 24666
Cumulative Timesteps: 206059044

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.09945
Policy Entropy: 1.32281
Value Function Loss: 0.01583

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06643
Policy Update Magnitude: 0.12980
Value Function Update Magnitude: 0.17753

Collected Steps per Second: 10025.05335
Overall Steps per Second: 7163.34399

Timestep Collection Time: 4.98800
Timestep Consumption Time: 1.99267
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 6.98068

Cumulative Model Updates: 24672
Cumulative Timesteps: 206109049

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.90552
Policy Entropy: 1.32584
Value Function Loss: 0.01477

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05840
Policy Update Magnitude: 0.12968
Value Function Update Magnitude: 0.16984

Collected Steps per Second: 10415.48809
Overall Steps per Second: 7434.54146

Timestep Collection Time: 4.80150
Timestep Consumption Time: 1.92521
PPO Batch Consumption Time: 0.02385
Total Iteration Time: 6.72671

Cumulative Model Updates: 24678
Cumulative Timesteps: 206159059

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.55715
Policy Entropy: 1.32691
Value Function Loss: 0.01489

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.05845
Policy Update Magnitude: 0.12901
Value Function Update Magnitude: 0.16666

Collected Steps per Second: 10071.58561
Overall Steps per Second: 7212.98941

Timestep Collection Time: 4.96794
Timestep Consumption Time: 1.96885
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 6.93679

Cumulative Model Updates: 24684
Cumulative Timesteps: 206209094

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.17606
Policy Entropy: 1.33065
Value Function Loss: 0.01537

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.12737
Value Function Update Magnitude: 0.17093

Collected Steps per Second: 10065.76096
Overall Steps per Second: 7125.64188

Timestep Collection Time: 4.97190
Timestep Consumption Time: 2.05146
PPO Batch Consumption Time: 0.03552
Total Iteration Time: 7.02337

Cumulative Model Updates: 24690
Cumulative Timesteps: 206259140

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 206259140...
Checkpoint 206259140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.72462
Policy Entropy: 1.32546
Value Function Loss: 0.01569

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.12555
Value Function Update Magnitude: 0.18050

Collected Steps per Second: 10442.50565
Overall Steps per Second: 7313.84707

Timestep Collection Time: 4.79100
Timestep Consumption Time: 2.04945
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 6.84045

Cumulative Model Updates: 24696
Cumulative Timesteps: 206309170

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.90130
Policy Entropy: 1.32905
Value Function Loss: 0.01513

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.12235
Value Function Update Magnitude: 0.18583

Collected Steps per Second: 9967.06725
Overall Steps per Second: 7044.16727

Timestep Collection Time: 5.02104
Timestep Consumption Time: 2.08342
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 7.10446

Cumulative Model Updates: 24702
Cumulative Timesteps: 206359215

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.34137
Policy Entropy: 1.32511
Value Function Loss: 0.01534

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.12803
Value Function Update Magnitude: 0.19167

Collected Steps per Second: 9786.11372
Overall Steps per Second: 6970.49511

Timestep Collection Time: 5.11378
Timestep Consumption Time: 2.06563
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.17940

Cumulative Model Updates: 24708
Cumulative Timesteps: 206409259

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.73977
Policy Entropy: 1.32219
Value Function Loss: 0.01546

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.13053
Value Function Update Magnitude: 0.18432

Collected Steps per Second: 10300.14520
Overall Steps per Second: 7215.22409

Timestep Collection Time: 4.85721
Timestep Consumption Time: 2.07674
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 6.93395

Cumulative Model Updates: 24714
Cumulative Timesteps: 206459289

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.23507
Policy Entropy: 1.31643
Value Function Loss: 0.01574

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.13137
Value Function Update Magnitude: 0.18481

Collected Steps per Second: 10001.36110
Overall Steps per Second: 7167.02832

Timestep Collection Time: 5.00052
Timestep Consumption Time: 1.97755
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 6.97807

Cumulative Model Updates: 24720
Cumulative Timesteps: 206509301

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.41176
Policy Entropy: 1.31385
Value Function Loss: 0.01514

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.12698
Value Function Update Magnitude: 0.18017

Collected Steps per Second: 9547.74948
Overall Steps per Second: 6687.01064

Timestep Collection Time: 5.23977
Timestep Consumption Time: 2.24160
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.48137

Cumulative Model Updates: 24726
Cumulative Timesteps: 206559329

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.43193
Policy Entropy: 1.31830
Value Function Loss: 0.01540

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.12267
Value Function Update Magnitude: 0.17819

Collected Steps per Second: 8915.77767
Overall Steps per Second: 6085.16683

Timestep Collection Time: 5.60994
Timestep Consumption Time: 2.60955
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 8.21950

Cumulative Model Updates: 24732
Cumulative Timesteps: 206609346

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.03167
Policy Entropy: 1.32668
Value Function Loss: 0.01640

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.12419
Value Function Update Magnitude: 0.18269

Collected Steps per Second: 9948.42797
Overall Steps per Second: 2523.65312

Timestep Collection Time: 5.02843
Timestep Consumption Time: 14.79402
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 19.82245

Cumulative Model Updates: 24738
Cumulative Timesteps: 206659371

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.86758
Policy Entropy: 1.32831
Value Function Loss: 0.01585

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.12606
Value Function Update Magnitude: 0.18738

Collected Steps per Second: 9826.21673
Overall Steps per Second: 6959.94290

Timestep Collection Time: 5.09168
Timestep Consumption Time: 2.09688
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.18856

Cumulative Model Updates: 24744
Cumulative Timesteps: 206709403

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.30371
Policy Entropy: 1.32977
Value Function Loss: 0.01512

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.12261
Value Function Update Magnitude: 0.18468

Collected Steps per Second: 10353.41191
Overall Steps per Second: 7200.38659

Timestep Collection Time: 4.82942
Timestep Consumption Time: 2.11479
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.94421

Cumulative Model Updates: 24750
Cumulative Timesteps: 206759404

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 206759404...
Checkpoint 206759404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.58374
Policy Entropy: 1.32632
Value Function Loss: 0.01487

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07171
Policy Update Magnitude: 0.12184
Value Function Update Magnitude: 0.17850

Collected Steps per Second: 9926.86236
Overall Steps per Second: 7000.72038

Timestep Collection Time: 5.03845
Timestep Consumption Time: 2.10596
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.14441

Cumulative Model Updates: 24756
Cumulative Timesteps: 206809420

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.86848
Policy Entropy: 1.32251
Value Function Loss: 0.01572

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.12179
Value Function Update Magnitude: 0.18099

Collected Steps per Second: 10501.20017
Overall Steps per Second: 7041.36613

Timestep Collection Time: 4.76174
Timestep Consumption Time: 2.33972
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.10146

Cumulative Model Updates: 24762
Cumulative Timesteps: 206859424

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.98700
Policy Entropy: 1.32091
Value Function Loss: 0.01677

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06261
Policy Update Magnitude: 0.12877
Value Function Update Magnitude: 0.19092

Collected Steps per Second: 10308.01928
Overall Steps per Second: 7179.84190

Timestep Collection Time: 4.85273
Timestep Consumption Time: 2.11428
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.96701

Cumulative Model Updates: 24768
Cumulative Timesteps: 206909446

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.74444
Policy Entropy: 1.31881
Value Function Loss: 0.01698

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.13074
Value Function Update Magnitude: 0.18959

Collected Steps per Second: 9830.75026
Overall Steps per Second: 7020.22891

Timestep Collection Time: 5.08822
Timestep Consumption Time: 2.03705
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.12527

Cumulative Model Updates: 24774
Cumulative Timesteps: 206959467

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.59277
Policy Entropy: 1.32187
Value Function Loss: 0.01652

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.12551
Value Function Update Magnitude: 0.19731

Collected Steps per Second: 9623.78650
Overall Steps per Second: 6893.71714

Timestep Collection Time: 5.19650
Timestep Consumption Time: 2.05793
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.25443

Cumulative Model Updates: 24780
Cumulative Timesteps: 207009477

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.21239
Policy Entropy: 1.32752
Value Function Loss: 0.01557

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06233
Policy Update Magnitude: 0.12757
Value Function Update Magnitude: 0.18691

Collected Steps per Second: 10400.41134
Overall Steps per Second: 7242.62505

Timestep Collection Time: 4.80846
Timestep Consumption Time: 2.09649
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 6.90495

Cumulative Model Updates: 24786
Cumulative Timesteps: 207059487

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.98960
Policy Entropy: 1.32465
Value Function Loss: 0.01519

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.12946
Value Function Update Magnitude: 0.18055

Collected Steps per Second: 9849.32803
Overall Steps per Second: 7030.74446

Timestep Collection Time: 5.08106
Timestep Consumption Time: 2.03697
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 7.11802

Cumulative Model Updates: 24792
Cumulative Timesteps: 207109532

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.07833
Policy Entropy: 1.32769
Value Function Loss: 0.01487

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.12408
Value Function Update Magnitude: 0.17247

Collected Steps per Second: 9598.49323
Overall Steps per Second: 6772.00998

Timestep Collection Time: 5.21342
Timestep Consumption Time: 2.17596
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.38939

Cumulative Model Updates: 24798
Cumulative Timesteps: 207159573

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.87389
Policy Entropy: 1.32018
Value Function Loss: 0.01535

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.12276
Value Function Update Magnitude: 0.17517

Collected Steps per Second: 9639.04479
Overall Steps per Second: 6820.15986

Timestep Collection Time: 5.18910
Timestep Consumption Time: 2.14474
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.33385

Cumulative Model Updates: 24804
Cumulative Timesteps: 207209591

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.41225
Policy Entropy: 1.32345
Value Function Loss: 0.01498

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.12621
Value Function Update Magnitude: 0.18012

Collected Steps per Second: 9580.63756
Overall Steps per Second: 6776.06564

Timestep Collection Time: 5.22241
Timestep Consumption Time: 2.16152
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 7.38393

Cumulative Model Updates: 24810
Cumulative Timesteps: 207259625

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 207259625...
Checkpoint 207259625 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.15704
Policy Entropy: 1.31951
Value Function Loss: 0.01562

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06281
Policy Update Magnitude: 0.12662
Value Function Update Magnitude: 0.18651

Collected Steps per Second: 9665.25137
Overall Steps per Second: 6965.80875

Timestep Collection Time: 5.17503
Timestep Consumption Time: 2.00547
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.18050

Cumulative Model Updates: 24816
Cumulative Timesteps: 207309643

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.55381
Policy Entropy: 1.31895
Value Function Loss: 0.01561

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06210
Policy Update Magnitude: 0.12971
Value Function Update Magnitude: 0.19783

Collected Steps per Second: 10307.70727
Overall Steps per Second: 7201.98185

Timestep Collection Time: 4.85384
Timestep Consumption Time: 2.09313
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.94698

Cumulative Model Updates: 24822
Cumulative Timesteps: 207359675

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.13168
Policy Entropy: 1.31634
Value Function Loss: 0.01592

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06517
Policy Update Magnitude: 0.12869
Value Function Update Magnitude: 0.18540

Collected Steps per Second: 9918.34417
Overall Steps per Second: 7031.39422

Timestep Collection Time: 5.04247
Timestep Consumption Time: 2.07034
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.11281

Cumulative Model Updates: 24828
Cumulative Timesteps: 207409688

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.53600
Policy Entropy: 1.31369
Value Function Loss: 0.01503

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.12814
Value Function Update Magnitude: 0.18192

Collected Steps per Second: 9755.37373
Overall Steps per Second: 6979.62104

Timestep Collection Time: 5.12610
Timestep Consumption Time: 2.03862
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.16472

Cumulative Model Updates: 24834
Cumulative Timesteps: 207459695

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.31422
Policy Entropy: 1.31534
Value Function Loss: 0.01399

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.12786
Value Function Update Magnitude: 0.18343

Collected Steps per Second: 10471.21994
Overall Steps per Second: 7242.57485

Timestep Collection Time: 4.77509
Timestep Consumption Time: 2.12867
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.90376

Cumulative Model Updates: 24840
Cumulative Timesteps: 207509696

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.79848
Policy Entropy: 1.31609
Value Function Loss: 0.01402

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.18537

Collected Steps per Second: 9870.38633
Overall Steps per Second: 7042.22633

Timestep Collection Time: 5.06667
Timestep Consumption Time: 2.03478
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.10145

Cumulative Model Updates: 24846
Cumulative Timesteps: 207559706

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.56997
Policy Entropy: 1.31846
Value Function Loss: 0.01486

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.12432
Value Function Update Magnitude: 0.18757

Collected Steps per Second: 9810.84342
Overall Steps per Second: 6929.65424

Timestep Collection Time: 5.09997
Timestep Consumption Time: 2.12045
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.22042

Cumulative Model Updates: 24852
Cumulative Timesteps: 207609741

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.43003
Policy Entropy: 1.31580
Value Function Loss: 0.01501

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06161
Policy Update Magnitude: 0.12796
Value Function Update Magnitude: 0.19565

Collected Steps per Second: 10318.06936
Overall Steps per Second: 7197.36795

Timestep Collection Time: 4.84771
Timestep Consumption Time: 2.10191
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 6.94962

Cumulative Model Updates: 24858
Cumulative Timesteps: 207659760

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.02582
Policy Entropy: 1.31806
Value Function Loss: 0.01594

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.12847
Value Function Update Magnitude: 0.19917

Collected Steps per Second: 10184.46579
Overall Steps per Second: 7148.04820

Timestep Collection Time: 4.91346
Timestep Consumption Time: 2.08719
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.00065

Cumulative Model Updates: 24864
Cumulative Timesteps: 207709801

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.43738
Policy Entropy: 1.31920
Value Function Loss: 0.01519

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06514
Policy Update Magnitude: 0.12538
Value Function Update Magnitude: 0.20145

Collected Steps per Second: 9825.90651
Overall Steps per Second: 7009.04564

Timestep Collection Time: 5.09052
Timestep Consumption Time: 2.04583
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.13635

Cumulative Model Updates: 24870
Cumulative Timesteps: 207759820

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 207759820...
Checkpoint 207759820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.97715
Policy Entropy: 1.32103
Value Function Loss: 0.01496

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.12421
Value Function Update Magnitude: 0.19271

Collected Steps per Second: 10447.65093
Overall Steps per Second: 7257.47202

Timestep Collection Time: 4.78806
Timestep Consumption Time: 2.10470
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.89276

Cumulative Model Updates: 24876
Cumulative Timesteps: 207809844

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.92731
Policy Entropy: 1.32678
Value Function Loss: 0.01482

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05615
Policy Update Magnitude: 0.12097
Value Function Update Magnitude: 0.18433

Collected Steps per Second: 9776.70002
Overall Steps per Second: 7018.32878

Timestep Collection Time: 5.11686
Timestep Consumption Time: 2.01105
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 7.12791

Cumulative Model Updates: 24882
Cumulative Timesteps: 207859870

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.22353
Policy Entropy: 1.32793
Value Function Loss: 0.01438

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.05880
Policy Update Magnitude: 0.11728
Value Function Update Magnitude: 0.18303

Collected Steps per Second: 9856.50741
Overall Steps per Second: 7026.47915

Timestep Collection Time: 5.07634
Timestep Consumption Time: 2.04458
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.12092

Cumulative Model Updates: 24888
Cumulative Timesteps: 207909905

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.55958
Policy Entropy: 1.32524
Value Function Loss: 0.01485

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.05904
Policy Update Magnitude: 0.11764
Value Function Update Magnitude: 0.17577

Collected Steps per Second: 10298.12090
Overall Steps per Second: 7174.08261

Timestep Collection Time: 4.85661
Timestep Consumption Time: 2.11487
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 6.97148

Cumulative Model Updates: 24894
Cumulative Timesteps: 207959919

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.98293
Policy Entropy: 1.32013
Value Function Loss: 0.01525

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05562
Policy Update Magnitude: 0.11775
Value Function Update Magnitude: 0.17156

Collected Steps per Second: 9878.59064
Overall Steps per Second: 6989.57286

Timestep Collection Time: 5.06378
Timestep Consumption Time: 2.09302
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.15680

Cumulative Model Updates: 24900
Cumulative Timesteps: 208009942

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.91723
Policy Entropy: 1.31907
Value Function Loss: 0.01586

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.04938
Policy Update Magnitude: 0.12162
Value Function Update Magnitude: 0.17893

Collected Steps per Second: 9812.13093
Overall Steps per Second: 6982.86119

Timestep Collection Time: 5.09655
Timestep Consumption Time: 2.06499
PPO Batch Consumption Time: 0.02903
Total Iteration Time: 7.16153

Cumulative Model Updates: 24906
Cumulative Timesteps: 208059950

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.16333
Policy Entropy: 1.31850
Value Function Loss: 0.01518

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.04988
Policy Update Magnitude: 0.12411
Value Function Update Magnitude: 0.17978

Collected Steps per Second: 10253.02599
Overall Steps per Second: 7185.98434

Timestep Collection Time: 4.87875
Timestep Consumption Time: 2.08230
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 6.96105

Cumulative Model Updates: 24912
Cumulative Timesteps: 208109972

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.07634
Policy Entropy: 1.32039
Value Function Loss: 0.01489

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.12738
Value Function Update Magnitude: 0.18823

Collected Steps per Second: 9755.86796
Overall Steps per Second: 6998.71411

Timestep Collection Time: 5.12625
Timestep Consumption Time: 2.01949
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.14574

Cumulative Model Updates: 24918
Cumulative Timesteps: 208159983

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18157
Policy Entropy: 1.31947
Value Function Loss: 0.01435

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.06619
Policy Update Magnitude: 0.12665
Value Function Update Magnitude: 0.19180

Collected Steps per Second: 9873.73969
Overall Steps per Second: 7038.81227

Timestep Collection Time: 5.06698
Timestep Consumption Time: 2.04076
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.10773

Cumulative Model Updates: 24924
Cumulative Timesteps: 208210013

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.73586
Policy Entropy: 1.32324
Value Function Loss: 0.01488

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.12681
Value Function Update Magnitude: 0.18276

Collected Steps per Second: 10526.61026
Overall Steps per Second: 7314.57247

Timestep Collection Time: 4.75395
Timestep Consumption Time: 2.08760
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 6.84155

Cumulative Model Updates: 24930
Cumulative Timesteps: 208260056

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 208260056...
Checkpoint 208260056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.17088
Policy Entropy: 1.32511
Value Function Loss: 0.01424

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.12521
Value Function Update Magnitude: 0.17609

Collected Steps per Second: 9692.96490
Overall Steps per Second: 6954.27633

Timestep Collection Time: 5.16189
Timestep Consumption Time: 2.03282
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.19471

Cumulative Model Updates: 24936
Cumulative Timesteps: 208310090

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.12540
Policy Entropy: 1.32191
Value Function Loss: 0.01488

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06641
Policy Update Magnitude: 0.12616
Value Function Update Magnitude: 0.17372

Collected Steps per Second: 9757.63520
Overall Steps per Second: 6984.13804

Timestep Collection Time: 5.12788
Timestep Consumption Time: 2.03635
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.16423

Cumulative Model Updates: 24942
Cumulative Timesteps: 208360126

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.43431
Policy Entropy: 1.32677
Value Function Loss: 0.01480

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.12698
Value Function Update Magnitude: 0.17151

Collected Steps per Second: 10248.49712
Overall Steps per Second: 7174.90031

Timestep Collection Time: 4.88013
Timestep Consumption Time: 2.09056
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.97069

Cumulative Model Updates: 24948
Cumulative Timesteps: 208410140

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.52644
Policy Entropy: 1.32245
Value Function Loss: 0.01471

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.14105
Value Function Update Magnitude: 0.18439

Collected Steps per Second: 9902.81292
Overall Steps per Second: 7108.43195

Timestep Collection Time: 5.05129
Timestep Consumption Time: 1.98570
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.03699

Cumulative Model Updates: 24954
Cumulative Timesteps: 208460162

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.90358
Policy Entropy: 1.32377
Value Function Loss: 0.01563

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06756
Policy Update Magnitude: 0.14104
Value Function Update Magnitude: 0.18043

Collected Steps per Second: 9870.79987
Overall Steps per Second: 7040.43697

Timestep Collection Time: 5.06990
Timestep Consumption Time: 2.03818
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.10808

Cumulative Model Updates: 24960
Cumulative Timesteps: 208510206

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.15267
Policy Entropy: 1.31823
Value Function Loss: 0.01585

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.06719
Policy Update Magnitude: 0.13929
Value Function Update Magnitude: 0.18127

Collected Steps per Second: 10787.07533
Overall Steps per Second: 7417.60541

Timestep Collection Time: 4.63851
Timestep Consumption Time: 2.10706
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 6.74557

Cumulative Model Updates: 24966
Cumulative Timesteps: 208560242

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.83444
Policy Entropy: 1.31939
Value Function Loss: 0.01607

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05548
Policy Update Magnitude: 0.13377
Value Function Update Magnitude: 0.18240

Collected Steps per Second: 9894.30187
Overall Steps per Second: 7076.06421

Timestep Collection Time: 5.05533
Timestep Consumption Time: 2.01343
PPO Batch Consumption Time: 0.02433
Total Iteration Time: 7.06876

Cumulative Model Updates: 24972
Cumulative Timesteps: 208610261

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.81350
Policy Entropy: 1.31634
Value Function Loss: 0.01562

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.13214
Value Function Update Magnitude: 0.17844

Collected Steps per Second: 10494.92857
Overall Steps per Second: 7381.45859

Timestep Collection Time: 4.76668
Timestep Consumption Time: 2.01057
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 6.77725

Cumulative Model Updates: 24978
Cumulative Timesteps: 208660287

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.16601
Policy Entropy: 1.31622
Value Function Loss: 0.01560

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06197
Policy Update Magnitude: 0.13116
Value Function Update Magnitude: 0.18019

Collected Steps per Second: 10917.78669
Overall Steps per Second: 7480.22544

Timestep Collection Time: 4.58216
Timestep Consumption Time: 2.10574
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 6.68790

Cumulative Model Updates: 24984
Cumulative Timesteps: 208710314

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.21387
Policy Entropy: 1.31513
Value Function Loss: 0.01625

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.12835
Value Function Update Magnitude: 0.17773

Collected Steps per Second: 9884.39406
Overall Steps per Second: 6959.52887

Timestep Collection Time: 5.05888
Timestep Consumption Time: 2.12609
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.18497

Cumulative Model Updates: 24990
Cumulative Timesteps: 208760318

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 208760318...
Checkpoint 208760318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.76686
Policy Entropy: 1.31791
Value Function Loss: 0.01592

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.13324
Value Function Update Magnitude: 0.17830

Collected Steps per Second: 9752.39830
Overall Steps per Second: 6971.81153

Timestep Collection Time: 5.13135
Timestep Consumption Time: 2.04655
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 7.17790

Cumulative Model Updates: 24996
Cumulative Timesteps: 208810361

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.21597
Policy Entropy: 1.31544
Value Function Loss: 0.01555

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06126
Policy Update Magnitude: 0.13174
Value Function Update Magnitude: 0.17165

Collected Steps per Second: 10321.56037
Overall Steps per Second: 7176.44483

Timestep Collection Time: 4.84597
Timestep Consumption Time: 2.12377
PPO Batch Consumption Time: 0.02448
Total Iteration Time: 6.96975

Cumulative Model Updates: 25002
Cumulative Timesteps: 208860379

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.87907
Policy Entropy: 1.31730
Value Function Loss: 0.01409

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.05970
Policy Update Magnitude: 0.13071
Value Function Update Magnitude: 0.17008

Collected Steps per Second: 9880.57833
Overall Steps per Second: 7054.21148

Timestep Collection Time: 5.06499
Timestep Consumption Time: 2.02936
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 7.09434

Cumulative Model Updates: 25008
Cumulative Timesteps: 208910424

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.05479
Policy Entropy: 1.31041
Value Function Loss: 0.01494

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.12924
Value Function Update Magnitude: 0.16955

Collected Steps per Second: 10491.83245
Overall Steps per Second: 7105.00789

Timestep Collection Time: 4.76914
Timestep Consumption Time: 2.27336
PPO Batch Consumption Time: 0.02448
Total Iteration Time: 7.04250

Cumulative Model Updates: 25014
Cumulative Timesteps: 208960461

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.38391
Policy Entropy: 1.30911
Value Function Loss: 0.01488

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.12965
Value Function Update Magnitude: 0.17145

Collected Steps per Second: 10564.61319
Overall Steps per Second: 7363.25979

Timestep Collection Time: 4.73534
Timestep Consumption Time: 2.05880
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 6.79414

Cumulative Model Updates: 25020
Cumulative Timesteps: 209010488

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.74998
Policy Entropy: 1.30650
Value Function Loss: 0.01560

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.13078
Value Function Update Magnitude: 0.16943

Collected Steps per Second: 9915.03660
Overall Steps per Second: 7087.22627

Timestep Collection Time: 5.04506
Timestep Consumption Time: 2.01299
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.05805

Cumulative Model Updates: 25026
Cumulative Timesteps: 209060510

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.63266
Policy Entropy: 1.30737
Value Function Loss: 0.01528

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.13439
Value Function Update Magnitude: 0.17261

Collected Steps per Second: 9786.83295
Overall Steps per Second: 7010.96683

Timestep Collection Time: 5.11034
Timestep Consumption Time: 2.02335
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.13368

Cumulative Model Updates: 25032
Cumulative Timesteps: 209110524

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.45451
Policy Entropy: 1.30592
Value Function Loss: 0.01641

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.13598
Value Function Update Magnitude: 0.17864

Collected Steps per Second: 10419.69200
Overall Steps per Second: 7238.35359

Timestep Collection Time: 4.80216
Timestep Consumption Time: 2.11060
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.91276

Cumulative Model Updates: 25038
Cumulative Timesteps: 209160561

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.75893
Policy Entropy: 1.30709
Value Function Loss: 0.01648

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.05952
Policy Update Magnitude: 0.13729
Value Function Update Magnitude: 0.18395

Collected Steps per Second: 9848.34708
Overall Steps per Second: 7053.88583

Timestep Collection Time: 5.07953
Timestep Consumption Time: 2.01230
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.09184

Cumulative Model Updates: 25044
Cumulative Timesteps: 209210586

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.35026
Policy Entropy: 1.30879
Value Function Loss: 0.01598

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.05860
Policy Update Magnitude: 0.13587
Value Function Update Magnitude: 0.18347

Collected Steps per Second: 9878.12082
Overall Steps per Second: 7032.03324

Timestep Collection Time: 5.06392
Timestep Consumption Time: 2.04953
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.11345

Cumulative Model Updates: 25050
Cumulative Timesteps: 209260608

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 209260608...
Checkpoint 209260608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.60230
Policy Entropy: 1.31132
Value Function Loss: 0.01559

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.13026
Value Function Update Magnitude: 0.17480

Collected Steps per Second: 10338.80169
Overall Steps per Second: 7203.70121

Timestep Collection Time: 4.84050
Timestep Consumption Time: 2.10662
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 6.94712

Cumulative Model Updates: 25056
Cumulative Timesteps: 209310653

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.08657
Policy Entropy: 1.31103
Value Function Loss: 0.01518

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.05604
Policy Update Magnitude: 0.12742
Value Function Update Magnitude: 0.17429

Collected Steps per Second: 9791.28393
Overall Steps per Second: 6981.02187

Timestep Collection Time: 5.10914
Timestep Consumption Time: 2.05672
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.16586

Cumulative Model Updates: 25062
Cumulative Timesteps: 209360678

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -15.90403
Policy Entropy: 1.31106
Value Function Loss: 0.01596

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.12637
Value Function Update Magnitude: 0.17940

Collected Steps per Second: 9990.98477
Overall Steps per Second: 7082.26779

Timestep Collection Time: 5.00491
Timestep Consumption Time: 2.05554
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 7.06045

Cumulative Model Updates: 25068
Cumulative Timesteps: 209410682

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.91416
Policy Entropy: 1.31097
Value Function Loss: 0.01579

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.13087
Value Function Update Magnitude: 0.18882

Collected Steps per Second: 10424.40768
Overall Steps per Second: 7265.87460

Timestep Collection Time: 4.79797
Timestep Consumption Time: 2.08572
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 6.88369

Cumulative Model Updates: 25074
Cumulative Timesteps: 209460698

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.58806
Policy Entropy: 1.30467
Value Function Loss: 0.01547

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.12948
Value Function Update Magnitude: 0.19163

Collected Steps per Second: 9933.36513
Overall Steps per Second: 7058.60703

Timestep Collection Time: 5.03455
Timestep Consumption Time: 2.05042
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.08497

Cumulative Model Updates: 25080
Cumulative Timesteps: 209510708

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.28715
Policy Entropy: 1.30233
Value Function Loss: 0.01504

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.13014
Value Function Update Magnitude: 0.18461

Collected Steps per Second: 9811.94140
Overall Steps per Second: 6975.95598

Timestep Collection Time: 5.09879
Timestep Consumption Time: 2.07285
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.17163

Cumulative Model Updates: 25086
Cumulative Timesteps: 209560737

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.49630
Policy Entropy: 1.29956
Value Function Loss: 0.01500

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.12463
Value Function Update Magnitude: 0.17749

Collected Steps per Second: 10344.25146
Overall Steps per Second: 7235.31252

Timestep Collection Time: 4.83641
Timestep Consumption Time: 2.07815
PPO Batch Consumption Time: 0.02352
Total Iteration Time: 6.91456

Cumulative Model Updates: 25092
Cumulative Timesteps: 209610766

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.03421
Policy Entropy: 1.30677
Value Function Loss: 0.01562

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.12405
Value Function Update Magnitude: 0.18056

Collected Steps per Second: 9867.55226
Overall Steps per Second: 7070.10444

Timestep Collection Time: 5.07167
Timestep Consumption Time: 2.00672
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.07840

Cumulative Model Updates: 25098
Cumulative Timesteps: 209660811

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.36137
Policy Entropy: 1.30927
Value Function Loss: 0.01546

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.12987
Value Function Update Magnitude: 0.18864

Collected Steps per Second: 9718.84686
Overall Steps per Second: 6971.29373

Timestep Collection Time: 5.14732
Timestep Consumption Time: 2.02868
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.17600

Cumulative Model Updates: 25104
Cumulative Timesteps: 209710837

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.81523
Policy Entropy: 1.31124
Value Function Loss: 0.01500

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.12715
Value Function Update Magnitude: 0.18765

Collected Steps per Second: 10348.26714
Overall Steps per Second: 7213.09670

Timestep Collection Time: 4.83308
Timestep Consumption Time: 2.10070
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 6.93378

Cumulative Model Updates: 25110
Cumulative Timesteps: 209760851

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 209760851...
Checkpoint 209760851 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.66167
Policy Entropy: 1.30521
Value Function Loss: 0.01537

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.12548
Value Function Update Magnitude: 0.17851

Collected Steps per Second: 9872.45913
Overall Steps per Second: 5957.09541

Timestep Collection Time: 5.06865
Timestep Consumption Time: 3.33142
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 8.40007

Cumulative Model Updates: 25116
Cumulative Timesteps: 209810891

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.48966
Policy Entropy: 1.30587
Value Function Loss: 0.01573

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.12646
Value Function Update Magnitude: 0.17106

Collected Steps per Second: 9665.55250
Overall Steps per Second: 6920.89125

Timestep Collection Time: 5.17467
Timestep Consumption Time: 2.05215
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.22681

Cumulative Model Updates: 25122
Cumulative Timesteps: 209860907

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.34533
Policy Entropy: 1.30352
Value Function Loss: 0.01609

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06216
Policy Update Magnitude: 0.12795
Value Function Update Magnitude: 0.16917

Collected Steps per Second: 10457.63594
Overall Steps per Second: 7279.45453

Timestep Collection Time: 4.78129
Timestep Consumption Time: 2.08749
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 6.86878

Cumulative Model Updates: 25128
Cumulative Timesteps: 209910908

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.73365
Policy Entropy: 1.30252
Value Function Loss: 0.01580

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06349
Policy Update Magnitude: 0.13217
Value Function Update Magnitude: 0.17012

Collected Steps per Second: 9799.07316
Overall Steps per Second: 6970.59959

Timestep Collection Time: 5.10416
Timestep Consumption Time: 2.07112
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.17528

Cumulative Model Updates: 25134
Cumulative Timesteps: 209960924

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.38007
Policy Entropy: 1.29866
Value Function Loss: 0.01606

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.13292
Value Function Update Magnitude: 0.17376

Collected Steps per Second: 9742.43180
Overall Steps per Second: 6963.82663

Timestep Collection Time: 5.13547
Timestep Consumption Time: 2.04908
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 7.18456

Cumulative Model Updates: 25140
Cumulative Timesteps: 210010956

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.32213
Policy Entropy: 1.29854
Value Function Loss: 0.01596

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.13440
Value Function Update Magnitude: 0.18447

Collected Steps per Second: 10268.78430
Overall Steps per Second: 7187.51926

Timestep Collection Time: 4.87098
Timestep Consumption Time: 2.08817
PPO Batch Consumption Time: 0.02450
Total Iteration Time: 6.95915

Cumulative Model Updates: 25146
Cumulative Timesteps: 210060975

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.34482
Policy Entropy: 1.29874
Value Function Loss: 0.01611

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.13260
Value Function Update Magnitude: 0.17750

Collected Steps per Second: 9858.67783
Overall Steps per Second: 7059.72836

Timestep Collection Time: 5.07391
Timestep Consumption Time: 2.01164
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.08554

Cumulative Model Updates: 25152
Cumulative Timesteps: 210110997

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.84598
Policy Entropy: 1.29893
Value Function Loss: 0.01552

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.13116
Value Function Update Magnitude: 0.17704

Collected Steps per Second: 9639.55406
Overall Steps per Second: 6948.61058

Timestep Collection Time: 5.19049
Timestep Consumption Time: 2.01009
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.20058

Cumulative Model Updates: 25158
Cumulative Timesteps: 210161031

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.38554
Policy Entropy: 1.30081
Value Function Loss: 0.01582

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.13177
Value Function Update Magnitude: 0.17571

Collected Steps per Second: 10362.07720
Overall Steps per Second: 7222.45498

Timestep Collection Time: 4.82673
Timestep Consumption Time: 2.09820
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.92493

Cumulative Model Updates: 25164
Cumulative Timesteps: 210211046

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.02875
Policy Entropy: 1.30315
Value Function Loss: 0.01640

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.13081
Value Function Update Magnitude: 0.16920

Collected Steps per Second: 10308.98677
Overall Steps per Second: 7286.75870

Timestep Collection Time: 4.85198
Timestep Consumption Time: 2.01239
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 6.86437

Cumulative Model Updates: 25170
Cumulative Timesteps: 210261065

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 210261065...
Checkpoint 210261065 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.53900
Policy Entropy: 1.30426
Value Function Loss: 0.01620

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.13070
Value Function Update Magnitude: 0.16488

Collected Steps per Second: 9699.50581
Overall Steps per Second: 6924.70094

Timestep Collection Time: 5.15748
Timestep Consumption Time: 2.06666
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.22414

Cumulative Model Updates: 25176
Cumulative Timesteps: 210311090

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.54737
Policy Entropy: 1.30438
Value Function Loss: 0.01613

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.13181
Value Function Update Magnitude: 0.17009

Collected Steps per Second: 10298.96545
Overall Steps per Second: 7219.28092

Timestep Collection Time: 4.85524
Timestep Consumption Time: 2.07121
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 6.92645

Cumulative Model Updates: 25182
Cumulative Timesteps: 210361094

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.98527
Policy Entropy: 1.30446
Value Function Loss: 0.01582

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.12967
Value Function Update Magnitude: 0.17438

Collected Steps per Second: 9734.99609
Overall Steps per Second: 6936.57757

Timestep Collection Time: 5.13786
Timestep Consumption Time: 2.07276
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 7.21062

Cumulative Model Updates: 25188
Cumulative Timesteps: 210411111

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.42480
Policy Entropy: 1.30095
Value Function Loss: 0.01645

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06424
Policy Update Magnitude: 0.13015
Value Function Update Magnitude: 0.17827

Collected Steps per Second: 9739.79512
Overall Steps per Second: 6991.71866

Timestep Collection Time: 5.13717
Timestep Consumption Time: 2.01915
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.15632

Cumulative Model Updates: 25194
Cumulative Timesteps: 210461146

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.91559
Policy Entropy: 1.30294
Value Function Loss: 0.01638

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 0.13224
Value Function Update Magnitude: 0.19053

Collected Steps per Second: 10153.69450
Overall Steps per Second: 7039.95949

Timestep Collection Time: 4.92432
Timestep Consumption Time: 2.17800
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.10231

Cumulative Model Updates: 25200
Cumulative Timesteps: 210511146

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.36302
Policy Entropy: 1.30371
Value Function Loss: 0.01629

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06248
Policy Update Magnitude: 0.13138
Value Function Update Magnitude: 0.19002

Collected Steps per Second: 9085.88854
Overall Steps per Second: 6387.04643

Timestep Collection Time: 5.50799
Timestep Consumption Time: 2.32740
PPO Batch Consumption Time: 0.03046
Total Iteration Time: 7.83539

Cumulative Model Updates: 25206
Cumulative Timesteps: 210561191

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.81974
Policy Entropy: 1.30788
Value Function Loss: 0.01587

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06282
Policy Update Magnitude: 0.13038
Value Function Update Magnitude: 0.19114

Collected Steps per Second: 9278.82688
Overall Steps per Second: 6556.45665

Timestep Collection Time: 5.39098
Timestep Consumption Time: 2.23844
PPO Batch Consumption Time: 0.02465
Total Iteration Time: 7.62943

Cumulative Model Updates: 25212
Cumulative Timesteps: 210611213

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.76084
Policy Entropy: 1.30692
Value Function Loss: 0.01627

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06268
Policy Update Magnitude: 0.13199
Value Function Update Magnitude: 0.18865

Collected Steps per Second: 9952.23764
Overall Steps per Second: 6964.71426

Timestep Collection Time: 5.02420
Timestep Consumption Time: 2.15514
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 7.17933

Cumulative Model Updates: 25218
Cumulative Timesteps: 210661215

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.67754
Policy Entropy: 1.30956
Value Function Loss: 0.01586

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.12908
Value Function Update Magnitude: 0.19927

Collected Steps per Second: 9743.67158
Overall Steps per Second: 6917.39621

Timestep Collection Time: 5.13482
Timestep Consumption Time: 2.09796
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.23278

Cumulative Model Updates: 25224
Cumulative Timesteps: 210711247

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.71827
Policy Entropy: 1.30692
Value Function Loss: 0.01531

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.05869
Policy Update Magnitude: 0.12724
Value Function Update Magnitude: 0.19899

Collected Steps per Second: 9613.48958
Overall Steps per Second: 6918.80619

Timestep Collection Time: 5.20415
Timestep Consumption Time: 2.02687
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.23102

Cumulative Model Updates: 25230
Cumulative Timesteps: 210761277

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 210761277...
Checkpoint 210761277 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.88812
Policy Entropy: 1.30800
Value Function Loss: 0.01495

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05062
Policy Update Magnitude: 0.12688
Value Function Update Magnitude: 0.18693

Collected Steps per Second: 10422.36325
Overall Steps per Second: 7212.78552

Timestep Collection Time: 4.80025
Timestep Consumption Time: 2.13604
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 6.93629

Cumulative Model Updates: 25236
Cumulative Timesteps: 210811307

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.97807
Policy Entropy: 1.30583
Value Function Loss: 0.01523

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06202
Policy Update Magnitude: 0.12896
Value Function Update Magnitude: 0.18778

Collected Steps per Second: 9854.92506
Overall Steps per Second: 6960.15801

Timestep Collection Time: 5.07635
Timestep Consumption Time: 2.11128
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.18762

Cumulative Model Updates: 25242
Cumulative Timesteps: 210861334

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.03860
Policy Entropy: 1.30765
Value Function Loss: 0.01548

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.05735
Policy Update Magnitude: 0.12913
Value Function Update Magnitude: 0.18015

Collected Steps per Second: 9785.86825
Overall Steps per Second: 6965.50312

Timestep Collection Time: 5.11390
Timestep Consumption Time: 2.07064
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.18455

Cumulative Model Updates: 25248
Cumulative Timesteps: 210911378

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.77809
Policy Entropy: 1.31073
Value Function Loss: 0.01559

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06116
Policy Update Magnitude: 0.12657
Value Function Update Magnitude: 0.18081

Collected Steps per Second: 10443.50502
Overall Steps per Second: 7260.36131

Timestep Collection Time: 4.79054
Timestep Consumption Time: 2.10030
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 6.89084

Cumulative Model Updates: 25254
Cumulative Timesteps: 210961408

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.92491
Policy Entropy: 1.31065
Value Function Loss: 0.01509

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.12286
Value Function Update Magnitude: 0.17859

Collected Steps per Second: 9877.41210
Overall Steps per Second: 7042.26134

Timestep Collection Time: 5.06286
Timestep Consumption Time: 2.03826
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.10113

Cumulative Model Updates: 25260
Cumulative Timesteps: 211011416

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.63443
Policy Entropy: 1.31021
Value Function Loss: 0.01509

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05303
Policy Update Magnitude: 0.12543
Value Function Update Magnitude: 0.17743

Collected Steps per Second: 9739.04496
Overall Steps per Second: 6965.46446

Timestep Collection Time: 5.13788
Timestep Consumption Time: 2.04585
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.18373

Cumulative Model Updates: 25266
Cumulative Timesteps: 211061454

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.62203
Policy Entropy: 1.30497
Value Function Loss: 0.01454

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06424
Policy Update Magnitude: 0.12750
Value Function Update Magnitude: 0.18997

Collected Steps per Second: 10259.16253
Overall Steps per Second: 7191.59998

Timestep Collection Time: 4.87603
Timestep Consumption Time: 2.07986
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 6.95589

Cumulative Model Updates: 25272
Cumulative Timesteps: 211111478

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.78081
Policy Entropy: 1.30848
Value Function Loss: 0.01474

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06231
Policy Update Magnitude: 0.12308
Value Function Update Magnitude: 0.18883

Collected Steps per Second: 9958.71536
Overall Steps per Second: 7010.42334

Timestep Collection Time: 5.02484
Timestep Consumption Time: 2.11324
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.13809

Cumulative Model Updates: 25278
Cumulative Timesteps: 211161519

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.60939
Policy Entropy: 1.30782
Value Function Loss: 0.01512

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05530
Policy Update Magnitude: 0.12371
Value Function Update Magnitude: 0.17102

Collected Steps per Second: 9644.93755
Overall Steps per Second: 6935.28208

Timestep Collection Time: 5.18614
Timestep Consumption Time: 2.02626
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.21240

Cumulative Model Updates: 25284
Cumulative Timesteps: 211211539

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.44496
Policy Entropy: 1.30927
Value Function Loss: 0.01568

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.05826
Policy Update Magnitude: 0.12793
Value Function Update Magnitude: 0.18292

Collected Steps per Second: 10440.92499
Overall Steps per Second: 7276.10673

Timestep Collection Time: 4.78971
Timestep Consumption Time: 2.08333
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 6.87304

Cumulative Model Updates: 25290
Cumulative Timesteps: 211261548

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 211261548...
Checkpoint 211261548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.95376
Policy Entropy: 1.31101
Value Function Loss: 0.01575

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06473
Policy Update Magnitude: 0.12892
Value Function Update Magnitude: 0.18054

Collected Steps per Second: 10039.08702
Overall Steps per Second: 7111.16661

Timestep Collection Time: 4.98103
Timestep Consumption Time: 2.05087
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.03190

Cumulative Model Updates: 25296
Cumulative Timesteps: 211311553

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.52189
Policy Entropy: 1.30884
Value Function Loss: 0.01544

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.06375
Policy Update Magnitude: 0.13761
Value Function Update Magnitude: 0.18507

Collected Steps per Second: 9679.03549
Overall Steps per Second: 6924.51005

Timestep Collection Time: 5.16611
Timestep Consumption Time: 2.05505
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.22116

Cumulative Model Updates: 25302
Cumulative Timesteps: 211361556

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.52483
Policy Entropy: 1.31091
Value Function Loss: 0.01542

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.15967
Value Function Update Magnitude: 0.19188

Collected Steps per Second: 10297.44392
Overall Steps per Second: 7104.77863

Timestep Collection Time: 4.85616
Timestep Consumption Time: 2.18220
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.03836

Cumulative Model Updates: 25308
Cumulative Timesteps: 211411562

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.05440
Policy Entropy: 1.30948
Value Function Loss: 0.01594

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.13845
Value Function Update Magnitude: 0.18438

Collected Steps per Second: 9875.16876
Overall Steps per Second: 6965.95266

Timestep Collection Time: 5.06503
Timestep Consumption Time: 2.11533
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.18035

Cumulative Model Updates: 25314
Cumulative Timesteps: 211461580

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.99368
Policy Entropy: 1.31168
Value Function Loss: 0.01659

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05636
Policy Update Magnitude: 0.13886
Value Function Update Magnitude: 0.17571

Collected Steps per Second: 9919.59992
Overall Steps per Second: 7073.82552

Timestep Collection Time: 5.04405
Timestep Consumption Time: 2.02920
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 7.07326

Cumulative Model Updates: 25320
Cumulative Timesteps: 211511615

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.81345
Policy Entropy: 1.30663
Value Function Loss: 0.01656

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06096
Policy Update Magnitude: 0.14265
Value Function Update Magnitude: 0.17971

Collected Steps per Second: 10499.91199
Overall Steps per Second: 7250.41995

Timestep Collection Time: 4.76194
Timestep Consumption Time: 2.13421
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.89615

Cumulative Model Updates: 25326
Cumulative Timesteps: 211561615

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.00177
Policy Entropy: 1.30688
Value Function Loss: 0.01627

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05906
Policy Update Magnitude: 0.13956
Value Function Update Magnitude: 0.17699

Collected Steps per Second: 9885.37729
Overall Steps per Second: 7024.33578

Timestep Collection Time: 5.05929
Timestep Consumption Time: 2.06067
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.11996

Cumulative Model Updates: 25332
Cumulative Timesteps: 211611628

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.74855
Policy Entropy: 1.30587
Value Function Loss: 0.01563

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.13178
Value Function Update Magnitude: 0.18233

Collected Steps per Second: 9749.88325
Overall Steps per Second: 7000.75210

Timestep Collection Time: 5.13063
Timestep Consumption Time: 2.01475
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.14538

Cumulative Model Updates: 25338
Cumulative Timesteps: 211661651

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.33756
Policy Entropy: 1.30882
Value Function Loss: 0.01634

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.13212
Value Function Update Magnitude: 0.17894

Collected Steps per Second: 10263.13597
Overall Steps per Second: 7230.24014

Timestep Collection Time: 4.87278
Timestep Consumption Time: 2.04400
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.91678

Cumulative Model Updates: 25344
Cumulative Timesteps: 211711661

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.52167
Policy Entropy: 1.30792
Value Function Loss: 0.01663

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.12823
Value Function Update Magnitude: 0.17982

Collected Steps per Second: 9821.43981
Overall Steps per Second: 7016.56469

Timestep Collection Time: 5.09325
Timestep Consumption Time: 2.03603
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.12927

Cumulative Model Updates: 25350
Cumulative Timesteps: 211761684

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 211761684...
Checkpoint 211761684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.44183
Policy Entropy: 1.31242
Value Function Loss: 0.01715

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06212
Policy Update Magnitude: 0.12999
Value Function Update Magnitude: 0.18200

Collected Steps per Second: 9762.28499
Overall Steps per Second: 6990.20575

Timestep Collection Time: 5.12237
Timestep Consumption Time: 2.03136
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.15372

Cumulative Model Updates: 25356
Cumulative Timesteps: 211811690

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.07777
Policy Entropy: 1.31301
Value Function Loss: 0.01693

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.12776
Value Function Update Magnitude: 0.19074

Collected Steps per Second: 10415.23621
Overall Steps per Second: 7244.15085

Timestep Collection Time: 4.80517
Timestep Consumption Time: 2.10344
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 6.90861

Cumulative Model Updates: 25362
Cumulative Timesteps: 211861737

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.45766
Policy Entropy: 1.31341
Value Function Loss: 0.01655

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.05852
Policy Update Magnitude: 0.12863
Value Function Update Magnitude: 0.20090

Collected Steps per Second: 9782.45124
Overall Steps per Second: 6983.99418

Timestep Collection Time: 5.11528
Timestep Consumption Time: 2.04967
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.16495

Cumulative Model Updates: 25368
Cumulative Timesteps: 211911777

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.10580
Policy Entropy: 1.30746
Value Function Loss: 0.01595

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06883
Policy Update Magnitude: 0.12995
Value Function Update Magnitude: 0.20871

Collected Steps per Second: 9745.02954
Overall Steps per Second: 6995.25258

Timestep Collection Time: 5.13513
Timestep Consumption Time: 2.01858
PPO Batch Consumption Time: 0.02465
Total Iteration Time: 7.15371

Cumulative Model Updates: 25374
Cumulative Timesteps: 211961819

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.28668
Policy Entropy: 1.30955
Value Function Loss: 0.01606

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06427
Policy Update Magnitude: 0.13147
Value Function Update Magnitude: 0.20252

Collected Steps per Second: 10409.56276
Overall Steps per Second: 7157.90830

Timestep Collection Time: 4.80616
Timestep Consumption Time: 2.18331
PPO Batch Consumption Time: 0.02459
Total Iteration Time: 6.98947

Cumulative Model Updates: 25380
Cumulative Timesteps: 212011849

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.12427
Policy Entropy: 1.30920
Value Function Loss: 0.01541

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.12990
Value Function Update Magnitude: 0.19966

Collected Steps per Second: 9870.09714
Overall Steps per Second: 6992.05239

Timestep Collection Time: 5.06591
Timestep Consumption Time: 2.08521
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.15112

Cumulative Model Updates: 25386
Cumulative Timesteps: 212061850

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.21091
Policy Entropy: 1.30997
Value Function Loss: 0.01612

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 0.12796
Value Function Update Magnitude: 0.20310

Collected Steps per Second: 9760.84473
Overall Steps per Second: 7062.76102

Timestep Collection Time: 5.12722
Timestep Consumption Time: 1.95868
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.08590

Cumulative Model Updates: 25392
Cumulative Timesteps: 212111896

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.04773
Policy Entropy: 1.30846
Value Function Loss: 0.01607

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06448
Policy Update Magnitude: 0.12664
Value Function Update Magnitude: 0.19325

Collected Steps per Second: 10295.84061
Overall Steps per Second: 7223.24040

Timestep Collection Time: 4.85691
Timestep Consumption Time: 2.06602
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 6.92293

Cumulative Model Updates: 25398
Cumulative Timesteps: 212161902

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.37198
Policy Entropy: 1.31047
Value Function Loss: 0.01608

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.12612
Value Function Update Magnitude: 0.19147

Collected Steps per Second: 9852.45511
Overall Steps per Second: 7014.79331

Timestep Collection Time: 5.07498
Timestep Consumption Time: 2.05296
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.12794

Cumulative Model Updates: 25404
Cumulative Timesteps: 212211903

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.01809
Policy Entropy: 1.31110
Value Function Loss: 0.01566

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.05791
Policy Update Magnitude: 0.12721
Value Function Update Magnitude: 0.18313

Collected Steps per Second: 9792.71789
Overall Steps per Second: 7000.26847

Timestep Collection Time: 5.10614
Timestep Consumption Time: 2.03687
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.14301

Cumulative Model Updates: 25410
Cumulative Timesteps: 212261906

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 212261906...
Checkpoint 212261906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.54921
Policy Entropy: 1.30791
Value Function Loss: 0.01630

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.13045
Value Function Update Magnitude: 0.17959

Collected Steps per Second: 10391.30995
Overall Steps per Second: 7247.30119

Timestep Collection Time: 4.81393
Timestep Consumption Time: 2.08837
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 6.90229

Cumulative Model Updates: 25416
Cumulative Timesteps: 212311929

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.34201
Policy Entropy: 1.31090
Value Function Loss: 0.01708

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.13259
Value Function Update Magnitude: 0.18322

Collected Steps per Second: 9959.30355
Overall Steps per Second: 7010.68732

Timestep Collection Time: 5.02465
Timestep Consumption Time: 2.11331
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 7.13796

Cumulative Model Updates: 25422
Cumulative Timesteps: 212361971

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.46326
Policy Entropy: 1.31607
Value Function Loss: 0.01669

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.05516
Policy Update Magnitude: 0.13984
Value Function Update Magnitude: 0.17889

Collected Steps per Second: 9746.04384
Overall Steps per Second: 6959.16226

Timestep Collection Time: 5.13244
Timestep Consumption Time: 2.05535
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.18779

Cumulative Model Updates: 25428
Cumulative Timesteps: 212411992

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.54714
Policy Entropy: 1.32061
Value Function Loss: 0.01590

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06312
Policy Update Magnitude: 0.14069
Value Function Update Magnitude: 0.17093

Collected Steps per Second: 10602.60903
Overall Steps per Second: 7309.15766

Timestep Collection Time: 4.71959
Timestep Consumption Time: 2.12661
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 6.84621

Cumulative Model Updates: 25434
Cumulative Timesteps: 212462032

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.23459
Policy Entropy: 1.32002
Value Function Loss: 0.01530

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.13457
Value Function Update Magnitude: 0.16938

Collected Steps per Second: 9833.91446
Overall Steps per Second: 6962.27546

Timestep Collection Time: 5.08739
Timestep Consumption Time: 2.09833
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.18573

Cumulative Model Updates: 25440
Cumulative Timesteps: 212512061

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.53215
Policy Entropy: 1.31598
Value Function Loss: 0.01557

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06547
Policy Update Magnitude: 0.13604
Value Function Update Magnitude: 0.16605

Collected Steps per Second: 9597.78390
Overall Steps per Second: 6907.22702

Timestep Collection Time: 5.21381
Timestep Consumption Time: 2.03092
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.24473

Cumulative Model Updates: 25446
Cumulative Timesteps: 212562102

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.86400
Policy Entropy: 1.31576
Value Function Loss: 0.01633

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06647
Policy Update Magnitude: 0.13678
Value Function Update Magnitude: 0.16399

Collected Steps per Second: 10270.98683
Overall Steps per Second: 1029.56992

Timestep Collection Time: 4.86837
Timestep Consumption Time: 43.69851
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 48.56688

Cumulative Model Updates: 25452
Cumulative Timesteps: 212612105

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.69756
Policy Entropy: 1.31858
Value Function Loss: 0.01666

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06029
Policy Update Magnitude: 0.13403
Value Function Update Magnitude: 0.17009

Collected Steps per Second: 9864.06980
Overall Steps per Second: 7053.08598

Timestep Collection Time: 5.07133
Timestep Consumption Time: 2.02116
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.09250

Cumulative Model Updates: 25458
Cumulative Timesteps: 212662129

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.66612
Policy Entropy: 1.31534
Value Function Loss: 0.01649

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06490
Policy Update Magnitude: 0.13008
Value Function Update Magnitude: 0.17557

Collected Steps per Second: 9768.38138
Overall Steps per Second: 7005.57324

Timestep Collection Time: 5.12122
Timestep Consumption Time: 2.01967
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.14089

Cumulative Model Updates: 25464
Cumulative Timesteps: 212712155

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.74231
Policy Entropy: 1.31414
Value Function Loss: 0.01625

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.13633
Value Function Update Magnitude: 0.17251

Collected Steps per Second: 10412.15485
Overall Steps per Second: 7232.25179

Timestep Collection Time: 4.80419
Timestep Consumption Time: 2.11233
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.91652

Cumulative Model Updates: 25470
Cumulative Timesteps: 212762177

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 212762177...
Checkpoint 212762177 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.06228
Policy Entropy: 1.30969
Value Function Loss: 0.01560

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.13133
Value Function Update Magnitude: 0.17330

Collected Steps per Second: 10001.41983
Overall Steps per Second: 7043.87458

Timestep Collection Time: 5.00149
Timestep Consumption Time: 2.10000
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.10149

Cumulative Model Updates: 25476
Cumulative Timesteps: 212812199

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.35291
Policy Entropy: 1.30982
Value Function Loss: 0.01575

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.12772
Value Function Update Magnitude: 0.17703

Collected Steps per Second: 9994.59722
Overall Steps per Second: 7068.26522

Timestep Collection Time: 5.00500
Timestep Consumption Time: 2.07212
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 7.07713

Cumulative Model Updates: 25482
Cumulative Timesteps: 212862222

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.14209
Policy Entropy: 1.31472
Value Function Loss: 0.01582

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.12780
Value Function Update Magnitude: 0.17061

Collected Steps per Second: 10380.32548
Overall Steps per Second: 7225.16137

Timestep Collection Time: 4.81844
Timestep Consumption Time: 2.10417
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 6.92261

Cumulative Model Updates: 25488
Cumulative Timesteps: 212912239

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.68438
Policy Entropy: 1.31783
Value Function Loss: 0.01590

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06049
Policy Update Magnitude: 0.13322
Value Function Update Magnitude: 0.16645

Collected Steps per Second: 9885.30787
Overall Steps per Second: 6939.15983

Timestep Collection Time: 5.05872
Timestep Consumption Time: 2.14777
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.20649

Cumulative Model Updates: 25494
Cumulative Timesteps: 212962246

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.21183
Policy Entropy: 1.32104
Value Function Loss: 0.01693

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05613
Policy Update Magnitude: 0.13635
Value Function Update Magnitude: 0.16685

Collected Steps per Second: 9699.81412
Overall Steps per Second: 6978.50606

Timestep Collection Time: 5.15762
Timestep Consumption Time: 2.01124
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.16887

Cumulative Model Updates: 25500
Cumulative Timesteps: 213012274

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.95393
Policy Entropy: 1.31713
Value Function Loss: 0.01583

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06657
Policy Update Magnitude: 0.13735
Value Function Update Magnitude: 0.17203

Collected Steps per Second: 10360.74771
Overall Steps per Second: 7237.68834

Timestep Collection Time: 4.82784
Timestep Consumption Time: 2.08321
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 6.91105

Cumulative Model Updates: 25506
Cumulative Timesteps: 213062294

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.86272
Policy Entropy: 1.31505
Value Function Loss: 0.01644

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.14010
Value Function Update Magnitude: 0.17524

Collected Steps per Second: 9899.42448
Overall Steps per Second: 7060.42506

Timestep Collection Time: 5.05312
Timestep Consumption Time: 2.03186
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.08498

Cumulative Model Updates: 25512
Cumulative Timesteps: 213112317

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.63337
Policy Entropy: 1.31534
Value Function Loss: 0.01629

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.13386
Value Function Update Magnitude: 0.18017

Collected Steps per Second: 9765.20799
Overall Steps per Second: 6942.20471

Timestep Collection Time: 5.12268
Timestep Consumption Time: 2.08310
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.20578

Cumulative Model Updates: 25518
Cumulative Timesteps: 213162341

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.77785
Policy Entropy: 1.31583
Value Function Loss: 0.01642

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.05356
Policy Update Magnitude: 0.13490
Value Function Update Magnitude: 0.18680

Collected Steps per Second: 10541.37981
Overall Steps per Second: 7334.12639

Timestep Collection Time: 4.74511
Timestep Consumption Time: 2.07506
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 6.82017

Cumulative Model Updates: 25524
Cumulative Timesteps: 213212361

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.48147
Policy Entropy: 1.31165
Value Function Loss: 0.01657

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.05896
Policy Update Magnitude: 0.13361
Value Function Update Magnitude: 0.18563

Collected Steps per Second: 9859.61891
Overall Steps per Second: 6993.96088

Timestep Collection Time: 5.07373
Timestep Consumption Time: 2.07887
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.15260

Cumulative Model Updates: 25530
Cumulative Timesteps: 213262386

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 213262386...
Checkpoint 213262386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.19602
Policy Entropy: 1.31048
Value Function Loss: 0.01677

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.06319
Policy Update Magnitude: 0.13425
Value Function Update Magnitude: 0.17940

Collected Steps per Second: 9752.85139
Overall Steps per Second: 6949.34497

Timestep Collection Time: 5.12855
Timestep Consumption Time: 2.06896
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.19751

Cumulative Model Updates: 25536
Cumulative Timesteps: 213312404

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.07052
Policy Entropy: 1.31047
Value Function Loss: 0.01644

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.05828
Policy Update Magnitude: 0.13313
Value Function Update Magnitude: 0.17716

Collected Steps per Second: 10438.53423
Overall Steps per Second: 7258.29349

Timestep Collection Time: 4.79291
Timestep Consumption Time: 2.10003
PPO Batch Consumption Time: 0.02402
Total Iteration Time: 6.89294

Cumulative Model Updates: 25542
Cumulative Timesteps: 213362435

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.21108
Policy Entropy: 1.30980
Value Function Loss: 0.01523

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.05999
Policy Update Magnitude: 0.13124
Value Function Update Magnitude: 0.17721

Collected Steps per Second: 9934.13897
Overall Steps per Second: 7102.52613

Timestep Collection Time: 5.03718
Timestep Consumption Time: 2.00821
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.04538

Cumulative Model Updates: 25548
Cumulative Timesteps: 213412475

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.06108
Policy Entropy: 1.31080
Value Function Loss: 0.01398

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05556
Policy Update Magnitude: 0.12839
Value Function Update Magnitude: 0.17755

Collected Steps per Second: 9824.85958
Overall Steps per Second: 6988.30268

Timestep Collection Time: 5.09045
Timestep Consumption Time: 2.06622
PPO Batch Consumption Time: 0.02440
Total Iteration Time: 7.15667

Cumulative Model Updates: 25554
Cumulative Timesteps: 213462488

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.00887
Policy Entropy: 1.31137
Value Function Loss: 0.01518

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05644
Policy Update Magnitude: 0.12832
Value Function Update Magnitude: 0.17484

Collected Steps per Second: 10297.43192
Overall Steps per Second: 7198.78916

Timestep Collection Time: 4.85888
Timestep Consumption Time: 2.09145
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 6.95034

Cumulative Model Updates: 25560
Cumulative Timesteps: 213512522

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.63873
Policy Entropy: 1.31177
Value Function Loss: 0.01540

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06544
Policy Update Magnitude: 0.12861
Value Function Update Magnitude: 0.18253

Collected Steps per Second: 9971.66954
Overall Steps per Second: 7009.35698

Timestep Collection Time: 5.01591
Timestep Consumption Time: 2.11984
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.13575

Cumulative Model Updates: 25566
Cumulative Timesteps: 213562539

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.33165
Policy Entropy: 1.30539
Value Function Loss: 0.01620

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.13382
Value Function Update Magnitude: 0.18853

Collected Steps per Second: 9695.79666
Overall Steps per Second: 6952.76868

Timestep Collection Time: 5.16059
Timestep Consumption Time: 2.03597
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.19656

Cumulative Model Updates: 25572
Cumulative Timesteps: 213612575

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.48732
Policy Entropy: 1.30571
Value Function Loss: 0.01511

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.13249
Value Function Update Magnitude: 0.18395

Collected Steps per Second: 10382.20230
Overall Steps per Second: 7220.14699

Timestep Collection Time: 4.81747
Timestep Consumption Time: 2.10981
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 6.92728

Cumulative Model Updates: 25578
Cumulative Timesteps: 213662591

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.30895
Policy Entropy: 1.30602
Value Function Loss: 0.01552

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.13071
Value Function Update Magnitude: 0.17779

Collected Steps per Second: 10010.60330
Overall Steps per Second: 7107.27098

Timestep Collection Time: 4.99870
Timestep Consumption Time: 2.04198
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.04068

Cumulative Model Updates: 25584
Cumulative Timesteps: 213712631

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.44171
Policy Entropy: 1.31732
Value Function Loss: 0.01499

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06793
Policy Update Magnitude: 0.12617
Value Function Update Magnitude: 0.17514

Collected Steps per Second: 9807.57115
Overall Steps per Second: 7005.73075

Timestep Collection Time: 5.09861
Timestep Consumption Time: 2.03912
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.13773

Cumulative Model Updates: 25590
Cumulative Timesteps: 213762636

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 213762636...
Checkpoint 213762636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.75675
Policy Entropy: 1.31289
Value Function Loss: 0.01536

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06410
Policy Update Magnitude: 0.13166
Value Function Update Magnitude: 0.18208

Collected Steps per Second: 10283.74222
Overall Steps per Second: 7168.77349

Timestep Collection Time: 4.86370
Timestep Consumption Time: 2.11337
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.97707

Cumulative Model Updates: 25596
Cumulative Timesteps: 213812653

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.27825
Policy Entropy: 1.31019
Value Function Loss: 0.01534

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.13738
Value Function Update Magnitude: 0.18325

Collected Steps per Second: 9803.32604
Overall Steps per Second: 7029.72272

Timestep Collection Time: 5.10174
Timestep Consumption Time: 2.01291
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.11465

Cumulative Model Updates: 25602
Cumulative Timesteps: 213862667

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.56114
Policy Entropy: 1.30536
Value Function Loss: 0.01583

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07444
Policy Update Magnitude: 0.13420
Value Function Update Magnitude: 0.17666

Collected Steps per Second: 9620.84105
Overall Steps per Second: 6884.36464

Timestep Collection Time: 5.19715
Timestep Consumption Time: 2.06582
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.26298

Cumulative Model Updates: 25608
Cumulative Timesteps: 213912668

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.57666
Policy Entropy: 1.30204
Value Function Loss: 0.01546

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.13485
Value Function Update Magnitude: 0.17254

Collected Steps per Second: 10285.25823
Overall Steps per Second: 7200.38760

Timestep Collection Time: 4.86230
Timestep Consumption Time: 2.08316
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 6.94546

Cumulative Model Updates: 25614
Cumulative Timesteps: 213962678

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.37545
Policy Entropy: 1.30348
Value Function Loss: 0.01588

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.13544
Value Function Update Magnitude: 0.17111

Collected Steps per Second: 9793.82722
Overall Steps per Second: 7003.70429

Timestep Collection Time: 5.10883
Timestep Consumption Time: 2.03525
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.14408

Cumulative Model Updates: 25620
Cumulative Timesteps: 214012713

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.31267
Policy Entropy: 1.30488
Value Function Loss: 0.01484

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.13536
Value Function Update Magnitude: 0.17064

Collected Steps per Second: 9843.89947
Overall Steps per Second: 7026.42989

Timestep Collection Time: 5.08061
Timestep Consumption Time: 2.03723
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.11784

Cumulative Model Updates: 25626
Cumulative Timesteps: 214062726

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.15238
Policy Entropy: 1.31298
Value Function Loss: 0.01519

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05915
Policy Update Magnitude: 0.13613
Value Function Update Magnitude: 0.17002

Collected Steps per Second: 10356.25641
Overall Steps per Second: 7218.62671

Timestep Collection Time: 4.83022
Timestep Consumption Time: 2.09949
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 6.92971

Cumulative Model Updates: 25632
Cumulative Timesteps: 214112749

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.90166
Policy Entropy: 1.31139
Value Function Loss: 0.01516

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.13238
Value Function Update Magnitude: 0.17176

Collected Steps per Second: 9844.26775
Overall Steps per Second: 7050.98048

Timestep Collection Time: 5.08123
Timestep Consumption Time: 2.01296
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.09419

Cumulative Model Updates: 25638
Cumulative Timesteps: 214162770

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.22535
Policy Entropy: 1.30985
Value Function Loss: 0.01528

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.05982
Policy Update Magnitude: 0.13156
Value Function Update Magnitude: 0.18483

Collected Steps per Second: 9909.62271
Overall Steps per Second: 7068.63912

Timestep Collection Time: 5.04802
Timestep Consumption Time: 2.02887
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.07689

Cumulative Model Updates: 25644
Cumulative Timesteps: 214212794

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.57305
Policy Entropy: 1.30931
Value Function Loss: 0.01574

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.13055
Value Function Update Magnitude: 0.18587

Collected Steps per Second: 10423.77121
Overall Steps per Second: 7252.70073

Timestep Collection Time: 4.80028
Timestep Consumption Time: 2.09881
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 6.89909

Cumulative Model Updates: 25650
Cumulative Timesteps: 214262831

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 214262831...
Checkpoint 214262831 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.62167
Policy Entropy: 1.31311
Value Function Loss: 0.01586

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06019
Policy Update Magnitude: 0.13164
Value Function Update Magnitude: 0.18623

Collected Steps per Second: 9951.89681
Overall Steps per Second: 7022.80059

Timestep Collection Time: 5.02457
Timestep Consumption Time: 2.09567
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.12024

Cumulative Model Updates: 25656
Cumulative Timesteps: 214312835

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.12396
Policy Entropy: 1.31437
Value Function Loss: 0.01639

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05899
Policy Update Magnitude: 0.13395
Value Function Update Magnitude: 0.18313

Collected Steps per Second: 9694.23683
Overall Steps per Second: 6924.52024

Timestep Collection Time: 5.16193
Timestep Consumption Time: 2.06470
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.22664

Cumulative Model Updates: 25662
Cumulative Timesteps: 214362876

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.70746
Policy Entropy: 1.30964
Value Function Loss: 0.01653

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.13166
Value Function Update Magnitude: 0.18058

Collected Steps per Second: 10406.49101
Overall Steps per Second: 7259.96163

Timestep Collection Time: 4.80767
Timestep Consumption Time: 2.08369
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 6.89136

Cumulative Model Updates: 25668
Cumulative Timesteps: 214412907

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.62144
Policy Entropy: 1.30452
Value Function Loss: 0.01670

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.13047
Value Function Update Magnitude: 0.17509

Collected Steps per Second: 9812.25127
Overall Steps per Second: 6966.94169

Timestep Collection Time: 5.09801
Timestep Consumption Time: 2.08204
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.18005

Cumulative Model Updates: 25674
Cumulative Timesteps: 214462930

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.26997
Policy Entropy: 1.30433
Value Function Loss: 0.01619

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06721
Policy Update Magnitude: 0.13394
Value Function Update Magnitude: 0.17423

Collected Steps per Second: 9727.72498
Overall Steps per Second: 6962.25676

Timestep Collection Time: 5.14056
Timestep Consumption Time: 2.04188
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.18244

Cumulative Model Updates: 25680
Cumulative Timesteps: 214512936

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.31652
Policy Entropy: 1.30106
Value Function Loss: 0.01556

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.12769
Value Function Update Magnitude: 0.17097

Collected Steps per Second: 10356.35186
Overall Steps per Second: 7206.60158

Timestep Collection Time: 4.82940
Timestep Consumption Time: 2.11076
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 6.94016

Cumulative Model Updates: 25686
Cumulative Timesteps: 214562951

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.81017
Policy Entropy: 1.30233
Value Function Loss: 0.01464

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.12461
Value Function Update Magnitude: 0.16509

Collected Steps per Second: 10182.67013
Overall Steps per Second: 7255.45384

Timestep Collection Time: 4.91443
Timestep Consumption Time: 1.98273
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 6.89716

Cumulative Model Updates: 25692
Cumulative Timesteps: 214612993

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.90148
Policy Entropy: 1.30784
Value Function Loss: 0.01444

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.12627
Value Function Update Magnitude: 0.16968

Collected Steps per Second: 10021.88725
Overall Steps per Second: 7117.50155

Timestep Collection Time: 4.99197
Timestep Consumption Time: 2.03704
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.02901

Cumulative Model Updates: 25698
Cumulative Timesteps: 214663022

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.94361
Policy Entropy: 1.31460
Value Function Loss: 0.01514

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.05965
Policy Update Magnitude: 0.12500
Value Function Update Magnitude: 0.17174

Collected Steps per Second: 10175.54731
Overall Steps per Second: 7111.96165

Timestep Collection Time: 4.91639
Timestep Consumption Time: 2.11781
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.03421

Cumulative Model Updates: 25704
Cumulative Timesteps: 214713049

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.70376
Policy Entropy: 1.31469
Value Function Loss: 0.01598

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.13004
Value Function Update Magnitude: 0.18023

Collected Steps per Second: 9902.38784
Overall Steps per Second: 6999.57538

Timestep Collection Time: 5.05323
Timestep Consumption Time: 2.09564
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.14886

Cumulative Model Updates: 25710
Cumulative Timesteps: 214763088

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 214763088...
Checkpoint 214763088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.27981
Policy Entropy: 1.31564
Value Function Loss: 0.01649

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.12936
Value Function Update Magnitude: 0.19202

Collected Steps per Second: 9969.93733
Overall Steps per Second: 7066.12285

Timestep Collection Time: 5.01708
Timestep Consumption Time: 2.06176
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 7.07885

Cumulative Model Updates: 25716
Cumulative Timesteps: 214813108

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.58134
Policy Entropy: 1.31328
Value Function Loss: 0.01569

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06280
Policy Update Magnitude: 0.13320
Value Function Update Magnitude: 0.18375

Collected Steps per Second: 10323.42656
Overall Steps per Second: 7144.35540

Timestep Collection Time: 4.84655
Timestep Consumption Time: 2.15660
PPO Batch Consumption Time: 0.03186
Total Iteration Time: 7.00315

Cumulative Model Updates: 25722
Cumulative Timesteps: 214863141

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.49243
Policy Entropy: 1.31047
Value Function Loss: 0.01610

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.06717
Policy Update Magnitude: 0.13206
Value Function Update Magnitude: 0.17480

Collected Steps per Second: 9576.56498
Overall Steps per Second: 6873.27677

Timestep Collection Time: 5.22265
Timestep Consumption Time: 2.05409
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.27673

Cumulative Model Updates: 25728
Cumulative Timesteps: 214913156

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.15400
Policy Entropy: 1.31031
Value Function Loss: 0.01630

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.05982
Policy Update Magnitude: 0.13156
Value Function Update Magnitude: 0.17360

Collected Steps per Second: 9706.87002
Overall Steps per Second: 6936.15022

Timestep Collection Time: 5.15243
Timestep Consumption Time: 2.05819
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.21063

Cumulative Model Updates: 25734
Cumulative Timesteps: 214963170

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.51415
Policy Entropy: 1.31083
Value Function Loss: 0.01609

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.05864
Policy Update Magnitude: 0.13340
Value Function Update Magnitude: 0.17364

Collected Steps per Second: 10353.67434
Overall Steps per Second: 7195.87887

Timestep Collection Time: 4.83017
Timestep Consumption Time: 2.11964
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 6.94981

Cumulative Model Updates: 25740
Cumulative Timesteps: 215013180

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.91000
Policy Entropy: 1.30748
Value Function Loss: 0.01622

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.13181
Value Function Update Magnitude: 0.16800

Collected Steps per Second: 9931.29901
Overall Steps per Second: 7037.11184

Timestep Collection Time: 5.03882
Timestep Consumption Time: 2.07234
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.11116

Cumulative Model Updates: 25746
Cumulative Timesteps: 215063222

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.97533
Policy Entropy: 1.30356
Value Function Loss: 0.01631

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.07942
Policy Update Magnitude: 0.12875
Value Function Update Magnitude: 0.17659

Collected Steps per Second: 9679.33316
Overall Steps per Second: 6937.03819

Timestep Collection Time: 5.16781
Timestep Consumption Time: 2.04290
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.21071

Cumulative Model Updates: 25752
Cumulative Timesteps: 215113243

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.87953
Policy Entropy: 1.30508
Value Function Loss: 0.01634

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.12839
Value Function Update Magnitude: 0.18607

Collected Steps per Second: 10317.56539
Overall Steps per Second: 7214.75829

Timestep Collection Time: 4.84853
Timestep Consumption Time: 2.08518
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.93370

Cumulative Model Updates: 25758
Cumulative Timesteps: 215163268

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.18618
Policy Entropy: 1.30684
Value Function Loss: 0.01628

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07198
Policy Update Magnitude: 0.12748
Value Function Update Magnitude: 0.19393

Collected Steps per Second: 9927.95950
Overall Steps per Second: 6984.66257

Timestep Collection Time: 5.04001
Timestep Consumption Time: 2.12383
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.16384

Cumulative Model Updates: 25764
Cumulative Timesteps: 215213305

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.46347
Policy Entropy: 1.31189
Value Function Loss: 0.01566

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06177
Policy Update Magnitude: 0.12819
Value Function Update Magnitude: 0.19720

Collected Steps per Second: 9765.62952
Overall Steps per Second: 6984.71893

Timestep Collection Time: 5.12112
Timestep Consumption Time: 2.03894
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.16006

Cumulative Model Updates: 25770
Cumulative Timesteps: 215263316

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 215263316...
Checkpoint 215263316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.07804
Policy Entropy: 1.30739
Value Function Loss: 0.01598

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.12741
Value Function Update Magnitude: 0.19222

Collected Steps per Second: 10198.98549
Overall Steps per Second: 7099.13234

Timestep Collection Time: 4.90451
Timestep Consumption Time: 2.14156
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.04607

Cumulative Model Updates: 25776
Cumulative Timesteps: 215313337

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.72034
Policy Entropy: 1.30971
Value Function Loss: 0.01610

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06420
Policy Update Magnitude: 0.12980
Value Function Update Magnitude: 0.19015

Collected Steps per Second: 9754.08406
Overall Steps per Second: 6981.74320

Timestep Collection Time: 5.12872
Timestep Consumption Time: 2.03654
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.16526

Cumulative Model Updates: 25782
Cumulative Timesteps: 215363363

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.40026
Policy Entropy: 1.30266
Value Function Loss: 0.01650

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.13195
Value Function Update Magnitude: 0.18405

Collected Steps per Second: 9775.40319
Overall Steps per Second: 6997.10210

Timestep Collection Time: 5.11498
Timestep Consumption Time: 2.03098
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.14596

Cumulative Model Updates: 25788
Cumulative Timesteps: 215413364

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.75230
Policy Entropy: 1.30511
Value Function Loss: 0.01700

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.12811
Value Function Update Magnitude: 0.17781

Collected Steps per Second: 9622.94122
Overall Steps per Second: 6707.65230

Timestep Collection Time: 5.19675
Timestep Consumption Time: 2.25862
PPO Batch Consumption Time: 0.02940
Total Iteration Time: 7.45537

Cumulative Model Updates: 25794
Cumulative Timesteps: 215463372

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.71080
Policy Entropy: 1.30447
Value Function Loss: 0.01755

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.12548
Value Function Update Magnitude: 0.18253

Collected Steps per Second: 9121.26439
Overall Steps per Second: 6567.77639

Timestep Collection Time: 5.48235
Timestep Consumption Time: 2.13149
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 7.61384

Cumulative Model Updates: 25800
Cumulative Timesteps: 215513378

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.05052
Policy Entropy: 1.30717
Value Function Loss: 0.01692

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06542
Policy Update Magnitude: 0.13071
Value Function Update Magnitude: 0.18245

Collected Steps per Second: 9894.46656
Overall Steps per Second: 6964.79368

Timestep Collection Time: 5.05454
Timestep Consumption Time: 2.12614
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.18069

Cumulative Model Updates: 25806
Cumulative Timesteps: 215563390

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.77948
Policy Entropy: 1.30167
Value Function Loss: 0.01598

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.12974
Value Function Update Magnitude: 0.18046

Collected Steps per Second: 10182.61497
Overall Steps per Second: 7148.49439

Timestep Collection Time: 4.91053
Timestep Consumption Time: 2.08423
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 6.99476

Cumulative Model Updates: 25812
Cumulative Timesteps: 215613392

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.61842
Policy Entropy: 1.29805
Value Function Loss: 0.01575

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.12611
Value Function Update Magnitude: 0.18586

Collected Steps per Second: 9908.11617
Overall Steps per Second: 6979.35601

Timestep Collection Time: 5.04788
Timestep Consumption Time: 2.11825
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.16613

Cumulative Model Updates: 25818
Cumulative Timesteps: 215663407

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.33087
Policy Entropy: 1.29840
Value Function Loss: 0.01642

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.12556
Value Function Update Magnitude: 0.18109

Collected Steps per Second: 9791.82932
Overall Steps per Second: 6963.94264

Timestep Collection Time: 5.10691
Timestep Consumption Time: 2.07379
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.18070

Cumulative Model Updates: 25824
Cumulative Timesteps: 215713413

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.81730
Policy Entropy: 1.30494
Value Function Loss: 0.01675

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.12724
Value Function Update Magnitude: 0.19848

Collected Steps per Second: 10388.86491
Overall Steps per Second: 7231.51844

Timestep Collection Time: 4.81583
Timestep Consumption Time: 2.10263
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 6.91846

Cumulative Model Updates: 25830
Cumulative Timesteps: 215763444

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 215763444...
Checkpoint 215763444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.49971
Policy Entropy: 1.30336
Value Function Loss: 0.01733

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.12983
Value Function Update Magnitude: 0.20229

Collected Steps per Second: 9741.53990
Overall Steps per Second: 6964.69189

Timestep Collection Time: 5.13471
Timestep Consumption Time: 2.04723
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 7.18194

Cumulative Model Updates: 25836
Cumulative Timesteps: 215813464

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.49401
Policy Entropy: 1.29880
Value Function Loss: 0.01676

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.13225
Value Function Update Magnitude: 0.20494

Collected Steps per Second: 9749.23249
Overall Steps per Second: 6920.70447

Timestep Collection Time: 5.12943
Timestep Consumption Time: 2.09642
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.22585

Cumulative Model Updates: 25842
Cumulative Timesteps: 215863472

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.12973
Policy Entropy: 1.29792
Value Function Loss: 0.01695

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.12877
Value Function Update Magnitude: 0.20133

Collected Steps per Second: 10387.28294
Overall Steps per Second: 7210.89257

Timestep Collection Time: 4.81637
Timestep Consumption Time: 2.12161
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.93798

Cumulative Model Updates: 25848
Cumulative Timesteps: 215913501

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.73007
Policy Entropy: 1.30611
Value Function Loss: 0.01639

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.13050
Value Function Update Magnitude: 0.19292

Collected Steps per Second: 9794.46079
Overall Steps per Second: 7003.54629

Timestep Collection Time: 5.10646
Timestep Consumption Time: 2.03492
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 7.14138

Cumulative Model Updates: 25854
Cumulative Timesteps: 215963516

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.39093
Policy Entropy: 1.31794
Value Function Loss: 0.01735

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06346
Policy Update Magnitude: 0.13094
Value Function Update Magnitude: 0.19486

Collected Steps per Second: 9825.39562
Overall Steps per Second: 6999.31479

Timestep Collection Time: 5.09242
Timestep Consumption Time: 2.05614
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 7.14856

Cumulative Model Updates: 25860
Cumulative Timesteps: 216013551

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.00674
Policy Entropy: 1.30994
Value Function Loss: 0.01695

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.13049
Value Function Update Magnitude: 0.20882

Collected Steps per Second: 10221.27770
Overall Steps per Second: 7186.70209

Timestep Collection Time: 4.89508
Timestep Consumption Time: 2.06694
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 6.96203

Cumulative Model Updates: 25866
Cumulative Timesteps: 216063585

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.33076
Policy Entropy: 1.31083
Value Function Loss: 0.01654

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.12505
Value Function Update Magnitude: 0.21591

Collected Steps per Second: 9821.86384
Overall Steps per Second: 6983.44745

Timestep Collection Time: 5.09068
Timestep Consumption Time: 2.06910
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.15979

Cumulative Model Updates: 25872
Cumulative Timesteps: 216113585

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.38005
Policy Entropy: 1.30197
Value Function Loss: 0.01656

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.12856
Value Function Update Magnitude: 0.21515

Collected Steps per Second: 9757.14318
Overall Steps per Second: 6924.27203

Timestep Collection Time: 5.12835
Timestep Consumption Time: 2.09812
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 7.22646

Cumulative Model Updates: 25878
Cumulative Timesteps: 216163623

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.47112
Policy Entropy: 1.30400
Value Function Loss: 0.01614

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.13060
Value Function Update Magnitude: 0.20627

Collected Steps per Second: 10252.79435
Overall Steps per Second: 7217.22427

Timestep Collection Time: 4.88033
Timestep Consumption Time: 2.05267
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.93300

Cumulative Model Updates: 25884
Cumulative Timesteps: 216213660

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.94961
Policy Entropy: 1.30087
Value Function Loss: 0.01617

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.14497
Value Function Update Magnitude: 0.19494

Collected Steps per Second: 9753.78867
Overall Steps per Second: 7026.47133

Timestep Collection Time: 5.12662
Timestep Consumption Time: 1.98989
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.11652

Cumulative Model Updates: 25890
Cumulative Timesteps: 216263664

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 216263664...
Checkpoint 216263664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.24138
Policy Entropy: 1.29893
Value Function Loss: 0.01642

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.15015
Value Function Update Magnitude: 0.19290

Collected Steps per Second: 9831.82570
Overall Steps per Second: 7044.59371

Timestep Collection Time: 5.08888
Timestep Consumption Time: 2.01344
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.10233

Cumulative Model Updates: 25896
Cumulative Timesteps: 216313697

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.39099
Policy Entropy: 1.29559
Value Function Loss: 0.01716

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.13440
Value Function Update Magnitude: 0.19408

Collected Steps per Second: 10584.71924
Overall Steps per Second: 7238.27457

Timestep Collection Time: 4.72511
Timestep Consumption Time: 2.18454
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 6.90966

Cumulative Model Updates: 25902
Cumulative Timesteps: 216363711

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.32357
Policy Entropy: 1.29370
Value Function Loss: 0.01854

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.13078
Value Function Update Magnitude: 0.19511

Collected Steps per Second: 9704.25627
Overall Steps per Second: 6864.22328

Timestep Collection Time: 5.15413
Timestep Consumption Time: 2.13249
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.28662

Cumulative Model Updates: 25908
Cumulative Timesteps: 216413728

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.70989
Policy Entropy: 1.28804
Value Function Loss: 0.01752

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.13384
Value Function Update Magnitude: 0.19632

Collected Steps per Second: 9733.86328
Overall Steps per Second: 6931.63716

Timestep Collection Time: 5.13835
Timestep Consumption Time: 2.07726
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 7.21561

Cumulative Model Updates: 25914
Cumulative Timesteps: 216463744

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.16369
Policy Entropy: 1.29077
Value Function Loss: 0.01772

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07384
Policy Update Magnitude: 0.13455
Value Function Update Magnitude: 0.20083

Collected Steps per Second: 10353.25110
Overall Steps per Second: 7177.50160

Timestep Collection Time: 4.83153
Timestep Consumption Time: 2.13775
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 6.96928

Cumulative Model Updates: 25920
Cumulative Timesteps: 216513766

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.24923
Policy Entropy: 1.28677
Value Function Loss: 0.01687

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.13381
Value Function Update Magnitude: 0.20178

Collected Steps per Second: 9836.24347
Overall Steps per Second: 7003.67546

Timestep Collection Time: 5.08375
Timestep Consumption Time: 2.05607
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.13982

Cumulative Model Updates: 25926
Cumulative Timesteps: 216563771

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.05138
Policy Entropy: 1.28731
Value Function Loss: 0.01650

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.13623
Value Function Update Magnitude: 0.19809

Collected Steps per Second: 9805.65249
Overall Steps per Second: 7000.14148

Timestep Collection Time: 5.10185
Timestep Consumption Time: 2.04472
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 7.14657

Cumulative Model Updates: 25932
Cumulative Timesteps: 216613798

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.12858
Policy Entropy: 1.28590
Value Function Loss: 0.01602

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.13443
Value Function Update Magnitude: 0.19519

Collected Steps per Second: 10309.04111
Overall Steps per Second: 7146.92094

Timestep Collection Time: 4.85254
Timestep Consumption Time: 2.14698
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 6.99952

Cumulative Model Updates: 25938
Cumulative Timesteps: 216663823

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.89155
Policy Entropy: 1.28815
Value Function Loss: 0.01576

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.13087
Value Function Update Magnitude: 0.19472

Collected Steps per Second: 10135.43755
Overall Steps per Second: 7146.55207

Timestep Collection Time: 4.93378
Timestep Consumption Time: 2.06344
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.99722

Cumulative Model Updates: 25944
Cumulative Timesteps: 216713829

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.19315
Policy Entropy: 1.28691
Value Function Loss: 0.01607

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.13099
Value Function Update Magnitude: 0.19486

Collected Steps per Second: 9774.95621
Overall Steps per Second: 6978.16025

Timestep Collection Time: 5.11654
Timestep Consumption Time: 2.05067
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.16722

Cumulative Model Updates: 25950
Cumulative Timesteps: 216763843

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 216763843...
Checkpoint 216763843 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.70408
Policy Entropy: 1.28158
Value Function Loss: 0.01727

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.13516
Value Function Update Magnitude: 0.18727

Collected Steps per Second: 10444.97877
Overall Steps per Second: 7029.93680

Timestep Collection Time: 4.79024
Timestep Consumption Time: 2.32703
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.11728

Cumulative Model Updates: 25956
Cumulative Timesteps: 216813877

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.30874
Policy Entropy: 1.27585
Value Function Loss: 0.01759

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.13925
Value Function Update Magnitude: 0.18687

Collected Steps per Second: 10251.80591
Overall Steps per Second: 7154.01011

Timestep Collection Time: 4.87924
Timestep Consumption Time: 2.11278
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 6.99202

Cumulative Model Updates: 25962
Cumulative Timesteps: 216863898

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.97249
Policy Entropy: 1.27711
Value Function Loss: 0.01767

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.13775
Value Function Update Magnitude: 0.19222

Collected Steps per Second: 9788.35488
Overall Steps per Second: 7021.72275

Timestep Collection Time: 5.10821
Timestep Consumption Time: 2.01269
PPO Batch Consumption Time: 0.02464
Total Iteration Time: 7.12090

Cumulative Model Updates: 25968
Cumulative Timesteps: 216913899

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.90310
Policy Entropy: 1.27826
Value Function Loss: 0.01765

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.13250
Value Function Update Magnitude: 0.18636

Collected Steps per Second: 9687.51165
Overall Steps per Second: 6981.98221

Timestep Collection Time: 5.16170
Timestep Consumption Time: 2.00017
PPO Batch Consumption Time: 0.02441
Total Iteration Time: 7.16186

Cumulative Model Updates: 25974
Cumulative Timesteps: 216963903

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.36494
Policy Entropy: 1.28032
Value Function Loss: 0.01878

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.13715
Value Function Update Magnitude: 0.19143

Collected Steps per Second: 10365.48164
Overall Steps per Second: 7189.46068

Timestep Collection Time: 4.82582
Timestep Consumption Time: 2.13186
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 6.95768

Cumulative Model Updates: 25980
Cumulative Timesteps: 217013925

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.26601
Policy Entropy: 1.28485
Value Function Loss: 0.01907

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.13728
Value Function Update Magnitude: 0.19441

Collected Steps per Second: 9757.61551
Overall Steps per Second: 6997.30909

Timestep Collection Time: 5.12625
Timestep Consumption Time: 2.02221
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.14846

Cumulative Model Updates: 25986
Cumulative Timesteps: 217063945

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.19621
Policy Entropy: 1.28800
Value Function Loss: 0.01778

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.13564
Value Function Update Magnitude: 0.19129

Collected Steps per Second: 9646.09059
Overall Steps per Second: 6931.94191

Timestep Collection Time: 5.18614
Timestep Consumption Time: 2.03059
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.21674

Cumulative Model Updates: 25992
Cumulative Timesteps: 217113971

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.40528
Policy Entropy: 1.28789
Value Function Loss: 0.01670

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.13419
Value Function Update Magnitude: 0.18020

Collected Steps per Second: 10568.35213
Overall Steps per Second: 7293.37032

Timestep Collection Time: 4.73413
Timestep Consumption Time: 2.12579
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 6.85993

Cumulative Model Updates: 25998
Cumulative Timesteps: 217164003

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.80890
Policy Entropy: 1.29002
Value Function Loss: 0.01635

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.13360
Value Function Update Magnitude: 0.17350

Collected Steps per Second: 9964.39014
Overall Steps per Second: 7010.32790

Timestep Collection Time: 5.01887
Timestep Consumption Time: 2.11489
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.13376

Cumulative Model Updates: 26004
Cumulative Timesteps: 217214013

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.26245
Policy Entropy: 1.29537
Value Function Loss: 0.01631

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07312
Policy Update Magnitude: 0.13086
Value Function Update Magnitude: 0.17629

Collected Steps per Second: 9767.62131
Overall Steps per Second: 6952.53655

Timestep Collection Time: 5.12100
Timestep Consumption Time: 2.07350
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.19450

Cumulative Model Updates: 26010
Cumulative Timesteps: 217264033

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 217264033...
Checkpoint 217264033 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.95832
Policy Entropy: 1.29668
Value Function Loss: 0.01667

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.05971
Policy Update Magnitude: 0.13354
Value Function Update Magnitude: 0.17567

Collected Steps per Second: 10347.21002
Overall Steps per Second: 7217.66993

Timestep Collection Time: 4.83493
Timestep Consumption Time: 2.09640
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 6.93132

Cumulative Model Updates: 26016
Cumulative Timesteps: 217314061

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.52140
Policy Entropy: 1.29379
Value Function Loss: 0.01737

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06301
Policy Update Magnitude: 0.13844
Value Function Update Magnitude: 0.17372

Collected Steps per Second: 9536.00868
Overall Steps per Second: 6893.81214

Timestep Collection Time: 5.24433
Timestep Consumption Time: 2.01000
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.25433

Cumulative Model Updates: 26022
Cumulative Timesteps: 217364071

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.17368
Policy Entropy: 1.29406
Value Function Loss: 0.01745

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06564
Policy Update Magnitude: 0.13490
Value Function Update Magnitude: 0.17402

Collected Steps per Second: 9672.89767
Overall Steps per Second: 6921.29152

Timestep Collection Time: 5.17136
Timestep Consumption Time: 2.05591
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 7.22726

Cumulative Model Updates: 26028
Cumulative Timesteps: 217414093

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.15229
Policy Entropy: 1.30075
Value Function Loss: 0.01788

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05455
Policy Update Magnitude: 0.13477
Value Function Update Magnitude: 0.18508

Collected Steps per Second: 10249.99496
Overall Steps per Second: 7180.68464

Timestep Collection Time: 4.88078
Timestep Consumption Time: 2.08624
PPO Batch Consumption Time: 0.02383
Total Iteration Time: 6.96702

Cumulative Model Updates: 26034
Cumulative Timesteps: 217464121

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.72896
Policy Entropy: 1.30450
Value Function Loss: 0.01678

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.04748
Policy Update Magnitude: 0.13486
Value Function Update Magnitude: 0.19787

Collected Steps per Second: 9848.16684
Overall Steps per Second: 7009.36640

Timestep Collection Time: 5.07871
Timestep Consumption Time: 2.05688
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 7.13560

Cumulative Model Updates: 26040
Cumulative Timesteps: 217514137

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.30167
Policy Entropy: 1.30422
Value Function Loss: 0.01711

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05231
Policy Update Magnitude: 0.13115
Value Function Update Magnitude: 0.20112

Collected Steps per Second: 9744.05116
Overall Steps per Second: 6973.71329

Timestep Collection Time: 5.13359
Timestep Consumption Time: 2.03934
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.17294

Cumulative Model Updates: 26046
Cumulative Timesteps: 217564159

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.54143
Policy Entropy: 1.30361
Value Function Loss: 0.01671

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.05178
Policy Update Magnitude: 0.12911
Value Function Update Magnitude: 0.20613

Collected Steps per Second: 10686.85174
Overall Steps per Second: 7197.70947

Timestep Collection Time: 4.68089
Timestep Consumption Time: 2.26910
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 6.94999

Cumulative Model Updates: 26052
Cumulative Timesteps: 217614183

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.94023
Policy Entropy: 1.30242
Value Function Loss: 0.01765

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05307
Policy Update Magnitude: 0.13306
Value Function Update Magnitude: 0.20961

Collected Steps per Second: 10470.56621
Overall Steps per Second: 7273.36719

Timestep Collection Time: 4.77921
Timestep Consumption Time: 2.10083
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 6.88003

Cumulative Model Updates: 26058
Cumulative Timesteps: 217664224

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.77924
Policy Entropy: 1.30100
Value Function Loss: 0.01752

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.13397
Value Function Update Magnitude: 0.21411

Collected Steps per Second: 9654.79541
Overall Steps per Second: 6915.13538

Timestep Collection Time: 5.17919
Timestep Consumption Time: 2.05191
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.23109

Cumulative Model Updates: 26064
Cumulative Timesteps: 217714228

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.05887
Policy Entropy: 1.30028
Value Function Loss: 0.01765

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.13253
Value Function Update Magnitude: 0.20652

Collected Steps per Second: 10608.06971
Overall Steps per Second: 7413.52902

Timestep Collection Time: 4.71754
Timestep Consumption Time: 2.03282
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 6.75036

Cumulative Model Updates: 26070
Cumulative Timesteps: 217764272

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 217764272...
Checkpoint 217764272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.65316
Policy Entropy: 1.30407
Value Function Loss: 0.01725

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.13276
Value Function Update Magnitude: 0.20530

Collected Steps per Second: 9721.41694
Overall Steps per Second: 6965.92716

Timestep Collection Time: 5.14647
Timestep Consumption Time: 2.03577
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 7.18225

Cumulative Model Updates: 26076
Cumulative Timesteps: 217814303

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.10530
Policy Entropy: 1.30150
Value Function Loss: 0.01719

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.07286
Policy Update Magnitude: 0.13290
Value Function Update Magnitude: 0.19640

Collected Steps per Second: 9673.10029
Overall Steps per Second: 6902.58073

Timestep Collection Time: 5.16970
Timestep Consumption Time: 2.07498
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.24468

Cumulative Model Updates: 26082
Cumulative Timesteps: 217864310

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.55388
Policy Entropy: 1.30098
Value Function Loss: 0.01624

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.12926
Value Function Update Magnitude: 0.18775

Collected Steps per Second: 10479.33998
Overall Steps per Second: 7267.73714

Timestep Collection Time: 4.77444
Timestep Consumption Time: 2.10982
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 6.88426

Cumulative Model Updates: 26088
Cumulative Timesteps: 217914343

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.30179
Policy Entropy: 1.29887
Value Function Loss: 0.01594

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.12704
Value Function Update Magnitude: 0.18676

Collected Steps per Second: 9895.03431
Overall Steps per Second: 7065.66758

Timestep Collection Time: 5.05597
Timestep Consumption Time: 2.02461
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.08058

Cumulative Model Updates: 26094
Cumulative Timesteps: 217964372

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.89916
Policy Entropy: 1.30229
Value Function Loss: 0.01538

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.12757
Value Function Update Magnitude: 0.19283

Collected Steps per Second: 9838.02913
Overall Steps per Second: 7037.64721

Timestep Collection Time: 5.08547
Timestep Consumption Time: 2.02358
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.10905

Cumulative Model Updates: 26100
Cumulative Timesteps: 218014403

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.07646
Policy Entropy: 1.30146
Value Function Loss: 0.01614

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.12918
Value Function Update Magnitude: 0.19672

Collected Steps per Second: 10355.27039
Overall Steps per Second: 7225.52601

Timestep Collection Time: 4.83136
Timestep Consumption Time: 2.09271
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 6.92406

Cumulative Model Updates: 26106
Cumulative Timesteps: 218064433

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.03445
Policy Entropy: 1.30403
Value Function Loss: 0.01669

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.05818
Policy Update Magnitude: 0.12945
Value Function Update Magnitude: 0.20443

Collected Steps per Second: 9820.25283
Overall Steps per Second: 7027.13642

Timestep Collection Time: 5.09294
Timestep Consumption Time: 2.02432
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.11727

Cumulative Model Updates: 26112
Cumulative Timesteps: 218114447

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.60683
Policy Entropy: 1.29865
Value Function Loss: 0.01736

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.13134
Value Function Update Magnitude: 0.20261

Collected Steps per Second: 9842.99013
Overall Steps per Second: 7022.89586

Timestep Collection Time: 5.08270
Timestep Consumption Time: 2.04100
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.12370

Cumulative Model Updates: 26118
Cumulative Timesteps: 218164476

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.61619
Policy Entropy: 1.29813
Value Function Loss: 0.01763

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.13341
Value Function Update Magnitude: 0.20233

Collected Steps per Second: 10342.75379
Overall Steps per Second: 7229.52184

Timestep Collection Time: 4.83836
Timestep Consumption Time: 2.08353
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.92190

Cumulative Model Updates: 26124
Cumulative Timesteps: 218214518

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.72144
Policy Entropy: 1.29683
Value Function Loss: 0.01784

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.13197
Value Function Update Magnitude: 0.20593

Collected Steps per Second: 9911.71574
Overall Steps per Second: 6969.86428

Timestep Collection Time: 5.04665
Timestep Consumption Time: 2.13010
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.17675

Cumulative Model Updates: 26130
Cumulative Timesteps: 218264539

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 218264539...
Checkpoint 218264539 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.66679
Policy Entropy: 1.30795
Value Function Loss: 0.01728

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07175
Policy Update Magnitude: 0.12913
Value Function Update Magnitude: 0.21271

Collected Steps per Second: 9884.52678
Overall Steps per Second: 7047.39423

Timestep Collection Time: 5.05871
Timestep Consumption Time: 2.03653
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.09525

Cumulative Model Updates: 26136
Cumulative Timesteps: 218314542

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.88866
Policy Entropy: 1.30077
Value Function Loss: 0.01681

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.13067
Value Function Update Magnitude: 0.20895

Collected Steps per Second: 10495.57876
Overall Steps per Second: 7272.90286

Timestep Collection Time: 4.76667
Timestep Consumption Time: 2.11215
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 6.87882

Cumulative Model Updates: 26142
Cumulative Timesteps: 218364571

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.97087
Policy Entropy: 1.31067
Value Function Loss: 0.01677

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.12769
Value Function Update Magnitude: 0.21156

Collected Steps per Second: 9929.97538
Overall Steps per Second: 6978.00606

Timestep Collection Time: 5.03697
Timestep Consumption Time: 2.13084
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.16781

Cumulative Model Updates: 26148
Cumulative Timesteps: 218414588

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.43736
Policy Entropy: 1.30480
Value Function Loss: 0.01654

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.11259
Policy Update Magnitude: 0.12341
Value Function Update Magnitude: 0.20191

Collected Steps per Second: 9810.96508
Overall Steps per Second: 6987.37468

Timestep Collection Time: 5.10042
Timestep Consumption Time: 2.06107
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 7.16149

Cumulative Model Updates: 26154
Cumulative Timesteps: 218464628

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.21088
Policy Entropy: 1.30886
Value Function Loss: 0.01667

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.12174
Value Function Update Magnitude: 0.19814

Collected Steps per Second: 10390.65998
Overall Steps per Second: 7235.23913

Timestep Collection Time: 4.81654
Timestep Consumption Time: 2.10058
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 6.91712

Cumulative Model Updates: 26160
Cumulative Timesteps: 218514675

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.10575
Policy Entropy: 1.29949
Value Function Loss: 0.01682

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.12297
Value Function Update Magnitude: 0.19517

Collected Steps per Second: 9787.82467
Overall Steps per Second: 6948.46623

Timestep Collection Time: 5.11084
Timestep Consumption Time: 2.08845
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 7.19929

Cumulative Model Updates: 26166
Cumulative Timesteps: 218564699

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.24388
Policy Entropy: 1.29949
Value Function Loss: 0.01687

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.12494
Value Function Update Magnitude: 0.19690

Collected Steps per Second: 9798.08803
Overall Steps per Second: 7000.39208

Timestep Collection Time: 5.10589
Timestep Consumption Time: 2.04056
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 7.14646

Cumulative Model Updates: 26172
Cumulative Timesteps: 218614727

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.50452
Policy Entropy: 1.30138
Value Function Loss: 0.01700

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.12650
Value Function Update Magnitude: 0.19304

Collected Steps per Second: 10314.85476
Overall Steps per Second: 7172.79985

Timestep Collection Time: 4.84922
Timestep Consumption Time: 2.12421
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 6.97343

Cumulative Model Updates: 26178
Cumulative Timesteps: 218664746

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.81061
Policy Entropy: 1.30139
Value Function Loss: 0.01675

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.12708
Value Function Update Magnitude: 0.18799

Collected Steps per Second: 9955.56191
Overall Steps per Second: 7013.29806

Timestep Collection Time: 5.02282
Timestep Consumption Time: 2.10721
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.13003

Cumulative Model Updates: 26184
Cumulative Timesteps: 218714751

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.40961
Policy Entropy: 1.29930
Value Function Loss: 0.01679

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.12901
Value Function Update Magnitude: 0.18464

Collected Steps per Second: 9824.68738
Overall Steps per Second: 7004.10081

Timestep Collection Time: 5.09319
Timestep Consumption Time: 2.05105
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.14424

Cumulative Model Updates: 26190
Cumulative Timesteps: 218764790

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 218764790...
Checkpoint 218764790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.31523
Policy Entropy: 1.29874
Value Function Loss: 0.01651

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06206
Policy Update Magnitude: 0.12877
Value Function Update Magnitude: 0.17666

Collected Steps per Second: 10403.77029
Overall Steps per Second: 7228.91593

Timestep Collection Time: 4.80835
Timestep Consumption Time: 2.11177
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.92012

Cumulative Model Updates: 26196
Cumulative Timesteps: 218814815

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.06589
Policy Entropy: 1.29597
Value Function Loss: 0.01639

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.12908
Value Function Update Magnitude: 0.17799

Collected Steps per Second: 9998.66956
Overall Steps per Second: 7027.43021

Timestep Collection Time: 5.00517
Timestep Consumption Time: 2.11621
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.12138

Cumulative Model Updates: 26202
Cumulative Timesteps: 218864860

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.97668
Policy Entropy: 1.29814
Value Function Loss: 0.01679

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.13115
Value Function Update Magnitude: 0.18500

Collected Steps per Second: 9721.14876
Overall Steps per Second: 6990.87901

Timestep Collection Time: 5.14703
Timestep Consumption Time: 2.01016
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.15718

Cumulative Model Updates: 26208
Cumulative Timesteps: 218914895

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.88101
Policy Entropy: 1.29806
Value Function Loss: 0.01679

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.12708
Value Function Update Magnitude: 0.19056

Collected Steps per Second: 10461.53136
Overall Steps per Second: 7264.29622

Timestep Collection Time: 4.78238
Timestep Consumption Time: 2.10487
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 6.88725

Cumulative Model Updates: 26214
Cumulative Timesteps: 218964926

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.16234
Policy Entropy: 1.30059
Value Function Loss: 0.01697

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.12682
Value Function Update Magnitude: 0.19261

Collected Steps per Second: 9995.29169
Overall Steps per Second: 7015.78224

Timestep Collection Time: 5.00286
Timestep Consumption Time: 2.12465
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.12750

Cumulative Model Updates: 26220
Cumulative Timesteps: 219014931

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.39695
Policy Entropy: 1.29929
Value Function Loss: 0.01685

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.12866
Value Function Update Magnitude: 0.19236

Collected Steps per Second: 9748.77896
Overall Steps per Second: 6972.96769

Timestep Collection Time: 5.13069
Timestep Consumption Time: 2.04244
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.17313

Cumulative Model Updates: 26226
Cumulative Timesteps: 219064949

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.43090
Policy Entropy: 1.29507
Value Function Loss: 0.01717

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.12803
Value Function Update Magnitude: 0.19601

Collected Steps per Second: 10405.58218
Overall Steps per Second: 7227.81197

Timestep Collection Time: 4.80896
Timestep Consumption Time: 2.11430
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.92326

Cumulative Model Updates: 26232
Cumulative Timesteps: 219114989

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.80829
Policy Entropy: 1.29381
Value Function Loss: 0.01659

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.12788
Value Function Update Magnitude: 0.19504

Collected Steps per Second: 9957.52384
Overall Steps per Second: 7100.57247

Timestep Collection Time: 5.02414
Timestep Consumption Time: 2.02149
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 7.04563

Cumulative Model Updates: 26238
Cumulative Timesteps: 219165017

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.53925
Policy Entropy: 1.29818
Value Function Loss: 0.01642

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.12547
Value Function Update Magnitude: 0.20246

Collected Steps per Second: 9881.65379
Overall Steps per Second: 7025.81193

Timestep Collection Time: 5.06130
Timestep Consumption Time: 2.05731
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 7.11861

Cumulative Model Updates: 26244
Cumulative Timesteps: 219215031

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.85173
Policy Entropy: 1.30546
Value Function Loss: 0.01738

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.12616
Value Function Update Magnitude: 0.20764

Collected Steps per Second: 10246.50435
Overall Steps per Second: 7087.11863

Timestep Collection Time: 4.88030
Timestep Consumption Time: 2.17560
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.05590

Cumulative Model Updates: 26250
Cumulative Timesteps: 219265037

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 219265037...
Checkpoint 219265037 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.83299
Policy Entropy: 1.30233
Value Function Loss: 0.01827

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.12980
Value Function Update Magnitude: 0.20301

Collected Steps per Second: 9967.07446
Overall Steps per Second: 7087.13202

Timestep Collection Time: 5.01852
Timestep Consumption Time: 2.03934
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.05786

Cumulative Model Updates: 26256
Cumulative Timesteps: 219315057

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.59993
Policy Entropy: 1.30155
Value Function Loss: 0.01838

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.12735
Value Function Update Magnitude: 0.19531

Collected Steps per Second: 9938.28790
Overall Steps per Second: 7053.84740

Timestep Collection Time: 5.03487
Timestep Consumption Time: 2.05885
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.09372

Cumulative Model Updates: 26262
Cumulative Timesteps: 219365095

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.44578
Policy Entropy: 1.30020
Value Function Loss: 0.01741

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.12704
Value Function Update Magnitude: 0.18597

Collected Steps per Second: 10432.52992
Overall Steps per Second: 7221.99422

Timestep Collection Time: 4.79586
Timestep Consumption Time: 2.13200
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 6.92786

Cumulative Model Updates: 26268
Cumulative Timesteps: 219415128

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.58150
Policy Entropy: 1.29642
Value Function Loss: 0.01820

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.12359
Value Function Update Magnitude: 0.19070

Collected Steps per Second: 9971.72149
Overall Steps per Second: 6983.26269

Timestep Collection Time: 5.01719
Timestep Consumption Time: 2.14709
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.16427

Cumulative Model Updates: 26274
Cumulative Timesteps: 219465158

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.71686
Policy Entropy: 1.28849
Value Function Loss: 0.01821

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.12972
Value Function Update Magnitude: 0.19968

Collected Steps per Second: 9717.25129
Overall Steps per Second: 6939.13512

Timestep Collection Time: 5.14765
Timestep Consumption Time: 2.06089
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.20854

Cumulative Model Updates: 26280
Cumulative Timesteps: 219515179

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18886
Policy Entropy: 1.28750
Value Function Loss: 0.01758

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.13213
Value Function Update Magnitude: 0.19669

Collected Steps per Second: 10285.41587
Overall Steps per Second: 7199.01500

Timestep Collection Time: 4.86300
Timestep Consumption Time: 2.08489
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 6.94789

Cumulative Model Updates: 26286
Cumulative Timesteps: 219565197

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.27418
Policy Entropy: 1.28794
Value Function Loss: 0.01700

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.13197
Value Function Update Magnitude: 0.19059

Collected Steps per Second: 9907.34086
Overall Steps per Second: 7050.38973

Timestep Collection Time: 5.05141
Timestep Consumption Time: 2.04693
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.09833

Cumulative Model Updates: 26292
Cumulative Timesteps: 219615243

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.46852
Policy Entropy: 1.29146
Value Function Loss: 0.01687

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06673
Policy Update Magnitude: 0.13210
Value Function Update Magnitude: 0.18685

Collected Steps per Second: 9749.84938
Overall Steps per Second: 6983.29385

Timestep Collection Time: 5.13064
Timestep Consumption Time: 2.03260
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.16324

Cumulative Model Updates: 26298
Cumulative Timesteps: 219665266

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.39775
Policy Entropy: 1.29332
Value Function Loss: 0.01717

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.12874
Value Function Update Magnitude: 0.19104

Collected Steps per Second: 10555.44797
Overall Steps per Second: 7302.32837

Timestep Collection Time: 4.73793
Timestep Consumption Time: 2.11071
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 6.84864

Cumulative Model Updates: 26304
Cumulative Timesteps: 219715277

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.27711
Policy Entropy: 1.29725
Value Function Loss: 0.01726

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.12672
Value Function Update Magnitude: 0.19120

Collected Steps per Second: 9934.89217
Overall Steps per Second: 7018.73228

Timestep Collection Time: 5.03438
Timestep Consumption Time: 2.09170
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.12607

Cumulative Model Updates: 26310
Cumulative Timesteps: 219765293

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 219765293...
Checkpoint 219765293 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.66719
Policy Entropy: 1.29711
Value Function Loss: 0.01781

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.12273
Value Function Update Magnitude: 0.19379

Collected Steps per Second: 9733.97635
Overall Steps per Second: 6962.21622

Timestep Collection Time: 5.13665
Timestep Consumption Time: 2.04497
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 7.18162

Cumulative Model Updates: 26316
Cumulative Timesteps: 219815293

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.16591
Policy Entropy: 1.29871
Value Function Loss: 0.01728

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06220
Policy Update Magnitude: 0.12527
Value Function Update Magnitude: 0.19169

Collected Steps per Second: 10307.74854
Overall Steps per Second: 7184.87024

Timestep Collection Time: 4.85247
Timestep Consumption Time: 2.10911
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 6.96157

Cumulative Model Updates: 26322
Cumulative Timesteps: 219865311

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.44584
Policy Entropy: 1.29560
Value Function Loss: 0.01810

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07461
Policy Update Magnitude: 0.12823
Value Function Update Magnitude: 0.18882

Collected Steps per Second: 10095.22397
Overall Steps per Second: 7067.99007

Timestep Collection Time: 4.95611
Timestep Consumption Time: 2.12271
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.07882

Cumulative Model Updates: 26328
Cumulative Timesteps: 219915344

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.34597
Policy Entropy: 1.30113
Value Function Loss: 0.01718

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07267
Policy Update Magnitude: 0.12617
Value Function Update Magnitude: 0.19118

Collected Steps per Second: 9759.28631
Overall Steps per Second: 6983.80730

Timestep Collection Time: 5.12445
Timestep Consumption Time: 2.03654
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 7.16099

Cumulative Model Updates: 26334
Cumulative Timesteps: 219965355

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.36273
Policy Entropy: 1.30422
Value Function Loss: 0.01745

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05735
Policy Update Magnitude: 0.12598
Value Function Update Magnitude: 0.19438

Collected Steps per Second: 10368.52545
Overall Steps per Second: 7211.30388

Timestep Collection Time: 4.82614
Timestep Consumption Time: 2.11296
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 6.93911

Cumulative Model Updates: 26340
Cumulative Timesteps: 220015395

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.91285
Policy Entropy: 1.30451
Value Function Loss: 0.01628

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.05554
Policy Update Magnitude: 0.12688
Value Function Update Magnitude: 0.19728

Collected Steps per Second: 9823.35504
Overall Steps per Second: 7006.88185

Timestep Collection Time: 5.09032
Timestep Consumption Time: 2.04609
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.13641

Cumulative Model Updates: 26346
Cumulative Timesteps: 220065399

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.09383
Policy Entropy: 1.29920
Value Function Loss: 0.01650

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05569
Policy Update Magnitude: 0.12706
Value Function Update Magnitude: 0.19876

Collected Steps per Second: 9849.83895
Overall Steps per Second: 7034.80773

Timestep Collection Time: 5.07907
Timestep Consumption Time: 2.03243
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.11150

Cumulative Model Updates: 26352
Cumulative Timesteps: 220115427

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.57211
Policy Entropy: 1.30013
Value Function Loss: 0.01748

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.13064
Value Function Update Magnitude: 0.19998

Collected Steps per Second: 10533.34427
Overall Steps per Second: 7273.23821

Timestep Collection Time: 4.74949
Timestep Consumption Time: 2.12888
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 6.87837

Cumulative Model Updates: 26358
Cumulative Timesteps: 220165455

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.99279
Policy Entropy: 1.29745
Value Function Loss: 0.01798

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.12766
Value Function Update Magnitude: 0.19668

Collected Steps per Second: 9763.41610
Overall Steps per Second: 6995.00764

Timestep Collection Time: 5.12362
Timestep Consumption Time: 2.02777
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.15139

Cumulative Model Updates: 26364
Cumulative Timesteps: 220215479

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.66379
Policy Entropy: 1.29624
Value Function Loss: 0.01856

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.12856
Value Function Update Magnitude: 0.19355

Collected Steps per Second: 9034.19559
Overall Steps per Second: 6362.32833

Timestep Collection Time: 5.53552
Timestep Consumption Time: 2.32465
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 7.86017

Cumulative Model Updates: 26370
Cumulative Timesteps: 220265488

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 220265488...
Checkpoint 220265488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.97994
Policy Entropy: 1.29527
Value Function Loss: 0.01715

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.12914
Value Function Update Magnitude: 0.18709

Collected Steps per Second: 9303.56612
Overall Steps per Second: 6627.23017

Timestep Collection Time: 5.37428
Timestep Consumption Time: 2.17035
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.54463

Cumulative Model Updates: 26376
Cumulative Timesteps: 220315488

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.83147
Policy Entropy: 1.30042
Value Function Loss: 0.01681

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.18160

Collected Steps per Second: 10186.78103
Overall Steps per Second: 7274.01365

Timestep Collection Time: 4.91146
Timestep Consumption Time: 1.96672
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 6.87818

Cumulative Model Updates: 26382
Cumulative Timesteps: 220365520

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.38382
Policy Entropy: 1.30118
Value Function Loss: 0.01628

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.12441
Value Function Update Magnitude: 0.18166

Collected Steps per Second: 9784.74485
Overall Steps per Second: 7041.86523

Timestep Collection Time: 5.11183
Timestep Consumption Time: 1.99111
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.10295

Cumulative Model Updates: 26388
Cumulative Timesteps: 220415538

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.38627
Policy Entropy: 1.30249
Value Function Loss: 0.01644

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.12490
Value Function Update Magnitude: 0.17488

Collected Steps per Second: 10265.04457
Overall Steps per Second: 7196.28307

Timestep Collection Time: 4.87372
Timestep Consumption Time: 2.07834
PPO Batch Consumption Time: 0.02398
Total Iteration Time: 6.95206

Cumulative Model Updates: 26394
Cumulative Timesteps: 220465567

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.95262
Policy Entropy: 1.30021
Value Function Loss: 0.01654

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.12327
Value Function Update Magnitude: 0.17796

Collected Steps per Second: 9834.82010
Overall Steps per Second: 6999.12752

Timestep Collection Time: 5.08510
Timestep Consumption Time: 2.06022
PPO Batch Consumption Time: 0.02378
Total Iteration Time: 7.14532

Cumulative Model Updates: 26400
Cumulative Timesteps: 220515578

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.23608
Policy Entropy: 1.29434
Value Function Loss: 0.01701

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06912
Policy Update Magnitude: 0.12529
Value Function Update Magnitude: 0.17932

Collected Steps per Second: 9674.96959
Overall Steps per Second: 6957.72661

Timestep Collection Time: 5.17159
Timestep Consumption Time: 2.01969
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 7.19129

Cumulative Model Updates: 26406
Cumulative Timesteps: 220565613

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.83457
Policy Entropy: 1.29062
Value Function Loss: 0.01699

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.12619
Value Function Update Magnitude: 0.18537

Collected Steps per Second: 10263.46970
Overall Steps per Second: 7193.42648

Timestep Collection Time: 4.87184
Timestep Consumption Time: 2.07923
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 6.95107

Cumulative Model Updates: 26412
Cumulative Timesteps: 220615615

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.31159
Policy Entropy: 1.29205
Value Function Loss: 0.01740

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07420
Policy Update Magnitude: 0.12703
Value Function Update Magnitude: 0.19533

Collected Steps per Second: 9801.18877
Overall Steps per Second: 6984.28154

Timestep Collection Time: 5.10469
Timestep Consumption Time: 2.05883
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.16351

Cumulative Model Updates: 26418
Cumulative Timesteps: 220665647

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.91066
Policy Entropy: 1.29963
Value Function Loss: 0.01818

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.12681
Value Function Update Magnitude: 0.19442

Collected Steps per Second: 9711.66988
Overall Steps per Second: 6987.38001

Timestep Collection Time: 5.14855
Timestep Consumption Time: 2.00735
PPO Batch Consumption Time: 0.02461
Total Iteration Time: 7.15590

Cumulative Model Updates: 26424
Cumulative Timesteps: 220715648

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.21875
Policy Entropy: 1.29197
Value Function Loss: 0.01947

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.12500
Value Function Update Magnitude: 0.19669

Collected Steps per Second: 10277.04280
Overall Steps per Second: 7157.83267

Timestep Collection Time: 4.86531
Timestep Consumption Time: 2.12018
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.98549

Cumulative Model Updates: 26430
Cumulative Timesteps: 220765649

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 220765649...
Checkpoint 220765649 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.67992
Policy Entropy: 1.28714
Value Function Loss: 0.01878

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.13080
Value Function Update Magnitude: 0.20588

Collected Steps per Second: 9806.38447
Overall Steps per Second: 7043.75581

Timestep Collection Time: 5.10249
Timestep Consumption Time: 2.00125
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 7.10374

Cumulative Model Updates: 26436
Cumulative Timesteps: 220815686

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.29389
Policy Entropy: 1.28279
Value Function Loss: 0.01820

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.13237
Value Function Update Magnitude: 0.20347

Collected Steps per Second: 9701.82412
Overall Steps per Second: 6985.63187

Timestep Collection Time: 5.15656
Timestep Consumption Time: 2.00500
PPO Batch Consumption Time: 0.02363
Total Iteration Time: 7.16156

Cumulative Model Updates: 26442
Cumulative Timesteps: 220865714

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.17209
Policy Entropy: 1.29352
Value Function Loss: 0.01691

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.12597
Value Function Update Magnitude: 0.20119

Collected Steps per Second: 10368.35382
Overall Steps per Second: 7257.68838

Timestep Collection Time: 4.82275
Timestep Consumption Time: 2.06704
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 6.88980

Cumulative Model Updates: 26448
Cumulative Timesteps: 220915718

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.03207
Policy Entropy: 1.29454
Value Function Loss: 0.01694

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.12617
Value Function Update Magnitude: 0.20185

Collected Steps per Second: 10056.42703
Overall Steps per Second: 7060.71486

Timestep Collection Time: 4.97423
Timestep Consumption Time: 2.11046
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.08469

Cumulative Model Updates: 26454
Cumulative Timesteps: 220965741

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.06789
Policy Entropy: 1.29587
Value Function Loss: 0.01740

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.12614
Value Function Update Magnitude: 0.19526

Collected Steps per Second: 9756.98406
Overall Steps per Second: 6967.52213

Timestep Collection Time: 5.12710
Timestep Consumption Time: 2.05264
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.17974

Cumulative Model Updates: 26460
Cumulative Timesteps: 221015766

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.65385
Policy Entropy: 1.29134
Value Function Loss: 0.01767

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.12713
Value Function Update Magnitude: 0.20082

Collected Steps per Second: 10499.17081
Overall Steps per Second: 7087.56468

Timestep Collection Time: 4.76580
Timestep Consumption Time: 2.29402
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.05983

Cumulative Model Updates: 26466
Cumulative Timesteps: 221065803

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.69429
Policy Entropy: 1.29413
Value Function Loss: 0.01733

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.06953
Policy Update Magnitude: 0.12581
Value Function Update Magnitude: 0.19261

Collected Steps per Second: 10321.91678
Overall Steps per Second: 7168.01387

Timestep Collection Time: 4.84803
Timestep Consumption Time: 2.13312
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.98115

Cumulative Model Updates: 26472
Cumulative Timesteps: 221115844

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.21685
Policy Entropy: 1.29129
Value Function Loss: 0.01674

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.12584
Value Function Update Magnitude: 0.19006

Collected Steps per Second: 9848.15872
Overall Steps per Second: 7012.56385

Timestep Collection Time: 5.07993
Timestep Consumption Time: 2.05412
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.13405

Cumulative Model Updates: 26478
Cumulative Timesteps: 221165872

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.85359
Policy Entropy: 1.29650
Value Function Loss: 0.01658

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.19232

Collected Steps per Second: 9739.71498
Overall Steps per Second: 6969.37244

Timestep Collection Time: 5.13701
Timestep Consumption Time: 2.04197
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.17898

Cumulative Model Updates: 26484
Cumulative Timesteps: 221215905

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.13860
Policy Entropy: 1.29023
Value Function Loss: 0.01647

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.18617

Collected Steps per Second: 10355.08729
Overall Steps per Second: 7195.67249

Timestep Collection Time: 4.82854
Timestep Consumption Time: 2.12008
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.94862

Cumulative Model Updates: 26490
Cumulative Timesteps: 221265905

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 221265905...
Checkpoint 221265905 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.29755
Policy Entropy: 1.29013
Value Function Loss: 0.01750

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.12674
Value Function Update Magnitude: 0.18332

Collected Steps per Second: 9971.06660
Overall Steps per Second: 7077.00659

Timestep Collection Time: 5.01812
Timestep Consumption Time: 2.05210
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 7.07022

Cumulative Model Updates: 26496
Cumulative Timesteps: 221315941

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.23090
Policy Entropy: 1.28843
Value Function Loss: 0.01696

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.12906
Value Function Update Magnitude: 0.18596

Collected Steps per Second: 9720.89934
Overall Steps per Second: 6941.33680

Timestep Collection Time: 5.14356
Timestep Consumption Time: 2.05967
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.20322

Cumulative Model Updates: 26502
Cumulative Timesteps: 221365941

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.43014
Policy Entropy: 1.29124
Value Function Loss: 0.01793

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.12888
Value Function Update Magnitude: 0.18167

Collected Steps per Second: 10645.46762
Overall Steps per Second: 7371.28692

Timestep Collection Time: 4.69928
Timestep Consumption Time: 2.08733
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 6.78660

Cumulative Model Updates: 26508
Cumulative Timesteps: 221415967

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.92013
Policy Entropy: 1.29566
Value Function Loss: 0.01705

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.17687

Collected Steps per Second: 9998.03848
Overall Steps per Second: 7023.81022

Timestep Collection Time: 5.00538
Timestep Consumption Time: 2.11953
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.12491

Cumulative Model Updates: 26514
Cumulative Timesteps: 221466011

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.23903
Policy Entropy: 1.29335
Value Function Loss: 0.01770

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.12751
Value Function Update Magnitude: 0.17316

Collected Steps per Second: 9735.34393
Overall Steps per Second: 6953.29082

Timestep Collection Time: 5.13716
Timestep Consumption Time: 2.05541
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.19257

Cumulative Model Updates: 26520
Cumulative Timesteps: 221516023

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.21786
Policy Entropy: 1.28963
Value Function Loss: 0.01722

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06445
Policy Update Magnitude: 0.13037
Value Function Update Magnitude: 0.17159

Collected Steps per Second: 10384.27401
Overall Steps per Second: 7242.63139

Timestep Collection Time: 4.81517
Timestep Consumption Time: 2.08868
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.90384

Cumulative Model Updates: 26526
Cumulative Timesteps: 221566025

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.69652
Policy Entropy: 1.28835
Value Function Loss: 0.01835

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.06772
Policy Update Magnitude: 0.13502
Value Function Update Magnitude: 0.17124

Collected Steps per Second: 9787.22687
Overall Steps per Second: 6963.80201

Timestep Collection Time: 5.11289
Timestep Consumption Time: 2.07298
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.18587

Cumulative Model Updates: 26532
Cumulative Timesteps: 221616066

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.14412
Policy Entropy: 1.28831
Value Function Loss: 0.01817

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.13230
Value Function Update Magnitude: 0.17561

Collected Steps per Second: 9817.40683
Overall Steps per Second: 7044.06302

Timestep Collection Time: 5.09544
Timestep Consumption Time: 2.00614
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.10158

Cumulative Model Updates: 26538
Cumulative Timesteps: 221666090

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.78263
Policy Entropy: 1.28609
Value Function Loss: 0.01767

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.13039
Value Function Update Magnitude: 0.18046

Collected Steps per Second: 10428.99992
Overall Steps per Second: 7263.64652

Timestep Collection Time: 4.79653
Timestep Consumption Time: 2.09023
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 6.88676

Cumulative Model Updates: 26544
Cumulative Timesteps: 221716113

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.07979
Policy Entropy: 1.28191
Value Function Loss: 0.01683

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.13217
Value Function Update Magnitude: 0.18304

Collected Steps per Second: 9837.61521
Overall Steps per Second: 6947.01154

Timestep Collection Time: 5.08629
Timestep Consumption Time: 2.11637
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.20267

Cumulative Model Updates: 26550
Cumulative Timesteps: 221766150

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 221766150...
Checkpoint 221766150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.97454
Policy Entropy: 1.28362
Value Function Loss: 0.01683

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.12753
Value Function Update Magnitude: 0.16845

Collected Steps per Second: 9845.51322
Overall Steps per Second: 7096.90570

Timestep Collection Time: 5.08140
Timestep Consumption Time: 1.96801
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.04941

Cumulative Model Updates: 26556
Cumulative Timesteps: 221816179

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.12949
Policy Entropy: 1.28524
Value Function Loss: 0.01877

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.12853
Value Function Update Magnitude: 0.16641

Collected Steps per Second: 10327.57367
Overall Steps per Second: 7228.38271

Timestep Collection Time: 4.84364
Timestep Consumption Time: 2.07672
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 6.92036

Cumulative Model Updates: 26562
Cumulative Timesteps: 221866202

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.90070
Policy Entropy: 1.29093
Value Function Loss: 0.01944

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.06903
Policy Update Magnitude: 0.13004
Value Function Update Magnitude: 0.18076

Collected Steps per Second: 9925.16648
Overall Steps per Second: 7014.48884

Timestep Collection Time: 5.03911
Timestep Consumption Time: 2.09099
PPO Batch Consumption Time: 0.02421
Total Iteration Time: 7.13010

Cumulative Model Updates: 26568
Cumulative Timesteps: 221916216

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.67245
Policy Entropy: 1.29178
Value Function Loss: 0.01950

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.13181
Value Function Update Magnitude: 0.19214

Collected Steps per Second: 9895.85971
Overall Steps per Second: 7050.40210

Timestep Collection Time: 5.05696
Timestep Consumption Time: 2.04093
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.09789

Cumulative Model Updates: 26574
Cumulative Timesteps: 221966259

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.97860
Policy Entropy: 1.28906
Value Function Loss: 0.01923

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07195
Policy Update Magnitude: 0.13079
Value Function Update Magnitude: 0.19652

Collected Steps per Second: 10461.80800
Overall Steps per Second: 7072.95474

Timestep Collection Time: 4.78139
Timestep Consumption Time: 2.29090
PPO Batch Consumption Time: 0.02437
Total Iteration Time: 7.07229

Cumulative Model Updates: 26580
Cumulative Timesteps: 222016281

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.49587
Policy Entropy: 1.28772
Value Function Loss: 0.01867

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.13378
Value Function Update Magnitude: 0.19698

Collected Steps per Second: 10427.42175
Overall Steps per Second: 7343.18914

Timestep Collection Time: 4.79678
Timestep Consumption Time: 2.01471
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.81148

Cumulative Model Updates: 26586
Cumulative Timesteps: 222066299

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.31200
Policy Entropy: 1.28851
Value Function Loss: 0.01841

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.13424
Value Function Update Magnitude: 0.19090

Collected Steps per Second: 9679.18438
Overall Steps per Second: 6965.25410

Timestep Collection Time: 5.16583
Timestep Consumption Time: 2.01280
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.17863

Cumulative Model Updates: 26592
Cumulative Timesteps: 222116300

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.54311
Policy Entropy: 1.29065
Value Function Loss: 0.01775

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.12631
Value Function Update Magnitude: 0.18805

Collected Steps per Second: 10379.58119
Overall Steps per Second: 7019.41359

Timestep Collection Time: 4.81773
Timestep Consumption Time: 2.30623
PPO Batch Consumption Time: 0.02455
Total Iteration Time: 7.12396

Cumulative Model Updates: 26598
Cumulative Timesteps: 222166306

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.82899
Policy Entropy: 1.29062
Value Function Loss: 0.01771

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.12537
Value Function Update Magnitude: 0.19254

Collected Steps per Second: 10274.18692
Overall Steps per Second: 7150.84340

Timestep Collection Time: 4.86783
Timestep Consumption Time: 2.12617
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 6.99400

Cumulative Model Updates: 26604
Cumulative Timesteps: 222216319

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.29185
Policy Entropy: 1.28903
Value Function Loss: 0.01773

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.12571
Value Function Update Magnitude: 0.19046

Collected Steps per Second: 9909.39335
Overall Steps per Second: 7032.09985

Timestep Collection Time: 5.05016
Timestep Consumption Time: 2.06635
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.11651

Cumulative Model Updates: 26610
Cumulative Timesteps: 222266363

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 222266363...
Checkpoint 222266363 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.90604
Policy Entropy: 1.28434
Value Function Loss: 0.01715

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.12459
Value Function Update Magnitude: 0.18882

Collected Steps per Second: 9692.40799
Overall Steps per Second: 6926.30164

Timestep Collection Time: 5.16064
Timestep Consumption Time: 2.06097
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.22160

Cumulative Model Updates: 26616
Cumulative Timesteps: 222316382

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.20300
Policy Entropy: 1.28572
Value Function Loss: 0.01658

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.12628
Value Function Update Magnitude: 0.18959

Collected Steps per Second: 10221.76480
Overall Steps per Second: 7116.96686

Timestep Collection Time: 4.89514
Timestep Consumption Time: 2.13552
PPO Batch Consumption Time: 0.03010
Total Iteration Time: 7.03066

Cumulative Model Updates: 26622
Cumulative Timesteps: 222366419

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.21323
Policy Entropy: 1.28991
Value Function Loss: 0.01725

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07222
Policy Update Magnitude: 0.12680
Value Function Update Magnitude: 0.19221

Collected Steps per Second: 9695.74857
Overall Steps per Second: 6937.20490

Timestep Collection Time: 5.16020
Timestep Consumption Time: 2.05193
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.21213

Cumulative Model Updates: 26628
Cumulative Timesteps: 222416451

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.65109
Policy Entropy: 1.29344
Value Function Loss: 0.01762

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06454
Policy Update Magnitude: 0.12701
Value Function Update Magnitude: 0.20019

Collected Steps per Second: 9731.62951
Overall Steps per Second: 6938.44084

Timestep Collection Time: 5.13819
Timestep Consumption Time: 2.06847
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.20666

Cumulative Model Updates: 26634
Cumulative Timesteps: 222466454

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.32387
Policy Entropy: 1.29215
Value Function Loss: 0.01780

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.05863
Policy Update Magnitude: 0.12721
Value Function Update Magnitude: 0.20436

Collected Steps per Second: 10344.55536
Overall Steps per Second: 7098.90977

Timestep Collection Time: 4.83684
Timestep Consumption Time: 2.21142
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.04827

Cumulative Model Updates: 26640
Cumulative Timesteps: 222516489

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.41102
Policy Entropy: 1.29155
Value Function Loss: 0.01686

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.12848
Value Function Update Magnitude: 0.18262

Collected Steps per Second: 9278.56042
Overall Steps per Second: 6572.18694

Timestep Collection Time: 5.39038
Timestep Consumption Time: 2.21972
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 7.61010

Cumulative Model Updates: 26646
Cumulative Timesteps: 222566504

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.66279
Policy Entropy: 1.28946
Value Function Loss: 0.01712

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.12627
Value Function Update Magnitude: 0.17887

Collected Steps per Second: 9513.27239
Overall Steps per Second: 6827.44244

Timestep Collection Time: 5.26023
Timestep Consumption Time: 2.06931
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.32954

Cumulative Model Updates: 26652
Cumulative Timesteps: 222616546

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.87308
Policy Entropy: 1.29127
Value Function Loss: 0.01823

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.12883
Value Function Update Magnitude: 0.18511

Collected Steps per Second: 10048.60537
Overall Steps per Second: 7090.32111

Timestep Collection Time: 4.97721
Timestep Consumption Time: 2.07663
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.05384

Cumulative Model Updates: 26658
Cumulative Timesteps: 222666560

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.73643
Policy Entropy: 1.28929
Value Function Loss: 0.01768

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07671
Policy Update Magnitude: 0.12765
Value Function Update Magnitude: 0.18999

Collected Steps per Second: 10027.17227
Overall Steps per Second: 7130.64159

Timestep Collection Time: 4.99014
Timestep Consumption Time: 2.02704
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.01718

Cumulative Model Updates: 26664
Cumulative Timesteps: 222716597

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.43646
Policy Entropy: 1.28931
Value Function Loss: 0.01736

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.12671
Value Function Update Magnitude: 0.18493

Collected Steps per Second: 9664.32344
Overall Steps per Second: 6968.03822

Timestep Collection Time: 5.17377
Timestep Consumption Time: 2.00199
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.17576

Cumulative Model Updates: 26670
Cumulative Timesteps: 222766598

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 222766598...
Checkpoint 222766598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.99007
Policy Entropy: 1.28318
Value Function Loss: 0.01624

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.12814
Value Function Update Magnitude: 0.19246

Collected Steps per Second: 10262.07575
Overall Steps per Second: 7171.32663

Timestep Collection Time: 4.87611
Timestep Consumption Time: 2.10154
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 6.97765

Cumulative Model Updates: 26676
Cumulative Timesteps: 222816637

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.51030
Policy Entropy: 1.28425
Value Function Loss: 0.01609

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.12348
Value Function Update Magnitude: 0.20125

Collected Steps per Second: 9842.26607
Overall Steps per Second: 6998.04578

Timestep Collection Time: 5.08257
Timestep Consumption Time: 2.06571
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.14828

Cumulative Model Updates: 26682
Cumulative Timesteps: 222866661

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.68716
Policy Entropy: 1.28649
Value Function Loss: 0.01628

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.12317
Value Function Update Magnitude: 0.19771

Collected Steps per Second: 9751.78642
Overall Steps per Second: 7001.01554

Timestep Collection Time: 5.12962
Timestep Consumption Time: 2.01548
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.14511

Cumulative Model Updates: 26688
Cumulative Timesteps: 222916684

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.51554
Policy Entropy: 1.28553
Value Function Loss: 0.01621

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.12553
Value Function Update Magnitude: 0.19898

Collected Steps per Second: 10395.12646
Overall Steps per Second: 7218.61436

Timestep Collection Time: 4.81379
Timestep Consumption Time: 2.11828
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 6.93208

Cumulative Model Updates: 26694
Cumulative Timesteps: 222966724

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.66073
Policy Entropy: 1.28660
Value Function Loss: 0.01655

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.12206
Value Function Update Magnitude: 0.20013

Collected Steps per Second: 9820.97253
Overall Steps per Second: 6972.77482

Timestep Collection Time: 5.09563
Timestep Consumption Time: 2.08143
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.17706

Cumulative Model Updates: 26700
Cumulative Timesteps: 223016768

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.26350
Policy Entropy: 1.28615
Value Function Loss: 0.01738

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06570
Policy Update Magnitude: 0.12404
Value Function Update Magnitude: 0.19130

Collected Steps per Second: 9752.67377
Overall Steps per Second: 6984.19520

Timestep Collection Time: 5.12864
Timestep Consumption Time: 2.03295
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 7.16160

Cumulative Model Updates: 26706
Cumulative Timesteps: 223066786

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.28947
Policy Entropy: 1.29192
Value Function Loss: 0.01789

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.12670
Value Function Update Magnitude: 0.19065

Collected Steps per Second: 10511.36333
Overall Steps per Second: 7309.71208

Timestep Collection Time: 4.75704
Timestep Consumption Time: 2.08358
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.84063

Cumulative Model Updates: 26712
Cumulative Timesteps: 223116789

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.72308
Policy Entropy: 1.29138
Value Function Loss: 0.01831

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.12263
Value Function Update Magnitude: 0.19115

Collected Steps per Second: 9840.41843
Overall Steps per Second: 7030.29808

Timestep Collection Time: 5.08484
Timestep Consumption Time: 2.03249
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.11734

Cumulative Model Updates: 26718
Cumulative Timesteps: 223166826

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.78804
Policy Entropy: 1.29119
Value Function Loss: 0.01833

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.12399
Value Function Update Magnitude: 0.19518

Collected Steps per Second: 9726.88776
Overall Steps per Second: 6952.14160

Timestep Collection Time: 5.14378
Timestep Consumption Time: 2.05299
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.19678

Cumulative Model Updates: 26724
Cumulative Timesteps: 223216859

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.66771
Policy Entropy: 1.28443
Value Function Loss: 0.01830

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.12850
Value Function Update Magnitude: 0.20334

Collected Steps per Second: 10364.08964
Overall Steps per Second: 7223.70726

Timestep Collection Time: 4.82850
Timestep Consumption Time: 2.09911
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 6.92761

Cumulative Model Updates: 26730
Cumulative Timesteps: 223266902

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 223266902...
Checkpoint 223266902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.50118
Policy Entropy: 1.28604
Value Function Loss: 0.01858

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.13028
Value Function Update Magnitude: 0.19718

Collected Steps per Second: 9816.05912
Overall Steps per Second: 7021.72438

Timestep Collection Time: 5.09695
Timestep Consumption Time: 2.02836
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.12532

Cumulative Model Updates: 26736
Cumulative Timesteps: 223316934

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.96912
Policy Entropy: 1.28349
Value Function Loss: 0.01892

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.13281
Value Function Update Magnitude: 0.19790

Collected Steps per Second: 9829.91329
Overall Steps per Second: 7020.58583

Timestep Collection Time: 5.08672
Timestep Consumption Time: 2.03548
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.12220

Cumulative Model Updates: 26742
Cumulative Timesteps: 223366936

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.56657
Policy Entropy: 1.28771
Value Function Loss: 0.01849

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.13394
Value Function Update Magnitude: 0.20617

Collected Steps per Second: 10380.49469
Overall Steps per Second: 7210.79586

Timestep Collection Time: 4.81962
Timestep Consumption Time: 2.11859
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 6.93821

Cumulative Model Updates: 26748
Cumulative Timesteps: 223416966

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.50765
Policy Entropy: 1.28770
Value Function Loss: 0.01864

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.13406
Value Function Update Magnitude: 0.19980

Collected Steps per Second: 9046.38443
Overall Steps per Second: 6316.91237

Timestep Collection Time: 5.52961
Timestep Consumption Time: 2.38929
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 7.91890

Cumulative Model Updates: 26754
Cumulative Timesteps: 223466989

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.51561
Policy Entropy: 1.29064
Value Function Loss: 0.01757

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.12947
Value Function Update Magnitude: 0.20165

Collected Steps per Second: 8865.14807
Overall Steps per Second: 6435.72081

Timestep Collection Time: 5.64537
Timestep Consumption Time: 2.13108
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.77644

Cumulative Model Updates: 26760
Cumulative Timesteps: 223517036

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.48822
Policy Entropy: 1.28919
Value Function Loss: 0.01795

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06400
Policy Update Magnitude: 0.12878
Value Function Update Magnitude: 0.19987

Collected Steps per Second: 10993.43665
Overall Steps per Second: 7421.19107

Timestep Collection Time: 4.55008
Timestep Consumption Time: 2.19021
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 6.74029

Cumulative Model Updates: 26766
Cumulative Timesteps: 223567057

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.10168
Policy Entropy: 1.28936
Value Function Loss: 0.01786

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06265
Policy Update Magnitude: 0.13022
Value Function Update Magnitude: 0.20668

Collected Steps per Second: 10023.71164
Overall Steps per Second: 7082.16435

Timestep Collection Time: 4.98877
Timestep Consumption Time: 2.07207
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.06084

Cumulative Model Updates: 26772
Cumulative Timesteps: 223617063

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.58902
Policy Entropy: 1.29225
Value Function Loss: 0.01786

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.13339
Value Function Update Magnitude: 0.22456

Collected Steps per Second: 9909.78397
Overall Steps per Second: 7023.59823

Timestep Collection Time: 5.04794
Timestep Consumption Time: 2.07433
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.12228

Cumulative Model Updates: 26778
Cumulative Timesteps: 223667087

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.26515
Policy Entropy: 1.28948
Value Function Loss: 0.01723

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.13116
Value Function Update Magnitude: 0.21934

Collected Steps per Second: 10427.71388
Overall Steps per Second: 7237.40185

Timestep Collection Time: 4.79760
Timestep Consumption Time: 2.11483
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 6.91243

Cumulative Model Updates: 26784
Cumulative Timesteps: 223717115

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.32419
Policy Entropy: 1.29092
Value Function Loss: 0.01705

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.12712
Value Function Update Magnitude: 0.21057

Collected Steps per Second: 9921.89846
Overall Steps per Second: 7081.55664

Timestep Collection Time: 5.04107
Timestep Consumption Time: 2.02192
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.06300

Cumulative Model Updates: 26790
Cumulative Timesteps: 223767132

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 223767132...
Checkpoint 223767132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.64482
Policy Entropy: 1.28771
Value Function Loss: 0.01761

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.12795
Value Function Update Magnitude: 0.19940

Collected Steps per Second: 9764.02591
Overall Steps per Second: 6947.01912

Timestep Collection Time: 5.12197
Timestep Consumption Time: 2.07695
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.19891

Cumulative Model Updates: 26796
Cumulative Timesteps: 223817143

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.07062
Policy Entropy: 1.28783
Value Function Loss: 0.01813

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.12899
Value Function Update Magnitude: 0.19813

Collected Steps per Second: 10459.66662
Overall Steps per Second: 7276.33720

Timestep Collection Time: 4.78304
Timestep Consumption Time: 2.09254
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 6.87557

Cumulative Model Updates: 26802
Cumulative Timesteps: 223867172

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.94342
Policy Entropy: 1.28807
Value Function Loss: 0.01805

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.12532
Value Function Update Magnitude: 0.19275

Collected Steps per Second: 9857.14382
Overall Steps per Second: 6957.44496

Timestep Collection Time: 5.07419
Timestep Consumption Time: 2.11480
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.18899

Cumulative Model Updates: 26808
Cumulative Timesteps: 223917189

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.67764
Policy Entropy: 1.29942
Value Function Loss: 0.01878

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.12749
Value Function Update Magnitude: 0.19862

Collected Steps per Second: 9649.92738
Overall Steps per Second: 6930.26271

Timestep Collection Time: 5.18543
Timestep Consumption Time: 2.03493
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.22036

Cumulative Model Updates: 26814
Cumulative Timesteps: 223967228

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.41536
Policy Entropy: 1.29689
Value Function Loss: 0.01854

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.12881
Value Function Update Magnitude: 0.20065

Collected Steps per Second: 10370.16009
Overall Steps per Second: 7202.34653

Timestep Collection Time: 4.82567
Timestep Consumption Time: 2.12248
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 6.94815

Cumulative Model Updates: 26820
Cumulative Timesteps: 224017271

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.54342
Policy Entropy: 1.29304
Value Function Loss: 0.01812

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.12539
Value Function Update Magnitude: 0.19241

Collected Steps per Second: 9732.75889
Overall Steps per Second: 7009.80700

Timestep Collection Time: 5.14130
Timestep Consumption Time: 1.99713
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.13843

Cumulative Model Updates: 26826
Cumulative Timesteps: 224067310

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.68494
Policy Entropy: 1.28923
Value Function Loss: 0.01715

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.12269
Value Function Update Magnitude: 0.18576

Collected Steps per Second: 9520.22407
Overall Steps per Second: 6865.24890

Timestep Collection Time: 5.25250
Timestep Consumption Time: 2.03128
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 7.28379

Cumulative Model Updates: 26832
Cumulative Timesteps: 224117315

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.22948
Policy Entropy: 1.28942
Value Function Loss: 0.01709

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.12242
Value Function Update Magnitude: 0.18783

Collected Steps per Second: 10244.51832
Overall Steps per Second: 7228.94686

Timestep Collection Time: 4.88300
Timestep Consumption Time: 2.03696
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 6.91996

Cumulative Model Updates: 26838
Cumulative Timesteps: 224167339

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.94918
Policy Entropy: 1.29176
Value Function Loss: 0.01755

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.12584
Value Function Update Magnitude: 0.18926

Collected Steps per Second: 9758.93843
Overall Steps per Second: 6991.12580

Timestep Collection Time: 5.12699
Timestep Consumption Time: 2.02980
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.15679

Cumulative Model Updates: 26844
Cumulative Timesteps: 224217373

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.54990
Policy Entropy: 1.29154
Value Function Loss: 0.01807

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.12782
Value Function Update Magnitude: 0.19993

Collected Steps per Second: 9716.36693
Overall Steps per Second: 6902.49917

Timestep Collection Time: 5.15028
Timestep Consumption Time: 2.09956
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.24984

Cumulative Model Updates: 26850
Cumulative Timesteps: 224267415

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 224267415...
Checkpoint 224267415 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.67623
Policy Entropy: 1.30183
Value Function Loss: 0.01703

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.12525
Value Function Update Magnitude: 0.20039

Collected Steps per Second: 10546.73004
Overall Steps per Second: 7275.72715

Timestep Collection Time: 4.74166
Timestep Consumption Time: 2.13174
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.87340

Cumulative Model Updates: 26856
Cumulative Timesteps: 224317424

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.37209
Policy Entropy: 1.29580
Value Function Loss: 0.01678

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.12156
Value Function Update Magnitude: 0.20476

Collected Steps per Second: 9900.39716
Overall Steps per Second: 7034.49269

Timestep Collection Time: 5.05111
Timestep Consumption Time: 2.05786
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.10897

Cumulative Model Updates: 26862
Cumulative Timesteps: 224367432

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.29413
Policy Entropy: 1.30011
Value Function Loss: 0.01660

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.12362
Value Function Update Magnitude: 0.19289

Collected Steps per Second: 9732.32805
Overall Steps per Second: 6993.58622

Timestep Collection Time: 5.14214
Timestep Consumption Time: 2.01370
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.15584

Cumulative Model Updates: 26868
Cumulative Timesteps: 224417477

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.76885
Policy Entropy: 1.29668
Value Function Loss: 0.01748

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06915
Policy Update Magnitude: 0.12727
Value Function Update Magnitude: 0.19491

Collected Steps per Second: 10413.03525
Overall Steps per Second: 7247.56417

Timestep Collection Time: 4.80244
Timestep Consumption Time: 2.09753
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 6.89997

Cumulative Model Updates: 26874
Cumulative Timesteps: 224467485

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.49410
Policy Entropy: 1.29766
Value Function Loss: 0.01692

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06492
Policy Update Magnitude: 0.13009
Value Function Update Magnitude: 0.19076

Collected Steps per Second: 9792.35406
Overall Steps per Second: 6909.62547

Timestep Collection Time: 5.11042
Timestep Consumption Time: 2.13209
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 7.24251

Cumulative Model Updates: 26880
Cumulative Timesteps: 224517528

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79617
Policy Entropy: 1.30246
Value Function Loss: 0.01668

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06163
Policy Update Magnitude: 0.12780
Value Function Update Magnitude: 0.19166

Collected Steps per Second: 9662.07639
Overall Steps per Second: 6928.25053

Timestep Collection Time: 5.17632
Timestep Consumption Time: 2.04253
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.21885

Cumulative Model Updates: 26886
Cumulative Timesteps: 224567542

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.43366
Policy Entropy: 1.30205
Value Function Loss: 0.01651

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06737
Policy Update Magnitude: 0.12641
Value Function Update Magnitude: 0.18972

Collected Steps per Second: 10325.73670
Overall Steps per Second: 7211.10742

Timestep Collection Time: 4.84401
Timestep Consumption Time: 2.09223
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 6.93624

Cumulative Model Updates: 26892
Cumulative Timesteps: 224617560

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.95824
Policy Entropy: 1.29668
Value Function Loss: 0.01738

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.12584
Value Function Update Magnitude: 0.19901

Collected Steps per Second: 9829.57318
Overall Steps per Second: 7002.50027

Timestep Collection Time: 5.09086
Timestep Consumption Time: 2.05530
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.14616

Cumulative Model Updates: 26898
Cumulative Timesteps: 224667601

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.53668
Policy Entropy: 1.29198
Value Function Loss: 0.01766

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.12601
Value Function Update Magnitude: 0.19941

Collected Steps per Second: 9678.01842
Overall Steps per Second: 6958.32344

Timestep Collection Time: 5.17100
Timestep Consumption Time: 2.02111
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.19211

Cumulative Model Updates: 26904
Cumulative Timesteps: 224717646

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.47996
Policy Entropy: 1.29094
Value Function Loss: 0.01879

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.12752
Value Function Update Magnitude: 0.19197

Collected Steps per Second: 10612.14958
Overall Steps per Second: 7374.97068

Timestep Collection Time: 4.71233
Timestep Consumption Time: 2.06844
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 6.78077

Cumulative Model Updates: 26910
Cumulative Timesteps: 224767654

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 224767654...
Checkpoint 224767654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.35063
Policy Entropy: 1.29534
Value Function Loss: 0.01889

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.12984
Value Function Update Magnitude: 0.19036

Collected Steps per Second: 9878.86049
Overall Steps per Second: 7028.85753

Timestep Collection Time: 5.06546
Timestep Consumption Time: 2.05390
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.11936

Cumulative Model Updates: 26916
Cumulative Timesteps: 224817695

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.42620
Policy Entropy: 1.29400
Value Function Loss: 0.01915

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06507
Policy Update Magnitude: 0.13009
Value Function Update Magnitude: 0.18632

Collected Steps per Second: 9767.81823
Overall Steps per Second: 6992.10893

Timestep Collection Time: 5.12039
Timestep Consumption Time: 2.03268
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.15306

Cumulative Model Updates: 26922
Cumulative Timesteps: 224867710

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.15056
Policy Entropy: 1.29650
Value Function Loss: 0.01784

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.13223
Value Function Update Magnitude: 0.18762

Collected Steps per Second: 10348.05200
Overall Steps per Second: 7183.27757

Timestep Collection Time: 4.83627
Timestep Consumption Time: 2.13074
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.96701

Cumulative Model Updates: 26928
Cumulative Timesteps: 224917756

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.43018
Policy Entropy: 1.29138
Value Function Loss: 0.01761

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.12901
Value Function Update Magnitude: 0.18486

Collected Steps per Second: 9751.71660
Overall Steps per Second: 6922.10202

Timestep Collection Time: 5.13151
Timestep Consumption Time: 2.09766
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.22916

Cumulative Model Updates: 26934
Cumulative Timesteps: 224967797

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.01554
Policy Entropy: 1.29600
Value Function Loss: 0.01727

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.12651
Value Function Update Magnitude: 0.18133

Collected Steps per Second: 9778.69012
Overall Steps per Second: 7001.14893

Timestep Collection Time: 5.11377
Timestep Consumption Time: 2.02877
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 7.14254

Cumulative Model Updates: 26940
Cumulative Timesteps: 225017803

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.87577
Policy Entropy: 1.29809
Value Function Loss: 0.01885

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.06762
Policy Update Magnitude: 0.12625
Value Function Update Magnitude: 0.18568

Collected Steps per Second: 10370.47069
Overall Steps per Second: 7270.16535

Timestep Collection Time: 4.82273
Timestep Consumption Time: 2.05662
PPO Batch Consumption Time: 0.02411
Total Iteration Time: 6.87935

Cumulative Model Updates: 26946
Cumulative Timesteps: 225067817

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.57998
Policy Entropy: 1.30019
Value Function Loss: 0.01893

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.12999
Value Function Update Magnitude: 0.18484

Collected Steps per Second: 9911.66565
Overall Steps per Second: 6984.93877

Timestep Collection Time: 5.04728
Timestep Consumption Time: 2.11484
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.16212

Cumulative Model Updates: 26952
Cumulative Timesteps: 225117844

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.05031
Policy Entropy: 1.30335
Value Function Loss: 0.01894

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.13123
Value Function Update Magnitude: 0.18884

Collected Steps per Second: 9705.98383
Overall Steps per Second: 6940.45336

Timestep Collection Time: 5.15496
Timestep Consumption Time: 2.05407
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 7.20904

Cumulative Model Updates: 26958
Cumulative Timesteps: 225167878

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.67577
Policy Entropy: 1.30437
Value Function Loss: 0.01785

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.12806
Value Function Update Magnitude: 0.18996

Collected Steps per Second: 10570.55340
Overall Steps per Second: 7314.72288

Timestep Collection Time: 4.73145
Timestep Consumption Time: 2.10600
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 6.83744

Cumulative Model Updates: 26964
Cumulative Timesteps: 225217892

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -11.65134
Policy Entropy: 1.31031
Value Function Loss: 0.01815

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.12509
Value Function Update Magnitude: 0.18986

Collected Steps per Second: 9809.05601
Overall Steps per Second: 6996.35000

Timestep Collection Time: 5.09988
Timestep Consumption Time: 2.05028
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.15016

Cumulative Model Updates: 26970
Cumulative Timesteps: 225267917

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 225267917...
Checkpoint 225267917 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.44947
Policy Entropy: 1.30773
Value Function Loss: 0.01733

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06413
Policy Update Magnitude: 0.12344
Value Function Update Magnitude: 0.19134

Collected Steps per Second: 9740.10081
Overall Steps per Second: 7018.15256

Timestep Collection Time: 5.13670
Timestep Consumption Time: 1.99224
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.12894

Cumulative Model Updates: 26976
Cumulative Timesteps: 225317949

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.05338
Policy Entropy: 1.31481
Value Function Loss: 0.01707

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06259
Policy Update Magnitude: 0.12353
Value Function Update Magnitude: 0.18283

Collected Steps per Second: 10405.90223
Overall Steps per Second: 7287.93565

Timestep Collection Time: 4.80641
Timestep Consumption Time: 2.05630
PPO Batch Consumption Time: 0.02499
Total Iteration Time: 6.86271

Cumulative Model Updates: 26982
Cumulative Timesteps: 225367964

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.20600
Policy Entropy: 1.31300
Value Function Loss: 0.01646

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.12228
Value Function Update Magnitude: 0.17537

Collected Steps per Second: 10079.20070
Overall Steps per Second: 7313.38983

Timestep Collection Time: 4.96230
Timestep Consumption Time: 1.87666
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 6.83896

Cumulative Model Updates: 26988
Cumulative Timesteps: 225417980

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.97224
Policy Entropy: 1.31343
Value Function Loss: 0.01711

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.05910
Policy Update Magnitude: 0.12237
Value Function Update Magnitude: 0.17794

Collected Steps per Second: 9820.87239
Overall Steps per Second: 7047.59883

Timestep Collection Time: 5.09334
Timestep Consumption Time: 2.00426
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.09759

Cumulative Model Updates: 26994
Cumulative Timesteps: 225468001

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.91419
Policy Entropy: 1.30868
Value Function Loss: 0.01779

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06366
Policy Update Magnitude: 0.12628
Value Function Update Magnitude: 0.18131

Collected Steps per Second: 10284.27793
Overall Steps per Second: 7211.91911

Timestep Collection Time: 4.86597
Timestep Consumption Time: 2.07296
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 6.93893

Cumulative Model Updates: 27000
Cumulative Timesteps: 225518044

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.50221
Policy Entropy: 1.30584
Value Function Loss: 0.01800

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.07618
Policy Update Magnitude: 0.12731
Value Function Update Magnitude: 0.18126

Collected Steps per Second: 9760.58348
Overall Steps per Second: 6969.87274

Timestep Collection Time: 5.12562
Timestep Consumption Time: 2.05228
PPO Batch Consumption Time: 0.03010
Total Iteration Time: 7.17789

Cumulative Model Updates: 27006
Cumulative Timesteps: 225568073

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.26801
Policy Entropy: 1.30941
Value Function Loss: 0.01805

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.12596
Value Function Update Magnitude: 0.18236

Collected Steps per Second: 9721.55754
Overall Steps per Second: 6947.36762

Timestep Collection Time: 5.14743
Timestep Consumption Time: 2.05545
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.20287

Cumulative Model Updates: 27012
Cumulative Timesteps: 225618114

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.39747
Policy Entropy: 1.30441
Value Function Loss: 0.01839

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.06674
Policy Update Magnitude: 0.12746
Value Function Update Magnitude: 0.18627

Collected Steps per Second: 10161.15987
Overall Steps per Second: 7138.49468

Timestep Collection Time: 4.92385
Timestep Consumption Time: 2.08491
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.00876

Cumulative Model Updates: 27018
Cumulative Timesteps: 225668146

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.99711
Policy Entropy: 1.30501
Value Function Loss: 0.01797

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.13191
Value Function Update Magnitude: 0.17961

Collected Steps per Second: 9647.61716
Overall Steps per Second: 6906.26236

Timestep Collection Time: 5.18574
Timestep Consumption Time: 2.05841
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.24415

Cumulative Model Updates: 27024
Cumulative Timesteps: 225718176

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.87776
Policy Entropy: 1.30140
Value Function Loss: 0.01821

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.12753
Value Function Update Magnitude: 0.17792

Collected Steps per Second: 9718.53746
Overall Steps per Second: 6978.01600

Timestep Collection Time: 5.14944
Timestep Consumption Time: 2.02237
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.17181

Cumulative Model Updates: 27030
Cumulative Timesteps: 225768221

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 225768221...
Checkpoint 225768221 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.73855
Policy Entropy: 1.30078
Value Function Loss: 0.01719

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.12591
Value Function Update Magnitude: 0.18242

Collected Steps per Second: 10212.81273
Overall Steps per Second: 7148.96619

Timestep Collection Time: 4.89640
Timestep Consumption Time: 2.09846
PPO Batch Consumption Time: 0.02417
Total Iteration Time: 6.99486

Cumulative Model Updates: 27036
Cumulative Timesteps: 225818227

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.16974
Policy Entropy: 1.29915
Value Function Loss: 0.01745

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.12594
Value Function Update Magnitude: 0.18510

Collected Steps per Second: 9822.45005
Overall Steps per Second: 6999.94353

Timestep Collection Time: 5.09242
Timestep Consumption Time: 2.05336
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.14577

Cumulative Model Updates: 27042
Cumulative Timesteps: 225868247

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.20772
Policy Entropy: 1.29691
Value Function Loss: 0.01687

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.12756
Value Function Update Magnitude: 0.18805

Collected Steps per Second: 9570.99856
Overall Steps per Second: 6929.24068

Timestep Collection Time: 5.22652
Timestep Consumption Time: 1.99260
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.21912

Cumulative Model Updates: 27048
Cumulative Timesteps: 225918270

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.69464
Policy Entropy: 1.30346
Value Function Loss: 0.01585

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.12201
Value Function Update Magnitude: 0.18303

Collected Steps per Second: 10327.05277
Overall Steps per Second: 7192.22141

Timestep Collection Time: 4.84340
Timestep Consumption Time: 2.11106
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 6.95446

Cumulative Model Updates: 27054
Cumulative Timesteps: 225968288

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.39222
Policy Entropy: 1.30377
Value Function Loss: 0.01613

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.12158
Value Function Update Magnitude: 0.17981

Collected Steps per Second: 9766.13740
Overall Steps per Second: 6948.69876

Timestep Collection Time: 5.12045
Timestep Consumption Time: 2.07615
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.19660

Cumulative Model Updates: 27060
Cumulative Timesteps: 226018295

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.37701
Policy Entropy: 1.30599
Value Function Loss: 0.01658

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06064
Policy Update Magnitude: 0.12279
Value Function Update Magnitude: 0.18049

Collected Steps per Second: 9780.41939
Overall Steps per Second: 6934.23905

Timestep Collection Time: 5.11399
Timestep Consumption Time: 2.09905
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.21305

Cumulative Model Updates: 27066
Cumulative Timesteps: 226068312

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.10691
Policy Entropy: 1.30275
Value Function Loss: 0.01642

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.12235
Value Function Update Magnitude: 0.18943

Collected Steps per Second: 10402.58903
Overall Steps per Second: 7203.97764

Timestep Collection Time: 4.81082
Timestep Consumption Time: 2.13604
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 6.94686

Cumulative Model Updates: 27072
Cumulative Timesteps: 226118357

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.19057
Policy Entropy: 1.30141
Value Function Loss: 0.01613

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06943
Policy Update Magnitude: 0.12166
Value Function Update Magnitude: 0.19005

Collected Steps per Second: 9781.07678
Overall Steps per Second: 6999.16141

Timestep Collection Time: 5.11365
Timestep Consumption Time: 2.03249
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.14614

Cumulative Model Updates: 27078
Cumulative Timesteps: 226168374

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.39850
Policy Entropy: 1.29999
Value Function Loss: 0.01631

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06773
Policy Update Magnitude: 0.12362
Value Function Update Magnitude: 0.17894

Collected Steps per Second: 9786.27962
Overall Steps per Second: 7072.08229

Timestep Collection Time: 5.11114
Timestep Consumption Time: 1.96160
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.07274

Cumulative Model Updates: 27084
Cumulative Timesteps: 226218393

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.05096
Policy Entropy: 1.29836
Value Function Loss: 0.01788

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06236
Policy Update Magnitude: 0.12788
Value Function Update Magnitude: 0.16813

Collected Steps per Second: 10430.93229
Overall Steps per Second: 7215.45814

Timestep Collection Time: 4.79545
Timestep Consumption Time: 2.13703
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 6.93248

Cumulative Model Updates: 27090
Cumulative Timesteps: 226268414

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 226268414...
Checkpoint 226268414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.49185
Policy Entropy: 1.29585
Value Function Loss: 0.01828

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06006
Policy Update Magnitude: 0.12804
Value Function Update Magnitude: 0.17791

Collected Steps per Second: 9951.23255
Overall Steps per Second: 7061.46408

Timestep Collection Time: 5.02641
Timestep Consumption Time: 2.05696
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.08338

Cumulative Model Updates: 27096
Cumulative Timesteps: 226318433

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.40407
Policy Entropy: 1.29665
Value Function Loss: 0.01726

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.05798
Policy Update Magnitude: 0.12674
Value Function Update Magnitude: 0.18330

Collected Steps per Second: 9627.25406
Overall Steps per Second: 6907.99751

Timestep Collection Time: 5.19567
Timestep Consumption Time: 2.04522
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.24088

Cumulative Model Updates: 27102
Cumulative Timesteps: 226368453

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.03244
Policy Entropy: 1.29726
Value Function Loss: 0.01627

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06184
Policy Update Magnitude: 0.12345
Value Function Update Magnitude: 0.18802

Collected Steps per Second: 10616.40351
Overall Steps per Second: 7353.58300

Timestep Collection Time: 4.71233
Timestep Consumption Time: 2.09088
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 6.80321

Cumulative Model Updates: 27108
Cumulative Timesteps: 226418481

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.85818
Policy Entropy: 1.29963
Value Function Loss: 0.01595

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.05889
Policy Update Magnitude: 0.12166
Value Function Update Magnitude: 0.17434

Collected Steps per Second: 9748.60561
Overall Steps per Second: 6869.95658

Timestep Collection Time: 5.12996
Timestep Consumption Time: 2.14956
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.27952

Cumulative Model Updates: 27114
Cumulative Timesteps: 226468491

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.70528
Policy Entropy: 1.29528
Value Function Loss: 0.01694

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.12201
Value Function Update Magnitude: 0.17343

Collected Steps per Second: 9758.58119
Overall Steps per Second: 6958.07152

Timestep Collection Time: 5.12503
Timestep Consumption Time: 2.06274
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.18777

Cumulative Model Updates: 27120
Cumulative Timesteps: 226518504

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.20509
Policy Entropy: 1.29655
Value Function Loss: 0.01736

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.12614
Value Function Update Magnitude: 0.18116

Collected Steps per Second: 10398.14245
Overall Steps per Second: 7200.58419

Timestep Collection Time: 4.81172
Timestep Consumption Time: 2.13674
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.94846

Cumulative Model Updates: 27126
Cumulative Timesteps: 226568537

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.85812
Policy Entropy: 1.29675
Value Function Loss: 0.01764

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07121
Policy Update Magnitude: 0.13113
Value Function Update Magnitude: 0.18147

Collected Steps per Second: 9803.42105
Overall Steps per Second: 7026.78427

Timestep Collection Time: 5.10393
Timestep Consumption Time: 2.01682
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.12075

Cumulative Model Updates: 27132
Cumulative Timesteps: 226618573

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.49729
Policy Entropy: 1.29888
Value Function Loss: 0.01754

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.13243
Value Function Update Magnitude: 0.18880

Collected Steps per Second: 9612.44700
Overall Steps per Second: 6880.49565

Timestep Collection Time: 5.20263
Timestep Consumption Time: 2.06574
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.26837

Cumulative Model Updates: 27138
Cumulative Timesteps: 226668583

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.00837
Policy Entropy: 1.29982
Value Function Loss: 0.01775

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07256
Policy Update Magnitude: 0.13032
Value Function Update Magnitude: 0.19254

Collected Steps per Second: 10280.08162
Overall Steps per Second: 7181.83381

Timestep Collection Time: 4.86660
Timestep Consumption Time: 2.09945
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 6.96605

Cumulative Model Updates: 27144
Cumulative Timesteps: 226718612

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.12949
Policy Entropy: 1.29803
Value Function Loss: 0.01758

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06810
Policy Update Magnitude: 0.12880
Value Function Update Magnitude: 0.19189

Collected Steps per Second: 9798.14240
Overall Steps per Second: 6951.96226

Timestep Collection Time: 5.10393
Timestep Consumption Time: 2.08958
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 7.19351

Cumulative Model Updates: 27150
Cumulative Timesteps: 226768621

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 226768621...
Checkpoint 226768621 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.96193
Policy Entropy: 1.29909
Value Function Loss: 0.01714

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06785
Policy Update Magnitude: 0.12578
Value Function Update Magnitude: 0.20110

Collected Steps per Second: 9663.85670
Overall Steps per Second: 6933.42750

Timestep Collection Time: 5.17495
Timestep Consumption Time: 2.03793
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.21288

Cumulative Model Updates: 27156
Cumulative Timesteps: 226818631

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.43824
Policy Entropy: 1.29062
Value Function Loss: 0.01668

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.12346
Value Function Update Magnitude: 0.18779

Collected Steps per Second: 10350.25397
Overall Steps per Second: 6992.81116

Timestep Collection Time: 4.83196
Timestep Consumption Time: 2.31996
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 7.15192

Cumulative Model Updates: 27162
Cumulative Timesteps: 226868643

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.63530
Policy Entropy: 1.29108
Value Function Loss: 0.01674

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.12098
Value Function Update Magnitude: 0.17184

Collected Steps per Second: 10398.87591
Overall Steps per Second: 7162.55762

Timestep Collection Time: 4.80975
Timestep Consumption Time: 2.17323
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 6.98298

Cumulative Model Updates: 27168
Cumulative Timesteps: 226918659

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.25518
Policy Entropy: 1.29288
Value Function Loss: 0.01733

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.06866
Policy Update Magnitude: 0.12554
Value Function Update Magnitude: 0.16665

Collected Steps per Second: 9982.01616
Overall Steps per Second: 7134.25356

Timestep Collection Time: 5.01201
Timestep Consumption Time: 2.00063
PPO Batch Consumption Time: 0.02449
Total Iteration Time: 7.01265

Cumulative Model Updates: 27174
Cumulative Timesteps: 226968689

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.89199
Policy Entropy: 1.29333
Value Function Loss: 0.01806

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.12787
Value Function Update Magnitude: 0.17073

Collected Steps per Second: 9752.52199
Overall Steps per Second: 6967.66411

Timestep Collection Time: 5.12883
Timestep Consumption Time: 2.04991
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.17873

Cumulative Model Updates: 27180
Cumulative Timesteps: 227018708

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.51501
Policy Entropy: 1.29467
Value Function Loss: 0.01706

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.12595
Value Function Update Magnitude: 0.17401

Collected Steps per Second: 10325.12028
Overall Steps per Second: 7210.69888

Timestep Collection Time: 4.84653
Timestep Consumption Time: 2.09330
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 6.93983

Cumulative Model Updates: 27186
Cumulative Timesteps: 227068749

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.27414
Policy Entropy: 1.29748
Value Function Loss: 0.01665

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.12410
Value Function Update Magnitude: 0.17072

Collected Steps per Second: 9765.67364
Overall Steps per Second: 6971.38701

Timestep Collection Time: 5.12120
Timestep Consumption Time: 2.05269
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.17390

Cumulative Model Updates: 27192
Cumulative Timesteps: 227118761

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.71385
Policy Entropy: 1.30341
Value Function Loss: 0.01689

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05680
Policy Update Magnitude: 0.12135
Value Function Update Magnitude: 0.17082

Collected Steps per Second: 9759.79929
Overall Steps per Second: 7001.12725

Timestep Collection Time: 5.12664
Timestep Consumption Time: 2.02006
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.14671

Cumulative Model Updates: 27198
Cumulative Timesteps: 227168796

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.97357
Policy Entropy: 1.30122
Value Function Loss: 0.01778

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06334
Policy Update Magnitude: 0.12271
Value Function Update Magnitude: 0.17876

Collected Steps per Second: 10332.34346
Overall Steps per Second: 7184.43389

Timestep Collection Time: 4.84053
Timestep Consumption Time: 2.12091
PPO Batch Consumption Time: 0.02429
Total Iteration Time: 6.96144

Cumulative Model Updates: 27204
Cumulative Timesteps: 227218810

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.98224
Policy Entropy: 1.29932
Value Function Loss: 0.01790

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07076
Policy Update Magnitude: 0.12266
Value Function Update Magnitude: 0.18519

Collected Steps per Second: 10225.02909
Overall Steps per Second: 7244.12829

Timestep Collection Time: 4.89358
Timestep Consumption Time: 2.01367
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.90725

Cumulative Model Updates: 27210
Cumulative Timesteps: 227268847

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 227268847...
Checkpoint 227268847 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.39610
Policy Entropy: 1.29478
Value Function Loss: 0.01723

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.12324
Value Function Update Magnitude: 0.19265

Collected Steps per Second: 9820.56628
Overall Steps per Second: 7045.90703

Timestep Collection Time: 5.09207
Timestep Consumption Time: 2.00524
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.09731

Cumulative Model Updates: 27216
Cumulative Timesteps: 227318854

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.18577
Policy Entropy: 1.29614
Value Function Loss: 0.01801

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.12400
Value Function Update Magnitude: 0.19455

Collected Steps per Second: 10291.92666
Overall Steps per Second: 7219.49436

Timestep Collection Time: 4.86051
Timestep Consumption Time: 2.06851
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 6.92902

Cumulative Model Updates: 27222
Cumulative Timesteps: 227368878

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.84121
Policy Entropy: 1.29119
Value Function Loss: 0.01812

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.12570
Value Function Update Magnitude: 0.19968

Collected Steps per Second: 9879.36601
Overall Steps per Second: 6998.38702

Timestep Collection Time: 5.06277
Timestep Consumption Time: 2.08416
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.14693

Cumulative Model Updates: 27228
Cumulative Timesteps: 227418895

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.34116
Policy Entropy: 1.29221
Value Function Loss: 0.01831

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.12776
Value Function Update Magnitude: 0.20472

Collected Steps per Second: 9802.89546
Overall Steps per Second: 7032.10839

Timestep Collection Time: 5.10451
Timestep Consumption Time: 2.01128
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.11579

Cumulative Model Updates: 27234
Cumulative Timesteps: 227468934

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.53083
Policy Entropy: 1.29657
Value Function Loss: 0.01712

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.12763
Value Function Update Magnitude: 0.20242

Collected Steps per Second: 10342.54149
Overall Steps per Second: 7194.49715

Timestep Collection Time: 4.83798
Timestep Consumption Time: 2.11692
PPO Batch Consumption Time: 0.02349
Total Iteration Time: 6.95490

Cumulative Model Updates: 27240
Cumulative Timesteps: 227518971

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.83356
Policy Entropy: 1.29967
Value Function Loss: 0.01712

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06319
Policy Update Magnitude: 0.12486
Value Function Update Magnitude: 0.19657

Collected Steps per Second: 9837.91716
Overall Steps per Second: 6984.94657

Timestep Collection Time: 5.08400
Timestep Consumption Time: 2.07654
PPO Batch Consumption Time: 0.02439
Total Iteration Time: 7.16054

Cumulative Model Updates: 27246
Cumulative Timesteps: 227568987

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.76263
Policy Entropy: 1.30022
Value Function Loss: 0.01693

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.06663
Policy Update Magnitude: 0.12636
Value Function Update Magnitude: 0.19147

Collected Steps per Second: 9793.52620
Overall Steps per Second: 7018.65354

Timestep Collection Time: 5.10980
Timestep Consumption Time: 2.02020
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.13000

Cumulative Model Updates: 27252
Cumulative Timesteps: 227619030

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.17371
Policy Entropy: 1.29815
Value Function Loss: 0.01703

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.12352
Value Function Update Magnitude: 0.18813

Collected Steps per Second: 10476.68692
Overall Steps per Second: 7258.06363

Timestep Collection Time: 4.77584
Timestep Consumption Time: 2.11787
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.89371

Cumulative Model Updates: 27258
Cumulative Timesteps: 227669065

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.28464
Policy Entropy: 1.29615
Value Function Loss: 0.01662

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.12367
Value Function Update Magnitude: 0.18479

Collected Steps per Second: 9902.68453
Overall Steps per Second: 7042.08036

Timestep Collection Time: 5.05247
Timestep Consumption Time: 2.05239
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 7.10486

Cumulative Model Updates: 27264
Cumulative Timesteps: 227719098

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.52170
Policy Entropy: 1.29861
Value Function Loss: 0.01693

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.06976
Policy Update Magnitude: 0.12366
Value Function Update Magnitude: 0.18151

Collected Steps per Second: 9938.50559
Overall Steps per Second: 7103.84974

Timestep Collection Time: 5.03154
Timestep Consumption Time: 2.00774
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.03928

Cumulative Model Updates: 27270
Cumulative Timesteps: 227769104

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 227769104...
Checkpoint 227769104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.33823
Policy Entropy: 1.29892
Value Function Loss: 0.01686

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.12498
Value Function Update Magnitude: 0.18612

Collected Steps per Second: 10403.76060
Overall Steps per Second: 7234.75369

Timestep Collection Time: 4.80615
Timestep Consumption Time: 2.10522
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.91136

Cumulative Model Updates: 27276
Cumulative Timesteps: 227819106

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.99917
Policy Entropy: 1.29476
Value Function Loss: 0.01763

Mean KL Divergence: 0.02168
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.12610
Value Function Update Magnitude: 0.18668

Collected Steps per Second: 10013.10290
Overall Steps per Second: 7123.17207

Timestep Collection Time: 4.99476
Timestep Consumption Time: 2.02641
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.02117

Cumulative Model Updates: 27282
Cumulative Timesteps: 227869119

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.58454
Policy Entropy: 1.29484
Value Function Loss: 0.01797

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.12540
Value Function Update Magnitude: 0.18879

Collected Steps per Second: 10299.76042
Overall Steps per Second: 6990.63125

Timestep Collection Time: 4.85516
Timestep Consumption Time: 2.29827
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.15343

Cumulative Model Updates: 27288
Cumulative Timesteps: 227919126

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.03232
Policy Entropy: 1.29579
Value Function Loss: 0.01809

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.12453
Value Function Update Magnitude: 0.19421

Collected Steps per Second: 10235.99731
Overall Steps per Second: 7176.03495

Timestep Collection Time: 4.88570
Timestep Consumption Time: 2.08333
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 6.96903

Cumulative Model Updates: 27294
Cumulative Timesteps: 227969136

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.95941
Policy Entropy: 1.30162
Value Function Loss: 0.01743

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.12442
Value Function Update Magnitude: 0.18998

Collected Steps per Second: 9700.41180
Overall Steps per Second: 6975.19916

Timestep Collection Time: 5.15525
Timestep Consumption Time: 2.01416
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.16940

Cumulative Model Updates: 27300
Cumulative Timesteps: 228019144

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.36413
Policy Entropy: 1.30217
Value Function Loss: 0.01725

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.12375
Value Function Update Magnitude: 0.18776

Collected Steps per Second: 10468.99133
Overall Steps per Second: 7023.04560

Timestep Collection Time: 4.77993
Timestep Consumption Time: 2.34533
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 7.12526

Cumulative Model Updates: 27306
Cumulative Timesteps: 228069185

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.14984
Policy Entropy: 1.29832
Value Function Loss: 0.01766

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06413
Policy Update Magnitude: 0.12595
Value Function Update Magnitude: 0.18685

Collected Steps per Second: 10312.02148
Overall Steps per Second: 7197.22513

Timestep Collection Time: 4.85181
Timestep Consumption Time: 2.09976
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 6.95157

Cumulative Model Updates: 27312
Cumulative Timesteps: 228119217

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.14780
Policy Entropy: 1.29667
Value Function Loss: 0.01778

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06737
Policy Update Magnitude: 0.12486
Value Function Update Magnitude: 0.18484

Collected Steps per Second: 9740.52411
Overall Steps per Second: 6986.93665

Timestep Collection Time: 5.13473
Timestep Consumption Time: 2.02362
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.15836

Cumulative Model Updates: 27318
Cumulative Timesteps: 228169232

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.39437
Policy Entropy: 1.28897
Value Function Loss: 0.01737

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.12400
Value Function Update Magnitude: 0.18228

Collected Steps per Second: 9621.97839
Overall Steps per Second: 6939.55889

Timestep Collection Time: 5.19779
Timestep Consumption Time: 2.00915
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.20694

Cumulative Model Updates: 27324
Cumulative Timesteps: 228219245

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.05574
Policy Entropy: 1.28992
Value Function Loss: 0.01631

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.12383
Value Function Update Magnitude: 0.18230

Collected Steps per Second: 10290.71042
Overall Steps per Second: 7203.10920

Timestep Collection Time: 4.86128
Timestep Consumption Time: 2.08378
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.94506

Cumulative Model Updates: 27330
Cumulative Timesteps: 228269271

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 228269271...
Checkpoint 228269271 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.45127
Policy Entropy: 1.28976
Value Function Loss: 0.01647

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.12419
Value Function Update Magnitude: 0.18138

Collected Steps per Second: 9595.40085
Overall Steps per Second: 6884.18194

Timestep Collection Time: 5.21198
Timestep Consumption Time: 2.05265
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.26462

Cumulative Model Updates: 27336
Cumulative Timesteps: 228319282

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.05873
Policy Entropy: 1.29121
Value Function Loss: 0.01685

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06436
Policy Update Magnitude: 0.12626
Value Function Update Magnitude: 0.18210

Collected Steps per Second: 9507.39321
Overall Steps per Second: 6824.73588

Timestep Collection Time: 5.26001
Timestep Consumption Time: 2.06760
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.32761

Cumulative Model Updates: 27342
Cumulative Timesteps: 228369291

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.85578
Policy Entropy: 1.28849
Value Function Loss: 0.01742

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.12734
Value Function Update Magnitude: 0.19157

Collected Steps per Second: 10239.84090
Overall Steps per Second: 7275.97509

Timestep Collection Time: 4.88289
Timestep Consumption Time: 1.98904
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.87193

Cumulative Model Updates: 27348
Cumulative Timesteps: 228419291

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.39245
Policy Entropy: 1.28930
Value Function Loss: 0.01787

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.12597
Value Function Update Magnitude: 0.19245

Collected Steps per Second: 10106.67766
Overall Steps per Second: 7107.06554

Timestep Collection Time: 4.94940
Timestep Consumption Time: 2.08895
PPO Batch Consumption Time: 0.02401
Total Iteration Time: 7.03835

Cumulative Model Updates: 27354
Cumulative Timesteps: 228469313

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.84186
Policy Entropy: 1.28839
Value Function Loss: 0.01754

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07408
Policy Update Magnitude: 0.12387
Value Function Update Magnitude: 0.18477

Collected Steps per Second: 9792.35429
Overall Steps per Second: 7033.97667

Timestep Collection Time: 5.11062
Timestep Consumption Time: 2.00413
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 7.11475

Cumulative Model Updates: 27360
Cumulative Timesteps: 228519358

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.78044
Policy Entropy: 1.29103
Value Function Loss: 0.01763

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.06654
Policy Update Magnitude: 0.12420
Value Function Update Magnitude: 0.18377

Collected Steps per Second: 10358.26149
Overall Steps per Second: 7217.79043

Timestep Collection Time: 4.82861
Timestep Consumption Time: 2.10093
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 6.92954

Cumulative Model Updates: 27366
Cumulative Timesteps: 228569374

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.31637
Policy Entropy: 1.28796
Value Function Loss: 0.01769

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.12887
Value Function Update Magnitude: 0.18342

Collected Steps per Second: 9986.15390
Overall Steps per Second: 7053.26912

Timestep Collection Time: 5.00743
Timestep Consumption Time: 2.08219
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 7.08962

Cumulative Model Updates: 27372
Cumulative Timesteps: 228619379

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.29728
Policy Entropy: 1.29426
Value Function Loss: 0.01834

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.12735
Value Function Update Magnitude: 0.18682

Collected Steps per Second: 9705.85476
Overall Steps per Second: 6996.76809

Timestep Collection Time: 5.15431
Timestep Consumption Time: 1.99570
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.15002

Cumulative Model Updates: 27378
Cumulative Timesteps: 228669406

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.18166
Policy Entropy: 1.29130
Value Function Loss: 0.01860

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.12648
Value Function Update Magnitude: 0.19484

Collected Steps per Second: 10393.90917
Overall Steps per Second: 7261.56809

Timestep Collection Time: 4.81051
Timestep Consumption Time: 2.07506
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.88557

Cumulative Model Updates: 27384
Cumulative Timesteps: 228719406

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.17735
Policy Entropy: 1.29292
Value Function Loss: 0.01817

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.12466
Value Function Update Magnitude: 0.19472

Collected Steps per Second: 9817.78000
Overall Steps per Second: 7034.35506

Timestep Collection Time: 5.09565
Timestep Consumption Time: 2.01630
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.11195

Cumulative Model Updates: 27390
Cumulative Timesteps: 228769434

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 228769434...
Checkpoint 228769434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.01181
Policy Entropy: 1.29035
Value Function Loss: 0.01799

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.06884
Policy Update Magnitude: 0.12897
Value Function Update Magnitude: 0.18752

Collected Steps per Second: 9841.61051
Overall Steps per Second: 7023.74139

Timestep Collection Time: 5.08047
Timestep Consumption Time: 2.03824
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.11871

Cumulative Model Updates: 27396
Cumulative Timesteps: 228819434

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.97004
Policy Entropy: 1.29097
Value Function Loss: 0.01720

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.13001
Value Function Update Magnitude: 0.18240

Collected Steps per Second: 10388.03361
Overall Steps per Second: 7248.97900

Timestep Collection Time: 4.81400
Timestep Consumption Time: 2.08463
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 6.89863

Cumulative Model Updates: 27402
Cumulative Timesteps: 228869442

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.98506
Policy Entropy: 1.29622
Value Function Loss: 0.01763

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.12990
Value Function Update Magnitude: 0.18876

Collected Steps per Second: 9752.02124
Overall Steps per Second: 6920.95589

Timestep Collection Time: 5.13186
Timestep Consumption Time: 2.09922
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.23108

Cumulative Model Updates: 27408
Cumulative Timesteps: 228919488

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.18689
Policy Entropy: 1.29540
Value Function Loss: 0.01770

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.12811
Value Function Update Magnitude: 0.19249

Collected Steps per Second: 9713.84050
Overall Steps per Second: 6986.62149

Timestep Collection Time: 5.14915
Timestep Consumption Time: 2.00996
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.15911

Cumulative Model Updates: 27414
Cumulative Timesteps: 228969506

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.50365
Policy Entropy: 1.29751
Value Function Loss: 0.01751

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.12922
Value Function Update Magnitude: 0.19438

Collected Steps per Second: 10245.31829
Overall Steps per Second: 7138.30548

Timestep Collection Time: 4.88272
Timestep Consumption Time: 2.12525
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.00797

Cumulative Model Updates: 27420
Cumulative Timesteps: 229019531

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.65547
Policy Entropy: 1.29580
Value Function Loss: 0.01707

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07154
Policy Update Magnitude: 0.12596
Value Function Update Magnitude: 0.18540

Collected Steps per Second: 9759.13861
Overall Steps per Second: 6906.90123

Timestep Collection Time: 5.12484
Timestep Consumption Time: 2.11633
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.24116

Cumulative Model Updates: 27426
Cumulative Timesteps: 229069545

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.66524
Policy Entropy: 1.29161
Value Function Loss: 0.01737

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.05903
Policy Update Magnitude: 0.12297
Value Function Update Magnitude: 0.17565

Collected Steps per Second: 9881.24987
Overall Steps per Second: 7049.16419

Timestep Collection Time: 5.06262
Timestep Consumption Time: 2.03397
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.09659

Cumulative Model Updates: 27432
Cumulative Timesteps: 229119570

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.84664
Policy Entropy: 1.29208
Value Function Loss: 0.01811

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.05559
Policy Update Magnitude: 0.12535
Value Function Update Magnitude: 0.17726

Collected Steps per Second: 10287.96848
Overall Steps per Second: 7178.45574

Timestep Collection Time: 4.86228
Timestep Consumption Time: 2.10621
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 6.96849

Cumulative Model Updates: 27438
Cumulative Timesteps: 229169593

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.85230
Policy Entropy: 1.29579
Value Function Loss: 0.01789

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06135
Policy Update Magnitude: 0.12871
Value Function Update Magnitude: 0.17731

Collected Steps per Second: 9999.22704
Overall Steps per Second: 7065.18966

Timestep Collection Time: 5.00299
Timestep Consumption Time: 2.07764
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.08063

Cumulative Model Updates: 27444
Cumulative Timesteps: 229219619

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.78870
Policy Entropy: 1.29911
Value Function Loss: 0.01840

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.12945
Value Function Update Magnitude: 0.17981

Collected Steps per Second: 9821.82900
Overall Steps per Second: 7013.06716

Timestep Collection Time: 5.09427
Timestep Consumption Time: 2.04027
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.13454

Cumulative Model Updates: 27450
Cumulative Timesteps: 229269654

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 229269654...
Checkpoint 229269654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.86890
Policy Entropy: 1.29579
Value Function Loss: 0.01703

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.12989
Value Function Update Magnitude: 0.18256

Collected Steps per Second: 10434.22459
Overall Steps per Second: 7284.40739

Timestep Collection Time: 4.79384
Timestep Consumption Time: 2.07288
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 6.86672

Cumulative Model Updates: 27456
Cumulative Timesteps: 229319674

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.31989
Policy Entropy: 1.29575
Value Function Loss: 0.01762

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.12538
Value Function Update Magnitude: 0.18116

Collected Steps per Second: 10050.56618
Overall Steps per Second: 7179.91320

Timestep Collection Time: 4.97892
Timestep Consumption Time: 1.99066
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 6.96958

Cumulative Model Updates: 27462
Cumulative Timesteps: 229369715

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.80857
Policy Entropy: 1.29789
Value Function Loss: 0.01687

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06927
Policy Update Magnitude: 0.12303
Value Function Update Magnitude: 0.18223

Collected Steps per Second: 10002.69142
Overall Steps per Second: 7095.59429

Timestep Collection Time: 5.00215
Timestep Consumption Time: 2.04941
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.05156

Cumulative Model Updates: 27468
Cumulative Timesteps: 229419750

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.57443
Policy Entropy: 1.29600
Value Function Loss: 0.01727

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.12702
Value Function Update Magnitude: 0.18788

Collected Steps per Second: 10481.29106
Overall Steps per Second: 7263.22220

Timestep Collection Time: 4.77222
Timestep Consumption Time: 2.11440
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 6.88661

Cumulative Model Updates: 27474
Cumulative Timesteps: 229469769

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.45950
Policy Entropy: 1.29735
Value Function Loss: 0.01722

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.12754
Value Function Update Magnitude: 0.18525

Collected Steps per Second: 9781.44578
Overall Steps per Second: 6989.53417

Timestep Collection Time: 5.11489
Timestep Consumption Time: 2.04310
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.15799

Cumulative Model Updates: 27480
Cumulative Timesteps: 229519800

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.22825
Policy Entropy: 1.29723
Value Function Loss: 0.01713

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07103
Policy Update Magnitude: 0.12599
Value Function Update Magnitude: 0.17758

Collected Steps per Second: 9631.63551
Overall Steps per Second: 6889.69080

Timestep Collection Time: 5.19278
Timestep Consumption Time: 2.06661
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.25940

Cumulative Model Updates: 27486
Cumulative Timesteps: 229569815

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.21406
Policy Entropy: 1.29647
Value Function Loss: 0.01758

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.12596
Value Function Update Magnitude: 0.17650

Collected Steps per Second: 10380.21095
Overall Steps per Second: 7221.94199

Timestep Collection Time: 4.81907
Timestep Consumption Time: 2.10746
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 6.92653

Cumulative Model Updates: 27492
Cumulative Timesteps: 229619838

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.05998
Policy Entropy: 1.29715
Value Function Loss: 0.01797

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.12820
Value Function Update Magnitude: 0.18315

Collected Steps per Second: 9842.07731
Overall Steps per Second: 7032.06643

Timestep Collection Time: 5.08135
Timestep Consumption Time: 2.03050
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.11185

Cumulative Model Updates: 27498
Cumulative Timesteps: 229669849

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.72274
Policy Entropy: 1.29783
Value Function Loss: 0.01881

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.12840
Value Function Update Magnitude: 0.18675

Collected Steps per Second: 9801.83492
Overall Steps per Second: 7104.31268

Timestep Collection Time: 5.10302
Timestep Consumption Time: 1.93763
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.04065

Cumulative Model Updates: 27504
Cumulative Timesteps: 229719868

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.84416
Policy Entropy: 1.29988
Value Function Loss: 0.01819

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.12563
Value Function Update Magnitude: 0.17457

Collected Steps per Second: 10380.63254
Overall Steps per Second: 7242.82852

Timestep Collection Time: 4.81820
Timestep Consumption Time: 2.08739
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 6.90559

Cumulative Model Updates: 27510
Cumulative Timesteps: 229769884

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 229769884...
Checkpoint 229769884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.29434
Policy Entropy: 1.29755
Value Function Loss: 0.01823

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.12883
Value Function Update Magnitude: 0.17232

Collected Steps per Second: 9894.64379
Overall Steps per Second: 6985.18680

Timestep Collection Time: 5.05738
Timestep Consumption Time: 2.10649
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.16387

Cumulative Model Updates: 27516
Cumulative Timesteps: 229819925

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.10288
Policy Entropy: 1.30059
Value Function Loss: 0.01702

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.12437
Value Function Update Magnitude: 0.17406

Collected Steps per Second: 9694.02310
Overall Steps per Second: 6949.01139

Timestep Collection Time: 5.15926
Timestep Consumption Time: 2.03802
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.19728

Cumulative Model Updates: 27522
Cumulative Timesteps: 229869939

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.37250
Policy Entropy: 1.30472
Value Function Loss: 0.01792

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.12444
Value Function Update Magnitude: 0.17630

Collected Steps per Second: 10472.24328
Overall Steps per Second: 7346.91510

Timestep Collection Time: 4.77663
Timestep Consumption Time: 2.03194
PPO Batch Consumption Time: 0.02381
Total Iteration Time: 6.80857

Cumulative Model Updates: 27528
Cumulative Timesteps: 229919961

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.84909
Policy Entropy: 1.30276
Value Function Loss: 0.01849

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.12740
Value Function Update Magnitude: 0.18166

Collected Steps per Second: 9764.19683
Overall Steps per Second: 7006.18635

Timestep Collection Time: 5.12505
Timestep Consumption Time: 2.01749
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 7.14254

Cumulative Model Updates: 27534
Cumulative Timesteps: 229970003

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.07021
Policy Entropy: 1.30407
Value Function Loss: 0.01948

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.13107
Value Function Update Magnitude: 0.18565

Collected Steps per Second: 9697.19441
Overall Steps per Second: 6957.38403

Timestep Collection Time: 5.15953
Timestep Consumption Time: 2.03182
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 7.19135

Cumulative Model Updates: 27540
Cumulative Timesteps: 230020036

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.03164
Policy Entropy: 1.30124
Value Function Loss: 0.01909

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.13246
Value Function Update Magnitude: 0.18112

Collected Steps per Second: 10512.33538
Overall Steps per Second: 7309.72278

Timestep Collection Time: 4.75850
Timestep Consumption Time: 2.08485
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.84335

Cumulative Model Updates: 27546
Cumulative Timesteps: 230070059

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.50575
Policy Entropy: 1.30405
Value Function Loss: 0.01812

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.12800
Value Function Update Magnitude: 0.17397

Collected Steps per Second: 9866.97774
Overall Steps per Second: 6943.28743

Timestep Collection Time: 5.07035
Timestep Consumption Time: 2.13503
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 7.20538

Cumulative Model Updates: 27552
Cumulative Timesteps: 230120088

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.73279
Policy Entropy: 1.30370
Value Function Loss: 0.01795

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06362
Policy Update Magnitude: 0.12446
Value Function Update Magnitude: 0.16788

Collected Steps per Second: 9748.14410
Overall Steps per Second: 6999.42019

Timestep Collection Time: 5.13226
Timestep Consumption Time: 2.01548
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.14773

Cumulative Model Updates: 27558
Cumulative Timesteps: 230170118

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -9.58455
Policy Entropy: 1.30419
Value Function Loss: 0.01844

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.13000
Value Function Update Magnitude: 0.17451

Collected Steps per Second: 10368.17692
Overall Steps per Second: 7244.37609

Timestep Collection Time: 4.82515
Timestep Consumption Time: 2.08062
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.90577

Cumulative Model Updates: 27564
Cumulative Timesteps: 230220146

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.06912
Policy Entropy: 1.30378
Value Function Loss: 0.01860

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.12765
Value Function Update Magnitude: 0.18198

Collected Steps per Second: 9916.85115
Overall Steps per Second: 7096.34938

Timestep Collection Time: 5.04596
Timestep Consumption Time: 2.00556
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.05151

Cumulative Model Updates: 27570
Cumulative Timesteps: 230270186

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 230270186...
Checkpoint 230270186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.51089
Policy Entropy: 1.30332
Value Function Loss: 0.01816

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.12597
Value Function Update Magnitude: 0.18182

Collected Steps per Second: 9919.19000
Overall Steps per Second: 7097.14197

Timestep Collection Time: 5.04144
Timestep Consumption Time: 2.00464
PPO Batch Consumption Time: 0.02461
Total Iteration Time: 7.04608

Cumulative Model Updates: 27576
Cumulative Timesteps: 230320193

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.72444
Policy Entropy: 1.29889
Value Function Loss: 0.01773

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.12731
Value Function Update Magnitude: 0.18210

Collected Steps per Second: 10415.30564
Overall Steps per Second: 7286.00011

Timestep Collection Time: 4.80341
Timestep Consumption Time: 2.06304
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.86646

Cumulative Model Updates: 27582
Cumulative Timesteps: 230370222

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.58035
Policy Entropy: 1.29734
Value Function Loss: 0.01693

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.12311
Value Function Update Magnitude: 0.17843

Collected Steps per Second: 9796.36497
Overall Steps per Second: 7055.01352

Timestep Collection Time: 5.10669
Timestep Consumption Time: 1.98430
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 7.09099

Cumulative Model Updates: 27588
Cumulative Timesteps: 230420249

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.41246
Policy Entropy: 1.30583
Value Function Loss: 0.01635

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.11920
Value Function Update Magnitude: 0.17876

Collected Steps per Second: 9759.35962
Overall Steps per Second: 6988.39008

Timestep Collection Time: 5.12503
Timestep Consumption Time: 2.03213
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 7.15716

Cumulative Model Updates: 27594
Cumulative Timesteps: 230470266

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.83277
Policy Entropy: 1.31021
Value Function Loss: 0.01662

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06300
Policy Update Magnitude: 0.12047
Value Function Update Magnitude: 0.19199

Collected Steps per Second: 10399.87237
Overall Steps per Second: 7223.06952

Timestep Collection Time: 4.81150
Timestep Consumption Time: 2.11616
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.92766

Cumulative Model Updates: 27600
Cumulative Timesteps: 230520305

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.58550
Policy Entropy: 1.30520
Value Function Loss: 0.01720

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.12153
Value Function Update Magnitude: 0.20044

Collected Steps per Second: 9797.99912
Overall Steps per Second: 7047.14441

Timestep Collection Time: 5.10523
Timestep Consumption Time: 1.99283
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.09805

Cumulative Model Updates: 27606
Cumulative Timesteps: 230570326

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.76907
Policy Entropy: 1.30228
Value Function Loss: 0.01702

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.12120
Value Function Update Magnitude: 0.19802

Collected Steps per Second: 9777.33134
Overall Steps per Second: 7026.57310

Timestep Collection Time: 5.11643
Timestep Consumption Time: 2.00298
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.11940

Cumulative Model Updates: 27612
Cumulative Timesteps: 230620351

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.94901
Policy Entropy: 1.30183
Value Function Loss: 0.01713

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.11996
Value Function Update Magnitude: 0.19647

Collected Steps per Second: 10374.08651
Overall Steps per Second: 7209.98152

Timestep Collection Time: 4.82336
Timestep Consumption Time: 2.11674
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.94010

Cumulative Model Updates: 27618
Cumulative Timesteps: 230670389

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.54658
Policy Entropy: 1.30321
Value Function Loss: 0.01815

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.12247
Value Function Update Magnitude: 0.19745

Collected Steps per Second: 9811.55160
Overall Steps per Second: 6947.25502

Timestep Collection Time: 5.09879
Timestep Consumption Time: 2.10219
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 7.20097

Cumulative Model Updates: 27624
Cumulative Timesteps: 230720416

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.74023
Policy Entropy: 1.30122
Value Function Loss: 0.01741

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.12329
Value Function Update Magnitude: 0.20360

Collected Steps per Second: 9845.65085
Overall Steps per Second: 7021.63706

Timestep Collection Time: 5.08194
Timestep Consumption Time: 2.04389
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 7.12583

Cumulative Model Updates: 27630
Cumulative Timesteps: 230770451

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 230770451...
Checkpoint 230770451 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.30231
Policy Entropy: 1.30017
Value Function Loss: 0.01711

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.12436
Value Function Update Magnitude: 0.19554

Collected Steps per Second: 10305.98849
Overall Steps per Second: 7189.80542

Timestep Collection Time: 4.85281
Timestep Consumption Time: 2.10329
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 6.95610

Cumulative Model Updates: 27636
Cumulative Timesteps: 230820464

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.45924
Policy Entropy: 1.30184
Value Function Loss: 0.01645

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.12337
Value Function Update Magnitude: 0.18554

Collected Steps per Second: 10158.22543
Overall Steps per Second: 7216.82584

Timestep Collection Time: 4.92448
Timestep Consumption Time: 2.00710
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.93158

Cumulative Model Updates: 27642
Cumulative Timesteps: 230870488

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.84844
Policy Entropy: 1.30186
Value Function Loss: 0.01710

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.05933
Policy Update Magnitude: 0.12511
Value Function Update Magnitude: 0.17906

Collected Steps per Second: 9687.05429
Overall Steps per Second: 6924.63248

Timestep Collection Time: 5.16287
Timestep Consumption Time: 2.05961
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.22248

Cumulative Model Updates: 27648
Cumulative Timesteps: 230920501

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.34162
Policy Entropy: 1.29690
Value Function Loss: 0.01717

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.12570
Value Function Update Magnitude: 0.17830

Collected Steps per Second: 10630.70918
Overall Steps per Second: 7320.39411

Timestep Collection Time: 4.70354
Timestep Consumption Time: 2.12696
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.83051

Cumulative Model Updates: 27654
Cumulative Timesteps: 230970503

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.64164
Policy Entropy: 1.29830
Value Function Loss: 0.01783

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.12478
Value Function Update Magnitude: 0.18709

Collected Steps per Second: 9738.15245
Overall Steps per Second: 6894.10377

Timestep Collection Time: 5.13876
Timestep Consumption Time: 2.11991
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.25867

Cumulative Model Updates: 27660
Cumulative Timesteps: 231020545

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.23089
Policy Entropy: 1.30007
Value Function Loss: 0.01741

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07014
Policy Update Magnitude: 0.12506
Value Function Update Magnitude: 0.19343

Collected Steps per Second: 9784.76424
Overall Steps per Second: 6973.75435

Timestep Collection Time: 5.11213
Timestep Consumption Time: 2.06062
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.17275

Cumulative Model Updates: 27666
Cumulative Timesteps: 231070566

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.38215
Policy Entropy: 1.30235
Value Function Loss: 0.01747

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06207
Policy Update Magnitude: 0.12587
Value Function Update Magnitude: 0.18254

Collected Steps per Second: 10525.73975
Overall Steps per Second: 7306.12163

Timestep Collection Time: 4.75340
Timestep Consumption Time: 2.09470
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 6.84809

Cumulative Model Updates: 27672
Cumulative Timesteps: 231120599

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.06830
Policy Entropy: 1.29806
Value Function Loss: 0.01754

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06406
Policy Update Magnitude: 0.12521
Value Function Update Magnitude: 0.17350

Collected Steps per Second: 9967.86423
Overall Steps per Second: 7040.91725

Timestep Collection Time: 5.01893
Timestep Consumption Time: 2.08640
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 7.10532

Cumulative Model Updates: 27678
Cumulative Timesteps: 231170627

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.96785
Policy Entropy: 1.29727
Value Function Loss: 0.01776

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06232
Policy Update Magnitude: 0.12563
Value Function Update Magnitude: 0.17939

Collected Steps per Second: 10633.07520
Overall Steps per Second: 7371.07492

Timestep Collection Time: 4.70475
Timestep Consumption Time: 2.08204
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 6.78680

Cumulative Model Updates: 27684
Cumulative Timesteps: 231220653

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.42127
Policy Entropy: 1.29608
Value Function Loss: 0.01838

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06342
Policy Update Magnitude: 0.12733
Value Function Update Magnitude: 0.18881

Collected Steps per Second: 9887.10687
Overall Steps per Second: 7010.48161

Timestep Collection Time: 5.05911
Timestep Consumption Time: 2.07592
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.13503

Cumulative Model Updates: 27690
Cumulative Timesteps: 231270673

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 231270673...
Checkpoint 231270673 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.93780
Policy Entropy: 1.29947
Value Function Loss: 0.01801

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06359
Policy Update Magnitude: 0.12934
Value Function Update Magnitude: 0.18715

Collected Steps per Second: 9803.72103
Overall Steps per Second: 7025.50645

Timestep Collection Time: 5.10480
Timestep Consumption Time: 2.01868
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.12347

Cumulative Model Updates: 27696
Cumulative Timesteps: 231320719

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.36429
Policy Entropy: 1.29654
Value Function Loss: 0.01855

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.06897
Policy Update Magnitude: 0.13089
Value Function Update Magnitude: 0.19423

Collected Steps per Second: 10435.95834
Overall Steps per Second: 7259.10649

Timestep Collection Time: 4.79506
Timestep Consumption Time: 2.09849
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 6.89355

Cumulative Model Updates: 27702
Cumulative Timesteps: 231370760

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.56902
Policy Entropy: 1.29869
Value Function Loss: 0.01783

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.12950
Value Function Update Magnitude: 0.19126

Collected Steps per Second: 9881.00959
Overall Steps per Second: 6985.68555

Timestep Collection Time: 5.06092
Timestep Consumption Time: 2.09758
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.15850

Cumulative Model Updates: 27708
Cumulative Timesteps: 231420767

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.47875
Policy Entropy: 1.29725
Value Function Loss: 0.01787

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.12465
Value Function Update Magnitude: 0.19091

Collected Steps per Second: 9701.25218
Overall Steps per Second: 6974.77499

Timestep Collection Time: 5.15562
Timestep Consumption Time: 2.01536
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 7.17098

Cumulative Model Updates: 27714
Cumulative Timesteps: 231470783

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.21664
Policy Entropy: 1.29939
Value Function Loss: 0.01833

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06578
Policy Update Magnitude: 0.12648
Value Function Update Magnitude: 0.19332

Collected Steps per Second: 10357.18899
Overall Steps per Second: 7252.07032

Timestep Collection Time: 4.83104
Timestep Consumption Time: 2.06851
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 6.89955

Cumulative Model Updates: 27720
Cumulative Timesteps: 231520819

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.26638
Policy Entropy: 1.29922
Value Function Loss: 0.01894

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06101
Policy Update Magnitude: 0.12884
Value Function Update Magnitude: 0.19991

Collected Steps per Second: 9783.22424
Overall Steps per Second: 7029.57088

Timestep Collection Time: 5.11191
Timestep Consumption Time: 2.00246
PPO Batch Consumption Time: 0.02499
Total Iteration Time: 7.11437

Cumulative Model Updates: 27726
Cumulative Timesteps: 231570830

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.89203
Policy Entropy: 1.29788
Value Function Loss: 0.01790

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.12795
Value Function Update Magnitude: 0.19966

Collected Steps per Second: 10140.03704
Overall Steps per Second: 7202.02269

Timestep Collection Time: 4.93124
Timestep Consumption Time: 2.01167
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 6.94291

Cumulative Model Updates: 27732
Cumulative Timesteps: 231620833

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.07932
Policy Entropy: 1.29721
Value Function Loss: 0.01698

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.12420
Value Function Update Magnitude: 0.19706

Collected Steps per Second: 10446.81876
Overall Steps per Second: 7286.97881

Timestep Collection Time: 4.78758
Timestep Consumption Time: 2.07603
PPO Batch Consumption Time: 0.02430
Total Iteration Time: 6.86361

Cumulative Model Updates: 27738
Cumulative Timesteps: 231670848

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.45076
Policy Entropy: 1.29870
Value Function Loss: 0.01649

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.12560
Value Function Update Magnitude: 0.20059

Collected Steps per Second: 9835.76011
Overall Steps per Second: 6977.42742

Timestep Collection Time: 5.08674
Timestep Consumption Time: 2.08381
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.17055

Cumulative Model Updates: 27744
Cumulative Timesteps: 231720880

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.68800
Policy Entropy: 1.30207
Value Function Loss: 0.01686

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.12559
Value Function Update Magnitude: 0.19247

Collected Steps per Second: 9713.90570
Overall Steps per Second: 6888.47185

Timestep Collection Time: 5.14747
Timestep Consumption Time: 2.11133
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.25879

Cumulative Model Updates: 27750
Cumulative Timesteps: 231770882

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 231770882...
Checkpoint 231770882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.03903
Policy Entropy: 1.30934
Value Function Loss: 0.01794

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.12446
Value Function Update Magnitude: 0.18757

Collected Steps per Second: 10286.46694
Overall Steps per Second: 7204.76545

Timestep Collection Time: 4.86163
Timestep Consumption Time: 2.07947
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 6.94110

Cumulative Model Updates: 27756
Cumulative Timesteps: 231820891

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.75464
Policy Entropy: 1.30705
Value Function Loss: 0.01768

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.12408
Value Function Update Magnitude: 0.19192

Collected Steps per Second: 9821.05610
Overall Steps per Second: 6960.59298

Timestep Collection Time: 5.09497
Timestep Consumption Time: 2.09378
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.18876

Cumulative Model Updates: 27762
Cumulative Timesteps: 231870929

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.93810
Policy Entropy: 1.30935
Value Function Loss: 0.01787

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.06894
Policy Update Magnitude: 0.12447
Value Function Update Magnitude: 0.19326

Collected Steps per Second: 9775.77709
Overall Steps per Second: 7008.87283

Timestep Collection Time: 5.11826
Timestep Consumption Time: 2.02055
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.13881

Cumulative Model Updates: 27768
Cumulative Timesteps: 231920964

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.60747
Policy Entropy: 1.30814
Value Function Loss: 0.01677

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.12266
Value Function Update Magnitude: 0.18692

Collected Steps per Second: 10386.72267
Overall Steps per Second: 7294.26090

Timestep Collection Time: 4.81519
Timestep Consumption Time: 2.04144
PPO Batch Consumption Time: 0.02362
Total Iteration Time: 6.85662

Cumulative Model Updates: 27774
Cumulative Timesteps: 231970978

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.59487
Policy Entropy: 1.30822
Value Function Loss: 0.01709

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06394
Policy Update Magnitude: 0.12184
Value Function Update Magnitude: 0.18886

Collected Steps per Second: 9918.75813
Overall Steps per Second: 6988.27113

Timestep Collection Time: 5.04368
Timestep Consumption Time: 2.11503
PPO Batch Consumption Time: 0.02452
Total Iteration Time: 7.15871

Cumulative Model Updates: 27780
Cumulative Timesteps: 232021005

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.90558
Policy Entropy: 1.30815
Value Function Loss: 0.01731

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06069
Policy Update Magnitude: 0.12299
Value Function Update Magnitude: 0.18860

Collected Steps per Second: 9982.51396
Overall Steps per Second: 7099.43779

Timestep Collection Time: 5.01096
Timestep Consumption Time: 2.03495
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 7.04591

Cumulative Model Updates: 27786
Cumulative Timesteps: 232071027

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.73696
Policy Entropy: 1.30452
Value Function Loss: 0.01729

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.05866
Policy Update Magnitude: 0.12265
Value Function Update Magnitude: 0.18794

Collected Steps per Second: 10400.78946
Overall Steps per Second: 7265.66419

Timestep Collection Time: 4.80887
Timestep Consumption Time: 2.07502
PPO Batch Consumption Time: 0.02468
Total Iteration Time: 6.88389

Cumulative Model Updates: 27792
Cumulative Timesteps: 232121043

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.03221
Policy Entropy: 1.30875
Value Function Loss: 0.01701

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.05750
Policy Update Magnitude: 0.12344
Value Function Update Magnitude: 0.18835

Collected Steps per Second: 9805.94798
Overall Steps per Second: 7042.27270

Timestep Collection Time: 5.10272
Timestep Consumption Time: 2.00252
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.10523

Cumulative Model Updates: 27798
Cumulative Timesteps: 232171080

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.62628
Policy Entropy: 1.30512
Value Function Loss: 0.01688

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.12159
Value Function Update Magnitude: 0.18570

Collected Steps per Second: 9817.55867
Overall Steps per Second: 6991.38838

Timestep Collection Time: 5.09505
Timestep Consumption Time: 2.05960
PPO Batch Consumption Time: 0.02437
Total Iteration Time: 7.15466

Cumulative Model Updates: 27804
Cumulative Timesteps: 232221101

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.12846
Policy Entropy: 1.31142
Value Function Loss: 0.01774

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.11866
Value Function Update Magnitude: 0.19007

Collected Steps per Second: 10273.52445
Overall Steps per Second: 7192.85625

Timestep Collection Time: 4.86698
Timestep Consumption Time: 2.08450
PPO Batch Consumption Time: 0.02468
Total Iteration Time: 6.95148

Cumulative Model Updates: 27810
Cumulative Timesteps: 232271102

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 232271102...
Checkpoint 232271102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.39219
Policy Entropy: 1.31047
Value Function Loss: 0.01837

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.11963
Value Function Update Magnitude: 0.20104

Collected Steps per Second: 9740.04174
Overall Steps per Second: 6951.56099

Timestep Collection Time: 5.13817
Timestep Consumption Time: 2.06108
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 7.19925

Cumulative Model Updates: 27816
Cumulative Timesteps: 232321148

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.10600
Policy Entropy: 1.31050
Value Function Loss: 0.01865

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06665
Policy Update Magnitude: 0.12413
Value Function Update Magnitude: 0.20951

Collected Steps per Second: 9644.91819
Overall Steps per Second: 6965.63530

Timestep Collection Time: 5.18625
Timestep Consumption Time: 1.99486
PPO Batch Consumption Time: 0.02449
Total Iteration Time: 7.18111

Cumulative Model Updates: 27822
Cumulative Timesteps: 232371169

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.65874
Policy Entropy: 1.30382
Value Function Loss: 0.01855

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05848
Policy Update Magnitude: 0.12321
Value Function Update Magnitude: 0.19901

Collected Steps per Second: 10278.93011
Overall Steps per Second: 7212.82739

Timestep Collection Time: 4.86539
Timestep Consumption Time: 2.06823
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.93362

Cumulative Model Updates: 27828
Cumulative Timesteps: 232421180

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.59006
Policy Entropy: 1.29747
Value Function Loss: 0.01787

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.12585
Value Function Update Magnitude: 0.19948

Collected Steps per Second: 10169.29713
Overall Steps per Second: 7128.81313

Timestep Collection Time: 4.91804
Timestep Consumption Time: 2.09757
PPO Batch Consumption Time: 0.02372
Total Iteration Time: 7.01561

Cumulative Model Updates: 27834
Cumulative Timesteps: 232471193

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.90976
Policy Entropy: 1.29501
Value Function Loss: 0.01729

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.12503
Value Function Update Magnitude: 0.18683

Collected Steps per Second: 9751.04691
Overall Steps per Second: 6991.51196

Timestep Collection Time: 5.12786
Timestep Consumption Time: 2.02396
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.15181

Cumulative Model Updates: 27840
Cumulative Timesteps: 232521195

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.85161
Policy Entropy: 1.29584
Value Function Loss: 0.01665

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06128
Policy Update Magnitude: 0.12163
Value Function Update Magnitude: 0.17955

Collected Steps per Second: 10237.59612
Overall Steps per Second: 7190.59652

Timestep Collection Time: 4.88621
Timestep Consumption Time: 2.07052
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 6.95672

Cumulative Model Updates: 27846
Cumulative Timesteps: 232571218

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.95384
Policy Entropy: 1.29832
Value Function Loss: 0.01714

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.05913
Policy Update Magnitude: 0.11989
Value Function Update Magnitude: 0.17998

Collected Steps per Second: 9779.18997
Overall Steps per Second: 7022.12830

Timestep Collection Time: 5.11290
Timestep Consumption Time: 2.00745
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.12035

Cumulative Model Updates: 27852
Cumulative Timesteps: 232621218

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.48715
Policy Entropy: 1.30138
Value Function Loss: 0.01705

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.04929
Policy Update Magnitude: 0.12150
Value Function Update Magnitude: 0.18285

Collected Steps per Second: 9660.38501
Overall Steps per Second: 6949.30188

Timestep Collection Time: 5.17847
Timestep Consumption Time: 2.02024
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.19871

Cumulative Model Updates: 27858
Cumulative Timesteps: 232671244

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.30095
Policy Entropy: 1.30012
Value Function Loss: 0.01720

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.05679
Policy Update Magnitude: 0.12185
Value Function Update Magnitude: 0.18469

Collected Steps per Second: 10382.33646
Overall Steps per Second: 7261.24278

Timestep Collection Time: 4.81655
Timestep Consumption Time: 2.07029
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 6.88684

Cumulative Model Updates: 27864
Cumulative Timesteps: 232721251

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.72786
Policy Entropy: 1.30396
Value Function Loss: 0.01667

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.19251

Collected Steps per Second: 9772.81714
Overall Steps per Second: 6932.81666

Timestep Collection Time: 5.11644
Timestep Consumption Time: 2.09593
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.21236

Cumulative Model Updates: 27870
Cumulative Timesteps: 232771253

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 232771253...
Checkpoint 232771253 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.34718
Policy Entropy: 1.30437
Value Function Loss: 0.01668

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.05869
Policy Update Magnitude: 0.12033
Value Function Update Magnitude: 0.19948

Collected Steps per Second: 9688.18521
Overall Steps per Second: 6914.28357

Timestep Collection Time: 5.16247
Timestep Consumption Time: 2.07110
PPO Batch Consumption Time: 0.02375
Total Iteration Time: 7.23358

Cumulative Model Updates: 27876
Cumulative Timesteps: 232821268

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.35618
Policy Entropy: 1.30442
Value Function Loss: 0.01607

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.05546
Policy Update Magnitude: 0.11956
Value Function Update Magnitude: 0.19437

Collected Steps per Second: 10405.35164
Overall Steps per Second: 7233.09811

Timestep Collection Time: 4.80589
Timestep Consumption Time: 2.10774
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 6.91363

Cumulative Model Updates: 27882
Cumulative Timesteps: 232871275

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.06565
Policy Entropy: 1.30310
Value Function Loss: 0.01606

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.11964
Value Function Update Magnitude: 0.18618

Collected Steps per Second: 9901.01081
Overall Steps per Second: 7008.30534

Timestep Collection Time: 5.05393
Timestep Consumption Time: 2.08603
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.13996

Cumulative Model Updates: 27888
Cumulative Timesteps: 232921314

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.72641
Policy Entropy: 1.30095
Value Function Loss: 0.01580

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05538
Policy Update Magnitude: 0.12111
Value Function Update Magnitude: 0.18876

Collected Steps per Second: 10264.89808
Overall Steps per Second: 7257.39028

Timestep Collection Time: 4.87526
Timestep Consumption Time: 2.02034
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.89559

Cumulative Model Updates: 27894
Cumulative Timesteps: 232971358

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.86625
Policy Entropy: 1.30001
Value Function Loss: 0.01636

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.12404
Value Function Update Magnitude: 0.18932

Collected Steps per Second: 10247.75682
Overall Steps per Second: 6870.66432

Timestep Collection Time: 4.88263
Timestep Consumption Time: 2.39993
PPO Batch Consumption Time: 0.02452
Total Iteration Time: 7.28256

Cumulative Model Updates: 27900
Cumulative Timesteps: 233021394

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.36783
Policy Entropy: 1.29717
Value Function Loss: 0.01641

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.12257
Value Function Update Magnitude: 0.18260

Collected Steps per Second: 10242.65697
Overall Steps per Second: 7177.03450

Timestep Collection Time: 4.88604
Timestep Consumption Time: 2.08704
PPO Batch Consumption Time: 0.02433
Total Iteration Time: 6.97308

Cumulative Model Updates: 27906
Cumulative Timesteps: 233071440

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.54140
Policy Entropy: 1.29527
Value Function Loss: 0.01649

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.12217
Value Function Update Magnitude: 0.18108

Collected Steps per Second: 9706.21286
Overall Steps per Second: 6954.39482

Timestep Collection Time: 5.15587
Timestep Consumption Time: 2.04015
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.19603

Cumulative Model Updates: 27912
Cumulative Timesteps: 233121484

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.86035
Policy Entropy: 1.29604
Value Function Loss: 0.01703

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.12144
Value Function Update Magnitude: 0.17824

Collected Steps per Second: 10446.07160
Overall Steps per Second: 7053.02857

Timestep Collection Time: 4.78850
Timestep Consumption Time: 2.30363
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.09213

Cumulative Model Updates: 27918
Cumulative Timesteps: 233171505

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.98328
Policy Entropy: 1.29171
Value Function Loss: 0.01747

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.12228
Value Function Update Magnitude: 0.17630

Collected Steps per Second: 10483.83171
Overall Steps per Second: 7262.11913

Timestep Collection Time: 4.77106
Timestep Consumption Time: 2.11660
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.88766

Cumulative Model Updates: 27924
Cumulative Timesteps: 233221524

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.69807
Policy Entropy: 1.29613
Value Function Loss: 0.01820

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.12428
Value Function Update Magnitude: 0.18410

Collected Steps per Second: 9793.21748
Overall Steps per Second: 6985.74540

Timestep Collection Time: 5.10874
Timestep Consumption Time: 2.05313
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.16187

Cumulative Model Updates: 27930
Cumulative Timesteps: 233271555

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 233271555...
Checkpoint 233271555 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.56942
Policy Entropy: 1.29453
Value Function Loss: 0.01791

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.12843
Value Function Update Magnitude: 0.18897

Collected Steps per Second: 9923.82587
Overall Steps per Second: 7064.92357

Timestep Collection Time: 5.04150
Timestep Consumption Time: 2.04010
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.08161

Cumulative Model Updates: 27936
Cumulative Timesteps: 233321586

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.12969
Policy Entropy: 1.29657
Value Function Loss: 0.01763

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.12590
Value Function Update Magnitude: 0.20053

Collected Steps per Second: 10377.78157
Overall Steps per Second: 7230.19622

Timestep Collection Time: 4.82088
Timestep Consumption Time: 2.09871
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.91959

Cumulative Model Updates: 27942
Cumulative Timesteps: 233371616

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.49274
Policy Entropy: 1.29797
Value Function Loss: 0.01781

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.12436
Value Function Update Magnitude: 0.20039

Collected Steps per Second: 9732.12237
Overall Steps per Second: 6948.52834

Timestep Collection Time: 5.13804
Timestep Consumption Time: 2.05831
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 7.19634

Cumulative Model Updates: 27948
Cumulative Timesteps: 233421620

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.30862
Policy Entropy: 1.30037
Value Function Loss: 0.01800

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05768
Policy Update Magnitude: 0.12318
Value Function Update Magnitude: 0.19282

Collected Steps per Second: 9511.44331
Overall Steps per Second: 6828.60260

Timestep Collection Time: 5.25735
Timestep Consumption Time: 2.06552
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 7.32287

Cumulative Model Updates: 27954
Cumulative Timesteps: 233471625

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.87937
Policy Entropy: 1.30267
Value Function Loss: 0.01903

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.05742
Policy Update Magnitude: 0.12426
Value Function Update Magnitude: 0.19130

Collected Steps per Second: 10127.28369
Overall Steps per Second: 7092.93851

Timestep Collection Time: 4.94101
Timestep Consumption Time: 2.11375
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.05476

Cumulative Model Updates: 27960
Cumulative Timesteps: 233521664

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.27042
Policy Entropy: 1.30605
Value Function Loss: 0.01954

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.12727
Value Function Update Magnitude: 0.19854

Collected Steps per Second: 10021.35608
Overall Steps per Second: 6987.59282

Timestep Collection Time: 4.99124
Timestep Consumption Time: 2.16702
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.15826

Cumulative Model Updates: 27966
Cumulative Timesteps: 233571683

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.51845
Policy Entropy: 1.30667
Value Function Loss: 0.01848

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06083
Policy Update Magnitude: 0.12617
Value Function Update Magnitude: 0.19811

Collected Steps per Second: 10756.99380
Overall Steps per Second: 7651.53334

Timestep Collection Time: 4.65083
Timestep Consumption Time: 1.88759
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 6.53843

Cumulative Model Updates: 27972
Cumulative Timesteps: 233621712

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.01542
Policy Entropy: 1.30850
Value Function Loss: 0.01805

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06212
Policy Update Magnitude: 0.12376
Value Function Update Magnitude: 0.19263

Collected Steps per Second: 10500.04518
Overall Steps per Second: 7276.63191

Timestep Collection Time: 4.76550
Timestep Consumption Time: 2.11103
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 6.87653

Cumulative Model Updates: 27978
Cumulative Timesteps: 233671750

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.99881
Policy Entropy: 1.30513
Value Function Loss: 0.01802

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.12367
Value Function Update Magnitude: 0.18783

Collected Steps per Second: 9884.77182
Overall Steps per Second: 7001.02388

Timestep Collection Time: 5.05910
Timestep Consumption Time: 2.08386
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.14296

Cumulative Model Updates: 27984
Cumulative Timesteps: 233721758

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.51460
Policy Entropy: 1.30631
Value Function Loss: 0.01838

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.12403
Value Function Update Magnitude: 0.19379

Collected Steps per Second: 9806.52323
Overall Steps per Second: 6980.00854

Timestep Collection Time: 5.09916
Timestep Consumption Time: 2.06487
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.16403

Cumulative Model Updates: 27990
Cumulative Timesteps: 233771763

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 233771763...
Checkpoint 233771763 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.42964
Policy Entropy: 1.30253
Value Function Loss: 0.01760

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.06748
Policy Update Magnitude: 0.12338
Value Function Update Magnitude: 0.19363

Collected Steps per Second: 10364.04417
Overall Steps per Second: 7205.84294

Timestep Collection Time: 4.82514
Timestep Consumption Time: 2.11478
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 6.93992

Cumulative Model Updates: 27996
Cumulative Timesteps: 233821771

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.07260
Policy Entropy: 1.30281
Value Function Loss: 0.01750

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.12269
Value Function Update Magnitude: 0.18851

Collected Steps per Second: 9814.99213
Overall Steps per Second: 6968.22941

Timestep Collection Time: 5.09649
Timestep Consumption Time: 2.08209
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.17858

Cumulative Model Updates: 28002
Cumulative Timesteps: 233871793

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.15946
Policy Entropy: 1.30437
Value Function Loss: 0.01843

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06391
Policy Update Magnitude: 0.12683
Value Function Update Magnitude: 0.18814

Collected Steps per Second: 9658.11583
Overall Steps per Second: 6917.90515

Timestep Collection Time: 5.18082
Timestep Consumption Time: 2.05215
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.23297

Cumulative Model Updates: 28008
Cumulative Timesteps: 233921830

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.95639
Policy Entropy: 1.30198
Value Function Loss: 0.01852

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.12661
Value Function Update Magnitude: 0.18462

Collected Steps per Second: 10445.31058
Overall Steps per Second: 7257.65516

Timestep Collection Time: 4.78846
Timestep Consumption Time: 2.10316
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 6.89162

Cumulative Model Updates: 28014
Cumulative Timesteps: 233971847

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.69981
Policy Entropy: 1.29644
Value Function Loss: 0.01788

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.12507
Value Function Update Magnitude: 0.18219

Collected Steps per Second: 9943.93789
Overall Steps per Second: 7019.92284

Timestep Collection Time: 5.03090
Timestep Consumption Time: 2.09553
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 7.12643

Cumulative Model Updates: 28020
Cumulative Timesteps: 234021874

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.37878
Policy Entropy: 1.29598
Value Function Loss: 0.01727

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.12136
Value Function Update Magnitude: 0.18434

Collected Steps per Second: 9870.76277
Overall Steps per Second: 6997.57244

Timestep Collection Time: 5.06810
Timestep Consumption Time: 2.08095
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 7.14905

Cumulative Model Updates: 28026
Cumulative Timesteps: 234071900

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.65221
Policy Entropy: 1.29796
Value Function Loss: 0.01755

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06837
Policy Update Magnitude: 0.12401
Value Function Update Magnitude: 0.18664

Collected Steps per Second: 10398.96257
Overall Steps per Second: 7014.90106

Timestep Collection Time: 4.81106
Timestep Consumption Time: 2.32090
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.13196

Cumulative Model Updates: 28032
Cumulative Timesteps: 234121930

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.80992
Policy Entropy: 1.30310
Value Function Loss: 0.01806

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.05722
Policy Update Magnitude: 0.12286
Value Function Update Magnitude: 0.19357

Collected Steps per Second: 10535.16963
Overall Steps per Second: 7303.10233

Timestep Collection Time: 4.74620
Timestep Consumption Time: 2.10048
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.84668

Cumulative Model Updates: 28038
Cumulative Timesteps: 234171932

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.27461
Policy Entropy: 1.30081
Value Function Loss: 0.01873

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.12785
Value Function Update Magnitude: 0.20554

Collected Steps per Second: 9807.67908
Overall Steps per Second: 7024.17359

Timestep Collection Time: 5.10049
Timestep Consumption Time: 2.02120
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.12169

Cumulative Model Updates: 28044
Cumulative Timesteps: 234221956

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.48092
Policy Entropy: 1.30036
Value Function Loss: 0.01909

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06145
Policy Update Magnitude: 0.12642
Value Function Update Magnitude: 0.21612

Collected Steps per Second: 9721.03828
Overall Steps per Second: 6966.76676

Timestep Collection Time: 5.14523
Timestep Consumption Time: 2.03414
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 7.17937

Cumulative Model Updates: 28050
Cumulative Timesteps: 234271973

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 234271973...
Checkpoint 234271973 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.07156
Policy Entropy: 1.30047
Value Function Loss: 0.01905

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07151
Policy Update Magnitude: 0.12691
Value Function Update Magnitude: 0.21742

Collected Steps per Second: 10405.99039
Overall Steps per Second: 7246.33631

Timestep Collection Time: 4.80713
Timestep Consumption Time: 2.09608
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 6.90321

Cumulative Model Updates: 28056
Cumulative Timesteps: 234321996

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.67445
Policy Entropy: 1.30087
Value Function Loss: 0.01875

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.12750
Value Function Update Magnitude: 0.21274

Collected Steps per Second: 9890.59599
Overall Steps per Second: 7072.60008

Timestep Collection Time: 5.05804
Timestep Consumption Time: 2.01532
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 7.07335

Cumulative Model Updates: 28062
Cumulative Timesteps: 234372023

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.75621
Policy Entropy: 1.30166
Value Function Loss: 0.01856

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.12792
Value Function Update Magnitude: 0.20957

Collected Steps per Second: 9847.07540
Overall Steps per Second: 6991.44363

Timestep Collection Time: 5.08080
Timestep Consumption Time: 2.07523
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.15603

Cumulative Model Updates: 28068
Cumulative Timesteps: 234422054

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.07915
Policy Entropy: 1.29913
Value Function Loss: 0.01798

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.19732

Collected Steps per Second: 10415.80167
Overall Steps per Second: 7257.24473

Timestep Collection Time: 4.80193
Timestep Consumption Time: 2.08994
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.89187

Cumulative Model Updates: 28074
Cumulative Timesteps: 234472070

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.88559
Policy Entropy: 1.30057
Value Function Loss: 0.01738

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.12558
Value Function Update Magnitude: 0.18859

Collected Steps per Second: 10058.45866
Overall Steps per Second: 7041.49225

Timestep Collection Time: 4.97372
Timestep Consumption Time: 2.13102
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 7.10474

Cumulative Model Updates: 28080
Cumulative Timesteps: 234522098

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.71146
Policy Entropy: 1.30088
Value Function Loss: 0.01721

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06567
Policy Update Magnitude: 0.12480
Value Function Update Magnitude: 0.17733

Collected Steps per Second: 9942.18578
Overall Steps per Second: 7089.17893

Timestep Collection Time: 5.02928
Timestep Consumption Time: 2.02401
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.05329

Cumulative Model Updates: 28086
Cumulative Timesteps: 234572100

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.96428
Policy Entropy: 1.30051
Value Function Loss: 0.01795

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.12634
Value Function Update Magnitude: 0.18134

Collected Steps per Second: 10492.00295
Overall Steps per Second: 7291.42504

Timestep Collection Time: 4.76982
Timestep Consumption Time: 2.09372
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.86354

Cumulative Model Updates: 28092
Cumulative Timesteps: 234622145

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.44307
Policy Entropy: 1.30147
Value Function Loss: 0.01917

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.12378
Value Function Update Magnitude: 0.19728

Collected Steps per Second: 9880.27629
Overall Steps per Second: 6977.36275

Timestep Collection Time: 5.06190
Timestep Consumption Time: 2.10599
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 7.16789

Cumulative Model Updates: 28098
Cumulative Timesteps: 234672158

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.26773
Policy Entropy: 1.30405
Value Function Loss: 0.01947

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.12200
Value Function Update Magnitude: 0.19741

Collected Steps per Second: 9793.43138
Overall Steps per Second: 6994.51053

Timestep Collection Time: 5.10669
Timestep Consumption Time: 2.04349
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 7.15018

Cumulative Model Updates: 28104
Cumulative Timesteps: 234722170

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.27018
Policy Entropy: 1.29729
Value Function Loss: 0.01890

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.12171
Value Function Update Magnitude: 0.18721

Collected Steps per Second: 10375.58128
Overall Steps per Second: 7230.44740

Timestep Collection Time: 4.81930
Timestep Consumption Time: 2.09632
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 6.91562

Cumulative Model Updates: 28110
Cumulative Timesteps: 234772173

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 234772173...
Checkpoint 234772173 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.04716
Policy Entropy: 1.29200
Value Function Loss: 0.01800

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.12570
Value Function Update Magnitude: 0.18411

Collected Steps per Second: 9975.14922
Overall Steps per Second: 7024.55011

Timestep Collection Time: 5.01386
Timestep Consumption Time: 2.10603
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.11989

Cumulative Model Updates: 28116
Cumulative Timesteps: 234822187

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.87789
Policy Entropy: 1.29961
Value Function Loss: 0.01692

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.12767
Value Function Update Magnitude: 0.17940

Collected Steps per Second: 9725.73260
Overall Steps per Second: 6959.97771

Timestep Collection Time: 5.14357
Timestep Consumption Time: 2.04395
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 7.18752

Cumulative Model Updates: 28122
Cumulative Timesteps: 234872212

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.48023
Policy Entropy: 1.30419
Value Function Loss: 0.01816

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.12379
Value Function Update Magnitude: 0.17973

Collected Steps per Second: 10382.00444
Overall Steps per Second: 7224.25592

Timestep Collection Time: 4.81872
Timestep Consumption Time: 2.10628
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 6.92500

Cumulative Model Updates: 28128
Cumulative Timesteps: 234922240

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.02843
Policy Entropy: 1.30078
Value Function Loss: 0.01849

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.12668
Value Function Update Magnitude: 0.19028

Collected Steps per Second: 9956.15132
Overall Steps per Second: 7028.60693

Timestep Collection Time: 5.02343
Timestep Consumption Time: 2.09235
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.11578

Cumulative Model Updates: 28134
Cumulative Timesteps: 234972254

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.39087
Policy Entropy: 1.29444
Value Function Loss: 0.01899

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.12820
Value Function Update Magnitude: 0.20004

Collected Steps per Second: 9796.48913
Overall Steps per Second: 6995.25527

Timestep Collection Time: 5.10571
Timestep Consumption Time: 2.04457
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.15028

Cumulative Model Updates: 28140
Cumulative Timesteps: 235022272

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.33992
Policy Entropy: 1.29499
Value Function Loss: 0.01882

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.12786
Value Function Update Magnitude: 0.19796

Collected Steps per Second: 10337.22311
Overall Steps per Second: 7213.85819

Timestep Collection Time: 4.83815
Timestep Consumption Time: 2.09476
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 6.93291

Cumulative Model Updates: 28146
Cumulative Timesteps: 235072285

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.80499
Policy Entropy: 1.29577
Value Function Loss: 0.01897

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07030
Policy Update Magnitude: 0.12680
Value Function Update Magnitude: 0.19664

Collected Steps per Second: 9748.02867
Overall Steps per Second: 6998.57413

Timestep Collection Time: 5.13242
Timestep Consumption Time: 2.01632
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.14874

Cumulative Model Updates: 28152
Cumulative Timesteps: 235122316

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.85036
Policy Entropy: 1.29261
Value Function Loss: 0.01944

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.12545
Value Function Update Magnitude: 0.19884

Collected Steps per Second: 9642.90883
Overall Steps per Second: 6916.60878

Timestep Collection Time: 5.18661
Timestep Consumption Time: 2.04439
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.23100

Cumulative Model Updates: 28158
Cumulative Timesteps: 235172330

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.59272
Policy Entropy: 1.29139
Value Function Loss: 0.01938

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.12715
Value Function Update Magnitude: 0.20095

Collected Steps per Second: 10344.14626
Overall Steps per Second: 7220.83871

Timestep Collection Time: 4.83713
Timestep Consumption Time: 2.09226
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.92939

Cumulative Model Updates: 28164
Cumulative Timesteps: 235222366

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.58605
Policy Entropy: 1.29203
Value Function Loss: 0.01910

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.12752
Value Function Update Magnitude: 0.19979

Collected Steps per Second: 9797.18705
Overall Steps per Second: 6951.04699

Timestep Collection Time: 5.10534
Timestep Consumption Time: 2.09041
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.19575

Cumulative Model Updates: 28170
Cumulative Timesteps: 235272384

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 235272384...
Checkpoint 235272384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.79936
Policy Entropy: 1.29671
Value Function Loss: 0.01871

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.06905
Policy Update Magnitude: 0.12776
Value Function Update Magnitude: 0.20292

Collected Steps per Second: 9667.54850
Overall Steps per Second: 6918.55113

Timestep Collection Time: 5.17215
Timestep Consumption Time: 2.05509
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.22724

Cumulative Model Updates: 28176
Cumulative Timesteps: 235322386

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.85366
Policy Entropy: 1.29492
Value Function Loss: 0.01899

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.12541
Value Function Update Magnitude: 0.19925

Collected Steps per Second: 10402.41083
Overall Steps per Second: 7189.58256

Timestep Collection Time: 4.80975
Timestep Consumption Time: 2.14935
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 6.95910

Cumulative Model Updates: 28182
Cumulative Timesteps: 235372419

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.11111
Policy Entropy: 1.29612
Value Function Loss: 0.01861

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.12627
Value Function Update Magnitude: 0.19874

Collected Steps per Second: 9886.08753
Overall Steps per Second: 6961.68530

Timestep Collection Time: 5.05873
Timestep Consumption Time: 2.12502
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.18375

Cumulative Model Updates: 28188
Cumulative Timesteps: 235422430

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.15483
Policy Entropy: 1.29545
Value Function Loss: 0.01856

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.12603
Value Function Update Magnitude: 0.19396

Collected Steps per Second: 9850.87088
Overall Steps per Second: 7032.83108

Timestep Collection Time: 5.07823
Timestep Consumption Time: 2.03484
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.11307

Cumulative Model Updates: 28194
Cumulative Timesteps: 235472455

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.63619
Policy Entropy: 1.29585
Value Function Loss: 0.01783

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07186
Policy Update Magnitude: 0.12469
Value Function Update Magnitude: 0.18990

Collected Steps per Second: 10152.54055
Overall Steps per Second: 7141.96084

Timestep Collection Time: 4.92793
Timestep Consumption Time: 2.07729
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.00522

Cumulative Model Updates: 28200
Cumulative Timesteps: 235522486

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.34187
Policy Entropy: 1.29937
Value Function Loss: 0.01743

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06058
Policy Update Magnitude: 0.12159
Value Function Update Magnitude: 0.19283

Collected Steps per Second: 9724.32653
Overall Steps per Second: 7000.36823

Timestep Collection Time: 5.14195
Timestep Consumption Time: 2.00082
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.14277

Cumulative Model Updates: 28206
Cumulative Timesteps: 235572488

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.15943
Policy Entropy: 1.30300
Value Function Loss: 0.01750

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05519
Policy Update Magnitude: 0.12231
Value Function Update Magnitude: 0.19100

Collected Steps per Second: 9785.71840
Overall Steps per Second: 6991.61776

Timestep Collection Time: 5.11357
Timestep Consumption Time: 2.04357
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 7.15714

Cumulative Model Updates: 28212
Cumulative Timesteps: 235622528

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.71498
Policy Entropy: 1.30132
Value Function Loss: 0.01800

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.05515
Policy Update Magnitude: 0.12545
Value Function Update Magnitude: 0.19378

Collected Steps per Second: 10233.21563
Overall Steps per Second: 7129.65673

Timestep Collection Time: 4.88820
Timestep Consumption Time: 2.12785
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.01605

Cumulative Model Updates: 28218
Cumulative Timesteps: 235672550

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.37619
Policy Entropy: 1.29911
Value Function Loss: 0.01884

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06410
Policy Update Magnitude: 0.12340
Value Function Update Magnitude: 0.19722

Collected Steps per Second: 9988.29113
Overall Steps per Second: 7114.23477

Timestep Collection Time: 5.00826
Timestep Consumption Time: 2.02327
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.03154

Cumulative Model Updates: 28224
Cumulative Timesteps: 235722574

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.40338
Policy Entropy: 1.29648
Value Function Loss: 0.01916

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.12386
Value Function Update Magnitude: 0.20068

Collected Steps per Second: 10106.34479
Overall Steps per Second: 7146.37294

Timestep Collection Time: 4.94788
Timestep Consumption Time: 2.04937
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 6.99726

Cumulative Model Updates: 28230
Cumulative Timesteps: 235772579

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 235772579...
Checkpoint 235772579 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.04277
Policy Entropy: 1.30094
Value Function Loss: 0.01889

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.12552
Value Function Update Magnitude: 0.20930

Collected Steps per Second: 10393.39666
Overall Steps per Second: 7237.12438

Timestep Collection Time: 4.81306
Timestep Consumption Time: 2.09908
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 6.91214

Cumulative Model Updates: 28236
Cumulative Timesteps: 235822603

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.48326
Policy Entropy: 1.30262
Value Function Loss: 0.01879

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.12373
Value Function Update Magnitude: 0.19847

Collected Steps per Second: 9885.39231
Overall Steps per Second: 7061.46991

Timestep Collection Time: 5.06171
Timestep Consumption Time: 2.02421
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.08592

Cumulative Model Updates: 28242
Cumulative Timesteps: 235872640

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.30179
Policy Entropy: 1.30662
Value Function Loss: 0.01841

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.12229
Value Function Update Magnitude: 0.19231

Collected Steps per Second: 9720.16491
Overall Steps per Second: 6966.20429

Timestep Collection Time: 5.14868
Timestep Consumption Time: 2.03544
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.18411

Cumulative Model Updates: 28248
Cumulative Timesteps: 235922686

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.72674
Policy Entropy: 1.30372
Value Function Loss: 0.01750

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06673
Policy Update Magnitude: 0.11981
Value Function Update Magnitude: 0.18970

Collected Steps per Second: 10336.95273
Overall Steps per Second: 7202.78431

Timestep Collection Time: 4.83827
Timestep Consumption Time: 2.10529
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 6.94356

Cumulative Model Updates: 28254
Cumulative Timesteps: 235972699

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.73883
Policy Entropy: 1.30439
Value Function Loss: 0.01715

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.12444
Value Function Update Magnitude: 0.18733

Collected Steps per Second: 9864.15484
Overall Steps per Second: 6970.28795

Timestep Collection Time: 5.07251
Timestep Consumption Time: 2.10596
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 7.17847

Cumulative Model Updates: 28260
Cumulative Timesteps: 236022735

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.56343
Policy Entropy: 1.29986
Value Function Loss: 0.01775

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.12254
Value Function Update Magnitude: 0.18608

Collected Steps per Second: 9930.52219
Overall Steps per Second: 7039.17442

Timestep Collection Time: 5.03770
Timestep Consumption Time: 2.06924
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.10694

Cumulative Model Updates: 28266
Cumulative Timesteps: 236072762

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.66534
Policy Entropy: 1.29834
Value Function Loss: 0.01828

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08270
Policy Update Magnitude: 0.12196
Value Function Update Magnitude: 0.19293

Collected Steps per Second: 10338.48987
Overall Steps per Second: 7193.23967

Timestep Collection Time: 4.84026
Timestep Consumption Time: 2.11641
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 6.95667

Cumulative Model Updates: 28272
Cumulative Timesteps: 236122803

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.30212
Policy Entropy: 1.30077
Value Function Loss: 0.01846

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.12291
Value Function Update Magnitude: 0.19125

Collected Steps per Second: 9852.52888
Overall Steps per Second: 7008.14787

Timestep Collection Time: 5.07656
Timestep Consumption Time: 2.06041
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.13698

Cumulative Model Updates: 28278
Cumulative Timesteps: 236172820

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.96082
Policy Entropy: 1.29858
Value Function Loss: 0.01889

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.12549
Value Function Update Magnitude: 0.19677

Collected Steps per Second: 9662.61463
Overall Steps per Second: 6931.55639

Timestep Collection Time: 5.17624
Timestep Consumption Time: 2.03946
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.21570

Cumulative Model Updates: 28284
Cumulative Timesteps: 236222836

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.32467
Policy Entropy: 1.29847
Value Function Loss: 0.01858

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07206
Policy Update Magnitude: 0.12679
Value Function Update Magnitude: 0.19468

Collected Steps per Second: 10333.20061
Overall Steps per Second: 7180.02485

Timestep Collection Time: 4.83877
Timestep Consumption Time: 2.12499
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 6.96376

Cumulative Model Updates: 28290
Cumulative Timesteps: 236272836

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 236272836...
Checkpoint 236272836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.61204
Policy Entropy: 1.29484
Value Function Loss: 0.01876

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.12633
Value Function Update Magnitude: 0.19781

Collected Steps per Second: 10077.99279
Overall Steps per Second: 7087.40646

Timestep Collection Time: 4.96418
Timestep Consumption Time: 2.09468
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.05886

Cumulative Model Updates: 28296
Cumulative Timesteps: 236322865

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.81608
Policy Entropy: 1.30030
Value Function Loss: 0.01867

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.12527
Value Function Update Magnitude: 0.20495

Collected Steps per Second: 9660.87839
Overall Steps per Second: 6912.95838

Timestep Collection Time: 5.17924
Timestep Consumption Time: 2.05876
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.23800

Cumulative Model Updates: 28302
Cumulative Timesteps: 236372901

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.53206
Policy Entropy: 1.30220
Value Function Loss: 0.01886

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.12627
Value Function Update Magnitude: 0.20207

Collected Steps per Second: 10408.70477
Overall Steps per Second: 7247.62745

Timestep Collection Time: 4.80588
Timestep Consumption Time: 2.09610
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.90198

Cumulative Model Updates: 28308
Cumulative Timesteps: 236422924

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.24111
Policy Entropy: 1.29992
Value Function Loss: 0.01886

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.12652
Value Function Update Magnitude: 0.20399

Collected Steps per Second: 9752.79205
Overall Steps per Second: 3852.01776

Timestep Collection Time: 5.13145
Timestep Consumption Time: 7.86070
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 12.99215

Cumulative Model Updates: 28314
Cumulative Timesteps: 236472970

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.07716
Policy Entropy: 1.29730
Value Function Loss: 0.01860

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.12704
Value Function Update Magnitude: 0.19576

Collected Steps per Second: 9634.02957
Overall Steps per Second: 6908.81343

Timestep Collection Time: 5.19004
Timestep Consumption Time: 2.04724
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 7.23728

Cumulative Model Updates: 28320
Cumulative Timesteps: 236522971

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.27383
Policy Entropy: 1.29726
Value Function Loss: 0.01809

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.12817
Value Function Update Magnitude: 0.19047

Collected Steps per Second: 10290.46045
Overall Steps per Second: 7219.35543

Timestep Collection Time: 4.86110
Timestep Consumption Time: 2.06791
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 6.92901

Cumulative Model Updates: 28326
Cumulative Timesteps: 236572994

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.42621
Policy Entropy: 1.30277
Value Function Loss: 0.01816

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.12471
Value Function Update Magnitude: 0.18465

Collected Steps per Second: 9795.59997
Overall Steps per Second: 6987.26963

Timestep Collection Time: 5.10566
Timestep Consumption Time: 2.05207
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.15773

Cumulative Model Updates: 28332
Cumulative Timesteps: 236623007

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.79943
Policy Entropy: 1.30040
Value Function Loss: 0.01822

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.12319
Value Function Update Magnitude: 0.18468

Collected Steps per Second: 9903.16608
Overall Steps per Second: 7062.11277

Timestep Collection Time: 5.05051
Timestep Consumption Time: 2.03179
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.08230

Cumulative Model Updates: 28338
Cumulative Timesteps: 236673023

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.77882
Policy Entropy: 1.30361
Value Function Loss: 0.01775

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06317
Policy Update Magnitude: 0.12329
Value Function Update Magnitude: 0.18680

Collected Steps per Second: 10435.89385
Overall Steps per Second: 7247.19565

Timestep Collection Time: 4.79413
Timestep Consumption Time: 2.10937
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 6.90350

Cumulative Model Updates: 28344
Cumulative Timesteps: 236723054

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.74258
Policy Entropy: 1.30578
Value Function Loss: 0.01847

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.12455
Value Function Update Magnitude: 0.19266

Collected Steps per Second: 9744.94995
Overall Steps per Second: 6995.36220

Timestep Collection Time: 5.13538
Timestep Consumption Time: 2.01850
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.15388

Cumulative Model Updates: 28350
Cumulative Timesteps: 236773098

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 236773098...
Checkpoint 236773098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.06625
Policy Entropy: 1.30831
Value Function Loss: 0.01822

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.05801
Policy Update Magnitude: 0.12597
Value Function Update Magnitude: 0.19218

Collected Steps per Second: 9780.03882
Overall Steps per Second: 7067.18486

Timestep Collection Time: 5.11726
Timestep Consumption Time: 1.96434
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.08160

Cumulative Model Updates: 28356
Cumulative Timesteps: 236823145

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.46433
Policy Entropy: 1.30581
Value Function Loss: 0.01957

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.12687
Value Function Update Magnitude: 0.19800

Collected Steps per Second: 10113.18367
Overall Steps per Second: 7155.90380

Timestep Collection Time: 4.94454
Timestep Consumption Time: 2.04340
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 6.98794

Cumulative Model Updates: 28362
Cumulative Timesteps: 236873150

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.30688
Policy Entropy: 1.30356
Value Function Loss: 0.01791

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06991
Policy Update Magnitude: 0.12568
Value Function Update Magnitude: 0.19426

Collected Steps per Second: 9740.38645
Overall Steps per Second: 6915.13296

Timestep Collection Time: 5.13624
Timestep Consumption Time: 2.09847
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.23471

Cumulative Model Updates: 28368
Cumulative Timesteps: 236923179

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.14101
Policy Entropy: 1.30373
Value Function Loss: 0.01782

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06685
Policy Update Magnitude: 0.12482
Value Function Update Magnitude: 0.18924

Collected Steps per Second: 9510.45847
Overall Steps per Second: 6858.88732

Timestep Collection Time: 5.25905
Timestep Consumption Time: 2.03309
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.29214

Cumulative Model Updates: 28374
Cumulative Timesteps: 236973195

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.16784
Policy Entropy: 1.30290
Value Function Loss: 0.01764

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.12513
Value Function Update Magnitude: 0.18483

Collected Steps per Second: 10342.03781
Overall Steps per Second: 7174.53853

Timestep Collection Time: 4.83841
Timestep Consumption Time: 2.13612
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.97453

Cumulative Model Updates: 28380
Cumulative Timesteps: 237023234

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.52232
Policy Entropy: 1.30157
Value Function Loss: 0.01741

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.12552
Value Function Update Magnitude: 0.18121

Collected Steps per Second: 9834.25171
Overall Steps per Second: 7011.05525

Timestep Collection Time: 5.08458
Timestep Consumption Time: 2.04745
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.13202

Cumulative Model Updates: 28386
Cumulative Timesteps: 237073237

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.62588
Policy Entropy: 1.29685
Value Function Loss: 0.01643

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.12358
Value Function Update Magnitude: 0.17336

Collected Steps per Second: 9831.10197
Overall Steps per Second: 7084.81159

Timestep Collection Time: 5.08915
Timestep Consumption Time: 1.97271
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.06187

Cumulative Model Updates: 28392
Cumulative Timesteps: 237123269

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.24799
Policy Entropy: 1.29349
Value Function Loss: 0.01670

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.12360
Value Function Update Magnitude: 0.16722

Collected Steps per Second: 10289.73207
Overall Steps per Second: 7202.84528

Timestep Collection Time: 4.86125
Timestep Consumption Time: 2.08336
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 6.94462

Cumulative Model Updates: 28398
Cumulative Timesteps: 237173290

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.32559
Policy Entropy: 1.29308
Value Function Loss: 0.01779

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.12667
Value Function Update Magnitude: 0.17779

Collected Steps per Second: 9819.68671
Overall Steps per Second: 6966.06606

Timestep Collection Time: 5.09385
Timestep Consumption Time: 2.08667
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.18052

Cumulative Model Updates: 28404
Cumulative Timesteps: 237223310

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.77006
Policy Entropy: 1.29496
Value Function Loss: 0.01896

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.12781
Value Function Update Magnitude: 0.18937

Collected Steps per Second: 9747.64175
Overall Steps per Second: 6972.78410

Timestep Collection Time: 5.13386
Timestep Consumption Time: 2.04305
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 7.17690

Cumulative Model Updates: 28410
Cumulative Timesteps: 237273353

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 237273353...
Checkpoint 237273353 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.46103
Policy Entropy: 1.30247
Value Function Loss: 0.01798

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.12253
Value Function Update Magnitude: 0.18984

Collected Steps per Second: 10349.95640
Overall Steps per Second: 7239.96174

Timestep Collection Time: 4.83413
Timestep Consumption Time: 2.07655
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 6.91067

Cumulative Model Updates: 28416
Cumulative Timesteps: 237323386

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.71332
Policy Entropy: 1.29689
Value Function Loss: 0.01856

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.12191
Value Function Update Magnitude: 0.19282

Collected Steps per Second: 9677.77252
Overall Steps per Second: 6923.89611

Timestep Collection Time: 5.16782
Timestep Consumption Time: 2.05542
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.22325

Cumulative Model Updates: 28422
Cumulative Timesteps: 237373399

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.00752
Policy Entropy: 1.29760
Value Function Loss: 0.01836

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.12209
Value Function Update Magnitude: 0.20050

Collected Steps per Second: 10804.19177
Overall Steps per Second: 7512.21496

Timestep Collection Time: 4.62811
Timestep Consumption Time: 2.02811
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 6.65623

Cumulative Model Updates: 28428
Cumulative Timesteps: 237423402

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.06177
Policy Entropy: 1.29539
Value Function Loss: 0.01936

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.12742
Value Function Update Magnitude: 0.19883

Collected Steps per Second: 10804.38682
Overall Steps per Second: 7405.42638

Timestep Collection Time: 4.63053
Timestep Consumption Time: 2.12533
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 6.75586

Cumulative Model Updates: 28434
Cumulative Timesteps: 237473432

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.93133
Policy Entropy: 1.29904
Value Function Loss: 0.01894

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.12511
Value Function Update Magnitude: 0.20275

Collected Steps per Second: 10047.05697
Overall Steps per Second: 7072.96374

Timestep Collection Time: 4.97688
Timestep Consumption Time: 2.09272
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.06960

Cumulative Model Updates: 28440
Cumulative Timesteps: 237523435

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.25682
Policy Entropy: 1.30259
Value Function Loss: 0.01858

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.12280
Value Function Update Magnitude: 0.20161

Collected Steps per Second: 9995.04680
Overall Steps per Second: 7108.13695

Timestep Collection Time: 5.00278
Timestep Consumption Time: 2.03184
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.03461

Cumulative Model Updates: 28446
Cumulative Timesteps: 237573438

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.69342
Policy Entropy: 1.30115
Value Function Loss: 0.01723

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07846
Policy Update Magnitude: 0.11985
Value Function Update Magnitude: 0.19663

Collected Steps per Second: 10366.43047
Overall Steps per Second: 7177.32264

Timestep Collection Time: 4.82625
Timestep Consumption Time: 2.14445
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 6.97071

Cumulative Model Updates: 28452
Cumulative Timesteps: 237623469

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.31597
Policy Entropy: 1.30382
Value Function Loss: 0.01688

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06516
Policy Update Magnitude: 0.12147
Value Function Update Magnitude: 0.19665

Collected Steps per Second: 9746.56684
Overall Steps per Second: 6939.00926

Timestep Collection Time: 5.13381
Timestep Consumption Time: 2.07716
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.21097

Cumulative Model Updates: 28458
Cumulative Timesteps: 237673506

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.10421
Policy Entropy: 1.30193
Value Function Loss: 0.01794

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.12312
Value Function Update Magnitude: 0.19748

Collected Steps per Second: 9586.89750
Overall Steps per Second: 6889.97228

Timestep Collection Time: 5.21743
Timestep Consumption Time: 2.04225
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.25968

Cumulative Model Updates: 28464
Cumulative Timesteps: 237723525

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.51587
Policy Entropy: 1.30269
Value Function Loss: 0.01823

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.12499
Value Function Update Magnitude: 0.19594

Collected Steps per Second: 10242.70245
Overall Steps per Second: 7183.89888

Timestep Collection Time: 4.88348
Timestep Consumption Time: 2.07932
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 6.96279

Cumulative Model Updates: 28470
Cumulative Timesteps: 237773545

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 237773545...
Checkpoint 237773545 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.43977
Policy Entropy: 1.30181
Value Function Loss: 0.01912

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.12597
Value Function Update Magnitude: 0.18666

Collected Steps per Second: 10118.80932
Overall Steps per Second: 7100.17757

Timestep Collection Time: 4.94465
Timestep Consumption Time: 2.10221
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.04687

Cumulative Model Updates: 28476
Cumulative Timesteps: 237823579

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.46754
Policy Entropy: 1.30371
Value Function Loss: 0.01757

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.12579
Value Function Update Magnitude: 0.18755

Collected Steps per Second: 9779.58108
Overall Steps per Second: 6992.49450

Timestep Collection Time: 5.11689
Timestep Consumption Time: 2.03950
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 7.15639

Cumulative Model Updates: 28482
Cumulative Timesteps: 237873620

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.41855
Policy Entropy: 1.29902
Value Function Loss: 0.01740

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.12379
Value Function Update Magnitude: 0.18752

Collected Steps per Second: 10552.27239
Overall Steps per Second: 7057.23386

Timestep Collection Time: 4.74135
Timestep Consumption Time: 2.34811
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.08946

Cumulative Model Updates: 28488
Cumulative Timesteps: 237923652

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.84679
Policy Entropy: 1.30184
Value Function Loss: 0.01667

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.12097
Value Function Update Magnitude: 0.18474

Collected Steps per Second: 10345.72891
Overall Steps per Second: 7138.36350

Timestep Collection Time: 4.83552
Timestep Consumption Time: 2.17267
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 7.00819

Cumulative Model Updates: 28494
Cumulative Timesteps: 237973679

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.23822
Policy Entropy: 1.30341
Value Function Loss: 0.01676

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.18509

Collected Steps per Second: 9977.97856
Overall Steps per Second: 7059.73241

Timestep Collection Time: 5.01424
Timestep Consumption Time: 2.07271
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.08695

Cumulative Model Updates: 28500
Cumulative Timesteps: 238023711

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.19104
Policy Entropy: 1.29745
Value Function Loss: 0.01736

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.12024
Value Function Update Magnitude: 0.18135

Collected Steps per Second: 9681.21648
Overall Steps per Second: 6946.11166

Timestep Collection Time: 5.16660
Timestep Consumption Time: 2.03440
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.20101

Cumulative Model Updates: 28506
Cumulative Timesteps: 238073730

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.96548
Policy Entropy: 1.29698
Value Function Loss: 0.01747

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.12167
Value Function Update Magnitude: 0.17234

Collected Steps per Second: 10266.54134
Overall Steps per Second: 7196.64798

Timestep Collection Time: 4.87311
Timestep Consumption Time: 2.07874
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 6.95185

Cumulative Model Updates: 28512
Cumulative Timesteps: 238123760

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.35223
Policy Entropy: 1.30137
Value Function Loss: 0.01809

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.12275
Value Function Update Magnitude: 0.17545

Collected Steps per Second: 9761.37051
Overall Steps per Second: 7010.21492

Timestep Collection Time: 5.12254
Timestep Consumption Time: 2.01034
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.13288

Cumulative Model Updates: 28518
Cumulative Timesteps: 238173763

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.54423
Policy Entropy: 1.30977
Value Function Loss: 0.01780

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.05955
Policy Update Magnitude: 0.12439
Value Function Update Magnitude: 0.18071

Collected Steps per Second: 9674.99995
Overall Steps per Second: 6897.30774

Timestep Collection Time: 5.17116
Timestep Consumption Time: 2.08254
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 7.25370

Cumulative Model Updates: 28524
Cumulative Timesteps: 238223794

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.00181
Policy Entropy: 1.30521
Value Function Loss: 0.01771

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.12419
Value Function Update Magnitude: 0.17711

Collected Steps per Second: 10267.29505
Overall Steps per Second: 7276.67002

Timestep Collection Time: 4.87051
Timestep Consumption Time: 2.00172
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 6.87224

Cumulative Model Updates: 28530
Cumulative Timesteps: 238273801

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 238273801...
Checkpoint 238273801 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.95518
Policy Entropy: 1.30214
Value Function Loss: 0.01798

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.12221
Value Function Update Magnitude: 0.17790

Collected Steps per Second: 9831.20355
Overall Steps per Second: 6925.54251

Timestep Collection Time: 5.08595
Timestep Consumption Time: 2.13385
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.21980

Cumulative Model Updates: 28536
Cumulative Timesteps: 238323802

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.85748
Policy Entropy: 1.30147
Value Function Loss: 0.01765

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06477
Policy Update Magnitude: 0.12481
Value Function Update Magnitude: 0.17277

Collected Steps per Second: 9962.75305
Overall Steps per Second: 7268.77530

Timestep Collection Time: 5.02100
Timestep Consumption Time: 1.86090
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 6.88190

Cumulative Model Updates: 28542
Cumulative Timesteps: 238373825

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.79558
Policy Entropy: 1.29814
Value Function Loss: 0.01805

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.06449
Policy Update Magnitude: 0.12602
Value Function Update Magnitude: 0.17913

Collected Steps per Second: 10315.98080
Overall Steps per Second: 7328.69219

Timestep Collection Time: 4.85140
Timestep Consumption Time: 1.97751
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 6.82891

Cumulative Model Updates: 28548
Cumulative Timesteps: 238423872

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.35719
Policy Entropy: 1.29490
Value Function Loss: 0.01827

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.12878
Value Function Update Magnitude: 0.17949

Collected Steps per Second: 10394.40490
Overall Steps per Second: 7220.30899

Timestep Collection Time: 4.81124
Timestep Consumption Time: 2.11505
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 6.92630

Cumulative Model Updates: 28554
Cumulative Timesteps: 238473882

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.66360
Policy Entropy: 1.29512
Value Function Loss: 0.01859

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.12881
Value Function Update Magnitude: 0.17482

Collected Steps per Second: 9790.76008
Overall Steps per Second: 6968.37092

Timestep Collection Time: 5.10696
Timestep Consumption Time: 2.06846
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 7.17542

Cumulative Model Updates: 28560
Cumulative Timesteps: 238523883

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.83808
Policy Entropy: 1.29788
Value Function Loss: 0.01779

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.12500
Value Function Update Magnitude: 0.17160

Collected Steps per Second: 9709.84391
Overall Steps per Second: 6977.45135

Timestep Collection Time: 5.15281
Timestep Consumption Time: 2.01786
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.17067

Cumulative Model Updates: 28566
Cumulative Timesteps: 238573916

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.22772
Policy Entropy: 1.29991
Value Function Loss: 0.01817

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06630
Policy Update Magnitude: 0.12700
Value Function Update Magnitude: 0.17329

Collected Steps per Second: 10412.94872
Overall Steps per Second: 7223.26849

Timestep Collection Time: 4.80565
Timestep Consumption Time: 2.12210
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 6.92775

Cumulative Model Updates: 28572
Cumulative Timesteps: 238623957

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.68400
Policy Entropy: 1.29745
Value Function Loss: 0.01855

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.12522
Value Function Update Magnitude: 0.18293

Collected Steps per Second: 9865.25839
Overall Steps per Second: 6980.88762

Timestep Collection Time: 5.07062
Timestep Consumption Time: 2.09509
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 7.16571

Cumulative Model Updates: 28578
Cumulative Timesteps: 238673980

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.15159
Policy Entropy: 1.30103
Value Function Loss: 0.01885

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.12590
Value Function Update Magnitude: 0.18785

Collected Steps per Second: 9754.86009
Overall Steps per Second: 7016.20899

Timestep Collection Time: 5.12596
Timestep Consumption Time: 2.00083
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.12678

Cumulative Model Updates: 28584
Cumulative Timesteps: 238723983

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.36869
Policy Entropy: 1.30212
Value Function Loss: 0.01845

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.12584
Value Function Update Magnitude: 0.20172

Collected Steps per Second: 10290.64077
Overall Steps per Second: 7207.01567

Timestep Collection Time: 4.86248
Timestep Consumption Time: 2.08048
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 6.94296

Cumulative Model Updates: 28590
Cumulative Timesteps: 238774021

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 238774021...
Checkpoint 238774021 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.28064
Policy Entropy: 1.30837
Value Function Loss: 0.01781

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.06580
Policy Update Magnitude: 0.12392
Value Function Update Magnitude: 0.19015

Collected Steps per Second: 9873.43617
Overall Steps per Second: 6983.76025

Timestep Collection Time: 5.06733
Timestep Consumption Time: 2.09671
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 7.16405

Cumulative Model Updates: 28596
Cumulative Timesteps: 238824053

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.61855
Policy Entropy: 1.30611
Value Function Loss: 0.01792

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.12231
Value Function Update Magnitude: 0.20437

Collected Steps per Second: 9791.48113
Overall Steps per Second: 6978.48229

Timestep Collection Time: 5.10862
Timestep Consumption Time: 2.05927
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.16789

Cumulative Model Updates: 28602
Cumulative Timesteps: 238874074

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.94496
Policy Entropy: 1.30005
Value Function Loss: 0.01750

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07178
Policy Update Magnitude: 0.12335
Value Function Update Magnitude: 0.19569

Collected Steps per Second: 10333.73988
Overall Steps per Second: 7189.73754

Timestep Collection Time: 4.84016
Timestep Consumption Time: 2.11656
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 6.95672

Cumulative Model Updates: 28608
Cumulative Timesteps: 238924091

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.23518
Policy Entropy: 1.29779
Value Function Loss: 0.01804

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.12193
Value Function Update Magnitude: 0.19235

Collected Steps per Second: 9623.23835
Overall Steps per Second: 6815.06704

Timestep Collection Time: 5.19648
Timestep Consumption Time: 2.14123
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.33771

Cumulative Model Updates: 28614
Cumulative Timesteps: 238974098

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.01066
Policy Entropy: 1.29689
Value Function Loss: 0.01883

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.12401
Value Function Update Magnitude: 0.19373

Collected Steps per Second: 9768.56406
Overall Steps per Second: 6914.39339

Timestep Collection Time: 5.11846
Timestep Consumption Time: 2.11283
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.23129

Cumulative Model Updates: 28620
Cumulative Timesteps: 239024098

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.88477
Policy Entropy: 1.30344
Value Function Loss: 0.01901

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.12509
Value Function Update Magnitude: 0.19722

Collected Steps per Second: 10233.27467
Overall Steps per Second: 7149.22526

Timestep Collection Time: 4.88993
Timestep Consumption Time: 2.10943
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 6.99936

Cumulative Model Updates: 28626
Cumulative Timesteps: 239074138

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.10504
Policy Entropy: 1.29768
Value Function Loss: 0.01892

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.12360
Value Function Update Magnitude: 0.20769

Collected Steps per Second: 10057.23663
Overall Steps per Second: 7149.91551

Timestep Collection Time: 4.97254
Timestep Consumption Time: 2.02195
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.99449

Cumulative Model Updates: 28632
Cumulative Timesteps: 239124148

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.52797
Policy Entropy: 1.29700
Value Function Loss: 0.01883

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.20474

Collected Steps per Second: 9699.91983
Overall Steps per Second: 6966.22515

Timestep Collection Time: 5.15808
Timestep Consumption Time: 2.02414
PPO Batch Consumption Time: 0.02401
Total Iteration Time: 7.18223

Cumulative Model Updates: 28638
Cumulative Timesteps: 239174181

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.22879
Policy Entropy: 1.29909
Value Function Loss: 0.01811

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.12703
Value Function Update Magnitude: 0.21761

Collected Steps per Second: 10376.49592
Overall Steps per Second: 7217.96046

Timestep Collection Time: 4.81964
Timestep Consumption Time: 2.10905
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 6.92869

Cumulative Model Updates: 28644
Cumulative Timesteps: 239224192

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.73065
Policy Entropy: 1.29915
Value Function Loss: 0.01778

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.12820
Value Function Update Magnitude: 0.21039

Collected Steps per Second: 9726.41736
Overall Steps per Second: 6890.98235

Timestep Collection Time: 5.14084
Timestep Consumption Time: 2.11531
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.25615

Cumulative Model Updates: 28650
Cumulative Timesteps: 239274194

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 239274194...
Checkpoint 239274194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.39817
Policy Entropy: 1.29990
Value Function Loss: 0.01679

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.06887
Policy Update Magnitude: 0.12634
Value Function Update Magnitude: 0.19503

Collected Steps per Second: 9751.77760
Overall Steps per Second: 6987.70937

Timestep Collection Time: 5.12809
Timestep Consumption Time: 2.02847
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.15657

Cumulative Model Updates: 28656
Cumulative Timesteps: 239324202

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.99644
Policy Entropy: 1.29630
Value Function Loss: 0.01699

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.12139
Value Function Update Magnitude: 0.18906

Collected Steps per Second: 10260.74559
Overall Steps per Second: 7190.23178

Timestep Collection Time: 4.87625
Timestep Consumption Time: 2.08235
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.95861

Cumulative Model Updates: 28662
Cumulative Timesteps: 239374236

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.27495
Policy Entropy: 1.29640
Value Function Loss: 0.01770

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06338
Policy Update Magnitude: 0.12143
Value Function Update Magnitude: 0.18821

Collected Steps per Second: 9929.50272
Overall Steps per Second: 6986.29531

Timestep Collection Time: 5.03943
Timestep Consumption Time: 2.12302
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.16245

Cumulative Model Updates: 28668
Cumulative Timesteps: 239424275

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.39116
Policy Entropy: 1.29736
Value Function Loss: 0.01814

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05742
Policy Update Magnitude: 0.12688
Value Function Update Magnitude: 0.18744

Collected Steps per Second: 9689.32375
Overall Steps per Second: 6988.94329

Timestep Collection Time: 5.16156
Timestep Consumption Time: 1.99432
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.15587

Cumulative Model Updates: 28674
Cumulative Timesteps: 239474287

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.94184
Policy Entropy: 1.30041
Value Function Loss: 0.01848

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05630
Policy Update Magnitude: 0.12789
Value Function Update Magnitude: 0.19317

Collected Steps per Second: 10272.29961
Overall Steps per Second: 7177.19238

Timestep Collection Time: 4.87126
Timestep Consumption Time: 2.10069
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 6.97195

Cumulative Model Updates: 28680
Cumulative Timesteps: 239524326

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.98280
Policy Entropy: 1.29810
Value Function Loss: 0.01769

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.12769
Value Function Update Magnitude: 0.19653

Collected Steps per Second: 9863.58169
Overall Steps per Second: 7065.48532

Timestep Collection Time: 5.07006
Timestep Consumption Time: 2.00786
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 7.07793

Cumulative Model Updates: 28686
Cumulative Timesteps: 239574335

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.78601
Policy Entropy: 1.29974
Value Function Loss: 0.01729

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.12413
Value Function Update Magnitude: 0.19196

Collected Steps per Second: 9538.41778
Overall Steps per Second: 6852.45177

Timestep Collection Time: 5.24322
Timestep Consumption Time: 2.05519
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.29841

Cumulative Model Updates: 28692
Cumulative Timesteps: 239624347

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.02268
Policy Entropy: 1.29885
Value Function Loss: 0.01751

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.12219
Value Function Update Magnitude: 0.19011

Collected Steps per Second: 10402.84407
Overall Steps per Second: 7287.56788

Timestep Collection Time: 4.81022
Timestep Consumption Time: 2.05627
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.86649

Cumulative Model Updates: 28698
Cumulative Timesteps: 239674387

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.30290
Policy Entropy: 1.30209
Value Function Loss: 0.01835

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.05768
Policy Update Magnitude: 0.12301
Value Function Update Magnitude: 0.19051

Collected Steps per Second: 9895.69731
Overall Steps per Second: 6957.30018

Timestep Collection Time: 5.05462
Timestep Consumption Time: 2.13481
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.18943

Cumulative Model Updates: 28704
Cumulative Timesteps: 239724406

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.39056
Policy Entropy: 1.30420
Value Function Loss: 0.01892

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06068
Policy Update Magnitude: 0.12357
Value Function Update Magnitude: 0.19032

Collected Steps per Second: 9698.94245
Overall Steps per Second: 6942.96436

Timestep Collection Time: 5.15664
Timestep Consumption Time: 2.04691
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.20355

Cumulative Model Updates: 28710
Cumulative Timesteps: 239774420

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 239774420...
Checkpoint 239774420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.94845
Policy Entropy: 1.30458
Value Function Loss: 0.01827

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.05874
Policy Update Magnitude: 0.12405
Value Function Update Magnitude: 0.19424

Collected Steps per Second: 10264.74952
Overall Steps per Second: 7201.81323

Timestep Collection Time: 4.87474
Timestep Consumption Time: 2.07323
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 6.94797

Cumulative Model Updates: 28716
Cumulative Timesteps: 239824458

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11945
Policy Entropy: 1.31058
Value Function Loss: 0.01771

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.05534
Policy Update Magnitude: 0.12448
Value Function Update Magnitude: 0.18658

Collected Steps per Second: 9928.98975
Overall Steps per Second: 6974.13855

Timestep Collection Time: 5.03989
Timestep Consumption Time: 2.13533
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.17522

Cumulative Model Updates: 28722
Cumulative Timesteps: 239874499

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.33246
Policy Entropy: 1.31031
Value Function Loss: 0.01732

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.05681
Policy Update Magnitude: 0.12201
Value Function Update Magnitude: 0.17864

Collected Steps per Second: 10018.42201
Overall Steps per Second: 7149.49628

Timestep Collection Time: 4.99230
Timestep Consumption Time: 2.00329
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 6.99560

Cumulative Model Updates: 28728
Cumulative Timesteps: 239924514

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.74723
Policy Entropy: 1.30898
Value Function Loss: 0.01777

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06261
Policy Update Magnitude: 0.12270
Value Function Update Magnitude: 0.17568

Collected Steps per Second: 10378.02515
Overall Steps per Second: 7280.73074

Timestep Collection Time: 4.82134
Timestep Consumption Time: 2.05105
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.87239

Cumulative Model Updates: 28734
Cumulative Timesteps: 239974550

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.18521
Policy Entropy: 1.30404
Value Function Loss: 0.01766

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.12415
Value Function Update Magnitude: 0.18013

Collected Steps per Second: 9845.91095
Overall Steps per Second: 7022.06351

Timestep Collection Time: 5.08028
Timestep Consumption Time: 2.04298
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 7.12326

Cumulative Model Updates: 28740
Cumulative Timesteps: 240024570

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.92322
Policy Entropy: 1.30498
Value Function Loss: 0.01719

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.18486

Collected Steps per Second: 9927.01370
Overall Steps per Second: 7075.84650

Timestep Collection Time: 5.03817
Timestep Consumption Time: 2.03010
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.06827

Cumulative Model Updates: 28746
Cumulative Timesteps: 240074584

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.02546
Policy Entropy: 1.30713
Value Function Loss: 0.01686

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.12219
Value Function Update Magnitude: 0.18503

Collected Steps per Second: 10327.93552
Overall Steps per Second: 7205.38949

Timestep Collection Time: 4.84434
Timestep Consumption Time: 2.09935
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 6.94369

Cumulative Model Updates: 28752
Cumulative Timesteps: 240124616

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.84604
Policy Entropy: 1.30815
Value Function Loss: 0.01692

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06062
Policy Update Magnitude: 0.11986
Value Function Update Magnitude: 0.17884

Collected Steps per Second: 9798.38281
Overall Steps per Second: 7039.02538

Timestep Collection Time: 5.10472
Timestep Consumption Time: 2.00109
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.10581

Cumulative Model Updates: 28758
Cumulative Timesteps: 240174634

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.90659
Policy Entropy: 1.31099
Value Function Loss: 0.01672

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.05866
Policy Update Magnitude: 0.12016
Value Function Update Magnitude: 0.17186

Collected Steps per Second: 9856.57019
Overall Steps per Second: 7059.19739

Timestep Collection Time: 5.07631
Timestep Consumption Time: 2.01161
PPO Batch Consumption Time: 0.02399
Total Iteration Time: 7.08792

Cumulative Model Updates: 28764
Cumulative Timesteps: 240224669

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.54740
Policy Entropy: 1.31066
Value Function Loss: 0.01743

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06639
Policy Update Magnitude: 0.12125
Value Function Update Magnitude: 0.17215

Collected Steps per Second: 10392.19934
Overall Steps per Second: 7187.84231

Timestep Collection Time: 4.81246
Timestep Consumption Time: 2.14540
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 6.95786

Cumulative Model Updates: 28770
Cumulative Timesteps: 240274681

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 240274681...
Checkpoint 240274681 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.86431
Policy Entropy: 1.30942
Value Function Loss: 0.01736

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.11842
Value Function Update Magnitude: 0.17768

Collected Steps per Second: 10102.60200
Overall Steps per Second: 7170.22416

Timestep Collection Time: 4.95110
Timestep Consumption Time: 2.02483
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 6.97593

Cumulative Model Updates: 28776
Cumulative Timesteps: 240324700

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.61667
Policy Entropy: 1.30668
Value Function Loss: 0.01823

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.05799
Policy Update Magnitude: 0.12227
Value Function Update Magnitude: 0.18029

Collected Steps per Second: 9816.05113
Overall Steps per Second: 7000.40656

Timestep Collection Time: 5.09390
Timestep Consumption Time: 2.04883
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.14273

Cumulative Model Updates: 28782
Cumulative Timesteps: 240374702

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.55931
Policy Entropy: 1.29671
Value Function Loss: 0.01782

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06304
Policy Update Magnitude: 0.12482
Value Function Update Magnitude: 0.18382

Collected Steps per Second: 10465.74684
Overall Steps per Second: 7293.26416

Timestep Collection Time: 4.77873
Timestep Consumption Time: 2.07869
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.85742

Cumulative Model Updates: 28788
Cumulative Timesteps: 240424715

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.56324
Policy Entropy: 1.29582
Value Function Loss: 0.01808

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.12525
Value Function Update Magnitude: 0.19002

Collected Steps per Second: 9726.61947
Overall Steps per Second: 6911.87271

Timestep Collection Time: 5.14207
Timestep Consumption Time: 2.09403
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.23610

Cumulative Model Updates: 28794
Cumulative Timesteps: 240474730

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.71867
Policy Entropy: 1.29827
Value Function Loss: 0.01769

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.19001

Collected Steps per Second: 9718.74836
Overall Steps per Second: 6982.36771

Timestep Collection Time: 5.14768
Timestep Consumption Time: 2.01737
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.16505

Cumulative Model Updates: 28800
Cumulative Timesteps: 240524759

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.37792
Policy Entropy: 1.30693
Value Function Loss: 0.01809

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.12214
Value Function Update Magnitude: 0.18676

Collected Steps per Second: 10384.26927
Overall Steps per Second: 7260.49099

Timestep Collection Time: 4.81555
Timestep Consumption Time: 2.07186
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.88741

Cumulative Model Updates: 28806
Cumulative Timesteps: 240574765

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.83570
Policy Entropy: 1.30820
Value Function Loss: 0.01851

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.12302
Value Function Update Magnitude: 0.19555

Collected Steps per Second: 9911.07573
Overall Steps per Second: 7071.41437

Timestep Collection Time: 5.04648
Timestep Consumption Time: 2.02651
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.07298

Cumulative Model Updates: 28812
Cumulative Timesteps: 240624781

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.91166
Policy Entropy: 1.30140
Value Function Loss: 0.01903

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.12380
Value Function Update Magnitude: 0.19225

Collected Steps per Second: 9924.64234
Overall Steps per Second: 7035.30406

Timestep Collection Time: 5.03887
Timestep Consumption Time: 2.06942
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.10829

Cumulative Model Updates: 28818
Cumulative Timesteps: 240674790

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.38218
Policy Entropy: 1.31022
Value Function Loss: 0.01856

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.12330
Value Function Update Magnitude: 0.18831

Collected Steps per Second: 10395.32586
Overall Steps per Second: 7260.14948

Timestep Collection Time: 4.81236
Timestep Consumption Time: 2.07814
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 6.89049

Cumulative Model Updates: 28824
Cumulative Timesteps: 240724816

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.63217
Policy Entropy: 1.30017
Value Function Loss: 0.01805

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.12268
Value Function Update Magnitude: 0.18204

Collected Steps per Second: 9843.32548
Overall Steps per Second: 7029.47614

Timestep Collection Time: 5.08070
Timestep Consumption Time: 2.03377
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.11447

Cumulative Model Updates: 28830
Cumulative Timesteps: 240774827

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 240774827...
Checkpoint 240774827 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.42869
Policy Entropy: 1.30351
Value Function Loss: 0.01792

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.12348
Value Function Update Magnitude: 0.17603

Collected Steps per Second: 9753.34396
Overall Steps per Second: 6962.22472

Timestep Collection Time: 5.12993
Timestep Consumption Time: 2.05656
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.18650

Cumulative Model Updates: 28836
Cumulative Timesteps: 240824861

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.28161
Policy Entropy: 1.30187
Value Function Loss: 0.01758

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.06802
Policy Update Magnitude: 0.12171
Value Function Update Magnitude: 0.17165

Collected Steps per Second: 10391.47699
Overall Steps per Second: 7234.57848

Timestep Collection Time: 4.81558
Timestep Consumption Time: 2.10134
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 6.91692

Cumulative Model Updates: 28842
Cumulative Timesteps: 240874902

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.88960
Policy Entropy: 1.30765
Value Function Loss: 0.01767

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06147
Policy Update Magnitude: 0.11979
Value Function Update Magnitude: 0.17419

Collected Steps per Second: 9992.54029
Overall Steps per Second: 7023.71378

Timestep Collection Time: 5.00493
Timestep Consumption Time: 2.11552
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.12045

Cumulative Model Updates: 28848
Cumulative Timesteps: 240924914

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.33973
Policy Entropy: 1.30791
Value Function Loss: 0.01791

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06205
Policy Update Magnitude: 0.12153
Value Function Update Magnitude: 0.18088

Collected Steps per Second: 9773.13237
Overall Steps per Second: 6996.92091

Timestep Collection Time: 5.11955
Timestep Consumption Time: 2.03131
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.15086

Cumulative Model Updates: 28854
Cumulative Timesteps: 240974948

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.21532
Policy Entropy: 1.30303
Value Function Loss: 0.01836

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.06844
Policy Update Magnitude: 0.12454
Value Function Update Magnitude: 0.18454

Collected Steps per Second: 10283.87392
Overall Steps per Second: 7205.57631

Timestep Collection Time: 4.86597
Timestep Consumption Time: 2.07879
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 6.94476

Cumulative Model Updates: 28860
Cumulative Timesteps: 241024989

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.26818
Policy Entropy: 1.30398
Value Function Loss: 0.01768

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.12251
Value Function Update Magnitude: 0.18480

Collected Steps per Second: 9778.77927
Overall Steps per Second: 7019.69384

Timestep Collection Time: 5.11577
Timestep Consumption Time: 2.01075
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.12652

Cumulative Model Updates: 28866
Cumulative Timesteps: 241075015

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.08810
Policy Entropy: 1.30416
Value Function Loss: 0.01778

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.12168
Value Function Update Magnitude: 0.18241

Collected Steps per Second: 9736.02110
Overall Steps per Second: 6992.27579

Timestep Collection Time: 5.13885
Timestep Consumption Time: 2.01647
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.15532

Cumulative Model Updates: 28872
Cumulative Timesteps: 241125047

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.93044
Policy Entropy: 1.30643
Value Function Loss: 0.01812

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.12226
Value Function Update Magnitude: 0.18487

Collected Steps per Second: 10419.03851
Overall Steps per Second: 7248.81778

Timestep Collection Time: 4.80198
Timestep Consumption Time: 2.10011
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.90209

Cumulative Model Updates: 28878
Cumulative Timesteps: 241175079

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.07710
Policy Entropy: 1.30509
Value Function Loss: 0.01833

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.12012
Value Function Update Magnitude: 0.20090

Collected Steps per Second: 9858.87985
Overall Steps per Second: 6976.00444

Timestep Collection Time: 5.07431
Timestep Consumption Time: 2.09699
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 7.17130

Cumulative Model Updates: 28884
Cumulative Timesteps: 241225106

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.88238
Policy Entropy: 1.30266
Value Function Loss: 0.01800

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.12092
Value Function Update Magnitude: 0.19928

Collected Steps per Second: 9606.76377
Overall Steps per Second: 6922.56714

Timestep Collection Time: 5.20810
Timestep Consumption Time: 2.01942
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.22752

Cumulative Model Updates: 28890
Cumulative Timesteps: 241275139

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 241275139...
Checkpoint 241275139 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.80520
Policy Entropy: 1.29934
Value Function Loss: 0.01803

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.11778
Value Function Update Magnitude: 0.19852

Collected Steps per Second: 10302.43548
Overall Steps per Second: 7198.12186

Timestep Collection Time: 4.85468
Timestep Consumption Time: 2.09366
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.94834

Cumulative Model Updates: 28896
Cumulative Timesteps: 241325154

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.79539
Policy Entropy: 1.30143
Value Function Loss: 0.01805

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.11890
Value Function Update Magnitude: 0.19652

Collected Steps per Second: 9951.44144
Overall Steps per Second: 7029.53749

Timestep Collection Time: 5.02711
Timestep Consumption Time: 2.08957
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.11668

Cumulative Model Updates: 28902
Cumulative Timesteps: 241375181

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.17549
Policy Entropy: 1.30583
Value Function Loss: 0.01848

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06414
Policy Update Magnitude: 0.12387
Value Function Update Magnitude: 0.19132

Collected Steps per Second: 9720.83110
Overall Steps per Second: 6919.00569

Timestep Collection Time: 5.14658
Timestep Consumption Time: 2.08409
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 7.23066

Cumulative Model Updates: 28908
Cumulative Timesteps: 241425210

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.63967
Policy Entropy: 1.30194
Value Function Loss: 0.01811

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.12299
Value Function Update Magnitude: 0.19412

Collected Steps per Second: 10461.90367
Overall Steps per Second: 7012.83382

Timestep Collection Time: 4.78230
Timestep Consumption Time: 2.35204
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.13435

Cumulative Model Updates: 28914
Cumulative Timesteps: 241475242

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.05276
Policy Entropy: 1.29830
Value Function Loss: 0.01917

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.12248
Value Function Update Magnitude: 0.18545

Collected Steps per Second: 10131.38538
Overall Steps per Second: 7127.18923

Timestep Collection Time: 4.93960
Timestep Consumption Time: 2.08210
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.02170

Cumulative Model Updates: 28920
Cumulative Timesteps: 241525287

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.63927
Policy Entropy: 1.29457
Value Function Loss: 0.01874

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.12229
Value Function Update Magnitude: 0.18140

Collected Steps per Second: 9889.68349
Overall Steps per Second: 6992.30365

Timestep Collection Time: 5.05931
Timestep Consumption Time: 2.09641
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 7.15572

Cumulative Model Updates: 28926
Cumulative Timesteps: 241575322

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.60920
Policy Entropy: 1.29790
Value Function Loss: 0.01931

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.12401
Value Function Update Magnitude: 0.19117

Collected Steps per Second: 10433.10182
Overall Steps per Second: 7035.34695

Timestep Collection Time: 4.79464
Timestep Consumption Time: 2.31560
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.11024

Cumulative Model Updates: 28932
Cumulative Timesteps: 241625345

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.48405
Policy Entropy: 1.29978
Value Function Loss: 0.01838

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.12309
Value Function Update Magnitude: 0.19148

Collected Steps per Second: 10310.59840
Overall Steps per Second: 7136.22658

Timestep Collection Time: 4.84967
Timestep Consumption Time: 2.15725
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.00692

Cumulative Model Updates: 28938
Cumulative Timesteps: 241675348

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.61952
Policy Entropy: 1.30528
Value Function Loss: 0.01789

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.12056
Value Function Update Magnitude: 0.18571

Collected Steps per Second: 9716.05474
Overall Steps per Second: 6920.02511

Timestep Collection Time: 5.14684
Timestep Consumption Time: 2.07958
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.22642

Cumulative Model Updates: 28944
Cumulative Timesteps: 241725355

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.52705
Policy Entropy: 1.30970
Value Function Loss: 0.01835

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07022
Policy Update Magnitude: 0.11977
Value Function Update Magnitude: 0.18815

Collected Steps per Second: 9960.51520
Overall Steps per Second: 7090.54582

Timestep Collection Time: 5.02183
Timestep Consumption Time: 2.03264
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.05446

Cumulative Model Updates: 28950
Cumulative Timesteps: 241775375

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 241775375...
Checkpoint 241775375 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.82722
Policy Entropy: 1.30290
Value Function Loss: 0.01836

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.12126
Value Function Update Magnitude: 0.19706

Collected Steps per Second: 10494.09294
Overall Steps per Second: 7238.34314

Timestep Collection Time: 4.76592
Timestep Consumption Time: 2.14367
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 6.90959

Cumulative Model Updates: 28956
Cumulative Timesteps: 241825389

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.84139
Policy Entropy: 1.30550
Value Function Loss: 0.01869

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.11682
Value Function Update Magnitude: 0.20152

Collected Steps per Second: 9794.81479
Overall Steps per Second: 6988.01458

Timestep Collection Time: 5.10852
Timestep Consumption Time: 2.05188
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.16040

Cumulative Model Updates: 28962
Cumulative Timesteps: 241875426

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.87992
Policy Entropy: 1.30257
Value Function Loss: 0.01733

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.11838
Value Function Update Magnitude: 0.19349

Collected Steps per Second: 9639.59536
Overall Steps per Second: 6955.67689

Timestep Collection Time: 5.18787
Timestep Consumption Time: 2.00179
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 7.18967

Cumulative Model Updates: 28968
Cumulative Timesteps: 241925435

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.19706
Policy Entropy: 1.30517
Value Function Loss: 0.01706

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.11788
Value Function Update Magnitude: 0.18453

Collected Steps per Second: 10313.89895
Overall Steps per Second: 7234.85981

Timestep Collection Time: 4.84860
Timestep Consumption Time: 2.06349
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 6.91209

Cumulative Model Updates: 28974
Cumulative Timesteps: 241975443

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.93078
Policy Entropy: 1.30120
Value Function Loss: 0.01653

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.11542
Value Function Update Magnitude: 0.18285

Collected Steps per Second: 9751.92060
Overall Steps per Second: 7048.80994

Timestep Collection Time: 5.12904
Timestep Consumption Time: 1.96691
PPO Batch Consumption Time: 0.02408
Total Iteration Time: 7.09595

Cumulative Model Updates: 28980
Cumulative Timesteps: 242025461

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.26473
Policy Entropy: 1.29869
Value Function Loss: 0.01790

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.11761
Value Function Update Magnitude: 0.18643

Collected Steps per Second: 9724.90832
Overall Steps per Second: 7007.81484

Timestep Collection Time: 5.14421
Timestep Consumption Time: 1.99453
PPO Batch Consumption Time: 0.02436
Total Iteration Time: 7.13874

Cumulative Model Updates: 28986
Cumulative Timesteps: 242075488

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.02515
Policy Entropy: 1.29769
Value Function Loss: 0.01811

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.12231
Value Function Update Magnitude: 0.18909

Collected Steps per Second: 10383.64136
Overall Steps per Second: 7029.31675

Timestep Collection Time: 4.81941
Timestep Consumption Time: 2.29978
PPO Batch Consumption Time: 0.02438
Total Iteration Time: 7.11918

Cumulative Model Updates: 28992
Cumulative Timesteps: 242125531

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69927
Policy Entropy: 1.30047
Value Function Loss: 0.01790

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.12320
Value Function Update Magnitude: 0.18858

Collected Steps per Second: 10237.02568
Overall Steps per Second: 7142.10802

Timestep Collection Time: 4.88521
Timestep Consumption Time: 2.11693
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 7.00213

Cumulative Model Updates: 28998
Cumulative Timesteps: 242175541

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.15907
Policy Entropy: 1.30482
Value Function Loss: 0.01752

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.12120
Value Function Update Magnitude: 0.19097

Collected Steps per Second: 9752.91555
Overall Steps per Second: 6963.86081

Timestep Collection Time: 5.13098
Timestep Consumption Time: 2.05498
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 7.18596

Cumulative Model Updates: 29004
Cumulative Timesteps: 242225583

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.41830
Policy Entropy: 1.30614
Value Function Loss: 0.01818

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.11859
Value Function Update Magnitude: 0.20082

Collected Steps per Second: 10292.49168
Overall Steps per Second: 6995.81618

Timestep Collection Time: 4.86044
Timestep Consumption Time: 2.29041
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.15085

Cumulative Model Updates: 29010
Cumulative Timesteps: 242275609

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 242275609...
Checkpoint 242275609 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.77110
Policy Entropy: 1.30361
Value Function Loss: 0.01880

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.11927
Value Function Update Magnitude: 0.20887

Collected Steps per Second: 10418.39017
Overall Steps per Second: 7382.95700

Timestep Collection Time: 4.79921
Timestep Consumption Time: 1.97315
PPO Batch Consumption Time: 0.02979
Total Iteration Time: 6.77235

Cumulative Model Updates: 29016
Cumulative Timesteps: 242325609

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.00287
Policy Entropy: 1.30378
Value Function Loss: 0.01879

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.11813
Value Function Update Magnitude: 0.21430

Collected Steps per Second: 9833.75709
Overall Steps per Second: 6996.62832

Timestep Collection Time: 5.08575
Timestep Consumption Time: 2.06227
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 7.14801

Cumulative Model Updates: 29022
Cumulative Timesteps: 242375621

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.45162
Policy Entropy: 1.30090
Value Function Loss: 0.01765

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.11645
Value Function Update Magnitude: 0.21154

Collected Steps per Second: 9558.47297
Overall Steps per Second: 1985.62733

Timestep Collection Time: 5.23316
Timestep Consumption Time: 19.95838
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 25.19153

Cumulative Model Updates: 29028
Cumulative Timesteps: 242425642

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.22805
Policy Entropy: 1.29974
Value Function Loss: 0.01794

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.11431
Value Function Update Magnitude: 0.20475

Collected Steps per Second: 10266.81297
Overall Steps per Second: 7148.70956

Timestep Collection Time: 4.87289
Timestep Consumption Time: 2.12544
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 6.99833

Cumulative Model Updates: 29034
Cumulative Timesteps: 242475671

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.49028
Policy Entropy: 1.29445
Value Function Loss: 0.01767

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.11591
Value Function Update Magnitude: 0.19553

Collected Steps per Second: 9844.88888
Overall Steps per Second: 7050.14065

Timestep Collection Time: 5.08233
Timestep Consumption Time: 2.01469
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.09702

Cumulative Model Updates: 29040
Cumulative Timesteps: 242525706

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.38191
Policy Entropy: 1.29108
Value Function Loss: 0.01850

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.12165
Value Function Update Magnitude: 0.19499

Collected Steps per Second: 9932.55633
Overall Steps per Second: 7068.30146

Timestep Collection Time: 5.03395
Timestep Consumption Time: 2.03988
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.07384

Cumulative Model Updates: 29046
Cumulative Timesteps: 242575706

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.06505
Policy Entropy: 1.28746
Value Function Loss: 0.01856

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.12320
Value Function Update Magnitude: 0.19920

Collected Steps per Second: 10301.19389
Overall Steps per Second: 7201.88620

Timestep Collection Time: 4.85410
Timestep Consumption Time: 2.08894
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 6.94304

Cumulative Model Updates: 29052
Cumulative Timesteps: 242625709

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.96085
Policy Entropy: 1.29133
Value Function Loss: 0.01901

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.12090
Value Function Update Magnitude: 0.21209

Collected Steps per Second: 9867.32603
Overall Steps per Second: 7019.68944

Timestep Collection Time: 5.06875
Timestep Consumption Time: 2.05621
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 7.12496

Cumulative Model Updates: 29058
Cumulative Timesteps: 242675724

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.96703
Policy Entropy: 1.28848
Value Function Loss: 0.01847

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.12301
Value Function Update Magnitude: 0.22665

Collected Steps per Second: 9801.46602
Overall Steps per Second: 7020.56579

Timestep Collection Time: 5.10475
Timestep Consumption Time: 2.02203
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.12678

Cumulative Model Updates: 29064
Cumulative Timesteps: 242725758

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.61897
Policy Entropy: 1.29029
Value Function Loss: 0.01801

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.22106

Collected Steps per Second: 10311.37743
Overall Steps per Second: 7292.99337

Timestep Collection Time: 4.85037
Timestep Consumption Time: 2.00744
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 6.85782

Cumulative Model Updates: 29070
Cumulative Timesteps: 242775772

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 242775772...
Checkpoint 242775772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.02679
Policy Entropy: 1.28483
Value Function Loss: 0.01823

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.12369
Value Function Update Magnitude: 0.20448

Collected Steps per Second: 9699.97712
Overall Steps per Second: 6905.30716

Timestep Collection Time: 5.15651
Timestep Consumption Time: 2.08691
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.24341

Cumulative Model Updates: 29076
Cumulative Timesteps: 242825790

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.57254
Policy Entropy: 1.28862
Value Function Loss: 0.01958

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.12273
Value Function Update Magnitude: 0.22023

Collected Steps per Second: 9868.56252
Overall Steps per Second: 7050.20692

Timestep Collection Time: 5.06690
Timestep Consumption Time: 2.02552
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.09242

Cumulative Model Updates: 29082
Cumulative Timesteps: 242875793

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.73211
Policy Entropy: 1.28579
Value Function Loss: 0.01972

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.12318
Value Function Update Magnitude: 0.23318

Collected Steps per Second: 10555.48160
Overall Steps per Second: 7339.07139

Timestep Collection Time: 4.73811
Timestep Consumption Time: 2.07652
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 6.81462

Cumulative Model Updates: 29088
Cumulative Timesteps: 242925806

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.76868
Policy Entropy: 1.28971
Value Function Loss: 0.01909

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06128
Policy Update Magnitude: 0.12755
Value Function Update Magnitude: 0.22240

Collected Steps per Second: 9590.65654
Overall Steps per Second: 6788.50478

Timestep Collection Time: 5.21779
Timestep Consumption Time: 2.15379
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.37158

Cumulative Model Updates: 29094
Cumulative Timesteps: 242975848

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.81524
Policy Entropy: 1.28770
Value Function Loss: 0.01748

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.12656
Value Function Update Magnitude: 0.20704

Collected Steps per Second: 9792.64265
Overall Steps per Second: 6995.08232

Timestep Collection Time: 5.10873
Timestep Consumption Time: 2.04315
PPO Batch Consumption Time: 0.02418
Total Iteration Time: 7.15188

Cumulative Model Updates: 29100
Cumulative Timesteps: 243025876

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.55299
Policy Entropy: 1.29428
Value Function Loss: 0.01899

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.12501
Value Function Update Magnitude: 0.19789

Collected Steps per Second: 10408.15220
Overall Steps per Second: 7246.38180

Timestep Collection Time: 4.80681
Timestep Consumption Time: 2.09733
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 6.90414

Cumulative Model Updates: 29106
Cumulative Timesteps: 243075906

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.44553
Policy Entropy: 1.30018
Value Function Loss: 0.01924

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.12633
Value Function Update Magnitude: 0.19780

Collected Steps per Second: 9781.26364
Overall Steps per Second: 7012.85518

Timestep Collection Time: 5.11202
Timestep Consumption Time: 2.01803
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.13005

Cumulative Model Updates: 29112
Cumulative Timesteps: 243125908

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.78410
Policy Entropy: 1.30044
Value Function Loss: 0.01944

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.12476
Value Function Update Magnitude: 0.20870

Collected Steps per Second: 9679.54133
Overall Steps per Second: 6957.34565

Timestep Collection Time: 5.16946
Timestep Consumption Time: 2.02265
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.19211

Cumulative Model Updates: 29118
Cumulative Timesteps: 243175946

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.86040
Policy Entropy: 1.29411
Value Function Loss: 0.01787

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.12080
Value Function Update Magnitude: 0.19639

Collected Steps per Second: 10175.85063
Overall Steps per Second: 7134.87884

Timestep Collection Time: 4.91733
Timestep Consumption Time: 2.09582
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 7.01315

Cumulative Model Updates: 29124
Cumulative Timesteps: 243225984

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.60289
Policy Entropy: 1.28817
Value Function Loss: 0.01795

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.12024
Value Function Update Magnitude: 0.20192

Collected Steps per Second: 9871.05954
Overall Steps per Second: 7024.37831

Timestep Collection Time: 5.06886
Timestep Consumption Time: 2.05419
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.12305

Cumulative Model Updates: 29130
Cumulative Timesteps: 243276019

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 243276019...
Checkpoint 243276019 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.38383
Policy Entropy: 1.28635
Value Function Loss: 0.01757

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.12230
Value Function Update Magnitude: 0.19589

Collected Steps per Second: 9629.67969
Overall Steps per Second: 6914.65634

Timestep Collection Time: 5.19311
Timestep Consumption Time: 2.03906
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.23217

Cumulative Model Updates: 29136
Cumulative Timesteps: 243326027

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.09064
Policy Entropy: 1.28979
Value Function Loss: 0.01761

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.12074
Value Function Update Magnitude: 0.19467

Collected Steps per Second: 10163.13375
Overall Steps per Second: 7070.27676

Timestep Collection Time: 4.92092
Timestep Consumption Time: 2.15263
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.07356

Cumulative Model Updates: 29142
Cumulative Timesteps: 243376039

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.78811
Policy Entropy: 1.29330
Value Function Loss: 0.01764

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.12111
Value Function Update Magnitude: 0.20274

Collected Steps per Second: 9859.63821
Overall Steps per Second: 7072.17303

Timestep Collection Time: 5.07219
Timestep Consumption Time: 1.99918
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.07138

Cumulative Model Updates: 29148
Cumulative Timesteps: 243426049

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.57651
Policy Entropy: 1.29375
Value Function Loss: 0.01860

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.12553
Value Function Update Magnitude: 0.20580

Collected Steps per Second: 10079.54604
Overall Steps per Second: 7164.38814

Timestep Collection Time: 4.96153
Timestep Consumption Time: 2.01883
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.98036

Cumulative Model Updates: 29154
Cumulative Timesteps: 243476059

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.21459
Policy Entropy: 1.29431
Value Function Loss: 0.01860

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.12361
Value Function Update Magnitude: 0.20539

Collected Steps per Second: 10331.68666
Overall Steps per Second: 7176.65175

Timestep Collection Time: 4.84297
Timestep Consumption Time: 2.12909
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.97205

Cumulative Model Updates: 29160
Cumulative Timesteps: 243526095

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.72063
Policy Entropy: 1.29200
Value Function Loss: 0.01898

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06987
Policy Update Magnitude: 0.12641
Value Function Update Magnitude: 0.20090

Collected Steps per Second: 9897.44521
Overall Steps per Second: 6991.16865

Timestep Collection Time: 5.05241
Timestep Consumption Time: 2.10032
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 7.15274

Cumulative Model Updates: 29166
Cumulative Timesteps: 243576101

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.58459
Policy Entropy: 1.29046
Value Function Loss: 0.01888

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06756
Policy Update Magnitude: 0.12455
Value Function Update Magnitude: 0.19539

Collected Steps per Second: 9673.38681
Overall Steps per Second: 6957.07740

Timestep Collection Time: 5.17192
Timestep Consumption Time: 2.01932
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 7.19124

Cumulative Model Updates: 29172
Cumulative Timesteps: 243626131

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.55055
Policy Entropy: 1.28809
Value Function Loss: 0.01985

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.12680
Value Function Update Magnitude: 0.19127

Collected Steps per Second: 10304.34089
Overall Steps per Second: 7168.26770

Timestep Collection Time: 4.85562
Timestep Consumption Time: 2.12431
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 6.97993

Cumulative Model Updates: 29178
Cumulative Timesteps: 243676165

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.48100
Policy Entropy: 1.28540
Value Function Loss: 0.01980

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.12516
Value Function Update Magnitude: 0.18957

Collected Steps per Second: 9702.00640
Overall Steps per Second: 6909.60016

Timestep Collection Time: 5.15656
Timestep Consumption Time: 2.08394
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.24051

Cumulative Model Updates: 29184
Cumulative Timesteps: 243726194

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.48419
Policy Entropy: 1.28863
Value Function Loss: 0.02039

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06391
Policy Update Magnitude: 0.12808
Value Function Update Magnitude: 0.19031

Collected Steps per Second: 9557.11830
Overall Steps per Second: 6853.21404

Timestep Collection Time: 5.23495
Timestep Consumption Time: 2.06542
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.30037

Cumulative Model Updates: 29190
Cumulative Timesteps: 243776225

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 243776225...
Checkpoint 243776225 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.21064
Policy Entropy: 1.29146
Value Function Loss: 0.02000

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.08236
Policy Update Magnitude: 0.13110
Value Function Update Magnitude: 0.20603

Collected Steps per Second: 10234.46931
Overall Steps per Second: 7189.64346

Timestep Collection Time: 4.88838
Timestep Consumption Time: 2.07024
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 6.95862

Cumulative Model Updates: 29196
Cumulative Timesteps: 243826255

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.39714
Policy Entropy: 1.29573
Value Function Loss: 0.02039

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.12989
Value Function Update Magnitude: 0.21321

Collected Steps per Second: 9765.24389
Overall Steps per Second: 7036.61225

Timestep Collection Time: 5.12358
Timestep Consumption Time: 1.98680
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 7.11038

Cumulative Model Updates: 29202
Cumulative Timesteps: 243876288

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.57892
Policy Entropy: 1.29607
Value Function Loss: 0.01925

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.12836
Value Function Update Magnitude: 0.21539

Collected Steps per Second: 9660.20574
Overall Steps per Second: 6942.41071

Timestep Collection Time: 5.17981
Timestep Consumption Time: 2.02778
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.20758

Cumulative Model Updates: 29208
Cumulative Timesteps: 243926326

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.62594
Policy Entropy: 1.29718
Value Function Loss: 0.01915

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06486
Policy Update Magnitude: 0.12888
Value Function Update Magnitude: 0.21120

Collected Steps per Second: 10184.76293
Overall Steps per Second: 7123.92077

Timestep Collection Time: 4.91155
Timestep Consumption Time: 2.11028
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.02184

Cumulative Model Updates: 29214
Cumulative Timesteps: 243976349

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.26730
Policy Entropy: 1.29600
Value Function Loss: 0.01820

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.12719
Value Function Update Magnitude: 0.20741

Collected Steps per Second: 10216.29614
Overall Steps per Second: 7191.36676

Timestep Collection Time: 4.89424
Timestep Consumption Time: 2.05868
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 6.95292

Cumulative Model Updates: 29220
Cumulative Timesteps: 244026350

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.17098
Policy Entropy: 1.29415
Value Function Loss: 0.01746

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.12340
Value Function Update Magnitude: 0.20052

Collected Steps per Second: 10291.51088
Overall Steps per Second: 7313.77400

Timestep Collection Time: 4.86236
Timestep Consumption Time: 1.97966
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 6.84202

Cumulative Model Updates: 29226
Cumulative Timesteps: 244076391

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.35561
Policy Entropy: 1.29426
Value Function Loss: 0.01817

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07191
Policy Update Magnitude: 0.12202
Value Function Update Magnitude: 0.18885

Collected Steps per Second: 10512.25891
Overall Steps per Second: 7334.64710

Timestep Collection Time: 4.75968
Timestep Consumption Time: 2.06205
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 6.82173

Cumulative Model Updates: 29232
Cumulative Timesteps: 244126426

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.74521
Policy Entropy: 1.29647
Value Function Loss: 0.01825

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.12205
Value Function Update Magnitude: 0.19330

Collected Steps per Second: 9686.41398
Overall Steps per Second: 6863.80630

Timestep Collection Time: 5.16424
Timestep Consumption Time: 2.12370
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.28794

Cumulative Model Updates: 29238
Cumulative Timesteps: 244176449

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.71880
Policy Entropy: 1.30283
Value Function Loss: 0.01896

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.05968
Policy Update Magnitude: 0.12460
Value Function Update Magnitude: 0.19709

Collected Steps per Second: 9680.45445
Overall Steps per Second: 6914.57423

Timestep Collection Time: 5.16732
Timestep Consumption Time: 2.06697
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.23428

Cumulative Model Updates: 29244
Cumulative Timesteps: 244226471

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.48282
Policy Entropy: 1.30420
Value Function Loss: 0.01960

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06424
Policy Update Magnitude: 0.12686
Value Function Update Magnitude: 0.21211

Collected Steps per Second: 10266.15878
Overall Steps per Second: 7209.73464

Timestep Collection Time: 4.87115
Timestep Consumption Time: 2.06503
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 6.93618

Cumulative Model Updates: 29250
Cumulative Timesteps: 244276479

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 244276479...
Checkpoint 244276479 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.94655
Policy Entropy: 1.30686
Value Function Loss: 0.01958

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06984
Policy Update Magnitude: 0.12791
Value Function Update Magnitude: 0.22560

Collected Steps per Second: 9892.83459
Overall Steps per Second: 6979.37739

Timestep Collection Time: 5.05487
Timestep Consumption Time: 2.11010
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.16497

Cumulative Model Updates: 29256
Cumulative Timesteps: 244326486

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.41748
Policy Entropy: 1.30596
Value Function Loss: 0.01934

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.06826
Policy Update Magnitude: 0.12428
Value Function Update Magnitude: 0.22392

Collected Steps per Second: 9687.41932
Overall Steps per Second: 6908.06437

Timestep Collection Time: 5.16557
Timestep Consumption Time: 2.07829
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.24385

Cumulative Model Updates: 29262
Cumulative Timesteps: 244376527

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.01791
Policy Entropy: 1.30806
Value Function Loss: 0.01774

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.06957
Policy Update Magnitude: 0.12270
Value Function Update Magnitude: 0.21288

Collected Steps per Second: 10272.28601
Overall Steps per Second: 7136.44183

Timestep Collection Time: 4.86883
Timestep Consumption Time: 2.13943
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.00825

Cumulative Model Updates: 29268
Cumulative Timesteps: 244426541

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.22928
Policy Entropy: 1.30600
Value Function Loss: 0.01851

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.12244
Value Function Update Magnitude: 0.20176

Collected Steps per Second: 9810.12330
Overall Steps per Second: 6989.57399

Timestep Collection Time: 5.09678
Timestep Consumption Time: 2.05674
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 7.15351

Cumulative Model Updates: 29274
Cumulative Timesteps: 244476541

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.85033
Policy Entropy: 1.31013
Value Function Loss: 0.01943

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.12228
Value Function Update Magnitude: 0.20605

Collected Steps per Second: 9757.23080
Overall Steps per Second: 6895.97614

Timestep Collection Time: 5.12666
Timestep Consumption Time: 2.12714
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.25380

Cumulative Model Updates: 29280
Cumulative Timesteps: 244526563

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.90589
Policy Entropy: 1.30598
Value Function Loss: 0.01960

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.12286
Value Function Update Magnitude: 0.21121

Collected Steps per Second: 10353.47658
Overall Steps per Second: 7220.27202

Timestep Collection Time: 4.83219
Timestep Consumption Time: 2.09691
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 6.92910

Cumulative Model Updates: 29286
Cumulative Timesteps: 244576593

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.78120
Policy Entropy: 1.30556
Value Function Loss: 0.01923

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.12143
Value Function Update Magnitude: 0.22991

Collected Steps per Second: 10070.90193
Overall Steps per Second: 7050.95722

Timestep Collection Time: 4.96698
Timestep Consumption Time: 2.12737
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 7.09436

Cumulative Model Updates: 29292
Cumulative Timesteps: 244626615

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.21632
Policy Entropy: 1.30278
Value Function Loss: 0.01776

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.12166
Value Function Update Magnitude: 0.22415

Collected Steps per Second: 9793.89894
Overall Steps per Second: 6974.59684

Timestep Collection Time: 5.10716
Timestep Consumption Time: 2.06444
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.17160

Cumulative Model Updates: 29298
Cumulative Timesteps: 244676634

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.35938
Policy Entropy: 1.30547
Value Function Loss: 0.01771

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.12257
Value Function Update Magnitude: 0.21441

Collected Steps per Second: 10298.81725
Overall Steps per Second: 7226.03053

Timestep Collection Time: 4.85531
Timestep Consumption Time: 2.06467
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.91998

Cumulative Model Updates: 29304
Cumulative Timesteps: 244726638

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.23861
Policy Entropy: 1.30993
Value Function Loss: 0.01784

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.12049
Value Function Update Magnitude: 0.20645

Collected Steps per Second: 9854.46267
Overall Steps per Second: 6962.18492

Timestep Collection Time: 5.07476
Timestep Consumption Time: 2.10819
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.18295

Cumulative Model Updates: 29310
Cumulative Timesteps: 244776647

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 244776647...
Checkpoint 244776647 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.34126
Policy Entropy: 1.30158
Value Function Loss: 0.01904

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.21009

Collected Steps per Second: 9549.80792
Overall Steps per Second: 6867.06901

Timestep Collection Time: 5.24031
Timestep Consumption Time: 2.04722
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.28753

Cumulative Model Updates: 29316
Cumulative Timesteps: 244826691

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.52144
Policy Entropy: 1.30392
Value Function Loss: 0.01860

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.12293
Value Function Update Magnitude: 0.21671

Collected Steps per Second: 10273.29190
Overall Steps per Second: 7170.40028

Timestep Collection Time: 4.86767
Timestep Consumption Time: 2.10642
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 6.97409

Cumulative Model Updates: 29322
Cumulative Timesteps: 244876698

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.78879
Policy Entropy: 1.30187
Value Function Loss: 0.01903

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.12407
Value Function Update Magnitude: 0.22076

Collected Steps per Second: 9917.10622
Overall Steps per Second: 7091.09093

Timestep Collection Time: 5.04401
Timestep Consumption Time: 2.01019
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.05420

Cumulative Model Updates: 29328
Cumulative Timesteps: 244926720

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.63395
Policy Entropy: 1.30438
Value Function Loss: 0.01833

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.12449
Value Function Update Magnitude: 0.20791

Collected Steps per Second: 9679.54390
Overall Steps per Second: 6909.08204

Timestep Collection Time: 5.16615
Timestep Consumption Time: 2.07157
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.23772

Cumulative Model Updates: 29334
Cumulative Timesteps: 244976726

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.17194
Policy Entropy: 1.30342
Value Function Loss: 0.01871

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06567
Policy Update Magnitude: 0.12307
Value Function Update Magnitude: 0.21734

Collected Steps per Second: 10360.16681
Overall Steps per Second: 7221.21454

Timestep Collection Time: 4.82927
Timestep Consumption Time: 2.09921
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 6.92847

Cumulative Model Updates: 29340
Cumulative Timesteps: 245026758

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.11762
Policy Entropy: 1.30430
Value Function Loss: 0.01889

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06102
Policy Update Magnitude: 0.12400
Value Function Update Magnitude: 0.21104

Collected Steps per Second: 9909.46095
Overall Steps per Second: 6996.74594

Timestep Collection Time: 5.04841
Timestep Consumption Time: 2.10163
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.15004

Cumulative Model Updates: 29346
Cumulative Timesteps: 245076785

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.58738
Policy Entropy: 1.30112
Value Function Loss: 0.01889

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.12562
Value Function Update Magnitude: 0.22563

Collected Steps per Second: 9697.16968
Overall Steps per Second: 6939.72394

Timestep Collection Time: 5.16017
Timestep Consumption Time: 2.05035
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.21052

Cumulative Model Updates: 29352
Cumulative Timesteps: 245126824

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.98160
Policy Entropy: 1.29775
Value Function Loss: 0.01924

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.12321
Value Function Update Magnitude: 0.21940

Collected Steps per Second: 10302.93912
Overall Steps per Second: 7166.12201

Timestep Collection Time: 4.85386
Timestep Consumption Time: 2.12467
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 6.97853

Cumulative Model Updates: 29358
Cumulative Timesteps: 245176833

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.52498
Policy Entropy: 1.29249
Value Function Loss: 0.01923

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.12047
Value Function Update Magnitude: 0.22586

Collected Steps per Second: 9826.70848
Overall Steps per Second: 6948.24069

Timestep Collection Time: 5.09123
Timestep Consumption Time: 2.10916
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 7.20038

Cumulative Model Updates: 29364
Cumulative Timesteps: 245226863

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.77170
Policy Entropy: 1.29917
Value Function Loss: 0.01893

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06563
Policy Update Magnitude: 0.12017
Value Function Update Magnitude: 0.22715

Collected Steps per Second: 9665.21692
Overall Steps per Second: 7011.89273

Timestep Collection Time: 5.17391
Timestep Consumption Time: 1.95783
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.13174

Cumulative Model Updates: 29370
Cumulative Timesteps: 245276870

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 245276870...
Checkpoint 245276870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.88511
Policy Entropy: 1.30008
Value Function Loss: 0.01867

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.12243
Value Function Update Magnitude: 0.21803

Collected Steps per Second: 10463.44422
Overall Steps per Second: 7316.82617

Timestep Collection Time: 4.77902
Timestep Consumption Time: 2.05523
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 6.83425

Cumulative Model Updates: 29376
Cumulative Timesteps: 245326875

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.99630
Policy Entropy: 1.29902
Value Function Loss: 0.01883

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06311
Policy Update Magnitude: 0.12305
Value Function Update Magnitude: 0.21078

Collected Steps per Second: 9768.45019
Overall Steps per Second: 6944.91573

Timestep Collection Time: 5.11985
Timestep Consumption Time: 2.08153
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.20138

Cumulative Model Updates: 29382
Cumulative Timesteps: 245376888

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.40567
Policy Entropy: 1.29671
Value Function Loss: 0.01854

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.12009
Value Function Update Magnitude: 0.19309

Collected Steps per Second: 9681.79521
Overall Steps per Second: 6943.85179

Timestep Collection Time: 5.16857
Timestep Consumption Time: 2.03795
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 7.20652

Cumulative Model Updates: 29388
Cumulative Timesteps: 245426929

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.59912
Policy Entropy: 1.29621
Value Function Loss: 0.01814

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.11751
Value Function Update Magnitude: 0.19037

Collected Steps per Second: 10620.03004
Overall Steps per Second: 7100.49892

Timestep Collection Time: 4.71082
Timestep Consumption Time: 2.33503
PPO Batch Consumption Time: 0.03217
Total Iteration Time: 7.04584

Cumulative Model Updates: 29394
Cumulative Timesteps: 245476958

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.02312
Policy Entropy: 1.30092
Value Function Loss: 0.01706

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.11593
Value Function Update Magnitude: 0.19120

Collected Steps per Second: 10257.06419
Overall Steps per Second: 7174.65059

Timestep Collection Time: 4.87781
Timestep Consumption Time: 2.09563
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 6.97344

Cumulative Model Updates: 29400
Cumulative Timesteps: 245526990

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.03766
Policy Entropy: 1.30113
Value Function Loss: 0.01659

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.11518
Value Function Update Magnitude: 0.18925

Collected Steps per Second: 9703.75794
Overall Steps per Second: 6980.39321

Timestep Collection Time: 5.15532
Timestep Consumption Time: 2.01132
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.16664

Cumulative Model Updates: 29406
Cumulative Timesteps: 245577016

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.16949
Policy Entropy: 1.30726
Value Function Loss: 0.01660

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.11348
Value Function Update Magnitude: 0.19995

Collected Steps per Second: 10633.24712
Overall Steps per Second: 7114.32222

Timestep Collection Time: 4.70280
Timestep Consumption Time: 2.32612
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.02892

Cumulative Model Updates: 29412
Cumulative Timesteps: 245627022

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.93182
Policy Entropy: 1.30331
Value Function Loss: 0.01817

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.11399
Value Function Update Magnitude: 0.20228

Collected Steps per Second: 10396.67379
Overall Steps per Second: 7241.58860

Timestep Collection Time: 4.81173
Timestep Consumption Time: 2.09642
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 6.90815

Cumulative Model Updates: 29418
Cumulative Timesteps: 245677048

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.07447
Policy Entropy: 1.30406
Value Function Loss: 0.01813

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.11944
Value Function Update Magnitude: 0.20516

Collected Steps per Second: 9764.98134
Overall Steps per Second: 6965.82016

Timestep Collection Time: 5.12474
Timestep Consumption Time: 2.05934
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 7.18408

Cumulative Model Updates: 29424
Cumulative Timesteps: 245727091

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.92235
Policy Entropy: 1.30329
Value Function Loss: 0.01791

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.11914
Value Function Update Magnitude: 0.20163

Collected Steps per Second: 9610.07222
Overall Steps per Second: 6911.70155

Timestep Collection Time: 5.20558
Timestep Consumption Time: 2.03229
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.23787

Cumulative Model Updates: 29430
Cumulative Timesteps: 245777117

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 245777117...
Checkpoint 245777117 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.45742
Policy Entropy: 1.30900
Value Function Loss: 0.01769

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.11578
Value Function Update Magnitude: 0.19891

Collected Steps per Second: 10224.06178
Overall Steps per Second: 7148.46723

Timestep Collection Time: 4.89052
Timestep Consumption Time: 2.10412
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 6.99465

Cumulative Model Updates: 29436
Cumulative Timesteps: 245827118

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.46133
Policy Entropy: 1.29965
Value Function Loss: 0.01866

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07371
Policy Update Magnitude: 0.12064
Value Function Update Magnitude: 0.19988

Collected Steps per Second: 9753.70767
Overall Steps per Second: 6992.39267

Timestep Collection Time: 5.12995
Timestep Consumption Time: 2.02583
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 7.15578

Cumulative Model Updates: 29442
Cumulative Timesteps: 245877154

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.63295
Policy Entropy: 1.29691
Value Function Loss: 0.02006

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.12485
Value Function Update Magnitude: 0.21024

Collected Steps per Second: 9861.61688
Overall Steps per Second: 7050.48663

Timestep Collection Time: 5.07128
Timestep Consumption Time: 2.02199
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.09327

Cumulative Model Updates: 29448
Cumulative Timesteps: 245927165

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.46048
Policy Entropy: 1.29298
Value Function Loss: 0.01971

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.12409
Value Function Update Magnitude: 0.22438

Collected Steps per Second: 10219.36925
Overall Steps per Second: 7208.40910

Timestep Collection Time: 4.89375
Timestep Consumption Time: 2.04412
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 6.93787

Cumulative Model Updates: 29454
Cumulative Timesteps: 245977176

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.35283
Policy Entropy: 1.29995
Value Function Loss: 0.01963

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06123
Policy Update Magnitude: 0.12264
Value Function Update Magnitude: 0.21887

Collected Steps per Second: 9675.70403
Overall Steps per Second: 6899.14987

Timestep Collection Time: 5.16924
Timestep Consumption Time: 2.08035
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.24959

Cumulative Model Updates: 29460
Cumulative Timesteps: 246027192

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.97088
Policy Entropy: 1.30372
Value Function Loss: 0.01887

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.05626
Policy Update Magnitude: 0.12267
Value Function Update Magnitude: 0.22338

Collected Steps per Second: 9939.26520
Overall Steps per Second: 7091.99202

Timestep Collection Time: 5.03297
Timestep Consumption Time: 2.02062
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 7.05359

Cumulative Model Updates: 29466
Cumulative Timesteps: 246077216

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.70585
Policy Entropy: 1.30185
Value Function Loss: 0.01884

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.12370
Value Function Update Magnitude: 0.22445

Collected Steps per Second: 10380.45163
Overall Steps per Second: 7170.72331

Timestep Collection Time: 4.81819
Timestep Consumption Time: 2.15670
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 6.97489

Cumulative Model Updates: 29472
Cumulative Timesteps: 246127231

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.61584
Policy Entropy: 1.29787
Value Function Loss: 0.01942

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.12342
Value Function Update Magnitude: 0.22587

Collected Steps per Second: 10730.31753
Overall Steps per Second: 7419.78431

Timestep Collection Time: 4.66091
Timestep Consumption Time: 2.07959
PPO Batch Consumption Time: 0.02469
Total Iteration Time: 6.74049

Cumulative Model Updates: 29478
Cumulative Timesteps: 246177244

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.65646
Policy Entropy: 1.29888
Value Function Loss: 0.01945

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.06464
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.23082

Collected Steps per Second: 10093.19140
Overall Steps per Second: 7160.49542

Timestep Collection Time: 4.95413
Timestep Consumption Time: 2.02904
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 6.98318

Cumulative Model Updates: 29484
Cumulative Timesteps: 246227247

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.47777
Policy Entropy: 1.30195
Value Function Loss: 0.01962

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.05708
Policy Update Magnitude: 0.12344
Value Function Update Magnitude: 0.22880

Collected Steps per Second: 10304.09157
Overall Steps per Second: 7226.39579

Timestep Collection Time: 4.85380
Timestep Consumption Time: 2.06722
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.92102

Cumulative Model Updates: 29490
Cumulative Timesteps: 246277261

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 246277261...
Checkpoint 246277261 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.10243
Policy Entropy: 1.30167
Value Function Loss: 0.01981

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.12425
Value Function Update Magnitude: 0.21658

Collected Steps per Second: 10151.35099
Overall Steps per Second: 7143.07185

Timestep Collection Time: 4.92654
Timestep Consumption Time: 2.07479
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.00133

Cumulative Model Updates: 29496
Cumulative Timesteps: 246327272

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.32283
Policy Entropy: 1.29745
Value Function Loss: 0.02004

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.12673
Value Function Update Magnitude: 0.21921

Collected Steps per Second: 9814.80980
Overall Steps per Second: 7046.83552

Timestep Collection Time: 5.09465
Timestep Consumption Time: 2.00116
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.09581

Cumulative Model Updates: 29502
Cumulative Timesteps: 246377275

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.56869
Policy Entropy: 1.29537
Value Function Loss: 0.02074

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.07523
Policy Update Magnitude: 0.13063
Value Function Update Magnitude: 0.22589

Collected Steps per Second: 9779.81290
Overall Steps per Second: 7028.51650

Timestep Collection Time: 5.11492
Timestep Consumption Time: 2.00223
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.11715

Cumulative Model Updates: 29508
Cumulative Timesteps: 246427298

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.92337
Policy Entropy: 1.30026
Value Function Loss: 0.02046

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.12823
Value Function Update Magnitude: 0.22485

Collected Steps per Second: 10124.82689
Overall Steps per Second: 7115.18825

Timestep Collection Time: 4.94181
Timestep Consumption Time: 2.09033
PPO Batch Consumption Time: 0.02811
Total Iteration Time: 7.03214

Cumulative Model Updates: 29514
Cumulative Timesteps: 246477333

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.30584
Policy Entropy: 1.30325
Value Function Loss: 0.02023

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.12745
Value Function Update Magnitude: 0.22056

Collected Steps per Second: 9841.82506
Overall Steps per Second: 7009.69328

Timestep Collection Time: 5.08320
Timestep Consumption Time: 2.05377
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.13697

Cumulative Model Updates: 29520
Cumulative Timesteps: 246527361

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.63613
Policy Entropy: 1.30374
Value Function Loss: 0.01965

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.12548
Value Function Update Magnitude: 0.22135

Collected Steps per Second: 9690.57396
Overall Steps per Second: 6952.22909

Timestep Collection Time: 5.15965
Timestep Consumption Time: 2.03228
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 7.19194

Cumulative Model Updates: 29526
Cumulative Timesteps: 246577361

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.36290
Policy Entropy: 1.30302
Value Function Loss: 0.01931

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.12431
Value Function Update Magnitude: 0.22155

Collected Steps per Second: 10414.65430
Overall Steps per Second: 7236.41978

Timestep Collection Time: 4.80275
Timestep Consumption Time: 2.10937
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 6.91212

Cumulative Model Updates: 29532
Cumulative Timesteps: 246627380

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.34983
Policy Entropy: 1.30376
Value Function Loss: 0.01894

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.12589
Value Function Update Magnitude: 0.21286

Collected Steps per Second: 9898.68200
Overall Steps per Second: 7070.08839

Timestep Collection Time: 5.05360
Timestep Consumption Time: 2.02184
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.07544

Cumulative Model Updates: 29538
Cumulative Timesteps: 246677404

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.69562
Policy Entropy: 1.30660
Value Function Loss: 0.01884

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.12550
Value Function Update Magnitude: 0.21040

Collected Steps per Second: 9757.33033
Overall Steps per Second: 6982.84710

Timestep Collection Time: 5.12835
Timestep Consumption Time: 2.03764
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 7.16599

Cumulative Model Updates: 29544
Cumulative Timesteps: 246727443

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.47636
Policy Entropy: 1.29780
Value Function Loss: 0.01901

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.12217
Value Function Update Magnitude: 0.20754

Collected Steps per Second: 10473.87733
Overall Steps per Second: 7284.15191

Timestep Collection Time: 4.77579
Timestep Consumption Time: 2.09131
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 6.86710

Cumulative Model Updates: 29550
Cumulative Timesteps: 246777464

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 246777464...
Checkpoint 246777464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.61347
Policy Entropy: 1.30125
Value Function Loss: 0.01868

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.12139
Value Function Update Magnitude: 0.21042

Collected Steps per Second: 9813.86169
Overall Steps per Second: 6993.84509

Timestep Collection Time: 5.09718
Timestep Consumption Time: 2.05525
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.15243

Cumulative Model Updates: 29556
Cumulative Timesteps: 246827487

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.53957
Policy Entropy: 1.29943
Value Function Loss: 0.01865

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06460
Policy Update Magnitude: 0.12305
Value Function Update Magnitude: 0.20545

Collected Steps per Second: 9697.54738
Overall Steps per Second: 6931.27629

Timestep Collection Time: 5.15646
Timestep Consumption Time: 2.05794
PPO Batch Consumption Time: 0.02884
Total Iteration Time: 7.21440

Cumulative Model Updates: 29562
Cumulative Timesteps: 246877492

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.59676
Policy Entropy: 1.30277
Value Function Loss: 0.01851

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06136
Policy Update Magnitude: 0.12269
Value Function Update Magnitude: 0.20090

Collected Steps per Second: 10246.57259
Overall Steps per Second: 7159.61933

Timestep Collection Time: 4.88114
Timestep Consumption Time: 2.10456
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 6.98571

Cumulative Model Updates: 29568
Cumulative Timesteps: 246927507

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.02298
Policy Entropy: 1.29618
Value Function Loss: 0.01860

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.12631
Value Function Update Magnitude: 0.20171

Collected Steps per Second: 9902.36628
Overall Steps per Second: 6981.61077

Timestep Collection Time: 5.05132
Timestep Consumption Time: 2.11322
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.16454

Cumulative Model Updates: 29574
Cumulative Timesteps: 246977527

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.29769
Policy Entropy: 1.29580
Value Function Loss: 0.01788

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.12291
Value Function Update Magnitude: 0.20524

Collected Steps per Second: 9692.25943
Overall Steps per Second: 6917.36760

Timestep Collection Time: 5.16185
Timestep Consumption Time: 2.07067
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.23252

Cumulative Model Updates: 29580
Cumulative Timesteps: 247027557

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.21859
Policy Entropy: 1.29314
Value Function Loss: 0.01821

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.12248
Value Function Update Magnitude: 0.21444

Collected Steps per Second: 10297.22391
Overall Steps per Second: 6914.98706

Timestep Collection Time: 4.85743
Timestep Consumption Time: 2.37585
PPO Batch Consumption Time: 0.02939
Total Iteration Time: 7.23327

Cumulative Model Updates: 29586
Cumulative Timesteps: 247077575

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.85576
Policy Entropy: 1.29369
Value Function Loss: 0.01811

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.12249
Value Function Update Magnitude: 0.21709

Collected Steps per Second: 10574.27404
Overall Steps per Second: 7347.38148

Timestep Collection Time: 4.73139
Timestep Consumption Time: 2.07798
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.80936

Cumulative Model Updates: 29592
Cumulative Timesteps: 247127606

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.49098
Policy Entropy: 1.29656
Value Function Loss: 0.01766

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.12110
Value Function Update Magnitude: 0.21446

Collected Steps per Second: 10192.26810
Overall Steps per Second: 7200.30306

Timestep Collection Time: 4.90990
Timestep Consumption Time: 2.04023
PPO Batch Consumption Time: 0.02961
Total Iteration Time: 6.95012

Cumulative Model Updates: 29598
Cumulative Timesteps: 247177649

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.87210
Policy Entropy: 1.30122
Value Function Loss: 0.01760

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.12148
Value Function Update Magnitude: 0.21571

Collected Steps per Second: 9737.83152
Overall Steps per Second: 6973.74498

Timestep Collection Time: 5.13626
Timestep Consumption Time: 2.03579
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.17204

Cumulative Model Updates: 29604
Cumulative Timesteps: 247227665

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.46884
Policy Entropy: 1.29766
Value Function Loss: 0.01851

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.12254
Value Function Update Magnitude: 0.22549

Collected Steps per Second: 10295.91796
Overall Steps per Second: 7325.12155

Timestep Collection Time: 4.86086
Timestep Consumption Time: 1.97138
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 6.83224

Cumulative Model Updates: 29610
Cumulative Timesteps: 247277712

Timesteps Collected: 50047
--------END ITERATION REPORT--------


Saving checkpoint 247277712...
Checkpoint 247277712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.03432
Policy Entropy: 1.29412
Value Function Loss: 0.01823

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.12553
Value Function Update Magnitude: 0.22892

Collected Steps per Second: 10118.29509
Overall Steps per Second: 7165.11647

Timestep Collection Time: 4.94569
Timestep Consumption Time: 2.03842
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 6.98412

Cumulative Model Updates: 29616
Cumulative Timesteps: 247327754

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.18791
Policy Entropy: 1.29401
Value Function Loss: 0.01863

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.13196
Value Function Update Magnitude: 0.24068

Collected Steps per Second: 9728.79348
Overall Steps per Second: 6958.38276

Timestep Collection Time: 5.14134
Timestep Consumption Time: 2.04697
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.18831

Cumulative Model Updates: 29622
Cumulative Timesteps: 247377773

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.07705
Policy Entropy: 1.29661
Value Function Loss: 0.01702

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.12733
Value Function Update Magnitude: 0.22481

Collected Steps per Second: 10385.96818
Overall Steps per Second: 7221.40381

Timestep Collection Time: 4.81756
Timestep Consumption Time: 2.11115
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 6.92871

Cumulative Model Updates: 29628
Cumulative Timesteps: 247427808

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.46480
Policy Entropy: 1.29595
Value Function Loss: 0.01849

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06271
Policy Update Magnitude: 0.12704
Value Function Update Magnitude: 0.22077

Collected Steps per Second: 9805.90662
Overall Steps per Second: 6922.17670

Timestep Collection Time: 5.10101
Timestep Consumption Time: 2.12504
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.22605

Cumulative Model Updates: 29634
Cumulative Timesteps: 247477828

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.73809
Policy Entropy: 1.29600
Value Function Loss: 0.01876

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.06725
Policy Update Magnitude: 0.13164
Value Function Update Magnitude: 0.22454

Collected Steps per Second: 9654.28218
Overall Steps per Second: 6927.96358

Timestep Collection Time: 5.18050
Timestep Consumption Time: 2.03865
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.21915

Cumulative Model Updates: 29640
Cumulative Timesteps: 247527842

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.57433
Policy Entropy: 1.29818
Value Function Loss: 0.01922

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.13270
Value Function Update Magnitude: 0.22908

Collected Steps per Second: 10233.92610
Overall Steps per Second: 7156.45379

Timestep Collection Time: 4.88698
Timestep Consumption Time: 2.10154
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 6.98852

Cumulative Model Updates: 29646
Cumulative Timesteps: 247577855

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.31038
Policy Entropy: 1.30157
Value Function Loss: 0.01929

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.06856
Policy Update Magnitude: 0.12561
Value Function Update Magnitude: 0.22231

Collected Steps per Second: 9880.79696
Overall Steps per Second: 7073.53614

Timestep Collection Time: 5.06184
Timestep Consumption Time: 2.00888
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.07072

Cumulative Model Updates: 29652
Cumulative Timesteps: 247627870

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.91571
Policy Entropy: 1.29941
Value Function Loss: 0.01896

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06663
Policy Update Magnitude: 0.12420
Value Function Update Magnitude: 0.21976

Collected Steps per Second: 9701.66765
Overall Steps per Second: 6941.07950

Timestep Collection Time: 5.15623
Timestep Consumption Time: 2.05072
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 7.20695

Cumulative Model Updates: 29658
Cumulative Timesteps: 247677894

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.85496
Policy Entropy: 1.29964
Value Function Loss: 0.01902

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.12636
Value Function Update Magnitude: 0.24225

Collected Steps per Second: 10469.81389
Overall Steps per Second: 7248.34733

Timestep Collection Time: 4.77697
Timestep Consumption Time: 2.12308
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 6.90006

Cumulative Model Updates: 29664
Cumulative Timesteps: 247727908

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.00988
Policy Entropy: 1.29701
Value Function Loss: 0.01855

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.12355
Value Function Update Magnitude: 0.24073

Collected Steps per Second: 9831.06998
Overall Steps per Second: 6933.77451

Timestep Collection Time: 5.08866
Timestep Consumption Time: 2.12631
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.21497

Cumulative Model Updates: 29670
Cumulative Timesteps: 247777935

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 247777935...
Checkpoint 247777935 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.00641
Policy Entropy: 1.29546
Value Function Loss: 0.01964

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.12539
Value Function Update Magnitude: 0.25655

Collected Steps per Second: 9671.87098
Overall Steps per Second: 6913.36187

Timestep Collection Time: 5.17346
Timestep Consumption Time: 2.06427
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.23772

Cumulative Model Updates: 29676
Cumulative Timesteps: 247827972

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18290
Policy Entropy: 1.29160
Value Function Loss: 0.01912

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06982
Policy Update Magnitude: 0.12541
Value Function Update Magnitude: 0.25821

Collected Steps per Second: 10315.67781
Overall Steps per Second: 7169.45996

Timestep Collection Time: 4.84864
Timestep Consumption Time: 2.12776
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 6.97640

Cumulative Model Updates: 29682
Cumulative Timesteps: 247877989

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.18263
Policy Entropy: 1.29164
Value Function Loss: 0.01956

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.06712
Policy Update Magnitude: 0.12613
Value Function Update Magnitude: 0.24878

Collected Steps per Second: 9666.83130
Overall Steps per Second: 6927.50169

Timestep Collection Time: 5.17408
Timestep Consumption Time: 2.04598
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.22006

Cumulative Model Updates: 29688
Cumulative Timesteps: 247928006

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.03441
Policy Entropy: 1.29100
Value Function Loss: 0.01925

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.12366
Value Function Update Magnitude: 0.24237

Collected Steps per Second: 9463.51268
Overall Steps per Second: 6864.89645

Timestep Collection Time: 5.28345
Timestep Consumption Time: 1.99998
PPO Batch Consumption Time: 0.02843
Total Iteration Time: 7.28343

Cumulative Model Updates: 29694
Cumulative Timesteps: 247978006

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.82813
Policy Entropy: 1.29136
Value Function Loss: 0.01993

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.12718
Value Function Update Magnitude: 0.23721

Collected Steps per Second: 10488.77654
Overall Steps per Second: 7289.28585

Timestep Collection Time: 4.77015
Timestep Consumption Time: 2.09376
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 6.86391

Cumulative Model Updates: 29700
Cumulative Timesteps: 248028039

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.32065
Policy Entropy: 1.28855
Value Function Loss: 0.01943

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.13283
Value Function Update Magnitude: 0.22950

Collected Steps per Second: 10248.07288
Overall Steps per Second: 7255.80422

Timestep Collection Time: 4.88141
Timestep Consumption Time: 2.01307
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 6.89448

Cumulative Model Updates: 29706
Cumulative Timesteps: 248078064

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.34454
Policy Entropy: 1.28460
Value Function Loss: 0.01947

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.13256
Value Function Update Magnitude: 0.22472

Collected Steps per Second: 9856.90052
Overall Steps per Second: 7006.96843

Timestep Collection Time: 5.07381
Timestep Consumption Time: 2.06366
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.13747

Cumulative Model Updates: 29712
Cumulative Timesteps: 248128076

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.24031
Policy Entropy: 1.28683
Value Function Loss: 0.01959

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.12830
Value Function Update Magnitude: 0.22081

Collected Steps per Second: 10390.29101
Overall Steps per Second: 7227.22111

Timestep Collection Time: 4.81517
Timestep Consumption Time: 2.10741
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 6.92258

Cumulative Model Updates: 29718
Cumulative Timesteps: 248178107

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.67062
Policy Entropy: 1.29176
Value Function Loss: 0.01950

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.12499
Value Function Update Magnitude: 0.23136

Collected Steps per Second: 9843.38839
Overall Steps per Second: 6947.07192

Timestep Collection Time: 5.08148
Timestep Consumption Time: 2.11853
PPO Batch Consumption Time: 0.02811
Total Iteration Time: 7.20001

Cumulative Model Updates: 29724
Cumulative Timesteps: 248228126

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.31898
Policy Entropy: 1.29372
Value Function Loss: 0.02018

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.12699
Value Function Update Magnitude: 0.22957

Collected Steps per Second: 10190.16265
Overall Steps per Second: 7198.30947

Timestep Collection Time: 4.90964
Timestep Consumption Time: 2.04061
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 6.95024

Cumulative Model Updates: 29730
Cumulative Timesteps: 248278156

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 248278156...
Checkpoint 248278156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.55649
Policy Entropy: 1.28459
Value Function Loss: 0.01975

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.12915
Value Function Update Magnitude: 0.21718

Collected Steps per Second: 10342.24330
Overall Steps per Second: 7227.78412

Timestep Collection Time: 4.83860
Timestep Consumption Time: 2.08496
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 6.92356

Cumulative Model Updates: 29736
Cumulative Timesteps: 248328198

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.87254
Policy Entropy: 1.28816
Value Function Loss: 0.02074

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.12487
Value Function Update Magnitude: 0.21351

Collected Steps per Second: 9693.16225
Overall Steps per Second: 6912.73145

Timestep Collection Time: 5.15931
Timestep Consumption Time: 2.07517
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.23448

Cumulative Model Updates: 29742
Cumulative Timesteps: 248378208

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.46067
Policy Entropy: 1.29138
Value Function Loss: 0.01971

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.12423
Value Function Update Magnitude: 0.21530

Collected Steps per Second: 9878.92992
Overall Steps per Second: 7013.68210

Timestep Collection Time: 5.06168
Timestep Consumption Time: 2.06781
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.12949

Cumulative Model Updates: 29748
Cumulative Timesteps: 248428212

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.15575
Policy Entropy: 1.29738
Value Function Loss: 0.01949

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.12316
Value Function Update Magnitude: 0.22245

Collected Steps per Second: 10444.70989
Overall Steps per Second: 7249.75750

Timestep Collection Time: 4.79104
Timestep Consumption Time: 2.11140
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 6.90244

Cumulative Model Updates: 29754
Cumulative Timesteps: 248478253

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.38465
Policy Entropy: 1.29741
Value Function Loss: 0.01832

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.12405
Value Function Update Magnitude: 0.21872

Collected Steps per Second: 9981.96211
Overall Steps per Second: 7016.16300

Timestep Collection Time: 5.01224
Timestep Consumption Time: 2.11872
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 7.13096

Cumulative Model Updates: 29760
Cumulative Timesteps: 248528285

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.20825
Policy Entropy: 1.29040
Value Function Loss: 0.01802

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.21164

Collected Steps per Second: 9716.36718
Overall Steps per Second: 6960.09520

Timestep Collection Time: 5.14719
Timestep Consumption Time: 2.03834
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.18553

Cumulative Model Updates: 29766
Cumulative Timesteps: 248578297

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.24129
Policy Entropy: 1.28924
Value Function Loss: 0.01732

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07179
Policy Update Magnitude: 0.12005
Value Function Update Magnitude: 0.20342

Collected Steps per Second: 10287.71441
Overall Steps per Second: 7187.36340

Timestep Collection Time: 4.86172
Timestep Consumption Time: 2.09716
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 6.95888

Cumulative Model Updates: 29772
Cumulative Timesteps: 248628313

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.87728
Policy Entropy: 1.28549
Value Function Loss: 0.01750

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.11938
Value Function Update Magnitude: 0.19892

Collected Steps per Second: 9779.17262
Overall Steps per Second: 6914.84302

Timestep Collection Time: 5.11567
Timestep Consumption Time: 2.11906
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 7.23473

Cumulative Model Updates: 29778
Cumulative Timesteps: 248678340

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.34197
Policy Entropy: 1.28588
Value Function Loss: 0.01799

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.12094
Value Function Update Magnitude: 0.19109

Collected Steps per Second: 9773.39321
Overall Steps per Second: 6939.33472

Timestep Collection Time: 5.11920
Timestep Consumption Time: 2.09071
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.20991

Cumulative Model Updates: 29784
Cumulative Timesteps: 248728372

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.85368
Policy Entropy: 1.28707
Value Function Loss: 0.01866

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.11910
Value Function Update Magnitude: 0.19370

Collected Steps per Second: 10318.28750
Overall Steps per Second: 7260.86252

Timestep Collection Time: 4.84770
Timestep Consumption Time: 2.04129
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 6.88899

Cumulative Model Updates: 29790
Cumulative Timesteps: 248778392

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 248778392...
Checkpoint 248778392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.60420
Policy Entropy: 1.28819
Value Function Loss: 0.01833

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.11885
Value Function Update Magnitude: 0.18851

Collected Steps per Second: 9815.12593
Overall Steps per Second: 6950.84352

Timestep Collection Time: 5.09876
Timestep Consumption Time: 2.10108
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.19985

Cumulative Model Updates: 29796
Cumulative Timesteps: 248828437

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.07332
Policy Entropy: 1.29786
Value Function Loss: 0.01837

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.11817
Value Function Update Magnitude: 0.18692

Collected Steps per Second: 10010.85137
Overall Steps per Second: 7116.69715

Timestep Collection Time: 4.99828
Timestep Consumption Time: 2.03265
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.03093

Cumulative Model Updates: 29802
Cumulative Timesteps: 248878474

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.15367
Policy Entropy: 1.30295
Value Function Loss: 0.01823

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.12256
Value Function Update Magnitude: 0.19423

Collected Steps per Second: 10412.56377
Overall Steps per Second: 7025.29907

Timestep Collection Time: 4.80525
Timestep Consumption Time: 2.31686
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 7.12212

Cumulative Model Updates: 29808
Cumulative Timesteps: 248928509

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.70673
Policy Entropy: 1.29768
Value Function Loss: 0.01857

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.12343
Value Function Update Magnitude: 0.19927

Collected Steps per Second: 10248.16520
Overall Steps per Second: 7139.58730

Timestep Collection Time: 4.88234
Timestep Consumption Time: 2.12577
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.00811

Cumulative Model Updates: 29814
Cumulative Timesteps: 248978544

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93153
Policy Entropy: 1.29979
Value Function Loss: 0.01916

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.12418
Value Function Update Magnitude: 0.19584

Collected Steps per Second: 9792.51827
Overall Steps per Second: 6985.46452

Timestep Collection Time: 5.10870
Timestep Consumption Time: 2.05289
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.16159

Cumulative Model Updates: 29820
Cumulative Timesteps: 249028571

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.97226
Policy Entropy: 1.29605
Value Function Loss: 0.01894

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.07932
Policy Update Magnitude: 0.12458
Value Function Update Magnitude: 0.19921

Collected Steps per Second: 9512.30149
Overall Steps per Second: 6765.74926

Timestep Collection Time: 5.25845
Timestep Consumption Time: 2.13467
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 7.39312

Cumulative Model Updates: 29826
Cumulative Timesteps: 249078591

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.26902
Policy Entropy: 1.29605
Value Function Loss: 0.01923

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.07354
Policy Update Magnitude: 0.12657
Value Function Update Magnitude: 0.20262

Collected Steps per Second: 10276.42453
Overall Steps per Second: 7172.42117

Timestep Collection Time: 4.86726
Timestep Consumption Time: 2.10640
PPO Batch Consumption Time: 0.02811
Total Iteration Time: 6.97366

Cumulative Model Updates: 29832
Cumulative Timesteps: 249128609

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.70558
Policy Entropy: 1.29972
Value Function Loss: 0.01788

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.07495
Policy Update Magnitude: 0.12667
Value Function Update Magnitude: 0.20765

Collected Steps per Second: 9964.18689
Overall Steps per Second: 7108.84471

Timestep Collection Time: 5.01837
Timestep Consumption Time: 2.01568
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.03405

Cumulative Model Updates: 29838
Cumulative Timesteps: 249178613

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.17245
Policy Entropy: 1.30061
Value Function Loss: 0.01816

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.12786
Value Function Update Magnitude: 0.20499

Collected Steps per Second: 9791.88863
Overall Steps per Second: 7010.42705

Timestep Collection Time: 5.10790
Timestep Consumption Time: 2.02661
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 7.13452

Cumulative Model Updates: 29844
Cumulative Timesteps: 249228629

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.32571
Policy Entropy: 1.30508
Value Function Loss: 0.01798

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07276
Policy Update Magnitude: 0.12610
Value Function Update Magnitude: 0.20052

Collected Steps per Second: 10326.37450
Overall Steps per Second: 7220.23943

Timestep Collection Time: 4.84391
Timestep Consumption Time: 2.08384
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 6.92775

Cumulative Model Updates: 29850
Cumulative Timesteps: 249278649

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 249278649...
Checkpoint 249278649 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.26941
Policy Entropy: 1.30085
Value Function Loss: 0.01888

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.12720
Value Function Update Magnitude: 0.19981

Collected Steps per Second: 9996.91431
Overall Steps per Second: 7059.30576

Timestep Collection Time: 5.00434
Timestep Consumption Time: 2.08247
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.08682

Cumulative Model Updates: 29856
Cumulative Timesteps: 249328677

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.14205
Policy Entropy: 1.29904
Value Function Loss: 0.01910

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.12672
Value Function Update Magnitude: 0.20057

Collected Steps per Second: 9737.39896
Overall Steps per Second: 6968.10992

Timestep Collection Time: 5.13885
Timestep Consumption Time: 2.04230
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.18114

Cumulative Model Updates: 29862
Cumulative Timesteps: 249378716

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.39717
Policy Entropy: 1.30026
Value Function Loss: 0.01911

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.12183
Value Function Update Magnitude: 0.19835

Collected Steps per Second: 10327.05661
Overall Steps per Second: 7219.54663

Timestep Collection Time: 4.84310
Timestep Consumption Time: 2.08462
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 6.92772

Cumulative Model Updates: 29868
Cumulative Timesteps: 249428731

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.52266
Policy Entropy: 1.29981
Value Function Loss: 0.01859

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.11880
Value Function Update Magnitude: 0.19069

Collected Steps per Second: 9828.40690
Overall Steps per Second: 6982.29782

Timestep Collection Time: 5.09136
Timestep Consumption Time: 2.07533
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.16670

Cumulative Model Updates: 29874
Cumulative Timesteps: 249478771

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.33918
Policy Entropy: 1.29930
Value Function Loss: 0.01868

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06260
Policy Update Magnitude: 0.12115
Value Function Update Magnitude: 0.18879

Collected Steps per Second: 9573.52110
Overall Steps per Second: 6910.39227

Timestep Collection Time: 5.22639
Timestep Consumption Time: 2.01415
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.24054

Cumulative Model Updates: 29880
Cumulative Timesteps: 249528806

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.09348
Policy Entropy: 1.29339
Value Function Loss: 0.01827

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.12147
Value Function Update Magnitude: 0.18609

Collected Steps per Second: 10307.39945
Overall Steps per Second: 7178.32591

Timestep Collection Time: 4.85447
Timestep Consumption Time: 2.11609
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 6.97057

Cumulative Model Updates: 29886
Cumulative Timesteps: 249578843

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.79210
Policy Entropy: 1.29231
Value Function Loss: 0.01871

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.19248

Collected Steps per Second: 10172.63974
Overall Steps per Second: 7281.19533

Timestep Collection Time: 4.91642
Timestep Consumption Time: 1.95237
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 6.86879

Cumulative Model Updates: 29892
Cumulative Timesteps: 249628856

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.95697
Policy Entropy: 1.29482
Value Function Loss: 0.01836

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.12079
Value Function Update Magnitude: 0.19509

Collected Steps per Second: 9767.49744
Overall Steps per Second: 6928.13594

Timestep Collection Time: 5.12096
Timestep Consumption Time: 2.09873
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.21969

Cumulative Model Updates: 29898
Cumulative Timesteps: 249678875

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.37836
Policy Entropy: 1.29851
Value Function Loss: 0.01859

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.11818
Value Function Update Magnitude: 0.19372

Collected Steps per Second: 10564.33370
Overall Steps per Second: 7311.67487

Timestep Collection Time: 4.73698
Timestep Consumption Time: 2.10728
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 6.84426

Cumulative Model Updates: 29904
Cumulative Timesteps: 249728918

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.25252
Policy Entropy: 1.29799
Value Function Loss: 0.01926

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.11948
Value Function Update Magnitude: 0.19101

Collected Steps per Second: 9937.56271
Overall Steps per Second: 6989.61070

Timestep Collection Time: 5.03302
Timestep Consumption Time: 2.12274
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.15576

Cumulative Model Updates: 29910
Cumulative Timesteps: 249778934

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 249778934...
Checkpoint 249778934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.96704
Policy Entropy: 1.29964
Value Function Loss: 0.01944

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.12159
Value Function Update Magnitude: 0.19358

Collected Steps per Second: 9780.41421
Overall Steps per Second: 6992.45669

Timestep Collection Time: 5.11379
Timestep Consumption Time: 2.03892
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.15271

Cumulative Model Updates: 29916
Cumulative Timesteps: 249828949

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.18279
Policy Entropy: 1.29630
Value Function Loss: 0.01902

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.13044
Value Function Update Magnitude: 0.19774

Collected Steps per Second: 10353.07961
Overall Steps per Second: 7231.03518

Timestep Collection Time: 4.83064
Timestep Consumption Time: 2.08566
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 6.91630

Cumulative Model Updates: 29922
Cumulative Timesteps: 249878961

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.13738
Policy Entropy: 1.28971
Value Function Loss: 0.01884

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.13028
Value Function Update Magnitude: 0.19466

Collected Steps per Second: 9760.88568
Overall Steps per Second: 6956.81850

Timestep Collection Time: 5.12382
Timestep Consumption Time: 2.06524
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 7.18906

Cumulative Model Updates: 29928
Cumulative Timesteps: 249928974

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.09003
Policy Entropy: 1.29203
Value Function Loss: 0.01830

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.12803
Value Function Update Magnitude: 0.19118

Collected Steps per Second: 9822.69958
Overall Steps per Second: 7009.46143

Timestep Collection Time: 5.09259
Timestep Consumption Time: 2.04391
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.13650

Cumulative Model Updates: 29934
Cumulative Timesteps: 249978997

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.95356
Policy Entropy: 1.29145
Value Function Loss: 0.01891

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.13694
Value Function Update Magnitude: 0.19587

Collected Steps per Second: 10425.53031
Overall Steps per Second: 7267.78053

Timestep Collection Time: 4.79860
Timestep Consumption Time: 2.08493
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 6.88353

Cumulative Model Updates: 29940
Cumulative Timesteps: 250029025

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.35712
Policy Entropy: 1.29344
Value Function Loss: 0.01878

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07157
Policy Update Magnitude: 0.14380
Value Function Update Magnitude: 0.20253

Collected Steps per Second: 9970.05489
Overall Steps per Second: 6996.94313

Timestep Collection Time: 5.01672
Timestep Consumption Time: 2.13168
PPO Batch Consumption Time: 0.03087
Total Iteration Time: 7.14841

Cumulative Model Updates: 29946
Cumulative Timesteps: 250079042

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.54894
Policy Entropy: 1.29391
Value Function Loss: 0.01960

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.13796
Value Function Update Magnitude: 0.20571

Collected Steps per Second: 9738.96794
Overall Steps per Second: 6991.37546

Timestep Collection Time: 5.13699
Timestep Consumption Time: 2.01882
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.15582

Cumulative Model Updates: 29952
Cumulative Timesteps: 250129071

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.59047
Policy Entropy: 1.29490
Value Function Loss: 0.01920

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.13328
Value Function Update Magnitude: 0.20499

Collected Steps per Second: 10478.50128
Overall Steps per Second: 7284.03151

Timestep Collection Time: 4.77473
Timestep Consumption Time: 2.09400
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 6.86872

Cumulative Model Updates: 29958
Cumulative Timesteps: 250179103

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.53565
Policy Entropy: 1.29986
Value Function Loss: 0.01961

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.13185
Value Function Update Magnitude: 0.20396

Collected Steps per Second: 9720.82966
Overall Steps per Second: 6901.29099

Timestep Collection Time: 5.14596
Timestep Consumption Time: 2.10239
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.24835

Cumulative Model Updates: 29964
Cumulative Timesteps: 250229126

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.26011
Policy Entropy: 1.29951
Value Function Loss: 0.01891

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06215
Policy Update Magnitude: 0.12887
Value Function Update Magnitude: 0.20725

Collected Steps per Second: 9780.49677
Overall Steps per Second: 7023.76404

Timestep Collection Time: 5.11242
Timestep Consumption Time: 2.00656
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.11897

Cumulative Model Updates: 29970
Cumulative Timesteps: 250279128

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 250279128...
Checkpoint 250279128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.44993
Policy Entropy: 1.29460
Value Function Loss: 0.01956

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.13308
Value Function Update Magnitude: 0.20556

Collected Steps per Second: 10400.59602
Overall Steps per Second: 7274.60674

Timestep Collection Time: 4.80819
Timestep Consumption Time: 2.06614
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 6.87432

Cumulative Model Updates: 29976
Cumulative Timesteps: 250329136

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.12339
Policy Entropy: 1.29532
Value Function Loss: 0.02112

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08038
Policy Update Magnitude: 0.13278
Value Function Update Magnitude: 0.20857

Collected Steps per Second: 9867.82165
Overall Steps per Second: 6995.54950

Timestep Collection Time: 5.07072
Timestep Consumption Time: 2.08197
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.15269

Cumulative Model Updates: 29982
Cumulative Timesteps: 250379173

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.34332
Policy Entropy: 1.29710
Value Function Loss: 0.02077

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.13264
Value Function Update Magnitude: 0.21112

Collected Steps per Second: 9689.38596
Overall Steps per Second: 7001.21017

Timestep Collection Time: 5.16225
Timestep Consumption Time: 1.98209
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.14434

Cumulative Model Updates: 29988
Cumulative Timesteps: 250429192

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.45025
Policy Entropy: 1.29894
Value Function Loss: 0.01950

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.12797
Value Function Update Magnitude: 0.20868

Collected Steps per Second: 10246.46539
Overall Steps per Second: 7139.57807

Timestep Collection Time: 4.88120
Timestep Consumption Time: 2.12412
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 7.00532

Cumulative Model Updates: 29994
Cumulative Timesteps: 250479207

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.94254
Policy Entropy: 1.29605
Value Function Loss: 0.01762

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07112
Policy Update Magnitude: 0.12464
Value Function Update Magnitude: 0.21357

Collected Steps per Second: 9804.88384
Overall Steps per Second: 7013.76287

Timestep Collection Time: 5.10164
Timestep Consumption Time: 2.03019
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.13184

Cumulative Model Updates: 30000
Cumulative Timesteps: 250529228

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.44075
Policy Entropy: 1.29843
Value Function Loss: 0.01805

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.12212
Value Function Update Magnitude: 0.23338

Collected Steps per Second: 9996.73733
Overall Steps per Second: 7111.21678

Timestep Collection Time: 5.00253
Timestep Consumption Time: 2.02988
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.03241

Cumulative Model Updates: 30006
Cumulative Timesteps: 250579237

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.48201
Policy Entropy: 1.29908
Value Function Loss: 0.01895

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.22142

Collected Steps per Second: 10349.84546
Overall Steps per Second: 7234.89167

Timestep Collection Time: 4.83283
Timestep Consumption Time: 2.08075
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 6.91358

Cumulative Model Updates: 30012
Cumulative Timesteps: 250629256

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.75031
Policy Entropy: 1.30234
Value Function Loss: 0.01854

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06164
Policy Update Magnitude: 0.12261
Value Function Update Magnitude: 0.23712

Collected Steps per Second: 9901.09588
Overall Steps per Second: 7064.86807

Timestep Collection Time: 5.05096
Timestep Consumption Time: 2.02773
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.07869

Cumulative Model Updates: 30018
Cumulative Timesteps: 250679266

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.15876
Policy Entropy: 1.29429
Value Function Loss: 0.01889

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.23138

Collected Steps per Second: 9733.63285
Overall Steps per Second: 7022.51711

Timestep Collection Time: 5.13960
Timestep Consumption Time: 1.98420
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.12380

Cumulative Model Updates: 30024
Cumulative Timesteps: 250729293

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.56773
Policy Entropy: 1.29831
Value Function Loss: 0.01919

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.07736
Policy Update Magnitude: 0.12344
Value Function Update Magnitude: 0.24199

Collected Steps per Second: 10421.11495
Overall Steps per Second: 7196.41144

Timestep Collection Time: 4.79997
Timestep Consumption Time: 2.15086
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 6.95083

Cumulative Model Updates: 30030
Cumulative Timesteps: 250779314

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 250779314...
Checkpoint 250779314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.58907
Policy Entropy: 1.29460
Value Function Loss: 0.02041

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.12453
Value Function Update Magnitude: 0.22403

Collected Steps per Second: 9883.97536
Overall Steps per Second: 7026.10722

Timestep Collection Time: 5.06264
Timestep Consumption Time: 2.05923
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 7.12187

Cumulative Model Updates: 30036
Cumulative Timesteps: 250829353

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.50265
Policy Entropy: 1.29572
Value Function Loss: 0.01929

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.12654
Value Function Update Magnitude: 0.21638

Collected Steps per Second: 9924.67680
Overall Steps per Second: 7089.97474

Timestep Collection Time: 5.04127
Timestep Consumption Time: 2.01559
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 7.05687

Cumulative Model Updates: 30042
Cumulative Timesteps: 250879386

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.00318
Policy Entropy: 1.29450
Value Function Loss: 0.01822

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.12298
Value Function Update Magnitude: 0.21578

Collected Steps per Second: 10470.47418
Overall Steps per Second: 7079.34608

Timestep Collection Time: 4.77810
Timestep Consumption Time: 2.28879
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.06690

Cumulative Model Updates: 30048
Cumulative Timesteps: 250929415

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.31800
Policy Entropy: 1.29431
Value Function Loss: 0.01836

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.12389
Value Function Update Magnitude: 0.20228

Collected Steps per Second: 10424.68412
Overall Steps per Second: 7315.98833

Timestep Collection Time: 4.79804
Timestep Consumption Time: 2.03877
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 6.83681

Cumulative Model Updates: 30054
Cumulative Timesteps: 250979433

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.90342
Policy Entropy: 1.29813
Value Function Loss: 0.01962

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.12457
Value Function Update Magnitude: 0.20477

Collected Steps per Second: 9888.15769
Overall Steps per Second: 7034.95726

Timestep Collection Time: 5.06110
Timestep Consumption Time: 2.05266
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.11376

Cumulative Model Updates: 30060
Cumulative Timesteps: 251029478

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.35024
Policy Entropy: 1.29763
Value Function Loss: 0.02079

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.12640
Value Function Update Magnitude: 0.20595

Collected Steps per Second: 9826.35476
Overall Steps per Second: 7052.85264

Timestep Collection Time: 5.09233
Timestep Consumption Time: 2.00253
PPO Batch Consumption Time: 0.02430
Total Iteration Time: 7.09486

Cumulative Model Updates: 30066
Cumulative Timesteps: 251079517

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.61050
Policy Entropy: 1.29664
Value Function Loss: 0.02020

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.12413
Value Function Update Magnitude: 0.20442

Collected Steps per Second: 10289.30052
Overall Steps per Second: 7200.12986

Timestep Collection Time: 4.86224
Timestep Consumption Time: 2.08611
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 6.94835

Cumulative Model Updates: 30072
Cumulative Timesteps: 251129546

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.03364
Policy Entropy: 1.29740
Value Function Loss: 0.01985

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.12371
Value Function Update Magnitude: 0.20775

Collected Steps per Second: 9823.70225
Overall Steps per Second: 7045.41480

Timestep Collection Time: 5.09431
Timestep Consumption Time: 2.00889
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.10320

Cumulative Model Updates: 30078
Cumulative Timesteps: 251179591

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.32995
Policy Entropy: 1.29812
Value Function Loss: 0.01846

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.06643
Policy Update Magnitude: 0.12299
Value Function Update Magnitude: 0.21836

Collected Steps per Second: 9609.26131
Overall Steps per Second: 6891.87975

Timestep Collection Time: 5.20602
Timestep Consumption Time: 2.05267
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.25869

Cumulative Model Updates: 30084
Cumulative Timesteps: 251229617

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.70525
Policy Entropy: 1.30028
Value Function Loss: 0.01791

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.11701
Value Function Update Magnitude: 0.20983

Collected Steps per Second: 10240.46740
Overall Steps per Second: 7182.77276

Timestep Collection Time: 4.88386
Timestep Consumption Time: 2.07905
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 6.96291

Cumulative Model Updates: 30090
Cumulative Timesteps: 251279630

Timesteps Collected: 50013
--------END ITERATION REPORT--------


Saving checkpoint 251279630...
Checkpoint 251279630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.98601
Policy Entropy: 1.30031
Value Function Loss: 0.01675

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.11334
Value Function Update Magnitude: 0.19575

Collected Steps per Second: 9809.71364
Overall Steps per Second: 7041.27492

Timestep Collection Time: 5.09964
Timestep Consumption Time: 2.00504
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.10468

Cumulative Model Updates: 30096
Cumulative Timesteps: 251329656

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.10264
Policy Entropy: 1.30012
Value Function Loss: 0.01700

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.11578
Value Function Update Magnitude: 0.19538

Collected Steps per Second: 9746.52922
Overall Steps per Second: 7005.48059

Timestep Collection Time: 5.13290
Timestep Consumption Time: 2.00836
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 7.14127

Cumulative Model Updates: 30102
Cumulative Timesteps: 251379684

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.84497
Policy Entropy: 1.30126
Value Function Loss: 0.01717

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06516
Policy Update Magnitude: 0.11701
Value Function Update Magnitude: 0.19027

Collected Steps per Second: 10649.90769
Overall Steps per Second: 7397.13952

Timestep Collection Time: 4.69544
Timestep Consumption Time: 2.06474
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 6.76018

Cumulative Model Updates: 30108
Cumulative Timesteps: 251429690

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.68438
Policy Entropy: 1.30147
Value Function Loss: 0.01776

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06046
Policy Update Magnitude: 0.11729
Value Function Update Magnitude: 0.20044

Collected Steps per Second: 9820.58153
Overall Steps per Second: 6960.01766

Timestep Collection Time: 5.09328
Timestep Consumption Time: 2.09334
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 7.18662

Cumulative Model Updates: 30114
Cumulative Timesteps: 251479709

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.70129
Policy Entropy: 1.29983
Value Function Loss: 0.01779

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.11929
Value Function Update Magnitude: 0.19365

Collected Steps per Second: 9755.18167
Overall Steps per Second: 6904.24382

Timestep Collection Time: 5.12938
Timestep Consumption Time: 2.11805
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 7.24743

Cumulative Model Updates: 30120
Cumulative Timesteps: 251529747

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.56854
Policy Entropy: 1.29732
Value Function Loss: 0.01756

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.11989
Value Function Update Magnitude: 0.19232

Collected Steps per Second: 10290.03823
Overall Steps per Second: 7196.80165

Timestep Collection Time: 4.86033
Timestep Consumption Time: 2.08901
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 6.94934

Cumulative Model Updates: 30126
Cumulative Timesteps: 251579760

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.58549
Policy Entropy: 1.29895
Value Function Loss: 0.01673

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.11800
Value Function Update Magnitude: 0.19017

Collected Steps per Second: 9976.05229
Overall Steps per Second: 7121.59949

Timestep Collection Time: 5.01210
Timestep Consumption Time: 2.00893
PPO Batch Consumption Time: 0.02567
Total Iteration Time: 7.02104

Cumulative Model Updates: 30132
Cumulative Timesteps: 251629761

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.28336
Policy Entropy: 1.30112
Value Function Loss: 0.01740

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.11770
Value Function Update Magnitude: 0.19313

Collected Steps per Second: 9735.03190
Overall Steps per Second: 6975.43274

Timestep Collection Time: 5.13773
Timestep Consumption Time: 2.03257
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.17031

Cumulative Model Updates: 30138
Cumulative Timesteps: 251679777

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.89378
Policy Entropy: 1.30766
Value Function Loss: 0.01763

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.11635
Value Function Update Magnitude: 0.20034

Collected Steps per Second: 10304.59734
Overall Steps per Second: 7195.98084

Timestep Collection Time: 4.85249
Timestep Consumption Time: 2.09625
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.94874

Cumulative Model Updates: 30144
Cumulative Timesteps: 251729780

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.52316
Policy Entropy: 1.30627
Value Function Loss: 0.01934

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06301
Policy Update Magnitude: 0.11670
Value Function Update Magnitude: 0.21233

Collected Steps per Second: 9938.92812
Overall Steps per Second: 7024.13277

Timestep Collection Time: 5.03274
Timestep Consumption Time: 2.08843
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.12116

Cumulative Model Updates: 30150
Cumulative Timesteps: 251779800

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 251779800...
Checkpoint 251779800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.08866
Policy Entropy: 1.29917
Value Function Loss: 0.01962

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.07786
Policy Update Magnitude: 0.12201
Value Function Update Magnitude: 0.22063

Collected Steps per Second: 9824.24784
Overall Steps per Second: 7010.96567

Timestep Collection Time: 5.09108
Timestep Consumption Time: 2.04289
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.13397

Cumulative Model Updates: 30156
Cumulative Timesteps: 251829816

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.85388
Policy Entropy: 1.29386
Value Function Loss: 0.02009

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.12142
Value Function Update Magnitude: 0.21520

Collected Steps per Second: 10365.81592
Overall Steps per Second: 7214.32621

Timestep Collection Time: 4.82731
Timestep Consumption Time: 2.10875
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 6.93606

Cumulative Model Updates: 30162
Cumulative Timesteps: 251879855

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.87624
Policy Entropy: 1.29385
Value Function Loss: 0.01934

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.12117
Value Function Update Magnitude: 0.20796

Collected Steps per Second: 9821.39817
Overall Steps per Second: 6981.36502

Timestep Collection Time: 5.09133
Timestep Consumption Time: 2.07116
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.16250

Cumulative Model Updates: 30168
Cumulative Timesteps: 251929859

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.38082
Policy Entropy: 1.29876
Value Function Loss: 0.01836

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.06778
Policy Update Magnitude: 0.12284
Value Function Update Magnitude: 0.19565

Collected Steps per Second: 9921.11108
Overall Steps per Second: 7196.83186

Timestep Collection Time: 5.04097
Timestep Consumption Time: 1.90820
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 6.94917

Cumulative Model Updates: 30174
Cumulative Timesteps: 251979871

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.39810
Policy Entropy: 1.30139
Value Function Loss: 0.01719

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.11752
Value Function Update Magnitude: 0.19024

Collected Steps per Second: 10382.29964
Overall Steps per Second: 7185.34258

Timestep Collection Time: 4.81849
Timestep Consumption Time: 2.14388
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 6.96237

Cumulative Model Updates: 30180
Cumulative Timesteps: 252029898

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.41744
Policy Entropy: 1.30166
Value Function Loss: 0.01818

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.11636
Value Function Update Magnitude: 0.19793

Collected Steps per Second: 9848.02294
Overall Steps per Second: 6963.98263

Timestep Collection Time: 5.07970
Timestep Consumption Time: 2.10369
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.18339

Cumulative Model Updates: 30186
Cumulative Timesteps: 252079923

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.16783
Policy Entropy: 1.30039
Value Function Loss: 0.01836

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.05789
Policy Update Magnitude: 0.11600
Value Function Update Magnitude: 0.20932

Collected Steps per Second: 9728.90262
Overall Steps per Second: 6984.37639

Timestep Collection Time: 5.14066
Timestep Consumption Time: 2.02003
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 7.16070

Cumulative Model Updates: 30192
Cumulative Timesteps: 252129936

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.10384
Policy Entropy: 1.30250
Value Function Loss: 0.01884

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.05820
Policy Update Magnitude: 0.11848
Value Function Update Magnitude: 0.21340

Collected Steps per Second: 10475.67870
Overall Steps per Second: 7278.84726

Timestep Collection Time: 4.77640
Timestep Consumption Time: 2.09777
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 6.87417

Cumulative Model Updates: 30198
Cumulative Timesteps: 252179972

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.07182
Policy Entropy: 1.30443
Value Function Loss: 0.01800

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06128
Policy Update Magnitude: 0.11817
Value Function Update Magnitude: 0.19844

Collected Steps per Second: 9876.08800
Overall Steps per Second: 7054.69904

Timestep Collection Time: 5.06385
Timestep Consumption Time: 2.02519
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.08903

Cumulative Model Updates: 30204
Cumulative Timesteps: 252229983

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.15401
Policy Entropy: 1.30219
Value Function Loss: 0.01870

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.11776
Value Function Update Magnitude: 0.19746

Collected Steps per Second: 10031.99398
Overall Steps per Second: 7112.65852

Timestep Collection Time: 4.98764
Timestep Consumption Time: 2.04714
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 7.03478

Cumulative Model Updates: 30210
Cumulative Timesteps: 252280019

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 252280019...
Checkpoint 252280019 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.09125
Policy Entropy: 1.29759
Value Function Loss: 0.01916

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.12144
Value Function Update Magnitude: 0.19189

Collected Steps per Second: 10375.75492
Overall Steps per Second: 7171.95623

Timestep Collection Time: 4.82259
Timestep Consumption Time: 2.15431
PPO Batch Consumption Time: 0.03001
Total Iteration Time: 6.97690

Cumulative Model Updates: 30216
Cumulative Timesteps: 252330057

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.63428
Policy Entropy: 1.29410
Value Function Loss: 0.01951

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.12192
Value Function Update Magnitude: 0.19369

Collected Steps per Second: 9900.27477
Overall Steps per Second: 7095.35177

Timestep Collection Time: 5.05148
Timestep Consumption Time: 1.99694
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.04842

Cumulative Model Updates: 30222
Cumulative Timesteps: 252380068

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.51011
Policy Entropy: 1.29847
Value Function Loss: 0.01909

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.11914
Value Function Update Magnitude: 0.18880

Collected Steps per Second: 10251.44625
Overall Steps per Second: 7258.61690

Timestep Collection Time: 4.87951
Timestep Consumption Time: 2.01189
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 6.89140

Cumulative Model Updates: 30228
Cumulative Timesteps: 252430090

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.67695
Policy Entropy: 1.29822
Value Function Loss: 0.01920

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06208
Policy Update Magnitude: 0.12050
Value Function Update Magnitude: 0.19692

Collected Steps per Second: 9783.54332
Overall Steps per Second: 6738.02934

Timestep Collection Time: 5.11134
Timestep Consumption Time: 2.31027
PPO Batch Consumption Time: 0.02863
Total Iteration Time: 7.42161

Cumulative Model Updates: 30234
Cumulative Timesteps: 252480097

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.19914
Policy Entropy: 1.30335
Value Function Loss: 0.01921

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.05654
Policy Update Magnitude: 0.12403
Value Function Update Magnitude: 0.19423

Collected Steps per Second: 8882.25916
Overall Steps per Second: 6451.38047

Timestep Collection Time: 5.62954
Timestep Consumption Time: 2.12121
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.75074

Cumulative Model Updates: 30240
Cumulative Timesteps: 252530100

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.50003
Policy Entropy: 1.29842
Value Function Loss: 0.01820

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06144
Policy Update Magnitude: 0.12396
Value Function Update Magnitude: 0.19066

Collected Steps per Second: 9879.80397
Overall Steps per Second: 7053.04953

Timestep Collection Time: 5.06245
Timestep Consumption Time: 2.02895
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 7.09140

Cumulative Model Updates: 30246
Cumulative Timesteps: 252580116

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.61948
Policy Entropy: 1.29965
Value Function Loss: 0.01823

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.12077
Value Function Update Magnitude: 0.18673

Collected Steps per Second: 9570.18211
Overall Steps per Second: 6525.92319

Timestep Collection Time: 5.22655
Timestep Consumption Time: 2.43812
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 7.66466

Cumulative Model Updates: 30252
Cumulative Timesteps: 252630135

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.72218
Policy Entropy: 1.30297
Value Function Loss: 0.01818

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06546
Policy Update Magnitude: 0.12406
Value Function Update Magnitude: 0.17919

Collected Steps per Second: 8796.05753
Overall Steps per Second: 6430.65404

Timestep Collection Time: 5.68755
Timestep Consumption Time: 2.09206
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.77961

Cumulative Model Updates: 30258
Cumulative Timesteps: 252680163

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.72635
Policy Entropy: 1.30273
Value Function Loss: 0.01884

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.12605
Value Function Update Magnitude: 0.18120

Collected Steps per Second: 9884.09864
Overall Steps per Second: 7127.95343

Timestep Collection Time: 5.05873
Timestep Consumption Time: 1.95605
PPO Batch Consumption Time: 0.02475
Total Iteration Time: 7.01478

Cumulative Model Updates: 30264
Cumulative Timesteps: 252730164

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.37639
Policy Entropy: 1.30419
Value Function Loss: 0.01869

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.12345
Value Function Update Magnitude: 0.18628

Collected Steps per Second: 9480.59014
Overall Steps per Second: 6533.01282

Timestep Collection Time: 5.27552
Timestep Consumption Time: 2.38022
PPO Batch Consumption Time: 0.03015
Total Iteration Time: 7.65573

Cumulative Model Updates: 30270
Cumulative Timesteps: 252780179

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 252780179...
Checkpoint 252780179 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.67865
Policy Entropy: 1.30288
Value Function Loss: 0.01877

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.11883
Value Function Update Magnitude: 0.17982

Collected Steps per Second: 8984.41640
Overall Steps per Second: 6459.78056

Timestep Collection Time: 5.56642
Timestep Consumption Time: 2.17549
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.74190

Cumulative Model Updates: 30276
Cumulative Timesteps: 252830190

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.95136
Policy Entropy: 1.30759
Value Function Loss: 0.01825

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.12168
Value Function Update Magnitude: 0.17878

Collected Steps per Second: 10212.42089
Overall Steps per Second: 7175.35416

Timestep Collection Time: 4.89864
Timestep Consumption Time: 2.07342
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.97206

Cumulative Model Updates: 30282
Cumulative Timesteps: 252880217

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.32121
Policy Entropy: 1.30811
Value Function Loss: 0.01853

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.12057
Value Function Update Magnitude: 0.18862

Collected Steps per Second: 10206.76831
Overall Steps per Second: 6874.86855

Timestep Collection Time: 4.90194
Timestep Consumption Time: 2.37572
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 7.27767

Cumulative Model Updates: 30288
Cumulative Timesteps: 252930250

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.13030
Policy Entropy: 1.31007
Value Function Loss: 0.01773

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.06896
Policy Update Magnitude: 0.11985
Value Function Update Magnitude: 0.19016

Collected Steps per Second: 8927.55297
Overall Steps per Second: 6449.05309

Timestep Collection Time: 5.60198
Timestep Consumption Time: 2.15295
PPO Batch Consumption Time: 0.02407
Total Iteration Time: 7.75494

Cumulative Model Updates: 30294
Cumulative Timesteps: 252980262

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.71646
Policy Entropy: 1.30863
Value Function Loss: 0.01834

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.11769
Value Function Update Magnitude: 0.18929

Collected Steps per Second: 10214.88725
Overall Steps per Second: 7201.56940

Timestep Collection Time: 4.89815
Timestep Consumption Time: 2.04951
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 6.94765

Cumulative Model Updates: 30300
Cumulative Timesteps: 253030296

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.56036
Policy Entropy: 1.31126
Value Function Loss: 0.01836

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.05835
Policy Update Magnitude: 0.11647
Value Function Update Magnitude: 0.18252

Collected Steps per Second: 10553.64113
Overall Steps per Second: 7439.18709

Timestep Collection Time: 4.73988
Timestep Consumption Time: 1.98438
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.72426

Cumulative Model Updates: 30306
Cumulative Timesteps: 253080319

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.40412
Policy Entropy: 1.30645
Value Function Loss: 0.01921

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.11940
Value Function Update Magnitude: 0.18188

Collected Steps per Second: 9938.99535
Overall Steps per Second: 7181.88427

Timestep Collection Time: 5.03170
Timestep Consumption Time: 1.93166
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.96335

Cumulative Model Updates: 30312
Cumulative Timesteps: 253130329

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.89427
Policy Entropy: 1.30804
Value Function Loss: 0.01889

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.11961
Value Function Update Magnitude: 0.18415

Collected Steps per Second: 10047.19841
Overall Steps per Second: 7217.15816

Timestep Collection Time: 4.97910
Timestep Consumption Time: 1.95244
PPO Batch Consumption Time: 0.03187
Total Iteration Time: 6.93154

Cumulative Model Updates: 30318
Cumulative Timesteps: 253180355

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.43648
Policy Entropy: 1.30755
Value Function Loss: 0.01897

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.12054
Value Function Update Magnitude: 0.17960

Collected Steps per Second: 10466.91416
Overall Steps per Second: 7402.98575

Timestep Collection Time: 4.78040
Timestep Consumption Time: 1.97850
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 6.75889

Cumulative Model Updates: 30324
Cumulative Timesteps: 253230391

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.03907
Policy Entropy: 1.30847
Value Function Loss: 0.01799

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.12351
Value Function Update Magnitude: 0.18204

Collected Steps per Second: 9942.64078
Overall Steps per Second: 7185.35049

Timestep Collection Time: 5.03277
Timestep Consumption Time: 1.93126
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 6.96403

Cumulative Model Updates: 30330
Cumulative Timesteps: 253280430

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 253280430...
Checkpoint 253280430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.71828
Policy Entropy: 1.31014
Value Function Loss: 0.01830

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.12392
Value Function Update Magnitude: 0.18183

Collected Steps per Second: 9781.66951
Overall Steps per Second: 7084.27265

Timestep Collection Time: 5.11262
Timestep Consumption Time: 1.94667
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.05930

Cumulative Model Updates: 30336
Cumulative Timesteps: 253330440

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.50684
Policy Entropy: 1.30760
Value Function Loss: 0.01796

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.06870
Policy Update Magnitude: 0.12270
Value Function Update Magnitude: 0.18217

Collected Steps per Second: 10672.44167
Overall Steps per Second: 7386.48921

Timestep Collection Time: 4.68506
Timestep Consumption Time: 2.08419
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.76925

Cumulative Model Updates: 30342
Cumulative Timesteps: 253380441

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.70246
Policy Entropy: 1.30405
Value Function Loss: 0.01875

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.19051

Collected Steps per Second: 10029.73170
Overall Steps per Second: 7151.66194

Timestep Collection Time: 4.98777
Timestep Consumption Time: 2.00725
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 6.99502

Cumulative Model Updates: 30348
Cumulative Timesteps: 253430467

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.51232
Policy Entropy: 1.30008
Value Function Loss: 0.01852

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.11991
Value Function Update Magnitude: 0.18674

Collected Steps per Second: 9815.77969
Overall Steps per Second: 6980.82569

Timestep Collection Time: 5.09414
Timestep Consumption Time: 2.06876
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 7.16291

Cumulative Model Updates: 30354
Cumulative Timesteps: 253480470

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.11167
Policy Entropy: 1.30480
Value Function Loss: 0.01870

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.18229

Collected Steps per Second: 9948.40871
Overall Steps per Second: 6993.95279

Timestep Collection Time: 5.03015
Timestep Consumption Time: 2.12489
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 7.15504

Cumulative Model Updates: 30360
Cumulative Timesteps: 253530512

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.68230
Policy Entropy: 1.30635
Value Function Loss: 0.01912

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.12213
Value Function Update Magnitude: 0.18720

Collected Steps per Second: 9874.48013
Overall Steps per Second: 6979.46222

Timestep Collection Time: 5.06649
Timestep Consumption Time: 2.10154
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.16803

Cumulative Model Updates: 30366
Cumulative Timesteps: 253580541

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.23857
Policy Entropy: 1.30543
Value Function Loss: 0.01932

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.12166
Value Function Update Magnitude: 0.19271

Collected Steps per Second: 9018.99757
Overall Steps per Second: 6501.02476

Timestep Collection Time: 5.54696
Timestep Consumption Time: 2.14844
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 7.69540

Cumulative Model Updates: 30372
Cumulative Timesteps: 253630569

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.91195
Policy Entropy: 1.29991
Value Function Loss: 0.01960

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.12046
Value Function Update Magnitude: 0.19142

Collected Steps per Second: 9390.79117
Overall Steps per Second: 6604.68262

Timestep Collection Time: 5.32607
Timestep Consumption Time: 2.24674
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 7.57281

Cumulative Model Updates: 30378
Cumulative Timesteps: 253680585

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.98960
Policy Entropy: 1.30380
Value Function Loss: 0.01968

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.11740
Value Function Update Magnitude: 0.19022

Collected Steps per Second: 9535.91750
Overall Steps per Second: 6890.78017

Timestep Collection Time: 5.24459
Timestep Consumption Time: 2.01322
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.25781

Cumulative Model Updates: 30384
Cumulative Timesteps: 253730597

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.53596
Policy Entropy: 1.30785
Value Function Loss: 0.01913

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.11751
Value Function Update Magnitude: 0.18611

Collected Steps per Second: 8909.51954
Overall Steps per Second: 6538.49338

Timestep Collection Time: 5.61568
Timestep Consumption Time: 2.03639
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.65207

Cumulative Model Updates: 30390
Cumulative Timesteps: 253780630

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 253780630...
Checkpoint 253780630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.23265
Policy Entropy: 1.31158
Value Function Loss: 0.01857

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.11676
Value Function Update Magnitude: 0.19534

Collected Steps per Second: 9290.92562
Overall Steps per Second: 6474.70689

Timestep Collection Time: 5.38579
Timestep Consumption Time: 2.34259
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 7.72838

Cumulative Model Updates: 30396
Cumulative Timesteps: 253830669

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.32451
Policy Entropy: 1.30952
Value Function Loss: 0.01853

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06240
Policy Update Magnitude: 0.11535
Value Function Update Magnitude: 0.19929

Collected Steps per Second: 9070.80894
Overall Steps per Second: 6567.62106

Timestep Collection Time: 5.51594
Timestep Consumption Time: 2.10235
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 7.61828

Cumulative Model Updates: 30402
Cumulative Timesteps: 253880703

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.06514
Policy Entropy: 1.30679
Value Function Loss: 0.01848

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06209
Policy Update Magnitude: 0.11687
Value Function Update Magnitude: 0.20361

Collected Steps per Second: 9100.19326
Overall Steps per Second: 6543.43546

Timestep Collection Time: 5.49889
Timestep Consumption Time: 2.14862
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.64751

Cumulative Model Updates: 30408
Cumulative Timesteps: 253930744

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.29011
Policy Entropy: 1.30803
Value Function Loss: 0.01895

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05415
Policy Update Magnitude: 0.12308
Value Function Update Magnitude: 0.19615

Collected Steps per Second: 9492.80356
Overall Steps per Second: 6614.55701

Timestep Collection Time: 5.26767
Timestep Consumption Time: 2.29217
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 7.55984

Cumulative Model Updates: 30414
Cumulative Timesteps: 253980749

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.75116
Policy Entropy: 1.30779
Value Function Loss: 0.01870

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.12233
Value Function Update Magnitude: 0.19040

Collected Steps per Second: 9029.47702
Overall Steps per Second: 6533.92962

Timestep Collection Time: 5.53908
Timestep Consumption Time: 2.11558
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.65466

Cumulative Model Updates: 30420
Cumulative Timesteps: 254030764

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.13350
Policy Entropy: 1.30902
Value Function Loss: 0.01856

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.05087
Policy Update Magnitude: 0.12876
Value Function Update Magnitude: 0.18932

Collected Steps per Second: 9049.75360
Overall Steps per Second: 6607.20583

Timestep Collection Time: 5.52755
Timestep Consumption Time: 2.04342
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 7.57098

Cumulative Model Updates: 30426
Cumulative Timesteps: 254080787

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.79447
Policy Entropy: 1.30786
Value Function Loss: 0.01887

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.05967
Policy Update Magnitude: 0.12554
Value Function Update Magnitude: 0.19274

Collected Steps per Second: 10000.14744
Overall Steps per Second: 7007.07969

Timestep Collection Time: 5.00173
Timestep Consumption Time: 2.13648
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 7.13821

Cumulative Model Updates: 30432
Cumulative Timesteps: 254130805

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.42054
Policy Entropy: 1.30925
Value Function Loss: 0.01980

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.05474
Policy Update Magnitude: 0.13060
Value Function Update Magnitude: 0.19216

Collected Steps per Second: 9783.10295
Overall Steps per Second: 7187.57840

Timestep Collection Time: 5.11443
Timestep Consumption Time: 1.84688
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.96132

Cumulative Model Updates: 30438
Cumulative Timesteps: 254180840

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.58641
Policy Entropy: 1.30996
Value Function Loss: 0.01950

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.05669
Policy Update Magnitude: 0.13112
Value Function Update Magnitude: 0.19387

Collected Steps per Second: 9824.00194
Overall Steps per Second: 7093.23944

Timestep Collection Time: 5.09273
Timestep Consumption Time: 1.96060
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.05334

Cumulative Model Updates: 30444
Cumulative Timesteps: 254230871

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.72809
Policy Entropy: 1.30900
Value Function Loss: 0.01885

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06267
Policy Update Magnitude: 0.13279
Value Function Update Magnitude: 0.18991

Collected Steps per Second: 10447.13600
Overall Steps per Second: 7373.75776

Timestep Collection Time: 4.78964
Timestep Consumption Time: 1.99632
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 6.78596

Cumulative Model Updates: 30450
Cumulative Timesteps: 254280909

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 254280909...
Checkpoint 254280909 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.93486
Policy Entropy: 1.31066
Value Function Loss: 0.01768

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.12967
Value Function Update Magnitude: 0.18653

Collected Steps per Second: 9812.94648
Overall Steps per Second: 7032.50203

Timestep Collection Time: 5.09674
Timestep Consumption Time: 2.01510
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.11184

Cumulative Model Updates: 30456
Cumulative Timesteps: 254330923

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.19410
Policy Entropy: 1.30847
Value Function Loss: 0.01759

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.12703
Value Function Update Magnitude: 0.18443

Collected Steps per Second: 10095.60473
Overall Steps per Second: 7135.55848

Timestep Collection Time: 4.95334
Timestep Consumption Time: 2.05480
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.00814

Cumulative Model Updates: 30462
Cumulative Timesteps: 254380930

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.93079
Policy Entropy: 1.31143
Value Function Loss: 0.01778

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.12356
Value Function Update Magnitude: 0.18351

Collected Steps per Second: 10514.46585
Overall Steps per Second: 7299.82322

Timestep Collection Time: 4.75602
Timestep Consumption Time: 2.09442
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 6.85044

Cumulative Model Updates: 30468
Cumulative Timesteps: 254430937

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.97238
Policy Entropy: 1.31424
Value Function Loss: 0.01858

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06580
Policy Update Magnitude: 0.12422
Value Function Update Magnitude: 0.18031

Collected Steps per Second: 9830.39460
Overall Steps per Second: 6981.27679

Timestep Collection Time: 5.08830
Timestep Consumption Time: 2.07658
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.16488

Cumulative Model Updates: 30474
Cumulative Timesteps: 254480957

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.60653
Policy Entropy: 1.31608
Value Function Loss: 0.01848

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06256
Policy Update Magnitude: 0.12315
Value Function Update Magnitude: 0.18782

Collected Steps per Second: 8979.96569
Overall Steps per Second: 6449.42320

Timestep Collection Time: 5.56951
Timestep Consumption Time: 2.18529
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.75480

Cumulative Model Updates: 30480
Cumulative Timesteps: 254530971

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.88895
Policy Entropy: 1.31193
Value Function Loss: 0.01805

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.12356
Value Function Update Magnitude: 0.18948

Collected Steps per Second: 9988.57644
Overall Steps per Second: 6925.47899

Timestep Collection Time: 5.00802
Timestep Consumption Time: 2.21502
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.22304

Cumulative Model Updates: 30486
Cumulative Timesteps: 254580994

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.10872
Policy Entropy: 1.30779
Value Function Loss: 0.01768

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.12327
Value Function Update Magnitude: 0.18999

Collected Steps per Second: 9583.71999
Overall Steps per Second: 6763.11170

Timestep Collection Time: 5.21864
Timestep Consumption Time: 2.17648
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 7.39512

Cumulative Model Updates: 30492
Cumulative Timesteps: 254631008

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.93559
Policy Entropy: 1.31096
Value Function Loss: 0.01775

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06114
Policy Update Magnitude: 0.12082
Value Function Update Magnitude: 0.18628

Collected Steps per Second: 8868.94139
Overall Steps per Second: 6382.16936

Timestep Collection Time: 5.63946
Timestep Consumption Time: 2.19738
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.83683

Cumulative Model Updates: 30498
Cumulative Timesteps: 254681024

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.82661
Policy Entropy: 1.31421
Value Function Loss: 0.01753

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.05613
Policy Update Magnitude: 0.12019
Value Function Update Magnitude: 0.19331

Collected Steps per Second: 10041.88647
Overall Steps per Second: 7006.16480

Timestep Collection Time: 4.98253
Timestep Consumption Time: 2.15889
PPO Batch Consumption Time: 0.03465
Total Iteration Time: 7.14142

Cumulative Model Updates: 30504
Cumulative Timesteps: 254731058

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.68595
Policy Entropy: 1.31259
Value Function Loss: 0.01772

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.12028
Value Function Update Magnitude: 0.19677

Collected Steps per Second: 9780.94639
Overall Steps per Second: 6720.74089

Timestep Collection Time: 5.11351
Timestep Consumption Time: 2.32837
PPO Batch Consumption Time: 0.03031
Total Iteration Time: 7.44189

Cumulative Model Updates: 30510
Cumulative Timesteps: 254781073

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 254781073...
Checkpoint 254781073 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.33049
Policy Entropy: 1.30965
Value Function Loss: 0.01811

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06314
Policy Update Magnitude: 0.11858
Value Function Update Magnitude: 0.20295

Collected Steps per Second: 8828.95047
Overall Steps per Second: 6322.56965

Timestep Collection Time: 5.66500
Timestep Consumption Time: 2.24571
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.91071

Cumulative Model Updates: 30516
Cumulative Timesteps: 254831089

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.94967
Policy Entropy: 1.31166
Value Function Loss: 0.01877

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.12202
Value Function Update Magnitude: 0.20122

Collected Steps per Second: 10169.22728
Overall Steps per Second: 6917.35762

Timestep Collection Time: 4.91768
Timestep Consumption Time: 2.31182
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.22949

Cumulative Model Updates: 30522
Cumulative Timesteps: 254881098

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.37177
Policy Entropy: 1.31476
Value Function Loss: 0.01913

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.12325
Value Function Update Magnitude: 0.20716

Collected Steps per Second: 10250.11134
Overall Steps per Second: 7060.58725

Timestep Collection Time: 4.88209
Timestep Consumption Time: 2.20542
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 7.08751

Cumulative Model Updates: 30528
Cumulative Timesteps: 254931140

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.84948
Policy Entropy: 1.31669
Value Function Loss: 0.01927

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.05691
Policy Update Magnitude: 0.12239
Value Function Update Magnitude: 0.21875

Collected Steps per Second: 8836.23897
Overall Steps per Second: 6304.40917

Timestep Collection Time: 5.66044
Timestep Consumption Time: 2.27321
PPO Batch Consumption Time: 0.03241
Total Iteration Time: 7.93365

Cumulative Model Updates: 30534
Cumulative Timesteps: 254981157

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.53741
Policy Entropy: 1.31572
Value Function Loss: 0.01869

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.05858
Policy Update Magnitude: 0.12194
Value Function Update Magnitude: 0.22024

Collected Steps per Second: 9709.10181
Overall Steps per Second: 6938.21888

Timestep Collection Time: 5.15207
Timestep Consumption Time: 2.05756
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.20963

Cumulative Model Updates: 30540
Cumulative Timesteps: 255031179

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.96428
Policy Entropy: 1.31079
Value Function Loss: 0.01854

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.11967
Value Function Update Magnitude: 0.20943

Collected Steps per Second: 9438.86522
Overall Steps per Second: 6876.78519

Timestep Collection Time: 5.29968
Timestep Consumption Time: 1.97450
PPO Batch Consumption Time: 0.02494
Total Iteration Time: 7.27418

Cumulative Model Updates: 30546
Cumulative Timesteps: 255081202

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.20711
Policy Entropy: 1.31310
Value Function Loss: 0.01808

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.12094
Value Function Update Magnitude: 0.20297

Collected Steps per Second: 9290.16699
Overall Steps per Second: 6792.79950

Timestep Collection Time: 5.38516
Timestep Consumption Time: 1.97985
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 7.36500

Cumulative Model Updates: 30552
Cumulative Timesteps: 255131231

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.31678
Policy Entropy: 1.31444
Value Function Loss: 0.01833

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06059
Policy Update Magnitude: 0.11964
Value Function Update Magnitude: 0.20340

Collected Steps per Second: 10160.23210
Overall Steps per Second: 7155.39089

Timestep Collection Time: 4.92440
Timestep Consumption Time: 2.06795
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 6.99235

Cumulative Model Updates: 30558
Cumulative Timesteps: 255181264

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.09196
Policy Entropy: 1.31134
Value Function Loss: 0.01796

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.11779
Value Function Update Magnitude: 0.19320

Collected Steps per Second: 9853.44352
Overall Steps per Second: 6888.04158

Timestep Collection Time: 5.07680
Timestep Consumption Time: 2.18564
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 7.26244

Cumulative Model Updates: 30564
Cumulative Timesteps: 255231288

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.36265
Policy Entropy: 1.30881
Value Function Loss: 0.01756

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.11737
Value Function Update Magnitude: 0.18485

Collected Steps per Second: 9554.86567
Overall Steps per Second: 6832.84541

Timestep Collection Time: 5.23691
Timestep Consumption Time: 2.08624
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.32316

Cumulative Model Updates: 30570
Cumulative Timesteps: 255281326

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 255281326...
Checkpoint 255281326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.11934
Policy Entropy: 1.30843
Value Function Loss: 0.01815

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06392
Policy Update Magnitude: 0.12079
Value Function Update Magnitude: 0.19052

Collected Steps per Second: 10294.67538
Overall Steps per Second: 7301.26892

Timestep Collection Time: 4.85834
Timestep Consumption Time: 1.99184
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 6.85018

Cumulative Model Updates: 30576
Cumulative Timesteps: 255331341

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.27796
Policy Entropy: 1.30892
Value Function Loss: 0.01803

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06152
Policy Update Magnitude: 0.11840
Value Function Update Magnitude: 0.20490

Collected Steps per Second: 9668.00958
Overall Steps per Second: 7064.59946

Timestep Collection Time: 5.17397
Timestep Consumption Time: 1.90669
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.08066

Cumulative Model Updates: 30582
Cumulative Timesteps: 255381363

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.71669
Policy Entropy: 1.30834
Value Function Loss: 0.01835

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.05776
Policy Update Magnitude: 0.11842
Value Function Update Magnitude: 0.19552

Collected Steps per Second: 9954.32941
Overall Steps per Second: 7161.74590

Timestep Collection Time: 5.02475
Timestep Consumption Time: 1.95930
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 6.98405

Cumulative Model Updates: 30588
Cumulative Timesteps: 255431381

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.76687
Policy Entropy: 1.30716
Value Function Loss: 0.01792

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.11945
Value Function Update Magnitude: 0.19346

Collected Steps per Second: 9912.25108
Overall Steps per Second: 6930.52999

Timestep Collection Time: 5.04628
Timestep Consumption Time: 2.17106
PPO Batch Consumption Time: 0.02948
Total Iteration Time: 7.21734

Cumulative Model Updates: 30594
Cumulative Timesteps: 255481401

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.14732
Policy Entropy: 1.30185
Value Function Loss: 0.01818

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.12005
Value Function Update Magnitude: 0.19550

Collected Steps per Second: 9737.18516
Overall Steps per Second: 6917.38992

Timestep Collection Time: 5.13619
Timestep Consumption Time: 2.09371
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.22989

Cumulative Model Updates: 30600
Cumulative Timesteps: 255531413

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.68373
Policy Entropy: 1.30082
Value Function Loss: 0.01779

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.11717
Value Function Update Magnitude: 0.18989

Collected Steps per Second: 9725.37385
Overall Steps per Second: 6910.18551

Timestep Collection Time: 5.14571
Timestep Consumption Time: 2.09635
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.24206

Cumulative Model Updates: 30606
Cumulative Timesteps: 255581457

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.03219
Policy Entropy: 1.30021
Value Function Loss: 0.01755

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.11770
Value Function Update Magnitude: 0.19385

Collected Steps per Second: 9616.61263
Overall Steps per Second: 6655.78482

Timestep Collection Time: 5.20246
Timestep Consumption Time: 2.31431
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.51677

Cumulative Model Updates: 30612
Cumulative Timesteps: 255631487

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.90547
Policy Entropy: 1.31185
Value Function Loss: 0.01823

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.06632
Policy Update Magnitude: 0.11640
Value Function Update Magnitude: 0.19842

Collected Steps per Second: 9535.64088
Overall Steps per Second: 6765.36479

Timestep Collection Time: 5.24391
Timestep Consumption Time: 2.14727
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.39118

Cumulative Model Updates: 30618
Cumulative Timesteps: 255681491

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.33992
Policy Entropy: 1.30682
Value Function Loss: 0.01908

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.11908
Value Function Update Magnitude: 0.20312

Collected Steps per Second: 10018.98425
Overall Steps per Second: 7125.22211

Timestep Collection Time: 4.99382
Timestep Consumption Time: 2.02814
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.02196

Cumulative Model Updates: 30624
Cumulative Timesteps: 255731524

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.44249
Policy Entropy: 1.30844
Value Function Loss: 0.01965

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07034
Policy Update Magnitude: 0.12168
Value Function Update Magnitude: 0.21082

Collected Steps per Second: 10407.11823
Overall Steps per Second: 7190.86472

Timestep Collection Time: 4.80729
Timestep Consumption Time: 2.15015
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 6.95744

Cumulative Model Updates: 30630
Cumulative Timesteps: 255781554

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 255781554...
Checkpoint 255781554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.57215
Policy Entropy: 1.30336
Value Function Loss: 0.01936

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.12334
Value Function Update Magnitude: 0.21419

Collected Steps per Second: 9513.92877
Overall Steps per Second: 6736.10104

Timestep Collection Time: 5.25619
Timestep Consumption Time: 2.16754
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.42373

Cumulative Model Updates: 30636
Cumulative Timesteps: 255831561

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.83716
Policy Entropy: 1.30020
Value Function Loss: 0.01942

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.12183
Value Function Update Magnitude: 0.20292

Collected Steps per Second: 9132.09872
Overall Steps per Second: 6542.04705

Timestep Collection Time: 5.48001
Timestep Consumption Time: 2.16958
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.64959

Cumulative Model Updates: 30642
Cumulative Timesteps: 255881605

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.53932
Policy Entropy: 1.29888
Value Function Loss: 0.01995

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06872
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.19988

Collected Steps per Second: 10098.99693
Overall Steps per Second: 6911.94890

Timestep Collection Time: 4.95386
Timestep Consumption Time: 2.28419
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.23805

Cumulative Model Updates: 30648
Cumulative Timesteps: 255931634

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.21119
Policy Entropy: 1.29751
Value Function Loss: 0.02019

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.12390
Value Function Update Magnitude: 0.20036

Collected Steps per Second: 9203.64447
Overall Steps per Second: 6390.33911

Timestep Collection Time: 5.43350
Timestep Consumption Time: 2.39206
PPO Batch Consumption Time: 0.02972
Total Iteration Time: 7.82556

Cumulative Model Updates: 30654
Cumulative Timesteps: 255981642

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.20277
Policy Entropy: 1.30022
Value Function Loss: 0.01887

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.12290
Value Function Update Magnitude: 0.19262

Collected Steps per Second: 9014.05586
Overall Steps per Second: 6484.35706

Timestep Collection Time: 5.54989
Timestep Consumption Time: 2.16514
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.71503

Cumulative Model Updates: 30660
Cumulative Timesteps: 256031669

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.62326
Policy Entropy: 1.30051
Value Function Loss: 0.01831

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.12266
Value Function Update Magnitude: 0.18933

Collected Steps per Second: 10068.18057
Overall Steps per Second: 7031.42744

Timestep Collection Time: 4.96783
Timestep Consumption Time: 2.14552
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 7.11335

Cumulative Model Updates: 30666
Cumulative Timesteps: 256081686

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.45226
Policy Entropy: 1.30284
Value Function Loss: 0.01820

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.12085
Value Function Update Magnitude: 0.19536

Collected Steps per Second: 9478.99359
Overall Steps per Second: 6885.45275

Timestep Collection Time: 5.27778
Timestep Consumption Time: 1.98798
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 7.26575

Cumulative Model Updates: 30672
Cumulative Timesteps: 256131714

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.34965
Policy Entropy: 1.30208
Value Function Loss: 0.01892

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06284
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.19211

Collected Steps per Second: 8851.78597
Overall Steps per Second: 6272.95598

Timestep Collection Time: 5.64892
Timestep Consumption Time: 2.32229
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.97120

Cumulative Model Updates: 30678
Cumulative Timesteps: 256181717

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.45745
Policy Entropy: 1.29868
Value Function Loss: 0.01896

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.12242
Value Function Update Magnitude: 0.18734

Collected Steps per Second: 9446.02529
Overall Steps per Second: 6709.89567

Timestep Collection Time: 5.29736
Timestep Consumption Time: 2.16013
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 7.45749

Cumulative Model Updates: 30684
Cumulative Timesteps: 256231756

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.21206
Policy Entropy: 1.29910
Value Function Loss: 0.01856

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.11966
Value Function Update Magnitude: 0.18908

Collected Steps per Second: 9499.68395
Overall Steps per Second: 6702.14387

Timestep Collection Time: 5.26449
Timestep Consumption Time: 2.19745
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.46194

Cumulative Model Updates: 30690
Cumulative Timesteps: 256281767

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 256281767...
Checkpoint 256281767 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.53714
Policy Entropy: 1.29930
Value Function Loss: 0.01815

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.12084
Value Function Update Magnitude: 0.18056

Collected Steps per Second: 9295.36263
Overall Steps per Second: 6563.09468

Timestep Collection Time: 5.38387
Timestep Consumption Time: 2.24135
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.62521

Cumulative Model Updates: 30696
Cumulative Timesteps: 256331812

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.72216
Policy Entropy: 1.29740
Value Function Loss: 0.01738

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.12304
Value Function Update Magnitude: 0.17565

Collected Steps per Second: 9333.06778
Overall Steps per Second: 6537.72389

Timestep Collection Time: 5.35837
Timestep Consumption Time: 2.29108
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 7.64945

Cumulative Model Updates: 30702
Cumulative Timesteps: 256381822

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.80835
Policy Entropy: 1.29343
Value Function Loss: 0.01704

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.12521
Value Function Update Magnitude: 0.17814

Collected Steps per Second: 9944.76228
Overall Steps per Second: 7018.15042

Timestep Collection Time: 5.02918
Timestep Consumption Time: 2.09720
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.12638

Cumulative Model Updates: 30708
Cumulative Timesteps: 256431836

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.48447
Policy Entropy: 1.29296
Value Function Loss: 0.01647

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.11959
Value Function Update Magnitude: 0.18309

Collected Steps per Second: 10166.18436
Overall Steps per Second: 7008.09056

Timestep Collection Time: 4.92171
Timestep Consumption Time: 2.21790
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.13961

Cumulative Model Updates: 30714
Cumulative Timesteps: 256481871

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.99514
Policy Entropy: 1.29552
Value Function Loss: 0.01663

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.11916
Value Function Update Magnitude: 0.18239

Collected Steps per Second: 9793.85213
Overall Steps per Second: 6892.34198

Timestep Collection Time: 5.10902
Timestep Consumption Time: 2.15078
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.25980

Cumulative Model Updates: 30720
Cumulative Timesteps: 256531908

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.68003
Policy Entropy: 1.29918
Value Function Loss: 0.01629

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07096
Policy Update Magnitude: 0.11858
Value Function Update Magnitude: 0.17997

Collected Steps per Second: 9939.02612
Overall Steps per Second: 6980.71693

Timestep Collection Time: 5.03349
Timestep Consumption Time: 2.13311
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 7.16660

Cumulative Model Updates: 30726
Cumulative Timesteps: 256581936

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.42602
Policy Entropy: 1.29901
Value Function Loss: 0.01740

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.12217
Value Function Update Magnitude: 0.17791

Collected Steps per Second: 9073.33502
Overall Steps per Second: 6449.07266

Timestep Collection Time: 5.51517
Timestep Consumption Time: 2.24424
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.75941

Cumulative Model Updates: 30732
Cumulative Timesteps: 256631977

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.67386
Policy Entropy: 1.29842
Value Function Loss: 0.01813

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.12071
Value Function Update Magnitude: 0.17880

Collected Steps per Second: 9544.89600
Overall Steps per Second: 6588.91067

Timestep Collection Time: 5.24071
Timestep Consumption Time: 2.35114
PPO Batch Consumption Time: 0.03025
Total Iteration Time: 7.59185

Cumulative Model Updates: 30738
Cumulative Timesteps: 256681999

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.87733
Policy Entropy: 1.29334
Value Function Loss: 0.01934

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06585
Policy Update Magnitude: 0.12035
Value Function Update Magnitude: 0.19002

Collected Steps per Second: 9483.13350
Overall Steps per Second: 6818.33618

Timestep Collection Time: 5.27621
Timestep Consumption Time: 2.06209
PPO Batch Consumption Time: 0.02875
Total Iteration Time: 7.33830

Cumulative Model Updates: 30744
Cumulative Timesteps: 256732034

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.00671
Policy Entropy: 1.29650
Value Function Loss: 0.01920

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06580
Policy Update Magnitude: 0.11974
Value Function Update Magnitude: 0.19240

Collected Steps per Second: 9255.82530
Overall Steps per Second: 6605.14183

Timestep Collection Time: 5.40373
Timestep Consumption Time: 2.16855
PPO Batch Consumption Time: 0.02887
Total Iteration Time: 7.57228

Cumulative Model Updates: 30750
Cumulative Timesteps: 256782050

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 256782050...
Checkpoint 256782050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.29311
Policy Entropy: 1.29320
Value Function Loss: 0.01816

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06665
Policy Update Magnitude: 0.11988
Value Function Update Magnitude: 0.19673

Collected Steps per Second: 9902.88210
Overall Steps per Second: 7026.95923

Timestep Collection Time: 5.05328
Timestep Consumption Time: 2.06815
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 7.12143

Cumulative Model Updates: 30756
Cumulative Timesteps: 256832092

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.59846
Policy Entropy: 1.29631
Value Function Loss: 0.01892

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.12184
Value Function Update Magnitude: 0.18860

Collected Steps per Second: 9614.32777
Overall Steps per Second: 6900.06077

Timestep Collection Time: 5.20140
Timestep Consumption Time: 2.04607
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.24747

Cumulative Model Updates: 30762
Cumulative Timesteps: 256882100

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.21087
Policy Entropy: 1.29486
Value Function Loss: 0.01781

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.11925
Value Function Update Magnitude: 0.17943

Collected Steps per Second: 9033.88391
Overall Steps per Second: 6590.93337

Timestep Collection Time: 5.53915
Timestep Consumption Time: 2.05310
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 7.59225

Cumulative Model Updates: 30768
Cumulative Timesteps: 256932140

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.95512
Policy Entropy: 1.30051
Value Function Loss: 0.01964

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.12122
Value Function Update Magnitude: 0.17762

Collected Steps per Second: 9442.21960
Overall Steps per Second: 6666.92544

Timestep Collection Time: 5.29971
Timestep Consumption Time: 2.20615
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 7.50586

Cumulative Model Updates: 30774
Cumulative Timesteps: 256982181

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.30842
Policy Entropy: 1.29730
Value Function Loss: 0.01918

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.12817
Value Function Update Magnitude: 0.18394

Collected Steps per Second: 9588.81132
Overall Steps per Second: 6749.11380

Timestep Collection Time: 5.21504
Timestep Consumption Time: 2.19423
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.40927

Cumulative Model Updates: 30780
Cumulative Timesteps: 257032187

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.36498
Policy Entropy: 1.29944
Value Function Loss: 0.01960

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.13305
Value Function Update Magnitude: 0.18523

Collected Steps per Second: 8880.56357
Overall Steps per Second: 6340.90052

Timestep Collection Time: 5.63557
Timestep Consumption Time: 2.25716
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.89273

Cumulative Model Updates: 30786
Cumulative Timesteps: 257082234

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.19216
Policy Entropy: 1.30083
Value Function Loss: 0.01808

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.13399
Value Function Update Magnitude: 0.18836

Collected Steps per Second: 9800.51392
Overall Steps per Second: 6647.18929

Timestep Collection Time: 5.10228
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.52273

Cumulative Model Updates: 30792
Cumulative Timesteps: 257132239

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.29660
Policy Entropy: 1.30290
Value Function Loss: 0.01746

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06218
Policy Update Magnitude: 0.12964
Value Function Update Magnitude: 0.18451

Collected Steps per Second: 10492.40153
Overall Steps per Second: 7316.94532

Timestep Collection Time: 4.76631
Timestep Consumption Time: 2.06851
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.83482

Cumulative Model Updates: 30798
Cumulative Timesteps: 257182249

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.17892
Policy Entropy: 1.30029
Value Function Loss: 0.01808

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.13421
Value Function Update Magnitude: 0.18577

Collected Steps per Second: 9354.66070
Overall Steps per Second: 6734.65828

Timestep Collection Time: 5.34899
Timestep Consumption Time: 2.08093
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 7.42992

Cumulative Model Updates: 30804
Cumulative Timesteps: 257232287

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.44738
Policy Entropy: 1.29898
Value Function Loss: 0.01838

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.12900
Value Function Update Magnitude: 0.18308

Collected Steps per Second: 9237.86271
Overall Steps per Second: 6620.19695

Timestep Collection Time: 5.41413
Timestep Consumption Time: 2.14078
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 7.55491

Cumulative Model Updates: 30810
Cumulative Timesteps: 257282302

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 257282302...
Checkpoint 257282302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.32171
Policy Entropy: 1.30271
Value Function Loss: 0.01804

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06122
Policy Update Magnitude: 0.12445
Value Function Update Magnitude: 0.17697

Collected Steps per Second: 9979.56335
Overall Steps per Second: 7101.85080

Timestep Collection Time: 5.01134
Timestep Consumption Time: 2.03063
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.04197

Cumulative Model Updates: 30816
Cumulative Timesteps: 257332313

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.99065
Policy Entropy: 1.30264
Value Function Loss: 0.01755

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06337
Policy Update Magnitude: 0.12551
Value Function Update Magnitude: 0.17907

Collected Steps per Second: 9328.95223
Overall Steps per Second: 6645.90906

Timestep Collection Time: 5.36191
Timestep Consumption Time: 2.16468
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.52659

Cumulative Model Updates: 30822
Cumulative Timesteps: 257382334

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.28245
Policy Entropy: 1.30402
Value Function Loss: 0.01772

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06746
Policy Update Magnitude: 0.12680
Value Function Update Magnitude: 0.18926

Collected Steps per Second: 9391.28784
Overall Steps per Second: 6846.12906

Timestep Collection Time: 5.32419
Timestep Consumption Time: 1.97935
PPO Batch Consumption Time: 0.02436
Total Iteration Time: 7.30354

Cumulative Model Updates: 30828
Cumulative Timesteps: 257432335

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -23.56107
Policy Entropy: 1.30202
Value Function Loss: 0.01806

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.12487
Value Function Update Magnitude: 0.19090

Collected Steps per Second: 10246.87004
Overall Steps per Second: 7172.22781

Timestep Collection Time: 4.88208
Timestep Consumption Time: 2.09288
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 6.97496

Cumulative Model Updates: 30834
Cumulative Timesteps: 257482361

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.51343
Policy Entropy: 1.30222
Value Function Loss: 0.01840

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.12477
Value Function Update Magnitude: 0.18480

Collected Steps per Second: 10324.90656
Overall Steps per Second: 7347.97043

Timestep Collection Time: 4.84401
Timestep Consumption Time: 1.96249
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.80651

Cumulative Model Updates: 30840
Cumulative Timesteps: 257532375

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.80164
Policy Entropy: 1.30298
Value Function Loss: 0.01866

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.12318
Value Function Update Magnitude: 0.18497

Collected Steps per Second: 9957.82987
Overall Steps per Second: 6962.37708

Timestep Collection Time: 5.02449
Timestep Consumption Time: 2.16171
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 7.18620

Cumulative Model Updates: 30846
Cumulative Timesteps: 257582408

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.22726
Policy Entropy: 1.30348
Value Function Loss: 0.01861

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.06927
Policy Update Magnitude: 0.13414
Value Function Update Magnitude: 0.19170

Collected Steps per Second: 10152.81628
Overall Steps per Second: 7068.01040

Timestep Collection Time: 4.92809
Timestep Consumption Time: 2.15085
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.07894

Cumulative Model Updates: 30852
Cumulative Timesteps: 257632442

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.27049
Policy Entropy: 1.30908
Value Function Loss: 0.01883

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.13413
Value Function Update Magnitude: 0.19594

Collected Steps per Second: 8859.41171
Overall Steps per Second: 6303.41275

Timestep Collection Time: 5.64789
Timestep Consumption Time: 2.29019
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.93808

Cumulative Model Updates: 30858
Cumulative Timesteps: 257682479

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.47008
Policy Entropy: 1.30884
Value Function Loss: 0.01835

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.13179
Value Function Update Magnitude: 0.20118

Collected Steps per Second: 9735.19640
Overall Steps per Second: 7000.47816

Timestep Collection Time: 5.13939
Timestep Consumption Time: 2.00769
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.14708

Cumulative Model Updates: 30864
Cumulative Timesteps: 257732512

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.96521
Policy Entropy: 1.30556
Value Function Loss: 0.01863

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.13603
Value Function Update Magnitude: 0.20666

Collected Steps per Second: 9685.46620
Overall Steps per Second: 6621.70237

Timestep Collection Time: 5.16671
Timestep Consumption Time: 2.39056
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.55727

Cumulative Model Updates: 30870
Cumulative Timesteps: 257782554

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 257782554...
Checkpoint 257782554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.56673
Policy Entropy: 1.30454
Value Function Loss: 0.01799

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.13074
Value Function Update Magnitude: 0.20187

Collected Steps per Second: 8836.60148
Overall Steps per Second: 6341.02120

Timestep Collection Time: 5.66123
Timestep Consumption Time: 2.22804
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.88927

Cumulative Model Updates: 30876
Cumulative Timesteps: 257832580

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.66333
Policy Entropy: 1.30631
Value Function Loss: 0.01814

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.13420
Value Function Update Magnitude: 0.19883

Collected Steps per Second: 9799.96011
Overall Steps per Second: 6991.29437

Timestep Collection Time: 5.10257
Timestep Consumption Time: 2.04989
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.15247

Cumulative Model Updates: 30882
Cumulative Timesteps: 257882585

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.47246
Policy Entropy: 1.31094
Value Function Loss: 0.01881

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.13288
Value Function Update Magnitude: 0.20442

Collected Steps per Second: 10484.80218
Overall Steps per Second: 7259.02562

Timestep Collection Time: 4.77033
Timestep Consumption Time: 2.11985
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 6.89018

Cumulative Model Updates: 30888
Cumulative Timesteps: 257932601

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.00684
Policy Entropy: 1.31117
Value Function Loss: 0.01835

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.12901
Value Function Update Magnitude: 0.20422

Collected Steps per Second: 9304.31251
Overall Steps per Second: 6680.68524

Timestep Collection Time: 5.37815
Timestep Consumption Time: 2.11210
PPO Batch Consumption Time: 0.02485
Total Iteration Time: 7.49025

Cumulative Model Updates: 30894
Cumulative Timesteps: 257982641

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.90675
Policy Entropy: 1.31178
Value Function Loss: 0.01920

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.12747
Value Function Update Magnitude: 0.19878

Collected Steps per Second: 9611.89852
Overall Steps per Second: 6787.77515

Timestep Collection Time: 5.20220
Timestep Consumption Time: 2.16443
PPO Batch Consumption Time: 0.02934
Total Iteration Time: 7.36663

Cumulative Model Updates: 30900
Cumulative Timesteps: 258032644

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.93592
Policy Entropy: 1.30684
Value Function Loss: 0.01843

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07050
Policy Update Magnitude: 0.12808
Value Function Update Magnitude: 0.19733

Collected Steps per Second: 10435.02301
Overall Steps per Second: 7156.44418

Timestep Collection Time: 4.79558
Timestep Consumption Time: 2.19700
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.99258

Cumulative Model Updates: 30906
Cumulative Timesteps: 258082686

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.37115
Policy Entropy: 1.30733
Value Function Loss: 0.01827

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.06754
Policy Update Magnitude: 0.12631
Value Function Update Magnitude: 0.20507

Collected Steps per Second: 9394.37389
Overall Steps per Second: 6779.64239

Timestep Collection Time: 5.32340
Timestep Consumption Time: 2.05310
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 7.37650

Cumulative Model Updates: 30912
Cumulative Timesteps: 258132696

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.43122
Policy Entropy: 1.30463
Value Function Loss: 0.01782

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.12162
Value Function Update Magnitude: 0.19583

Collected Steps per Second: 9485.76221
Overall Steps per Second: 6757.38478

Timestep Collection Time: 5.27285
Timestep Consumption Time: 2.12898
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.40183

Cumulative Model Updates: 30918
Cumulative Timesteps: 258182713

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.18698
Policy Entropy: 1.30468
Value Function Loss: 0.01808

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.06844
Policy Update Magnitude: 0.12387
Value Function Update Magnitude: 0.19234

Collected Steps per Second: 9391.24819
Overall Steps per Second: 6839.07229

Timestep Collection Time: 5.32485
Timestep Consumption Time: 1.98711
PPO Batch Consumption Time: 0.02475
Total Iteration Time: 7.31196

Cumulative Model Updates: 30924
Cumulative Timesteps: 258232720

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.06369
Policy Entropy: 1.30552
Value Function Loss: 0.01859

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.05730
Policy Update Magnitude: 0.12413
Value Function Update Magnitude: 0.21071

Collected Steps per Second: 9778.08820
Overall Steps per Second: 7023.11230

Timestep Collection Time: 5.11787
Timestep Consumption Time: 2.00760
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.12547

Cumulative Model Updates: 30930
Cumulative Timesteps: 258282763

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 258282763...
Checkpoint 258282763 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.92838
Policy Entropy: 1.30064
Value Function Loss: 0.01929

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.12541
Value Function Update Magnitude: 0.20811

Collected Steps per Second: 10097.68426
Overall Steps per Second: 7212.59989

Timestep Collection Time: 4.95232
Timestep Consumption Time: 1.98096
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.93328

Cumulative Model Updates: 30936
Cumulative Timesteps: 258332770

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.99593
Policy Entropy: 1.30080
Value Function Loss: 0.01891

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.12734
Value Function Update Magnitude: 0.20937

Collected Steps per Second: 9539.38745
Overall Steps per Second: 6700.44708

Timestep Collection Time: 5.24300
Timestep Consumption Time: 2.22143
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.46443

Cumulative Model Updates: 30942
Cumulative Timesteps: 258382785

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.74927
Policy Entropy: 1.29943
Value Function Loss: 0.01956

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.12664
Value Function Update Magnitude: 0.20599

Collected Steps per Second: 9289.16256
Overall Steps per Second: 6717.56890

Timestep Collection Time: 5.38574
Timestep Consumption Time: 2.06175
PPO Batch Consumption Time: 0.02409
Total Iteration Time: 7.44749

Cumulative Model Updates: 30948
Cumulative Timesteps: 258432814

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.07461
Policy Entropy: 1.30108
Value Function Loss: 0.01932

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.12260
Value Function Update Magnitude: 0.20269

Collected Steps per Second: 9703.22555
Overall Steps per Second: 6942.14063

Timestep Collection Time: 5.15550
Timestep Consumption Time: 2.05049
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.20599

Cumulative Model Updates: 30954
Cumulative Timesteps: 258482839

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.82697
Policy Entropy: 1.29651
Value Function Loss: 0.02006

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.12697
Value Function Update Magnitude: 0.19581

Collected Steps per Second: 10506.65343
Overall Steps per Second: 7283.64673

Timestep Collection Time: 4.76127
Timestep Consumption Time: 2.10686
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 6.86813

Cumulative Model Updates: 30960
Cumulative Timesteps: 258532864

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.06837
Policy Entropy: 1.29330
Value Function Loss: 0.01847

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.12389
Value Function Update Magnitude: 0.20322

Collected Steps per Second: 9154.86579
Overall Steps per Second: 6547.01271

Timestep Collection Time: 5.46507
Timestep Consumption Time: 2.17689
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.64196

Cumulative Model Updates: 30966
Cumulative Timesteps: 258582896

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.19902
Policy Entropy: 1.29723
Value Function Loss: 0.01742

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.12196
Value Function Update Magnitude: 0.20712

Collected Steps per Second: 9438.73718
Overall Steps per Second: 6816.81433

Timestep Collection Time: 5.29774
Timestep Consumption Time: 2.03765
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.33539

Cumulative Model Updates: 30972
Cumulative Timesteps: 258632900

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.40719
Policy Entropy: 1.29746
Value Function Loss: 0.01647

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.12047
Value Function Update Magnitude: 0.20512

Collected Steps per Second: 10210.17336
Overall Steps per Second: 7241.16537

Timestep Collection Time: 4.90011
Timestep Consumption Time: 2.00913
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 6.90925

Cumulative Model Updates: 30978
Cumulative Timesteps: 258682931

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.99821
Policy Entropy: 1.29852
Value Function Loss: 0.01711

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.12013
Value Function Update Magnitude: 0.20031

Collected Steps per Second: 8907.02180
Overall Steps per Second: 6319.75844

Timestep Collection Time: 5.61748
Timestep Consumption Time: 2.29975
PPO Batch Consumption Time: 0.02898
Total Iteration Time: 7.91723

Cumulative Model Updates: 30984
Cumulative Timesteps: 258732966

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.47172
Policy Entropy: 1.29719
Value Function Loss: 0.01811

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.12249
Value Function Update Magnitude: 0.19160

Collected Steps per Second: 8878.58866
Overall Steps per Second: 6499.42969

Timestep Collection Time: 5.63502
Timestep Consumption Time: 2.06274
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.69775

Cumulative Model Updates: 30990
Cumulative Timesteps: 258782997

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 258782997...
Checkpoint 258782997 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.23601
Policy Entropy: 1.29688
Value Function Loss: 0.01831

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.12425
Value Function Update Magnitude: 0.18990

Collected Steps per Second: 10151.75243
Overall Steps per Second: 7200.28132

Timestep Collection Time: 4.92949
Timestep Consumption Time: 2.02065
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 6.95015

Cumulative Model Updates: 30996
Cumulative Timesteps: 258833040

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.21433
Policy Entropy: 1.29669
Value Function Loss: 0.01877

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.12567
Value Function Update Magnitude: 0.18956

Collected Steps per Second: 9387.22120
Overall Steps per Second: 6553.53115

Timestep Collection Time: 5.32852
Timestep Consumption Time: 2.30401
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 7.63253

Cumulative Model Updates: 31002
Cumulative Timesteps: 258883060

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.99159
Policy Entropy: 1.29659
Value Function Loss: 0.01941

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.12430
Value Function Update Magnitude: 0.19205

Collected Steps per Second: 9448.95070
Overall Steps per Second: 6860.55268

Timestep Collection Time: 5.29180
Timestep Consumption Time: 1.99653
PPO Batch Consumption Time: 0.02438
Total Iteration Time: 7.28833

Cumulative Model Updates: 31008
Cumulative Timesteps: 258933062

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.20931
Policy Entropy: 1.29805
Value Function Loss: 0.01857

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06967
Policy Update Magnitude: 0.12187
Value Function Update Magnitude: 0.19085

Collected Steps per Second: 10125.25674
Overall Steps per Second: 7126.16263

Timestep Collection Time: 4.94180
Timestep Consumption Time: 2.07979
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.02159

Cumulative Model Updates: 31014
Cumulative Timesteps: 258983099

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.45578
Policy Entropy: 1.29190
Value Function Loss: 0.01819

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.12371
Value Function Update Magnitude: 0.18528

Collected Steps per Second: 9195.91093
Overall Steps per Second: 6667.48774

Timestep Collection Time: 5.44046
Timestep Consumption Time: 2.06311
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.50358

Cumulative Model Updates: 31020
Cumulative Timesteps: 259033129

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.98953
Policy Entropy: 1.28995
Value Function Loss: 0.01810

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.12170
Value Function Update Magnitude: 0.18757

Collected Steps per Second: 8968.44410
Overall Steps per Second: 6537.24807

Timestep Collection Time: 5.57722
Timestep Consumption Time: 2.07416
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.65138

Cumulative Model Updates: 31026
Cumulative Timesteps: 259083148

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.39949
Policy Entropy: 1.28877
Value Function Loss: 0.01930

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.12579
Value Function Update Magnitude: 0.19521

Collected Steps per Second: 10130.14055
Overall Steps per Second: 7216.57336

Timestep Collection Time: 4.93794
Timestep Consumption Time: 1.99361
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 6.93154

Cumulative Model Updates: 31032
Cumulative Timesteps: 259133170

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.04411
Policy Entropy: 1.29039
Value Function Loss: 0.01842

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.12872
Value Function Update Magnitude: 0.19179

Collected Steps per Second: 9281.60852
Overall Steps per Second: 6588.53417

Timestep Collection Time: 5.38732
Timestep Consumption Time: 2.20208
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.58940

Cumulative Model Updates: 31038
Cumulative Timesteps: 259183173

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.46417
Policy Entropy: 1.28836
Value Function Loss: 0.01845

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.12806
Value Function Update Magnitude: 0.18654

Collected Steps per Second: 9001.39219
Overall Steps per Second: 6523.23815

Timestep Collection Time: 5.55559
Timestep Consumption Time: 2.11055
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 7.66613

Cumulative Model Updates: 31044
Cumulative Timesteps: 259233181

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.52382
Policy Entropy: 1.28636
Value Function Loss: 0.01785

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.12394
Value Function Update Magnitude: 0.18480

Collected Steps per Second: 9679.10124
Overall Steps per Second: 6725.09021

Timestep Collection Time: 5.16649
Timestep Consumption Time: 2.26939
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.43589

Cumulative Model Updates: 31050
Cumulative Timesteps: 259283188

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 259283188...
Checkpoint 259283188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.22485
Policy Entropy: 1.28794
Value Function Loss: 0.01918

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.12284
Value Function Update Magnitude: 0.18943

Collected Steps per Second: 9671.48303
Overall Steps per Second: 6841.08931

Timestep Collection Time: 5.17077
Timestep Consumption Time: 2.13932
PPO Batch Consumption Time: 0.02427
Total Iteration Time: 7.31009

Cumulative Model Updates: 31056
Cumulative Timesteps: 259333197

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.42811
Policy Entropy: 1.29247
Value Function Loss: 0.01932

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.12507
Value Function Update Magnitude: 0.19264

Collected Steps per Second: 10099.25279
Overall Steps per Second: 7134.10960

Timestep Collection Time: 4.95413
Timestep Consumption Time: 2.05908
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.01321

Cumulative Model Updates: 31062
Cumulative Timesteps: 259383230

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.81374
Policy Entropy: 1.29454
Value Function Loss: 0.01994

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.12715
Value Function Update Magnitude: 0.20329

Collected Steps per Second: 10099.60493
Overall Steps per Second: 7058.56569

Timestep Collection Time: 4.95168
Timestep Consumption Time: 2.13333
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.08501

Cumulative Model Updates: 31068
Cumulative Timesteps: 259433240

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.53538
Policy Entropy: 1.29093
Value Function Loss: 0.02019

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.12746
Value Function Update Magnitude: 0.20534

Collected Steps per Second: 9505.99981
Overall Steps per Second: 6908.79875

Timestep Collection Time: 5.26089
Timestep Consumption Time: 1.97771
PPO Batch Consumption Time: 0.02420
Total Iteration Time: 7.23860

Cumulative Model Updates: 31074
Cumulative Timesteps: 259483250

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.98710
Policy Entropy: 1.28568
Value Function Loss: 0.02046

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.12405
Value Function Update Magnitude: 0.21420

Collected Steps per Second: 10266.42183
Overall Steps per Second: 7143.62164

Timestep Collection Time: 4.87180
Timestep Consumption Time: 2.12969
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.00149

Cumulative Model Updates: 31080
Cumulative Timesteps: 259533266

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.93162
Policy Entropy: 1.29151
Value Function Loss: 0.02066

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.12248
Value Function Update Magnitude: 0.23284

Collected Steps per Second: 10550.94112
Overall Steps per Second: 7396.50277

Timestep Collection Time: 4.73958
Timestep Consumption Time: 2.02132
PPO Batch Consumption Time: 0.02377
Total Iteration Time: 6.76090

Cumulative Model Updates: 31086
Cumulative Timesteps: 259583273

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.31467
Policy Entropy: 1.30046
Value Function Loss: 0.02045

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.12238
Value Function Update Magnitude: 0.22184

Collected Steps per Second: 9317.13729
Overall Steps per Second: 6538.27170

Timestep Collection Time: 5.36903
Timestep Consumption Time: 2.28192
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.65095

Cumulative Model Updates: 31092
Cumulative Timesteps: 259633297

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.56467
Policy Entropy: 1.30325
Value Function Loss: 0.01936

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.12365
Value Function Update Magnitude: 0.20800

Collected Steps per Second: 9516.94219
Overall Steps per Second: 6918.22597

Timestep Collection Time: 5.25589
Timestep Consumption Time: 1.97429
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.23018

Cumulative Model Updates: 31098
Cumulative Timesteps: 259683317

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.97848
Policy Entropy: 1.30381
Value Function Loss: 0.02012

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06421
Policy Update Magnitude: 0.12286
Value Function Update Magnitude: 0.20059

Collected Steps per Second: 9969.64627
Overall Steps per Second: 7132.53086

Timestep Collection Time: 5.01693
Timestep Consumption Time: 1.99559
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.01252

Cumulative Model Updates: 31104
Cumulative Timesteps: 259733334

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.52287
Policy Entropy: 1.30455
Value Function Loss: 0.02020

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.12263
Value Function Update Magnitude: 0.20197

Collected Steps per Second: 8860.67952
Overall Steps per Second: 6351.25036

Timestep Collection Time: 5.64449
Timestep Consumption Time: 2.23018
PPO Batch Consumption Time: 0.02851
Total Iteration Time: 7.87467

Cumulative Model Updates: 31110
Cumulative Timesteps: 259783348

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 259783348...
Checkpoint 259783348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.59422
Policy Entropy: 1.30505
Value Function Loss: 0.01964

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06239
Policy Update Magnitude: 0.12417
Value Function Update Magnitude: 0.19998

Collected Steps per Second: 9131.01219
Overall Steps per Second: 6612.40087

Timestep Collection Time: 5.47760
Timestep Consumption Time: 2.08637
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 7.56397

Cumulative Model Updates: 31116
Cumulative Timesteps: 259833364

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.86357
Policy Entropy: 1.29822
Value Function Loss: 0.01842

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.11952
Value Function Update Magnitude: 0.18892

Collected Steps per Second: 10083.27673
Overall Steps per Second: 7033.27922

Timestep Collection Time: 4.96237
Timestep Consumption Time: 2.15195
PPO Batch Consumption Time: 0.02457
Total Iteration Time: 7.11432

Cumulative Model Updates: 31122
Cumulative Timesteps: 259883401

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.20270
Policy Entropy: 1.29388
Value Function Loss: 0.01831

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06323
Policy Update Magnitude: 0.11876
Value Function Update Magnitude: 0.17785

Collected Steps per Second: 9659.61447
Overall Steps per Second: 6890.51333

Timestep Collection Time: 5.17619
Timestep Consumption Time: 2.08016
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.25635

Cumulative Model Updates: 31128
Cumulative Timesteps: 259933401

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.88877
Policy Entropy: 1.29910
Value Function Loss: 0.01840

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.12456
Value Function Update Magnitude: 0.17508

Collected Steps per Second: 9259.41481
Overall Steps per Second: 6773.24828

Timestep Collection Time: 5.40067
Timestep Consumption Time: 1.98235
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.38302

Cumulative Model Updates: 31134
Cumulative Timesteps: 259983408

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.35597
Policy Entropy: 1.30075
Value Function Loss: 0.01904

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.12369
Value Function Update Magnitude: 0.18263

Collected Steps per Second: 10090.85997
Overall Steps per Second: 7084.58364

Timestep Collection Time: 4.95914
Timestep Consumption Time: 2.10436
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.06351

Cumulative Model Updates: 31140
Cumulative Timesteps: 260033450

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.55925
Policy Entropy: 1.30585
Value Function Loss: 0.01945

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.12358
Value Function Update Magnitude: 0.19073

Collected Steps per Second: 9095.73661
Overall Steps per Second: 6407.65312

Timestep Collection Time: 5.49972
Timestep Consumption Time: 2.30719
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.80691

Cumulative Model Updates: 31146
Cumulative Timesteps: 260083474

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.08200
Policy Entropy: 1.30042
Value Function Loss: 0.01936

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.12354
Value Function Update Magnitude: 0.19677

Collected Steps per Second: 8920.78727
Overall Steps per Second: 6447.10176

Timestep Collection Time: 5.60836
Timestep Consumption Time: 2.15187
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.76023

Cumulative Model Updates: 31152
Cumulative Timesteps: 260133505

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.58322
Policy Entropy: 1.30437
Value Function Loss: 0.01878

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.11987
Value Function Update Magnitude: 0.19659

Collected Steps per Second: 10425.15619
Overall Steps per Second: 7129.77637

Timestep Collection Time: 4.79945
Timestep Consumption Time: 2.21830
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.01775

Cumulative Model Updates: 31158
Cumulative Timesteps: 260183540

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.11568
Policy Entropy: 1.30031
Value Function Loss: 0.01871

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.12150
Value Function Update Magnitude: 0.19527

Collected Steps per Second: 9230.65504
Overall Steps per Second: 6321.06546

Timestep Collection Time: 5.41760
Timestep Consumption Time: 2.49372
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.91132

Cumulative Model Updates: 31164
Cumulative Timesteps: 260233548

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.56447
Policy Entropy: 1.30128
Value Function Loss: 0.01847

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.07608
Policy Update Magnitude: 0.12004
Value Function Update Magnitude: 0.19501

Collected Steps per Second: 9238.79474
Overall Steps per Second: 6539.87278

Timestep Collection Time: 5.41521
Timestep Consumption Time: 2.23479
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 7.65000

Cumulative Model Updates: 31170
Cumulative Timesteps: 260283578

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 260283578...
Checkpoint 260283578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.53413
Policy Entropy: 1.29955
Value Function Loss: 0.01923

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.11828
Value Function Update Magnitude: 0.19031

Collected Steps per Second: 10643.98361
Overall Steps per Second: 7214.58257

Timestep Collection Time: 4.70078
Timestep Consumption Time: 2.23448
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 6.93526

Cumulative Model Updates: 31176
Cumulative Timesteps: 260333613

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.15892
Policy Entropy: 1.30012
Value Function Loss: 0.01817

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.11919
Value Function Update Magnitude: 0.19272

Collected Steps per Second: 9681.07000
Overall Steps per Second: 6829.51627

Timestep Collection Time: 5.16647
Timestep Consumption Time: 2.15718
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.32365

Cumulative Model Updates: 31182
Cumulative Timesteps: 260383630

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.34893
Policy Entropy: 1.30447
Value Function Loss: 0.01877

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.05849
Policy Update Magnitude: 0.11695
Value Function Update Magnitude: 0.18905

Collected Steps per Second: 9824.57908
Overall Steps per Second: 6870.82533

Timestep Collection Time: 5.09325
Timestep Consumption Time: 2.18958
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 7.28282

Cumulative Model Updates: 31188
Cumulative Timesteps: 260433669

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.92040
Policy Entropy: 1.29967
Value Function Loss: 0.01819

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.06654
Policy Update Magnitude: 0.11821
Value Function Update Magnitude: 0.18410

Collected Steps per Second: 10550.87007
Overall Steps per Second: 7281.36190

Timestep Collection Time: 4.73923
Timestep Consumption Time: 2.12803
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.86726

Cumulative Model Updates: 31194
Cumulative Timesteps: 260483672

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.81682
Policy Entropy: 1.30135
Value Function Loss: 0.01858

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.06369
Policy Update Magnitude: 0.12134
Value Function Update Magnitude: 0.18619

Collected Steps per Second: 9160.49629
Overall Steps per Second: 6323.49153

Timestep Collection Time: 5.45833
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.02894
Total Iteration Time: 7.90718

Cumulative Model Updates: 31200
Cumulative Timesteps: 260533673

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.39641
Policy Entropy: 1.29701
Value Function Loss: 0.01837

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.11932
Value Function Update Magnitude: 0.17752

Collected Steps per Second: 9003.29939
Overall Steps per Second: 6381.09382

Timestep Collection Time: 5.55718
Timestep Consumption Time: 2.28363
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 7.84082

Cumulative Model Updates: 31206
Cumulative Timesteps: 260583706

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.47578
Policy Entropy: 1.30226
Value Function Loss: 0.01901

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.11985
Value Function Update Magnitude: 0.17395

Collected Steps per Second: 10731.84159
Overall Steps per Second: 7407.96698

Timestep Collection Time: 4.66211
Timestep Consumption Time: 2.09184
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 6.75394

Cumulative Model Updates: 31212
Cumulative Timesteps: 260633739

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.74322
Policy Entropy: 1.30077
Value Function Loss: 0.01946

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.17791

Collected Steps per Second: 10321.18534
Overall Steps per Second: 7206.81820

Timestep Collection Time: 4.84537
Timestep Consumption Time: 2.09389
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 6.93926

Cumulative Model Updates: 31218
Cumulative Timesteps: 260683749

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.28746
Policy Entropy: 1.30175
Value Function Loss: 0.01951

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.12164
Value Function Update Magnitude: 0.18008

Collected Steps per Second: 9160.83746
Overall Steps per Second: 6576.93014

Timestep Collection Time: 5.45998
Timestep Consumption Time: 2.14509
PPO Batch Consumption Time: 0.02328
Total Iteration Time: 7.60507

Cumulative Model Updates: 31224
Cumulative Timesteps: 260733767

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.57338
Policy Entropy: 1.30091
Value Function Loss: 0.01923

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.11760
Value Function Update Magnitude: 0.17830

Collected Steps per Second: 10031.90705
Overall Steps per Second: 7043.88529

Timestep Collection Time: 4.98559
Timestep Consumption Time: 2.11489
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.10048

Cumulative Model Updates: 31230
Cumulative Timesteps: 260783782

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 260783782...
Checkpoint 260783782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.09674
Policy Entropy: 1.29903
Value Function Loss: 0.01894

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.06718
Policy Update Magnitude: 0.11948
Value Function Update Magnitude: 0.17694

Collected Steps per Second: 9546.77480
Overall Steps per Second: 6737.97155

Timestep Collection Time: 5.23831
Timestep Consumption Time: 2.18365
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 7.42197

Cumulative Model Updates: 31236
Cumulative Timesteps: 260833791

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.49754
Policy Entropy: 1.29576
Value Function Loss: 0.01870

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.11799
Value Function Update Magnitude: 0.18437

Collected Steps per Second: 9042.56500
Overall Steps per Second: 6523.35894

Timestep Collection Time: 5.53416
Timestep Consumption Time: 2.13719
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.67135

Cumulative Model Updates: 31242
Cumulative Timesteps: 260883834

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.57830
Policy Entropy: 1.29559
Value Function Loss: 0.01707

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.11654
Value Function Update Magnitude: 0.18554

Collected Steps per Second: 10221.37676
Overall Steps per Second: 7089.06914

Timestep Collection Time: 4.89562
Timestep Consumption Time: 2.16313
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.05875

Cumulative Model Updates: 31248
Cumulative Timesteps: 260933874

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.14642
Policy Entropy: 1.29941
Value Function Loss: 0.01778

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.11499
Value Function Update Magnitude: 0.17604

Collected Steps per Second: 9114.74241
Overall Steps per Second: 6496.81607

Timestep Collection Time: 5.48803
Timestep Consumption Time: 2.21143
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.69946

Cumulative Model Updates: 31254
Cumulative Timesteps: 260983896

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.40026
Policy Entropy: 1.29964
Value Function Loss: 0.01803

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.11911
Value Function Update Magnitude: 0.18738

Collected Steps per Second: 8815.91081
Overall Steps per Second: 6350.06499

Timestep Collection Time: 5.67667
Timestep Consumption Time: 2.20435
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.88102

Cumulative Model Updates: 31260
Cumulative Timesteps: 261033941

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.08404
Policy Entropy: 1.30144
Value Function Loss: 0.01864

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07597
Policy Update Magnitude: 0.12151
Value Function Update Magnitude: 0.19830

Collected Steps per Second: 9774.35919
Overall Steps per Second: 6852.89744

Timestep Collection Time: 5.11583
Timestep Consumption Time: 2.18093
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 7.29677

Cumulative Model Updates: 31266
Cumulative Timesteps: 261083945

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.92851
Policy Entropy: 1.29945
Value Function Loss: 0.02005

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06805
Policy Update Magnitude: 0.12314
Value Function Update Magnitude: 0.19766

Collected Steps per Second: 10070.50808
Overall Steps per Second: 7136.26470

Timestep Collection Time: 4.96718
Timestep Consumption Time: 2.04237
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.00955

Cumulative Model Updates: 31272
Cumulative Timesteps: 261133967

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.16555
Policy Entropy: 1.30099
Value Function Loss: 0.02069

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.12552
Value Function Update Magnitude: 0.19927

Collected Steps per Second: 9625.96489
Overall Steps per Second: 6915.54987

Timestep Collection Time: 5.19584
Timestep Consumption Time: 2.03641
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.23225

Cumulative Model Updates: 31278
Cumulative Timesteps: 261183982

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.75998
Policy Entropy: 1.29752
Value Function Loss: 0.02037

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.12369
Value Function Update Magnitude: 0.20755

Collected Steps per Second: 9868.57075
Overall Steps per Second: 6951.25891

Timestep Collection Time: 5.06760
Timestep Consumption Time: 2.12678
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.19438

Cumulative Model Updates: 31284
Cumulative Timesteps: 261233992

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.38184
Policy Entropy: 1.29584
Value Function Loss: 0.01908

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.12117
Value Function Update Magnitude: 0.20952

Collected Steps per Second: 10185.07372
Overall Steps per Second: 7091.67178

Timestep Collection Time: 4.91327
Timestep Consumption Time: 2.14318
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.05645

Cumulative Model Updates: 31290
Cumulative Timesteps: 261284034

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 261284034...
Checkpoint 261284034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.62570
Policy Entropy: 1.29648
Value Function Loss: 0.01847

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.12196
Value Function Update Magnitude: 0.21127

Collected Steps per Second: 9762.00912
Overall Steps per Second: 6855.49135

Timestep Collection Time: 5.12528
Timestep Consumption Time: 2.17296
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 7.29824

Cumulative Model Updates: 31296
Cumulative Timesteps: 261334067

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.47269
Policy Entropy: 1.29985
Value Function Loss: 0.01934

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.12343
Value Function Update Magnitude: 0.21172

Collected Steps per Second: 9955.14200
Overall Steps per Second: 6978.18410

Timestep Collection Time: 5.02705
Timestep Consumption Time: 2.14459
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 7.17164

Cumulative Model Updates: 31302
Cumulative Timesteps: 261384112

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.90580
Policy Entropy: 1.30210
Value Function Loss: 0.01956

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.12392
Value Function Update Magnitude: 0.21447

Collected Steps per Second: 9719.33707
Overall Steps per Second: 6866.90510

Timestep Collection Time: 5.14706
Timestep Consumption Time: 2.13803
PPO Batch Consumption Time: 0.02967
Total Iteration Time: 7.28509

Cumulative Model Updates: 31308
Cumulative Timesteps: 261434138

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.96762
Policy Entropy: 1.30558
Value Function Loss: 0.01999

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.12131
Value Function Update Magnitude: 0.21618

Collected Steps per Second: 9614.34454
Overall Steps per Second: 6831.14245

Timestep Collection Time: 5.20254
Timestep Consumption Time: 2.11966
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 7.32220

Cumulative Model Updates: 31314
Cumulative Timesteps: 261484157

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.13041
Policy Entropy: 1.31075
Value Function Loss: 0.01951

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06354
Policy Update Magnitude: 0.12059
Value Function Update Magnitude: 0.22015

Collected Steps per Second: 9859.82781
Overall Steps per Second: 6767.28318

Timestep Collection Time: 5.07494
Timestep Consumption Time: 2.31917
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.39410

Cumulative Model Updates: 31320
Cumulative Timesteps: 261534195

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.53327
Policy Entropy: 1.30693
Value Function Loss: 0.01902

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.12163
Value Function Update Magnitude: 0.21972

Collected Steps per Second: 9262.20857
Overall Steps per Second: 6608.62305

Timestep Collection Time: 5.40120
Timestep Consumption Time: 2.16876
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 7.56996

Cumulative Model Updates: 31326
Cumulative Timesteps: 261584222

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.06753
Policy Entropy: 1.30830
Value Function Loss: 0.01806

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.11985
Value Function Update Magnitude: 0.22411

Collected Steps per Second: 9153.13362
Overall Steps per Second: 6723.38359

Timestep Collection Time: 5.46676
Timestep Consumption Time: 1.97562
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.44238

Cumulative Model Updates: 31332
Cumulative Timesteps: 261634260

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.71199
Policy Entropy: 1.30953
Value Function Loss: 0.01870

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.06863
Policy Update Magnitude: 0.11733
Value Function Update Magnitude: 0.21572

Collected Steps per Second: 10164.39067
Overall Steps per Second: 7053.44239

Timestep Collection Time: 4.92277
Timestep Consumption Time: 2.17121
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.09398

Cumulative Model Updates: 31338
Cumulative Timesteps: 261684297

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.25925
Policy Entropy: 1.31133
Value Function Loss: 0.01912

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.05882
Policy Update Magnitude: 0.12035
Value Function Update Magnitude: 0.20861

Collected Steps per Second: 10398.33662
Overall Steps per Second: 7326.48154

Timestep Collection Time: 4.81106
Timestep Consumption Time: 2.01719
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 6.82824

Cumulative Model Updates: 31344
Cumulative Timesteps: 261734324

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.80779
Policy Entropy: 1.30945
Value Function Loss: 0.01925

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06222
Policy Update Magnitude: 0.12114
Value Function Update Magnitude: 0.20418

Collected Steps per Second: 9360.47970
Overall Steps per Second: 6505.27580

Timestep Collection Time: 5.34374
Timestep Consumption Time: 2.34540
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.68914

Cumulative Model Updates: 31350
Cumulative Timesteps: 261784344

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 261784344...
Checkpoint 261784344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.86041
Policy Entropy: 1.30454
Value Function Loss: 0.01880

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06295
Policy Update Magnitude: 0.11993
Value Function Update Magnitude: 0.20261

Collected Steps per Second: 8557.08372
Overall Steps per Second: 6272.61526

Timestep Collection Time: 5.84370
Timestep Consumption Time: 2.12826
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.97195

Cumulative Model Updates: 31356
Cumulative Timesteps: 261834349

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.69419
Policy Entropy: 1.30268
Value Function Loss: 0.01902

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06037
Policy Update Magnitude: 0.12087
Value Function Update Magnitude: 0.19685

Collected Steps per Second: 9798.91460
Overall Steps per Second: 6994.87418

Timestep Collection Time: 5.10628
Timestep Consumption Time: 2.04696
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.15324

Cumulative Model Updates: 31362
Cumulative Timesteps: 261884385

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.68950
Policy Entropy: 1.30432
Value Function Loss: 0.02000

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06228
Policy Update Magnitude: 0.11988
Value Function Update Magnitude: 0.19569

Collected Steps per Second: 9492.27180
Overall Steps per Second: 6654.87088

Timestep Collection Time: 5.27113
Timestep Consumption Time: 2.24742
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.51855

Cumulative Model Updates: 31368
Cumulative Timesteps: 261934420

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.25056
Policy Entropy: 1.30446
Value Function Loss: 0.01993

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.06800
Policy Update Magnitude: 0.12222
Value Function Update Magnitude: 0.19671

Collected Steps per Second: 9243.68663
Overall Steps per Second: 6656.48153

Timestep Collection Time: 5.41278
Timestep Consumption Time: 2.10381
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.51658

Cumulative Model Updates: 31374
Cumulative Timesteps: 261984454

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.23472
Policy Entropy: 1.30576
Value Function Loss: 0.01955

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.12159
Value Function Update Magnitude: 0.20442

Collected Steps per Second: 10475.64673
Overall Steps per Second: 7289.33526

Timestep Collection Time: 4.77393
Timestep Consumption Time: 2.08678
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 6.86071

Cumulative Model Updates: 31380
Cumulative Timesteps: 262034464

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.95146
Policy Entropy: 1.30038
Value Function Loss: 0.01904

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.21180

Collected Steps per Second: 9268.39193
Overall Steps per Second: 6551.24566

Timestep Collection Time: 5.39619
Timestep Consumption Time: 2.23808
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.63427

Cumulative Model Updates: 31386
Cumulative Timesteps: 262084478

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.00713
Policy Entropy: 1.30214
Value Function Loss: 0.01830

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.12528
Value Function Update Magnitude: 0.21288

Collected Steps per Second: 9171.01577
Overall Steps per Second: 6572.83140

Timestep Collection Time: 5.45272
Timestep Consumption Time: 2.15541
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.60814

Cumulative Model Updates: 31392
Cumulative Timesteps: 262134485

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.54027
Policy Entropy: 1.30275
Value Function Loss: 0.01864

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.12124
Value Function Update Magnitude: 0.21188

Collected Steps per Second: 10806.67637
Overall Steps per Second: 7477.98018

Timestep Collection Time: 4.62816
Timestep Consumption Time: 2.06015
PPO Batch Consumption Time: 0.02430
Total Iteration Time: 6.68830

Cumulative Model Updates: 31398
Cumulative Timesteps: 262184500

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.24847
Policy Entropy: 1.30293
Value Function Loss: 0.01848

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.06774
Policy Update Magnitude: 0.12015
Value Function Update Magnitude: 0.21015

Collected Steps per Second: 9815.89599
Overall Steps per Second: 6850.11928

Timestep Collection Time: 5.09622
Timestep Consumption Time: 2.20642
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.30265

Cumulative Model Updates: 31404
Cumulative Timesteps: 262234524

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.81804
Policy Entropy: 1.30021
Value Function Loss: 0.01908

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.11851
Value Function Update Magnitude: 0.20266

Collected Steps per Second: 9210.95409
Overall Steps per Second: 6739.82636

Timestep Collection Time: 5.42919
Timestep Consumption Time: 1.99059
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.41978

Cumulative Model Updates: 31410
Cumulative Timesteps: 262284532

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 262284532...
Checkpoint 262284532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.23471
Policy Entropy: 1.30367
Value Function Loss: 0.01925

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.06177
Policy Update Magnitude: 0.12194
Value Function Update Magnitude: 0.19653

Collected Steps per Second: 10333.08080
Overall Steps per Second: 7187.72039

Timestep Collection Time: 4.84086
Timestep Consumption Time: 2.11837
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 6.95923

Cumulative Model Updates: 31416
Cumulative Timesteps: 262334553

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.49139
Policy Entropy: 1.30683
Value Function Loss: 0.01820

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.06626
Policy Update Magnitude: 0.11958
Value Function Update Magnitude: 0.19798

Collected Steps per Second: 10076.55347
Overall Steps per Second: 7266.77587

Timestep Collection Time: 4.96469
Timestep Consumption Time: 1.91965
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 6.88435

Cumulative Model Updates: 31422
Cumulative Timesteps: 262384580

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.75876
Policy Entropy: 1.30928
Value Function Loss: 0.01848

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.06874
Policy Update Magnitude: 0.12112
Value Function Update Magnitude: 0.20105

Collected Steps per Second: 9583.06585
Overall Steps per Second: 6971.35067

Timestep Collection Time: 5.21921
Timestep Consumption Time: 1.95530
PPO Batch Consumption Time: 0.02462
Total Iteration Time: 7.17451

Cumulative Model Updates: 31428
Cumulative Timesteps: 262434596

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.34842
Policy Entropy: 1.30875
Value Function Loss: 0.01840

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.11874
Value Function Update Magnitude: 0.20456

Collected Steps per Second: 10660.79161
Overall Steps per Second: 7346.53033

Timestep Collection Time: 4.69393
Timestep Consumption Time: 2.11759
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 6.81151

Cumulative Model Updates: 31434
Cumulative Timesteps: 262484637

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.99543
Policy Entropy: 1.31036
Value Function Loss: 0.02002

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06415
Policy Update Magnitude: 0.11974
Value Function Update Magnitude: 0.21904

Collected Steps per Second: 9901.61264
Overall Steps per Second: 7063.78603

Timestep Collection Time: 5.05059
Timestep Consumption Time: 2.02904
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.07963

Cumulative Model Updates: 31440
Cumulative Timesteps: 262534646

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.48405
Policy Entropy: 1.31230
Value Function Loss: 0.01963

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.12198
Value Function Update Magnitude: 0.22664

Collected Steps per Second: 9835.74679
Overall Steps per Second: 7091.97422

Timestep Collection Time: 5.08472
Timestep Consumption Time: 1.96720
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.05192

Cumulative Model Updates: 31446
Cumulative Timesteps: 262584658

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.60175
Policy Entropy: 1.31676
Value Function Loss: 0.01939

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05941
Policy Update Magnitude: 0.12190
Value Function Update Magnitude: 0.22229

Collected Steps per Second: 9952.27606
Overall Steps per Second: 7042.64324

Timestep Collection Time: 5.02488
Timestep Consumption Time: 2.07600
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 7.10089

Cumulative Model Updates: 31452
Cumulative Timesteps: 262634667

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.84128
Policy Entropy: 1.31519
Value Function Loss: 0.01893

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05571
Policy Update Magnitude: 0.11844
Value Function Update Magnitude: 0.21304

Collected Steps per Second: 9329.01984
Overall Steps per Second: 6596.91369

Timestep Collection Time: 5.36091
Timestep Consumption Time: 2.22021
PPO Batch Consumption Time: 0.03017
Total Iteration Time: 7.58112

Cumulative Model Updates: 31458
Cumulative Timesteps: 262684679

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.96175
Policy Entropy: 1.31112
Value Function Loss: 0.01849

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.11733
Value Function Update Magnitude: 0.21091

Collected Steps per Second: 10165.82224
Overall Steps per Second: 7154.21392

Timestep Collection Time: 4.92198
Timestep Consumption Time: 2.07194
PPO Batch Consumption Time: 0.02959
Total Iteration Time: 6.99392

Cumulative Model Updates: 31464
Cumulative Timesteps: 262734715

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.75383
Policy Entropy: 1.30080
Value Function Loss: 0.01920

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.12185
Value Function Update Magnitude: 0.20829

Collected Steps per Second: 9767.68519
Overall Steps per Second: 6964.70976

Timestep Collection Time: 5.12076
Timestep Consumption Time: 2.06087
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.18163

Cumulative Model Updates: 31470
Cumulative Timesteps: 262784733

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 262784733...
Checkpoint 262784733 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.36428
Policy Entropy: 1.29821
Value Function Loss: 0.01932

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.12504
Value Function Update Magnitude: 0.21423

Collected Steps per Second: 10025.85375
Overall Steps per Second: 6903.98004

Timestep Collection Time: 4.98940
Timestep Consumption Time: 2.25613
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.24553

Cumulative Model Updates: 31476
Cumulative Timesteps: 262834756

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.23366
Policy Entropy: 1.30236
Value Function Loss: 0.01926

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.12017
Value Function Update Magnitude: 0.21538

Collected Steps per Second: 9237.12721
Overall Steps per Second: 6582.89685

Timestep Collection Time: 5.41597
Timestep Consumption Time: 2.18372
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.59969

Cumulative Model Updates: 31482
Cumulative Timesteps: 262884784

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.89553
Policy Entropy: 1.30767
Value Function Loss: 0.01967

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.11971
Value Function Update Magnitude: 0.21168

Collected Steps per Second: 9978.22847
Overall Steps per Second: 6949.63410

Timestep Collection Time: 5.01231
Timestep Consumption Time: 2.18433
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.19664

Cumulative Model Updates: 31488
Cumulative Timesteps: 262934798

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.56944
Policy Entropy: 1.30601
Value Function Loss: 0.01961

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.12300
Value Function Update Magnitude: 0.21943

Collected Steps per Second: 9540.35716
Overall Steps per Second: 6579.33109

Timestep Collection Time: 5.24551
Timestep Consumption Time: 2.36074
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 7.60624

Cumulative Model Updates: 31494
Cumulative Timesteps: 262984842

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.45722
Policy Entropy: 1.30446
Value Function Loss: 0.01977

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.12457
Value Function Update Magnitude: 0.23412

Collected Steps per Second: 9022.14948
Overall Steps per Second: 6579.06964

Timestep Collection Time: 5.54679
Timestep Consumption Time: 2.05975
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.60655

Cumulative Model Updates: 31500
Cumulative Timesteps: 263034886

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.39131
Policy Entropy: 1.30503
Value Function Loss: 0.02015

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.12131
Value Function Update Magnitude: 0.24730

Collected Steps per Second: 9494.74952
Overall Steps per Second: 6952.60022

Timestep Collection Time: 5.26712
Timestep Consumption Time: 1.92587
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.19299

Cumulative Model Updates: 31506
Cumulative Timesteps: 263084896

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.63057
Policy Entropy: 1.30583
Value Function Loss: 0.02008

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.06798
Policy Update Magnitude: 0.12370
Value Function Update Magnitude: 0.22791

Collected Steps per Second: 9458.36354
Overall Steps per Second: 6573.14860

Timestep Collection Time: 5.28844
Timestep Consumption Time: 2.32131
PPO Batch Consumption Time: 0.03028
Total Iteration Time: 7.60975

Cumulative Model Updates: 31512
Cumulative Timesteps: 263134916

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.80932
Policy Entropy: 1.30085
Value Function Loss: 0.02040

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06138
Policy Update Magnitude: 0.12447
Value Function Update Magnitude: 0.22402

Collected Steps per Second: 9217.60262
Overall Steps per Second: 6685.55333

Timestep Collection Time: 5.42549
Timestep Consumption Time: 2.05482
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.48031

Cumulative Model Updates: 31518
Cumulative Timesteps: 263184926

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.18631
Policy Entropy: 1.29788
Value Function Loss: 0.01971

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.12472
Value Function Update Magnitude: 0.22681

Collected Steps per Second: 9735.76132
Overall Steps per Second: 7036.23473

Timestep Collection Time: 5.13725
Timestep Consumption Time: 1.97096
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 7.10821

Cumulative Model Updates: 31524
Cumulative Timesteps: 263234941

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.68981
Policy Entropy: 1.29604
Value Function Loss: 0.01965

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.12360
Value Function Update Magnitude: 0.21145

Collected Steps per Second: 9619.51622
Overall Steps per Second: 6702.65322

Timestep Collection Time: 5.20265
Timestep Consumption Time: 2.26409
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 7.46674

Cumulative Model Updates: 31530
Cumulative Timesteps: 263284988

Timesteps Collected: 50047
--------END ITERATION REPORT--------


Saving checkpoint 263284988...
Checkpoint 263284988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.40202
Policy Entropy: 1.29861
Value Function Loss: 0.02012

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.12250
Value Function Update Magnitude: 0.20943

Collected Steps per Second: 9401.06842
Overall Steps per Second: 6780.15181

Timestep Collection Time: 5.32259
Timestep Consumption Time: 2.05748
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.38007

Cumulative Model Updates: 31536
Cumulative Timesteps: 263335026

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.07562
Policy Entropy: 1.29828
Value Function Loss: 0.02072

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07179
Policy Update Magnitude: 0.12528
Value Function Update Magnitude: 0.22199

Collected Steps per Second: 10047.19415
Overall Steps per Second: 7126.51648

Timestep Collection Time: 4.97681
Timestep Consumption Time: 2.03966
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.01647

Cumulative Model Updates: 31542
Cumulative Timesteps: 263385029

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.67699
Policy Entropy: 1.30042
Value Function Loss: 0.02098

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.12481
Value Function Update Magnitude: 0.22559

Collected Steps per Second: 10565.66641
Overall Steps per Second: 7379.78432

Timestep Collection Time: 4.73562
Timestep Consumption Time: 2.04439
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 6.78001

Cumulative Model Updates: 31548
Cumulative Timesteps: 263435064

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.60417
Policy Entropy: 1.29861
Value Function Loss: 0.02055

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.12486
Value Function Update Magnitude: 0.22245

Collected Steps per Second: 9623.44836
Overall Steps per Second: 7088.30849

Timestep Collection Time: 5.19938
Timestep Consumption Time: 1.85956
PPO Batch Consumption Time: 0.02434
Total Iteration Time: 7.05895

Cumulative Model Updates: 31554
Cumulative Timesteps: 263485100

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -4.75608
Policy Entropy: 1.30885
Value Function Loss: 0.02014

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.12513
Value Function Update Magnitude: 0.21456

Collected Steps per Second: 9672.84121
Overall Steps per Second: 6966.41954

Timestep Collection Time: 5.16942
Timestep Consumption Time: 2.00830
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 7.17772

Cumulative Model Updates: 31560
Cumulative Timesteps: 263535103

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.78733
Policy Entropy: 1.30445
Value Function Loss: 0.01932

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.12294
Value Function Update Magnitude: 0.21259

Collected Steps per Second: 10583.60165
Overall Steps per Second: 7509.83133

Timestep Collection Time: 4.72476
Timestep Consumption Time: 1.93384
PPO Batch Consumption Time: 0.02471
Total Iteration Time: 6.65860

Cumulative Model Updates: 31566
Cumulative Timesteps: 263585108

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.56851
Policy Entropy: 1.30635
Value Function Loss: 0.01857

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.06746
Policy Update Magnitude: 0.12463
Value Function Update Magnitude: 0.20484

Collected Steps per Second: 9947.09741
Overall Steps per Second: 7014.78204

Timestep Collection Time: 5.02709
Timestep Consumption Time: 2.10142
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 7.12852

Cumulative Model Updates: 31572
Cumulative Timesteps: 263635113

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.51890
Policy Entropy: 1.29438
Value Function Loss: 0.01867

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.12424
Value Function Update Magnitude: 0.19422

Collected Steps per Second: 9285.00147
Overall Steps per Second: 6654.50657

Timestep Collection Time: 5.38611
Timestep Consumption Time: 2.12910
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 7.51521

Cumulative Model Updates: 31578
Cumulative Timesteps: 263685123

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.77589
Policy Entropy: 1.29954
Value Function Loss: 0.01899

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.18688

Collected Steps per Second: 9498.72561
Overall Steps per Second: 6655.13429

Timestep Collection Time: 5.26786
Timestep Consumption Time: 2.25084
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.51871

Cumulative Model Updates: 31584
Cumulative Timesteps: 263735161

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.10945
Policy Entropy: 1.29734
Value Function Loss: 0.01942

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.12156
Value Function Update Magnitude: 0.19119

Collected Steps per Second: 9882.10509
Overall Steps per Second: 6946.83637

Timestep Collection Time: 5.06218
Timestep Consumption Time: 2.13894
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.20112

Cumulative Model Updates: 31590
Cumulative Timesteps: 263785186

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 263785186...
Checkpoint 263785186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.14291
Policy Entropy: 1.30119
Value Function Loss: 0.01891

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06512
Policy Update Magnitude: 0.12067
Value Function Update Magnitude: 0.19120

Collected Steps per Second: 9309.09206
Overall Steps per Second: 6533.91668

Timestep Collection Time: 5.37227
Timestep Consumption Time: 2.28179
PPO Batch Consumption Time: 0.03036
Total Iteration Time: 7.65406

Cumulative Model Updates: 31596
Cumulative Timesteps: 263835197

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.68197
Policy Entropy: 1.30000
Value Function Loss: 0.01879

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.05844
Policy Update Magnitude: 0.11866
Value Function Update Magnitude: 0.18680

Collected Steps per Second: 9067.27134
Overall Steps per Second: 6353.53533

Timestep Collection Time: 5.51676
Timestep Consumption Time: 2.35633
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.87310

Cumulative Model Updates: 31602
Cumulative Timesteps: 263885219

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.28365
Policy Entropy: 1.30039
Value Function Loss: 0.01902

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.12074
Value Function Update Magnitude: 0.19566

Collected Steps per Second: 9512.92869
Overall Steps per Second: 6802.61192

Timestep Collection Time: 5.25664
Timestep Consumption Time: 2.09436
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.35100

Cumulative Model Updates: 31608
Cumulative Timesteps: 263935225

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.66526
Policy Entropy: 1.30205
Value Function Loss: 0.01890

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.12158
Value Function Update Magnitude: 0.20136

Collected Steps per Second: 9682.54228
Overall Steps per Second: 7029.61726

Timestep Collection Time: 5.16559
Timestep Consumption Time: 1.94945
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.11504

Cumulative Model Updates: 31614
Cumulative Timesteps: 263985241

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.69605
Policy Entropy: 1.31057
Value Function Loss: 0.01940

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07264
Policy Update Magnitude: 0.12155
Value Function Update Magnitude: 0.19404

Collected Steps per Second: 9346.89395
Overall Steps per Second: 6532.10105

Timestep Collection Time: 5.35301
Timestep Consumption Time: 2.30670
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 7.65971

Cumulative Model Updates: 31620
Cumulative Timesteps: 264035275

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.67689
Policy Entropy: 1.31092
Value Function Loss: 0.01865

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06656
Policy Update Magnitude: 0.12085
Value Function Update Magnitude: 0.19786

Collected Steps per Second: 9586.99494
Overall Steps per Second: 6748.63325

Timestep Collection Time: 5.21905
Timestep Consumption Time: 2.19504
PPO Batch Consumption Time: 0.02924
Total Iteration Time: 7.41409

Cumulative Model Updates: 31626
Cumulative Timesteps: 264085310

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.69022
Policy Entropy: 1.31029
Value Function Loss: 0.01884

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.07007
Policy Update Magnitude: 0.11794
Value Function Update Magnitude: 0.19563

Collected Steps per Second: 9685.08852
Overall Steps per Second: 6815.52226

Timestep Collection Time: 5.16258
Timestep Consumption Time: 2.17362
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.33619

Cumulative Model Updates: 31632
Cumulative Timesteps: 264135310

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.93486
Policy Entropy: 1.30223
Value Function Loss: 0.01801

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.11810
Value Function Update Magnitude: 0.18657

Collected Steps per Second: 9237.01860
Overall Steps per Second: 6547.31634

Timestep Collection Time: 5.41419
Timestep Consumption Time: 2.22420
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 7.63840

Cumulative Model Updates: 31638
Cumulative Timesteps: 264185321

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.56330
Policy Entropy: 1.30191
Value Function Loss: 0.01930

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.12510
Value Function Update Magnitude: 0.18268

Collected Steps per Second: 9192.92843
Overall Steps per Second: 6606.34109

Timestep Collection Time: 5.43907
Timestep Consumption Time: 2.12957
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.56864

Cumulative Model Updates: 31644
Cumulative Timesteps: 264235322

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.09866
Policy Entropy: 1.29636
Value Function Loss: 0.01905

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.12348
Value Function Update Magnitude: 0.18513

Collected Steps per Second: 9940.05561
Overall Steps per Second: 7166.11503

Timestep Collection Time: 5.03166
Timestep Consumption Time: 1.94771
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 6.97937

Cumulative Model Updates: 31650
Cumulative Timesteps: 264285337

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 264285337...
Checkpoint 264285337 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.39926
Policy Entropy: 1.29383
Value Function Loss: 0.01977

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.12186
Value Function Update Magnitude: 0.19916

Collected Steps per Second: 9896.81796
Overall Steps per Second: 6934.34121

Timestep Collection Time: 5.05526
Timestep Consumption Time: 2.15970
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 7.21496

Cumulative Model Updates: 31656
Cumulative Timesteps: 264335368

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.10898
Policy Entropy: 1.28898
Value Function Loss: 0.01887

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.12110
Value Function Update Magnitude: 0.20690

Collected Steps per Second: 9283.56866
Overall Steps per Second: 6672.54511

Timestep Collection Time: 5.38931
Timestep Consumption Time: 2.10888
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 7.49819

Cumulative Model Updates: 31662
Cumulative Timesteps: 264385400

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.05597
Policy Entropy: 1.29191
Value Function Loss: 0.01923

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.07172
Policy Update Magnitude: 0.13121
Value Function Update Magnitude: 0.20546

Collected Steps per Second: 9027.76687
Overall Steps per Second: 6629.87247

Timestep Collection Time: 5.54157
Timestep Consumption Time: 2.00428
PPO Batch Consumption Time: 0.02409
Total Iteration Time: 7.54585

Cumulative Model Updates: 31668
Cumulative Timesteps: 264435428

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.34569
Policy Entropy: 1.29548
Value Function Loss: 0.02023

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.12573
Value Function Update Magnitude: 0.20456

Collected Steps per Second: 9798.24236
Overall Steps per Second: 6987.86809

Timestep Collection Time: 5.10500
Timestep Consumption Time: 2.05312
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.15812

Cumulative Model Updates: 31674
Cumulative Timesteps: 264485448

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.17950
Policy Entropy: 1.29758
Value Function Loss: 0.01948

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.06774
Policy Update Magnitude: 0.12469
Value Function Update Magnitude: 0.20869

Collected Steps per Second: 9728.80670
Overall Steps per Second: 6945.74986

Timestep Collection Time: 5.14143
Timestep Consumption Time: 2.06009
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 7.20153

Cumulative Model Updates: 31680
Cumulative Timesteps: 264535468

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.54300
Policy Entropy: 1.29969
Value Function Loss: 0.01999

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.12520
Value Function Update Magnitude: 0.20903

Collected Steps per Second: 8841.03217
Overall Steps per Second: 6445.09432

Timestep Collection Time: 5.66054
Timestep Consumption Time: 2.10428
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 7.76482

Cumulative Model Updates: 31686
Cumulative Timesteps: 264585513

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.82319
Policy Entropy: 1.29963
Value Function Loss: 0.01947

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.12254
Value Function Update Magnitude: 0.20049

Collected Steps per Second: 9677.76752
Overall Steps per Second: 7003.65867

Timestep Collection Time: 5.16689
Timestep Consumption Time: 1.97280
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.13970

Cumulative Model Updates: 31692
Cumulative Timesteps: 264635517

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.98128
Policy Entropy: 1.30036
Value Function Loss: 0.02038

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.06700
Policy Update Magnitude: 0.12583
Value Function Update Magnitude: 0.20601

Collected Steps per Second: 9601.79319
Overall Steps per Second: 6954.82787

Timestep Collection Time: 5.20861
Timestep Consumption Time: 1.98237
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.19098

Cumulative Model Updates: 31698
Cumulative Timesteps: 264685529

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.47185
Policy Entropy: 1.29604
Value Function Loss: 0.01957

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.12533
Value Function Update Magnitude: 0.21660

Collected Steps per Second: 9195.37317
Overall Steps per Second: 6667.07505

Timestep Collection Time: 5.44100
Timestep Consumption Time: 2.06334
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.50434

Cumulative Model Updates: 31704
Cumulative Timesteps: 264735561

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.65094
Policy Entropy: 1.29669
Value Function Loss: 0.02081

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.12368
Value Function Update Magnitude: 0.21177

Collected Steps per Second: 10309.24716
Overall Steps per Second: 7169.07257

Timestep Collection Time: 4.85292
Timestep Consumption Time: 2.12566
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 6.97859

Cumulative Model Updates: 31710
Cumulative Timesteps: 264785591

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 264785591...
Checkpoint 264785591 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.34249
Policy Entropy: 1.29415
Value Function Loss: 0.01992

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.12269
Value Function Update Magnitude: 0.21070

Collected Steps per Second: 9306.40773
Overall Steps per Second: 6605.18753

Timestep Collection Time: 5.37683
Timestep Consumption Time: 2.19888
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.57571

Cumulative Model Updates: 31716
Cumulative Timesteps: 264835630

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.89208
Policy Entropy: 1.30035
Value Function Loss: 0.01950

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.12193
Value Function Update Magnitude: 0.20803

Collected Steps per Second: 8667.84203
Overall Steps per Second: 6359.12372

Timestep Collection Time: 5.77272
Timestep Consumption Time: 2.09582
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.86854

Cumulative Model Updates: 31722
Cumulative Timesteps: 264885667

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.64141
Policy Entropy: 1.30178
Value Function Loss: 0.01782

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.11839
Value Function Update Magnitude: 0.20101

Collected Steps per Second: 10728.74759
Overall Steps per Second: 7383.51135

Timestep Collection Time: 4.66355
Timestep Consumption Time: 2.11291
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 6.77645

Cumulative Model Updates: 31728
Cumulative Timesteps: 264935701

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.68383
Policy Entropy: 1.30283
Value Function Loss: 0.01860

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06398
Policy Update Magnitude: 0.12141
Value Function Update Magnitude: 0.21080

Collected Steps per Second: 10445.45315
Overall Steps per Second: 7335.17101

Timestep Collection Time: 4.78888
Timestep Consumption Time: 2.03059
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 6.81947

Cumulative Model Updates: 31734
Cumulative Timesteps: 264985723

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.56763
Policy Entropy: 1.29889
Value Function Loss: 0.01869

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.13520
Value Function Update Magnitude: 0.22349

Collected Steps per Second: 9274.26863
Overall Steps per Second: 6595.68545

Timestep Collection Time: 5.39342
Timestep Consumption Time: 2.19033
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 7.58375

Cumulative Model Updates: 31740
Cumulative Timesteps: 265035743

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.46032
Policy Entropy: 1.30022
Value Function Loss: 0.01911

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.14521
Value Function Update Magnitude: 0.22191

Collected Steps per Second: 10282.44357
Overall Steps per Second: 7211.87885

Timestep Collection Time: 4.86616
Timestep Consumption Time: 2.07184
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 6.93800

Cumulative Model Updates: 31746
Cumulative Timesteps: 265085779

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.91002
Policy Entropy: 1.29969
Value Function Loss: 0.01917

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.14196
Value Function Update Magnitude: 0.22075

Collected Steps per Second: 9276.82225
Overall Steps per Second: 6754.03177

Timestep Collection Time: 5.39085
Timestep Consumption Time: 2.01361
PPO Batch Consumption Time: 0.02371
Total Iteration Time: 7.40447

Cumulative Model Updates: 31752
Cumulative Timesteps: 265135789

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.64283
Policy Entropy: 1.30313
Value Function Loss: 0.01902

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.13155
Value Function Update Magnitude: 0.22313

Collected Steps per Second: 9305.75353
Overall Steps per Second: 6789.26076

Timestep Collection Time: 5.37517
Timestep Consumption Time: 1.99235
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.36752

Cumulative Model Updates: 31758
Cumulative Timesteps: 265185809

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.42504
Policy Entropy: 1.29993
Value Function Loss: 0.01915

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.12387
Value Function Update Magnitude: 0.21320

Collected Steps per Second: 10178.76624
Overall Steps per Second: 7264.67417

Timestep Collection Time: 4.91641
Timestep Consumption Time: 1.97213
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 6.88854

Cumulative Model Updates: 31764
Cumulative Timesteps: 265235852

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.28534
Policy Entropy: 1.30763
Value Function Loss: 0.01900

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.12084
Value Function Update Magnitude: 0.21233

Collected Steps per Second: 9883.96891
Overall Steps per Second: 7044.69686

Timestep Collection Time: 5.06254
Timestep Consumption Time: 2.04039
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.10293

Cumulative Model Updates: 31770
Cumulative Timesteps: 265285890

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 265285890...
Checkpoint 265285890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.55098
Policy Entropy: 1.30733
Value Function Loss: 0.01942

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.06558
Policy Update Magnitude: 0.11651
Value Function Update Magnitude: 0.20599

Collected Steps per Second: 9498.69539
Overall Steps per Second: 6783.97397

Timestep Collection Time: 5.26693
Timestep Consumption Time: 2.10765
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 7.37459

Cumulative Model Updates: 31776
Cumulative Timesteps: 265335919

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.91253
Policy Entropy: 1.30713
Value Function Loss: 0.01905

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.07422
Policy Update Magnitude: 0.12043
Value Function Update Magnitude: 0.20466

Collected Steps per Second: 10043.59452
Overall Steps per Second: 7050.19483

Timestep Collection Time: 4.98029
Timestep Consumption Time: 2.11455
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.09484

Cumulative Model Updates: 31782
Cumulative Timesteps: 265385939

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.98495
Policy Entropy: 1.30709
Value Function Loss: 0.01882

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.11798
Value Function Update Magnitude: 0.20668

Collected Steps per Second: 9746.50136
Overall Steps per Second: 7058.77009

Timestep Collection Time: 5.13394
Timestep Consumption Time: 1.95483
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.08877

Cumulative Model Updates: 31788
Cumulative Timesteps: 265435977

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.70269
Policy Entropy: 1.31176
Value Function Loss: 0.01819

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.06974
Policy Update Magnitude: 0.11736
Value Function Update Magnitude: 0.20438

Collected Steps per Second: 9434.33660
Overall Steps per Second: 6834.33435

Timestep Collection Time: 5.30149
Timestep Consumption Time: 2.01686
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.31834

Cumulative Model Updates: 31794
Cumulative Timesteps: 265485993

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.96425
Policy Entropy: 1.31006
Value Function Loss: 0.01926

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.11985
Value Function Update Magnitude: 0.20264

Collected Steps per Second: 9893.40299
Overall Steps per Second: 7061.91140

Timestep Collection Time: 5.05781
Timestep Consumption Time: 2.02794
PPO Batch Consumption Time: 0.02427
Total Iteration Time: 7.08576

Cumulative Model Updates: 31800
Cumulative Timesteps: 265536032

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.68342
Policy Entropy: 1.30584
Value Function Loss: 0.01881

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.11935
Value Function Update Magnitude: 0.20973

Collected Steps per Second: 9947.86871
Overall Steps per Second: 6915.60325

Timestep Collection Time: 5.02650
Timestep Consumption Time: 2.20396
PPO Batch Consumption Time: 0.02491
Total Iteration Time: 7.23046

Cumulative Model Updates: 31806
Cumulative Timesteps: 265586035

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.65305
Policy Entropy: 1.30258
Value Function Loss: 0.01946

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.12098
Value Function Update Magnitude: 0.20602

Collected Steps per Second: 9094.43877
Overall Steps per Second: 6417.44614

Timestep Collection Time: 5.50270
Timestep Consumption Time: 2.29541
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 7.79812

Cumulative Model Updates: 31812
Cumulative Timesteps: 265636079

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.58479
Policy Entropy: 1.30190
Value Function Loss: 0.01897

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.12022
Value Function Update Magnitude: 0.21048

Collected Steps per Second: 9495.09733
Overall Steps per Second: 6663.55739

Timestep Collection Time: 5.26682
Timestep Consumption Time: 2.23803
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 7.50485

Cumulative Model Updates: 31818
Cumulative Timesteps: 265686088

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.57549
Policy Entropy: 1.30549
Value Function Loss: 0.01984

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.11823
Value Function Update Magnitude: 0.20948

Collected Steps per Second: 9787.48713
Overall Steps per Second: 6861.96830

Timestep Collection Time: 5.11265
Timestep Consumption Time: 2.17972
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.29237

Cumulative Model Updates: 31824
Cumulative Timesteps: 265736128

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.96079
Policy Entropy: 1.31185
Value Function Loss: 0.01953

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06559
Policy Update Magnitude: 0.11890
Value Function Update Magnitude: 0.20152

Collected Steps per Second: 8847.45179
Overall Steps per Second: 6455.66629

Timestep Collection Time: 5.65168
Timestep Consumption Time: 2.09391
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.74560

Cumulative Model Updates: 31830
Cumulative Timesteps: 265786131

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 265786131...
Checkpoint 265786131 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.94038
Policy Entropy: 1.30979
Value Function Loss: 0.02000

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07103
Policy Update Magnitude: 0.11989
Value Function Update Magnitude: 0.19976

Collected Steps per Second: 9749.49319
Overall Steps per Second: 6907.56792

Timestep Collection Time: 5.12929
Timestep Consumption Time: 2.11030
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.23960

Cumulative Model Updates: 31836
Cumulative Timesteps: 265836139

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.40716
Policy Entropy: 1.31240
Value Function Loss: 0.01984

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.12124
Value Function Update Magnitude: 0.19607

Collected Steps per Second: 9290.05771
Overall Steps per Second: 6654.83648

Timestep Collection Time: 5.38414
Timestep Consumption Time: 2.13204
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 7.51619

Cumulative Model Updates: 31842
Cumulative Timesteps: 265886158

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.37691
Policy Entropy: 1.31071
Value Function Loss: 0.01956

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.12291
Value Function Update Magnitude: 0.18965

Collected Steps per Second: 8990.10305
Overall Steps per Second: 6490.93565

Timestep Collection Time: 5.56378
Timestep Consumption Time: 2.14219
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.70598

Cumulative Model Updates: 31848
Cumulative Timesteps: 265936177

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.93373
Policy Entropy: 1.31384
Value Function Loss: 0.01905

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.05805
Policy Update Magnitude: 0.12587
Value Function Update Magnitude: 0.19305

Collected Steps per Second: 10126.13989
Overall Steps per Second: 6999.98742

Timestep Collection Time: 4.94107
Timestep Consumption Time: 2.20665
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.14773

Cumulative Model Updates: 31854
Cumulative Timesteps: 265986211

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.65205
Policy Entropy: 1.30264
Value Function Loss: 0.01908

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.12330
Value Function Update Magnitude: 0.19590

Collected Steps per Second: 9108.69497
Overall Steps per Second: 6535.36481

Timestep Collection Time: 5.49014
Timestep Consumption Time: 2.16177
PPO Batch Consumption Time: 0.02367
Total Iteration Time: 7.65191

Cumulative Model Updates: 31860
Cumulative Timesteps: 266036219

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.22426
Policy Entropy: 1.30301
Value Function Loss: 0.01902

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.13146
Value Function Update Magnitude: 0.19223

Collected Steps per Second: 9187.38557
Overall Steps per Second: 6479.88616

Timestep Collection Time: 5.44377
Timestep Consumption Time: 2.27458
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 7.71835

Cumulative Model Updates: 31866
Cumulative Timesteps: 266086233

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.77799
Policy Entropy: 1.30173
Value Function Loss: 0.01952

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.13244
Value Function Update Magnitude: 0.19229

Collected Steps per Second: 9993.90809
Overall Steps per Second: 7122.87314

Timestep Collection Time: 5.00675
Timestep Consumption Time: 2.01808
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.02483

Cumulative Model Updates: 31872
Cumulative Timesteps: 266136270

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.87094
Policy Entropy: 1.30368
Value Function Loss: 0.01891

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.12640
Value Function Update Magnitude: 0.19290

Collected Steps per Second: 9991.41555
Overall Steps per Second: 7107.45692

Timestep Collection Time: 5.00660
Timestep Consumption Time: 2.03150
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.03810

Cumulative Model Updates: 31878
Cumulative Timesteps: 266186293

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.20405
Policy Entropy: 1.30183
Value Function Loss: 0.01925

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.12218
Value Function Update Magnitude: 0.19066

Collected Steps per Second: 10059.56745
Overall Steps per Second: 3739.53946

Timestep Collection Time: 4.97109
Timestep Consumption Time: 8.40141
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 13.37250

Cumulative Model Updates: 31884
Cumulative Timesteps: 266236300

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.85180
Policy Entropy: 1.30211
Value Function Loss: 0.01876

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.12247
Value Function Update Magnitude: 0.19468

Collected Steps per Second: 10573.04110
Overall Steps per Second: 7493.76773

Timestep Collection Time: 4.72901
Timestep Consumption Time: 1.94320
PPO Batch Consumption Time: 0.02460
Total Iteration Time: 6.67221

Cumulative Model Updates: 31890
Cumulative Timesteps: 266286300

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 266286300...
Checkpoint 266286300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.54166
Policy Entropy: 1.29975
Value Function Loss: 0.01878

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.12652
Value Function Update Magnitude: 0.19679

Collected Steps per Second: 9951.71758
Overall Steps per Second: 7014.14247

Timestep Collection Time: 5.02888
Timestep Consumption Time: 2.10613
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.13501

Cumulative Model Updates: 31896
Cumulative Timesteps: 266336346

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.13911
Policy Entropy: 1.29390
Value Function Loss: 0.01854

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.12379
Value Function Update Magnitude: 0.20509

Collected Steps per Second: 9482.46968
Overall Steps per Second: 6693.15633

Timestep Collection Time: 5.27468
Timestep Consumption Time: 2.19818
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 7.47286

Cumulative Model Updates: 31902
Cumulative Timesteps: 266386363

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.40667
Policy Entropy: 1.30135
Value Function Loss: 0.01891

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.12165
Value Function Update Magnitude: 0.19228

Collected Steps per Second: 10000.76343
Overall Steps per Second: 6994.20442

Timestep Collection Time: 5.00292
Timestep Consumption Time: 2.15058
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 7.15349

Cumulative Model Updates: 31908
Cumulative Timesteps: 266436396

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.79071
Policy Entropy: 1.30427
Value Function Loss: 0.01872

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.11882
Value Function Update Magnitude: 0.19190

Collected Steps per Second: 9965.53967
Overall Steps per Second: 7162.06707

Timestep Collection Time: 5.02120
Timestep Consumption Time: 1.96547
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 6.98667

Cumulative Model Updates: 31914
Cumulative Timesteps: 266486435

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.96097
Policy Entropy: 1.31133
Value Function Loss: 0.01980

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.20227

Collected Steps per Second: 9300.77092
Overall Steps per Second: 6749.96329

Timestep Collection Time: 5.37601
Timestep Consumption Time: 2.03159
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 7.40760

Cumulative Model Updates: 31920
Cumulative Timesteps: 266536436

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.61440
Policy Entropy: 1.30078
Value Function Loss: 0.01899

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.20314

Collected Steps per Second: 9448.49347
Overall Steps per Second: 6680.63208

Timestep Collection Time: 5.29365
Timestep Consumption Time: 2.19322
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.48687

Cumulative Model Updates: 31926
Cumulative Timesteps: 266586453

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.58014
Policy Entropy: 1.29977
Value Function Loss: 0.01987

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.12347
Value Function Update Magnitude: 0.20515

Collected Steps per Second: 9447.63081
Overall Steps per Second: 6689.03505

Timestep Collection Time: 5.29625
Timestep Consumption Time: 2.18420
PPO Batch Consumption Time: 0.02890
Total Iteration Time: 7.48045

Cumulative Model Updates: 31932
Cumulative Timesteps: 266636490

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.19930
Policy Entropy: 1.29539
Value Function Loss: 0.01951

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.12286
Value Function Update Magnitude: 0.19875

Collected Steps per Second: 9076.50264
Overall Steps per Second: 6504.57313

Timestep Collection Time: 5.51038
Timestep Consumption Time: 2.17882
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.68921

Cumulative Model Updates: 31938
Cumulative Timesteps: 266686505

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97794
Policy Entropy: 1.29726
Value Function Loss: 0.01886

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.12365
Value Function Update Magnitude: 0.20136

Collected Steps per Second: 10046.17246
Overall Steps per Second: 6943.30872

Timestep Collection Time: 4.98100
Timestep Consumption Time: 2.22594
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 7.20694

Cumulative Model Updates: 31944
Cumulative Timesteps: 266736545

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.79434
Policy Entropy: 1.29551
Value Function Loss: 0.01830

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.11996
Value Function Update Magnitude: 0.20061

Collected Steps per Second: 9572.84378
Overall Steps per Second: 6751.91949

Timestep Collection Time: 5.22374
Timestep Consumption Time: 2.18246
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 7.40619

Cumulative Model Updates: 31950
Cumulative Timesteps: 266786551

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 266786551...
Checkpoint 266786551 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.28125
Policy Entropy: 1.30116
Value Function Loss: 0.01781

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.11781
Value Function Update Magnitude: 0.19295

Collected Steps per Second: 9451.65531
Overall Steps per Second: 6759.85726

Timestep Collection Time: 5.29188
Timestep Consumption Time: 2.10724
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.39912

Cumulative Model Updates: 31956
Cumulative Timesteps: 266836568

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.84791
Policy Entropy: 1.29765
Value Function Loss: 0.01925

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.12183
Value Function Update Magnitude: 0.19426

Collected Steps per Second: 9725.87292
Overall Steps per Second: 6700.11173

Timestep Collection Time: 5.14360
Timestep Consumption Time: 2.32284
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 7.46644

Cumulative Model Updates: 31962
Cumulative Timesteps: 266886594

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.61719
Policy Entropy: 1.29570
Value Function Loss: 0.01885

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.12189
Value Function Update Magnitude: 0.19135

Collected Steps per Second: 8855.58802
Overall Steps per Second: 6348.24936

Timestep Collection Time: 5.64830
Timestep Consumption Time: 2.23088
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 7.87918

Cumulative Model Updates: 31968
Cumulative Timesteps: 266936613

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.70298
Policy Entropy: 1.29089
Value Function Loss: 0.01857

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.12076
Value Function Update Magnitude: 0.18808

Collected Steps per Second: 9120.43996
Overall Steps per Second: 6544.39480

Timestep Collection Time: 5.48625
Timestep Consumption Time: 2.15953
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 7.64578

Cumulative Model Updates: 31974
Cumulative Timesteps: 266986650

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.81525
Policy Entropy: 1.29131
Value Function Loss: 0.01813

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.18547

Collected Steps per Second: 9681.29531
Overall Steps per Second: 6884.08733

Timestep Collection Time: 5.16646
Timestep Consumption Time: 2.09928
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.26574

Cumulative Model Updates: 31980
Cumulative Timesteps: 267036668

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.47090
Policy Entropy: 1.29197
Value Function Loss: 0.01827

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.12255
Value Function Update Magnitude: 0.19508

Collected Steps per Second: 9422.10035
Overall Steps per Second: 6796.62035

Timestep Collection Time: 5.31092
Timestep Consumption Time: 2.05156
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 7.36248

Cumulative Model Updates: 31986
Cumulative Timesteps: 267086708

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.11470
Policy Entropy: 1.29603
Value Function Loss: 0.01870

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.12152
Value Function Update Magnitude: 0.20450

Collected Steps per Second: 9717.31358
Overall Steps per Second: 6978.85961

Timestep Collection Time: 5.14813
Timestep Consumption Time: 2.02009
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.16822

Cumulative Model Updates: 31992
Cumulative Timesteps: 267136734

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.73138
Policy Entropy: 1.29866
Value Function Loss: 0.02002

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.12169
Value Function Update Magnitude: 0.21236

Collected Steps per Second: 10713.32284
Overall Steps per Second: 7552.58428

Timestep Collection Time: 4.67054
Timestep Consumption Time: 1.95461
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 6.62515

Cumulative Model Updates: 31998
Cumulative Timesteps: 267186771

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.01890
Policy Entropy: 1.29707
Value Function Loss: 0.02046

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07144
Policy Update Magnitude: 0.12378
Value Function Update Magnitude: 0.21445

Collected Steps per Second: 10071.57012
Overall Steps per Second: 7189.16243

Timestep Collection Time: 4.96636
Timestep Consumption Time: 1.99120
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.95756

Cumulative Model Updates: 32004
Cumulative Timesteps: 267236790

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.75153
Policy Entropy: 1.29277
Value Function Loss: 0.02069

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07154
Policy Update Magnitude: 0.12558
Value Function Update Magnitude: 0.21833

Collected Steps per Second: 9987.16321
Overall Steps per Second: 7177.48708

Timestep Collection Time: 5.00793
Timestep Consumption Time: 1.96039
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 6.96832

Cumulative Model Updates: 32010
Cumulative Timesteps: 267286805

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 267286805...
Checkpoint 267286805 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.82461
Policy Entropy: 1.29539
Value Function Loss: 0.02018

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.06940
Policy Update Magnitude: 0.12531
Value Function Update Magnitude: 0.21599

Collected Steps per Second: 10233.55549
Overall Steps per Second: 7083.32012

Timestep Collection Time: 4.88657
Timestep Consumption Time: 2.17325
PPO Batch Consumption Time: 0.02398
Total Iteration Time: 7.05982

Cumulative Model Updates: 32016
Cumulative Timesteps: 267336812

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.82120
Policy Entropy: 1.29712
Value Function Loss: 0.02034

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.12767
Value Function Update Magnitude: 0.20415

Collected Steps per Second: 9361.26926
Overall Steps per Second: 6679.43157

Timestep Collection Time: 5.34340
Timestep Consumption Time: 2.14541
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 7.48881

Cumulative Model Updates: 32022
Cumulative Timesteps: 267386833

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.69132
Policy Entropy: 1.29284
Value Function Loss: 0.01980

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07011
Policy Update Magnitude: 0.12510
Value Function Update Magnitude: 0.19647

Collected Steps per Second: 9645.27910
Overall Steps per Second: 6880.44066

Timestep Collection Time: 5.18585
Timestep Consumption Time: 2.08388
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.26974

Cumulative Model Updates: 32028
Cumulative Timesteps: 267436852

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.75352
Policy Entropy: 1.28555
Value Function Loss: 0.02022

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.19729

Collected Steps per Second: 10411.03508
Overall Steps per Second: 7033.58539

Timestep Collection Time: 4.80269
Timestep Consumption Time: 2.30620
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.10889

Cumulative Model Updates: 32034
Cumulative Timesteps: 267486853

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.40832
Policy Entropy: 1.28467
Value Function Loss: 0.01940

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.12209
Value Function Update Magnitude: 0.19674

Collected Steps per Second: 9556.50132
Overall Steps per Second: 6866.53794

Timestep Collection Time: 5.23466
Timestep Consumption Time: 2.05067
PPO Batch Consumption Time: 0.02346
Total Iteration Time: 7.28533

Cumulative Model Updates: 32040
Cumulative Timesteps: 267536878

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.07293
Policy Entropy: 1.28865
Value Function Loss: 0.01923

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.12337
Value Function Update Magnitude: 0.20241

Collected Steps per Second: 9513.33670
Overall Steps per Second: 6637.39958

Timestep Collection Time: 5.25704
Timestep Consumption Time: 2.27784
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 7.53488

Cumulative Model Updates: 32046
Cumulative Timesteps: 267586890

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.37075
Policy Entropy: 1.29144
Value Function Loss: 0.01827

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.12499
Value Function Update Magnitude: 0.19814

Collected Steps per Second: 9523.82947
Overall Steps per Second: 6599.46504

Timestep Collection Time: 5.25041
Timestep Consumption Time: 2.32657
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.57698

Cumulative Model Updates: 32052
Cumulative Timesteps: 267636894

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.44076
Policy Entropy: 1.29061
Value Function Loss: 0.01909

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.12325
Value Function Update Magnitude: 0.21221

Collected Steps per Second: 9666.35802
Overall Steps per Second: 6861.62221

Timestep Collection Time: 5.17351
Timestep Consumption Time: 2.11471
PPO Batch Consumption Time: 0.02466
Total Iteration Time: 7.28822

Cumulative Model Updates: 32058
Cumulative Timesteps: 267686903

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.14060
Policy Entropy: 1.29343
Value Function Loss: 0.01987

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.12280
Value Function Update Magnitude: 0.20923

Collected Steps per Second: 9939.22317
Overall Steps per Second: 6979.39299

Timestep Collection Time: 5.03239
Timestep Consumption Time: 2.13414
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.16653

Cumulative Model Updates: 32064
Cumulative Timesteps: 267736921

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.90677
Policy Entropy: 1.29560
Value Function Loss: 0.02015

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.12338
Value Function Update Magnitude: 0.20133

Collected Steps per Second: 9676.70981
Overall Steps per Second: 6587.83574

Timestep Collection Time: 5.16911
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 7.59278

Cumulative Model Updates: 32070
Cumulative Timesteps: 267786941

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 267786941...
Checkpoint 267786941 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.42456
Policy Entropy: 1.29653
Value Function Loss: 0.01980

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06367
Policy Update Magnitude: 0.12237
Value Function Update Magnitude: 0.20193

Collected Steps per Second: 9242.34466
Overall Steps per Second: 6676.82944

Timestep Collection Time: 5.41107
Timestep Consumption Time: 2.07916
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.49023

Cumulative Model Updates: 32076
Cumulative Timesteps: 267836952

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.82520
Policy Entropy: 1.29716
Value Function Loss: 0.01999

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.06457
Policy Update Magnitude: 0.12319
Value Function Update Magnitude: 0.20312

Collected Steps per Second: 9956.22608
Overall Steps per Second: 7085.80011

Timestep Collection Time: 5.02399
Timestep Consumption Time: 2.03520
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 7.05919

Cumulative Model Updates: 32082
Cumulative Timesteps: 267886972

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.70146
Policy Entropy: 1.29756
Value Function Loss: 0.02020

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06290
Policy Update Magnitude: 0.12780
Value Function Update Magnitude: 0.19006

Collected Steps per Second: 10732.14487
Overall Steps per Second: 7337.34165

Timestep Collection Time: 4.65918
Timestep Consumption Time: 2.15569
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 6.81487

Cumulative Model Updates: 32088
Cumulative Timesteps: 267936975

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.57259
Policy Entropy: 1.29787
Value Function Loss: 0.02010

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06745
Policy Update Magnitude: 0.12555
Value Function Update Magnitude: 0.20029

Collected Steps per Second: 9234.40117
Overall Steps per Second: 6577.90921

Timestep Collection Time: 5.41703
Timestep Consumption Time: 2.18767
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.60470

Cumulative Model Updates: 32094
Cumulative Timesteps: 267986998

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.90647
Policy Entropy: 1.29842
Value Function Loss: 0.02001

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.12432
Value Function Update Magnitude: 0.20662

Collected Steps per Second: 9431.41809
Overall Steps per Second: 6788.22031

Timestep Collection Time: 5.30302
Timestep Consumption Time: 2.06489
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 7.36791

Cumulative Model Updates: 32100
Cumulative Timesteps: 268037013

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.26500
Policy Entropy: 1.30238
Value Function Loss: 0.01910

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.11812
Value Function Update Magnitude: 0.20031

Collected Steps per Second: 10067.98695
Overall Steps per Second: 6963.58126

Timestep Collection Time: 4.96882
Timestep Consumption Time: 2.21513
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.18395

Cumulative Model Updates: 32106
Cumulative Timesteps: 268087039

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.62880
Policy Entropy: 1.29958
Value Function Loss: 0.01983

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.06716
Policy Update Magnitude: 0.12090
Value Function Update Magnitude: 0.18802

Collected Steps per Second: 9340.26675
Overall Steps per Second: 6498.85602

Timestep Collection Time: 5.35520
Timestep Consumption Time: 2.34138
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 7.69659

Cumulative Model Updates: 32112
Cumulative Timesteps: 268137058

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.13825
Policy Entropy: 1.29860
Value Function Loss: 0.02005

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06253
Policy Update Magnitude: 0.13032
Value Function Update Magnitude: 0.18193

Collected Steps per Second: 9562.79171
Overall Steps per Second: 6958.93445

Timestep Collection Time: 5.22975
Timestep Consumption Time: 1.95684
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.18659

Cumulative Model Updates: 32118
Cumulative Timesteps: 268187069

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.37104
Policy Entropy: 1.30062
Value Function Loss: 0.02072

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.14042
Value Function Update Magnitude: 0.18828

Collected Steps per Second: 10032.44831
Overall Steps per Second: 7104.41774

Timestep Collection Time: 4.98483
Timestep Consumption Time: 2.05446
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.03928

Cumulative Model Updates: 32124
Cumulative Timesteps: 268237079

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.27372
Policy Entropy: 1.30537
Value Function Loss: 0.02019

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.13837
Value Function Update Magnitude: 0.18919

Collected Steps per Second: 9921.79807
Overall Steps per Second: 7113.87707

Timestep Collection Time: 5.04405
Timestep Consumption Time: 1.99094
PPO Batch Consumption Time: 0.02505
Total Iteration Time: 7.03498

Cumulative Model Updates: 32130
Cumulative Timesteps: 268287125

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 268287125...
Checkpoint 268287125 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.35969
Policy Entropy: 1.30826
Value Function Loss: 0.01962

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.13681
Value Function Update Magnitude: 0.18215

Collected Steps per Second: 10208.20493
Overall Steps per Second: 7226.24439

Timestep Collection Time: 4.89939
Timestep Consumption Time: 2.02177
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 6.92116

Cumulative Model Updates: 32136
Cumulative Timesteps: 268337139

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.18403
Policy Entropy: 1.30459
Value Function Loss: 0.01941

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.05843
Policy Update Magnitude: 0.13669
Value Function Update Magnitude: 0.19251

Collected Steps per Second: 9577.69137
Overall Steps per Second: 6617.93513

Timestep Collection Time: 5.22464
Timestep Consumption Time: 2.33663
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.56127

Cumulative Model Updates: 32142
Cumulative Timesteps: 268387179

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.59185
Policy Entropy: 1.30374
Value Function Loss: 0.01967

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.06440
Policy Update Magnitude: 0.13294
Value Function Update Magnitude: 0.19438

Collected Steps per Second: 8964.72980
Overall Steps per Second: 6542.33713

Timestep Collection Time: 5.57875
Timestep Consumption Time: 2.06561
PPO Batch Consumption Time: 0.02377
Total Iteration Time: 7.64436

Cumulative Model Updates: 32148
Cumulative Timesteps: 268437191

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.80843
Policy Entropy: 1.30587
Value Function Loss: 0.01926

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.13051
Value Function Update Magnitude: 0.20026

Collected Steps per Second: 9571.41527
Overall Steps per Second: 6800.62812

Timestep Collection Time: 5.22420
Timestep Consumption Time: 2.12850
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.35270

Cumulative Model Updates: 32154
Cumulative Timesteps: 268487194

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.32824
Policy Entropy: 1.30884
Value Function Loss: 0.01900

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.05934
Policy Update Magnitude: 0.12514
Value Function Update Magnitude: 0.19106

Collected Steps per Second: 9553.68605
Overall Steps per Second: 6515.04996

Timestep Collection Time: 5.23358
Timestep Consumption Time: 2.44096
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 7.67454

Cumulative Model Updates: 32160
Cumulative Timesteps: 268537194

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.97369
Policy Entropy: 1.30921
Value Function Loss: 0.01810

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.05835
Policy Update Magnitude: 0.12391
Value Function Update Magnitude: 0.18374

Collected Steps per Second: 8637.40393
Overall Steps per Second: 6286.60430

Timestep Collection Time: 5.79294
Timestep Consumption Time: 2.16620
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.95915

Cumulative Model Updates: 32166
Cumulative Timesteps: 268587230

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.37283
Policy Entropy: 1.30102
Value Function Loss: 0.01843

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.06652
Policy Update Magnitude: 0.12300
Value Function Update Magnitude: 0.18489

Collected Steps per Second: 9676.57845
Overall Steps per Second: 6870.71100

Timestep Collection Time: 5.16774
Timestep Consumption Time: 2.11040
PPO Batch Consumption Time: 0.02499
Total Iteration Time: 7.27814

Cumulative Model Updates: 32172
Cumulative Timesteps: 268637236

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.96314
Policy Entropy: 1.29966
Value Function Loss: 0.01791

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.12225
Value Function Update Magnitude: 0.19365

Collected Steps per Second: 10030.19832
Overall Steps per Second: 6849.57801

Timestep Collection Time: 4.98744
Timestep Consumption Time: 2.31593
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 7.30337

Cumulative Model Updates: 32178
Cumulative Timesteps: 268687261

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.38956
Policy Entropy: 1.29862
Value Function Loss: 0.01835

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.12330
Value Function Update Magnitude: 0.19841

Collected Steps per Second: 8823.60617
Overall Steps per Second: 6292.46986

Timestep Collection Time: 5.66922
Timestep Consumption Time: 2.28044
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.94966

Cumulative Model Updates: 32184
Cumulative Timesteps: 268737284

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.96043
Policy Entropy: 1.30181
Value Function Loss: 0.01802

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.12062
Value Function Update Magnitude: 0.19810

Collected Steps per Second: 9884.22580
Overall Steps per Second: 6869.32798

Timestep Collection Time: 5.06271
Timestep Consumption Time: 2.22199
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.28470

Cumulative Model Updates: 32190
Cumulative Timesteps: 268787325

Timesteps Collected: 50041
--------END ITERATION REPORT--------


Saving checkpoint 268787325...
Checkpoint 268787325 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.01976
Policy Entropy: 1.29968
Value Function Loss: 0.01815

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.20208

Collected Steps per Second: 10278.98329
Overall Steps per Second: 6957.01477

Timestep Collection Time: 4.86566
Timestep Consumption Time: 2.32335
PPO Batch Consumption Time: 0.02879
Total Iteration Time: 7.18900

Cumulative Model Updates: 32196
Cumulative Timesteps: 268837339

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.03071
Policy Entropy: 1.29934
Value Function Loss: 0.01835

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.11999
Value Function Update Magnitude: 0.19834

Collected Steps per Second: 9018.87331
Overall Steps per Second: 6393.84466

Timestep Collection Time: 5.54482
Timestep Consumption Time: 2.27646
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.82127

Cumulative Model Updates: 32202
Cumulative Timesteps: 268887347

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.89944
Policy Entropy: 1.29639
Value Function Loss: 0.01843

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.11719
Value Function Update Magnitude: 0.19840

Collected Steps per Second: 9610.54565
Overall Steps per Second: 6819.78965

Timestep Collection Time: 5.20407
Timestep Consumption Time: 2.12958
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.33366

Cumulative Model Updates: 32208
Cumulative Timesteps: 268937361

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.87152
Policy Entropy: 1.29776
Value Function Loss: 0.01897

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.11889
Value Function Update Magnitude: 0.19413

Collected Steps per Second: 10826.78187
Overall Steps per Second: 7468.81009

Timestep Collection Time: 4.62067
Timestep Consumption Time: 2.07745
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 6.69812

Cumulative Model Updates: 32214
Cumulative Timesteps: 268987388

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.88401
Policy Entropy: 1.29877
Value Function Loss: 0.01974

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.12257
Value Function Update Magnitude: 0.18972

Collected Steps per Second: 10087.87078
Overall Steps per Second: 7155.11179

Timestep Collection Time: 4.96012
Timestep Consumption Time: 2.03307
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 6.99318

Cumulative Model Updates: 32220
Cumulative Timesteps: 269037425

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.70414
Policy Entropy: 1.30704
Value Function Loss: 0.02035

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.12491
Value Function Update Magnitude: 0.19568

Collected Steps per Second: 10060.00579
Overall Steps per Second: 7258.70812

Timestep Collection Time: 4.97137
Timestep Consumption Time: 1.91856
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 6.88993

Cumulative Model Updates: 32226
Cumulative Timesteps: 269087437

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.29337
Policy Entropy: 1.30564
Value Function Loss: 0.02021

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.13025
Value Function Update Magnitude: 0.20282

Collected Steps per Second: 10057.59103
Overall Steps per Second: 6934.88003

Timestep Collection Time: 4.97405
Timestep Consumption Time: 2.23977
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 7.21382

Cumulative Model Updates: 32232
Cumulative Timesteps: 269137464

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.34762
Policy Entropy: 1.30232
Value Function Loss: 0.01906

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.12926
Value Function Update Magnitude: 0.19428

Collected Steps per Second: 9294.34675
Overall Steps per Second: 6721.86379

Timestep Collection Time: 5.38316
Timestep Consumption Time: 2.06016
PPO Batch Consumption Time: 0.02311
Total Iteration Time: 7.44332

Cumulative Model Updates: 32238
Cumulative Timesteps: 269187497

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.26409
Policy Entropy: 1.30239
Value Function Loss: 0.01845

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.12683
Value Function Update Magnitude: 0.19385

Collected Steps per Second: 9337.30944
Overall Steps per Second: 6805.94218

Timestep Collection Time: 5.35561
Timestep Consumption Time: 1.99194
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.34755

Cumulative Model Updates: 32244
Cumulative Timesteps: 269237504

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.67638
Policy Entropy: 1.31097
Value Function Loss: 0.01854

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.12348
Value Function Update Magnitude: 0.20373

Collected Steps per Second: 9905.11994
Overall Steps per Second: 7013.72921

Timestep Collection Time: 5.04820
Timestep Consumption Time: 2.08111
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.12930

Cumulative Model Updates: 32250
Cumulative Timesteps: 269287507

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 269287507...
Checkpoint 269287507 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.28060
Policy Entropy: 1.31077
Value Function Loss: 0.01919

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.06991
Policy Update Magnitude: 0.12603
Value Function Update Magnitude: 0.20107

Collected Steps per Second: 9415.84777
Overall Steps per Second: 6802.36885

Timestep Collection Time: 5.31349
Timestep Consumption Time: 2.04145
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.35494

Cumulative Model Updates: 32256
Cumulative Timesteps: 269337538

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.49450
Policy Entropy: 1.30898
Value Function Loss: 0.01939

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.12841
Value Function Update Magnitude: 0.20853

Collected Steps per Second: 9745.24449
Overall Steps per Second: 6997.90949

Timestep Collection Time: 5.13153
Timestep Consumption Time: 2.01461
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 7.14613

Cumulative Model Updates: 32262
Cumulative Timesteps: 269387546

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.77702
Policy Entropy: 1.30437
Value Function Loss: 0.01962

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.13229
Value Function Update Magnitude: 0.22633

Collected Steps per Second: 9812.96500
Overall Steps per Second: 6714.14582

Timestep Collection Time: 5.09927
Timestep Consumption Time: 2.35350
PPO Batch Consumption Time: 0.03002
Total Iteration Time: 7.45277

Cumulative Model Updates: 32268
Cumulative Timesteps: 269437585

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.68308
Policy Entropy: 1.30450
Value Function Loss: 0.01899

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.12989
Value Function Update Magnitude: 0.21267

Collected Steps per Second: 8774.78974
Overall Steps per Second: 6295.37560

Timestep Collection Time: 5.70054
Timestep Consumption Time: 2.24514
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 7.94567

Cumulative Model Updates: 32274
Cumulative Timesteps: 269487606

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.28978
Policy Entropy: 1.30729
Value Function Loss: 0.01931

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.12630
Value Function Update Magnitude: 0.21199

Collected Steps per Second: 9825.02029
Overall Steps per Second: 7065.86161

Timestep Collection Time: 5.09007
Timestep Consumption Time: 1.98763
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 7.07769

Cumulative Model Updates: 32280
Cumulative Timesteps: 269537616

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.75294
Policy Entropy: 1.30906
Value Function Loss: 0.02082

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.12717
Value Function Update Magnitude: 0.21101

Collected Steps per Second: 9714.09811
Overall Steps per Second: 6706.89714

Timestep Collection Time: 5.14850
Timestep Consumption Time: 2.30845
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.45695

Cumulative Model Updates: 32286
Cumulative Timesteps: 269587629

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.45118
Policy Entropy: 1.30465
Value Function Loss: 0.02023

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.12707
Value Function Update Magnitude: 0.21460

Collected Steps per Second: 8772.32125
Overall Steps per Second: 6325.73428

Timestep Collection Time: 5.69986
Timestep Consumption Time: 2.20452
PPO Batch Consumption Time: 0.02443
Total Iteration Time: 7.90438

Cumulative Model Updates: 32292
Cumulative Timesteps: 269637630

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.41385
Policy Entropy: 1.30604
Value Function Loss: 0.02006

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.12340
Value Function Update Magnitude: 0.20869

Collected Steps per Second: 9876.89198
Overall Steps per Second: 7023.92520

Timestep Collection Time: 5.06617
Timestep Consumption Time: 2.05777
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.12394

Cumulative Model Updates: 32298
Cumulative Timesteps: 269687668

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.57827
Policy Entropy: 1.30459
Value Function Loss: 0.01870

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.05632
Policy Update Magnitude: 0.12329
Value Function Update Magnitude: 0.20102

Collected Steps per Second: 9823.87592
Overall Steps per Second: 6949.62919

Timestep Collection Time: 5.09086
Timestep Consumption Time: 2.10549
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 7.19636

Cumulative Model Updates: 32304
Cumulative Timesteps: 269737680

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.18819
Policy Entropy: 1.30586
Value Function Loss: 0.01976

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.12626
Value Function Update Magnitude: 0.20478

Collected Steps per Second: 9283.41031
Overall Steps per Second: 6834.44279

Timestep Collection Time: 5.38703
Timestep Consumption Time: 1.93032
PPO Batch Consumption Time: 0.02456
Total Iteration Time: 7.31735

Cumulative Model Updates: 32310
Cumulative Timesteps: 269787690

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 269787690...
Checkpoint 269787690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.33279
Policy Entropy: 1.30025
Value Function Loss: 0.01971

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.12558
Value Function Update Magnitude: 0.20678

Collected Steps per Second: 9721.04471
Overall Steps per Second: 6879.06113

Timestep Collection Time: 5.14749
Timestep Consumption Time: 2.12661
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.27410

Cumulative Model Updates: 32316
Cumulative Timesteps: 269837729

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.33784
Policy Entropy: 1.30195
Value Function Loss: 0.01962

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.12275
Value Function Update Magnitude: 0.20949

Collected Steps per Second: 10246.12475
Overall Steps per Second: 7151.88689

Timestep Collection Time: 4.88067
Timestep Consumption Time: 2.11161
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 6.99228

Cumulative Model Updates: 32322
Cumulative Timesteps: 269887737

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.19182
Policy Entropy: 1.30616
Value Function Loss: 0.01920

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.12434
Value Function Update Magnitude: 0.22358

Collected Steps per Second: 9124.29740
Overall Steps per Second: 6616.57160

Timestep Collection Time: 5.48239
Timestep Consumption Time: 2.07787
PPO Batch Consumption Time: 0.02362
Total Iteration Time: 7.56026

Cumulative Model Updates: 32328
Cumulative Timesteps: 269937760

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.22077
Policy Entropy: 1.30593
Value Function Loss: 0.01928

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.12429
Value Function Update Magnitude: 0.21911

Collected Steps per Second: 9800.91480
Overall Steps per Second: 7010.65254

Timestep Collection Time: 5.10279
Timestep Consumption Time: 2.03093
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.13372

Cumulative Model Updates: 32334
Cumulative Timesteps: 269987772

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.05055
Policy Entropy: 1.30196
Value Function Loss: 0.01929

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.12486
Value Function Update Magnitude: 0.22242

Collected Steps per Second: 10148.68766
Overall Steps per Second: 7302.88954

Timestep Collection Time: 4.92793
Timestep Consumption Time: 1.92032
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 6.84825

Cumulative Model Updates: 32340
Cumulative Timesteps: 270037784

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.43544
Policy Entropy: 1.30001
Value Function Loss: 0.02016

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.12336
Value Function Update Magnitude: 0.21834

Collected Steps per Second: 9688.83830
Overall Steps per Second: 7065.25778

Timestep Collection Time: 5.16295
Timestep Consumption Time: 1.91719
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.08014

Cumulative Model Updates: 32346
Cumulative Timesteps: 270087807

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.95548
Policy Entropy: 1.29934
Value Function Loss: 0.02067

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.12438
Value Function Update Magnitude: 0.21734

Collected Steps per Second: 9599.82560
Overall Steps per Second: 6951.08138

Timestep Collection Time: 5.20926
Timestep Consumption Time: 1.98501
PPO Batch Consumption Time: 0.02418
Total Iteration Time: 7.19428

Cumulative Model Updates: 32352
Cumulative Timesteps: 270137815

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.18892
Policy Entropy: 1.30045
Value Function Loss: 0.02029

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.12279
Value Function Update Magnitude: 0.21953

Collected Steps per Second: 9776.88883
Overall Steps per Second: 6815.14380

Timestep Collection Time: 5.11461
Timestep Consumption Time: 2.22272
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.33734

Cumulative Model Updates: 32358
Cumulative Timesteps: 270187820

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.77405
Policy Entropy: 1.30146
Value Function Loss: 0.01994

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.12067
Value Function Update Magnitude: 0.21863

Collected Steps per Second: 9801.78848
Overall Steps per Second: 6951.51302

Timestep Collection Time: 5.10346
Timestep Consumption Time: 2.09253
PPO Batch Consumption Time: 0.02846
Total Iteration Time: 7.19599

Cumulative Model Updates: 32364
Cumulative Timesteps: 270237843

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.62004
Policy Entropy: 1.30571
Value Function Loss: 0.01925

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.12190
Value Function Update Magnitude: 0.21747

Collected Steps per Second: 9825.51005
Overall Steps per Second: 6873.47843

Timestep Collection Time: 5.09164
Timestep Consumption Time: 2.18677
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.27841

Cumulative Model Updates: 32370
Cumulative Timesteps: 270287871

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 270287871...
Checkpoint 270287871 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.58496
Policy Entropy: 1.30478
Value Function Loss: 0.01902

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.21412

Collected Steps per Second: 9869.55691
Overall Steps per Second: 6958.19857

Timestep Collection Time: 5.06720
Timestep Consumption Time: 2.12015
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.18735

Cumulative Model Updates: 32376
Cumulative Timesteps: 270337882

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.78565
Policy Entropy: 1.30385
Value Function Loss: 0.01864

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.11909
Value Function Update Magnitude: 0.21330

Collected Steps per Second: 9663.64555
Overall Steps per Second: 6918.83101

Timestep Collection Time: 5.17403
Timestep Consumption Time: 2.05262
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.22665

Cumulative Model Updates: 32382
Cumulative Timesteps: 270387882

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.69908
Policy Entropy: 1.30663
Value Function Loss: 0.01855

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.11698
Value Function Update Magnitude: 0.20763

Collected Steps per Second: 9613.36009
Overall Steps per Second: 6835.65007

Timestep Collection Time: 5.20390
Timestep Consumption Time: 2.11464
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.31854

Cumulative Model Updates: 32388
Cumulative Timesteps: 270437909

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.08149
Policy Entropy: 1.29634
Value Function Loss: 0.01891

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.11896
Value Function Update Magnitude: 0.21615

Collected Steps per Second: 9370.75757
Overall Steps per Second: 6495.83641

Timestep Collection Time: 5.34023
Timestep Consumption Time: 2.36347
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.70370

Cumulative Model Updates: 32394
Cumulative Timesteps: 270487951

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.05833
Policy Entropy: 1.29893
Value Function Loss: 0.01961

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.12024
Value Function Update Magnitude: 0.21062

Collected Steps per Second: 9015.83950
Overall Steps per Second: 6544.65852

Timestep Collection Time: 5.54835
Timestep Consumption Time: 2.09499
PPO Batch Consumption Time: 0.02496
Total Iteration Time: 7.64333

Cumulative Model Updates: 32400
Cumulative Timesteps: 270537974

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.30095
Policy Entropy: 1.29403
Value Function Loss: 0.01969

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.12454
Value Function Update Magnitude: 0.20265

Collected Steps per Second: 9905.82000
Overall Steps per Second: 7020.53596

Timestep Collection Time: 5.05117
Timestep Consumption Time: 2.07592
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 7.12709

Cumulative Model Updates: 32406
Cumulative Timesteps: 270588010

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.47030
Policy Entropy: 1.29558
Value Function Loss: 0.02057

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.12514
Value Function Update Magnitude: 0.20269

Collected Steps per Second: 9871.66506
Overall Steps per Second: 6747.99185

Timestep Collection Time: 5.06885
Timestep Consumption Time: 2.34639
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.41524

Cumulative Model Updates: 32412
Cumulative Timesteps: 270638048

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.05669
Policy Entropy: 1.29790
Value Function Loss: 0.01996

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.12342
Value Function Update Magnitude: 0.20362

Collected Steps per Second: 9032.09054
Overall Steps per Second: 6464.80802

Timestep Collection Time: 5.53703
Timestep Consumption Time: 2.19885
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.73588

Cumulative Model Updates: 32418
Cumulative Timesteps: 270688059

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.80363
Policy Entropy: 1.29978
Value Function Loss: 0.02004

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.12231
Value Function Update Magnitude: 0.20739

Collected Steps per Second: 9805.11677
Overall Steps per Second: 6947.85448

Timestep Collection Time: 5.10264
Timestep Consumption Time: 2.09843
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 7.20107

Cumulative Model Updates: 32424
Cumulative Timesteps: 270738091

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.18520
Policy Entropy: 1.30097
Value Function Loss: 0.01962

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.12280
Value Function Update Magnitude: 0.20511

Collected Steps per Second: 10372.96032
Overall Steps per Second: 7169.41839

Timestep Collection Time: 4.82447
Timestep Consumption Time: 2.15574
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 6.98020

Cumulative Model Updates: 32430
Cumulative Timesteps: 270788135

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 270788135...
Checkpoint 270788135 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.36625
Policy Entropy: 1.29624
Value Function Loss: 0.02024

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.12547
Value Function Update Magnitude: 0.20378

Collected Steps per Second: 9794.94661
Overall Steps per Second: 7081.80549

Timestep Collection Time: 5.10753
Timestep Consumption Time: 1.95677
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 7.06430

Cumulative Model Updates: 32436
Cumulative Timesteps: 270838163

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.46659
Policy Entropy: 1.29754
Value Function Loss: 0.02066

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.12584
Value Function Update Magnitude: 0.20296

Collected Steps per Second: 10024.86089
Overall Steps per Second: 7055.69894

Timestep Collection Time: 4.99189
Timestep Consumption Time: 2.10067
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.09256

Cumulative Model Updates: 32442
Cumulative Timesteps: 270888206

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.18288
Policy Entropy: 1.29781
Value Function Loss: 0.02095

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.12479
Value Function Update Magnitude: 0.20723

Collected Steps per Second: 9392.18456
Overall Steps per Second: 6546.58688

Timestep Collection Time: 5.32358
Timestep Consumption Time: 2.31399
PPO Batch Consumption Time: 0.02903
Total Iteration Time: 7.63757

Cumulative Model Updates: 32448
Cumulative Timesteps: 270938206

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.64992
Policy Entropy: 1.30479
Value Function Loss: 0.02018

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.07350
Policy Update Magnitude: 0.12098
Value Function Update Magnitude: 0.21263

Collected Steps per Second: 9110.64840
Overall Steps per Second: 6487.90176

Timestep Collection Time: 5.48874
Timestep Consumption Time: 2.21883
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 7.70758

Cumulative Model Updates: 32454
Cumulative Timesteps: 270988212

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.76746
Policy Entropy: 1.30128
Value Function Loss: 0.01985

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.11946
Value Function Update Magnitude: 0.21421

Collected Steps per Second: 9181.74206
Overall Steps per Second: 6468.00747

Timestep Collection Time: 5.44766
Timestep Consumption Time: 2.28563
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.73329

Cumulative Model Updates: 32460
Cumulative Timesteps: 271038231

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.68624
Policy Entropy: 1.30070
Value Function Loss: 0.02002

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.12464
Value Function Update Magnitude: 0.22199

Collected Steps per Second: 10071.30900
Overall Steps per Second: 6990.41825

Timestep Collection Time: 4.96678
Timestep Consumption Time: 2.18901
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.15580

Cumulative Model Updates: 32466
Cumulative Timesteps: 271088253

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.80632
Policy Entropy: 1.30081
Value Function Loss: 0.01988

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.06857
Policy Update Magnitude: 0.12245
Value Function Update Magnitude: 0.22921

Collected Steps per Second: 9927.12837
Overall Steps per Second: 7123.02680

Timestep Collection Time: 5.03983
Timestep Consumption Time: 1.98401
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.02384

Cumulative Model Updates: 32472
Cumulative Timesteps: 271138284

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.81390
Policy Entropy: 1.30412
Value Function Loss: 0.02079

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.12488
Value Function Update Magnitude: 0.22113

Collected Steps per Second: 9889.64005
Overall Steps per Second: 7113.42514

Timestep Collection Time: 5.05812
Timestep Consumption Time: 1.97407
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 7.03220

Cumulative Model Updates: 32478
Cumulative Timesteps: 271188307

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.56761
Policy Entropy: 1.30178
Value Function Loss: 0.02006

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.12008
Value Function Update Magnitude: 0.23785

Collected Steps per Second: 9613.42552
Overall Steps per Second: 6568.62141

Timestep Collection Time: 5.20584
Timestep Consumption Time: 2.41311
PPO Batch Consumption Time: 0.02879
Total Iteration Time: 7.61895

Cumulative Model Updates: 32484
Cumulative Timesteps: 271238353

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.34445
Policy Entropy: 1.30006
Value Function Loss: 0.02043

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06192
Policy Update Magnitude: 0.12072
Value Function Update Magnitude: 0.22586

Collected Steps per Second: 8866.95920
Overall Steps per Second: 6319.89000

Timestep Collection Time: 5.64196
Timestep Consumption Time: 2.27385
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.91580

Cumulative Model Updates: 32490
Cumulative Timesteps: 271288380

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 271288380...
Checkpoint 271288380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.81902
Policy Entropy: 1.29591
Value Function Loss: 0.02029

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.12056
Value Function Update Magnitude: 0.22974

Collected Steps per Second: 9618.89141
Overall Steps per Second: 6867.15186

Timestep Collection Time: 5.19852
Timestep Consumption Time: 2.08310
PPO Batch Consumption Time: 0.03032
Total Iteration Time: 7.28162

Cumulative Model Updates: 32496
Cumulative Timesteps: 271338384

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.66811
Policy Entropy: 1.29497
Value Function Loss: 0.01984

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07555
Policy Update Magnitude: 0.12223
Value Function Update Magnitude: 0.22595

Collected Steps per Second: 9649.97139
Overall Steps per Second: 6358.19326

Timestep Collection Time: 5.18281
Timestep Consumption Time: 2.68326
PPO Batch Consumption Time: 0.02881
Total Iteration Time: 7.86607

Cumulative Model Updates: 32502
Cumulative Timesteps: 271388398

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.40718
Policy Entropy: 1.29598
Value Function Loss: 0.01991

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.12141
Value Function Update Magnitude: 0.23086

Collected Steps per Second: 9415.87284
Overall Steps per Second: 6512.75815

Timestep Collection Time: 5.31114
Timestep Consumption Time: 2.36748
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.67862

Cumulative Model Updates: 32508
Cumulative Timesteps: 271438407

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.53995
Policy Entropy: 1.29650
Value Function Loss: 0.01950

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06749
Policy Update Magnitude: 0.11928
Value Function Update Magnitude: 0.22166

Collected Steps per Second: 9811.41496
Overall Steps per Second: 7130.05634

Timestep Collection Time: 5.09702
Timestep Consumption Time: 1.91681
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.01383

Cumulative Model Updates: 32514
Cumulative Timesteps: 271488416

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.72225
Policy Entropy: 1.29864
Value Function Loss: 0.01867

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06384
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.21749

Collected Steps per Second: 9852.96171
Overall Steps per Second: 6986.07901

Timestep Collection Time: 5.07563
Timestep Consumption Time: 2.08289
PPO Batch Consumption Time: 0.02811
Total Iteration Time: 7.15852

Cumulative Model Updates: 32520
Cumulative Timesteps: 271538426

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.34710
Policy Entropy: 1.30142
Value Function Loss: 0.01879

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.05898
Policy Update Magnitude: 0.12006
Value Function Update Magnitude: 0.21710

Collected Steps per Second: 9870.26714
Overall Steps per Second: 6798.07865

Timestep Collection Time: 5.07018
Timestep Consumption Time: 2.29131
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.36149

Cumulative Model Updates: 32526
Cumulative Timesteps: 271588470

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.25888
Policy Entropy: 1.29804
Value Function Loss: 0.02015

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.12148
Value Function Update Magnitude: 0.22640

Collected Steps per Second: 9670.33725
Overall Steps per Second: 6861.82616

Timestep Collection Time: 5.17293
Timestep Consumption Time: 2.11726
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.29019

Cumulative Model Updates: 32532
Cumulative Timesteps: 271638494

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.94420
Policy Entropy: 1.30091
Value Function Loss: 0.02048

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.12262
Value Function Update Magnitude: 0.23245

Collected Steps per Second: 9696.15727
Overall Steps per Second: 6921.74132

Timestep Collection Time: 5.16050
Timestep Consumption Time: 2.06846
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.22896

Cumulative Model Updates: 32538
Cumulative Timesteps: 271688531

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.87730
Policy Entropy: 1.30106
Value Function Loss: 0.01956

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07264
Policy Update Magnitude: 0.12366
Value Function Update Magnitude: 0.23710

Collected Steps per Second: 9672.92905
Overall Steps per Second: 6800.38662

Timestep Collection Time: 5.17320
Timestep Consumption Time: 2.18520
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.35841

Cumulative Model Updates: 32544
Cumulative Timesteps: 271738571

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.10643
Policy Entropy: 1.30803
Value Function Loss: 0.01851

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.05662
Policy Update Magnitude: 0.12023
Value Function Update Magnitude: 0.23363

Collected Steps per Second: 9503.14369
Overall Steps per Second: 6749.70610

Timestep Collection Time: 5.26478
Timestep Consumption Time: 2.14769
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.41247

Cumulative Model Updates: 32550
Cumulative Timesteps: 271788603

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 271788603...
Checkpoint 271788603 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.72042
Policy Entropy: 1.30243
Value Function Loss: 0.01911

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.05937
Policy Update Magnitude: 0.12121
Value Function Update Magnitude: 0.22474

Collected Steps per Second: 9696.69040
Overall Steps per Second: 6975.71286

Timestep Collection Time: 5.15733
Timestep Consumption Time: 2.01169
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.16902

Cumulative Model Updates: 32556
Cumulative Timesteps: 271838612

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.17267
Policy Entropy: 1.30292
Value Function Loss: 0.01966

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.12642
Value Function Update Magnitude: 0.22394

Collected Steps per Second: 10329.33722
Overall Steps per Second: 7197.72682

Timestep Collection Time: 4.84232
Timestep Consumption Time: 2.10681
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 6.94914

Cumulative Model Updates: 32562
Cumulative Timesteps: 271888630

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.01440
Policy Entropy: 1.29981
Value Function Loss: 0.02061

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.12467
Value Function Update Magnitude: 0.21977

Collected Steps per Second: 9118.17021
Overall Steps per Second: 6529.10324

Timestep Collection Time: 5.48443
Timestep Consumption Time: 2.17481
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.65924

Cumulative Model Updates: 32568
Cumulative Timesteps: 271938638

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.97592
Policy Entropy: 1.30098
Value Function Loss: 0.02058

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.12268
Value Function Update Magnitude: 0.21831

Collected Steps per Second: 9431.57632
Overall Steps per Second: 6785.88763

Timestep Collection Time: 5.30357
Timestep Consumption Time: 2.06776
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.37133

Cumulative Model Updates: 32574
Cumulative Timesteps: 271988659

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.86053
Policy Entropy: 1.29586
Value Function Loss: 0.01996

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.12106
Value Function Update Magnitude: 0.20805

Collected Steps per Second: 9997.77424
Overall Steps per Second: 6984.62550

Timestep Collection Time: 5.00111
Timestep Consumption Time: 2.15747
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 7.15858

Cumulative Model Updates: 32580
Cumulative Timesteps: 272038659

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.57355
Policy Entropy: 1.29749
Value Function Loss: 0.01967

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.11962
Value Function Update Magnitude: 0.20640

Collected Steps per Second: 9220.27643
Overall Steps per Second: 6468.82709

Timestep Collection Time: 5.42587
Timestep Consumption Time: 2.30784
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.73370

Cumulative Model Updates: 32586
Cumulative Timesteps: 272088687

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.10353
Policy Entropy: 1.29458
Value Function Loss: 0.01997

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.12259
Value Function Update Magnitude: 0.21420

Collected Steps per Second: 9349.96166
Overall Steps per Second: 6817.66801

Timestep Collection Time: 5.35232
Timestep Consumption Time: 1.98802
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.34034

Cumulative Model Updates: 32592
Cumulative Timesteps: 272138731

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.20605
Policy Entropy: 1.29312
Value Function Loss: 0.02018

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.12502
Value Function Update Magnitude: 0.22406

Collected Steps per Second: 10018.30935
Overall Steps per Second: 7137.31148

Timestep Collection Time: 4.99206
Timestep Consumption Time: 2.01506
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 7.00712

Cumulative Model Updates: 32598
Cumulative Timesteps: 272188743

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.82465
Policy Entropy: 1.29051
Value Function Loss: 0.02005

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.12491
Value Function Update Magnitude: 0.22495

Collected Steps per Second: 9227.04078
Overall Steps per Second: 6533.10230

Timestep Collection Time: 5.42102
Timestep Consumption Time: 2.23537
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.65639

Cumulative Model Updates: 32604
Cumulative Timesteps: 272238763

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.61808
Policy Entropy: 1.29295
Value Function Loss: 0.01968

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.12490
Value Function Update Magnitude: 0.21843

Collected Steps per Second: 8977.29700
Overall Steps per Second: 6474.74686

Timestep Collection Time: 5.57339
Timestep Consumption Time: 2.15417
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.72756

Cumulative Model Updates: 32610
Cumulative Timesteps: 272288797

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 272288797...
Checkpoint 272288797 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.73603
Policy Entropy: 1.29288
Value Function Loss: 0.01962

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.12409
Value Function Update Magnitude: 0.21510

Collected Steps per Second: 9532.92429
Overall Steps per Second: 6744.76568

Timestep Collection Time: 5.24760
Timestep Consumption Time: 2.16926
PPO Batch Consumption Time: 0.02365
Total Iteration Time: 7.41686

Cumulative Model Updates: 32616
Cumulative Timesteps: 272338822

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.61457
Policy Entropy: 1.29504
Value Function Loss: 0.01973

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.06965
Policy Update Magnitude: 0.12247
Value Function Update Magnitude: 0.21089

Collected Steps per Second: 9371.82115
Overall Steps per Second: 6556.76664

Timestep Collection Time: 5.33941
Timestep Consumption Time: 2.29240
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.63181

Cumulative Model Updates: 32622
Cumulative Timesteps: 272388862

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.37896
Policy Entropy: 1.29564
Value Function Loss: 0.01969

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.06842
Policy Update Magnitude: 0.12160
Value Function Update Magnitude: 0.20925

Collected Steps per Second: 9202.91989
Overall Steps per Second: 6517.26011

Timestep Collection Time: 5.43795
Timestep Consumption Time: 2.24089
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.67884

Cumulative Model Updates: 32628
Cumulative Timesteps: 272438907

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.37576
Policy Entropy: 1.29818
Value Function Loss: 0.01955

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.12360
Value Function Update Magnitude: 0.21099

Collected Steps per Second: 9582.31139
Overall Steps per Second: 6723.92364

Timestep Collection Time: 5.21826
Timestep Consumption Time: 2.21832
PPO Batch Consumption Time: 0.02342
Total Iteration Time: 7.43658

Cumulative Model Updates: 32634
Cumulative Timesteps: 272488910

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.20812
Policy Entropy: 1.29651
Value Function Loss: 0.02059

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.07677
Policy Update Magnitude: 0.12367
Value Function Update Magnitude: 0.21728

Collected Steps per Second: 9817.88347
Overall Steps per Second: 6984.16586

Timestep Collection Time: 5.09499
Timestep Consumption Time: 2.06721
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.16220

Cumulative Model Updates: 32640
Cumulative Timesteps: 272538932

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.15235
Policy Entropy: 1.29753
Value Function Loss: 0.02047

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.12546
Value Function Update Magnitude: 0.21679

Collected Steps per Second: 9944.84884
Overall Steps per Second: 7105.62509

Timestep Collection Time: 5.02914
Timestep Consumption Time: 2.00951
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.03865

Cumulative Model Updates: 32646
Cumulative Timesteps: 272588946

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.05282
Policy Entropy: 1.29723
Value Function Loss: 0.02061

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06882
Policy Update Magnitude: 0.12133
Value Function Update Magnitude: 0.20913

Collected Steps per Second: 9801.57863
Overall Steps per Second: 6763.69415

Timestep Collection Time: 5.10336
Timestep Consumption Time: 2.29215
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.39551

Cumulative Model Updates: 32652
Cumulative Timesteps: 272638967

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.20311
Policy Entropy: 1.29610
Value Function Loss: 0.02051

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.06618
Policy Update Magnitude: 0.12343
Value Function Update Magnitude: 0.21251

Collected Steps per Second: 8882.79832
Overall Steps per Second: 6400.46072

Timestep Collection Time: 5.63190
Timestep Consumption Time: 2.18426
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.81616

Cumulative Model Updates: 32658
Cumulative Timesteps: 272688994

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.13883
Policy Entropy: 1.29432
Value Function Loss: 0.01986

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.12247
Value Function Update Magnitude: 0.21509

Collected Steps per Second: 8942.19349
Overall Steps per Second: 6360.17992

Timestep Collection Time: 5.59281
Timestep Consumption Time: 2.27049
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 7.86330

Cumulative Model Updates: 32664
Cumulative Timesteps: 272739006

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.49375
Policy Entropy: 1.29584
Value Function Loss: 0.02017

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.12442
Value Function Update Magnitude: 0.20469

Collected Steps per Second: 9282.03594
Overall Steps per Second: 6568.51450

Timestep Collection Time: 5.38944
Timestep Consumption Time: 2.22643
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 7.61588

Cumulative Model Updates: 32670
Cumulative Timesteps: 272789031

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 272789031...
Checkpoint 272789031 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.69905
Policy Entropy: 1.29419
Value Function Loss: 0.02017

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.12622
Value Function Update Magnitude: 0.20541

Collected Steps per Second: 9036.40886
Overall Steps per Second: 6441.87519

Timestep Collection Time: 5.53771
Timestep Consumption Time: 2.23037
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.76808

Cumulative Model Updates: 32676
Cumulative Timesteps: 272839072

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.46406
Policy Entropy: 1.29172
Value Function Loss: 0.01956

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.12533
Value Function Update Magnitude: 0.21416

Collected Steps per Second: 9887.50637
Overall Steps per Second: 7041.74785

Timestep Collection Time: 5.05770
Timestep Consumption Time: 2.04395
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 7.10165

Cumulative Model Updates: 32682
Cumulative Timesteps: 272889080

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.39974
Policy Entropy: 1.29170
Value Function Loss: 0.01951

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.12365
Value Function Update Magnitude: 0.21146

Collected Steps per Second: 10288.30826
Overall Steps per Second: 7102.96561

Timestep Collection Time: 4.86018
Timestep Consumption Time: 2.17956
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.03974

Cumulative Model Updates: 32688
Cumulative Timesteps: 272939083

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.15518
Policy Entropy: 1.29466
Value Function Loss: 0.01941

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.12408
Value Function Update Magnitude: 0.21321

Collected Steps per Second: 9230.55616
Overall Steps per Second: 6580.88117

Timestep Collection Time: 5.42134
Timestep Consumption Time: 2.18281
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 7.60415

Cumulative Model Updates: 32694
Cumulative Timesteps: 272989125

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.86717
Policy Entropy: 1.29475
Value Function Loss: 0.02069

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.12503
Value Function Update Magnitude: 0.21334

Collected Steps per Second: 9340.12953
Overall Steps per Second: 6711.35698

Timestep Collection Time: 5.35710
Timestep Consumption Time: 2.09832
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.45542

Cumulative Model Updates: 32700
Cumulative Timesteps: 273039161

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.66342
Policy Entropy: 1.29460
Value Function Loss: 0.02058

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.12180
Value Function Update Magnitude: 0.20734

Collected Steps per Second: 9942.32164
Overall Steps per Second: 6988.46632

Timestep Collection Time: 5.03122
Timestep Consumption Time: 2.12657
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.15779

Cumulative Model Updates: 32706
Cumulative Timesteps: 273089183

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.49147
Policy Entropy: 1.29500
Value Function Loss: 0.01954

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.12066
Value Function Update Magnitude: 0.20229

Collected Steps per Second: 9264.77338
Overall Steps per Second: 6752.34678

Timestep Collection Time: 5.39819
Timestep Consumption Time: 2.00857
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.40676

Cumulative Model Updates: 32712
Cumulative Timesteps: 273139196

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.16755
Policy Entropy: 1.29982
Value Function Loss: 0.01990

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.12290
Value Function Update Magnitude: 0.19468

Collected Steps per Second: 9627.35183
Overall Steps per Second: 6928.59369

Timestep Collection Time: 5.19748
Timestep Consumption Time: 2.02447
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.22196

Cumulative Model Updates: 32718
Cumulative Timesteps: 273189234

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.71585
Policy Entropy: 1.30077
Value Function Loss: 0.01938

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.12023
Value Function Update Magnitude: 0.19086

Collected Steps per Second: 9950.23570
Overall Steps per Second: 7143.17550

Timestep Collection Time: 5.02772
Timestep Consumption Time: 1.97575
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.00347

Cumulative Model Updates: 32724
Cumulative Timesteps: 273239261

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.44234
Policy Entropy: 1.30315
Value Function Loss: 0.02104

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.06507
Policy Update Magnitude: 0.11851
Value Function Update Magnitude: 0.19957

Collected Steps per Second: 10029.17251
Overall Steps per Second: 7140.87130

Timestep Collection Time: 4.98815
Timestep Consumption Time: 2.01758
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 7.00573

Cumulative Model Updates: 32730
Cumulative Timesteps: 273289288

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 273289288...
Checkpoint 273289288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.45968
Policy Entropy: 1.30495
Value Function Loss: 0.02048

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.11827
Value Function Update Magnitude: 0.20571

Collected Steps per Second: 9551.65970
Overall Steps per Second: 6847.51191

Timestep Collection Time: 5.23637
Timestep Consumption Time: 2.06789
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.30426

Cumulative Model Updates: 32736
Cumulative Timesteps: 273339304

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.17351
Policy Entropy: 1.30905
Value Function Loss: 0.02078

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06203
Policy Update Magnitude: 0.11710
Value Function Update Magnitude: 0.22883

Collected Steps per Second: 9658.30662
Overall Steps per Second: 6622.69141

Timestep Collection Time: 5.17762
Timestep Consumption Time: 2.37324
PPO Batch Consumption Time: 0.02847
Total Iteration Time: 7.55086

Cumulative Model Updates: 32742
Cumulative Timesteps: 273389311

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.15694
Policy Entropy: 1.30743
Value Function Loss: 0.01990

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.11934
Value Function Update Magnitude: 0.23766

Collected Steps per Second: 9842.35878
Overall Steps per Second: 7115.51489

Timestep Collection Time: 5.08069
Timestep Consumption Time: 1.94705
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 7.02774

Cumulative Model Updates: 32748
Cumulative Timesteps: 273439317

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.57067
Policy Entropy: 1.30644
Value Function Loss: 0.02038

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07108
Policy Update Magnitude: 0.12375
Value Function Update Magnitude: 0.23973

Collected Steps per Second: 9628.60377
Overall Steps per Second: 6862.94221

Timestep Collection Time: 5.19338
Timestep Consumption Time: 2.09285
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.28623

Cumulative Model Updates: 32754
Cumulative Timesteps: 273489322

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.50656
Policy Entropy: 1.30403
Value Function Loss: 0.02083

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.23531

Collected Steps per Second: 9633.93199
Overall Steps per Second: 6960.36294

Timestep Collection Time: 5.19373
Timestep Consumption Time: 1.99498
PPO Batch Consumption Time: 0.02420
Total Iteration Time: 7.18871

Cumulative Model Updates: 32760
Cumulative Timesteps: 273539358

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.57718
Policy Entropy: 1.30051
Value Function Loss: 0.02078

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.12506
Value Function Update Magnitude: 0.23707

Collected Steps per Second: 9840.52067
Overall Steps per Second: 7110.79314

Timestep Collection Time: 5.08469
Timestep Consumption Time: 1.95194
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 7.03663

Cumulative Model Updates: 32766
Cumulative Timesteps: 273589394

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.71910
Policy Entropy: 1.29696
Value Function Loss: 0.02050

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.12236
Value Function Update Magnitude: 0.24189

Collected Steps per Second: 9655.42663
Overall Steps per Second: 6872.47853

Timestep Collection Time: 5.17968
Timestep Consumption Time: 2.09746
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 7.27714

Cumulative Model Updates: 32772
Cumulative Timesteps: 273639406

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.06672
Policy Entropy: 1.29548
Value Function Loss: 0.01988

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.12116
Value Function Update Magnitude: 0.22997

Collected Steps per Second: 9620.83814
Overall Steps per Second: 6674.66680

Timestep Collection Time: 5.19955
Timestep Consumption Time: 2.29506
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 7.49461

Cumulative Model Updates: 32778
Cumulative Timesteps: 273689430

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.08580
Policy Entropy: 1.29084
Value Function Loss: 0.01986

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.12121
Value Function Update Magnitude: 0.21659

Collected Steps per Second: 9218.84753
Overall Steps per Second: 6470.50744

Timestep Collection Time: 5.42411
Timestep Consumption Time: 2.30388
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.72799

Cumulative Model Updates: 32784
Cumulative Timesteps: 273739434

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.35805
Policy Entropy: 1.29293
Value Function Loss: 0.01939

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.11925
Value Function Update Magnitude: 0.20859

Collected Steps per Second: 9670.68774
Overall Steps per Second: 6994.18448

Timestep Collection Time: 5.17171
Timestep Consumption Time: 1.97909
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.15080

Cumulative Model Updates: 32790
Cumulative Timesteps: 273789448

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 273789448...
Checkpoint 273789448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.16969
Policy Entropy: 1.29300
Value Function Loss: 0.01895

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.11792
Value Function Update Magnitude: 0.19786

Collected Steps per Second: 10029.64725
Overall Steps per Second: 6935.32670

Timestep Collection Time: 4.98662
Timestep Consumption Time: 2.22487
PPO Batch Consumption Time: 0.02902
Total Iteration Time: 7.21148

Cumulative Model Updates: 32796
Cumulative Timesteps: 273839462

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.17219
Policy Entropy: 1.29668
Value Function Loss: 0.01970

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07604
Policy Update Magnitude: 0.12150
Value Function Update Magnitude: 0.19621

Collected Steps per Second: 9035.31949
Overall Steps per Second: 6405.14064

Timestep Collection Time: 5.53694
Timestep Consumption Time: 2.27366
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 7.81060

Cumulative Model Updates: 32802
Cumulative Timesteps: 273889490

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.93854
Policy Entropy: 1.29140
Value Function Loss: 0.01985

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.12363
Value Function Update Magnitude: 0.19674

Collected Steps per Second: 9266.62319
Overall Steps per Second: 6806.69434

Timestep Collection Time: 5.39700
Timestep Consumption Time: 1.95047
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 7.34747

Cumulative Model Updates: 32808
Cumulative Timesteps: 273939502

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.13701
Policy Entropy: 1.29127
Value Function Loss: 0.02055

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07410
Policy Update Magnitude: 0.12321
Value Function Update Magnitude: 0.19990

Collected Steps per Second: 10418.57711
Overall Steps per Second: 7335.21435

Timestep Collection Time: 4.80046
Timestep Consumption Time: 2.01788
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 6.81834

Cumulative Model Updates: 32814
Cumulative Timesteps: 273989516

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.60122
Policy Entropy: 1.29164
Value Function Loss: 0.01961

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.06996
Policy Update Magnitude: 0.12388
Value Function Update Magnitude: 0.20118

Collected Steps per Second: 9111.99207
Overall Steps per Second: 6473.83479

Timestep Collection Time: 5.48749
Timestep Consumption Time: 2.23621
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.72371

Cumulative Model Updates: 32820
Cumulative Timesteps: 274039518

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.71250
Policy Entropy: 1.29406
Value Function Loss: 0.01985

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.12524
Value Function Update Magnitude: 0.19420

Collected Steps per Second: 9092.41451
Overall Steps per Second: 6485.89227

Timestep Collection Time: 5.50085
Timestep Consumption Time: 2.21066
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.71151

Cumulative Model Updates: 32826
Cumulative Timesteps: 274089534

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.14108
Policy Entropy: 1.29824
Value Function Loss: 0.01964

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.12242
Value Function Update Magnitude: 0.19459

Collected Steps per Second: 10431.93751
Overall Steps per Second: 7159.30676

Timestep Collection Time: 4.79537
Timestep Consumption Time: 2.19204
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 6.98741

Cumulative Model Updates: 32832
Cumulative Timesteps: 274139559

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.18358
Policy Entropy: 1.28943
Value Function Loss: 0.02044

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.20021

Collected Steps per Second: 9970.97511
Overall Steps per Second: 6996.97373

Timestep Collection Time: 5.01726
Timestep Consumption Time: 2.13254
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.14981

Cumulative Model Updates: 32838
Cumulative Timesteps: 274189586

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.48753
Policy Entropy: 1.29027
Value Function Loss: 0.02025

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.12353
Value Function Update Magnitude: 0.20457

Collected Steps per Second: 9260.65718
Overall Steps per Second: 6748.84031

Timestep Collection Time: 5.40232
Timestep Consumption Time: 2.01066
PPO Batch Consumption Time: 0.02449
Total Iteration Time: 7.41298

Cumulative Model Updates: 32844
Cumulative Timesteps: 274239615

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.50677
Policy Entropy: 1.28719
Value Function Loss: 0.01974

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.12502
Value Function Update Magnitude: 0.19495

Collected Steps per Second: 10203.83091
Overall Steps per Second: 7110.66556

Timestep Collection Time: 4.90424
Timestep Consumption Time: 2.13336
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.03760

Cumulative Model Updates: 32850
Cumulative Timesteps: 274289657

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 274289657...
Checkpoint 274289657 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.10243
Policy Entropy: 1.29238
Value Function Loss: 0.01938

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.12229
Value Function Update Magnitude: 0.18931

Collected Steps per Second: 9586.49480
Overall Steps per Second: 7057.62745

Timestep Collection Time: 5.21849
Timestep Consumption Time: 1.86987
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.08836

Cumulative Model Updates: 32856
Cumulative Timesteps: 274339684

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.07769
Policy Entropy: 1.29160
Value Function Loss: 0.01946

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.11893
Value Function Update Magnitude: 0.18881

Collected Steps per Second: 9651.32591
Overall Steps per Second: 6918.79925

Timestep Collection Time: 5.18551
Timestep Consumption Time: 2.04798
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.23348

Cumulative Model Updates: 32862
Cumulative Timesteps: 274389731

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.32680
Policy Entropy: 1.29567
Value Function Loss: 0.01930

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06268
Policy Update Magnitude: 0.11963
Value Function Update Magnitude: 0.19604

Collected Steps per Second: 10282.82240
Overall Steps per Second: 6970.84811

Timestep Collection Time: 4.86549
Timestep Consumption Time: 2.31168
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.17718

Cumulative Model Updates: 32868
Cumulative Timesteps: 274439762

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.83209
Policy Entropy: 1.28903
Value Function Loss: 0.01916

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06763
Policy Update Magnitude: 0.11868
Value Function Update Magnitude: 0.20324

Collected Steps per Second: 9284.60861
Overall Steps per Second: 6620.11353

Timestep Collection Time: 5.38946
Timestep Consumption Time: 2.16917
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 7.55863

Cumulative Model Updates: 32874
Cumulative Timesteps: 274489801

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.81737
Policy Entropy: 1.28440
Value Function Loss: 0.01949

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.11961
Value Function Update Magnitude: 0.20050

Collected Steps per Second: 9892.62429
Overall Steps per Second: 6988.10611

Timestep Collection Time: 5.05670
Timestep Consumption Time: 2.10175
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.15845

Cumulative Model Updates: 32880
Cumulative Timesteps: 274539825

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.02844
Policy Entropy: 1.28654
Value Function Loss: 0.01997

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.12040
Value Function Update Magnitude: 0.19416

Collected Steps per Second: 10462.58278
Overall Steps per Second: 7289.53645

Timestep Collection Time: 4.78238
Timestep Consumption Time: 2.08171
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 6.86409

Cumulative Model Updates: 32886
Cumulative Timesteps: 274589861

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.38098
Policy Entropy: 1.29339
Value Function Loss: 0.01942

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.11768
Value Function Update Magnitude: 0.19256

Collected Steps per Second: 9506.26622
Overall Steps per Second: 6699.01297

Timestep Collection Time: 5.26232
Timestep Consumption Time: 2.20520
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.46752

Cumulative Model Updates: 32892
Cumulative Timesteps: 274639886

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.66654
Policy Entropy: 1.29289
Value Function Loss: 0.02000

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.11333
Value Function Update Magnitude: 0.18403

Collected Steps per Second: 9069.74526
Overall Steps per Second: 6585.21403

Timestep Collection Time: 5.51658
Timestep Consumption Time: 2.08135
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 7.59793

Cumulative Model Updates: 32898
Cumulative Timesteps: 274689920

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.27718
Policy Entropy: 1.29235
Value Function Loss: 0.02077

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.11681
Value Function Update Magnitude: 0.18955

Collected Steps per Second: 9721.13795
Overall Steps per Second: 6562.96678

Timestep Collection Time: 5.14456
Timestep Consumption Time: 2.47562
PPO Batch Consumption Time: 0.02993
Total Iteration Time: 7.62018

Cumulative Model Updates: 32904
Cumulative Timesteps: 274739931

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.81720
Policy Entropy: 1.29269
Value Function Loss: 0.02206

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.12087
Value Function Update Magnitude: 0.18837

Collected Steps per Second: 8829.40611
Overall Steps per Second: 6350.86168

Timestep Collection Time: 5.66777
Timestep Consumption Time: 2.21195
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.87972

Cumulative Model Updates: 32910
Cumulative Timesteps: 274789974

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 274789974...
Checkpoint 274789974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.64329
Policy Entropy: 1.29139
Value Function Loss: 0.02113

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.06327
Policy Update Magnitude: 0.12555
Value Function Update Magnitude: 0.19181

Collected Steps per Second: 9846.57801
Overall Steps per Second: 6969.92159

Timestep Collection Time: 5.08197
Timestep Consumption Time: 2.09745
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.17942

Cumulative Model Updates: 32916
Cumulative Timesteps: 274840014

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.52260
Policy Entropy: 1.28934
Value Function Loss: 0.02008

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.12263
Value Function Update Magnitude: 0.19782

Collected Steps per Second: 10314.74381
Overall Steps per Second: 7095.38828

Timestep Collection Time: 4.84840
Timestep Consumption Time: 2.19984
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 7.04824

Cumulative Model Updates: 32922
Cumulative Timesteps: 274890024

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.75187
Policy Entropy: 1.28606
Value Function Loss: 0.01991

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.12051
Value Function Update Magnitude: 0.20477

Collected Steps per Second: 8991.19679
Overall Steps per Second: 6344.95577

Timestep Collection Time: 5.56277
Timestep Consumption Time: 2.32002
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 7.88280

Cumulative Model Updates: 32928
Cumulative Timesteps: 274940040

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.34448
Policy Entropy: 1.28401
Value Function Loss: 0.01946

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07595
Policy Update Magnitude: 0.12138
Value Function Update Magnitude: 0.20596

Collected Steps per Second: 10178.56261
Overall Steps per Second: 7276.76341

Timestep Collection Time: 4.91238
Timestep Consumption Time: 1.95894
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 6.87132

Cumulative Model Updates: 32934
Cumulative Timesteps: 274990041

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.26110
Policy Entropy: 1.28052
Value Function Loss: 0.02030

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.12179
Value Function Update Magnitude: 0.19553

Collected Steps per Second: 10545.76604
Overall Steps per Second: 7371.36528

Timestep Collection Time: 4.74484
Timestep Consumption Time: 2.04332
PPO Batch Consumption Time: 0.02487
Total Iteration Time: 6.78816

Cumulative Model Updates: 32940
Cumulative Timesteps: 275040079

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.72657
Policy Entropy: 1.28051
Value Function Loss: 0.02064

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.12194
Value Function Update Magnitude: 0.18660

Collected Steps per Second: 9417.25760
Overall Steps per Second: 6761.46687

Timestep Collection Time: 5.31195
Timestep Consumption Time: 2.08644
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.39839

Cumulative Model Updates: 32946
Cumulative Timesteps: 275090103

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.75181
Policy Entropy: 1.28590
Value Function Loss: 0.02213

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.12580
Value Function Update Magnitude: 0.19469

Collected Steps per Second: 9846.68333
Overall Steps per Second: 7092.45187

Timestep Collection Time: 5.07917
Timestep Consumption Time: 1.97241
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.05158

Cumulative Model Updates: 32952
Cumulative Timesteps: 275140116

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.17795
Policy Entropy: 1.28772
Value Function Loss: 0.02156

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.12545
Value Function Update Magnitude: 0.20106

Collected Steps per Second: 9986.40224
Overall Steps per Second: 6756.82763

Timestep Collection Time: 5.01071
Timestep Consumption Time: 2.39498
PPO Batch Consumption Time: 0.03142
Total Iteration Time: 7.40569

Cumulative Model Updates: 32958
Cumulative Timesteps: 275190155

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.77618
Policy Entropy: 1.28713
Value Function Loss: 0.02055

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.12461
Value Function Update Magnitude: 0.20030

Collected Steps per Second: 8960.50336
Overall Steps per Second: 6316.80140

Timestep Collection Time: 5.58495
Timestep Consumption Time: 2.33741
PPO Batch Consumption Time: 0.02897
Total Iteration Time: 7.92236

Cumulative Model Updates: 32964
Cumulative Timesteps: 275240199

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.19057
Policy Entropy: 1.28648
Value Function Loss: 0.01988

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.12185
Value Function Update Magnitude: 0.18561

Collected Steps per Second: 9719.04361
Overall Steps per Second: 6788.30988

Timestep Collection Time: 5.14742
Timestep Consumption Time: 2.22231
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.36973

Cumulative Model Updates: 32970
Cumulative Timesteps: 275290227

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 275290227...
Checkpoint 275290227 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.50757
Policy Entropy: 1.28782
Value Function Loss: 0.01954

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.12014
Value Function Update Magnitude: 0.18721

Collected Steps per Second: 10225.11048
Overall Steps per Second: 6915.18603

Timestep Collection Time: 4.89286
Timestep Consumption Time: 2.34195
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.23480

Cumulative Model Updates: 32976
Cumulative Timesteps: 275340257

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.01834
Policy Entropy: 1.29108
Value Function Loss: 0.02070

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06013
Policy Update Magnitude: 0.12466
Value Function Update Magnitude: 0.18673

Collected Steps per Second: 9414.47542
Overall Steps per Second: 6733.60849

Timestep Collection Time: 5.31193
Timestep Consumption Time: 2.11485
PPO Batch Consumption Time: 0.02460
Total Iteration Time: 7.42678

Cumulative Model Updates: 32982
Cumulative Timesteps: 275390266

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.17554
Policy Entropy: 1.29007
Value Function Loss: 0.02113

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.12582
Value Function Update Magnitude: 0.18597

Collected Steps per Second: 9898.62291
Overall Steps per Second: 7017.70129

Timestep Collection Time: 5.05363
Timestep Consumption Time: 2.07463
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.12826

Cumulative Model Updates: 32988
Cumulative Timesteps: 275440290

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.70170
Policy Entropy: 1.28953
Value Function Loss: 0.02130

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.12397
Value Function Update Magnitude: 0.18866

Collected Steps per Second: 9471.92760
Overall Steps per Second: 6508.56392

Timestep Collection Time: 5.27939
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.68311

Cumulative Model Updates: 32994
Cumulative Timesteps: 275490296

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.59597
Policy Entropy: 1.28972
Value Function Loss: 0.02095

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.12369
Value Function Update Magnitude: 0.18483

Collected Steps per Second: 8850.74087
Overall Steps per Second: 6413.53458

Timestep Collection Time: 5.65263
Timestep Consumption Time: 2.14806
PPO Batch Consumption Time: 0.02843
Total Iteration Time: 7.80069

Cumulative Model Updates: 33000
Cumulative Timesteps: 275540326

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.47245
Policy Entropy: 1.28954
Value Function Loss: 0.01996

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.15668
Value Function Update Magnitude: 0.18687

Collected Steps per Second: 10088.95981
Overall Steps per Second: 7094.37254

Timestep Collection Time: 4.95819
Timestep Consumption Time: 2.09289
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.05108

Cumulative Model Updates: 33006
Cumulative Timesteps: 275590349

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.66270
Policy Entropy: 1.28849
Value Function Loss: 0.02008

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.13503
Value Function Update Magnitude: 0.19541

Collected Steps per Second: 9638.80606
Overall Steps per Second: 6453.44587

Timestep Collection Time: 5.18768
Timestep Consumption Time: 2.56059
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 7.74826

Cumulative Model Updates: 33012
Cumulative Timesteps: 275640352

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.11928
Policy Entropy: 1.28519
Value Function Loss: 0.01984

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.12564
Value Function Update Magnitude: 0.20068

Collected Steps per Second: 8928.52449
Overall Steps per Second: 6388.89040

Timestep Collection Time: 5.60227
Timestep Consumption Time: 2.22695
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 7.82922

Cumulative Model Updates: 33018
Cumulative Timesteps: 275690372

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.36803
Policy Entropy: 1.28317
Value Function Loss: 0.02116

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.12205
Value Function Update Magnitude: 0.20414

Collected Steps per Second: 9644.25761
Overall Steps per Second: 6972.77665

Timestep Collection Time: 5.18516
Timestep Consumption Time: 1.98659
PPO Batch Consumption Time: 0.03016
Total Iteration Time: 7.17175

Cumulative Model Updates: 33024
Cumulative Timesteps: 275740379

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.92872
Policy Entropy: 1.28337
Value Function Loss: 0.02178

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.12656
Value Function Update Magnitude: 0.21737

Collected Steps per Second: 10075.13276
Overall Steps per Second: 6895.38578

Timestep Collection Time: 4.96668
Timestep Consumption Time: 2.29034
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.25703

Cumulative Model Updates: 33030
Cumulative Timesteps: 275790419

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 275790419...
Checkpoint 275790419 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.84267
Policy Entropy: 1.28786
Value Function Loss: 0.02245

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.12754
Value Function Update Magnitude: 0.22543

Collected Steps per Second: 9374.96576
Overall Steps per Second: 6833.07670

Timestep Collection Time: 5.33709
Timestep Consumption Time: 1.98538
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.32247

Cumulative Model Updates: 33036
Cumulative Timesteps: 275840454

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.29298
Policy Entropy: 1.29088
Value Function Loss: 0.02207

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.12500
Value Function Update Magnitude: 0.22686

Collected Steps per Second: 9680.27139
Overall Steps per Second: 6894.28520

Timestep Collection Time: 5.16700
Timestep Consumption Time: 2.08799
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.25499

Cumulative Model Updates: 33042
Cumulative Timesteps: 275890472

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.74683
Policy Entropy: 1.29366
Value Function Loss: 0.02190

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.07712
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.21903

Collected Steps per Second: 9752.96742
Overall Steps per Second: 6952.88926

Timestep Collection Time: 5.13085
Timestep Consumption Time: 2.06630
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.19715

Cumulative Model Updates: 33048
Cumulative Timesteps: 275940513

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.21151
Policy Entropy: 1.29664
Value Function Loss: 0.02089

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.12143
Value Function Update Magnitude: 0.21228

Collected Steps per Second: 9488.26591
Overall Steps per Second: 6695.08315

Timestep Collection Time: 5.27062
Timestep Consumption Time: 2.19890
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.46951

Cumulative Model Updates: 33054
Cumulative Timesteps: 275990522

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.35213
Policy Entropy: 1.29836
Value Function Loss: 0.02024

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.12002
Value Function Update Magnitude: 0.20518

Collected Steps per Second: 9728.37466
Overall Steps per Second: 7042.16888

Timestep Collection Time: 5.14300
Timestep Consumption Time: 1.96177
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 7.10477

Cumulative Model Updates: 33060
Cumulative Timesteps: 276040555

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.64427
Policy Entropy: 1.29632
Value Function Loss: 0.02079

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.12051
Value Function Update Magnitude: 0.21033

Collected Steps per Second: 10515.05252
Overall Steps per Second: 7422.26633

Timestep Collection Time: 4.75813
Timestep Consumption Time: 1.98267
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.74080

Cumulative Model Updates: 33066
Cumulative Timesteps: 276090587

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.03905
Policy Entropy: 1.29431
Value Function Loss: 0.02052

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.12114
Value Function Update Magnitude: 0.22445

Collected Steps per Second: 9993.57432
Overall Steps per Second: 7138.31063

Timestep Collection Time: 5.00412
Timestep Consumption Time: 2.00160
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.00572

Cumulative Model Updates: 33072
Cumulative Timesteps: 276140596

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.02234
Policy Entropy: 1.29313
Value Function Loss: 0.02004

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.12106
Value Function Update Magnitude: 0.21105

Collected Steps per Second: 9676.41485
Overall Steps per Second: 6840.71320

Timestep Collection Time: 5.16875
Timestep Consumption Time: 2.14262
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.31137

Cumulative Model Updates: 33078
Cumulative Timesteps: 276190611

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.14167
Policy Entropy: 1.29242
Value Function Loss: 0.01951

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.11744
Value Function Update Magnitude: 0.20175

Collected Steps per Second: 9975.58889
Overall Steps per Second: 6821.14800

Timestep Collection Time: 5.01364
Timestep Consumption Time: 2.31856
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.33220

Cumulative Model Updates: 33084
Cumulative Timesteps: 276240625

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.76941
Policy Entropy: 1.28878
Value Function Loss: 0.01866

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.11982
Value Function Update Magnitude: 0.20628

Collected Steps per Second: 9896.31522
Overall Steps per Second: 7072.19974

Timestep Collection Time: 5.05340
Timestep Consumption Time: 2.01795
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 7.07135

Cumulative Model Updates: 33090
Cumulative Timesteps: 276290635

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 276290635...
Checkpoint 276290635 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.43893
Policy Entropy: 1.28647
Value Function Loss: 0.01988

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.11926
Value Function Update Magnitude: 0.21072

Collected Steps per Second: 9661.76154
Overall Steps per Second: 6870.20411

Timestep Collection Time: 5.17576
Timestep Consumption Time: 2.10306
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.27882

Cumulative Model Updates: 33096
Cumulative Timesteps: 276340642

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.07377
Policy Entropy: 1.28834
Value Function Loss: 0.01965

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.11841
Value Function Update Magnitude: 0.20886

Collected Steps per Second: 9432.45485
Overall Steps per Second: 6564.32504

Timestep Collection Time: 5.30286
Timestep Consumption Time: 2.31696
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.61982

Cumulative Model Updates: 33102
Cumulative Timesteps: 276390661

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.67353
Policy Entropy: 1.28513
Value Function Loss: 0.02055

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.11993
Value Function Update Magnitude: 0.21093

Collected Steps per Second: 9276.18239
Overall Steps per Second: 6865.54977

Timestep Collection Time: 5.39468
Timestep Consumption Time: 1.89418
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.28886

Cumulative Model Updates: 33108
Cumulative Timesteps: 276440703

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.70212
Policy Entropy: 1.28190
Value Function Loss: 0.02025

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.12366
Value Function Update Magnitude: 0.20407

Collected Steps per Second: 9435.23832
Overall Steps per Second: 6764.34878

Timestep Collection Time: 5.30320
Timestep Consumption Time: 2.09396
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 7.39716

Cumulative Model Updates: 33114
Cumulative Timesteps: 276490740

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.81279
Policy Entropy: 1.27811
Value Function Loss: 0.01969

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.12322
Value Function Update Magnitude: 0.20509

Collected Steps per Second: 9753.97033
Overall Steps per Second: 6787.13937

Timestep Collection Time: 5.12684
Timestep Consumption Time: 2.24107
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.36791

Cumulative Model Updates: 33120
Cumulative Timesteps: 276540747

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.71946
Policy Entropy: 1.28193
Value Function Loss: 0.01930

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.12198
Value Function Update Magnitude: 0.20116

Collected Steps per Second: 9633.28569
Overall Steps per Second: 7004.56104

Timestep Collection Time: 5.19252
Timestep Consumption Time: 1.94869
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 7.14120

Cumulative Model Updates: 33126
Cumulative Timesteps: 276590768

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.09537
Policy Entropy: 1.28725
Value Function Loss: 0.01897

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.12281
Value Function Update Magnitude: 0.19972

Collected Steps per Second: 9088.05376
Overall Steps per Second: 6550.03891

Timestep Collection Time: 5.50514
Timestep Consumption Time: 2.13314
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.63828

Cumulative Model Updates: 33132
Cumulative Timesteps: 276640799

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.03242
Policy Entropy: 1.28980
Value Function Loss: 0.01931

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.06945
Policy Update Magnitude: 0.12193
Value Function Update Magnitude: 0.20015

Collected Steps per Second: 9446.30469
Overall Steps per Second: 6552.04971

Timestep Collection Time: 5.29308
Timestep Consumption Time: 2.33812
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.63120

Cumulative Model Updates: 33138
Cumulative Timesteps: 276690799

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.56176
Policy Entropy: 1.29043
Value Function Loss: 0.01971

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.12261
Value Function Update Magnitude: 0.20520

Collected Steps per Second: 9331.37001
Overall Steps per Second: 6686.01329

Timestep Collection Time: 5.35902
Timestep Consumption Time: 2.12032
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.47934

Cumulative Model Updates: 33144
Cumulative Timesteps: 276740806

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.46374
Policy Entropy: 1.29007
Value Function Loss: 0.02005

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.06976
Policy Update Magnitude: 0.12568
Value Function Update Magnitude: 0.22258

Collected Steps per Second: 9270.41125
Overall Steps per Second: 6723.80328

Timestep Collection Time: 5.39771
Timestep Consumption Time: 2.04436
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.44207

Cumulative Model Updates: 33150
Cumulative Timesteps: 276790845

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 276790845...
Checkpoint 276790845 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.98192
Policy Entropy: 1.28569
Value Function Loss: 0.02093

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.07480
Policy Update Magnitude: 0.12382
Value Function Update Magnitude: 0.21574

Collected Steps per Second: 9680.46826
Overall Steps per Second: 6815.47335

Timestep Collection Time: 5.16814
Timestep Consumption Time: 2.17251
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 7.34065

Cumulative Model Updates: 33156
Cumulative Timesteps: 276840875

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.72629
Policy Entropy: 1.28729
Value Function Loss: 0.02018

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.07410
Policy Update Magnitude: 0.12326
Value Function Update Magnitude: 0.21476

Collected Steps per Second: 9741.09905
Overall Steps per Second: 7001.38486

Timestep Collection Time: 5.13751
Timestep Consumption Time: 2.01036
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.14787

Cumulative Model Updates: 33162
Cumulative Timesteps: 276890920

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.90038
Policy Entropy: 1.28373
Value Function Loss: 0.01997

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.06703
Policy Update Magnitude: 0.12117
Value Function Update Magnitude: 0.21378

Collected Steps per Second: 9195.37396
Overall Steps per Second: 6665.59211

Timestep Collection Time: 5.43784
Timestep Consumption Time: 2.06382
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 7.50166

Cumulative Model Updates: 33168
Cumulative Timesteps: 276940923

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.32457
Policy Entropy: 1.28607
Value Function Loss: 0.01887

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06450
Policy Update Magnitude: 0.11931
Value Function Update Magnitude: 0.20557

Collected Steps per Second: 9972.25908
Overall Steps per Second: 7098.00591

Timestep Collection Time: 5.01742
Timestep Consumption Time: 2.03174
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.04916

Cumulative Model Updates: 33174
Cumulative Timesteps: 276990958

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.12606
Policy Entropy: 1.27756
Value Function Loss: 0.01971

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.12050
Value Function Update Magnitude: 0.20121

Collected Steps per Second: 9938.31648
Overall Steps per Second: 6903.41779

Timestep Collection Time: 5.03335
Timestep Consumption Time: 2.21277
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.24612

Cumulative Model Updates: 33180
Cumulative Timesteps: 277040981

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.66485
Policy Entropy: 1.27774
Value Function Loss: 0.01948

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.11919
Value Function Update Magnitude: 0.19973

Collected Steps per Second: 10123.26948
Overall Steps per Second: 7268.46308

Timestep Collection Time: 4.94198
Timestep Consumption Time: 1.94104
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.88302

Cumulative Model Updates: 33186
Cumulative Timesteps: 277091010

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.19048
Policy Entropy: 1.28130
Value Function Loss: 0.01941

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.12060
Value Function Update Magnitude: 0.20279

Collected Steps per Second: 10466.78629
Overall Steps per Second: 7449.29815

Timestep Collection Time: 4.77864
Timestep Consumption Time: 1.93568
PPO Batch Consumption Time: 0.02515
Total Iteration Time: 6.71432

Cumulative Model Updates: 33192
Cumulative Timesteps: 277141027

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.54211
Policy Entropy: 1.29015
Value Function Loss: 0.01966

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.11989
Value Function Update Magnitude: 0.19200

Collected Steps per Second: 9891.72924
Overall Steps per Second: 7050.12984

Timestep Collection Time: 5.05796
Timestep Consumption Time: 2.03864
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.09661

Cumulative Model Updates: 33198
Cumulative Timesteps: 277191059

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.59622
Policy Entropy: 1.29418
Value Function Loss: 0.02011

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07400
Policy Update Magnitude: 0.12126
Value Function Update Magnitude: 0.19182

Collected Steps per Second: 9285.35806
Overall Steps per Second: 6676.69224

Timestep Collection Time: 5.38902
Timestep Consumption Time: 2.10556
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 7.49458

Cumulative Model Updates: 33204
Cumulative Timesteps: 277241098

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.18389
Policy Entropy: 1.29256
Value Function Loss: 0.02118

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.12054
Value Function Update Magnitude: 0.19366

Collected Steps per Second: 9799.85290
Overall Steps per Second: 6965.24261

Timestep Collection Time: 5.10222
Timestep Consumption Time: 2.07642
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.17864

Cumulative Model Updates: 33210
Cumulative Timesteps: 277291099

Timesteps Collected: 50001
--------END ITERATION REPORT--------


Saving checkpoint 277291099...
Checkpoint 277291099 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.56739
Policy Entropy: 1.28998
Value Function Loss: 0.02048

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.12340
Value Function Update Magnitude: 0.20878

Collected Steps per Second: 9822.19046
Overall Steps per Second: 7011.59425

Timestep Collection Time: 5.09082
Timestep Consumption Time: 2.04065
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.13147

Cumulative Model Updates: 33216
Cumulative Timesteps: 277341102

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.25246
Policy Entropy: 1.28864
Value Function Loss: 0.02101

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.12394
Value Function Update Magnitude: 0.21413

Collected Steps per Second: 9191.74106
Overall Steps per Second: 6525.66285

Timestep Collection Time: 5.44108
Timestep Consumption Time: 2.22297
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.66405

Cumulative Model Updates: 33222
Cumulative Timesteps: 277391115

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.49587
Policy Entropy: 1.29319
Value Function Loss: 0.02112

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.12412
Value Function Update Magnitude: 0.21915

Collected Steps per Second: 9603.92081
Overall Steps per Second: 6709.63679

Timestep Collection Time: 5.20714
Timestep Consumption Time: 2.24617
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.45331

Cumulative Model Updates: 33228
Cumulative Timesteps: 277441124

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.45893
Policy Entropy: 1.29634
Value Function Loss: 0.02109

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06572
Policy Update Magnitude: 0.12186
Value Function Update Magnitude: 0.22495

Collected Steps per Second: 9936.65182
Overall Steps per Second: 6938.50129

Timestep Collection Time: 5.03198
Timestep Consumption Time: 2.17433
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 7.20631

Cumulative Model Updates: 33234
Cumulative Timesteps: 277491125

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.34428
Policy Entropy: 1.29881
Value Function Loss: 0.01991

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.11992
Value Function Update Magnitude: 0.21803

Collected Steps per Second: 9322.51847
Overall Steps per Second: 6484.22016

Timestep Collection Time: 5.36507
Timestep Consumption Time: 2.34842
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.71350

Cumulative Model Updates: 33240
Cumulative Timesteps: 277541141

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.68344
Policy Entropy: 1.29670
Value Function Loss: 0.01890

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07059
Policy Update Magnitude: 0.11910
Value Function Update Magnitude: 0.21468

Collected Steps per Second: 9525.93563
Overall Steps per Second: 6780.57414

Timestep Collection Time: 5.25093
Timestep Consumption Time: 2.12603
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.37696

Cumulative Model Updates: 33246
Cumulative Timesteps: 277591161

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.29135
Policy Entropy: 1.29123
Value Function Loss: 0.01907

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07428
Policy Update Magnitude: 0.11939
Value Function Update Magnitude: 0.20886

Collected Steps per Second: 10021.80620
Overall Steps per Second: 7087.68057

Timestep Collection Time: 4.99241
Timestep Consumption Time: 2.06674
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.05915

Cumulative Model Updates: 33252
Cumulative Timesteps: 277641194

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.52553
Policy Entropy: 1.28883
Value Function Loss: 0.01996

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.11990
Value Function Update Magnitude: 0.20670

Collected Steps per Second: 9411.86308
Overall Steps per Second: 6613.87939

Timestep Collection Time: 5.31723
Timestep Consumption Time: 2.24944
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.56666

Cumulative Model Updates: 33258
Cumulative Timesteps: 277691239

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.44754
Policy Entropy: 1.29071
Value Function Loss: 0.01968

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.12044
Value Function Update Magnitude: 0.20364

Collected Steps per Second: 9213.14140
Overall Steps per Second: 6442.26716

Timestep Collection Time: 5.42953
Timestep Consumption Time: 2.33529
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.76481

Cumulative Model Updates: 33264
Cumulative Timesteps: 277741262

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.99151
Policy Entropy: 1.29069
Value Function Loss: 0.01982

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.11613
Value Function Update Magnitude: 0.19566

Collected Steps per Second: 9673.89153
Overall Steps per Second: 6907.40419

Timestep Collection Time: 5.16938
Timestep Consumption Time: 2.07039
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.23977

Cumulative Model Updates: 33270
Cumulative Timesteps: 277791270

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 277791270...
Checkpoint 277791270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.80958
Policy Entropy: 1.30030
Value Function Loss: 0.01956

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.07550
Policy Update Magnitude: 0.11822
Value Function Update Magnitude: 0.20009

Collected Steps per Second: 9485.09151
Overall Steps per Second: 6881.38955

Timestep Collection Time: 5.27628
Timestep Consumption Time: 1.99638
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.27266

Cumulative Model Updates: 33276
Cumulative Timesteps: 277841316

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.22781
Policy Entropy: 1.29471
Value Function Loss: 0.02095

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.12179
Value Function Update Magnitude: 0.20233

Collected Steps per Second: 9799.39653
Overall Steps per Second: 6912.34647

Timestep Collection Time: 5.10501
Timestep Consumption Time: 2.13219
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.23720

Cumulative Model Updates: 33282
Cumulative Timesteps: 277891342

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.69935
Policy Entropy: 1.29624
Value Function Loss: 0.02171

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.12448
Value Function Update Magnitude: 0.22349

Collected Steps per Second: 10069.12053
Overall Steps per Second: 6987.01149

Timestep Collection Time: 4.96895
Timestep Consumption Time: 2.19190
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.16086

Cumulative Model Updates: 33288
Cumulative Timesteps: 277941375

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.91549
Policy Entropy: 1.28856
Value Function Loss: 0.02179

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.12760
Value Function Update Magnitude: 0.22846

Collected Steps per Second: 9094.82954
Overall Steps per Second: 6353.82881

Timestep Collection Time: 5.49994
Timestep Consumption Time: 2.37264
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.87258

Cumulative Model Updates: 33294
Cumulative Timesteps: 277991396

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.79705
Policy Entropy: 1.29235
Value Function Loss: 0.02028

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.12379
Value Function Update Magnitude: 0.22566

Collected Steps per Second: 9390.09513
Overall Steps per Second: 6618.10824

Timestep Collection Time: 5.32732
Timestep Consumption Time: 2.23134
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.55866

Cumulative Model Updates: 33300
Cumulative Timesteps: 278041420

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.85167
Policy Entropy: 1.28948
Value Function Loss: 0.02041

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.11980
Value Function Update Magnitude: 0.21772

Collected Steps per Second: 9730.76786
Overall Steps per Second: 6860.29325

Timestep Collection Time: 5.14307
Timestep Consumption Time: 2.15196
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.29502

Cumulative Model Updates: 33306
Cumulative Timesteps: 278091466

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.53241
Policy Entropy: 1.29390
Value Function Loss: 0.02000

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06528
Policy Update Magnitude: 0.12326
Value Function Update Magnitude: 0.21698

Collected Steps per Second: 9697.64447
Overall Steps per Second: 6868.64078

Timestep Collection Time: 5.15847
Timestep Consumption Time: 2.12463
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 7.28310

Cumulative Model Updates: 33312
Cumulative Timesteps: 278141491

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.51034
Policy Entropy: 1.29286
Value Function Loss: 0.02100

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.12593
Value Function Update Magnitude: 0.22869

Collected Steps per Second: 10287.68160
Overall Steps per Second: 7248.41237

Timestep Collection Time: 4.86261
Timestep Consumption Time: 2.03890
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 6.90151

Cumulative Model Updates: 33318
Cumulative Timesteps: 278191516

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.97363
Policy Entropy: 1.28968
Value Function Loss: 0.02068

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.12628
Value Function Update Magnitude: 0.22641

Collected Steps per Second: 10123.98951
Overall Steps per Second: 7278.44184

Timestep Collection Time: 4.93946
Timestep Consumption Time: 1.93111
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 6.87056

Cumulative Model Updates: 33324
Cumulative Timesteps: 278241523

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.83134
Policy Entropy: 1.28760
Value Function Loss: 0.02122

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.12130
Value Function Update Magnitude: 0.21629

Collected Steps per Second: 9058.94615
Overall Steps per Second: 6422.60712

Timestep Collection Time: 5.52349
Timestep Consumption Time: 2.26727
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 7.79076

Cumulative Model Updates: 33330
Cumulative Timesteps: 278291560

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 278291560...
Checkpoint 278291560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.55758
Policy Entropy: 1.28249
Value Function Loss: 0.02050

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.11988
Value Function Update Magnitude: 0.21017

Collected Steps per Second: 9194.55969
Overall Steps per Second: 6458.93953

Timestep Collection Time: 5.44061
Timestep Consumption Time: 2.30432
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.74492

Cumulative Model Updates: 33336
Cumulative Timesteps: 278341584

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.84177
Policy Entropy: 1.28611
Value Function Loss: 0.02106

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.21119

Collected Steps per Second: 9803.04517
Overall Steps per Second: 6971.16426

Timestep Collection Time: 5.10392
Timestep Consumption Time: 2.07336
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.17728

Cumulative Model Updates: 33342
Cumulative Timesteps: 278391618

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.95635
Policy Entropy: 1.28030
Value Function Loss: 0.02050

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.13107
Value Function Update Magnitude: 0.20991

Collected Steps per Second: 9454.68739
Overall Steps per Second: 6601.95641

Timestep Collection Time: 5.29029
Timestep Consumption Time: 2.28595
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 7.57624

Cumulative Model Updates: 33348
Cumulative Timesteps: 278441636

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.64489
Policy Entropy: 1.27854
Value Function Loss: 0.02086

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.13113
Value Function Update Magnitude: 0.19913

Collected Steps per Second: 9404.32364
Overall Steps per Second: 6455.40419

Timestep Collection Time: 5.31681
Timestep Consumption Time: 2.42879
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.74560

Cumulative Model Updates: 33354
Cumulative Timesteps: 278491637

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.42146
Policy Entropy: 1.27282
Value Function Loss: 0.02037

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.12489
Value Function Update Magnitude: 0.19111

Collected Steps per Second: 9487.19467
Overall Steps per Second: 6757.89653

Timestep Collection Time: 5.27047
Timestep Consumption Time: 2.12858
PPO Batch Consumption Time: 0.03041
Total Iteration Time: 7.39905

Cumulative Model Updates: 33360
Cumulative Timesteps: 278541639

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.82179
Policy Entropy: 1.27904
Value Function Loss: 0.02008

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.12390
Value Function Update Magnitude: 0.19150

Collected Steps per Second: 9238.30216
Overall Steps per Second: 6672.70697

Timestep Collection Time: 5.41690
Timestep Consumption Time: 2.08275
PPO Batch Consumption Time: 0.02994
Total Iteration Time: 7.49965

Cumulative Model Updates: 33366
Cumulative Timesteps: 278591682

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.43461
Policy Entropy: 1.28245
Value Function Loss: 0.02032

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.12374
Value Function Update Magnitude: 0.19692

Collected Steps per Second: 9873.99593
Overall Steps per Second: 7017.19871

Timestep Collection Time: 5.06512
Timestep Consumption Time: 2.06208
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 7.12720

Cumulative Model Updates: 33372
Cumulative Timesteps: 278641695

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.15517
Policy Entropy: 1.28850
Value Function Loss: 0.02020

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.12459
Value Function Update Magnitude: 0.20397

Collected Steps per Second: 9544.55647
Overall Steps per Second: 6863.61484

Timestep Collection Time: 5.24341
Timestep Consumption Time: 2.04809
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.29149

Cumulative Model Updates: 33378
Cumulative Timesteps: 278691741

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.84995
Policy Entropy: 1.29300
Value Function Loss: 0.02063

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.12424
Value Function Update Magnitude: 0.20612

Collected Steps per Second: 9045.53788
Overall Steps per Second: 6551.45406

Timestep Collection Time: 5.53168
Timestep Consumption Time: 2.10586
PPO Batch Consumption Time: 0.02902
Total Iteration Time: 7.63754

Cumulative Model Updates: 33384
Cumulative Timesteps: 278741778

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.09404
Policy Entropy: 1.29498
Value Function Loss: 0.02040

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.12582
Value Function Update Magnitude: 0.20383

Collected Steps per Second: 9825.65827
Overall Steps per Second: 6964.55214

Timestep Collection Time: 5.09218
Timestep Consumption Time: 2.09192
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.18409

Cumulative Model Updates: 33390
Cumulative Timesteps: 278791812

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 278791812...
Checkpoint 278791812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.57287
Policy Entropy: 1.29039
Value Function Loss: 0.02028

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06608
Policy Update Magnitude: 0.12766
Value Function Update Magnitude: 0.20138

Collected Steps per Second: 9679.07147
Overall Steps per Second: 7023.34911

Timestep Collection Time: 5.16578
Timestep Consumption Time: 1.95333
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 7.11911

Cumulative Model Updates: 33396
Cumulative Timesteps: 278841812

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.05744
Policy Entropy: 1.28295
Value Function Loss: 0.02124

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.13050
Value Function Update Magnitude: 0.19822

Collected Steps per Second: 9783.54330
Overall Steps per Second: 7119.58922

Timestep Collection Time: 5.11175
Timestep Consumption Time: 1.91267
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.02442

Cumulative Model Updates: 33402
Cumulative Timesteps: 278891823

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.44614
Policy Entropy: 1.28193
Value Function Loss: 0.02103

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.13002
Value Function Update Magnitude: 0.20462

Collected Steps per Second: 10892.19946
Overall Steps per Second: 7645.74421

Timestep Collection Time: 4.59292
Timestep Consumption Time: 1.95020
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 6.54312

Cumulative Model Updates: 33408
Cumulative Timesteps: 278941850

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.44027
Policy Entropy: 1.28283
Value Function Loss: 0.02179

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.10606
Policy Update Magnitude: 0.12698
Value Function Update Magnitude: 0.20843

Collected Steps per Second: 9585.48172
Overall Steps per Second: 6696.40929

Timestep Collection Time: 5.21633
Timestep Consumption Time: 2.25051
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 7.46684

Cumulative Model Updates: 33414
Cumulative Timesteps: 278991851

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.33050
Policy Entropy: 1.28419
Value Function Loss: 0.01982

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.12426
Value Function Update Magnitude: 0.20826

Collected Steps per Second: 9332.04862
Overall Steps per Second: 6761.87161

Timestep Collection Time: 5.35852
Timestep Consumption Time: 2.03677
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.39529

Cumulative Model Updates: 33420
Cumulative Timesteps: 279041857

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.83905
Policy Entropy: 1.29160
Value Function Loss: 0.02010

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.12144
Value Function Update Magnitude: 0.20067

Collected Steps per Second: 10549.20787
Overall Steps per Second: 7211.18982

Timestep Collection Time: 4.74121
Timestep Consumption Time: 2.19468
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 6.93589

Cumulative Model Updates: 33426
Cumulative Timesteps: 279091873

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.70207
Policy Entropy: 1.29624
Value Function Loss: 0.01946

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.11905
Value Function Update Magnitude: 0.20339

Collected Steps per Second: 10131.17273
Overall Steps per Second: 7039.41421

Timestep Collection Time: 4.93714
Timestep Consumption Time: 2.16842
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.10556

Cumulative Model Updates: 33432
Cumulative Timesteps: 279141892

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.50426
Policy Entropy: 1.29952
Value Function Loss: 0.02052

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.11769
Value Function Update Magnitude: 0.20871

Collected Steps per Second: 9078.32157
Overall Steps per Second: 6449.21948

Timestep Collection Time: 5.51104
Timestep Consumption Time: 2.24664
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.75768

Cumulative Model Updates: 33438
Cumulative Timesteps: 279191923

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.03575
Policy Entropy: 1.29568
Value Function Loss: 0.02065

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.11860
Value Function Update Magnitude: 0.21218

Collected Steps per Second: 10082.51626
Overall Steps per Second: 7095.67315

Timestep Collection Time: 4.95958
Timestep Consumption Time: 2.08768
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 7.04725

Cumulative Model Updates: 33444
Cumulative Timesteps: 279241928

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.06884
Policy Entropy: 1.29513
Value Function Loss: 0.02085

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.12054
Value Function Update Magnitude: 0.21401

Collected Steps per Second: 9702.59578
Overall Steps per Second: 6774.46436

Timestep Collection Time: 5.15450
Timestep Consumption Time: 2.22793
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.38243

Cumulative Model Updates: 33450
Cumulative Timesteps: 279291940

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 279291940...
Checkpoint 279291940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.63829
Policy Entropy: 1.29583
Value Function Loss: 0.02143

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.11993
Value Function Update Magnitude: 0.22018

Collected Steps per Second: 8823.18826
Overall Steps per Second: 6283.16296

Timestep Collection Time: 5.66757
Timestep Consumption Time: 2.29116
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 7.95873

Cumulative Model Updates: 33456
Cumulative Timesteps: 279341946

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.66911
Policy Entropy: 1.29171
Value Function Loss: 0.02123

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.12181
Value Function Update Magnitude: 0.21897

Collected Steps per Second: 9568.26232
Overall Steps per Second: 6801.73652

Timestep Collection Time: 5.22833
Timestep Consumption Time: 2.12656
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.35489

Cumulative Model Updates: 33462
Cumulative Timesteps: 279391972

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.21924
Policy Entropy: 1.28846
Value Function Loss: 0.02069

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.12220
Value Function Update Magnitude: 0.20890

Collected Steps per Second: 9709.86984
Overall Steps per Second: 6934.08237

Timestep Collection Time: 5.14971
Timestep Consumption Time: 2.06148
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.21119

Cumulative Model Updates: 33468
Cumulative Timesteps: 279441975

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.28351
Policy Entropy: 1.28443
Value Function Loss: 0.01950

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.20390

Collected Steps per Second: 8860.48703
Overall Steps per Second: 6311.60774

Timestep Collection Time: 5.64800
Timestep Consumption Time: 2.28089
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.92888

Cumulative Model Updates: 33474
Cumulative Timesteps: 279492019

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.65609
Policy Entropy: 1.28028
Value Function Loss: 0.02006

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.12072
Value Function Update Magnitude: 0.19938

Collected Steps per Second: 9689.36554
Overall Steps per Second: 6843.08925

Timestep Collection Time: 5.16184
Timestep Consumption Time: 2.14699
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 7.30883

Cumulative Model Updates: 33480
Cumulative Timesteps: 279542034

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.64591
Policy Entropy: 1.28750
Value Function Loss: 0.02042

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.11990
Value Function Update Magnitude: 0.19305

Collected Steps per Second: 9962.82717
Overall Steps per Second: 7212.97956

Timestep Collection Time: 5.02056
Timestep Consumption Time: 1.91402
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 6.93458

Cumulative Model Updates: 33486
Cumulative Timesteps: 279592053

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.49587
Policy Entropy: 1.28747
Value Function Loss: 0.02053

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.12136
Value Function Update Magnitude: 0.19230

Collected Steps per Second: 9198.31472
Overall Steps per Second: 6559.71935

Timestep Collection Time: 5.43795
Timestep Consumption Time: 2.18737
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.62533

Cumulative Model Updates: 33492
Cumulative Timesteps: 279642073

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.25534
Policy Entropy: 1.28630
Value Function Loss: 0.01975

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.18672

Collected Steps per Second: 9629.35015
Overall Steps per Second: 6891.93874

Timestep Collection Time: 5.19298
Timestep Consumption Time: 2.06260
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.25558

Cumulative Model Updates: 33498
Cumulative Timesteps: 279692078

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.23239
Policy Entropy: 1.28365
Value Function Loss: 0.01979

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.12204
Value Function Update Magnitude: 0.18155

Collected Steps per Second: 9992.82022
Overall Steps per Second: 7177.88448

Timestep Collection Time: 5.00659
Timestep Consumption Time: 1.96343
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.97002

Cumulative Model Updates: 33504
Cumulative Timesteps: 279742108

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.38671
Policy Entropy: 1.28566
Value Function Loss: 0.01988

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.11926
Value Function Update Magnitude: 0.18199

Collected Steps per Second: 9551.83455
Overall Steps per Second: 6928.33689

Timestep Collection Time: 5.23585
Timestep Consumption Time: 1.98262
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.21847

Cumulative Model Updates: 33510
Cumulative Timesteps: 279792120

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 279792120...
Checkpoint 279792120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.76405
Policy Entropy: 1.28897
Value Function Loss: 0.02047

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.11786
Value Function Update Magnitude: 0.18886

Collected Steps per Second: 9674.75301
Overall Steps per Second: 6827.38604

Timestep Collection Time: 5.16943
Timestep Consumption Time: 2.15592
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 7.32535

Cumulative Model Updates: 33516
Cumulative Timesteps: 279842133

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.75869
Policy Entropy: 1.28375
Value Function Loss: 0.02030

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.11948
Value Function Update Magnitude: 0.18818

Collected Steps per Second: 9847.23972
Overall Steps per Second: 7003.57424

Timestep Collection Time: 5.08010
Timestep Consumption Time: 2.06268
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 7.14278

Cumulative Model Updates: 33522
Cumulative Timesteps: 279892158

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.48104
Policy Entropy: 1.29061
Value Function Loss: 0.01970

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.11871
Value Function Update Magnitude: 0.18488

Collected Steps per Second: 9849.73774
Overall Steps per Second: 7015.34614

Timestep Collection Time: 5.08105
Timestep Consumption Time: 2.05288
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.13393

Cumulative Model Updates: 33528
Cumulative Timesteps: 279942205

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.63492
Policy Entropy: 1.28999
Value Function Loss: 0.02010

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.11753
Value Function Update Magnitude: 0.18893

Collected Steps per Second: 10398.40933
Overall Steps per Second: 7334.22585

Timestep Collection Time: 4.81025
Timestep Consumption Time: 2.00969
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.81994

Cumulative Model Updates: 33534
Cumulative Timesteps: 279992224

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.61645
Policy Entropy: 1.28894
Value Function Loss: 0.02018

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.11873
Value Function Update Magnitude: 0.19142

Collected Steps per Second: 9671.98072
Overall Steps per Second: 6991.78525

Timestep Collection Time: 5.17381
Timestep Consumption Time: 1.98330
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.15711

Cumulative Model Updates: 33540
Cumulative Timesteps: 280042265

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.91631
Policy Entropy: 1.28792
Value Function Loss: 0.02118

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.12029
Value Function Update Magnitude: 0.19658

Collected Steps per Second: 9062.79590
Overall Steps per Second: 6379.48947

Timestep Collection Time: 5.51728
Timestep Consumption Time: 2.32065
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 7.83793

Cumulative Model Updates: 33546
Cumulative Timesteps: 280092267

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.45054
Policy Entropy: 1.28930
Value Function Loss: 0.01984

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.06837
Policy Update Magnitude: 0.12192
Value Function Update Magnitude: 0.21331

Collected Steps per Second: 9957.24915
Overall Steps per Second: 6958.86574

Timestep Collection Time: 5.02327
Timestep Consumption Time: 2.16439
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.18767

Cumulative Model Updates: 33552
Cumulative Timesteps: 280142285

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.97757
Policy Entropy: 1.28824
Value Function Loss: 0.01990

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.12095
Value Function Update Magnitude: 0.21129

Collected Steps per Second: 9530.62179
Overall Steps per Second: 6603.69104

Timestep Collection Time: 5.24688
Timestep Consumption Time: 2.32555
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.57243

Cumulative Model Updates: 33558
Cumulative Timesteps: 280192291

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.98437
Policy Entropy: 1.28740
Value Function Loss: 0.01918

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.12004
Value Function Update Magnitude: 0.19896

Collected Steps per Second: 8865.91163
Overall Steps per Second: 6307.62721

Timestep Collection Time: 5.64262
Timestep Consumption Time: 2.28857
PPO Batch Consumption Time: 0.03118
Total Iteration Time: 7.93119

Cumulative Model Updates: 33564
Cumulative Timesteps: 280242318

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.93452
Policy Entropy: 1.29136
Value Function Loss: 0.02048

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.11849
Value Function Update Magnitude: 0.19455

Collected Steps per Second: 9351.64781
Overall Steps per Second: 6638.34828

Timestep Collection Time: 5.34868
Timestep Consumption Time: 2.18617
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.53486

Cumulative Model Updates: 33570
Cumulative Timesteps: 280292337

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 280292337...
Checkpoint 280292337 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.02707
Policy Entropy: 1.28844
Value Function Loss: 0.01964

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.11892
Value Function Update Magnitude: 0.18172

Collected Steps per Second: 9372.95456
Overall Steps per Second: 6716.26914

Timestep Collection Time: 5.33642
Timestep Consumption Time: 2.11087
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.44729

Cumulative Model Updates: 33576
Cumulative Timesteps: 280342355

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.03218
Policy Entropy: 1.28947
Value Function Loss: 0.01995

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.11699
Value Function Update Magnitude: 0.18394

Collected Steps per Second: 9413.00303
Overall Steps per Second: 6796.78490

Timestep Collection Time: 5.31371
Timestep Consumption Time: 2.04535
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 7.35907

Cumulative Model Updates: 33582
Cumulative Timesteps: 280392373

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.26074
Policy Entropy: 1.27986
Value Function Loss: 0.01970

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.11516
Value Function Update Magnitude: 0.18199

Collected Steps per Second: 10041.66593
Overall Steps per Second: 6944.64647

Timestep Collection Time: 4.98184
Timestep Consumption Time: 2.22169
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 7.20353

Cumulative Model Updates: 33588
Cumulative Timesteps: 280442399

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.47426
Policy Entropy: 1.28183
Value Function Loss: 0.01994

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.11668
Value Function Update Magnitude: 0.18713

Collected Steps per Second: 9907.13403
Overall Steps per Second: 7022.06316

Timestep Collection Time: 5.05000
Timestep Consumption Time: 2.07483
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 7.12483

Cumulative Model Updates: 33594
Cumulative Timesteps: 280492430

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.71890
Policy Entropy: 1.27735
Value Function Loss: 0.02008

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.12028
Value Function Update Magnitude: 0.19028

Collected Steps per Second: 9004.85323
Overall Steps per Second: 6385.99275

Timestep Collection Time: 5.55578
Timestep Consumption Time: 2.27840
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.83418

Cumulative Model Updates: 33600
Cumulative Timesteps: 280542459

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.82312
Policy Entropy: 1.28265
Value Function Loss: 0.02051

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.12284
Value Function Update Magnitude: 0.19380

Collected Steps per Second: 9864.65908
Overall Steps per Second: 6905.73699

Timestep Collection Time: 5.07052
Timestep Consumption Time: 2.17258
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.24311

Cumulative Model Updates: 33606
Cumulative Timesteps: 280592478

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.87115
Policy Entropy: 1.27718
Value Function Loss: 0.02007

Mean KL Divergence: 0.01765
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.12144
Value Function Update Magnitude: 0.19449

Collected Steps per Second: 9717.37235
Overall Steps per Second: 7105.74509

Timestep Collection Time: 5.14913
Timestep Consumption Time: 1.89250
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.04163

Cumulative Model Updates: 33612
Cumulative Timesteps: 280642514

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.71571
Policy Entropy: 1.27656
Value Function Loss: 0.01983

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.11952
Value Function Update Magnitude: 0.18716

Collected Steps per Second: 10103.22056
Overall Steps per Second: 7225.23992

Timestep Collection Time: 4.95129
Timestep Consumption Time: 1.97221
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 6.92351

Cumulative Model Updates: 33618
Cumulative Timesteps: 280692538

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.90284
Policy Entropy: 1.27780
Value Function Loss: 0.01970

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.12109
Value Function Update Magnitude: 0.18324

Collected Steps per Second: 10517.74250
Overall Steps per Second: 7358.98763

Timestep Collection Time: 4.75644
Timestep Consumption Time: 2.04164
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 6.79808

Cumulative Model Updates: 33624
Cumulative Timesteps: 280742565

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.00032
Policy Entropy: 1.27681
Value Function Loss: 0.02028

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.12234
Value Function Update Magnitude: 0.18060

Collected Steps per Second: 9310.42268
Overall Steps per Second: 6724.50671

Timestep Collection Time: 5.37108
Timestep Consumption Time: 2.06545
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.43653

Cumulative Model Updates: 33630
Cumulative Timesteps: 280792572

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 280792572...
Checkpoint 280792572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.88232
Policy Entropy: 1.28919
Value Function Loss: 0.02079

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.11963
Value Function Update Magnitude: 0.19312

Collected Steps per Second: 9358.88139
Overall Steps per Second: 6788.87172

Timestep Collection Time: 5.34626
Timestep Consumption Time: 2.02389
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.37015

Cumulative Model Updates: 33636
Cumulative Timesteps: 280842607

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.76692
Policy Entropy: 1.28398
Value Function Loss: 0.02053

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.12232
Value Function Update Magnitude: 0.21147

Collected Steps per Second: 10040.15573
Overall Steps per Second: 7129.98450

Timestep Collection Time: 4.98000
Timestep Consumption Time: 2.03264
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 7.01264

Cumulative Model Updates: 33642
Cumulative Timesteps: 280892607

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.17689
Policy Entropy: 1.29397
Value Function Loss: 0.02059

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.12110
Value Function Update Magnitude: 0.22080

Collected Steps per Second: 9833.36506
Overall Steps per Second: 6770.35205

Timestep Collection Time: 5.08768
Timestep Consumption Time: 2.30175
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 7.38942

Cumulative Model Updates: 33648
Cumulative Timesteps: 280942636

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.55167
Policy Entropy: 1.29258
Value Function Loss: 0.02183

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.12216
Value Function Update Magnitude: 0.22989

Collected Steps per Second: 9073.60321
Overall Steps per Second: 6384.71799

Timestep Collection Time: 5.51225
Timestep Consumption Time: 2.32145
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 7.83371

Cumulative Model Updates: 33654
Cumulative Timesteps: 280992652

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.87230
Policy Entropy: 1.29264
Value Function Loss: 0.02264

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.12596
Value Function Update Magnitude: 0.22443

Collected Steps per Second: 10191.03425
Overall Steps per Second: 6803.97383

Timestep Collection Time: 4.90971
Timestep Consumption Time: 2.44408
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.35379

Cumulative Model Updates: 33660
Cumulative Timesteps: 281042687

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.46016
Policy Entropy: 1.28975
Value Function Loss: 0.02243

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.12368
Value Function Update Magnitude: 0.23555

Collected Steps per Second: 10301.25514
Overall Steps per Second: 7136.65052

Timestep Collection Time: 4.85523
Timestep Consumption Time: 2.15296
PPO Batch Consumption Time: 0.02405
Total Iteration Time: 7.00819

Cumulative Model Updates: 33666
Cumulative Timesteps: 281092702

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.36899
Policy Entropy: 1.28936
Value Function Loss: 0.02180

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.12363
Value Function Update Magnitude: 0.23924

Collected Steps per Second: 9140.80156
Overall Steps per Second: 6524.08574

Timestep Collection Time: 5.47195
Timestep Consumption Time: 2.19472
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.66667

Cumulative Model Updates: 33672
Cumulative Timesteps: 281142720

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.60121
Policy Entropy: 1.28873
Value Function Loss: 0.02131

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.12364
Value Function Update Magnitude: 0.23017

Collected Steps per Second: 10267.79969
Overall Steps per Second: 6990.57657

Timestep Collection Time: 4.87105
Timestep Consumption Time: 2.28358
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.15463

Cumulative Model Updates: 33678
Cumulative Timesteps: 281192735

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.52191
Policy Entropy: 1.28720
Value Function Loss: 0.02103

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.12232
Value Function Update Magnitude: 0.21434

Collected Steps per Second: 9858.52201
Overall Steps per Second: 6734.76462

Timestep Collection Time: 5.07439
Timestep Consumption Time: 2.35363
PPO Batch Consumption Time: 0.02863
Total Iteration Time: 7.42803

Cumulative Model Updates: 33684
Cumulative Timesteps: 281242761

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.87181
Policy Entropy: 1.28550
Value Function Loss: 0.02010

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.11967
Value Function Update Magnitude: 0.20744

Collected Steps per Second: 8889.98488
Overall Steps per Second: 6496.66093

Timestep Collection Time: 5.62779
Timestep Consumption Time: 2.07324
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.70103

Cumulative Model Updates: 33690
Cumulative Timesteps: 281292792

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 281292792...
Checkpoint 281292792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.53979
Policy Entropy: 1.29145
Value Function Loss: 0.01962

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.06415
Policy Update Magnitude: 0.11838
Value Function Update Magnitude: 0.19609

Collected Steps per Second: 9726.48757
Overall Steps per Second: 6928.18193

Timestep Collection Time: 5.14142
Timestep Consumption Time: 2.07663
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.21806

Cumulative Model Updates: 33696
Cumulative Timesteps: 281342800

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.07816
Policy Entropy: 1.28868
Value Function Loss: 0.01920

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06368
Policy Update Magnitude: 0.11505
Value Function Update Magnitude: 0.19557

Collected Steps per Second: 9824.07490
Overall Steps per Second: 6821.50637

Timestep Collection Time: 5.09300
Timestep Consumption Time: 2.24174
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.33474

Cumulative Model Updates: 33702
Cumulative Timesteps: 281392834

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.68884
Policy Entropy: 1.28376
Value Function Loss: 0.01958

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.11440
Value Function Update Magnitude: 0.19822

Collected Steps per Second: 9306.44554
Overall Steps per Second: 6718.08975

Timestep Collection Time: 5.37584
Timestep Consumption Time: 2.07121
PPO Batch Consumption Time: 0.02468
Total Iteration Time: 7.44706

Cumulative Model Updates: 33708
Cumulative Timesteps: 281442864

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.25639
Policy Entropy: 1.27535
Value Function Loss: 0.02064

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.11713
Value Function Update Magnitude: 0.20323

Collected Steps per Second: 9785.36878
Overall Steps per Second: 6954.70934

Timestep Collection Time: 5.11008
Timestep Consumption Time: 2.07987
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.18995

Cumulative Model Updates: 33714
Cumulative Timesteps: 281492868

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.66082
Policy Entropy: 1.28352
Value Function Loss: 0.02144

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.11967
Value Function Update Magnitude: 0.19731

Collected Steps per Second: 10463.57593
Overall Steps per Second: 7087.82691

Timestep Collection Time: 4.77858
Timestep Consumption Time: 2.27591
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.05449

Cumulative Model Updates: 33720
Cumulative Timesteps: 281542869

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.84628
Policy Entropy: 1.28823
Value Function Loss: 0.02103

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.12061
Value Function Update Magnitude: 0.19823

Collected Steps per Second: 9363.04400
Overall Steps per Second: 6647.65428

Timestep Collection Time: 5.34175
Timestep Consumption Time: 2.18196
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.52371

Cumulative Model Updates: 33726
Cumulative Timesteps: 281592884

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.65369
Policy Entropy: 1.28905
Value Function Loss: 0.02018

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.11997
Value Function Update Magnitude: 0.20499

Collected Steps per Second: 9557.64173
Overall Steps per Second: 6761.52209

Timestep Collection Time: 5.23194
Timestep Consumption Time: 2.16359
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.39552

Cumulative Model Updates: 33732
Cumulative Timesteps: 281642889

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.04288
Policy Entropy: 1.28533
Value Function Loss: 0.02083

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.11939
Value Function Update Magnitude: 0.19966

Collected Steps per Second: 10683.05772
Overall Steps per Second: 7427.26313

Timestep Collection Time: 4.68209
Timestep Consumption Time: 2.05243
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 6.73451

Cumulative Model Updates: 33738
Cumulative Timesteps: 281692908

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.92394
Policy Entropy: 1.28789
Value Function Loss: 0.02095

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.12250
Value Function Update Magnitude: 0.20472

Collected Steps per Second: 9753.01479
Overall Steps per Second: 7100.32109

Timestep Collection Time: 5.12949
Timestep Consumption Time: 1.91639
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.04588

Cumulative Model Updates: 33744
Cumulative Timesteps: 281742936

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.20349
Policy Entropy: 1.28813
Value Function Loss: 0.02058

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.12121
Value Function Update Magnitude: 0.20772

Collected Steps per Second: 10208.12166
Overall Steps per Second: 7313.33139

Timestep Collection Time: 4.89875
Timestep Consumption Time: 1.93904
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.83779

Cumulative Model Updates: 33750
Cumulative Timesteps: 281792943

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 281792943...
Checkpoint 281792943 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.02918
Policy Entropy: 1.28614
Value Function Loss: 0.02035

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.12074
Value Function Update Magnitude: 0.20135

Collected Steps per Second: 9577.89561
Overall Steps per Second: 6561.31181

Timestep Collection Time: 5.22495
Timestep Consumption Time: 2.40219
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 7.62713

Cumulative Model Updates: 33756
Cumulative Timesteps: 281842987

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.89125
Policy Entropy: 1.29038
Value Function Loss: 0.02041

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.12014
Value Function Update Magnitude: 0.19139

Collected Steps per Second: 8918.39127
Overall Steps per Second: 6394.37039

Timestep Collection Time: 5.60673
Timestep Consumption Time: 2.21312
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.81985

Cumulative Model Updates: 33762
Cumulative Timesteps: 281892990

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.00952
Policy Entropy: 1.29072
Value Function Loss: 0.02118

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.12019
Value Function Update Magnitude: 0.19521

Collected Steps per Second: 9399.51578
Overall Steps per Second: 6827.74260

Timestep Collection Time: 5.32336
Timestep Consumption Time: 2.00512
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.32848

Cumulative Model Updates: 33768
Cumulative Timesteps: 281943027

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.39007
Policy Entropy: 1.29330
Value Function Loss: 0.02034

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.11847
Value Function Update Magnitude: 0.19907

Collected Steps per Second: 9174.84145
Overall Steps per Second: 6372.65403

Timestep Collection Time: 5.45176
Timestep Consumption Time: 2.39725
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 7.84901

Cumulative Model Updates: 33774
Cumulative Timesteps: 281993046

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.09949
Policy Entropy: 1.29647
Value Function Loss: 0.02044

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.11751
Value Function Update Magnitude: 0.19594

Collected Steps per Second: 9054.39451
Overall Steps per Second: 6520.30160

Timestep Collection Time: 5.52328
Timestep Consumption Time: 2.14661
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.66989

Cumulative Model Updates: 33780
Cumulative Timesteps: 282043056

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.76727
Policy Entropy: 1.29898
Value Function Loss: 0.02050

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.11539
Value Function Update Magnitude: 0.19802

Collected Steps per Second: 9526.18810
Overall Steps per Second: 6913.87447

Timestep Collection Time: 5.24932
Timestep Consumption Time: 1.98338
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.23270

Cumulative Model Updates: 33786
Cumulative Timesteps: 282093062

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.27157
Policy Entropy: 1.29023
Value Function Loss: 0.02120

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.11563
Value Function Update Magnitude: 0.19922

Collected Steps per Second: 9237.02861
Overall Steps per Second: 6333.75227

Timestep Collection Time: 5.41343
Timestep Consumption Time: 2.48142
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 7.89485

Cumulative Model Updates: 33792
Cumulative Timesteps: 282143066

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.60845
Policy Entropy: 1.28925
Value Function Loss: 0.02114

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.11690
Value Function Update Magnitude: 0.20163

Collected Steps per Second: 9188.63989
Overall Steps per Second: 6555.16576

Timestep Collection Time: 5.44411
Timestep Consumption Time: 2.18712
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 7.63123

Cumulative Model Updates: 33798
Cumulative Timesteps: 282193090

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.71152
Policy Entropy: 1.29029
Value Function Loss: 0.02042

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.11902
Value Function Update Magnitude: 0.19808

Collected Steps per Second: 9404.93574
Overall Steps per Second: 6828.61958

Timestep Collection Time: 5.31923
Timestep Consumption Time: 2.00685
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 7.32608

Cumulative Model Updates: 33804
Cumulative Timesteps: 282243117

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.51752
Policy Entropy: 1.29481
Value Function Loss: 0.01939

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.11952
Value Function Update Magnitude: 0.20056

Collected Steps per Second: 9402.11111
Overall Steps per Second: 6528.63143

Timestep Collection Time: 5.31827
Timestep Consumption Time: 2.34076
PPO Batch Consumption Time: 0.03060
Total Iteration Time: 7.65903

Cumulative Model Updates: 33810
Cumulative Timesteps: 282293120

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 282293120...
Checkpoint 282293120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.10162
Policy Entropy: 1.28456
Value Function Loss: 0.01900

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.12083
Value Function Update Magnitude: 0.20484

Collected Steps per Second: 9401.13678
Overall Steps per Second: 6747.70074

Timestep Collection Time: 5.32276
Timestep Consumption Time: 2.09310
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.41586

Cumulative Model Updates: 33816
Cumulative Timesteps: 282343160

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.40146
Policy Entropy: 1.28276
Value Function Loss: 0.01914

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.11956
Value Function Update Magnitude: 0.21385

Collected Steps per Second: 9742.82935
Overall Steps per Second: 7121.86570

Timestep Collection Time: 5.13526
Timestep Consumption Time: 1.88986
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.02513

Cumulative Model Updates: 33822
Cumulative Timesteps: 282393192

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.20514
Policy Entropy: 1.28141
Value Function Loss: 0.01997

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.11902
Value Function Update Magnitude: 0.19462

Collected Steps per Second: 10616.19008
Overall Steps per Second: 7375.02576

Timestep Collection Time: 4.71365
Timestep Consumption Time: 2.07155
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.78520

Cumulative Model Updates: 33828
Cumulative Timesteps: 282443233

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.58751
Policy Entropy: 1.28868
Value Function Loss: 0.02023

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.12013
Value Function Update Magnitude: 0.19284

Collected Steps per Second: 9707.90930
Overall Steps per Second: 6986.11387

Timestep Collection Time: 5.15229
Timestep Consumption Time: 2.00734
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.15963

Cumulative Model Updates: 33834
Cumulative Timesteps: 282493251

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.53401
Policy Entropy: 1.28751
Value Function Loss: 0.02043

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.11894
Value Function Update Magnitude: 0.19392

Collected Steps per Second: 9865.04602
Overall Steps per Second: 7014.76480

Timestep Collection Time: 5.07245
Timestep Consumption Time: 2.06107
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.13352

Cumulative Model Updates: 33840
Cumulative Timesteps: 282543291

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.46625
Policy Entropy: 1.28545
Value Function Loss: 0.02001

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.12247
Value Function Update Magnitude: 0.20298

Collected Steps per Second: 10316.33708
Overall Steps per Second: 7339.43188

Timestep Collection Time: 4.84755
Timestep Consumption Time: 1.96619
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.81374

Cumulative Model Updates: 33846
Cumulative Timesteps: 282593300

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.96628
Policy Entropy: 1.28157
Value Function Loss: 0.02019

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.12251
Value Function Update Magnitude: 0.20316

Collected Steps per Second: 9844.46402
Overall Steps per Second: 7144.81305

Timestep Collection Time: 5.08154
Timestep Consumption Time: 1.92005
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.00158

Cumulative Model Updates: 33852
Cumulative Timesteps: 282643325

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.85816
Policy Entropy: 1.28235
Value Function Loss: 0.01929

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.12108
Value Function Update Magnitude: 0.20480

Collected Steps per Second: 9858.88567
Overall Steps per Second: 7088.56648

Timestep Collection Time: 5.07573
Timestep Consumption Time: 1.98367
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.05940

Cumulative Model Updates: 33858
Cumulative Timesteps: 282693366

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.64574
Policy Entropy: 1.28276
Value Function Loss: 0.02024

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.20623

Collected Steps per Second: 10391.47797
Overall Steps per Second: 7268.05963

Timestep Collection Time: 4.81202
Timestep Consumption Time: 2.06795
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 6.87997

Cumulative Model Updates: 33864
Cumulative Timesteps: 282743370

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.38550
Policy Entropy: 1.28710
Value Function Loss: 0.02006

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.12533
Value Function Update Magnitude: 0.20352

Collected Steps per Second: 9851.34468
Overall Steps per Second: 6928.49369

Timestep Collection Time: 5.07657
Timestep Consumption Time: 2.14160
PPO Batch Consumption Time: 0.02443
Total Iteration Time: 7.21816

Cumulative Model Updates: 33870
Cumulative Timesteps: 282793381

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 282793381...
Checkpoint 282793381 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.61198
Policy Entropy: 1.28632
Value Function Loss: 0.02124

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.13023
Value Function Update Magnitude: 0.20636

Collected Steps per Second: 8812.05075
Overall Steps per Second: 6273.73924

Timestep Collection Time: 5.67654
Timestep Consumption Time: 2.29669
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.97324

Cumulative Model Updates: 33876
Cumulative Timesteps: 282843403

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.90930
Policy Entropy: 1.28832
Value Function Loss: 0.02141

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07198
Policy Update Magnitude: 0.12949
Value Function Update Magnitude: 0.21214

Collected Steps per Second: 9528.09575
Overall Steps per Second: 6698.02562

Timestep Collection Time: 5.24858
Timestep Consumption Time: 2.21765
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.46623

Cumulative Model Updates: 33882
Cumulative Timesteps: 282893412

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.98292
Policy Entropy: 1.28842
Value Function Loss: 0.02122

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.13766
Value Function Update Magnitude: 0.21447

Collected Steps per Second: 9551.00671
Overall Steps per Second: 6705.02120

Timestep Collection Time: 5.23652
Timestep Consumption Time: 2.22267
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 7.45919

Cumulative Model Updates: 33888
Cumulative Timesteps: 282943426

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.13743
Policy Entropy: 1.28828
Value Function Loss: 0.02115

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.14028
Value Function Update Magnitude: 0.21487

Collected Steps per Second: 9003.20717
Overall Steps per Second: 6385.34172

Timestep Collection Time: 5.55746
Timestep Consumption Time: 2.27845
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 7.83592

Cumulative Model Updates: 33894
Cumulative Timesteps: 282993461

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.39165
Policy Entropy: 1.28626
Value Function Loss: 0.02055

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.12940
Value Function Update Magnitude: 0.21129

Collected Steps per Second: 9876.27096
Overall Steps per Second: 6939.19548

Timestep Collection Time: 5.06618
Timestep Consumption Time: 2.14431
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.21049

Cumulative Model Updates: 33900
Cumulative Timesteps: 283043496

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.11544
Policy Entropy: 1.28987
Value Function Loss: 0.01983

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.12169
Value Function Update Magnitude: 0.20628

Collected Steps per Second: 9904.26139
Overall Steps per Second: 6896.38780

Timestep Collection Time: 5.04934
Timestep Consumption Time: 2.20228
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.25162

Cumulative Model Updates: 33906
Cumulative Timesteps: 283093506

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.09947
Policy Entropy: 1.29545
Value Function Loss: 0.02001

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.14153
Value Function Update Magnitude: 0.19670

Collected Steps per Second: 9476.96186
Overall Steps per Second: 6692.71539

Timestep Collection Time: 5.27975
Timestep Consumption Time: 2.19644
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 7.47619

Cumulative Model Updates: 33912
Cumulative Timesteps: 283143542

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.99185
Policy Entropy: 1.29085
Value Function Loss: 0.02074

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.12687
Value Function Update Magnitude: 0.19651

Collected Steps per Second: 9713.65995
Overall Steps per Second: 6859.66295

Timestep Collection Time: 5.15151
Timestep Consumption Time: 2.14331
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.29482

Cumulative Model Updates: 33918
Cumulative Timesteps: 283193582

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.48001
Policy Entropy: 1.29019
Value Function Loss: 0.02098

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.11940
Value Function Update Magnitude: 0.20774

Collected Steps per Second: 9356.16592
Overall Steps per Second: 6407.27788

Timestep Collection Time: 5.34738
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.02884
Total Iteration Time: 7.80846

Cumulative Model Updates: 33924
Cumulative Timesteps: 283243613

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.57314
Policy Entropy: 1.29110
Value Function Loss: 0.02059

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.11816
Value Function Update Magnitude: 0.20306

Collected Steps per Second: 8988.40422
Overall Steps per Second: 6399.39791

Timestep Collection Time: 5.56784
Timestep Consumption Time: 2.25258
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 7.82042

Cumulative Model Updates: 33930
Cumulative Timesteps: 283293659

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 283293659...
Checkpoint 283293659 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.93076
Policy Entropy: 1.29325
Value Function Loss: 0.02081

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.11801
Value Function Update Magnitude: 0.20633

Collected Steps per Second: 9534.52652
Overall Steps per Second: 6714.22803

Timestep Collection Time: 5.24840
Timestep Consumption Time: 2.20458
PPO Batch Consumption Time: 0.02433
Total Iteration Time: 7.45298

Cumulative Model Updates: 33936
Cumulative Timesteps: 283343700

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.61073
Policy Entropy: 1.29260
Value Function Loss: 0.02091

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.11977
Value Function Update Magnitude: 0.20092

Collected Steps per Second: 9851.19026
Overall Steps per Second: 7073.08178

Timestep Collection Time: 5.07573
Timestep Consumption Time: 1.99361
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.06934

Cumulative Model Updates: 33942
Cumulative Timesteps: 283393702

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.91001
Policy Entropy: 1.28918
Value Function Loss: 0.02009

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.11980
Value Function Update Magnitude: 0.20029

Collected Steps per Second: 10362.72168
Overall Steps per Second: 7417.61119

Timestep Collection Time: 4.82518
Timestep Consumption Time: 1.91580
PPO Batch Consumption Time: 0.02493
Total Iteration Time: 6.74098

Cumulative Model Updates: 33948
Cumulative Timesteps: 283443704

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.27071
Policy Entropy: 1.28754
Value Function Loss: 0.01942

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.11855
Value Function Update Magnitude: 0.19506

Collected Steps per Second: 10263.71140
Overall Steps per Second: 7310.55300

Timestep Collection Time: 4.87504
Timestep Consumption Time: 1.96931
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.84435

Cumulative Model Updates: 33954
Cumulative Timesteps: 283493740

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.70667
Policy Entropy: 1.28686
Value Function Loss: 0.01953

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.11785
Value Function Update Magnitude: 0.18950

Collected Steps per Second: 9096.71698
Overall Steps per Second: 6587.30928

Timestep Collection Time: 5.50001
Timestep Consumption Time: 2.09520
PPO Batch Consumption Time: 0.02452
Total Iteration Time: 7.59521

Cumulative Model Updates: 33960
Cumulative Timesteps: 283543772

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.12349
Policy Entropy: 1.28089
Value Function Loss: 0.02084

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.19153

Collected Steps per Second: 9487.54655
Overall Steps per Second: 6819.72674

Timestep Collection Time: 5.27239
Timestep Consumption Time: 2.06251
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.33490

Cumulative Model Updates: 33966
Cumulative Timesteps: 283593794

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.91735
Policy Entropy: 1.28710
Value Function Loss: 0.02003

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.12285
Value Function Update Magnitude: 0.19635

Collected Steps per Second: 10349.45478
Overall Steps per Second: 7251.31497

Timestep Collection Time: 4.83339
Timestep Consumption Time: 2.06508
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 6.89847

Cumulative Model Updates: 33972
Cumulative Timesteps: 283643817

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.21026
Policy Entropy: 1.28118
Value Function Loss: 0.02005

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.12629
Value Function Update Magnitude: 0.19518

Collected Steps per Second: 9133.57791
Overall Steps per Second: 6544.33007

Timestep Collection Time: 5.47737
Timestep Consumption Time: 2.16711
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 7.64448

Cumulative Model Updates: 33978
Cumulative Timesteps: 283693845

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.26867
Policy Entropy: 1.28073
Value Function Loss: 0.01941

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.13185
Value Function Update Magnitude: 0.19646

Collected Steps per Second: 9268.17634
Overall Steps per Second: 6741.29125

Timestep Collection Time: 5.39901
Timestep Consumption Time: 2.02375
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.42276

Cumulative Model Updates: 33984
Cumulative Timesteps: 283743884

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.41673
Policy Entropy: 1.27863
Value Function Loss: 0.02002

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.13170
Value Function Update Magnitude: 0.19046

Collected Steps per Second: 10012.80350
Overall Steps per Second: 6965.75514

Timestep Collection Time: 4.99451
Timestep Consumption Time: 2.18476
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.17926

Cumulative Model Updates: 33990
Cumulative Timesteps: 283793893

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 283793893...
Checkpoint 283793893 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.51160
Policy Entropy: 1.28205
Value Function Loss: 0.01922

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.13747
Value Function Update Magnitude: 0.18689

Collected Steps per Second: 9287.42493
Overall Steps per Second: 6530.89128

Timestep Collection Time: 5.38707
Timestep Consumption Time: 2.27375
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.66082

Cumulative Model Updates: 33996
Cumulative Timesteps: 283843925

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.62317
Policy Entropy: 1.28212
Value Function Loss: 0.01983

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.13242
Value Function Update Magnitude: 0.18183

Collected Steps per Second: 8956.82030
Overall Steps per Second: 6401.75603

Timestep Collection Time: 5.58290
Timestep Consumption Time: 2.22824
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 7.81114

Cumulative Model Updates: 34002
Cumulative Timesteps: 283893930

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.54247
Policy Entropy: 1.28243
Value Function Loss: 0.01995

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.12936
Value Function Update Magnitude: 0.18596

Collected Steps per Second: 9471.48620
Overall Steps per Second: 6406.94914

Timestep Collection Time: 5.27964
Timestep Consumption Time: 2.52533
PPO Batch Consumption Time: 0.02879
Total Iteration Time: 7.80496

Cumulative Model Updates: 34008
Cumulative Timesteps: 283943936

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.03914
Policy Entropy: 1.28305
Value Function Loss: 0.02095

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.19072

Collected Steps per Second: 9435.00945
Overall Steps per Second: 6725.65292

Timestep Collection Time: 5.30068
Timestep Consumption Time: 2.13532
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.43601

Cumulative Model Updates: 34014
Cumulative Timesteps: 283993948

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.57889
Policy Entropy: 1.29168
Value Function Loss: 0.02039

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07133
Policy Update Magnitude: 0.12316
Value Function Update Magnitude: 0.18805

Collected Steps per Second: 8988.83915
Overall Steps per Second: 6435.66007

Timestep Collection Time: 5.56401
Timestep Consumption Time: 2.20738
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 7.77139

Cumulative Model Updates: 34020
Cumulative Timesteps: 284043962

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.88001
Policy Entropy: 1.29080
Value Function Loss: 0.02011

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06101
Policy Update Magnitude: 0.12211
Value Function Update Magnitude: 0.18597

Collected Steps per Second: 9069.08343
Overall Steps per Second: 6601.70283

Timestep Collection Time: 5.51324
Timestep Consumption Time: 2.06057
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.57380

Cumulative Model Updates: 34026
Cumulative Timesteps: 284093962

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.26846
Policy Entropy: 1.28974
Value Function Loss: 0.02035

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.12179
Value Function Update Magnitude: 0.18846

Collected Steps per Second: 10296.96520
Overall Steps per Second: 7240.82925

Timestep Collection Time: 4.85881
Timestep Consumption Time: 2.05076
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 6.90957

Cumulative Model Updates: 34032
Cumulative Timesteps: 284143993

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.04577
Policy Entropy: 1.28660
Value Function Loss: 0.02201

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.12336
Value Function Update Magnitude: 0.18586

Collected Steps per Second: 9218.83102
Overall Steps per Second: 6621.93336

Timestep Collection Time: 5.42769
Timestep Consumption Time: 2.12856
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 7.55625

Cumulative Model Updates: 34038
Cumulative Timesteps: 284194030

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.78606
Policy Entropy: 1.28599
Value Function Loss: 0.02270

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.12425
Value Function Update Magnitude: 0.19847

Collected Steps per Second: 9285.60542
Overall Steps per Second: 6695.36497

Timestep Collection Time: 5.38608
Timestep Consumption Time: 2.08372
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 7.46979

Cumulative Model Updates: 34044
Cumulative Timesteps: 284244043

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.66230
Policy Entropy: 1.28560
Value Function Loss: 0.02157

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.12297
Value Function Update Magnitude: 0.19944

Collected Steps per Second: 9981.95308
Overall Steps per Second: 6870.67954

Timestep Collection Time: 5.01215
Timestep Consumption Time: 2.26967
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.28181

Cumulative Model Updates: 34050
Cumulative Timesteps: 284294074

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 284294074...
Checkpoint 284294074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.62440
Policy Entropy: 1.28080
Value Function Loss: 0.01969

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.11810
Value Function Update Magnitude: 0.19404

Collected Steps per Second: 9215.76407
Overall Steps per Second: 6673.09248

Timestep Collection Time: 5.42896
Timestep Consumption Time: 2.06861
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.49757

Cumulative Model Updates: 34056
Cumulative Timesteps: 284344106

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.76209
Policy Entropy: 1.28129
Value Function Loss: 0.01871

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.11688
Value Function Update Magnitude: 0.18757

Collected Steps per Second: 9435.17492
Overall Steps per Second: 6759.20715

Timestep Collection Time: 5.30197
Timestep Consumption Time: 2.09905
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 7.40102

Cumulative Model Updates: 34062
Cumulative Timesteps: 284394131

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.53748
Policy Entropy: 1.28195
Value Function Loss: 0.01822

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.11526
Value Function Update Magnitude: 0.18916

Collected Steps per Second: 10239.67099
Overall Steps per Second: 7341.31622

Timestep Collection Time: 4.88385
Timestep Consumption Time: 1.92815
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 6.81199

Cumulative Model Updates: 34068
Cumulative Timesteps: 284444140

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.36558
Policy Entropy: 1.27906
Value Function Loss: 0.01912

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.10800
Policy Update Magnitude: 0.11332
Value Function Update Magnitude: 0.18406

Collected Steps per Second: 9890.06961
Overall Steps per Second: 7061.95190

Timestep Collection Time: 5.05598
Timestep Consumption Time: 2.02478
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.08076

Cumulative Model Updates: 34074
Cumulative Timesteps: 284494144

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.40673
Policy Entropy: 1.28208
Value Function Loss: 0.01904

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08256
Policy Update Magnitude: 0.11411
Value Function Update Magnitude: 0.17863

Collected Steps per Second: 9180.31326
Overall Steps per Second: 6593.96558

Timestep Collection Time: 5.44709
Timestep Consumption Time: 2.13651
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.58360

Cumulative Model Updates: 34080
Cumulative Timesteps: 284544150

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.73958
Policy Entropy: 1.28276
Value Function Loss: 0.02088

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.11512
Value Function Update Magnitude: 0.18093

Collected Steps per Second: 9037.04676
Overall Steps per Second: 6566.91259

Timestep Collection Time: 5.53333
Timestep Consumption Time: 2.08136
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.61469

Cumulative Model Updates: 34086
Cumulative Timesteps: 284594155

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.14512
Policy Entropy: 1.28509
Value Function Loss: 0.02083

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.11932
Value Function Update Magnitude: 0.19299

Collected Steps per Second: 10121.35128
Overall Steps per Second: 7107.62318

Timestep Collection Time: 4.94331
Timestep Consumption Time: 2.09603
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.03934

Cumulative Model Updates: 34092
Cumulative Timesteps: 284644188

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.96909
Policy Entropy: 1.27844
Value Function Loss: 0.02084

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.12038
Value Function Update Magnitude: 0.20062

Collected Steps per Second: 9052.29500
Overall Steps per Second: 6524.78624

Timestep Collection Time: 5.52368
Timestep Consumption Time: 2.13971
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.66339

Cumulative Model Updates: 34098
Cumulative Timesteps: 284694190

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.54774
Policy Entropy: 1.28247
Value Function Loss: 0.02048

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.12011
Value Function Update Magnitude: 0.19895

Collected Steps per Second: 9330.48126
Overall Steps per Second: 6854.31204

Timestep Collection Time: 5.35899
Timestep Consumption Time: 1.93598
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.29497

Cumulative Model Updates: 34104
Cumulative Timesteps: 284744192

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.02898
Policy Entropy: 1.28167
Value Function Loss: 0.02002

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.11983
Value Function Update Magnitude: 0.19055

Collected Steps per Second: 10491.88229
Overall Steps per Second: 7298.70900

Timestep Collection Time: 4.76912
Timestep Consumption Time: 2.08648
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.85560

Cumulative Model Updates: 34110
Cumulative Timesteps: 284794229

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 284794229...
Checkpoint 284794229 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.75767
Policy Entropy: 1.28354
Value Function Loss: 0.02069

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.12133
Value Function Update Magnitude: 0.19494

Collected Steps per Second: 10693.66907
Overall Steps per Second: 7378.72385

Timestep Collection Time: 4.67753
Timestep Consumption Time: 2.10142
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 6.77895

Cumulative Model Updates: 34116
Cumulative Timesteps: 284844249

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.16695
Policy Entropy: 1.28302
Value Function Loss: 0.01996

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.12337
Value Function Update Magnitude: 0.19338

Collected Steps per Second: 9547.48528
Overall Steps per Second: 6793.67325

Timestep Collection Time: 5.24054
Timestep Consumption Time: 2.12425
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.36479

Cumulative Model Updates: 34122
Cumulative Timesteps: 284894283

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.09044
Policy Entropy: 1.28534
Value Function Loss: 0.02098

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.12339
Value Function Update Magnitude: 0.18754

Collected Steps per Second: 9803.76406
Overall Steps per Second: 7027.41263

Timestep Collection Time: 5.10314
Timestep Consumption Time: 2.01612
PPO Batch Consumption Time: 0.02428
Total Iteration Time: 7.11926

Cumulative Model Updates: 34128
Cumulative Timesteps: 284944313

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.35056
Policy Entropy: 1.28807
Value Function Loss: 0.02055

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.12361
Value Function Update Magnitude: 0.18491

Collected Steps per Second: 9633.20352
Overall Steps per Second: 6953.68228

Timestep Collection Time: 5.19267
Timestep Consumption Time: 2.00093
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.19360

Cumulative Model Updates: 34134
Cumulative Timesteps: 284994335

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.18031
Policy Entropy: 1.28704
Value Function Loss: 0.02087

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.12049
Value Function Update Magnitude: 0.18883

Collected Steps per Second: 10043.46140
Overall Steps per Second: 7096.47523

Timestep Collection Time: 4.98195
Timestep Consumption Time: 2.06888
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.05082

Cumulative Model Updates: 34140
Cumulative Timesteps: 285044371

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.40457
Policy Entropy: 1.28771
Value Function Loss: 0.01993

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.06958
Policy Update Magnitude: 0.11898
Value Function Update Magnitude: 0.19234

Collected Steps per Second: 10486.41831
Overall Steps per Second: 7192.46371

Timestep Collection Time: 4.77103
Timestep Consumption Time: 2.18500
PPO Batch Consumption Time: 0.02867
Total Iteration Time: 6.95603

Cumulative Model Updates: 34146
Cumulative Timesteps: 285094402

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.96921
Policy Entropy: 1.28508
Value Function Loss: 0.01971

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.11862
Value Function Update Magnitude: 0.19334

Collected Steps per Second: 9270.24412
Overall Steps per Second: 6503.32465

Timestep Collection Time: 5.39511
Timestep Consumption Time: 2.29542
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 7.69053

Cumulative Model Updates: 34152
Cumulative Timesteps: 285144416

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.96125
Policy Entropy: 1.28481
Value Function Loss: 0.01919

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.11928
Value Function Update Magnitude: 0.19788

Collected Steps per Second: 9650.97101
Overall Steps per Second: 6767.14421

Timestep Collection Time: 5.18238
Timestep Consumption Time: 2.20848
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 7.39086

Cumulative Model Updates: 34158
Cumulative Timesteps: 285194431

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.60006
Policy Entropy: 1.28741
Value Function Loss: 0.01979

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.11849
Value Function Update Magnitude: 0.20055

Collected Steps per Second: 10388.15827
Overall Steps per Second: 7007.58881

Timestep Collection Time: 4.81616
Timestep Consumption Time: 2.32339
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 7.13955

Cumulative Model Updates: 34164
Cumulative Timesteps: 285244462

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.57782
Policy Entropy: 1.28893
Value Function Loss: 0.02077

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.06628
Policy Update Magnitude: 0.11626
Value Function Update Magnitude: 0.20476

Collected Steps per Second: 10023.12281
Overall Steps per Second: 7083.04615

Timestep Collection Time: 4.99176
Timestep Consumption Time: 2.07201
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.06377

Cumulative Model Updates: 34170
Cumulative Timesteps: 285294495

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 285294495...
Checkpoint 285294495 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.00136
Policy Entropy: 1.28933
Value Function Loss: 0.02051

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.11684
Value Function Update Magnitude: 0.21039

Collected Steps per Second: 10200.88038
Overall Steps per Second: 7307.67162

Timestep Collection Time: 4.90262
Timestep Consumption Time: 1.94101
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 6.84363

Cumulative Model Updates: 34176
Cumulative Timesteps: 285344506

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.65493
Policy Entropy: 1.28309
Value Function Loss: 0.02068

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.11864
Value Function Update Magnitude: 0.20493

Collected Steps per Second: 10335.58785
Overall Steps per Second: 7318.08598

Timestep Collection Time: 4.83969
Timestep Consumption Time: 1.99557
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 6.83526

Cumulative Model Updates: 34182
Cumulative Timesteps: 285394527

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.59216
Policy Entropy: 1.28567
Value Function Loss: 0.01960

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.11612
Value Function Update Magnitude: 0.20228

Collected Steps per Second: 11135.95997
Overall Steps per Second: 7330.78700

Timestep Collection Time: 4.49014
Timestep Consumption Time: 2.33068
PPO Batch Consumption Time: 0.02981
Total Iteration Time: 6.82082

Cumulative Model Updates: 34188
Cumulative Timesteps: 285444529

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.20689
Policy Entropy: 1.28716
Value Function Loss: 0.02014

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.11658
Value Function Update Magnitude: 0.19865

Collected Steps per Second: 9532.26560
Overall Steps per Second: 6800.17977

Timestep Collection Time: 5.24723
Timestep Consumption Time: 2.10816
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.35539

Cumulative Model Updates: 34194
Cumulative Timesteps: 285494547

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.05223
Policy Entropy: 1.28637
Value Function Loss: 0.02000

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.11765
Value Function Update Magnitude: 0.20234

Collected Steps per Second: 10854.32761
Overall Steps per Second: 7512.87283

Timestep Collection Time: 4.60673
Timestep Consumption Time: 2.04891
PPO Batch Consumption Time: 0.02847
Total Iteration Time: 6.65564

Cumulative Model Updates: 34200
Cumulative Timesteps: 285544550

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.28738
Policy Entropy: 1.28742
Value Function Loss: 0.02002

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.11676
Value Function Update Magnitude: 0.19999

Collected Steps per Second: 11736.03555
Overall Steps per Second: 7886.80280

Timestep Collection Time: 4.26115
Timestep Consumption Time: 2.07970
PPO Batch Consumption Time: 0.02913
Total Iteration Time: 6.34085

Cumulative Model Updates: 34206
Cumulative Timesteps: 285594559

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.92778
Policy Entropy: 1.28909
Value Function Loss: 0.02046

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.11839
Value Function Update Magnitude: 0.19690

Collected Steps per Second: 9535.81501
Overall Steps per Second: 6708.11341

Timestep Collection Time: 5.24381
Timestep Consumption Time: 2.21045
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.45426

Cumulative Model Updates: 34212
Cumulative Timesteps: 285644563

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.94909
Policy Entropy: 1.29318
Value Function Loss: 0.02091

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.07614
Policy Update Magnitude: 0.11818
Value Function Update Magnitude: 0.18423

Collected Steps per Second: 9307.37177
Overall Steps per Second: 6662.51457

Timestep Collection Time: 5.37295
Timestep Consumption Time: 2.13293
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.50587

Cumulative Model Updates: 34218
Cumulative Timesteps: 285694571

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.95936
Policy Entropy: 1.29092
Value Function Loss: 0.02181

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.08103
Policy Update Magnitude: 0.12267
Value Function Update Magnitude: 0.18825

Collected Steps per Second: 10738.64742
Overall Steps per Second: 7288.00653

Timestep Collection Time: 4.65729
Timestep Consumption Time: 2.20508
PPO Batch Consumption Time: 0.02949
Total Iteration Time: 6.86237

Cumulative Model Updates: 34224
Cumulative Timesteps: 285744584

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.18732
Policy Entropy: 1.29157
Value Function Loss: 0.02120

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.11926
Value Function Update Magnitude: 0.19466

Collected Steps per Second: 8945.03221
Overall Steps per Second: 6287.06371

Timestep Collection Time: 5.59025
Timestep Consumption Time: 2.36338
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.95363

Cumulative Model Updates: 34230
Cumulative Timesteps: 285794589

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 285794589...
Checkpoint 285794589 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.66314
Policy Entropy: 1.29104
Value Function Loss: 0.02166

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.11903
Value Function Update Magnitude: 0.19648

Collected Steps per Second: 9025.82751
Overall Steps per Second: 6575.42707

Timestep Collection Time: 5.54043
Timestep Consumption Time: 2.06470
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.60513

Cumulative Model Updates: 34236
Cumulative Timesteps: 285844596

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.79160
Policy Entropy: 1.29426
Value Function Loss: 0.02033

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.11853
Value Function Update Magnitude: 0.19532

Collected Steps per Second: 10247.70068
Overall Steps per Second: 7076.95335

Timestep Collection Time: 4.88363
Timestep Consumption Time: 2.18806
PPO Batch Consumption Time: 0.02846
Total Iteration Time: 7.07169

Cumulative Model Updates: 34242
Cumulative Timesteps: 285894642

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.71318
Policy Entropy: 1.29537
Value Function Loss: 0.02070

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.11701
Value Function Update Magnitude: 0.19229

Collected Steps per Second: 9416.72104
Overall Steps per Second: 6740.63169

Timestep Collection Time: 5.31204
Timestep Consumption Time: 2.10893
PPO Batch Consumption Time: 0.02460
Total Iteration Time: 7.42097

Cumulative Model Updates: 34248
Cumulative Timesteps: 285944664

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.37765
Policy Entropy: 1.29310
Value Function Loss: 0.02068

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.11620
Value Function Update Magnitude: 0.19484

Collected Steps per Second: 9309.18083
Overall Steps per Second: 6621.90229

Timestep Collection Time: 5.37308
Timestep Consumption Time: 2.18049
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 7.55357

Cumulative Model Updates: 34254
Cumulative Timesteps: 285994683

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.36377
Policy Entropy: 1.28997
Value Function Loss: 0.02116

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.07510
Policy Update Magnitude: 0.12013
Value Function Update Magnitude: 0.19899

Collected Steps per Second: 11143.57629
Overall Steps per Second: 7475.74311

Timestep Collection Time: 4.48707
Timestep Consumption Time: 2.20150
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 6.68857

Cumulative Model Updates: 34260
Cumulative Timesteps: 286044685

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.66843
Policy Entropy: 1.28641
Value Function Loss: 0.02137

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.11912
Value Function Update Magnitude: 0.20453

Collected Steps per Second: 10883.88645
Overall Steps per Second: 7500.24247

Timestep Collection Time: 4.59413
Timestep Consumption Time: 2.07259
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 6.66672

Cumulative Model Updates: 34266
Cumulative Timesteps: 286094687

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.05813
Policy Entropy: 1.29252
Value Function Loss: 0.02022

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.11942
Value Function Update Magnitude: 0.20172

Collected Steps per Second: 10989.84316
Overall Steps per Second: 7589.61924

Timestep Collection Time: 4.55102
Timestep Consumption Time: 2.03890
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 6.58992

Cumulative Model Updates: 34272
Cumulative Timesteps: 286144702

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.89492
Policy Entropy: 1.29628
Value Function Loss: 0.02057

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.11992
Value Function Update Magnitude: 0.19447

Collected Steps per Second: 11082.33066
Overall Steps per Second: 7589.49362

Timestep Collection Time: 4.51376
Timestep Consumption Time: 2.07732
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 6.59109

Cumulative Model Updates: 34278
Cumulative Timesteps: 286194725

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.78242
Policy Entropy: 1.29578
Value Function Loss: 0.02010

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.12008
Value Function Update Magnitude: 0.19417

Collected Steps per Second: 10618.80833
Overall Steps per Second: 7351.56203

Timestep Collection Time: 4.70947
Timestep Consumption Time: 2.09303
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 6.80250

Cumulative Model Updates: 34284
Cumulative Timesteps: 286244734

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.35695
Policy Entropy: 1.29107
Value Function Loss: 0.02025

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.11732
Value Function Update Magnitude: 0.19290

Collected Steps per Second: 9816.39649
Overall Steps per Second: 7012.58925

Timestep Collection Time: 5.09566
Timestep Consumption Time: 2.03737
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.13303

Cumulative Model Updates: 34290
Cumulative Timesteps: 286294755

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 286294755...
Checkpoint 286294755 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.03189
Policy Entropy: 1.28803
Value Function Loss: 0.02033

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.11861
Value Function Update Magnitude: 0.19780

Collected Steps per Second: 10745.53606
Overall Steps per Second: 7413.22680

Timestep Collection Time: 4.65654
Timestep Consumption Time: 2.09315
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 6.74969

Cumulative Model Updates: 34296
Cumulative Timesteps: 286344792

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.37289
Policy Entropy: 1.28952
Value Function Loss: 0.02072

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.12020
Value Function Update Magnitude: 0.19724

Collected Steps per Second: 9755.89043
Overall Steps per Second: 6990.89662

Timestep Collection Time: 5.12665
Timestep Consumption Time: 2.02766
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.15430

Cumulative Model Updates: 34302
Cumulative Timesteps: 286394807

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.73511
Policy Entropy: 1.28954
Value Function Loss: 0.02087

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.12339
Value Function Update Magnitude: 0.19339

Collected Steps per Second: 9816.63876
Overall Steps per Second: 7018.52806

Timestep Collection Time: 5.09370
Timestep Consumption Time: 2.03073
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.12443

Cumulative Model Updates: 34308
Cumulative Timesteps: 286444810

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.86155
Policy Entropy: 1.29577
Value Function Loss: 0.02037

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.12046
Value Function Update Magnitude: 0.18781

Collected Steps per Second: 10266.40805
Overall Steps per Second: 7144.69871

Timestep Collection Time: 4.87376
Timestep Consumption Time: 2.12948
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 7.00323

Cumulative Model Updates: 34314
Cumulative Timesteps: 286494846

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.76278
Policy Entropy: 1.28635
Value Function Loss: 0.01955

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.11745
Value Function Update Magnitude: 0.19018

Collected Steps per Second: 9159.97675
Overall Steps per Second: 6426.89013

Timestep Collection Time: 5.45973
Timestep Consumption Time: 2.32179
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.78152

Cumulative Model Updates: 34320
Cumulative Timesteps: 286544857

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.85046
Policy Entropy: 1.29043
Value Function Loss: 0.01935

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.11285
Value Function Update Magnitude: 0.19198

Collected Steps per Second: 9244.39244
Overall Steps per Second: 6649.95389

Timestep Collection Time: 5.41366
Timestep Consumption Time: 2.11211
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.52577

Cumulative Model Updates: 34326
Cumulative Timesteps: 286594903

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.47457
Policy Entropy: 1.28149
Value Function Loss: 0.01947

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.11394
Value Function Update Magnitude: 0.19300

Collected Steps per Second: 9963.25447
Overall Steps per Second: 7031.34323

Timestep Collection Time: 5.02145
Timestep Consumption Time: 2.09383
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 7.11528

Cumulative Model Updates: 34332
Cumulative Timesteps: 286644933

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.70832
Policy Entropy: 1.28004
Value Function Loss: 0.02017

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.11827
Value Function Update Magnitude: 0.19463

Collected Steps per Second: 9856.07737
Overall Steps per Second: 7006.65743

Timestep Collection Time: 5.07474
Timestep Consumption Time: 2.06376
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.13850

Cumulative Model Updates: 34338
Cumulative Timesteps: 286694950

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.12630
Policy Entropy: 1.28081
Value Function Loss: 0.02021

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.12130
Value Function Update Magnitude: 0.18744

Collected Steps per Second: 9718.87471
Overall Steps per Second: 6977.71186

Timestep Collection Time: 5.14627
Timestep Consumption Time: 2.02169
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 7.16797

Cumulative Model Updates: 34344
Cumulative Timesteps: 286744966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.35908
Policy Entropy: 1.28443
Value Function Loss: 0.02043

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.12233
Value Function Update Magnitude: 0.18960

Collected Steps per Second: 10386.88975
Overall Steps per Second: 7265.87152

Timestep Collection Time: 4.81675
Timestep Consumption Time: 2.06901
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.88575

Cumulative Model Updates: 34350
Cumulative Timesteps: 286794997

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 286794997...
Checkpoint 286794997 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.80675
Policy Entropy: 1.28418
Value Function Loss: 0.02106

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.12026
Value Function Update Magnitude: 0.19530

Collected Steps per Second: 9738.12252
Overall Steps per Second: 7048.60657

Timestep Collection Time: 5.13508
Timestep Consumption Time: 1.95938
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.09445

Cumulative Model Updates: 34356
Cumulative Timesteps: 286845003

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.14734
Policy Entropy: 1.28386
Value Function Loss: 0.02059

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.11859
Value Function Update Magnitude: 0.19959

Collected Steps per Second: 9682.45725
Overall Steps per Second: 6953.66644

Timestep Collection Time: 5.16821
Timestep Consumption Time: 2.02813
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 7.19635

Cumulative Model Updates: 34362
Cumulative Timesteps: 286895044

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.76426
Policy Entropy: 1.28154
Value Function Loss: 0.02100

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.12170
Value Function Update Magnitude: 0.19507

Collected Steps per Second: 10293.11636
Overall Steps per Second: 7217.49153

Timestep Collection Time: 4.86004
Timestep Consumption Time: 2.07103
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 6.93108

Cumulative Model Updates: 34368
Cumulative Timesteps: 286945069

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.68318
Policy Entropy: 1.28344
Value Function Loss: 0.02043

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.11893
Value Function Update Magnitude: 0.19666

Collected Steps per Second: 9870.57664
Overall Steps per Second: 6969.29496

Timestep Collection Time: 5.06779
Timestep Consumption Time: 2.10969
PPO Batch Consumption Time: 0.02834
Total Iteration Time: 7.17748

Cumulative Model Updates: 34374
Cumulative Timesteps: 286995091

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.51266
Policy Entropy: 1.28446
Value Function Loss: 0.02222

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.12228
Value Function Update Magnitude: 0.19063

Collected Steps per Second: 9663.58017
Overall Steps per Second: 6943.24669

Timestep Collection Time: 5.17479
Timestep Consumption Time: 2.02746
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.20225

Cumulative Model Updates: 34380
Cumulative Timesteps: 287045098

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.53521
Policy Entropy: 1.28100
Value Function Loss: 0.02086

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.19136

Collected Steps per Second: 10221.45706
Overall Steps per Second: 7141.74834

Timestep Collection Time: 4.89441
Timestep Consumption Time: 2.11060
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.00501

Cumulative Model Updates: 34386
Cumulative Timesteps: 287095126

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.66429
Policy Entropy: 1.28420
Value Function Loss: 0.02078

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.12023
Value Function Update Magnitude: 0.18359

Collected Steps per Second: 9854.72747
Overall Steps per Second: 6971.46764

Timestep Collection Time: 5.07391
Timestep Consumption Time: 2.09847
PPO Batch Consumption Time: 0.02419
Total Iteration Time: 7.17238

Cumulative Model Updates: 34392
Cumulative Timesteps: 287145128

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.09381
Policy Entropy: 1.28179
Value Function Loss: 0.01985

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.11693
Value Function Update Magnitude: 0.18280

Collected Steps per Second: 10057.62117
Overall Steps per Second: 7187.73019

Timestep Collection Time: 4.97275
Timestep Consumption Time: 1.98550
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 6.95825

Cumulative Model Updates: 34398
Cumulative Timesteps: 287195142

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.05608
Policy Entropy: 1.28624
Value Function Loss: 0.01948

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.11676
Value Function Update Magnitude: 0.18333

Collected Steps per Second: 10487.75029
Overall Steps per Second: 7267.42546

Timestep Collection Time: 4.76956
Timestep Consumption Time: 2.11348
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.88304

Cumulative Model Updates: 34404
Cumulative Timesteps: 287245164

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.67394
Policy Entropy: 1.28358
Value Function Loss: 0.01958

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.11684
Value Function Update Magnitude: 0.18167

Collected Steps per Second: 9578.00455
Overall Steps per Second: 6735.56463

Timestep Collection Time: 5.22447
Timestep Consumption Time: 2.20475
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.42922

Cumulative Model Updates: 34410
Cumulative Timesteps: 287295204

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 287295204...
Checkpoint 287295204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.09365
Policy Entropy: 1.28702
Value Function Loss: 0.01999

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.11698
Value Function Update Magnitude: 0.18248

Collected Steps per Second: 9314.96351
Overall Steps per Second: 6691.51876

Timestep Collection Time: 5.37168
Timestep Consumption Time: 2.10599
PPO Batch Consumption Time: 0.02427
Total Iteration Time: 7.47767

Cumulative Model Updates: 34416
Cumulative Timesteps: 287345241

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.71259
Policy Entropy: 1.28482
Value Function Loss: 0.02018

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.11965
Value Function Update Magnitude: 0.18408

Collected Steps per Second: 10087.91674
Overall Steps per Second: 7227.34098

Timestep Collection Time: 4.95900
Timestep Consumption Time: 1.96277
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 6.92177

Cumulative Model Updates: 34422
Cumulative Timesteps: 287395267

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.20558
Policy Entropy: 1.28752
Value Function Loss: 0.01937

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.11711
Value Function Update Magnitude: 0.19023

Collected Steps per Second: 9884.59970
Overall Steps per Second: 6982.04732

Timestep Collection Time: 5.06060
Timestep Consumption Time: 2.10377
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.16437

Cumulative Model Updates: 34428
Cumulative Timesteps: 287445289

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.29958
Policy Entropy: 1.28286
Value Function Loss: 0.01902

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.11444
Value Function Update Magnitude: 0.18540

Collected Steps per Second: 9723.33829
Overall Steps per Second: 6909.41641

Timestep Collection Time: 5.14453
Timestep Consumption Time: 2.09516
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 7.23969

Cumulative Model Updates: 34434
Cumulative Timesteps: 287495311

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.96359
Policy Entropy: 1.28332
Value Function Loss: 0.01931

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.11753
Value Function Update Magnitude: 0.18618

Collected Steps per Second: 10159.85377
Overall Steps per Second: 7168.45407

Timestep Collection Time: 4.92143
Timestep Consumption Time: 2.05371
PPO Batch Consumption Time: 0.02486
Total Iteration Time: 6.97514

Cumulative Model Updates: 34440
Cumulative Timesteps: 287545312

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.67265
Policy Entropy: 1.27866
Value Function Loss: 0.02074

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07346
Policy Update Magnitude: 0.11964
Value Function Update Magnitude: 0.19340

Collected Steps per Second: 9617.44269
Overall Steps per Second: 6902.35995

Timestep Collection Time: 5.20149
Timestep Consumption Time: 2.04603
PPO Batch Consumption Time: 0.02445
Total Iteration Time: 7.24752

Cumulative Model Updates: 34446
Cumulative Timesteps: 287595337

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.61270
Policy Entropy: 1.27828
Value Function Loss: 0.02168

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.12275
Value Function Update Magnitude: 0.20487

Collected Steps per Second: 9494.93320
Overall Steps per Second: 6821.30462

Timestep Collection Time: 5.26670
Timestep Consumption Time: 2.06430
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.33100

Cumulative Model Updates: 34452
Cumulative Timesteps: 287645344

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.79212
Policy Entropy: 1.27558
Value Function Loss: 0.02186

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.12429
Value Function Update Magnitude: 0.20165

Collected Steps per Second: 10124.07324
Overall Steps per Second: 6942.83040

Timestep Collection Time: 4.93872
Timestep Consumption Time: 2.26295
PPO Batch Consumption Time: 0.02966
Total Iteration Time: 7.20167

Cumulative Model Updates: 34458
Cumulative Timesteps: 287695344

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.63337
Policy Entropy: 1.27707
Value Function Loss: 0.02155

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.12490
Value Function Update Magnitude: 0.20677

Collected Steps per Second: 9135.32040
Overall Steps per Second: 6609.21015

Timestep Collection Time: 5.47501
Timestep Consumption Time: 2.09261
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 7.56762

Cumulative Model Updates: 34464
Cumulative Timesteps: 287745360

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.85740
Policy Entropy: 1.27672
Value Function Loss: 0.02097

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.12476
Value Function Update Magnitude: 0.20646

Collected Steps per Second: 9443.00979
Overall Steps per Second: 6823.91657

Timestep Collection Time: 5.29736
Timestep Consumption Time: 2.03318
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.33054

Cumulative Model Updates: 34470
Cumulative Timesteps: 287795383

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 287795383...
Checkpoint 287795383 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.24947
Policy Entropy: 1.28009
Value Function Loss: 0.02124

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.12358
Value Function Update Magnitude: 0.20842

Collected Steps per Second: 9332.30001
Overall Steps per Second: 6517.49082

Timestep Collection Time: 5.36063
Timestep Consumption Time: 2.31518
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.67581

Cumulative Model Updates: 34476
Cumulative Timesteps: 287845410

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.12719
Policy Entropy: 1.27893
Value Function Loss: 0.02243

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.12236
Value Function Update Magnitude: 0.21219

Collected Steps per Second: 9123.60816
Overall Steps per Second: 6519.81056

Timestep Collection Time: 5.48456
Timestep Consumption Time: 2.19035
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 7.67492

Cumulative Model Updates: 34482
Cumulative Timesteps: 287895449

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.06756
Policy Entropy: 1.28369
Value Function Loss: 0.02179

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.12280
Value Function Update Magnitude: 0.21847

Collected Steps per Second: 8965.29567
Overall Steps per Second: 6393.85709

Timestep Collection Time: 5.57717
Timestep Consumption Time: 2.24299
PPO Batch Consumption Time: 0.02834
Total Iteration Time: 7.82016

Cumulative Model Updates: 34488
Cumulative Timesteps: 287945450

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.87684
Policy Entropy: 1.28378
Value Function Loss: 0.02220

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.12442
Value Function Update Magnitude: 0.21821

Collected Steps per Second: 9589.21289
Overall Steps per Second: 6802.27118

Timestep Collection Time: 5.21461
Timestep Consumption Time: 2.13646
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.35107

Cumulative Model Updates: 34494
Cumulative Timesteps: 287995454

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.42391
Policy Entropy: 1.28439
Value Function Loss: 0.02119

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07070
Policy Update Magnitude: 0.12187
Value Function Update Magnitude: 0.21463

Collected Steps per Second: 9594.09356
Overall Steps per Second: 6704.74321

Timestep Collection Time: 5.21217
Timestep Consumption Time: 2.24614
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.45830

Cumulative Model Updates: 34500
Cumulative Timesteps: 288045460

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.24560
Policy Entropy: 1.28107
Value Function Loss: 0.02143

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.12168
Value Function Update Magnitude: 0.21988

Collected Steps per Second: 9275.47990
Overall Steps per Second: 6588.81601

Timestep Collection Time: 5.39336
Timestep Consumption Time: 2.19920
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.59256

Cumulative Model Updates: 34506
Cumulative Timesteps: 288095486

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.15785
Policy Entropy: 1.27679
Value Function Loss: 0.02041

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.11905
Value Function Update Magnitude: 0.21988

Collected Steps per Second: 9330.49341
Overall Steps per Second: 6429.79447

Timestep Collection Time: 5.36285
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.78221

Cumulative Model Updates: 34512
Cumulative Timesteps: 288145524

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.16539
Policy Entropy: 1.27743
Value Function Loss: 0.01991

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.12373
Value Function Update Magnitude: 0.22149

Collected Steps per Second: 9906.28107
Overall Steps per Second: 6915.71120

Timestep Collection Time: 5.05144
Timestep Consumption Time: 2.18440
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.23584

Cumulative Model Updates: 34518
Cumulative Timesteps: 288195565

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.32440
Policy Entropy: 1.27571
Value Function Loss: 0.02048

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.12195
Value Function Update Magnitude: 0.21822

Collected Steps per Second: 9705.91590
Overall Steps per Second: 6925.24071

Timestep Collection Time: 5.15325
Timestep Consumption Time: 2.06917
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.22242

Cumulative Model Updates: 34524
Cumulative Timesteps: 288245582

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.90260
Policy Entropy: 1.28024
Value Function Loss: 0.02022

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.21200

Collected Steps per Second: 9605.14300
Overall Steps per Second: 6740.63584

Timestep Collection Time: 5.21002
Timestep Consumption Time: 2.21406
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 7.42408

Cumulative Model Updates: 34530
Cumulative Timesteps: 288295625

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 288295625...
Checkpoint 288295625 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.98636
Policy Entropy: 1.28406
Value Function Loss: 0.02110

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.21600

Collected Steps per Second: 10037.79003
Overall Steps per Second: 7103.92988

Timestep Collection Time: 4.98476
Timestep Consumption Time: 2.05866
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 7.04343

Cumulative Model Updates: 34536
Cumulative Timesteps: 288345661

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.19753
Policy Entropy: 1.29237
Value Function Loss: 0.02036

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.12136
Value Function Update Magnitude: 0.20853

Collected Steps per Second: 9880.43006
Overall Steps per Second: 7080.17361

Timestep Collection Time: 5.06527
Timestep Consumption Time: 2.00335
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 7.06861

Cumulative Model Updates: 34542
Cumulative Timesteps: 288395708

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.13619
Policy Entropy: 1.29348
Value Function Loss: 0.02140

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.11895
Value Function Update Magnitude: 0.20683

Collected Steps per Second: 9741.22153
Overall Steps per Second: 6986.85699

Timestep Collection Time: 5.13591
Timestep Consumption Time: 2.02468
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.16059

Cumulative Model Updates: 34548
Cumulative Timesteps: 288445738

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.54457
Policy Entropy: 1.28765
Value Function Loss: 0.02038

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06737
Policy Update Magnitude: 0.11818
Value Function Update Magnitude: 0.19622

Collected Steps per Second: 10256.02705
Overall Steps per Second: 7201.75842

Timestep Collection Time: 4.87859
Timestep Consumption Time: 2.06901
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 6.94761

Cumulative Model Updates: 34554
Cumulative Timesteps: 288495773

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.31931
Policy Entropy: 1.28243
Value Function Loss: 0.02093

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.06920
Policy Update Magnitude: 0.11904
Value Function Update Magnitude: 0.18700

Collected Steps per Second: 9872.05297
Overall Steps per Second: 6970.81876

Timestep Collection Time: 5.06511
Timestep Consumption Time: 2.10808
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 7.17319

Cumulative Model Updates: 34560
Cumulative Timesteps: 288545776

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.69726
Policy Entropy: 1.28309
Value Function Loss: 0.02035

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.12008
Value Function Update Magnitude: 0.18742

Collected Steps per Second: 9661.58441
Overall Steps per Second: 6859.77028

Timestep Collection Time: 5.17524
Timestep Consumption Time: 2.11378
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 7.28902

Cumulative Model Updates: 34566
Cumulative Timesteps: 288595777

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.21572
Policy Entropy: 1.28628
Value Function Loss: 0.02082

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06184
Policy Update Magnitude: 0.12020
Value Function Update Magnitude: 0.19157

Collected Steps per Second: 10066.02356
Overall Steps per Second: 6997.12873

Timestep Collection Time: 4.97009
Timestep Consumption Time: 2.17985
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 7.14993

Cumulative Model Updates: 34572
Cumulative Timesteps: 288645806

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.99261
Policy Entropy: 1.28374
Value Function Loss: 0.02119

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.12096
Value Function Update Magnitude: 0.18944

Collected Steps per Second: 8835.32713
Overall Steps per Second: 6274.86574

Timestep Collection Time: 5.65910
Timestep Consumption Time: 2.30920
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 7.96830

Cumulative Model Updates: 34578
Cumulative Timesteps: 288695806

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.87959
Policy Entropy: 1.28468
Value Function Loss: 0.02138

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.12330
Value Function Update Magnitude: 0.19043

Collected Steps per Second: 9316.52078
Overall Steps per Second: 6667.91183

Timestep Collection Time: 5.36853
Timestep Consumption Time: 2.13247
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.50100

Cumulative Model Updates: 34584
Cumulative Timesteps: 288745822

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.36767
Policy Entropy: 1.28420
Value Function Loss: 0.02123

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.12095
Value Function Update Magnitude: 0.19081

Collected Steps per Second: 10029.23393
Overall Steps per Second: 6990.52109

Timestep Collection Time: 4.98662
Timestep Consumption Time: 2.16764
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 7.15426

Cumulative Model Updates: 34590
Cumulative Timesteps: 288795834

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 288795834...
Checkpoint 288795834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.81024
Policy Entropy: 1.28538
Value Function Loss: 0.02040

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.11955
Value Function Update Magnitude: 0.18673

Collected Steps per Second: 9770.48542
Overall Steps per Second: 3645.86787

Timestep Collection Time: 5.12042
Timestep Consumption Time: 8.60169
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 13.72211

Cumulative Model Updates: 34596
Cumulative Timesteps: 288845863

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.22833
Policy Entropy: 1.28853
Value Function Loss: 0.02045

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06413
Policy Update Magnitude: 0.11952
Value Function Update Magnitude: 0.19344

Collected Steps per Second: 9964.62557
Overall Steps per Second: 7059.38985

Timestep Collection Time: 5.02106
Timestep Consumption Time: 2.06638
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.08744

Cumulative Model Updates: 34602
Cumulative Timesteps: 288895896

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.80087
Policy Entropy: 1.28895
Value Function Loss: 0.01970

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.06605
Policy Update Magnitude: 0.12276
Value Function Update Magnitude: 0.19309

Collected Steps per Second: 10338.89689
Overall Steps per Second: 7236.60949

Timestep Collection Time: 4.83678
Timestep Consumption Time: 2.07350
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 6.91028

Cumulative Model Updates: 34608
Cumulative Timesteps: 288945903

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.87809
Policy Entropy: 1.28230
Value Function Loss: 0.02034

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.12253
Value Function Update Magnitude: 0.20006

Collected Steps per Second: 9722.27105
Overall Steps per Second: 7009.37461

Timestep Collection Time: 5.14509
Timestep Consumption Time: 1.99135
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.13644

Cumulative Model Updates: 34614
Cumulative Timesteps: 288995925

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.13444
Policy Entropy: 1.27551
Value Function Loss: 0.02020

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.12183
Value Function Update Magnitude: 0.19848

Collected Steps per Second: 9657.03205
Overall Steps per Second: 6933.02588

Timestep Collection Time: 5.17892
Timestep Consumption Time: 2.03481
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.21373

Cumulative Model Updates: 34620
Cumulative Timesteps: 289045938

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.44668
Policy Entropy: 1.27184
Value Function Loss: 0.02119

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.12178
Value Function Update Magnitude: 0.19615

Collected Steps per Second: 10319.29504
Overall Steps per Second: 7193.30400

Timestep Collection Time: 4.84597
Timestep Consumption Time: 2.10591
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 6.95188

Cumulative Model Updates: 34626
Cumulative Timesteps: 289095945

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.09992
Policy Entropy: 1.27522
Value Function Loss: 0.02120

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.12449
Value Function Update Magnitude: 0.19719

Collected Steps per Second: 9916.90719
Overall Steps per Second: 6968.35726

Timestep Collection Time: 5.04210
Timestep Consumption Time: 2.13348
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 7.17558

Cumulative Model Updates: 34632
Cumulative Timesteps: 289145947

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.23347
Policy Entropy: 1.27528
Value Function Loss: 0.02058

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.11981
Value Function Update Magnitude: 0.18898

Collected Steps per Second: 9876.71428
Overall Steps per Second: 7075.41390

Timestep Collection Time: 5.06575
Timestep Consumption Time: 2.00563
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.07139

Cumulative Model Updates: 34638
Cumulative Timesteps: 289195980

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.56873
Policy Entropy: 1.27760
Value Function Loss: 0.02018

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.12484
Value Function Update Magnitude: 0.18264

Collected Steps per Second: 10313.45146
Overall Steps per Second: 7116.12804

Timestep Collection Time: 4.84891
Timestep Consumption Time: 2.17865
PPO Batch Consumption Time: 0.02878
Total Iteration Time: 7.02756

Cumulative Model Updates: 34644
Cumulative Timesteps: 289245989

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.29780
Policy Entropy: 1.27012
Value Function Loss: 0.02042

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.13305
Value Function Update Magnitude: 0.18821

Collected Steps per Second: 9822.51612
Overall Steps per Second: 6894.21480

Timestep Collection Time: 5.09330
Timestep Consumption Time: 2.16337
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 7.25666

Cumulative Model Updates: 34650
Cumulative Timesteps: 289296018

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 289296018...
Checkpoint 289296018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.54707
Policy Entropy: 1.26696
Value Function Loss: 0.02082

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.13174
Value Function Update Magnitude: 0.18773

Collected Steps per Second: 9700.17559
Overall Steps per Second: 6943.35014

Timestep Collection Time: 5.15465
Timestep Consumption Time: 2.04663
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.20128

Cumulative Model Updates: 34656
Cumulative Timesteps: 289346019

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.51944
Policy Entropy: 1.26559
Value Function Loss: 0.02062

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.12927
Value Function Update Magnitude: 0.18698

Collected Steps per Second: 10145.64348
Overall Steps per Second: 7146.57761

Timestep Collection Time: 4.93138
Timestep Consumption Time: 2.06946
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.00083

Cumulative Model Updates: 34662
Cumulative Timesteps: 289396051

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.51943
Policy Entropy: 1.26958
Value Function Loss: 0.02118

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.12422
Value Function Update Magnitude: 0.18952

Collected Steps per Second: 9977.11265
Overall Steps per Second: 7033.28474

Timestep Collection Time: 5.01247
Timestep Consumption Time: 2.09800
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.11048

Cumulative Model Updates: 34668
Cumulative Timesteps: 289446061

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.40187
Policy Entropy: 1.26957
Value Function Loss: 0.02101

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.12697
Value Function Update Magnitude: 0.20052

Collected Steps per Second: 9823.53150
Overall Steps per Second: 7010.03411

Timestep Collection Time: 5.09124
Timestep Consumption Time: 2.04339
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 7.13463

Cumulative Model Updates: 34674
Cumulative Timesteps: 289496075

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.15997
Policy Entropy: 1.27036
Value Function Loss: 0.02091

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.12668
Value Function Update Magnitude: 0.21471

Collected Steps per Second: 10285.64930
Overall Steps per Second: 7130.78939

Timestep Collection Time: 4.86173
Timestep Consumption Time: 2.15096
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.01269

Cumulative Model Updates: 34680
Cumulative Timesteps: 289546081

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.80795
Policy Entropy: 1.27371
Value Function Loss: 0.02083

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.12707
Value Function Update Magnitude: 0.22054

Collected Steps per Second: 9810.20451
Overall Steps per Second: 6980.49130

Timestep Collection Time: 5.10071
Timestep Consumption Time: 2.06770
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.16841

Cumulative Model Updates: 34686
Cumulative Timesteps: 289596120

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.06766
Policy Entropy: 1.27827
Value Function Loss: 0.02157

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.12550
Value Function Update Magnitude: 0.20664

Collected Steps per Second: 9585.48888
Overall Steps per Second: 6901.92630

Timestep Collection Time: 5.22070
Timestep Consumption Time: 2.02988
PPO Batch Consumption Time: 0.02847
Total Iteration Time: 7.25058

Cumulative Model Updates: 34692
Cumulative Timesteps: 289646163

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.07852
Policy Entropy: 1.28130
Value Function Loss: 0.02281

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.12671
Value Function Update Magnitude: 0.21227

Collected Steps per Second: 10361.18070
Overall Steps per Second: 7243.96191

Timestep Collection Time: 4.82831
Timestep Consumption Time: 2.07772
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 6.90603

Cumulative Model Updates: 34698
Cumulative Timesteps: 289696190

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.88566
Policy Entropy: 1.27958
Value Function Loss: 0.02346

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.12805
Value Function Update Magnitude: 0.20920

Collected Steps per Second: 9775.95331
Overall Steps per Second: 6972.72758

Timestep Collection Time: 5.11643
Timestep Consumption Time: 2.05694
PPO Batch Consumption Time: 0.02999
Total Iteration Time: 7.17338

Cumulative Model Updates: 34704
Cumulative Timesteps: 289746208

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.23655
Policy Entropy: 1.28358
Value Function Loss: 0.02316

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.12751
Value Function Update Magnitude: 0.20712

Collected Steps per Second: 9729.74266
Overall Steps per Second: 6977.07711

Timestep Collection Time: 5.14361
Timestep Consumption Time: 2.02931
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.17292

Cumulative Model Updates: 34710
Cumulative Timesteps: 289796254

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 289796254...
Checkpoint 289796254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.12589
Policy Entropy: 1.28729
Value Function Loss: 0.02256

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.12329
Value Function Update Magnitude: 0.19942

Collected Steps per Second: 10384.27242
Overall Steps per Second: 7154.26282

Timestep Collection Time: 4.81671
Timestep Consumption Time: 2.17465
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 6.99136

Cumulative Model Updates: 34716
Cumulative Timesteps: 289846272

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.31192
Policy Entropy: 1.28262
Value Function Loss: 0.02107

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.12320
Value Function Update Magnitude: 0.21108

Collected Steps per Second: 9931.83770
Overall Steps per Second: 7066.73923

Timestep Collection Time: 5.03885
Timestep Consumption Time: 2.04292
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 7.08177

Cumulative Model Updates: 34722
Cumulative Timesteps: 289896317

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.48248
Policy Entropy: 1.27973
Value Function Loss: 0.02019

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.20635

Collected Steps per Second: 9803.33564
Overall Steps per Second: 7020.20697

Timestep Collection Time: 5.10102
Timestep Consumption Time: 2.02228
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.12329

Cumulative Model Updates: 34728
Cumulative Timesteps: 289946324

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.04476
Policy Entropy: 1.27996
Value Function Loss: 0.01995

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.11997
Value Function Update Magnitude: 0.19693

Collected Steps per Second: 10430.31209
Overall Steps per Second: 7230.32317

Timestep Collection Time: 4.79410
Timestep Consumption Time: 2.12177
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 6.91587

Cumulative Model Updates: 34734
Cumulative Timesteps: 289996328

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.61551
Policy Entropy: 1.28083
Value Function Loss: 0.02124

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.11855
Value Function Update Magnitude: 0.21480

Collected Steps per Second: 10148.94568
Overall Steps per Second: 7057.06271

Timestep Collection Time: 4.93036
Timestep Consumption Time: 2.16012
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.09049

Cumulative Model Updates: 34740
Cumulative Timesteps: 290046366

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.04162
Policy Entropy: 1.28056
Value Function Loss: 0.02180

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.11936
Value Function Update Magnitude: 0.21520

Collected Steps per Second: 9943.01499
Overall Steps per Second: 7091.67619

Timestep Collection Time: 5.03197
Timestep Consumption Time: 2.02320
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.05517

Cumulative Model Updates: 34746
Cumulative Timesteps: 290096399

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.64537
Policy Entropy: 1.28055
Value Function Loss: 0.02209

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.12006
Value Function Update Magnitude: 0.21027

Collected Steps per Second: 10374.79493
Overall Steps per Second: 7237.49598

Timestep Collection Time: 4.81947
Timestep Consumption Time: 2.08914
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 6.90860

Cumulative Model Updates: 34752
Cumulative Timesteps: 290146400

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.36859
Policy Entropy: 1.28369
Value Function Loss: 0.02177

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07171
Policy Update Magnitude: 0.12133
Value Function Update Magnitude: 0.20826

Collected Steps per Second: 9876.78594
Overall Steps per Second: 6999.66547

Timestep Collection Time: 5.06349
Timestep Consumption Time: 2.08128
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.14477

Cumulative Model Updates: 34758
Cumulative Timesteps: 290196411

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.37004
Policy Entropy: 1.28182
Value Function Loss: 0.02143

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.12036
Value Function Update Magnitude: 0.21475

Collected Steps per Second: 9822.54462
Overall Steps per Second: 7009.12774

Timestep Collection Time: 5.09216
Timestep Consumption Time: 2.04396
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 7.13612

Cumulative Model Updates: 34764
Cumulative Timesteps: 290246429

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97003
Policy Entropy: 1.27661
Value Function Loss: 0.02195

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.12081
Value Function Update Magnitude: 0.21321

Collected Steps per Second: 10429.90660
Overall Steps per Second: 7273.53850

Timestep Collection Time: 4.79458
Timestep Consumption Time: 2.08062
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 6.87520

Cumulative Model Updates: 34770
Cumulative Timesteps: 290296436

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 290296436...
Checkpoint 290296436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.96500
Policy Entropy: 1.28059
Value Function Loss: 0.02283

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.12210
Value Function Update Magnitude: 0.22777

Collected Steps per Second: 9819.70633
Overall Steps per Second: 6956.58688

Timestep Collection Time: 5.09190
Timestep Consumption Time: 2.09567
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.18758

Cumulative Model Updates: 34776
Cumulative Timesteps: 290346437

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.33209
Policy Entropy: 1.27730
Value Function Loss: 0.02331

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07083
Policy Update Magnitude: 0.12751
Value Function Update Magnitude: 0.22156

Collected Steps per Second: 9799.89736
Overall Steps per Second: 7044.20181

Timestep Collection Time: 5.10475
Timestep Consumption Time: 1.99698
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.10173

Cumulative Model Updates: 34782
Cumulative Timesteps: 290396463

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.86389
Policy Entropy: 1.27998
Value Function Loss: 0.02298

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.06915
Policy Update Magnitude: 0.12694
Value Function Update Magnitude: 0.20911

Collected Steps per Second: 10642.37543
Overall Steps per Second: 7151.54276

Timestep Collection Time: 4.70243
Timestep Consumption Time: 2.29536
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 6.99779

Cumulative Model Updates: 34788
Cumulative Timesteps: 290446508

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.58972
Policy Entropy: 1.27695
Value Function Loss: 0.02215

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.12689
Value Function Update Magnitude: 0.19991

Collected Steps per Second: 10285.20158
Overall Steps per Second: 7219.26242

Timestep Collection Time: 4.86544
Timestep Consumption Time: 2.06630
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.93173

Cumulative Model Updates: 34794
Cumulative Timesteps: 290496550

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.72145
Policy Entropy: 1.27613
Value Function Loss: 0.02123

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.12441
Value Function Update Magnitude: 0.20468

Collected Steps per Second: 9817.62619
Overall Steps per Second: 7046.61171

Timestep Collection Time: 5.09685
Timestep Consumption Time: 2.00429
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.10114

Cumulative Model Updates: 34800
Cumulative Timesteps: 290546589

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.67751
Policy Entropy: 1.27883
Value Function Loss: 0.02109

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.11904
Value Function Update Magnitude: 0.20629

Collected Steps per Second: 10397.26121
Overall Steps per Second: 7271.11753

Timestep Collection Time: 4.81088
Timestep Consumption Time: 2.06839
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.87927

Cumulative Model Updates: 34806
Cumulative Timesteps: 290596609

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.41215
Policy Entropy: 1.27779
Value Function Loss: 0.02024

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.11887
Value Function Update Magnitude: 0.20017

Collected Steps per Second: 9702.44095
Overall Steps per Second: 6827.56931

Timestep Collection Time: 5.15633
Timestep Consumption Time: 2.17117
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.32750

Cumulative Model Updates: 34812
Cumulative Timesteps: 290646638

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.64526
Policy Entropy: 1.28641
Value Function Loss: 0.02191

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.06574
Policy Update Magnitude: 0.12152
Value Function Update Magnitude: 0.20453

Collected Steps per Second: 9275.32757
Overall Steps per Second: 6668.68450

Timestep Collection Time: 5.39248
Timestep Consumption Time: 2.10780
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.50028

Cumulative Model Updates: 34818
Cumulative Timesteps: 290696655

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.63667
Policy Entropy: 1.28485
Value Function Loss: 0.02252

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.12334
Value Function Update Magnitude: 0.21598

Collected Steps per Second: 9938.93706
Overall Steps per Second: 6961.09728

Timestep Collection Time: 5.03112
Timestep Consumption Time: 2.15223
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 7.18335

Cumulative Model Updates: 34824
Cumulative Timesteps: 290746659

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.30298
Policy Entropy: 1.28388
Value Function Loss: 0.02326

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07327
Policy Update Magnitude: 0.12525
Value Function Update Magnitude: 0.21223

Collected Steps per Second: 9661.77469
Overall Steps per Second: 6904.03252

Timestep Collection Time: 5.17793
Timestep Consumption Time: 2.06827
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 7.24620

Cumulative Model Updates: 34830
Cumulative Timesteps: 290796687

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 290796687...
Checkpoint 290796687 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.47820
Policy Entropy: 1.27684
Value Function Loss: 0.02151

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.12646
Value Function Update Magnitude: 0.20491

Collected Steps per Second: 9246.76655
Overall Steps per Second: 6720.60679

Timestep Collection Time: 5.41173
Timestep Consumption Time: 2.03418
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.44591

Cumulative Model Updates: 34836
Cumulative Timesteps: 290846728

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.94765
Policy Entropy: 1.27715
Value Function Loss: 0.02127

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.12420
Value Function Update Magnitude: 0.19230

Collected Steps per Second: 9973.40469
Overall Steps per Second: 6969.77084

Timestep Collection Time: 5.01333
Timestep Consumption Time: 2.16050
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 7.17384

Cumulative Model Updates: 34842
Cumulative Timesteps: 290896728

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.10789
Policy Entropy: 1.28102
Value Function Loss: 0.02028

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.11868
Value Function Update Magnitude: 0.18762

Collected Steps per Second: 9084.33394
Overall Steps per Second: 6548.96057

Timestep Collection Time: 5.50486
Timestep Consumption Time: 2.13116
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 7.63602

Cumulative Model Updates: 34848
Cumulative Timesteps: 290946736

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.90690
Policy Entropy: 1.28316
Value Function Loss: 0.02049

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.11926
Value Function Update Magnitude: 0.18856

Collected Steps per Second: 9547.76770
Overall Steps per Second: 6663.94077

Timestep Collection Time: 5.24091
Timestep Consumption Time: 2.26801
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.50892

Cumulative Model Updates: 34854
Cumulative Timesteps: 290996775

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.06424
Policy Entropy: 1.28410
Value Function Loss: 0.02044

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.11900
Value Function Update Magnitude: 0.18613

Collected Steps per Second: 10078.33738
Overall Steps per Second: 6928.85558

Timestep Collection Time: 4.96223
Timestep Consumption Time: 2.25556
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.21779

Cumulative Model Updates: 34860
Cumulative Timesteps: 291046786

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.49853
Policy Entropy: 1.28223
Value Function Loss: 0.02096

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.11709
Value Function Update Magnitude: 0.18871

Collected Steps per Second: 9762.67937
Overall Steps per Second: 6863.05012

Timestep Collection Time: 5.12370
Timestep Consumption Time: 2.16475
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 7.28845

Cumulative Model Updates: 34866
Cumulative Timesteps: 291096807

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.91134
Policy Entropy: 1.27975
Value Function Loss: 0.01990

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.11628
Value Function Update Magnitude: 0.19827

Collected Steps per Second: 9431.97899
Overall Steps per Second: 6831.94669

Timestep Collection Time: 5.30387
Timestep Consumption Time: 2.01849
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 7.32236

Cumulative Model Updates: 34872
Cumulative Timesteps: 291146833

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.48909
Policy Entropy: 1.27806
Value Function Loss: 0.02043

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.11682
Value Function Update Magnitude: 0.19943

Collected Steps per Second: 10100.11524
Overall Steps per Second: 7099.38665

Timestep Collection Time: 4.95400
Timestep Consumption Time: 2.09393
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.04793

Cumulative Model Updates: 34878
Cumulative Timesteps: 291196869

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.34099
Policy Entropy: 1.28390
Value Function Loss: 0.01989

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.11666
Value Function Update Magnitude: 0.21931

Collected Steps per Second: 9691.87613
Overall Steps per Second: 6838.37443

Timestep Collection Time: 5.16185
Timestep Consumption Time: 2.15392
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 7.31577

Cumulative Model Updates: 34884
Cumulative Timesteps: 291246897

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.73716
Policy Entropy: 1.28742
Value Function Loss: 0.02066

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.11949
Value Function Update Magnitude: 0.22925

Collected Steps per Second: 9803.26607
Overall Steps per Second: 6996.80142

Timestep Collection Time: 5.10218
Timestep Consumption Time: 2.04652
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.14870

Cumulative Model Updates: 34890
Cumulative Timesteps: 291296915

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 291296915...
Checkpoint 291296915 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.13605
Policy Entropy: 1.29382
Value Function Loss: 0.02141

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.12008
Value Function Update Magnitude: 0.22403

Collected Steps per Second: 10260.22269
Overall Steps per Second: 7203.17322

Timestep Collection Time: 4.87348
Timestep Consumption Time: 2.06832
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 6.94180

Cumulative Model Updates: 34896
Cumulative Timesteps: 291346918

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.94043
Policy Entropy: 1.28271
Value Function Loss: 0.02141

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.12246
Value Function Update Magnitude: 0.22977

Collected Steps per Second: 9715.40214
Overall Steps per Second: 6989.99289

Timestep Collection Time: 5.14750
Timestep Consumption Time: 2.00702
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.15451

Cumulative Model Updates: 34902
Cumulative Timesteps: 291396928

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.83182
Policy Entropy: 1.28150
Value Function Loss: 0.02126

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.12341
Value Function Update Magnitude: 0.21606

Collected Steps per Second: 9677.00543
Overall Steps per Second: 6980.84084

Timestep Collection Time: 5.16782
Timestep Consumption Time: 1.99593
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.16375

Cumulative Model Updates: 34908
Cumulative Timesteps: 291446937

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.54154
Policy Entropy: 1.27941
Value Function Loss: 0.01916

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.11883
Value Function Update Magnitude: 0.20985

Collected Steps per Second: 10140.86983
Overall Steps per Second: 7123.70731

Timestep Collection Time: 4.93242
Timestep Consumption Time: 2.08907
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.02148

Cumulative Model Updates: 34914
Cumulative Timesteps: 291496956

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.08888
Policy Entropy: 1.28547
Value Function Loss: 0.01957

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.11609
Value Function Update Magnitude: 0.21241

Collected Steps per Second: 9733.66304
Overall Steps per Second: 6984.12740

Timestep Collection Time: 5.13959
Timestep Consumption Time: 2.02337
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.16296

Cumulative Model Updates: 34920
Cumulative Timesteps: 291546983

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.34998
Policy Entropy: 1.28417
Value Function Loss: 0.02023

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.11720
Value Function Update Magnitude: 0.20791

Collected Steps per Second: 9880.15146
Overall Steps per Second: 7075.82065

Timestep Collection Time: 5.06278
Timestep Consumption Time: 2.00651
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 7.06929

Cumulative Model Updates: 34926
Cumulative Timesteps: 291597004

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.61676
Policy Entropy: 1.28895
Value Function Loss: 0.02151

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.06646
Policy Update Magnitude: 0.11998
Value Function Update Magnitude: 0.21338

Collected Steps per Second: 10204.93763
Overall Steps per Second: 7128.62789

Timestep Collection Time: 4.90116
Timestep Consumption Time: 2.11506
PPO Batch Consumption Time: 0.03005
Total Iteration Time: 7.01622

Cumulative Model Updates: 34932
Cumulative Timesteps: 291647020

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.54581
Policy Entropy: 1.28805
Value Function Loss: 0.02170

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.12267
Value Function Update Magnitude: 0.23176

Collected Steps per Second: 9762.26670
Overall Steps per Second: 6920.64490

Timestep Collection Time: 5.12535
Timestep Consumption Time: 2.10447
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.22982

Cumulative Model Updates: 34938
Cumulative Timesteps: 291697055

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.37577
Policy Entropy: 1.29534
Value Function Loss: 0.02104

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.12084
Value Function Update Magnitude: 0.23728

Collected Steps per Second: 9708.44741
Overall Steps per Second: 6956.04056

Timestep Collection Time: 5.15304
Timestep Consumption Time: 2.03898
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.19202

Cumulative Model Updates: 34944
Cumulative Timesteps: 291747083

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.23901
Policy Entropy: 1.29469
Value Function Loss: 0.02094

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.12108
Value Function Update Magnitude: 0.24366

Collected Steps per Second: 10310.39593
Overall Steps per Second: 7166.26835

Timestep Collection Time: 4.85161
Timestep Consumption Time: 2.12859
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 6.98020

Cumulative Model Updates: 34950
Cumulative Timesteps: 291797105

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 291797105...
Checkpoint 291797105 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.92975
Policy Entropy: 1.29453
Value Function Loss: 0.01981

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.11691
Value Function Update Magnitude: 0.22444

Collected Steps per Second: 9801.23888
Overall Steps per Second: 6905.22635

Timestep Collection Time: 5.10589
Timestep Consumption Time: 2.14138
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 7.24726

Cumulative Model Updates: 34956
Cumulative Timesteps: 291847149

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.03084
Policy Entropy: 1.28733
Value Function Loss: 0.01958

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.11625
Value Function Update Magnitude: 0.21419

Collected Steps per Second: 9717.04659
Overall Steps per Second: 6935.48587

Timestep Collection Time: 5.14663
Timestep Consumption Time: 2.06412
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 7.21074

Cumulative Model Updates: 34962
Cumulative Timesteps: 291897159

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.32089
Policy Entropy: 1.28229
Value Function Loss: 0.02069

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.11766
Value Function Update Magnitude: 0.20787

Collected Steps per Second: 10367.48232
Overall Steps per Second: 7223.94135

Timestep Collection Time: 4.82692
Timestep Consumption Time: 2.10046
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 6.92738

Cumulative Model Updates: 34968
Cumulative Timesteps: 291947202

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.44109
Policy Entropy: 1.28121
Value Function Loss: 0.02107

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.12212
Value Function Update Magnitude: 0.20714

Collected Steps per Second: 10112.56550
Overall Steps per Second: 7281.69739

Timestep Collection Time: 4.94593
Timestep Consumption Time: 1.92280
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.86873

Cumulative Model Updates: 34974
Cumulative Timesteps: 291997218

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.99640
Policy Entropy: 1.28227
Value Function Loss: 0.02101

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.12335
Value Function Update Magnitude: 0.21131

Collected Steps per Second: 9786.27629
Overall Steps per Second: 7010.64020

Timestep Collection Time: 5.11103
Timestep Consumption Time: 2.02355
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.13458

Cumulative Model Updates: 34980
Cumulative Timesteps: 292047236

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.98978
Policy Entropy: 1.28592
Value Function Loss: 0.02147

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.12371
Value Function Update Magnitude: 0.21325

Collected Steps per Second: 10006.08732
Overall Steps per Second: 6999.38972

Timestep Collection Time: 4.99746
Timestep Consumption Time: 2.14674
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 7.14419

Cumulative Model Updates: 34986
Cumulative Timesteps: 292097241

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.79987
Policy Entropy: 1.28652
Value Function Loss: 0.02155

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.12593
Value Function Update Magnitude: 0.20869

Collected Steps per Second: 9848.82462
Overall Steps per Second: 7064.82200

Timestep Collection Time: 5.07807
Timestep Consumption Time: 2.00109
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.07916

Cumulative Model Updates: 34992
Cumulative Timesteps: 292147254

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.04536
Policy Entropy: 1.28657
Value Function Loss: 0.02367

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.09545
Policy Update Magnitude: 0.12261
Value Function Update Magnitude: 0.17959

Collected Steps per Second: 9804.75325
Overall Steps per Second: 7007.20631

Timestep Collection Time: 5.09957
Timestep Consumption Time: 2.03594
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 7.13551

Cumulative Model Updates: 34998
Cumulative Timesteps: 292197254

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.26112
Policy Entropy: 1.29032
Value Function Loss: 0.02247

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.11828
Value Function Update Magnitude: 0.15829

Collected Steps per Second: 10321.34877
Overall Steps per Second: 7228.61464

Timestep Collection Time: 4.84723
Timestep Consumption Time: 2.07387
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 6.92110

Cumulative Model Updates: 35004
Cumulative Timesteps: 292247284

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.50008
Policy Entropy: 1.28873
Value Function Loss: 0.02204

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.11879
Value Function Update Magnitude: 0.16490

Collected Steps per Second: 9801.37855
Overall Steps per Second: 7047.30952

Timestep Collection Time: 5.10398
Timestep Consumption Time: 1.99462
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.09860

Cumulative Model Updates: 35010
Cumulative Timesteps: 292297310

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 292297310...
Checkpoint 292297310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.31375
Policy Entropy: 1.29158
Value Function Loss: 0.02151

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.12768
Value Function Update Magnitude: 0.18010

Collected Steps per Second: 9807.99977
Overall Steps per Second: 7027.59561

Timestep Collection Time: 5.09920
Timestep Consumption Time: 2.01745
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.11666

Cumulative Model Updates: 35016
Cumulative Timesteps: 292347323

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.35428
Policy Entropy: 1.28662
Value Function Loss: 0.02164

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.13144
Value Function Update Magnitude: 0.19390

Collected Steps per Second: 10543.87825
Overall Steps per Second: 7293.31457

Timestep Collection Time: 4.74417
Timestep Consumption Time: 2.11444
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 6.85861

Cumulative Model Updates: 35022
Cumulative Timesteps: 292397345

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.30336
Policy Entropy: 1.28193
Value Function Loss: 0.02086

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.13325
Value Function Update Magnitude: 0.19194

Collected Steps per Second: 9921.87728
Overall Steps per Second: 7004.26352

Timestep Collection Time: 5.04330
Timestep Consumption Time: 2.10078
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 7.14408

Cumulative Model Updates: 35028
Cumulative Timesteps: 292447384

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.14049
Policy Entropy: 1.27490
Value Function Loss: 0.01989

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.12855
Value Function Update Magnitude: 0.18747

Collected Steps per Second: 9598.89954
Overall Steps per Second: 6870.64728

Timestep Collection Time: 5.21258
Timestep Consumption Time: 2.06985
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 7.28243

Cumulative Model Updates: 35034
Cumulative Timesteps: 292497419

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.05970
Policy Entropy: 1.27246
Value Function Loss: 0.01983

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.12712
Value Function Update Magnitude: 0.19221

Collected Steps per Second: 10337.97174
Overall Steps per Second: 7174.75188

Timestep Collection Time: 4.83683
Timestep Consumption Time: 2.13247
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 6.96930

Cumulative Model Updates: 35040
Cumulative Timesteps: 292547422

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.67967
Policy Entropy: 1.27567
Value Function Loss: 0.02116

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.12341
Value Function Update Magnitude: 0.19796

Collected Steps per Second: 9875.55657
Overall Steps per Second: 7008.42799

Timestep Collection Time: 5.06321
Timestep Consumption Time: 2.07134
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.13455

Cumulative Model Updates: 35046
Cumulative Timesteps: 292597424

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.68514
Policy Entropy: 1.27972
Value Function Loss: 0.02222

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.12617
Value Function Update Magnitude: 0.19406

Collected Steps per Second: 9854.30674
Overall Steps per Second: 7013.31106

Timestep Collection Time: 5.07514
Timestep Consumption Time: 2.05587
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 7.13101

Cumulative Model Updates: 35052
Cumulative Timesteps: 292647436

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.94000
Policy Entropy: 1.27239
Value Function Loss: 0.02212

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.12650
Value Function Update Magnitude: 0.19288

Collected Steps per Second: 10394.43160
Overall Steps per Second: 7205.25983

Timestep Collection Time: 4.81258
Timestep Consumption Time: 2.13013
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 6.94271

Cumulative Model Updates: 35058
Cumulative Timesteps: 292697460

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.91538
Policy Entropy: 1.27298
Value Function Loss: 0.02128

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.12463
Value Function Update Magnitude: 0.20711

Collected Steps per Second: 9830.21908
Overall Steps per Second: 6955.43316

Timestep Collection Time: 5.08656
Timestep Consumption Time: 2.10235
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.18891

Cumulative Model Updates: 35064
Cumulative Timesteps: 292747462

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.93271
Policy Entropy: 1.27463
Value Function Loss: 0.02120

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.12429
Value Function Update Magnitude: 0.20553

Collected Steps per Second: 9669.76308
Overall Steps per Second: 6971.69350

Timestep Collection Time: 5.17169
Timestep Consumption Time: 2.00146
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.17315

Cumulative Model Updates: 35070
Cumulative Timesteps: 292797471

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 292797471...
Checkpoint 292797471 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.16193
Policy Entropy: 1.28408
Value Function Loss: 0.02103

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.12657
Value Function Update Magnitude: 0.20037

Collected Steps per Second: 10640.75607
Overall Steps per Second: 7322.19884

Timestep Collection Time: 4.70249
Timestep Consumption Time: 2.13125
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 6.83374

Cumulative Model Updates: 35076
Cumulative Timesteps: 292847509

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.42991
Policy Entropy: 1.26939
Value Function Loss: 0.02114

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.12548
Value Function Update Magnitude: 0.19492

Collected Steps per Second: 9722.27408
Overall Steps per Second: 6987.38942

Timestep Collection Time: 5.14489
Timestep Consumption Time: 2.01372
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.15861

Cumulative Model Updates: 35082
Cumulative Timesteps: 292897529

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.67960
Policy Entropy: 1.26510
Value Function Loss: 0.02055

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.12444
Value Function Update Magnitude: 0.19306

Collected Steps per Second: 9599.75644
Overall Steps per Second: 6922.13191

Timestep Collection Time: 5.21222
Timestep Consumption Time: 2.01619
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 7.22841

Cumulative Model Updates: 35088
Cumulative Timesteps: 292947565

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.09919
Policy Entropy: 1.25890
Value Function Loss: 0.02112

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.12189
Value Function Update Magnitude: 0.19401

Collected Steps per Second: 10470.53666
Overall Steps per Second: 7279.86503

Timestep Collection Time: 4.77664
Timestep Consumption Time: 2.09354
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 6.87018

Cumulative Model Updates: 35094
Cumulative Timesteps: 292997579

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.51718
Policy Entropy: 1.26148
Value Function Loss: 0.02110

Mean KL Divergence: 0.01958
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.12404
Value Function Update Magnitude: 0.20909

Collected Steps per Second: 9732.79538
Overall Steps per Second: 6999.52264

Timestep Collection Time: 5.14148
Timestep Consumption Time: 2.00772
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.14920

Cumulative Model Updates: 35100
Cumulative Timesteps: 293047620

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.09216
Policy Entropy: 1.26169
Value Function Loss: 0.02170

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.12297
Value Function Update Magnitude: 0.22160

Collected Steps per Second: 9655.42337
Overall Steps per Second: 6972.65523

Timestep Collection Time: 5.17854
Timestep Consumption Time: 1.99247
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.17101

Cumulative Model Updates: 35106
Cumulative Timesteps: 293097621

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.94348
Policy Entropy: 1.26701
Value Function Loss: 0.02162

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.12625
Value Function Update Magnitude: 0.21370

Collected Steps per Second: 10274.13690
Overall Steps per Second: 7267.65954

Timestep Collection Time: 4.86892
Timestep Consumption Time: 2.01417
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 6.88310

Cumulative Model Updates: 35112
Cumulative Timesteps: 293147645

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.96949
Policy Entropy: 1.27343
Value Function Loss: 0.02187

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.12736
Value Function Update Magnitude: 0.20851

Collected Steps per Second: 9807.16841
Overall Steps per Second: 7057.13989

Timestep Collection Time: 5.09903
Timestep Consumption Time: 1.98699
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.08602

Cumulative Model Updates: 35118
Cumulative Timesteps: 293197652

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.24821
Policy Entropy: 1.26554
Value Function Loss: 0.02114

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.12844
Value Function Update Magnitude: 0.20022

Collected Steps per Second: 9910.22482
Overall Steps per Second: 7093.56265

Timestep Collection Time: 5.04994
Timestep Consumption Time: 2.00519
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.05513

Cumulative Model Updates: 35124
Cumulative Timesteps: 293247698

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.53327
Policy Entropy: 1.26789
Value Function Loss: 0.02128

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.12942
Value Function Update Magnitude: 0.20414

Collected Steps per Second: 10623.02629
Overall Steps per Second: 7371.54700

Timestep Collection Time: 4.71033
Timestep Consumption Time: 2.07766
PPO Batch Consumption Time: 0.02484
Total Iteration Time: 6.78799

Cumulative Model Updates: 35130
Cumulative Timesteps: 293297736

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 293297736...
Checkpoint 293297736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.72082
Policy Entropy: 1.26052
Value Function Loss: 0.02115

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.12865
Value Function Update Magnitude: 0.21290

Collected Steps per Second: 9812.00006
Overall Steps per Second: 6980.00517

Timestep Collection Time: 5.09651
Timestep Consumption Time: 2.06781
PPO Batch Consumption Time: 0.02501
Total Iteration Time: 7.16432

Cumulative Model Updates: 35136
Cumulative Timesteps: 293347743

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.44182
Policy Entropy: 1.26395
Value Function Loss: 0.02204

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.12949
Value Function Update Magnitude: 0.22405

Collected Steps per Second: 9638.09129
Overall Steps per Second: 6943.74157

Timestep Collection Time: 5.18931
Timestep Consumption Time: 2.01358
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.20289

Cumulative Model Updates: 35142
Cumulative Timesteps: 293397758

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.30408
Policy Entropy: 1.25895
Value Function Loss: 0.02190

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.13068
Value Function Update Magnitude: 0.22026

Collected Steps per Second: 10454.24020
Overall Steps per Second: 7213.79416

Timestep Collection Time: 4.78705
Timestep Consumption Time: 2.15035
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 6.93740

Cumulative Model Updates: 35148
Cumulative Timesteps: 293447803

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.04155
Policy Entropy: 1.25938
Value Function Loss: 0.02203

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.12912
Value Function Update Magnitude: 0.21748

Collected Steps per Second: 10164.28303
Overall Steps per Second: 7198.00894

Timestep Collection Time: 4.92292
Timestep Consumption Time: 2.02872
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.95164

Cumulative Model Updates: 35154
Cumulative Timesteps: 293497841

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.57813
Policy Entropy: 1.25610
Value Function Loss: 0.02131

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.12583
Value Function Update Magnitude: 0.22808

Collected Steps per Second: 10025.61797
Overall Steps per Second: 7102.31041

Timestep Collection Time: 4.99002
Timestep Consumption Time: 2.05389
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 7.04391

Cumulative Model Updates: 35160
Cumulative Timesteps: 293547869

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.82005
Policy Entropy: 1.25035
Value Function Loss: 0.02105

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.12188
Value Function Update Magnitude: 0.23413

Collected Steps per Second: 10336.07041
Overall Steps per Second: 7217.90570

Timestep Collection Time: 4.83898
Timestep Consumption Time: 2.09046
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 6.92943

Cumulative Model Updates: 35166
Cumulative Timesteps: 293597885

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.57020
Policy Entropy: 1.25190
Value Function Loss: 0.02234

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.12151
Value Function Update Magnitude: 0.22763

Collected Steps per Second: 9866.29113
Overall Steps per Second: 7063.41703

Timestep Collection Time: 5.07040
Timestep Consumption Time: 2.01201
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.08241

Cumulative Model Updates: 35172
Cumulative Timesteps: 293647911

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.74123
Policy Entropy: 1.25532
Value Function Loss: 0.02313

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.12634
Value Function Update Magnitude: 0.22665

Collected Steps per Second: 9696.85534
Overall Steps per Second: 6937.86471

Timestep Collection Time: 5.15827
Timestep Consumption Time: 2.05130
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.20957

Cumulative Model Updates: 35178
Cumulative Timesteps: 293697930

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.44808
Policy Entropy: 1.25849
Value Function Loss: 0.02348

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.12699
Value Function Update Magnitude: 0.23614

Collected Steps per Second: 10461.05184
Overall Steps per Second: 7282.65877

Timestep Collection Time: 4.78327
Timestep Consumption Time: 2.08758
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 6.87084

Cumulative Model Updates: 35184
Cumulative Timesteps: 293747968

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.06862
Policy Entropy: 1.25826
Value Function Loss: 0.02204

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.12876
Value Function Update Magnitude: 0.23392

Collected Steps per Second: 10000.69482
Overall Steps per Second: 7040.25641

Timestep Collection Time: 5.00195
Timestep Consumption Time: 2.10333
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.10528

Cumulative Model Updates: 35190
Cumulative Timesteps: 293797991

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 293797991...
Checkpoint 293797991 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.35474
Policy Entropy: 1.25369
Value Function Loss: 0.02164

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.12728
Value Function Update Magnitude: 0.22850

Collected Steps per Second: 9894.60231
Overall Steps per Second: 7027.72657

Timestep Collection Time: 5.05740
Timestep Consumption Time: 2.06311
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 7.12051

Cumulative Model Updates: 35196
Cumulative Timesteps: 293848032

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.63866
Policy Entropy: 1.24857
Value Function Loss: 0.02161

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.12337
Value Function Update Magnitude: 0.22795

Collected Steps per Second: 10420.49828
Overall Steps per Second: 7052.51221

Timestep Collection Time: 4.79919
Timestep Consumption Time: 2.29190
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 7.09109

Cumulative Model Updates: 35202
Cumulative Timesteps: 293898042

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.64339
Policy Entropy: 1.24993
Value Function Loss: 0.02131

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.22607

Collected Steps per Second: 10521.20677
Overall Steps per Second: 7274.70985

Timestep Collection Time: 4.75544
Timestep Consumption Time: 2.12222
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 6.87766

Cumulative Model Updates: 35208
Cumulative Timesteps: 293948075

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.31541
Policy Entropy: 1.25296
Value Function Loss: 0.02026

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.12467
Value Function Update Magnitude: 0.22740

Collected Steps per Second: 9952.48955
Overall Steps per Second: 7110.18507

Timestep Collection Time: 5.02628
Timestep Consumption Time: 2.00926
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.03554

Cumulative Model Updates: 35214
Cumulative Timesteps: 293998099

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.28203
Policy Entropy: 1.25612
Value Function Loss: 0.02066

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.13052
Value Function Update Magnitude: 0.22589

Collected Steps per Second: 9768.62508
Overall Steps per Second: 6984.75881

Timestep Collection Time: 5.12058
Timestep Consumption Time: 2.04087
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 7.16145

Cumulative Model Updates: 35220
Cumulative Timesteps: 294048120

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.25612
Policy Entropy: 1.25011
Value Function Loss: 0.02057

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.13449
Value Function Update Magnitude: 0.22506

Collected Steps per Second: 10299.14805
Overall Steps per Second: 7144.61903

Timestep Collection Time: 4.85865
Timestep Consumption Time: 2.14522
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.00387

Cumulative Model Updates: 35226
Cumulative Timesteps: 294098160

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.33650
Policy Entropy: 1.25150
Value Function Loss: 0.02110

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.13851
Value Function Update Magnitude: 0.22341

Collected Steps per Second: 9808.26847
Overall Steps per Second: 6930.73477

Timestep Collection Time: 5.09794
Timestep Consumption Time: 2.11659
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 7.21453

Cumulative Model Updates: 35232
Cumulative Timesteps: 294148162

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.28023
Policy Entropy: 1.25014
Value Function Loss: 0.02165

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.13395
Value Function Update Magnitude: 0.21913

Collected Steps per Second: 9758.14466
Overall Steps per Second: 6972.82963

Timestep Collection Time: 5.12515
Timestep Consumption Time: 2.04726
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.17241

Cumulative Model Updates: 35238
Cumulative Timesteps: 294198174

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.35958
Policy Entropy: 1.25568
Value Function Loss: 0.02150

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.14188
Value Function Update Magnitude: 0.21872

Collected Steps per Second: 10372.30210
Overall Steps per Second: 7175.02033

Timestep Collection Time: 4.82198
Timestep Consumption Time: 2.14874
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 6.97071

Cumulative Model Updates: 35244
Cumulative Timesteps: 294248189

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.61730
Policy Entropy: 1.26013
Value Function Loss: 0.02125

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.14409
Value Function Update Magnitude: 0.22074

Collected Steps per Second: 9727.43992
Overall Steps per Second: 3322.32754

Timestep Collection Time: 5.14452
Timestep Consumption Time: 9.91811
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 15.06263

Cumulative Model Updates: 35250
Cumulative Timesteps: 294298232

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 294298232...
Checkpoint 294298232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.68837
Policy Entropy: 1.26060
Value Function Loss: 0.02178

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.14651
Value Function Update Magnitude: 0.21751

Collected Steps per Second: 9656.61058
Overall Steps per Second: 6913.80922

Timestep Collection Time: 5.18080
Timestep Consumption Time: 2.05529
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 7.23610

Cumulative Model Updates: 35256
Cumulative Timesteps: 294348261

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.28820
Policy Entropy: 1.26062
Value Function Loss: 0.02200

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07297
Policy Update Magnitude: 0.14215
Value Function Update Magnitude: 0.23113

Collected Steps per Second: 10292.30528
Overall Steps per Second: 7203.03016

Timestep Collection Time: 4.86169
Timestep Consumption Time: 2.08511
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 6.94680

Cumulative Model Updates: 35262
Cumulative Timesteps: 294398299

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.85992
Policy Entropy: 1.25732
Value Function Loss: 0.02413

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.13987
Value Function Update Magnitude: 0.22662

Collected Steps per Second: 9841.03059
Overall Steps per Second: 7025.66409

Timestep Collection Time: 5.08168
Timestep Consumption Time: 2.03636
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 7.11805

Cumulative Model Updates: 35268
Cumulative Timesteps: 294448308

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.77163
Policy Entropy: 1.25453
Value Function Loss: 0.02370

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.14488
Value Function Update Magnitude: 0.22593

Collected Steps per Second: 9711.15145
Overall Steps per Second: 6953.90376

Timestep Collection Time: 5.15253
Timestep Consumption Time: 2.04300
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.19553

Cumulative Model Updates: 35274
Cumulative Timesteps: 294498345

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.68934
Policy Entropy: 1.25297
Value Function Loss: 0.02336

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.14315
Value Function Update Magnitude: 0.21254

Collected Steps per Second: 10187.78135
Overall Steps per Second: 7180.43455

Timestep Collection Time: 4.91069
Timestep Consumption Time: 2.05672
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.96741

Cumulative Model Updates: 35280
Cumulative Timesteps: 294548374

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.51458
Policy Entropy: 1.25475
Value Function Loss: 0.02145

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.13964
Value Function Update Magnitude: 0.21057

Collected Steps per Second: 9816.47024
Overall Steps per Second: 6980.53788

Timestep Collection Time: 5.09389
Timestep Consumption Time: 2.06946
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 7.16334

Cumulative Model Updates: 35286
Cumulative Timesteps: 294598378

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.35772
Policy Entropy: 1.26027
Value Function Loss: 0.02098

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.13511
Value Function Update Magnitude: 0.21218

Collected Steps per Second: 9889.46225
Overall Steps per Second: 7060.43750

Timestep Collection Time: 5.05943
Timestep Consumption Time: 2.02725
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.08667

Cumulative Model Updates: 35292
Cumulative Timesteps: 294648413

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.38630
Policy Entropy: 1.26134
Value Function Loss: 0.02145

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.13382
Value Function Update Magnitude: 0.20996

Collected Steps per Second: 10239.51735
Overall Steps per Second: 7162.63574

Timestep Collection Time: 4.88685
Timestep Consumption Time: 2.09926
PPO Batch Consumption Time: 0.02490
Total Iteration Time: 6.98612

Cumulative Model Updates: 35298
Cumulative Timesteps: 294698452

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.18594
Policy Entropy: 1.25700
Value Function Loss: 0.02239

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.13658
Value Function Update Magnitude: 0.21559

Collected Steps per Second: 9729.43559
Overall Steps per Second: 6882.48260

Timestep Collection Time: 5.14182
Timestep Consumption Time: 2.12692
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.26874

Cumulative Model Updates: 35304
Cumulative Timesteps: 294748479

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.32317
Policy Entropy: 1.25496
Value Function Loss: 0.02328

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.13345
Value Function Update Magnitude: 0.21705

Collected Steps per Second: 9781.26104
Overall Steps per Second: 6981.72248

Timestep Collection Time: 5.11396
Timestep Consumption Time: 2.05060
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.16456

Cumulative Model Updates: 35310
Cumulative Timesteps: 294798500

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 294798500...
Checkpoint 294798500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.72016
Policy Entropy: 1.25579
Value Function Loss: 0.02282

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.12984
Value Function Update Magnitude: 0.20644

Collected Steps per Second: 10352.39248
Overall Steps per Second: 7176.72324

Timestep Collection Time: 4.83376
Timestep Consumption Time: 2.13892
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 6.97268

Cumulative Model Updates: 35316
Cumulative Timesteps: 294848541

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.44241
Policy Entropy: 1.25711
Value Function Loss: 0.02110

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.12912
Value Function Update Magnitude: 0.19118

Collected Steps per Second: 9885.24403
Overall Steps per Second: 7083.51423

Timestep Collection Time: 5.05865
Timestep Consumption Time: 2.00084
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.05949

Cumulative Model Updates: 35322
Cumulative Timesteps: 294898547

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.35910
Policy Entropy: 1.26000
Value Function Loss: 0.02091

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.12609
Value Function Update Magnitude: 0.18555

Collected Steps per Second: 9933.31528
Overall Steps per Second: 7104.57292

Timestep Collection Time: 5.03608
Timestep Consumption Time: 2.00516
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.04124

Cumulative Model Updates: 35328
Cumulative Timesteps: 294948572

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.46816
Policy Entropy: 1.25799
Value Function Loss: 0.02083

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.12783
Value Function Update Magnitude: 0.18909

Collected Steps per Second: 10335.17939
Overall Steps per Second: 7225.89295

Timestep Collection Time: 4.83823
Timestep Consumption Time: 2.08188
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 6.92011

Cumulative Model Updates: 35334
Cumulative Timesteps: 294998576

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.98174
Policy Entropy: 1.25597
Value Function Loss: 0.02215

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.13183
Value Function Update Magnitude: 0.18634

Collected Steps per Second: 9860.76298
Overall Steps per Second: 6997.03911

Timestep Collection Time: 5.07435
Timestep Consumption Time: 2.07681
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.15117

Cumulative Model Updates: 35340
Cumulative Timesteps: 295048613

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.06552
Policy Entropy: 1.25776
Value Function Loss: 0.02096

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.12916
Value Function Update Magnitude: 0.19069

Collected Steps per Second: 9750.73001
Overall Steps per Second: 6942.03336

Timestep Collection Time: 5.12946
Timestep Consumption Time: 2.07534
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 7.20481

Cumulative Model Updates: 35346
Cumulative Timesteps: 295098629

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.83489
Policy Entropy: 1.26040
Value Function Loss: 0.02058

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.12767
Value Function Update Magnitude: 0.19699

Collected Steps per Second: 10441.41914
Overall Steps per Second: 7071.44606

Timestep Collection Time: 4.79006
Timestep Consumption Time: 2.28275
PPO Batch Consumption Time: 0.02510
Total Iteration Time: 7.07281

Cumulative Model Updates: 35352
Cumulative Timesteps: 295148644

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.56601
Policy Entropy: 1.26853
Value Function Loss: 0.02069

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.12993
Value Function Update Magnitude: 0.19276

Collected Steps per Second: 10233.28268
Overall Steps per Second: 7088.50339

Timestep Collection Time: 4.88758
Timestep Consumption Time: 2.16835
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.05593

Cumulative Model Updates: 35358
Cumulative Timesteps: 295198660

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.37377
Policy Entropy: 1.26463
Value Function Loss: 0.02182

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.12962
Value Function Update Magnitude: 0.19029

Collected Steps per Second: 9782.50169
Overall Steps per Second: 6998.80173

Timestep Collection Time: 5.11331
Timestep Consumption Time: 2.03377
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.14708

Cumulative Model Updates: 35364
Cumulative Timesteps: 295248681

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.32610
Policy Entropy: 1.26723
Value Function Loss: 0.02223

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.12738
Value Function Update Magnitude: 0.18491

Collected Steps per Second: 9845.29290
Overall Steps per Second: 7102.47562

Timestep Collection Time: 5.07958
Timestep Consumption Time: 1.96162
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 7.04121

Cumulative Model Updates: 35370
Cumulative Timesteps: 295298691

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 295298691...
Checkpoint 295298691 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.30651
Policy Entropy: 1.26822
Value Function Loss: 0.02152

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.12463
Value Function Update Magnitude: 0.18748

Collected Steps per Second: 10193.45444
Overall Steps per Second: 7130.93867

Timestep Collection Time: 4.90835
Timestep Consumption Time: 2.10798
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.01633

Cumulative Model Updates: 35376
Cumulative Timesteps: 295348724

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.07159
Policy Entropy: 1.26923
Value Function Loss: 0.02077

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.12393
Value Function Update Magnitude: 0.18832

Collected Steps per Second: 9713.49517
Overall Steps per Second: 6849.51169

Timestep Collection Time: 5.15118
Timestep Consumption Time: 2.15386
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 7.30505

Cumulative Model Updates: 35382
Cumulative Timesteps: 295398760

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.92563
Policy Entropy: 1.27070
Value Function Loss: 0.02122

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.12552
Value Function Update Magnitude: 0.19058

Collected Steps per Second: 9843.73383
Overall Steps per Second: 6987.34773

Timestep Collection Time: 5.08232
Timestep Consumption Time: 2.07762
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.15994

Cumulative Model Updates: 35388
Cumulative Timesteps: 295448789

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.95481
Policy Entropy: 1.27231
Value Function Loss: 0.02073

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.12577
Value Function Update Magnitude: 0.19681

Collected Steps per Second: 10539.62302
Overall Steps per Second: 7376.37439

Timestep Collection Time: 4.74600
Timestep Consumption Time: 2.03525
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 6.78124

Cumulative Model Updates: 35394
Cumulative Timesteps: 295498810

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.10893
Policy Entropy: 1.27008
Value Function Loss: 0.02028

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.12567
Value Function Update Magnitude: 0.20298

Collected Steps per Second: 10067.87186
Overall Steps per Second: 7150.37332

Timestep Collection Time: 4.96629
Timestep Consumption Time: 2.02635
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 6.99264

Cumulative Model Updates: 35400
Cumulative Timesteps: 295548810

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.21688
Policy Entropy: 1.27406
Value Function Loss: 0.02100

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.12574
Value Function Update Magnitude: 0.20304

Collected Steps per Second: 9839.99010
Overall Steps per Second: 7013.89041

Timestep Collection Time: 5.08171
Timestep Consumption Time: 2.04757
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.12928

Cumulative Model Updates: 35406
Cumulative Timesteps: 295598814

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.33874
Policy Entropy: 1.27433
Value Function Loss: 0.02172

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.19648

Collected Steps per Second: 10316.49952
Overall Steps per Second: 7196.15156

Timestep Collection Time: 4.85058
Timestep Consumption Time: 2.10328
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 6.95386

Cumulative Model Updates: 35412
Cumulative Timesteps: 295648855

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.46616
Policy Entropy: 1.27237
Value Function Loss: 0.02225

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.12292
Value Function Update Magnitude: 0.19252

Collected Steps per Second: 9771.98189
Overall Steps per Second: 6944.94914

Timestep Collection Time: 5.11820
Timestep Consumption Time: 2.08343
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 7.20164

Cumulative Model Updates: 35418
Cumulative Timesteps: 295698870

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.04213
Policy Entropy: 1.26875
Value Function Loss: 0.02071

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.18831

Collected Steps per Second: 9684.13392
Overall Steps per Second: 6934.50340

Timestep Collection Time: 5.16443
Timestep Consumption Time: 2.04777
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.21220

Cumulative Model Updates: 35424
Cumulative Timesteps: 295748883

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.86370
Policy Entropy: 1.26491
Value Function Loss: 0.02017

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.12090
Value Function Update Magnitude: 0.18063

Collected Steps per Second: 10202.88752
Overall Steps per Second: 7171.46444

Timestep Collection Time: 4.90332
Timestep Consumption Time: 2.07266
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.97598

Cumulative Model Updates: 35430
Cumulative Timesteps: 295798911

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 295798911...
Checkpoint 295798911 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.11795
Policy Entropy: 1.28265
Value Function Loss: 0.02020

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.11923
Value Function Update Magnitude: 0.17916

Collected Steps per Second: 9649.12810
Overall Steps per Second: 6842.08837

Timestep Collection Time: 5.18451
Timestep Consumption Time: 2.12700
PPO Batch Consumption Time: 0.02949
Total Iteration Time: 7.31151

Cumulative Model Updates: 35436
Cumulative Timesteps: 295848937

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.71243
Policy Entropy: 1.27153
Value Function Loss: 0.02060

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.12065
Value Function Update Magnitude: 0.18038

Collected Steps per Second: 9828.18333
Overall Steps per Second: 6979.87343

Timestep Collection Time: 5.08833
Timestep Consumption Time: 2.07642
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.16474

Cumulative Model Updates: 35442
Cumulative Timesteps: 295898946

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.22740
Policy Entropy: 1.27704
Value Function Loss: 0.02092

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.12286
Value Function Update Magnitude: 0.18113

Collected Steps per Second: 10277.07703
Overall Steps per Second: 7176.97393

Timestep Collection Time: 4.86559
Timestep Consumption Time: 2.10170
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 6.96728

Cumulative Model Updates: 35448
Cumulative Timesteps: 295948950

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.24435
Policy Entropy: 1.27138
Value Function Loss: 0.02081

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.12009
Value Function Update Magnitude: 0.18283

Collected Steps per Second: 9769.83013
Overall Steps per Second: 673.87069

Timestep Collection Time: 5.12169
Timestep Consumption Time: 69.13292
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 74.25460

Cumulative Model Updates: 35454
Cumulative Timesteps: 295998988

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.68944
Policy Entropy: 1.27928
Value Function Loss: 0.02126

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.12105
Value Function Update Magnitude: 0.18970

Collected Steps per Second: 9299.71940
Overall Steps per Second: 6639.75011

Timestep Collection Time: 5.37919
Timestep Consumption Time: 2.15497
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.53417

Cumulative Model Updates: 35460
Cumulative Timesteps: 296049013

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.19689
Policy Entropy: 1.27891
Value Function Loss: 0.02156

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.12131
Value Function Update Magnitude: 0.19732

Collected Steps per Second: 9428.04940
Overall Steps per Second: 6706.11683

Timestep Collection Time: 5.30661
Timestep Consumption Time: 2.15389
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 7.46050

Cumulative Model Updates: 35466
Cumulative Timesteps: 296099044

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.14529
Policy Entropy: 1.27077
Value Function Loss: 0.02223

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.06793
Policy Update Magnitude: 0.12533
Value Function Update Magnitude: 0.20234

Collected Steps per Second: 9266.00159
Overall Steps per Second: 6583.14613

Timestep Collection Time: 5.39952
Timestep Consumption Time: 2.20049
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.60001

Cumulative Model Updates: 35472
Cumulative Timesteps: 296149076

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.60289
Policy Entropy: 1.26941
Value Function Loss: 0.02317

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.12764
Value Function Update Magnitude: 0.21270

Collected Steps per Second: 9394.23285
Overall Steps per Second: 6690.14791

Timestep Collection Time: 5.32422
Timestep Consumption Time: 2.15199
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.47622

Cumulative Model Updates: 35478
Cumulative Timesteps: 296199093

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.29225
Policy Entropy: 1.27158
Value Function Loss: 0.02398

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.12844
Value Function Update Magnitude: 0.22373

Collected Steps per Second: 9756.25963
Overall Steps per Second: 6802.20505

Timestep Collection Time: 5.12789
Timestep Consumption Time: 2.22693
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.35482

Cumulative Model Updates: 35484
Cumulative Timesteps: 296249122

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.80202
Policy Entropy: 1.27351
Value Function Loss: 0.02418

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.12708
Value Function Update Magnitude: 0.22399

Collected Steps per Second: 9675.68388
Overall Steps per Second: 6990.28171

Timestep Collection Time: 5.16945
Timestep Consumption Time: 1.98591
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.15536

Cumulative Model Updates: 35490
Cumulative Timesteps: 296299140

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 296299140...
Checkpoint 296299140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.65637
Policy Entropy: 1.27225
Value Function Loss: 0.02345

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.12630
Value Function Update Magnitude: 0.21683

Collected Steps per Second: 9830.09516
Overall Steps per Second: 7015.17797

Timestep Collection Time: 5.08683
Timestep Consumption Time: 2.04115
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.12797

Cumulative Model Updates: 35496
Cumulative Timesteps: 296349144

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.20283
Policy Entropy: 1.27333
Value Function Loss: 0.02121

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.12561
Value Function Update Magnitude: 0.21135

Collected Steps per Second: 10302.73224
Overall Steps per Second: 7197.43563

Timestep Collection Time: 4.85444
Timestep Consumption Time: 2.09442
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 6.94886

Cumulative Model Updates: 35502
Cumulative Timesteps: 296399158

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.88885
Policy Entropy: 1.26959
Value Function Loss: 0.02004

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.11967
Value Function Update Magnitude: 0.20606

Collected Steps per Second: 9882.59562
Overall Steps per Second: 6984.25785

Timestep Collection Time: 5.06233
Timestep Consumption Time: 2.10077
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 7.16311

Cumulative Model Updates: 35508
Cumulative Timesteps: 296449187

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.07030
Policy Entropy: 1.26990
Value Function Loss: 0.01973

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.11767
Value Function Update Magnitude: 0.20776

Collected Steps per Second: 9701.05843
Overall Steps per Second: 6950.69206

Timestep Collection Time: 5.15841
Timestep Consumption Time: 2.04116
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.19957

Cumulative Model Updates: 35514
Cumulative Timesteps: 296499229

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.16307
Policy Entropy: 1.26161
Value Function Loss: 0.02080

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.11878
Value Function Update Magnitude: 0.21057

Collected Steps per Second: 10316.19657
Overall Steps per Second: 7150.75566

Timestep Collection Time: 4.84714
Timestep Consumption Time: 2.14569
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 6.99283

Cumulative Model Updates: 35520
Cumulative Timesteps: 296549233

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.81393
Policy Entropy: 1.25632
Value Function Loss: 0.02125

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.12053
Value Function Update Magnitude: 0.21388

Collected Steps per Second: 9836.09276
Overall Steps per Second: 6985.67774

Timestep Collection Time: 5.08342
Timestep Consumption Time: 2.07422
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.15764

Cumulative Model Updates: 35526
Cumulative Timesteps: 296599234

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.30249
Policy Entropy: 1.25000
Value Function Loss: 0.02194

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.12166
Value Function Update Magnitude: 0.23627

Collected Steps per Second: 9708.96453
Overall Steps per Second: 6909.78041

Timestep Collection Time: 5.15184
Timestep Consumption Time: 2.08703
PPO Batch Consumption Time: 0.03092
Total Iteration Time: 7.23887

Cumulative Model Updates: 35532
Cumulative Timesteps: 296649253

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.37144
Policy Entropy: 1.25367
Value Function Loss: 0.02254

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.12338
Value Function Update Magnitude: 0.23111

Collected Steps per Second: 10465.57002
Overall Steps per Second: 7341.19877

Timestep Collection Time: 4.78034
Timestep Consumption Time: 2.03449
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 6.81483

Cumulative Model Updates: 35538
Cumulative Timesteps: 296699282

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.36361
Policy Entropy: 1.26226
Value Function Loss: 0.02307

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.12375
Value Function Update Magnitude: 0.23235

Collected Steps per Second: 9784.96101
Overall Steps per Second: 7070.42153

Timestep Collection Time: 5.11050
Timestep Consumption Time: 1.96207
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.07256

Cumulative Model Updates: 35544
Cumulative Timesteps: 296749288

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.07333
Policy Entropy: 1.26434
Value Function Loss: 0.02274

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.12576
Value Function Update Magnitude: 0.22816

Collected Steps per Second: 9752.46206
Overall Steps per Second: 7035.81445

Timestep Collection Time: 5.13029
Timestep Consumption Time: 1.98089
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.11119

Cumulative Model Updates: 35550
Cumulative Timesteps: 296799321

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 296799321...
Checkpoint 296799321 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.98446
Policy Entropy: 1.26128
Value Function Loss: 0.02161

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.12165
Value Function Update Magnitude: 0.21678

Collected Steps per Second: 10434.95547
Overall Steps per Second: 7263.66861

Timestep Collection Time: 4.79437
Timestep Consumption Time: 2.09320
PPO Batch Consumption Time: 0.02407
Total Iteration Time: 6.88757

Cumulative Model Updates: 35556
Cumulative Timesteps: 296849350

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.57839
Policy Entropy: 1.25845
Value Function Loss: 0.02062

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.12230
Value Function Update Magnitude: 0.20858

Collected Steps per Second: 9969.33033
Overall Steps per Second: 7063.46378

Timestep Collection Time: 5.01548
Timestep Consumption Time: 2.06334
PPO Batch Consumption Time: 0.02448
Total Iteration Time: 7.07882

Cumulative Model Updates: 35562
Cumulative Timesteps: 296899351

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.28745
Policy Entropy: 1.25290
Value Function Loss: 0.02135

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.12394
Value Function Update Magnitude: 0.20372

Collected Steps per Second: 9739.40428
Overall Steps per Second: 6971.40204

Timestep Collection Time: 5.13543
Timestep Consumption Time: 2.03903
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.17445

Cumulative Model Updates: 35568
Cumulative Timesteps: 296949367

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.11190
Policy Entropy: 1.25516
Value Function Loss: 0.02223

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.12232
Value Function Update Magnitude: 0.20834

Collected Steps per Second: 9734.25939
Overall Steps per Second: 7009.03219

Timestep Collection Time: 5.13896
Timestep Consumption Time: 1.99811
PPO Batch Consumption Time: 0.02435
Total Iteration Time: 7.13708

Cumulative Model Updates: 35574
Cumulative Timesteps: 296999391

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.88614
Policy Entropy: 1.25391
Value Function Loss: 0.02328

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.12965
Value Function Update Magnitude: 0.21282

Collected Steps per Second: 10288.49627
Overall Steps per Second: 7196.68663

Timestep Collection Time: 4.86193
Timestep Consumption Time: 2.08876
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 6.95070

Cumulative Model Updates: 35580
Cumulative Timesteps: 297049413

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.13544
Policy Entropy: 1.25597
Value Function Loss: 0.02217

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.12903
Value Function Update Magnitude: 0.21643

Collected Steps per Second: 9791.08582
Overall Steps per Second: 6986.57356

Timestep Collection Time: 5.10750
Timestep Consumption Time: 2.05023
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.15773

Cumulative Model Updates: 35586
Cumulative Timesteps: 297099421

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.18668
Policy Entropy: 1.25711
Value Function Loss: 0.02267

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.12631
Value Function Update Magnitude: 0.21243

Collected Steps per Second: 9649.56831
Overall Steps per Second: 6904.47921

Timestep Collection Time: 5.18562
Timestep Consumption Time: 2.06170
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.24732

Cumulative Model Updates: 35592
Cumulative Timesteps: 297149460

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.65510
Policy Entropy: 1.25480
Value Function Loss: 0.02308

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.12579
Value Function Update Magnitude: 0.20882

Collected Steps per Second: 10368.52356
Overall Steps per Second: 7240.84561

Timestep Collection Time: 4.82451
Timestep Consumption Time: 2.08394
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 6.90845

Cumulative Model Updates: 35598
Cumulative Timesteps: 297199483

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.96133
Policy Entropy: 1.25510
Value Function Loss: 0.02370

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.12590
Value Function Update Magnitude: 0.21379

Collected Steps per Second: 9909.88876
Overall Steps per Second: 7029.55279

Timestep Collection Time: 5.04698
Timestep Consumption Time: 2.06798
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.11496

Cumulative Model Updates: 35604
Cumulative Timesteps: 297249498

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.12069
Policy Entropy: 1.25424
Value Function Loss: 0.02329

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.12461
Value Function Update Magnitude: 0.21562

Collected Steps per Second: 9679.08323
Overall Steps per Second: 6936.10269

Timestep Collection Time: 5.16630
Timestep Consumption Time: 2.04308
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.20938

Cumulative Model Updates: 35610
Cumulative Timesteps: 297299503

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 297299503...
Checkpoint 297299503 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.20106
Policy Entropy: 1.25962
Value Function Loss: 0.02307

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.12510
Value Function Update Magnitude: 0.21564

Collected Steps per Second: 10256.79871
Overall Steps per Second: 7167.48698

Timestep Collection Time: 4.87891
Timestep Consumption Time: 2.10290
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 6.98181

Cumulative Model Updates: 35616
Cumulative Timesteps: 297349545

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.62423
Policy Entropy: 1.25389
Value Function Loss: 0.02394

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.12690
Value Function Update Magnitude: 0.20591

Collected Steps per Second: 9735.88369
Overall Steps per Second: 6988.50992

Timestep Collection Time: 5.13934
Timestep Consumption Time: 2.02041
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 7.15975

Cumulative Model Updates: 35622
Cumulative Timesteps: 297399581

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.17879
Policy Entropy: 1.24709
Value Function Loss: 0.02401

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.12717
Value Function Update Magnitude: 0.20839

Collected Steps per Second: 9614.16331
Overall Steps per Second: 6907.73175

Timestep Collection Time: 5.20326
Timestep Consumption Time: 2.03862
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.24189

Cumulative Model Updates: 35628
Cumulative Timesteps: 297449606

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.21499
Policy Entropy: 1.24859
Value Function Loss: 0.02245

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.12651
Value Function Update Magnitude: 0.21537

Collected Steps per Second: 10294.98852
Overall Steps per Second: 7132.71814

Timestep Collection Time: 4.85741
Timestep Consumption Time: 2.15352
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 7.01093

Cumulative Model Updates: 35634
Cumulative Timesteps: 297499613

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.36722
Policy Entropy: 1.25028
Value Function Loss: 0.02187

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.12694
Value Function Update Magnitude: 0.21946

Collected Steps per Second: 9842.60651
Overall Steps per Second: 6946.55489

Timestep Collection Time: 5.08432
Timestep Consumption Time: 2.11968
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.20400

Cumulative Model Updates: 35640
Cumulative Timesteps: 297549656

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.69285
Policy Entropy: 1.24802
Value Function Loss: 0.02232

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.12649
Value Function Update Magnitude: 0.21125

Collected Steps per Second: 9699.90919
Overall Steps per Second: 6952.58460

Timestep Collection Time: 5.15520
Timestep Consumption Time: 2.03709
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.19229

Cumulative Model Updates: 35646
Cumulative Timesteps: 297599661

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.48145
Policy Entropy: 1.24090
Value Function Loss: 0.02364

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.13254
Value Function Update Magnitude: 0.21926

Collected Steps per Second: 10341.48378
Overall Steps per Second: 7235.31284

Timestep Collection Time: 4.83886
Timestep Consumption Time: 2.07736
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.91622

Cumulative Model Updates: 35652
Cumulative Timesteps: 297649702

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.63302
Policy Entropy: 1.24258
Value Function Loss: 0.02266

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.13253
Value Function Update Magnitude: 0.23009

Collected Steps per Second: 9645.16586
Overall Steps per Second: 6971.33752

Timestep Collection Time: 5.18674
Timestep Consumption Time: 1.98935
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 7.17610

Cumulative Model Updates: 35658
Cumulative Timesteps: 297699729

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.43335
Policy Entropy: 1.24753
Value Function Loss: 0.02235

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.12805
Value Function Update Magnitude: 0.23036

Collected Steps per Second: 9496.34111
Overall Steps per Second: 6854.64967

Timestep Collection Time: 5.26561
Timestep Consumption Time: 2.02930
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.29490

Cumulative Model Updates: 35664
Cumulative Timesteps: 297749733

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.34139
Policy Entropy: 1.25097
Value Function Loss: 0.02236

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.12823
Value Function Update Magnitude: 0.23496

Collected Steps per Second: 10315.34251
Overall Steps per Second: 7222.32182

Timestep Collection Time: 4.85122
Timestep Consumption Time: 2.07758
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.92880

Cumulative Model Updates: 35670
Cumulative Timesteps: 297799775

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 297799775...
Checkpoint 297799775 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.63688
Policy Entropy: 1.25430
Value Function Loss: 0.02431

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.12966
Value Function Update Magnitude: 0.23728

Collected Steps per Second: 9795.56824
Overall Steps per Second: 6903.84297

Timestep Collection Time: 5.10915
Timestep Consumption Time: 2.14000
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.24915

Cumulative Model Updates: 35676
Cumulative Timesteps: 297849822

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.02579
Policy Entropy: 1.24894
Value Function Loss: 0.02306

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.12722
Value Function Update Magnitude: 0.21940

Collected Steps per Second: 9722.33505
Overall Steps per Second: 7036.20983

Timestep Collection Time: 5.14537
Timestep Consumption Time: 1.96428
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.10965

Cumulative Model Updates: 35682
Cumulative Timesteps: 297899847

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.42210
Policy Entropy: 1.25084
Value Function Loss: 0.02225

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.12472
Value Function Update Magnitude: 0.21732

Collected Steps per Second: 10388.10123
Overall Steps per Second: 7247.66884

Timestep Collection Time: 4.81772
Timestep Consumption Time: 2.08753
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 6.90525

Cumulative Model Updates: 35688
Cumulative Timesteps: 297949894

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.56060
Policy Entropy: 1.24978
Value Function Loss: 0.02143

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.12263
Value Function Update Magnitude: 0.20647

Collected Steps per Second: 9781.50169
Overall Steps per Second: 6861.84011

Timestep Collection Time: 5.11486
Timestep Consumption Time: 2.17633
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 7.29119

Cumulative Model Updates: 35694
Cumulative Timesteps: 297999925

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.40897
Policy Entropy: 1.25397
Value Function Loss: 0.02348

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.12279
Value Function Update Magnitude: 0.20539

Collected Steps per Second: 9808.40450
Overall Steps per Second: 7027.76351

Timestep Collection Time: 5.09920
Timestep Consumption Time: 2.01757
PPO Batch Consumption Time: 0.02445
Total Iteration Time: 7.11677

Cumulative Model Updates: 35700
Cumulative Timesteps: 298049940

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.38489
Policy Entropy: 1.25451
Value Function Loss: 0.02406

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.12475
Value Function Update Magnitude: 0.21244

Collected Steps per Second: 10289.52395
Overall Steps per Second: 6928.30160

Timestep Collection Time: 4.86291
Timestep Consumption Time: 2.35921
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 7.22212

Cumulative Model Updates: 35706
Cumulative Timesteps: 298099977

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.05825
Policy Entropy: 1.25621
Value Function Loss: 0.02360

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.12585
Value Function Update Magnitude: 0.21196

Collected Steps per Second: 10353.80526
Overall Steps per Second: 7207.89576

Timestep Collection Time: 4.83214
Timestep Consumption Time: 2.10900
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 6.94114

Cumulative Model Updates: 35712
Cumulative Timesteps: 298150008

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.63295
Policy Entropy: 1.26138
Value Function Loss: 0.02283

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.12621
Value Function Update Magnitude: 0.21521

Collected Steps per Second: 9706.25740
Overall Steps per Second: 6953.04263

Timestep Collection Time: 5.15183
Timestep Consumption Time: 2.03998
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 7.19182

Cumulative Model Updates: 35718
Cumulative Timesteps: 298200013

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.86314
Policy Entropy: 1.26199
Value Function Loss: 0.02218

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.12517
Value Function Update Magnitude: 0.21355

Collected Steps per Second: 9779.31335
Overall Steps per Second: 6948.17717

Timestep Collection Time: 5.11559
Timestep Consumption Time: 2.08442
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.20002

Cumulative Model Updates: 35724
Cumulative Timesteps: 298250040

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.14875
Policy Entropy: 1.26912
Value Function Loss: 0.02206

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.12471
Value Function Update Magnitude: 0.21499

Collected Steps per Second: 10373.89215
Overall Steps per Second: 7218.19015

Timestep Collection Time: 4.82278
Timestep Consumption Time: 2.10846
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 6.93124

Cumulative Model Updates: 35730
Cumulative Timesteps: 298300071

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 298300071...
Checkpoint 298300071 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.58943
Policy Entropy: 1.27531
Value Function Loss: 0.02243

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.12362
Value Function Update Magnitude: 0.20405

Collected Steps per Second: 9886.71006
Overall Steps per Second: 7048.32769

Timestep Collection Time: 5.05901
Timestep Consumption Time: 2.03728
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.09629

Cumulative Model Updates: 35736
Cumulative Timesteps: 298350088

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.75148
Policy Entropy: 1.27776
Value Function Loss: 0.02359

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.12212
Value Function Update Magnitude: 0.20234

Collected Steps per Second: 10011.33947
Overall Steps per Second: 7134.22506

Timestep Collection Time: 4.99544
Timestep Consumption Time: 2.01458
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 7.01001

Cumulative Model Updates: 35742
Cumulative Timesteps: 298400099

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.21047
Policy Entropy: 1.28157
Value Function Loss: 0.02432

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.12539
Value Function Update Magnitude: 0.21896

Collected Steps per Second: 10282.91023
Overall Steps per Second: 7194.54584

Timestep Collection Time: 4.86283
Timestep Consumption Time: 2.08744
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 6.95026

Cumulative Model Updates: 35748
Cumulative Timesteps: 298450103

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.67011
Policy Entropy: 1.27856
Value Function Loss: 0.02484

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.12667
Value Function Update Magnitude: 0.23387

Collected Steps per Second: 10037.64360
Overall Steps per Second: 7045.20722

Timestep Collection Time: 4.98155
Timestep Consumption Time: 2.11590
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 7.09745

Cumulative Model Updates: 35754
Cumulative Timesteps: 298500106

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.54756
Policy Entropy: 1.28751
Value Function Loss: 0.02383

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.12834
Value Function Update Magnitude: 0.24034

Collected Steps per Second: 9661.02963
Overall Steps per Second: 6919.20756

Timestep Collection Time: 5.17792
Timestep Consumption Time: 2.05181
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.22973

Cumulative Model Updates: 35760
Cumulative Timesteps: 298550130

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.53008
Policy Entropy: 1.29359
Value Function Loss: 0.02235

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.12169
Value Function Update Magnitude: 0.23293

Collected Steps per Second: 10216.24871
Overall Steps per Second: 7160.88226

Timestep Collection Time: 4.89739
Timestep Consumption Time: 2.08959
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 6.98699

Cumulative Model Updates: 35766
Cumulative Timesteps: 298600163

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.82271
Policy Entropy: 1.28943
Value Function Loss: 0.02110

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.11806
Value Function Update Magnitude: 0.22261

Collected Steps per Second: 9771.01769
Overall Steps per Second: 7038.11010

Timestep Collection Time: 5.11973
Timestep Consumption Time: 1.98800
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.10773

Cumulative Model Updates: 35772
Cumulative Timesteps: 298650188

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.39138
Policy Entropy: 1.29086
Value Function Loss: 0.02116

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.11873
Value Function Update Magnitude: 0.22202

Collected Steps per Second: 9689.47312
Overall Steps per Second: 6938.28814

Timestep Collection Time: 5.16354
Timestep Consumption Time: 2.04746
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.21100

Cumulative Model Updates: 35778
Cumulative Timesteps: 298700220

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.01656
Policy Entropy: 1.29089
Value Function Loss: 0.02269

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.11996
Value Function Update Magnitude: 0.20876

Collected Steps per Second: 10382.12696
Overall Steps per Second: 7224.00143

Timestep Collection Time: 4.81838
Timestep Consumption Time: 2.10646
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 6.92483

Cumulative Model Updates: 35784
Cumulative Timesteps: 298750245

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.67841
Policy Entropy: 1.29219
Value Function Loss: 0.02284

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.11958
Value Function Update Magnitude: 0.21207

Collected Steps per Second: 9895.27526
Overall Steps per Second: 7002.31608

Timestep Collection Time: 5.05463
Timestep Consumption Time: 2.08829
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.14292

Cumulative Model Updates: 35790
Cumulative Timesteps: 298800262

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 298800262...
Checkpoint 298800262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.18335
Policy Entropy: 1.29008
Value Function Loss: 0.02288

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.11999
Value Function Update Magnitude: 0.21222

Collected Steps per Second: 9721.57619
Overall Steps per Second: 6971.28528

Timestep Collection Time: 5.14618
Timestep Consumption Time: 2.03026
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.17644

Cumulative Model Updates: 35796
Cumulative Timesteps: 298850291

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.22818
Policy Entropy: 1.29102
Value Function Loss: 0.02230

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.06433
Policy Update Magnitude: 0.11674
Value Function Update Magnitude: 0.20845

Collected Steps per Second: 10478.65098
Overall Steps per Second: 7282.66042

Timestep Collection Time: 4.77514
Timestep Consumption Time: 2.09557
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.87070

Cumulative Model Updates: 35802
Cumulative Timesteps: 298900328

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.60597
Policy Entropy: 1.29552
Value Function Loss: 0.02121

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.05839
Policy Update Magnitude: 0.11967
Value Function Update Magnitude: 0.20988

Collected Steps per Second: 9907.51858
Overall Steps per Second: 7022.59640

Timestep Collection Time: 5.04859
Timestep Consumption Time: 2.07399
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 7.12258

Cumulative Model Updates: 35808
Cumulative Timesteps: 298950347

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.77504
Policy Entropy: 1.29042
Value Function Loss: 0.02156

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.06528
Policy Update Magnitude: 0.11935
Value Function Update Magnitude: 0.21239

Collected Steps per Second: 9734.78996
Overall Steps per Second: 6976.44181

Timestep Collection Time: 5.13694
Timestep Consumption Time: 2.03104
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.16798

Cumulative Model Updates: 35814
Cumulative Timesteps: 299000354

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.87708
Policy Entropy: 1.28925
Value Function Loss: 0.02067

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.11655
Value Function Update Magnitude: 0.20713

Collected Steps per Second: 10491.60166
Overall Steps per Second: 7324.14884

Timestep Collection Time: 4.76591
Timestep Consumption Time: 2.06110
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 6.82700

Cumulative Model Updates: 35820
Cumulative Timesteps: 299050356

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.30231
Policy Entropy: 1.28809
Value Function Loss: 0.02152

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.11808
Value Function Update Magnitude: 0.21433

Collected Steps per Second: 9813.85037
Overall Steps per Second: 6985.24405

Timestep Collection Time: 5.09606
Timestep Consumption Time: 2.06360
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 7.15966

Cumulative Model Updates: 35826
Cumulative Timesteps: 299100368

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.38537
Policy Entropy: 1.29250
Value Function Loss: 0.02129

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.11895
Value Function Update Magnitude: 0.22177

Collected Steps per Second: 9856.68222
Overall Steps per Second: 7043.67102

Timestep Collection Time: 5.07544
Timestep Consumption Time: 2.02696
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.10240

Cumulative Model Updates: 35832
Cumulative Timesteps: 299150395

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.20788
Policy Entropy: 1.29615
Value Function Loss: 0.02251

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.11824
Value Function Update Magnitude: 0.21797

Collected Steps per Second: 10361.05094
Overall Steps per Second: 7007.99343

Timestep Collection Time: 4.82837
Timestep Consumption Time: 2.31019
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.13856

Cumulative Model Updates: 35838
Cumulative Timesteps: 299200422

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.87788
Policy Entropy: 1.29902
Value Function Loss: 0.02354

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.12119
Value Function Update Magnitude: 0.21791

Collected Steps per Second: 10538.25484
Overall Steps per Second: 7248.83492

Timestep Collection Time: 4.74851
Timestep Consumption Time: 2.15481
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 6.90332

Cumulative Model Updates: 35844
Cumulative Timesteps: 299250463

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.21906
Policy Entropy: 1.29761
Value Function Loss: 0.02245

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.12250
Value Function Update Magnitude: 0.22330

Collected Steps per Second: 10220.18872
Overall Steps per Second: 7368.69605

Timestep Collection Time: 4.89286
Timestep Consumption Time: 1.89341
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 6.78628

Cumulative Model Updates: 35850
Cumulative Timesteps: 299300469

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 299300469...
Checkpoint 299300469 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.85820
Policy Entropy: 1.29833
Value Function Loss: 0.02262

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.12191
Value Function Update Magnitude: 0.21937

Collected Steps per Second: 10648.08433
Overall Steps per Second: 7150.57385

Timestep Collection Time: 4.69728
Timestep Consumption Time: 2.29755
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.99482

Cumulative Model Updates: 35856
Cumulative Timesteps: 299350486

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.34617
Policy Entropy: 1.30641
Value Function Loss: 0.02158

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.11759
Value Function Update Magnitude: 0.21644

Collected Steps per Second: 10458.00012
Overall Steps per Second: 7289.64512

Timestep Collection Time: 4.78285
Timestep Consumption Time: 2.07881
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 6.86165

Cumulative Model Updates: 35862
Cumulative Timesteps: 299400505

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.81512
Policy Entropy: 1.30809
Value Function Loss: 0.02247

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.06805
Policy Update Magnitude: 0.11994
Value Function Update Magnitude: 0.20743

Collected Steps per Second: 9776.39447
Overall Steps per Second: 6999.15789

Timestep Collection Time: 5.11743
Timestep Consumption Time: 2.03057
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.14800

Cumulative Model Updates: 35868
Cumulative Timesteps: 299450535

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.08973
Policy Entropy: 1.30681
Value Function Loss: 0.02285

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.05992
Policy Update Magnitude: 0.11756
Value Function Update Magnitude: 0.21774

Collected Steps per Second: 9735.18068
Overall Steps per Second: 7211.30590

Timestep Collection Time: 5.13601
Timestep Consumption Time: 1.79755
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 6.93356

Cumulative Model Updates: 35874
Cumulative Timesteps: 299500535

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.80109
Policy Entropy: 1.30825
Value Function Loss: 0.02280

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.06476
Policy Update Magnitude: 0.11904
Value Function Update Magnitude: 0.21907

Collected Steps per Second: 9914.64520
Overall Steps per Second: 6999.84554

Timestep Collection Time: 5.04345
Timestep Consumption Time: 2.10014
PPO Batch Consumption Time: 0.02531
Total Iteration Time: 7.14359

Cumulative Model Updates: 35880
Cumulative Timesteps: 299550539

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.13057
Policy Entropy: 1.30769
Value Function Loss: 0.02192

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.06309
Policy Update Magnitude: 0.11767
Value Function Update Magnitude: 0.21159

Collected Steps per Second: 9680.29633
Overall Steps per Second: 6983.64013

Timestep Collection Time: 5.16678
Timestep Consumption Time: 1.99510
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 7.16188

Cumulative Model Updates: 35886
Cumulative Timesteps: 299600555

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.70577
Policy Entropy: 1.31120
Value Function Loss: 0.02243

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.11517
Value Function Update Magnitude: 0.21033

Collected Steps per Second: 10581.01360
Overall Steps per Second: 7397.02651

Timestep Collection Time: 4.72705
Timestep Consumption Time: 2.03472
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 6.76177

Cumulative Model Updates: 35892
Cumulative Timesteps: 299650572

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.74518
Policy Entropy: 1.31214
Value Function Loss: 0.02185

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.06434
Policy Update Magnitude: 0.11610
Value Function Update Magnitude: 0.21449

Collected Steps per Second: 10162.56704
Overall Steps per Second: 7146.75509

Timestep Collection Time: 4.92415
Timestep Consumption Time: 2.07791
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.00206

Cumulative Model Updates: 35898
Cumulative Timesteps: 299700614

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.16457
Policy Entropy: 1.32047
Value Function Loss: 0.02225

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.06041
Policy Update Magnitude: 0.11604
Value Function Update Magnitude: 0.22007

Collected Steps per Second: 9824.05893
Overall Steps per Second: 7007.91946

Timestep Collection Time: 5.09046
Timestep Consumption Time: 2.04561
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.13607

Cumulative Model Updates: 35904
Cumulative Timesteps: 299750623

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.39532
Policy Entropy: 1.31745
Value Function Loss: 0.02121

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.05581
Policy Update Magnitude: 0.11420
Value Function Update Magnitude: 0.21722

Collected Steps per Second: 10544.27959
Overall Steps per Second: 7317.58859

Timestep Collection Time: 4.74229
Timestep Consumption Time: 2.09111
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 6.83340

Cumulative Model Updates: 35910
Cumulative Timesteps: 299800627

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 299800627...
Checkpoint 299800627 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.44254
Policy Entropy: 1.31359
Value Function Loss: 0.02138

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06066
Policy Update Magnitude: 0.11301
Value Function Update Magnitude: 0.21120

Collected Steps per Second: 9694.80382
Overall Steps per Second: 6915.92229

Timestep Collection Time: 5.16122
Timestep Consumption Time: 2.07383
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.23504

Cumulative Model Updates: 35916
Cumulative Timesteps: 299850664

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.01467
Policy Entropy: 1.30775
Value Function Loss: 0.02127

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.11437
Value Function Update Magnitude: 0.21898

Collected Steps per Second: 9662.77461
Overall Steps per Second: 6950.58129

Timestep Collection Time: 5.17833
Timestep Consumption Time: 2.02064
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.19897

Cumulative Model Updates: 35922
Cumulative Timesteps: 299900701

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.36528
Policy Entropy: 1.31231
Value Function Loss: 0.02082

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.11565
Value Function Update Magnitude: 0.23182

Collected Steps per Second: 10266.79802
Overall Steps per Second: 7115.56120

Timestep Collection Time: 4.87299
Timestep Consumption Time: 2.15808
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.03107

Cumulative Model Updates: 35928
Cumulative Timesteps: 299950731

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.78056
Policy Entropy: 1.31920
Value Function Loss: 0.02114

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.07164
Policy Update Magnitude: 0.11620
Value Function Update Magnitude: 0.22309

Collected Steps per Second: 9756.46757
Overall Steps per Second: 6976.07981

Timestep Collection Time: 5.12891
Timestep Consumption Time: 2.04418
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 7.17308

Cumulative Model Updates: 35934
Cumulative Timesteps: 300000771

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.84040
Policy Entropy: 1.31023
Value Function Loss: 0.02175

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.11600
Value Function Update Magnitude: 0.21524

Collected Steps per Second: 9706.61214
Overall Steps per Second: 6929.53255

Timestep Collection Time: 5.15587
Timestep Consumption Time: 2.06627
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.22213

Cumulative Model Updates: 35940
Cumulative Timesteps: 300050817

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.93113
Policy Entropy: 1.31046
Value Function Loss: 0.02209

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.12060
Value Function Update Magnitude: 0.21785

Collected Steps per Second: 10640.39081
Overall Steps per Second: 7313.05052

Timestep Collection Time: 4.69983
Timestep Consumption Time: 2.13836
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 6.83819

Cumulative Model Updates: 35946
Cumulative Timesteps: 300100825

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.54894
Policy Entropy: 1.30982
Value Function Loss: 0.02217

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.11951
Value Function Update Magnitude: 0.22611

Collected Steps per Second: 10392.18550
Overall Steps per Second: 7282.02223

Timestep Collection Time: 4.81169
Timestep Consumption Time: 2.05508
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 6.86677

Cumulative Model Updates: 35952
Cumulative Timesteps: 300150829

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.99441
Policy Entropy: 1.31302
Value Function Loss: 0.02173

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.12132
Value Function Update Magnitude: 0.22568

Collected Steps per Second: 10057.35198
Overall Steps per Second: 7181.98327

Timestep Collection Time: 4.97537
Timestep Consumption Time: 1.99193
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 6.96730

Cumulative Model Updates: 35958
Cumulative Timesteps: 300200868

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.96709
Policy Entropy: 1.31182
Value Function Loss: 0.02189

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.11975
Value Function Update Magnitude: 0.22128

Collected Steps per Second: 10393.15604
Overall Steps per Second: 7223.24995

Timestep Collection Time: 4.81394
Timestep Consumption Time: 2.11258
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 6.92652

Cumulative Model Updates: 35964
Cumulative Timesteps: 300250900

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.09586
Policy Entropy: 1.30741
Value Function Loss: 0.02319

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.11867
Value Function Update Magnitude: 0.22889

Collected Steps per Second: 9790.41533
Overall Steps per Second: 7036.16418

Timestep Collection Time: 5.10755
Timestep Consumption Time: 1.99931
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 7.10686

Cumulative Model Updates: 35970
Cumulative Timesteps: 300300905

Timesteps Collected: 50005
--------END ITERATION REPORT--------


Saving checkpoint 300300905...
Checkpoint 300300905 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.97555
Policy Entropy: 1.31391
Value Function Loss: 0.02349

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.11756
Value Function Update Magnitude: 0.22378

Collected Steps per Second: 9703.76282
Overall Steps per Second: 6972.81784

Timestep Collection Time: 5.15697
Timestep Consumption Time: 2.01976
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 7.17673

Cumulative Model Updates: 35976
Cumulative Timesteps: 300350947

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.83874
Policy Entropy: 1.31612
Value Function Loss: 0.02340

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.07354
Policy Update Magnitude: 0.11800
Value Function Update Magnitude: 0.22011

Collected Steps per Second: 10373.43723
Overall Steps per Second: 7240.15370

Timestep Collection Time: 4.82174
Timestep Consumption Time: 2.08668
PPO Batch Consumption Time: 0.02457
Total Iteration Time: 6.90842

Cumulative Model Updates: 35982
Cumulative Timesteps: 300400965

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.62286
Policy Entropy: 1.31263
Value Function Loss: 0.02264

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.11824
Value Function Update Magnitude: 0.22221

Collected Steps per Second: 9982.88162
Overall Steps per Second: 7112.28730

Timestep Collection Time: 5.00968
Timestep Consumption Time: 2.02196
PPO Batch Consumption Time: 0.02375
Total Iteration Time: 7.03163

Cumulative Model Updates: 35988
Cumulative Timesteps: 300450976

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.85596
Policy Entropy: 1.30694
Value Function Loss: 0.02151

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.11901
Value Function Update Magnitude: 0.22140

Collected Steps per Second: 9862.02042
Overall Steps per Second: 7071.22589

Timestep Collection Time: 5.07046
Timestep Consumption Time: 2.00115
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.07162

Cumulative Model Updates: 35994
Cumulative Timesteps: 300500981

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.83533
Policy Entropy: 1.30285
Value Function Loss: 0.02143

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.12217
Value Function Update Magnitude: 0.21375

Collected Steps per Second: 10785.94480
Overall Steps per Second: 7427.89781

Timestep Collection Time: 4.63798
Timestep Consumption Time: 2.09676
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 6.73475

Cumulative Model Updates: 36000
Cumulative Timesteps: 300551006

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.04298
Policy Entropy: 1.30387
Value Function Loss: 0.02104

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.11798
Value Function Update Magnitude: 0.21515

Collected Steps per Second: 9847.24473
Overall Steps per Second: 7057.39908

Timestep Collection Time: 5.07929
Timestep Consumption Time: 2.00788
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 7.08717

Cumulative Model Updates: 36006
Cumulative Timesteps: 300601023

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.27399
Policy Entropy: 1.30614
Value Function Loss: 0.02153

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.11905
Value Function Update Magnitude: 0.21668

Collected Steps per Second: 9722.66222
Overall Steps per Second: 6993.15002

Timestep Collection Time: 5.14365
Timestep Consumption Time: 2.00763
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.15128

Cumulative Model Updates: 36012
Cumulative Timesteps: 300651033

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.50011
Policy Entropy: 1.30805
Value Function Loss: 0.02215

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.11840
Value Function Update Magnitude: 0.20781

Collected Steps per Second: 10264.07835
Overall Steps per Second: 7185.15153

Timestep Collection Time: 4.87477
Timestep Consumption Time: 2.08890
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 6.96367

Cumulative Model Updates: 36018
Cumulative Timesteps: 300701068

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.00488
Policy Entropy: 1.30735
Value Function Loss: 0.02183

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.11478
Value Function Update Magnitude: 0.20630

Collected Steps per Second: 9701.17822
Overall Steps per Second: 6908.73655

Timestep Collection Time: 5.15473
Timestep Consumption Time: 2.08349
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.23823

Cumulative Model Updates: 36024
Cumulative Timesteps: 300751075

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.61150
Policy Entropy: 1.30462
Value Function Loss: 0.02233

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.11629
Value Function Update Magnitude: 0.20538

Collected Steps per Second: 9859.77096
Overall Steps per Second: 7065.38154

Timestep Collection Time: 5.07263
Timestep Consumption Time: 2.00625
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.07888

Cumulative Model Updates: 36030
Cumulative Timesteps: 300801090

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 300801090...
Checkpoint 300801090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.26850
Policy Entropy: 1.30618
Value Function Loss: 0.02157

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.11559
Value Function Update Magnitude: 0.20529

Collected Steps per Second: 10351.20533
Overall Steps per Second: 7231.68616

Timestep Collection Time: 4.83383
Timestep Consumption Time: 2.08516
PPO Batch Consumption Time: 0.02443
Total Iteration Time: 6.91899

Cumulative Model Updates: 36036
Cumulative Timesteps: 300851126

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.99296
Policy Entropy: 1.30481
Value Function Loss: 0.02230

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.11719
Value Function Update Magnitude: 0.20632

Collected Steps per Second: 9866.01025
Overall Steps per Second: 6985.81211

Timestep Collection Time: 5.06922
Timestep Consumption Time: 2.09000
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.15922

Cumulative Model Updates: 36042
Cumulative Timesteps: 300901139

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.02478
Policy Entropy: 1.30401
Value Function Loss: 0.02176

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.06925
Policy Update Magnitude: 0.11798
Value Function Update Magnitude: 0.20935

Collected Steps per Second: 9799.22826
Overall Steps per Second: 7027.32864

Timestep Collection Time: 5.10244
Timestep Consumption Time: 2.01264
PPO Batch Consumption Time: 0.02454
Total Iteration Time: 7.11508

Cumulative Model Updates: 36048
Cumulative Timesteps: 300951139

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.88938
Policy Entropy: 1.30546
Value Function Loss: 0.02228

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.11528
Value Function Update Magnitude: 0.21386

Collected Steps per Second: 10482.31865
Overall Steps per Second: 7264.27721

Timestep Collection Time: 4.77060
Timestep Consumption Time: 2.11336
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 6.88396

Cumulative Model Updates: 36054
Cumulative Timesteps: 301001146

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.84227
Policy Entropy: 1.30477
Value Function Loss: 0.02274

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.11726
Value Function Update Magnitude: 0.20735

Collected Steps per Second: 9776.33604
Overall Steps per Second: 7166.47911

Timestep Collection Time: 5.11807
Timestep Consumption Time: 1.86388
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 6.98195

Cumulative Model Updates: 36060
Cumulative Timesteps: 301051182

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.38472
Policy Entropy: 1.30521
Value Function Loss: 0.02333

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.11953
Value Function Update Magnitude: 0.21282

Collected Steps per Second: 9933.21483
Overall Steps per Second: 7082.05263

Timestep Collection Time: 5.03402
Timestep Consumption Time: 2.02665
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.06066

Cumulative Model Updates: 36066
Cumulative Timesteps: 301101186

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.33587
Policy Entropy: 1.30295
Value Function Loss: 0.02315

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.11887
Value Function Update Magnitude: 0.21913

Collected Steps per Second: 10307.50137
Overall Steps per Second: 7139.18643

Timestep Collection Time: 4.85287
Timestep Consumption Time: 2.15367
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.00654

Cumulative Model Updates: 36072
Cumulative Timesteps: 301151207

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.32127
Policy Entropy: 1.30611
Value Function Loss: 0.02290

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.06695
Policy Update Magnitude: 0.12063
Value Function Update Magnitude: 0.22222

Collected Steps per Second: 9691.93694
Overall Steps per Second: 6820.02712

Timestep Collection Time: 5.15955
Timestep Consumption Time: 2.17268
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.33223

Cumulative Model Updates: 36078
Cumulative Timesteps: 301201213

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.45703
Policy Entropy: 1.30585
Value Function Loss: 0.02243

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.12174
Value Function Update Magnitude: 0.23272

Collected Steps per Second: 9754.69492
Overall Steps per Second: 6982.80750

Timestep Collection Time: 5.12717
Timestep Consumption Time: 2.03528
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 7.16245

Cumulative Model Updates: 36084
Cumulative Timesteps: 301251227

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.06843
Policy Entropy: 1.30484
Value Function Loss: 0.02332

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.12324
Value Function Update Magnitude: 0.23666

Collected Steps per Second: 10423.20948
Overall Steps per Second: 7249.88128

Timestep Collection Time: 4.80034
Timestep Consumption Time: 2.10115
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.90149

Cumulative Model Updates: 36090
Cumulative Timesteps: 301301262

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 301301262...
Checkpoint 301301262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.65928
Policy Entropy: 1.29887
Value Function Loss: 0.02290

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.12259
Value Function Update Magnitude: 0.22693

Collected Steps per Second: 9662.00192
Overall Steps per Second: 6942.03972

Timestep Collection Time: 5.17512
Timestep Consumption Time: 2.02766
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.20278

Cumulative Model Updates: 36096
Cumulative Timesteps: 301351264

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.31227
Policy Entropy: 1.29784
Value Function Loss: 0.02473

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.12430
Value Function Update Magnitude: 0.22383

Collected Steps per Second: 10189.52578
Overall Steps per Second: 7236.37560

Timestep Collection Time: 4.90818
Timestep Consumption Time: 2.00302
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.91119

Cumulative Model Updates: 36102
Cumulative Timesteps: 301401276

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.98591
Policy Entropy: 1.29330
Value Function Loss: 0.02395

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.11896
Value Function Update Magnitude: 0.22597

Collected Steps per Second: 10401.99230
Overall Steps per Second: 7280.97943

Timestep Collection Time: 4.80783
Timestep Consumption Time: 2.06089
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 6.86872

Cumulative Model Updates: 36108
Cumulative Timesteps: 301451287

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.46390
Policy Entropy: 1.30440
Value Function Loss: 0.02408

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.12056
Value Function Update Magnitude: 0.23387

Collected Steps per Second: 9702.70569
Overall Steps per Second: 6978.75301

Timestep Collection Time: 5.15361
Timestep Consumption Time: 2.01156
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.16518

Cumulative Model Updates: 36114
Cumulative Timesteps: 301501291

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.24133
Policy Entropy: 1.30272
Value Function Loss: 0.02192

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.11852
Value Function Update Magnitude: 0.23109

Collected Steps per Second: 9966.71242
Overall Steps per Second: 7087.72611

Timestep Collection Time: 5.01921
Timestep Consumption Time: 2.03877
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.05798

Cumulative Model Updates: 36120
Cumulative Timesteps: 301551316

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.14030
Policy Entropy: 1.30250
Value Function Loss: 0.02115

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.11633
Value Function Update Magnitude: 0.22430

Collected Steps per Second: 10208.99701
Overall Steps per Second: 7117.46620

Timestep Collection Time: 4.89891
Timestep Consumption Time: 2.12788
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 7.02680

Cumulative Model Updates: 36126
Cumulative Timesteps: 301601329

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.52883
Policy Entropy: 1.29675
Value Function Loss: 0.02089

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.11445
Value Function Update Magnitude: 0.22187

Collected Steps per Second: 9868.04473
Overall Steps per Second: 7030.22838

Timestep Collection Time: 5.07051
Timestep Consumption Time: 2.04676
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.11727

Cumulative Model Updates: 36132
Cumulative Timesteps: 301651365

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.62354
Policy Entropy: 1.29882
Value Function Loss: 0.02049

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.11570
Value Function Update Magnitude: 0.22869

Collected Steps per Second: 9758.23533
Overall Steps per Second: 6957.73126

Timestep Collection Time: 5.12449
Timestep Consumption Time: 2.06262
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.18711

Cumulative Model Updates: 36138
Cumulative Timesteps: 301701371

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.59433
Policy Entropy: 1.29648
Value Function Loss: 0.02108

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.11476
Value Function Update Magnitude: 0.22370

Collected Steps per Second: 10406.05396
Overall Steps per Second: 7235.37477

Timestep Collection Time: 4.80576
Timestep Consumption Time: 2.10598
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 6.91174

Cumulative Model Updates: 36144
Cumulative Timesteps: 301751380

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.57101
Policy Entropy: 1.29335
Value Function Loss: 0.02207

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.12010
Value Function Update Magnitude: 0.20938

Collected Steps per Second: 9882.81389
Overall Steps per Second: 6948.58618

Timestep Collection Time: 5.06364
Timestep Consumption Time: 2.13826
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 7.20190

Cumulative Model Updates: 36150
Cumulative Timesteps: 301801423

Timesteps Collected: 50043
--------END ITERATION REPORT--------


Saving checkpoint 301801423...
Checkpoint 301801423 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.56971
Policy Entropy: 1.28843
Value Function Loss: 0.02379

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.12096
Value Function Update Magnitude: 0.20635

Collected Steps per Second: 9668.88167
Overall Steps per Second: 6938.50968

Timestep Collection Time: 5.17185
Timestep Consumption Time: 2.03517
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.20702

Cumulative Model Updates: 36156
Cumulative Timesteps: 301851429

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.07266
Policy Entropy: 1.28736
Value Function Loss: 0.02454

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.12359
Value Function Update Magnitude: 0.21551

Collected Steps per Second: 10152.83910
Overall Steps per Second: 2013.42717

Timestep Collection Time: 4.92769
Timestep Consumption Time: 19.92049
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 24.84818

Cumulative Model Updates: 36162
Cumulative Timesteps: 301901459

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.97478
Policy Entropy: 1.29182
Value Function Loss: 0.02474

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.12621
Value Function Update Magnitude: 0.21438

Collected Steps per Second: 9917.47279
Overall Steps per Second: 7036.03953

Timestep Collection Time: 5.04383
Timestep Consumption Time: 2.06557
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.10940

Cumulative Model Updates: 36168
Cumulative Timesteps: 301951481

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.94546
Policy Entropy: 1.28953
Value Function Loss: 0.02402

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.12318
Value Function Update Magnitude: 0.20571

Collected Steps per Second: 9644.69844
Overall Steps per Second: 6927.84166

Timestep Collection Time: 5.18596
Timestep Consumption Time: 2.03375
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.21971

Cumulative Model Updates: 36174
Cumulative Timesteps: 302001498

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.61778
Policy Entropy: 1.28942
Value Function Loss: 0.02314

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.20171

Collected Steps per Second: 10303.90451
Overall Steps per Second: 7175.23235

Timestep Collection Time: 4.85622
Timestep Consumption Time: 2.11749
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 6.97371

Cumulative Model Updates: 36180
Cumulative Timesteps: 302051536

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.01883
Policy Entropy: 1.28715
Value Function Loss: 0.02213

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.12036
Value Function Update Magnitude: 0.19691

Collected Steps per Second: 9825.89772
Overall Steps per Second: 6994.64387

Timestep Collection Time: 5.09277
Timestep Consumption Time: 2.06142
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.15419

Cumulative Model Updates: 36186
Cumulative Timesteps: 302101577

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.38852
Policy Entropy: 1.29426
Value Function Loss: 0.02176

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.11844
Value Function Update Magnitude: 0.19731

Collected Steps per Second: 9884.64627
Overall Steps per Second: 7018.10132

Timestep Collection Time: 5.06179
Timestep Consumption Time: 2.06749
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.12928

Cumulative Model Updates: 36192
Cumulative Timesteps: 302151611

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.98854
Policy Entropy: 1.29336
Value Function Loss: 0.02255

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.11826
Value Function Update Magnitude: 0.19971

Collected Steps per Second: 10301.65619
Overall Steps per Second: 7153.13227

Timestep Collection Time: 4.85582
Timestep Consumption Time: 2.13734
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 6.99316

Cumulative Model Updates: 36198
Cumulative Timesteps: 302201634

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.03441
Policy Entropy: 1.29308
Value Function Loss: 0.02205

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.11797
Value Function Update Magnitude: 0.20063

Collected Steps per Second: 9745.94904
Overall Steps per Second: 6957.96433

Timestep Collection Time: 5.13136
Timestep Consumption Time: 2.05608
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.18745

Cumulative Model Updates: 36204
Cumulative Timesteps: 302251644

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.77555
Policy Entropy: 1.29952
Value Function Loss: 0.02242

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.12179
Value Function Update Magnitude: 0.20205

Collected Steps per Second: 9682.49122
Overall Steps per Second: 6951.18782

Timestep Collection Time: 5.16520
Timestep Consumption Time: 2.02954
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.19474

Cumulative Model Updates: 36210
Cumulative Timesteps: 302301656

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 302301656...
Checkpoint 302301656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.15637
Policy Entropy: 1.29474
Value Function Loss: 0.02206

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.12078
Value Function Update Magnitude: 0.20099

Collected Steps per Second: 10527.51449
Overall Steps per Second: 7306.71743

Timestep Collection Time: 4.75012
Timestep Consumption Time: 2.09385
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.84398

Cumulative Model Updates: 36216
Cumulative Timesteps: 302351663

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.56232
Policy Entropy: 1.28864
Value Function Loss: 0.02345

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.12391
Value Function Update Magnitude: 0.21281

Collected Steps per Second: 9769.41810
Overall Steps per Second: 6935.76607

Timestep Collection Time: 5.11832
Timestep Consumption Time: 2.09112
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.20944

Cumulative Model Updates: 36222
Cumulative Timesteps: 302401666

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.00978
Policy Entropy: 1.28175
Value Function Loss: 0.02385

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.12104
Value Function Update Magnitude: 0.21831

Collected Steps per Second: 9673.63595
Overall Steps per Second: 7013.44259

Timestep Collection Time: 5.17324
Timestep Consumption Time: 1.96220
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 7.13544

Cumulative Model Updates: 36228
Cumulative Timesteps: 302451710

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.94211
Policy Entropy: 1.28839
Value Function Loss: 0.02426

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.12286
Value Function Update Magnitude: 0.22141

Collected Steps per Second: 10403.62725
Overall Steps per Second: 7301.59894

Timestep Collection Time: 4.80688
Timestep Consumption Time: 2.04217
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 6.84905

Cumulative Model Updates: 36234
Cumulative Timesteps: 302501719

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.48573
Policy Entropy: 1.29417
Value Function Loss: 0.02313

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07015
Policy Update Magnitude: 0.12271
Value Function Update Magnitude: 0.21817

Collected Steps per Second: 9810.87082
Overall Steps per Second: 7056.10929

Timestep Collection Time: 5.09863
Timestep Consumption Time: 1.99055
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.08918

Cumulative Model Updates: 36240
Cumulative Timesteps: 302551741

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.59531
Policy Entropy: 1.29255
Value Function Loss: 0.02273

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.12288
Value Function Update Magnitude: 0.21535

Collected Steps per Second: 9703.19195
Overall Steps per Second: 6995.44893

Timestep Collection Time: 5.15325
Timestep Consumption Time: 1.99468
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.14793

Cumulative Model Updates: 36246
Cumulative Timesteps: 302601744

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.94068
Policy Entropy: 1.28867
Value Function Loss: 0.02305

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.21123

Collected Steps per Second: 10319.36774
Overall Steps per Second: 7005.05576

Timestep Collection Time: 4.84943
Timestep Consumption Time: 2.29442
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.14384

Cumulative Model Updates: 36252
Cumulative Timesteps: 302651787

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.04230
Policy Entropy: 1.28668
Value Function Loss: 0.02337

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.12350
Value Function Update Magnitude: 0.21170

Collected Steps per Second: 10299.81264
Overall Steps per Second: 7126.87372

Timestep Collection Time: 4.85582
Timestep Consumption Time: 2.16185
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 7.01766

Cumulative Model Updates: 36258
Cumulative Timesteps: 302701801

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.53954
Policy Entropy: 1.28971
Value Function Loss: 0.02276

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.12629
Value Function Update Magnitude: 0.21722

Collected Steps per Second: 9770.01639
Overall Steps per Second: 7027.16868

Timestep Collection Time: 5.11842
Timestep Consumption Time: 1.99782
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.11624

Cumulative Model Updates: 36264
Cumulative Timesteps: 302751808

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.64767
Policy Entropy: 1.29347
Value Function Loss: 0.02177

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.12484
Value Function Update Magnitude: 0.22152

Collected Steps per Second: 9918.46858
Overall Steps per Second: 7074.24364

Timestep Collection Time: 5.04372
Timestep Consumption Time: 2.02785
PPO Batch Consumption Time: 0.02834
Total Iteration Time: 7.07157

Cumulative Model Updates: 36270
Cumulative Timesteps: 302801834

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 302801834...
Checkpoint 302801834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.84499
Policy Entropy: 1.29454
Value Function Loss: 0.02208

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.12425
Value Function Update Magnitude: 0.22291

Collected Steps per Second: 10530.12197
Overall Steps per Second: 7241.48556

Timestep Collection Time: 4.75094
Timestep Consumption Time: 2.15759
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 6.90853

Cumulative Model Updates: 36276
Cumulative Timesteps: 302851862

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.98008
Policy Entropy: 1.29800
Value Function Loss: 0.02266

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.12210
Value Function Update Magnitude: 0.21855

Collected Steps per Second: 9849.78737
Overall Steps per Second: 7033.62961

Timestep Collection Time: 5.07970
Timestep Consumption Time: 2.03384
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 7.11354

Cumulative Model Updates: 36282
Cumulative Timesteps: 302901896

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.37847
Policy Entropy: 1.29611
Value Function Loss: 0.02455

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.06825
Policy Update Magnitude: 0.12313
Value Function Update Magnitude: 0.22428

Collected Steps per Second: 9741.20432
Overall Steps per Second: 6966.99689

Timestep Collection Time: 5.13571
Timestep Consumption Time: 2.04500
PPO Batch Consumption Time: 0.02869
Total Iteration Time: 7.18071

Cumulative Model Updates: 36288
Cumulative Timesteps: 302951924

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.97691
Policy Entropy: 1.30164
Value Function Loss: 0.02337

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.23280

Collected Steps per Second: 10470.76927
Overall Steps per Second: 7255.87396

Timestep Collection Time: 4.77911
Timestep Consumption Time: 2.11751
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 6.89662

Cumulative Model Updates: 36294
Cumulative Timesteps: 303001965

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.57976
Policy Entropy: 1.30394
Value Function Loss: 0.02369

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.12169
Value Function Update Magnitude: 0.23640

Collected Steps per Second: 9922.74018
Overall Steps per Second: 7067.87707

Timestep Collection Time: 5.04236
Timestep Consumption Time: 2.03671
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 7.07907

Cumulative Model Updates: 36300
Cumulative Timesteps: 303051999

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.47841
Policy Entropy: 1.30991
Value Function Loss: 0.02254

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.12081
Value Function Update Magnitude: 0.22539

Collected Steps per Second: 9729.66373
Overall Steps per Second: 6959.00372

Timestep Collection Time: 5.14283
Timestep Consumption Time: 2.04757
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.19040

Cumulative Model Updates: 36306
Cumulative Timesteps: 303102037

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.22131
Policy Entropy: 1.31315
Value Function Loss: 0.02244

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.11848
Value Function Update Magnitude: 0.22809

Collected Steps per Second: 10261.38623
Overall Steps per Second: 7174.38957

Timestep Collection Time: 4.87361
Timestep Consumption Time: 2.09702
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 6.97063

Cumulative Model Updates: 36312
Cumulative Timesteps: 303152047

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.24754
Policy Entropy: 1.30873
Value Function Loss: 0.02228

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.06493
Policy Update Magnitude: 0.11820
Value Function Update Magnitude: 0.22220

Collected Steps per Second: 9952.75798
Overall Steps per Second: 7016.85069

Timestep Collection Time: 5.02655
Timestep Consumption Time: 2.10315
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.12969

Cumulative Model Updates: 36318
Cumulative Timesteps: 303202075

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.22474
Policy Entropy: 1.30097
Value Function Loss: 0.02293

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.07248
Policy Update Magnitude: 0.11918
Value Function Update Magnitude: 0.21747

Collected Steps per Second: 9880.80035
Overall Steps per Second: 7067.40518

Timestep Collection Time: 5.06163
Timestep Consumption Time: 2.01494
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.07657

Cumulative Model Updates: 36324
Cumulative Timesteps: 303252088

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.24680
Policy Entropy: 1.29611
Value Function Loss: 0.02356

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.12009
Value Function Update Magnitude: 0.20824

Collected Steps per Second: 10417.77487
Overall Steps per Second: 7300.50943

Timestep Collection Time: 4.80227
Timestep Consumption Time: 2.05054
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 6.85281

Cumulative Model Updates: 36330
Cumulative Timesteps: 303302117

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 303302117...
Checkpoint 303302117 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.87898
Policy Entropy: 1.29657
Value Function Loss: 0.02286

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.06948
Policy Update Magnitude: 0.12292
Value Function Update Magnitude: 0.20721

Collected Steps per Second: 9814.01300
Overall Steps per Second: 7056.31382

Timestep Collection Time: 5.09741
Timestep Consumption Time: 1.99213
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.08954

Cumulative Model Updates: 36336
Cumulative Timesteps: 303352143

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.90258
Policy Entropy: 1.29909
Value Function Loss: 0.02315

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.06933
Policy Update Magnitude: 0.12107
Value Function Update Magnitude: 0.21129

Collected Steps per Second: 10185.71854
Overall Steps per Second: 7331.93634

Timestep Collection Time: 4.91080
Timestep Consumption Time: 1.91141
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.82221

Cumulative Model Updates: 36342
Cumulative Timesteps: 303402163

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.58384
Policy Entropy: 1.29830
Value Function Loss: 0.02239

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.11927
Value Function Update Magnitude: 0.22331

Collected Steps per Second: 10423.83596
Overall Steps per Second: 7270.38061

Timestep Collection Time: 4.79689
Timestep Consumption Time: 2.08060
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 6.87749

Cumulative Model Updates: 36348
Cumulative Timesteps: 303452165

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.39840
Policy Entropy: 1.29393
Value Function Loss: 0.02270

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.11845
Value Function Update Magnitude: 0.21355

Collected Steps per Second: 9941.44713
Overall Steps per Second: 7073.73107

Timestep Collection Time: 5.03257
Timestep Consumption Time: 2.04022
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.07279

Cumulative Model Updates: 36354
Cumulative Timesteps: 303502196

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.55688
Policy Entropy: 1.28994
Value Function Loss: 0.02146

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.11794
Value Function Update Magnitude: 0.21203

Collected Steps per Second: 9537.40648
Overall Steps per Second: 6856.68306

Timestep Collection Time: 5.24598
Timestep Consumption Time: 2.05099
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.29697

Cumulative Model Updates: 36360
Cumulative Timesteps: 303552229

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.81266
Policy Entropy: 1.29422
Value Function Loss: 0.02140

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.11661
Value Function Update Magnitude: 0.21781

Collected Steps per Second: 10184.89811
Overall Steps per Second: 7194.38853

Timestep Collection Time: 4.91119
Timestep Consumption Time: 2.04145
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.95264

Cumulative Model Updates: 36366
Cumulative Timesteps: 303602249

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.67055
Policy Entropy: 1.30207
Value Function Loss: 0.02099

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.11689
Value Function Update Magnitude: 0.21457

Collected Steps per Second: 9635.28121
Overall Steps per Second: 6927.80753

Timestep Collection Time: 5.19144
Timestep Consumption Time: 2.02888
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.22032

Cumulative Model Updates: 36372
Cumulative Timesteps: 303652270

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.85865
Policy Entropy: 1.29583
Value Function Loss: 0.02175

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.12229
Value Function Update Magnitude: 0.21377

Collected Steps per Second: 9929.60180
Overall Steps per Second: 7091.90999

Timestep Collection Time: 5.03615
Timestep Consumption Time: 2.01512
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.05127

Cumulative Model Updates: 36378
Cumulative Timesteps: 303702277

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.51018
Policy Entropy: 1.29717
Value Function Loss: 0.02160

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.12023
Value Function Update Magnitude: 0.22122

Collected Steps per Second: 10434.60175
Overall Steps per Second: 7242.51295

Timestep Collection Time: 4.79185
Timestep Consumption Time: 2.11197
PPO Batch Consumption Time: 0.02454
Total Iteration Time: 6.90382

Cumulative Model Updates: 36384
Cumulative Timesteps: 303752278

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.11541
Policy Entropy: 1.29546
Value Function Loss: 0.02131

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.22182

Collected Steps per Second: 9930.58871
Overall Steps per Second: 7027.36557

Timestep Collection Time: 5.03736
Timestep Consumption Time: 2.08109
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 7.11846

Cumulative Model Updates: 36390
Cumulative Timesteps: 303802302

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 303802302...
Checkpoint 303802302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.86437
Policy Entropy: 1.30027
Value Function Loss: 0.02058

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.12000
Value Function Update Magnitude: 0.21973

Collected Steps per Second: 9895.68351
Overall Steps per Second: 7083.50431

Timestep Collection Time: 5.05321
Timestep Consumption Time: 2.00615
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 7.05936

Cumulative Model Updates: 36396
Cumulative Timesteps: 303852307

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.02752
Policy Entropy: 1.29950
Value Function Loss: 0.02134

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.11609
Value Function Update Magnitude: 0.22212

Collected Steps per Second: 10282.04293
Overall Steps per Second: 7175.91275

Timestep Collection Time: 4.86508
Timestep Consumption Time: 2.10588
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 6.97096

Cumulative Model Updates: 36402
Cumulative Timesteps: 303902330

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.89781
Policy Entropy: 1.30203
Value Function Loss: 0.02144

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.11475
Value Function Update Magnitude: 0.21671

Collected Steps per Second: 9913.62584
Overall Steps per Second: 7170.32455

Timestep Collection Time: 5.04538
Timestep Consumption Time: 1.93032
PPO Batch Consumption Time: 0.02491
Total Iteration Time: 6.97570

Cumulative Model Updates: 36408
Cumulative Timesteps: 303952348

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.27419
Policy Entropy: 1.30206
Value Function Loss: 0.02184

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.11573
Value Function Update Magnitude: 0.21611

Collected Steps per Second: 9705.76307
Overall Steps per Second: 6949.73877

Timestep Collection Time: 5.15364
Timestep Consumption Time: 2.04375
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.19739

Cumulative Model Updates: 36414
Cumulative Timesteps: 304002368

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.51572
Policy Entropy: 1.30253
Value Function Loss: 0.02080

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.11459
Value Function Update Magnitude: 0.21052

Collected Steps per Second: 10365.24844
Overall Steps per Second: 7209.84249

Timestep Collection Time: 4.82651
Timestep Consumption Time: 2.11234
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 6.93885

Cumulative Model Updates: 36420
Cumulative Timesteps: 304052396

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.07178
Policy Entropy: 1.29949
Value Function Loss: 0.02234

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.11426
Value Function Update Magnitude: 0.20248

Collected Steps per Second: 9785.13192
Overall Steps per Second: 6994.52781

Timestep Collection Time: 5.11286
Timestep Consumption Time: 2.03988
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 7.15273

Cumulative Model Updates: 36426
Cumulative Timesteps: 304102426

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.21708
Policy Entropy: 1.29940
Value Function Loss: 0.02281

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.11628
Value Function Update Magnitude: 0.20633

Collected Steps per Second: 9906.38847
Overall Steps per Second: 6981.90806

Timestep Collection Time: 5.04967
Timestep Consumption Time: 2.11513
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.16480

Cumulative Model Updates: 36432
Cumulative Timesteps: 304152450

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.24995
Policy Entropy: 1.30082
Value Function Loss: 0.02396

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.11978
Value Function Update Magnitude: 0.21836

Collected Steps per Second: 10293.05739
Overall Steps per Second: 7192.80751

Timestep Collection Time: 4.85900
Timestep Consumption Time: 2.09433
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 6.95333

Cumulative Model Updates: 36438
Cumulative Timesteps: 304202464

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.78238
Policy Entropy: 1.29662
Value Function Loss: 0.02291

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.12070
Value Function Update Magnitude: 0.21607

Collected Steps per Second: 10041.62750
Overall Steps per Second: 7129.11206

Timestep Collection Time: 4.98047
Timestep Consumption Time: 2.03471
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 7.01518

Cumulative Model Updates: 36444
Cumulative Timesteps: 304252476

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.01527
Policy Entropy: 1.30104
Value Function Loss: 0.02366

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.11931
Value Function Update Magnitude: 0.20576

Collected Steps per Second: 9756.39137
Overall Steps per Second: 6951.49125

Timestep Collection Time: 5.12710
Timestep Consumption Time: 2.06877
PPO Batch Consumption Time: 0.02425
Total Iteration Time: 7.19587

Cumulative Model Updates: 36450
Cumulative Timesteps: 304302498

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 304302498...
Checkpoint 304302498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.99471
Policy Entropy: 1.29919
Value Function Loss: 0.02266

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.11882
Value Function Update Magnitude: 0.21047

Collected Steps per Second: 10451.08088
Overall Steps per Second: 7228.64800

Timestep Collection Time: 4.78783
Timestep Consumption Time: 2.13435
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 6.92218

Cumulative Model Updates: 36456
Cumulative Timesteps: 304352536

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.76449
Policy Entropy: 1.29382
Value Function Loss: 0.02456

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.12008
Value Function Update Magnitude: 0.22263

Collected Steps per Second: 9721.71602
Overall Steps per Second: 6961.89097

Timestep Collection Time: 5.14518
Timestep Consumption Time: 2.03965
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.18483

Cumulative Model Updates: 36462
Cumulative Timesteps: 304402556

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.14777
Policy Entropy: 1.28656
Value Function Loss: 0.02391

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.12177
Value Function Update Magnitude: 0.21586

Collected Steps per Second: 9628.99795
Overall Steps per Second: 6947.64854

Timestep Collection Time: 5.19358
Timestep Consumption Time: 2.00439
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.19797

Cumulative Model Updates: 36468
Cumulative Timesteps: 304452565

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.25051
Policy Entropy: 1.28505
Value Function Loss: 0.02423

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.12115
Value Function Update Magnitude: 0.21464

Collected Steps per Second: 10116.63283
Overall Steps per Second: 7154.95497

Timestep Collection Time: 4.94354
Timestep Consumption Time: 2.04630
PPO Batch Consumption Time: 0.02409
Total Iteration Time: 6.98984

Cumulative Model Updates: 36474
Cumulative Timesteps: 304502577

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.01052
Policy Entropy: 1.28911
Value Function Loss: 0.02229

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.12243
Value Function Update Magnitude: 0.20941

Collected Steps per Second: 9757.45393
Overall Steps per Second: 6887.60031

Timestep Collection Time: 5.12593
Timestep Consumption Time: 2.13582
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 7.26175

Cumulative Model Updates: 36480
Cumulative Timesteps: 304552593

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.31076
Policy Entropy: 1.29055
Value Function Loss: 0.02237

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.12078
Value Function Update Magnitude: 0.20543

Collected Steps per Second: 9868.40780
Overall Steps per Second: 7026.50752

Timestep Collection Time: 5.06880
Timestep Consumption Time: 2.05010
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 7.11890

Cumulative Model Updates: 36486
Cumulative Timesteps: 304602614

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.08460
Policy Entropy: 1.29262
Value Function Loss: 0.02216

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.12041
Value Function Update Magnitude: 0.20536

Collected Steps per Second: 10153.52920
Overall Steps per Second: 7127.22129

Timestep Collection Time: 4.92804
Timestep Consumption Time: 2.09251
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 7.02055

Cumulative Model Updates: 36492
Cumulative Timesteps: 304652651

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.91426
Policy Entropy: 1.29240
Value Function Loss: 0.02281

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.11856
Value Function Update Magnitude: 0.21008

Collected Steps per Second: 9906.58536
Overall Steps per Second: 7066.51809

Timestep Collection Time: 5.05139
Timestep Consumption Time: 2.03018
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 7.08156

Cumulative Model Updates: 36498
Cumulative Timesteps: 304702693

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.75408
Policy Entropy: 1.29204
Value Function Loss: 0.02241

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07516
Policy Update Magnitude: 0.11792
Value Function Update Magnitude: 0.21719

Collected Steps per Second: 9707.95542
Overall Steps per Second: 6928.11496

Timestep Collection Time: 5.15062
Timestep Consumption Time: 2.06664
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 7.21726

Cumulative Model Updates: 36504
Cumulative Timesteps: 304752695

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.24607
Policy Entropy: 1.28228
Value Function Loss: 0.02324

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.12139
Value Function Update Magnitude: 0.21847

Collected Steps per Second: 10951.43716
Overall Steps per Second: 7481.19649

Timestep Collection Time: 4.56671
Timestep Consumption Time: 2.11832
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 6.68503

Cumulative Model Updates: 36510
Cumulative Timesteps: 304802707

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 304802707...
Checkpoint 304802707 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.75631
Policy Entropy: 1.27634
Value Function Loss: 0.02365

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.12271
Value Function Update Magnitude: 0.23197

Collected Steps per Second: 10070.71773
Overall Steps per Second: 7084.66696

Timestep Collection Time: 4.96519
Timestep Consumption Time: 2.09273
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.05792

Cumulative Model Updates: 36516
Cumulative Timesteps: 304852710

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.61328
Policy Entropy: 1.27652
Value Function Loss: 0.02323

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.12147
Value Function Update Magnitude: 0.23931

Collected Steps per Second: 9677.33487
Overall Steps per Second: 6935.57218

Timestep Collection Time: 5.17147
Timestep Consumption Time: 2.04438
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 7.21584

Cumulative Model Updates: 36522
Cumulative Timesteps: 304902756

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.40582
Policy Entropy: 1.27916
Value Function Loss: 0.02384

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.12456
Value Function Update Magnitude: 0.23712

Collected Steps per Second: 10393.99382
Overall Steps per Second: 7267.95766

Timestep Collection Time: 4.81249
Timestep Consumption Time: 2.06991
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 6.88240

Cumulative Model Updates: 36528
Cumulative Timesteps: 304952777

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.96091
Policy Entropy: 1.28199
Value Function Loss: 0.02510

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.12261
Value Function Update Magnitude: 0.24268

Collected Steps per Second: 10026.40036
Overall Steps per Second: 7063.08882

Timestep Collection Time: 4.99023
Timestep Consumption Time: 2.09364
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.08387

Cumulative Model Updates: 36534
Cumulative Timesteps: 305002811

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.11582
Policy Entropy: 1.28795
Value Function Loss: 0.02685

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.12120
Value Function Update Magnitude: 0.26362

Collected Steps per Second: 9946.38751
Overall Steps per Second: 7096.01077

Timestep Collection Time: 5.02836
Timestep Consumption Time: 2.01983
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 7.04819

Cumulative Model Updates: 36540
Cumulative Timesteps: 305052825

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.40966
Policy Entropy: 1.28556
Value Function Loss: 0.02521

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.12218
Value Function Update Magnitude: 0.26310

Collected Steps per Second: 10671.79575
Overall Steps per Second: 7341.16151

Timestep Collection Time: 4.68562
Timestep Consumption Time: 2.12583
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 6.81146

Cumulative Model Updates: 36546
Cumulative Timesteps: 305102829

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.49142
Policy Entropy: 1.28548
Value Function Loss: 0.02416

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.11898
Value Function Update Magnitude: 0.24980

Collected Steps per Second: 9791.71160
Overall Steps per Second: 6958.50530

Timestep Collection Time: 5.10922
Timestep Consumption Time: 2.08026
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 7.18948

Cumulative Model Updates: 36552
Cumulative Timesteps: 305152857

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.71959
Policy Entropy: 1.27754
Value Function Loss: 0.02278

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.11894
Value Function Update Magnitude: 0.23029

Collected Steps per Second: 9754.97737
Overall Steps per Second: 6949.97414

Timestep Collection Time: 5.12795
Timestep Consumption Time: 2.06963
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.19758

Cumulative Model Updates: 36558
Cumulative Timesteps: 305202880

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.79242
Policy Entropy: 1.27934
Value Function Loss: 0.02280

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.07678
Policy Update Magnitude: 0.12060
Value Function Update Magnitude: 0.22218

Collected Steps per Second: 10393.82257
Overall Steps per Second: 7187.69412

Timestep Collection Time: 4.81142
Timestep Consumption Time: 2.14617
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 6.95759

Cumulative Model Updates: 36564
Cumulative Timesteps: 305252889

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.82846
Policy Entropy: 1.27919
Value Function Loss: 0.02261

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.22668

Collected Steps per Second: 9766.53866
Overall Steps per Second: 6921.58348

Timestep Collection Time: 5.12116
Timestep Consumption Time: 2.10493
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.22609

Cumulative Model Updates: 36570
Cumulative Timesteps: 305302905

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 305302905...
Checkpoint 305302905 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.04403
Policy Entropy: 1.27819
Value Function Loss: 0.02404

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.12356
Value Function Update Magnitude: 0.21961

Collected Steps per Second: 9728.00194
Overall Steps per Second: 6965.92149

Timestep Collection Time: 5.14268
Timestep Consumption Time: 2.03914
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.18182

Cumulative Model Updates: 36576
Cumulative Timesteps: 305352933

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.29609
Policy Entropy: 1.28038
Value Function Loss: 0.02466

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.12329
Value Function Update Magnitude: 0.21424

Collected Steps per Second: 10469.32036
Overall Steps per Second: 7240.42583

Timestep Collection Time: 4.77939
Timestep Consumption Time: 2.13139
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 6.91078

Cumulative Model Updates: 36582
Cumulative Timesteps: 305402970

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.65069
Policy Entropy: 1.28103
Value Function Loss: 0.02506

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.12555
Value Function Update Magnitude: 0.20980

Collected Steps per Second: 9818.00446
Overall Steps per Second: 6899.61902

Timestep Collection Time: 5.09330
Timestep Consumption Time: 2.15435
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 7.24765

Cumulative Model Updates: 36588
Cumulative Timesteps: 305452976

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.62534
Policy Entropy: 1.27838
Value Function Loss: 0.02367

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.12533
Value Function Update Magnitude: 0.21167

Collected Steps per Second: 9714.27932
Overall Steps per Second: 6921.96170

Timestep Collection Time: 5.15015
Timestep Consumption Time: 2.07757
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.22772

Cumulative Model Updates: 36594
Cumulative Timesteps: 305503006

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.17106
Policy Entropy: 1.28054
Value Function Loss: 0.02297

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.13016
Value Function Update Magnitude: 0.21046

Collected Steps per Second: 10295.92616
Overall Steps per Second: 7139.38763

Timestep Collection Time: 4.85930
Timestep Consumption Time: 2.14844
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.00774

Cumulative Model Updates: 36600
Cumulative Timesteps: 305553037

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.62148
Policy Entropy: 1.27661
Value Function Loss: 0.02374

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.13092
Value Function Update Magnitude: 0.21123

Collected Steps per Second: 9827.47432
Overall Steps per Second: 7125.60043

Timestep Collection Time: 5.09114
Timestep Consumption Time: 1.93045
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 7.02158

Cumulative Model Updates: 36606
Cumulative Timesteps: 305603070

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.90971
Policy Entropy: 1.28364
Value Function Loss: 0.02476

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.12920
Value Function Update Magnitude: 0.22062

Collected Steps per Second: 10021.97769
Overall Steps per Second: 7213.75187

Timestep Collection Time: 4.99233
Timestep Consumption Time: 1.94345
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 6.93578

Cumulative Model Updates: 36612
Cumulative Timesteps: 305653103

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.13275
Policy Entropy: 1.28427
Value Function Loss: 0.02397

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.13340
Value Function Update Magnitude: 0.21981

Collected Steps per Second: 10594.05786
Overall Steps per Second: 7515.74510

Timestep Collection Time: 4.72142
Timestep Consumption Time: 1.93381
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.65523

Cumulative Model Updates: 36618
Cumulative Timesteps: 305703122

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.51324
Policy Entropy: 1.28377
Value Function Loss: 0.02423

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.13018
Value Function Update Magnitude: 0.21364

Collected Steps per Second: 10368.99085
Overall Steps per Second: 7221.20894

Timestep Collection Time: 4.82390
Timestep Consumption Time: 2.10278
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 6.92668

Cumulative Model Updates: 36624
Cumulative Timesteps: 305753141

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.39708
Policy Entropy: 1.28337
Value Function Loss: 0.02333

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07199
Policy Update Magnitude: 0.12736
Value Function Update Magnitude: 0.20480

Collected Steps per Second: 9764.46852
Overall Steps per Second: 6966.68303

Timestep Collection Time: 5.12276
Timestep Consumption Time: 2.05727
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.18003

Cumulative Model Updates: 36630
Cumulative Timesteps: 305803162

Timesteps Collected: 50021
--------END ITERATION REPORT--------


Saving checkpoint 305803162...
Checkpoint 305803162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.76530
Policy Entropy: 1.28462
Value Function Loss: 0.02394

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.12417
Value Function Update Magnitude: 0.19917

Collected Steps per Second: 10317.36355
Overall Steps per Second: 7224.71541

Timestep Collection Time: 4.84794
Timestep Consumption Time: 2.07524
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 6.92318

Cumulative Model Updates: 36636
Cumulative Timesteps: 305853180

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.90343
Policy Entropy: 1.28816
Value Function Loss: 0.02455

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.12230
Value Function Update Magnitude: 0.20827

Collected Steps per Second: 9927.16221
Overall Steps per Second: 7009.69514

Timestep Collection Time: 5.03789
Timestep Consumption Time: 2.09679
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.13469

Cumulative Model Updates: 36642
Cumulative Timesteps: 305903192

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.57866
Policy Entropy: 1.29113
Value Function Loss: 0.02510

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.12252
Value Function Update Magnitude: 0.21104

Collected Steps per Second: 9685.34678
Overall Steps per Second: 6963.76169

Timestep Collection Time: 5.16316
Timestep Consumption Time: 2.01787
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.18103

Cumulative Model Updates: 36648
Cumulative Timesteps: 305953199

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.47838
Policy Entropy: 1.30028
Value Function Loss: 0.02483

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.12225
Value Function Update Magnitude: 0.20609

Collected Steps per Second: 10382.73969
Overall Steps per Second: 7258.01552

Timestep Collection Time: 4.81896
Timestep Consumption Time: 2.07466
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 6.89362

Cumulative Model Updates: 36654
Cumulative Timesteps: 306003233

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.80605
Policy Entropy: 1.29689
Value Function Loss: 0.02290

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.12113
Value Function Update Magnitude: 0.20038

Collected Steps per Second: 9819.67558
Overall Steps per Second: 6887.27678

Timestep Collection Time: 5.09579
Timestep Consumption Time: 2.16964
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 7.26543

Cumulative Model Updates: 36660
Cumulative Timesteps: 306053272

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.01290
Policy Entropy: 1.30202
Value Function Loss: 0.02252

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.12071
Value Function Update Magnitude: 0.19526

Collected Steps per Second: 9683.46967
Overall Steps per Second: 6919.76480

Timestep Collection Time: 5.16798
Timestep Consumption Time: 2.06406
PPO Batch Consumption Time: 0.02954
Total Iteration Time: 7.23204

Cumulative Model Updates: 36666
Cumulative Timesteps: 306103316

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.08977
Policy Entropy: 1.30006
Value Function Loss: 0.02250

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.11887
Value Function Update Magnitude: 0.19596

Collected Steps per Second: 10436.71406
Overall Steps per Second: 7258.14337

Timestep Collection Time: 4.79318
Timestep Consumption Time: 2.09908
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 6.89226

Cumulative Model Updates: 36672
Cumulative Timesteps: 306153341

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.11163
Policy Entropy: 1.30680
Value Function Loss: 0.02230

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06443
Policy Update Magnitude: 0.11919
Value Function Update Magnitude: 0.20188

Collected Steps per Second: 9778.70358
Overall Steps per Second: 6987.34685

Timestep Collection Time: 5.11755
Timestep Consumption Time: 2.04440
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.16195

Cumulative Model Updates: 36678
Cumulative Timesteps: 306203384

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.87241
Policy Entropy: 1.29971
Value Function Loss: 0.02199

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.11877
Value Function Update Magnitude: 0.20371

Collected Steps per Second: 9708.59878
Overall Steps per Second: 6974.43712

Timestep Collection Time: 5.15255
Timestep Consumption Time: 2.01993
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 7.17248

Cumulative Model Updates: 36684
Cumulative Timesteps: 306253408

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.02597
Policy Entropy: 1.30192
Value Function Loss: 0.02241

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.11723
Value Function Update Magnitude: 0.19708

Collected Steps per Second: 10562.05189
Overall Steps per Second: 7356.13117

Timestep Collection Time: 4.73724
Timestep Consumption Time: 2.06457
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.80181

Cumulative Model Updates: 36690
Cumulative Timesteps: 306303443

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 306303443...
Checkpoint 306303443 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.72998
Policy Entropy: 1.29494
Value Function Loss: 0.02256

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.11625
Value Function Update Magnitude: 0.19918

Collected Steps per Second: 9816.38980
Overall Steps per Second: 7055.84922

Timestep Collection Time: 5.09790
Timestep Consumption Time: 1.99451
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.09241

Cumulative Model Updates: 36696
Cumulative Timesteps: 306353486

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.94008
Policy Entropy: 1.30125
Value Function Loss: 0.02312

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.12186
Value Function Update Magnitude: 0.20588

Collected Steps per Second: 9698.76560
Overall Steps per Second: 6936.61820

Timestep Collection Time: 5.15746
Timestep Consumption Time: 2.05369
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.21115

Cumulative Model Updates: 36702
Cumulative Timesteps: 306403507

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.96952
Policy Entropy: 1.29848
Value Function Loss: 0.02308

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.12108
Value Function Update Magnitude: 0.20602

Collected Steps per Second: 10436.53119
Overall Steps per Second: 7287.40980

Timestep Collection Time: 4.79278
Timestep Consumption Time: 2.07111
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.86389

Cumulative Model Updates: 36708
Cumulative Timesteps: 306453527

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.43601
Policy Entropy: 1.30206
Value Function Loss: 0.02333

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.11949
Value Function Update Magnitude: 0.20841

Collected Steps per Second: 9869.51528
Overall Steps per Second: 6980.96947

Timestep Collection Time: 5.06631
Timestep Consumption Time: 2.09631
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.16262

Cumulative Model Updates: 36714
Cumulative Timesteps: 306503529

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.92557
Policy Entropy: 1.29713
Value Function Loss: 0.02308

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.11700
Value Function Update Magnitude: 0.21152

Collected Steps per Second: 9672.32746
Overall Steps per Second: 6934.13241

Timestep Collection Time: 5.17373
Timestep Consumption Time: 2.04304
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 7.21676

Cumulative Model Updates: 36720
Cumulative Timesteps: 306553571

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.28903
Policy Entropy: 1.30202
Value Function Loss: 0.02388

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06387
Policy Update Magnitude: 0.11983
Value Function Update Magnitude: 0.21268

Collected Steps per Second: 10336.93850
Overall Steps per Second: 7230.03469

Timestep Collection Time: 4.83992
Timestep Consumption Time: 2.07982
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 6.91975

Cumulative Model Updates: 36726
Cumulative Timesteps: 306603601

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.55342
Policy Entropy: 1.30126
Value Function Loss: 0.02303

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.05841
Policy Update Magnitude: 0.12556
Value Function Update Magnitude: 0.21160

Collected Steps per Second: 9739.89304
Overall Steps per Second: 6989.22219

Timestep Collection Time: 5.13394
Timestep Consumption Time: 2.02051
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 7.15444

Cumulative Model Updates: 36732
Cumulative Timesteps: 306653605

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.99306
Policy Entropy: 1.30466
Value Function Loss: 0.02259

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.12365
Value Function Update Magnitude: 0.21068

Collected Steps per Second: 9670.34813
Overall Steps per Second: 6933.67788

Timestep Collection Time: 5.17530
Timestep Consumption Time: 2.04265
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 7.21796

Cumulative Model Updates: 36738
Cumulative Timesteps: 306703652

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.31310
Policy Entropy: 1.30341
Value Function Loss: 0.02211

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.12052
Value Function Update Magnitude: 0.21098

Collected Steps per Second: 10510.23949
Overall Steps per Second: 7276.91318

Timestep Collection Time: 4.75955
Timestep Consumption Time: 2.11479
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 6.87434

Cumulative Model Updates: 36744
Cumulative Timesteps: 306753676

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.92895
Policy Entropy: 1.30368
Value Function Loss: 0.02310

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.11822
Value Function Update Magnitude: 0.21354

Collected Steps per Second: 10114.09256
Overall Steps per Second: 7086.70526

Timestep Collection Time: 4.94508
Timestep Consumption Time: 2.11250
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 7.05758

Cumulative Model Updates: 36750
Cumulative Timesteps: 306803691

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 306803691...
Checkpoint 306803691 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.76461
Policy Entropy: 1.30155
Value Function Loss: 0.02325

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.11663
Value Function Update Magnitude: 0.21105

Collected Steps per Second: 9745.84263
Overall Steps per Second: 6955.86911

Timestep Collection Time: 5.13132
Timestep Consumption Time: 2.05815
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.18947

Cumulative Model Updates: 36756
Cumulative Timesteps: 306853700

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.86750
Policy Entropy: 1.30409
Value Function Loss: 0.02282

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.11599
Value Function Update Magnitude: 0.20709

Collected Steps per Second: 10355.26632
Overall Steps per Second: 851.96581

Timestep Collection Time: 4.83145
Timestep Consumption Time: 53.89273
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 58.72419

Cumulative Model Updates: 36762
Cumulative Timesteps: 306903731

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.79250
Policy Entropy: 1.30648
Value Function Loss: 0.02232

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.11713
Value Function Update Magnitude: 0.20620

Collected Steps per Second: 9814.75067
Overall Steps per Second: 7029.90172

Timestep Collection Time: 5.09641
Timestep Consumption Time: 2.01891
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.11532

Cumulative Model Updates: 36768
Cumulative Timesteps: 306953751

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.13583
Policy Entropy: 1.30441
Value Function Loss: 0.02190

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.11358
Value Function Update Magnitude: 0.20815

Collected Steps per Second: 9736.39192
Overall Steps per Second: 6957.71641

Timestep Collection Time: 5.13763
Timestep Consumption Time: 2.05180
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.18943

Cumulative Model Updates: 36774
Cumulative Timesteps: 307003773

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.06512
Policy Entropy: 1.30558
Value Function Loss: 0.02301

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.11690
Value Function Update Magnitude: 0.20773

Collected Steps per Second: 10403.34532
Overall Steps per Second: 7262.71033

Timestep Collection Time: 4.80768
Timestep Consumption Time: 2.07900
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 6.88669

Cumulative Model Updates: 36780
Cumulative Timesteps: 307053789

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.08796
Policy Entropy: 1.30580
Value Function Loss: 0.02318

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.11956
Value Function Update Magnitude: 0.20689

Collected Steps per Second: 10001.55841
Overall Steps per Second: 6912.85403

Timestep Collection Time: 5.00202
Timestep Consumption Time: 2.23493
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.23695

Cumulative Model Updates: 36786
Cumulative Timesteps: 307103817

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.04780
Policy Entropy: 1.30986
Value Function Loss: 0.02263

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.06845
Policy Update Magnitude: 0.11674
Value Function Update Magnitude: 0.20258

Collected Steps per Second: 9678.09714
Overall Steps per Second: 6952.33296

Timestep Collection Time: 5.17033
Timestep Consumption Time: 2.02711
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 7.19744

Cumulative Model Updates: 36792
Cumulative Timesteps: 307153856

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.29283
Policy Entropy: 1.30686
Value Function Loss: 0.02177

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.11565
Value Function Update Magnitude: 0.19960

Collected Steps per Second: 10274.88585
Overall Steps per Second: 7235.08239

Timestep Collection Time: 4.86653
Timestep Consumption Time: 2.04466
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.91119

Cumulative Model Updates: 36798
Cumulative Timesteps: 307203859

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.43246
Policy Entropy: 1.30601
Value Function Loss: 0.02223

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.11172
Value Function Update Magnitude: 0.19515

Collected Steps per Second: 9814.36824
Overall Steps per Second: 6971.95213

Timestep Collection Time: 5.09814
Timestep Consumption Time: 2.07848
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 7.17661

Cumulative Model Updates: 36804
Cumulative Timesteps: 307253894

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.79649
Policy Entropy: 1.30136
Value Function Loss: 0.02273

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.07680
Policy Update Magnitude: 0.11287
Value Function Update Magnitude: 0.20534

Collected Steps per Second: 9680.79837
Overall Steps per Second: 6924.01263

Timestep Collection Time: 5.16869
Timestep Consumption Time: 2.05790
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.22659

Cumulative Model Updates: 36810
Cumulative Timesteps: 307303931

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 307303931...
Checkpoint 307303931 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.47078
Policy Entropy: 1.30179
Value Function Loss: 0.02340

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.11446
Value Function Update Magnitude: 0.21489

Collected Steps per Second: 10419.17486
Overall Steps per Second: 7226.11069

Timestep Collection Time: 4.80057
Timestep Consumption Time: 2.12127
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 6.92184

Cumulative Model Updates: 36816
Cumulative Timesteps: 307353949

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.18416
Policy Entropy: 1.29989
Value Function Loss: 0.02316

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.11362
Value Function Update Magnitude: 0.21349

Collected Steps per Second: 9793.86148
Overall Steps per Second: 7008.74639

Timestep Collection Time: 5.10575
Timestep Consumption Time: 2.02891
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 7.13466

Cumulative Model Updates: 36822
Cumulative Timesteps: 307403954

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.51967
Policy Entropy: 1.30486
Value Function Loss: 0.02280

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.11820
Value Function Update Magnitude: 0.20980

Collected Steps per Second: 9782.08545
Overall Steps per Second: 6991.76167

Timestep Collection Time: 5.11496
Timestep Consumption Time: 2.04132
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.15628

Cumulative Model Updates: 36828
Cumulative Timesteps: 307453989

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.74369
Policy Entropy: 1.30997
Value Function Loss: 0.02349

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.11958
Value Function Update Magnitude: 0.20969

Collected Steps per Second: 10393.74563
Overall Steps per Second: 7245.36186

Timestep Collection Time: 4.81116
Timestep Consumption Time: 2.09063
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 6.90179

Cumulative Model Updates: 36834
Cumulative Timesteps: 307503995

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.92744
Policy Entropy: 1.31075
Value Function Loss: 0.02250

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.11616
Value Function Update Magnitude: 0.20505

Collected Steps per Second: 9815.24691
Overall Steps per Second: 7064.14709

Timestep Collection Time: 5.09615
Timestep Consumption Time: 1.98467
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 7.08083

Cumulative Model Updates: 36840
Cumulative Timesteps: 307554015

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.45623
Policy Entropy: 1.31096
Value Function Loss: 0.02358

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.11567
Value Function Update Magnitude: 0.20078

Collected Steps per Second: 9726.54899
Overall Steps per Second: 6984.29300

Timestep Collection Time: 5.14078
Timestep Consumption Time: 2.01843
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.15921

Cumulative Model Updates: 36846
Cumulative Timesteps: 307604017

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.47878
Policy Entropy: 1.31104
Value Function Loss: 0.02329

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.05948
Policy Update Magnitude: 0.11457
Value Function Update Magnitude: 0.20793

Collected Steps per Second: 10346.44614
Overall Steps per Second: 7178.65767

Timestep Collection Time: 4.83354
Timestep Consumption Time: 2.13294
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 6.96648

Cumulative Model Updates: 36852
Cumulative Timesteps: 307654027

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.85634
Policy Entropy: 1.31163
Value Function Loss: 0.02328

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.05462
Policy Update Magnitude: 0.11589
Value Function Update Magnitude: 0.21028

Collected Steps per Second: 10050.20276
Overall Steps per Second: 7144.22124

Timestep Collection Time: 4.97751
Timestep Consumption Time: 2.02465
PPO Batch Consumption Time: 0.02481
Total Iteration Time: 7.00216

Cumulative Model Updates: 36858
Cumulative Timesteps: 307704052

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.31585
Policy Entropy: 1.30876
Value Function Loss: 0.02325

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.05399
Policy Update Magnitude: 0.11814
Value Function Update Magnitude: 0.20159

Collected Steps per Second: 9828.52972
Overall Steps per Second: 7024.02167

Timestep Collection Time: 5.08998
Timestep Consumption Time: 2.03230
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.12227

Cumulative Model Updates: 36864
Cumulative Timesteps: 307754079

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.49828
Policy Entropy: 1.30576
Value Function Loss: 0.02305

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.06825
Policy Update Magnitude: 0.11891
Value Function Update Magnitude: 0.20015

Collected Steps per Second: 10403.15785
Overall Steps per Second: 7172.55140

Timestep Collection Time: 4.80941
Timestep Consumption Time: 2.16622
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 6.97562

Cumulative Model Updates: 36870
Cumulative Timesteps: 307804112

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 307804112...
Checkpoint 307804112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.90091
Policy Entropy: 1.30553
Value Function Loss: 0.02327

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.11460
Value Function Update Magnitude: 0.19314

Collected Steps per Second: 9964.38240
Overall Steps per Second: 7020.94295

Timestep Collection Time: 5.02169
Timestep Consumption Time: 2.10528
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.12696

Cumulative Model Updates: 36876
Cumulative Timesteps: 307854150

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.46653
Policy Entropy: 1.30840
Value Function Loss: 0.02436

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.11512
Value Function Update Magnitude: 0.19530

Collected Steps per Second: 9732.49422
Overall Steps per Second: 6941.77509

Timestep Collection Time: 5.13763
Timestep Consumption Time: 2.06542
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.20306

Cumulative Model Updates: 36882
Cumulative Timesteps: 307904152

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.34426
Policy Entropy: 1.31281
Value Function Loss: 0.02491

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.11724
Value Function Update Magnitude: 0.21021

Collected Steps per Second: 10226.65092
Overall Steps per Second: 6877.25187

Timestep Collection Time: 4.89320
Timestep Consumption Time: 2.38311
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.27631

Cumulative Model Updates: 36888
Cumulative Timesteps: 307954193

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.11556
Policy Entropy: 1.30966
Value Function Loss: 0.02326

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.11865
Value Function Update Magnitude: 0.21443

Collected Steps per Second: 10500.99662
Overall Steps per Second: 7277.16815

Timestep Collection Time: 4.76174
Timestep Consumption Time: 2.10948
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 6.87122

Cumulative Model Updates: 36894
Cumulative Timesteps: 308004196

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.77629
Policy Entropy: 1.30696
Value Function Loss: 0.02141

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.07199
Policy Update Magnitude: 0.11486
Value Function Update Magnitude: 0.20446

Collected Steps per Second: 9680.28712
Overall Steps per Second: 6978.17720

Timestep Collection Time: 5.16906
Timestep Consumption Time: 2.00158
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 7.17064

Cumulative Model Updates: 36900
Cumulative Timesteps: 308054234

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.56005
Policy Entropy: 1.31088
Value Function Loss: 0.02109

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.11392
Value Function Update Magnitude: 0.19636

Collected Steps per Second: 10749.14859
Overall Steps per Second: 7184.45168

Timestep Collection Time: 4.65460
Timestep Consumption Time: 2.30947
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 6.96407

Cumulative Model Updates: 36906
Cumulative Timesteps: 308104267

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.45184
Policy Entropy: 1.31469
Value Function Loss: 0.02106

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.05813
Policy Update Magnitude: 0.11452
Value Function Update Magnitude: 0.19604

Collected Steps per Second: 10650.54618
Overall Steps per Second: 7351.30937

Timestep Collection Time: 4.69619
Timestep Consumption Time: 2.10763
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 6.80382

Cumulative Model Updates: 36912
Cumulative Timesteps: 308154284

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.83708
Policy Entropy: 1.30936
Value Function Loss: 0.02124

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.11461
Value Function Update Magnitude: 0.20060

Collected Steps per Second: 9718.01828
Overall Steps per Second: 6983.59596

Timestep Collection Time: 5.14868
Timestep Consumption Time: 2.01596
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.16465

Cumulative Model Updates: 36918
Cumulative Timesteps: 308204319

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.65776
Policy Entropy: 1.30831
Value Function Loss: 0.02136

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.11298
Value Function Update Magnitude: 0.19970

Collected Steps per Second: 10439.82854
Overall Steps per Second: 7052.20779

Timestep Collection Time: 4.78973
Timestep Consumption Time: 2.30081
PPO Batch Consumption Time: 0.02421
Total Iteration Time: 7.09055

Cumulative Model Updates: 36924
Cumulative Timesteps: 308254323

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.19726
Policy Entropy: 1.30852
Value Function Loss: 0.02219

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.11636
Value Function Update Magnitude: 0.20421

Collected Steps per Second: 10340.25334
Overall Steps per Second: 7215.29406

Timestep Collection Time: 4.83847
Timestep Consumption Time: 2.09555
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 6.93402

Cumulative Model Updates: 36930
Cumulative Timesteps: 308304354

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 308304354...
Checkpoint 308304354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.01582
Policy Entropy: 1.31132
Value Function Loss: 0.02314

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.05879
Policy Update Magnitude: 0.11887
Value Function Update Magnitude: 0.22373

Collected Steps per Second: 9818.93978
Overall Steps per Second: 6970.69225

Timestep Collection Time: 5.09525
Timestep Consumption Time: 2.08194
PPO Batch Consumption Time: 0.02842
Total Iteration Time: 7.17719

Cumulative Model Updates: 36936
Cumulative Timesteps: 308354384

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.65555
Policy Entropy: 1.31023
Value Function Loss: 0.02362

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.06514
Policy Update Magnitude: 0.11864
Value Function Update Magnitude: 0.22963

Collected Steps per Second: 10375.32748
Overall Steps per Second: 7006.39880

Timestep Collection Time: 4.82317
Timestep Consumption Time: 2.31916
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 7.14233

Cumulative Model Updates: 36942
Cumulative Timesteps: 308404426

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.43594
Policy Entropy: 1.30882
Value Function Loss: 0.02385

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.11933
Value Function Update Magnitude: 0.22838

Collected Steps per Second: 10516.65787
Overall Steps per Second: 7305.53950

Timestep Collection Time: 4.75455
Timestep Consumption Time: 2.08984
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 6.84440

Cumulative Model Updates: 36948
Cumulative Timesteps: 308454428

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.17157
Policy Entropy: 1.30932
Value Function Loss: 0.02250

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.11550
Value Function Update Magnitude: 0.23097

Collected Steps per Second: 9709.97637
Overall Steps per Second: 6949.06072

Timestep Collection Time: 5.15418
Timestep Consumption Time: 2.04780
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 7.20198

Cumulative Model Updates: 36954
Cumulative Timesteps: 308504475

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.38175
Policy Entropy: 1.31547
Value Function Loss: 0.02282

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.06486
Policy Update Magnitude: 0.11405
Value Function Update Magnitude: 0.22109

Collected Steps per Second: 9916.96466
Overall Steps per Second: 7090.51752

Timestep Collection Time: 5.04287
Timestep Consumption Time: 2.01021
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 7.05308

Cumulative Model Updates: 36960
Cumulative Timesteps: 308554485

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.39145
Policy Entropy: 1.31949
Value Function Loss: 0.02187

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.05774
Policy Update Magnitude: 0.11338
Value Function Update Magnitude: 0.23190

Collected Steps per Second: 10257.50361
Overall Steps per Second: 7147.47322

Timestep Collection Time: 4.87604
Timestep Consumption Time: 2.12168
PPO Batch Consumption Time: 0.02516
Total Iteration Time: 6.99772

Cumulative Model Updates: 36966
Cumulative Timesteps: 308604501

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.17260
Policy Entropy: 1.31662
Value Function Loss: 0.02321

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.05939
Policy Update Magnitude: 0.11376
Value Function Update Magnitude: 0.23714

Collected Steps per Second: 9745.21591
Overall Steps per Second: 6988.85164

Timestep Collection Time: 5.13349
Timestep Consumption Time: 2.02462
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 7.15811

Cumulative Model Updates: 36972
Cumulative Timesteps: 308654528

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.08732
Policy Entropy: 1.31238
Value Function Loss: 0.02290

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.11611
Value Function Update Magnitude: 0.23860

Collected Steps per Second: 9819.61897
Overall Steps per Second: 7003.25386

Timestep Collection Time: 5.09225
Timestep Consumption Time: 2.04785
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.14011

Cumulative Model Updates: 36978
Cumulative Timesteps: 308704532

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.18282
Policy Entropy: 1.30743
Value Function Loss: 0.02349

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.11389
Value Function Update Magnitude: 0.23368

Collected Steps per Second: 10382.24641
Overall Steps per Second: 7238.23999

Timestep Collection Time: 4.82006
Timestep Consumption Time: 2.09364
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 6.91370

Cumulative Model Updates: 36984
Cumulative Timesteps: 308754575

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.74841
Policy Entropy: 1.31336
Value Function Loss: 0.02291

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.11132
Value Function Update Magnitude: 0.22419

Collected Steps per Second: 9874.71814
Overall Steps per Second: 7089.81921

Timestep Collection Time: 5.06627
Timestep Consumption Time: 1.99004
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.05632

Cumulative Model Updates: 36990
Cumulative Timesteps: 308804603

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 308804603...
Checkpoint 308804603 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.26270
Policy Entropy: 1.31503
Value Function Loss: 0.02369

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.11324
Value Function Update Magnitude: 0.21742

Collected Steps per Second: 9897.40658
Overall Steps per Second: 7044.50184

Timestep Collection Time: 5.05516
Timestep Consumption Time: 2.04726
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 7.10242

Cumulative Model Updates: 36996
Cumulative Timesteps: 308854636

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.65988
Policy Entropy: 1.31735
Value Function Loss: 0.02325

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.07073
Policy Update Magnitude: 0.11948
Value Function Update Magnitude: 0.22108

Collected Steps per Second: 10273.82366
Overall Steps per Second: 7202.30946

Timestep Collection Time: 4.86898
Timestep Consumption Time: 2.07644
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 6.94541

Cumulative Model Updates: 37002
Cumulative Timesteps: 308904659

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.86911
Policy Entropy: 1.31599
Value Function Loss: 0.02315

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.11984
Value Function Update Magnitude: 0.22762

Collected Steps per Second: 9904.28983
Overall Steps per Second: 7051.49853

Timestep Collection Time: 5.05215
Timestep Consumption Time: 2.04393
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.09608

Cumulative Model Updates: 37008
Cumulative Timesteps: 308954697

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.26514
Policy Entropy: 1.31367
Value Function Loss: 0.02274

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.11634
Value Function Update Magnitude: 0.21108

Collected Steps per Second: 9632.48140
Overall Steps per Second: 6933.78055

Timestep Collection Time: 5.19326
Timestep Consumption Time: 2.02127
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.21453

Cumulative Model Updates: 37014
Cumulative Timesteps: 309004721

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.25101
Policy Entropy: 1.31365
Value Function Loss: 0.02284

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.11792
Value Function Update Magnitude: 0.21655

Collected Steps per Second: 10375.95807
Overall Steps per Second: 7246.35051

Timestep Collection Time: 4.82298
Timestep Consumption Time: 2.08298
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 6.90596

Cumulative Model Updates: 37020
Cumulative Timesteps: 309054764

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.75044
Policy Entropy: 1.31411
Value Function Loss: 0.02236

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.11592
Value Function Update Magnitude: 0.22885

Collected Steps per Second: 10079.42074
Overall Steps per Second: 7123.28039

Timestep Collection Time: 4.96120
Timestep Consumption Time: 2.05888
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.02008

Cumulative Model Updates: 37026
Cumulative Timesteps: 309104770

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.58707
Policy Entropy: 1.31485
Value Function Loss: 0.02303

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.11441
Value Function Update Magnitude: 0.22053

Collected Steps per Second: 9814.44250
Overall Steps per Second: 7012.51194

Timestep Collection Time: 5.09565
Timestep Consumption Time: 2.03603
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 7.13168

Cumulative Model Updates: 37032
Cumulative Timesteps: 309154781

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.70740
Policy Entropy: 1.31510
Value Function Loss: 0.02320

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.06963
Policy Update Magnitude: 0.11474
Value Function Update Magnitude: 0.20856

Collected Steps per Second: 10365.53164
Overall Steps per Second: 7234.92941

Timestep Collection Time: 4.82397
Timestep Consumption Time: 2.08736
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 6.91133

Cumulative Model Updates: 37038
Cumulative Timesteps: 309204784

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.46752
Policy Entropy: 1.31205
Value Function Loss: 0.02231

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.11364
Value Function Update Magnitude: 0.20087

Collected Steps per Second: 9873.59368
Overall Steps per Second: 6987.49507

Timestep Collection Time: 5.06634
Timestep Consumption Time: 2.09259
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.15893

Cumulative Model Updates: 37044
Cumulative Timesteps: 309254807

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.67303
Policy Entropy: 1.31220
Value Function Loss: 0.02251

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.11160
Value Function Update Magnitude: 0.19798

Collected Steps per Second: 9608.92677
Overall Steps per Second: 6869.64679

Timestep Collection Time: 5.20349
Timestep Consumption Time: 2.07490
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 7.27839

Cumulative Model Updates: 37050
Cumulative Timesteps: 309304807

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 309304807...
Checkpoint 309304807 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.05605
Policy Entropy: 1.31016
Value Function Loss: 0.02230

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.11306
Value Function Update Magnitude: 0.20187

Collected Steps per Second: 10328.94703
Overall Steps per Second: 7240.76045

Timestep Collection Time: 4.84270
Timestep Consumption Time: 2.06541
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 6.90811

Cumulative Model Updates: 37056
Cumulative Timesteps: 309354827

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.92201
Policy Entropy: 1.30815
Value Function Loss: 0.02285

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06924
Policy Update Magnitude: 0.11415
Value Function Update Magnitude: 0.21045

Collected Steps per Second: 10121.85989
Overall Steps per Second: 7131.13114

Timestep Collection Time: 4.94129
Timestep Consumption Time: 2.07233
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.01361

Cumulative Model Updates: 37062
Cumulative Timesteps: 309404842

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.73830
Policy Entropy: 1.29956
Value Function Loss: 0.02062

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.11399
Value Function Update Magnitude: 0.20906

Collected Steps per Second: 9840.18193
Overall Steps per Second: 6942.43268

Timestep Collection Time: 5.08365
Timestep Consumption Time: 2.12190
PPO Batch Consumption Time: 0.02965
Total Iteration Time: 7.20554

Cumulative Model Updates: 37068
Cumulative Timesteps: 309454866

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.63750
Policy Entropy: 1.30586
Value Function Loss: 0.02144

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.11298
Value Function Update Magnitude: 0.20407

Collected Steps per Second: 10393.73764
Overall Steps per Second: 7367.56157

Timestep Collection Time: 4.81155
Timestep Consumption Time: 1.97631
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 6.78786

Cumulative Model Updates: 37074
Cumulative Timesteps: 309504876

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.79157
Policy Entropy: 1.30573
Value Function Loss: 0.02140

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.11490
Value Function Update Magnitude: 0.20611

Collected Steps per Second: 10016.10376
Overall Steps per Second: 6993.72234

Timestep Collection Time: 4.99595
Timestep Consumption Time: 2.15903
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 7.15499

Cumulative Model Updates: 37080
Cumulative Timesteps: 309554916

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.02945
Policy Entropy: 1.30560
Value Function Loss: 0.02222

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.11377
Value Function Update Magnitude: 0.20403

Collected Steps per Second: 9773.22392
Overall Steps per Second: 6989.66078

Timestep Collection Time: 5.12011
Timestep Consumption Time: 2.03903
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.15915

Cumulative Model Updates: 37086
Cumulative Timesteps: 309604956

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.70897
Policy Entropy: 1.30510
Value Function Loss: 0.02177

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.11750
Value Function Update Magnitude: 0.19955

Collected Steps per Second: 10295.89799
Overall Steps per Second: 7190.61887

Timestep Collection Time: 4.85630
Timestep Consumption Time: 2.09720
PPO Batch Consumption Time: 0.03049
Total Iteration Time: 6.95350

Cumulative Model Updates: 37092
Cumulative Timesteps: 309654956

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.57088
Policy Entropy: 1.31017
Value Function Loss: 0.02342

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.11886
Value Function Update Magnitude: 0.20770

Collected Steps per Second: 9773.68265
Overall Steps per Second: 6920.19385

Timestep Collection Time: 5.11997
Timestep Consumption Time: 2.11118
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.23116

Cumulative Model Updates: 37098
Cumulative Timesteps: 309704997

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.95774
Policy Entropy: 1.30337
Value Function Loss: 0.02308

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.11870
Value Function Update Magnitude: 0.21640

Collected Steps per Second: 9698.39416
Overall Steps per Second: 6976.73843

Timestep Collection Time: 5.15766
Timestep Consumption Time: 2.01202
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.16968

Cumulative Model Updates: 37104
Cumulative Timesteps: 309755018

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.19816
Policy Entropy: 1.30215
Value Function Loss: 0.02292

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.11729
Value Function Update Magnitude: 0.21177

Collected Steps per Second: 10367.43419
Overall Steps per Second: 7228.26176

Timestep Collection Time: 4.82443
Timestep Consumption Time: 2.09521
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 6.91964

Cumulative Model Updates: 37110
Cumulative Timesteps: 309805035

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 309805035...
Checkpoint 309805035 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.60293
Policy Entropy: 1.30087
Value Function Loss: 0.02243

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.11629
Value Function Update Magnitude: 0.21025

Collected Steps per Second: 9876.05644
Overall Steps per Second: 7043.94296

Timestep Collection Time: 5.06457
Timestep Consumption Time: 2.03628
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.10085

Cumulative Model Updates: 37116
Cumulative Timesteps: 309855053

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.42024
Policy Entropy: 1.30415
Value Function Loss: 0.02338

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.07458
Policy Update Magnitude: 0.11416
Value Function Update Magnitude: 0.21996

Collected Steps per Second: 9758.33501
Overall Steps per Second: 6937.30997

Timestep Collection Time: 5.12516
Timestep Consumption Time: 2.08412
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 7.20928

Cumulative Model Updates: 37122
Cumulative Timesteps: 309905066

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.90682
Policy Entropy: 1.29749
Value Function Loss: 0.02497

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.11706
Value Function Update Magnitude: 0.22013

Collected Steps per Second: 10296.35127
Overall Steps per Second: 7171.39045

Timestep Collection Time: 4.85871
Timestep Consumption Time: 2.11720
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 6.97591

Cumulative Model Updates: 37128
Cumulative Timesteps: 309955093

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.93119
Policy Entropy: 1.29872
Value Function Loss: 0.02367

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.11950
Value Function Update Magnitude: 0.21907

Collected Steps per Second: 9968.63963
Overall Steps per Second: 6971.22160

Timestep Collection Time: 5.01754
Timestep Consumption Time: 2.15739
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 7.17493

Cumulative Model Updates: 37134
Cumulative Timesteps: 310005111

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.86076
Policy Entropy: 1.29999
Value Function Loss: 0.02269

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.11419
Value Function Update Magnitude: 0.22549

Collected Steps per Second: 9630.11203
Overall Steps per Second: 6875.24036

Timestep Collection Time: 5.19620
Timestep Consumption Time: 2.08209
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.27829

Cumulative Model Updates: 37140
Cumulative Timesteps: 310055151

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.59663
Policy Entropy: 1.31177
Value Function Loss: 0.02250

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.06490
Policy Update Magnitude: 0.11324
Value Function Update Magnitude: 0.21421

Collected Steps per Second: 10372.47647
Overall Steps per Second: 7242.10384

Timestep Collection Time: 4.82238
Timestep Consumption Time: 2.08445
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 6.90683

Cumulative Model Updates: 37146
Cumulative Timesteps: 310105171

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.62435
Policy Entropy: 1.30463
Value Function Loss: 0.02330

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.07206
Policy Update Magnitude: 0.11547
Value Function Update Magnitude: 0.20973

Collected Steps per Second: 9828.21522
Overall Steps per Second: 6965.22548

Timestep Collection Time: 5.09024
Timestep Consumption Time: 2.09230
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 7.18254

Cumulative Model Updates: 37152
Cumulative Timesteps: 310155199

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.24101
Policy Entropy: 1.30204
Value Function Loss: 0.02372

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.11998
Value Function Update Magnitude: 0.20472

Collected Steps per Second: 9886.15160
Overall Steps per Second: 7016.59812

Timestep Collection Time: 5.05910
Timestep Consumption Time: 2.06900
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 7.12810

Cumulative Model Updates: 37158
Cumulative Timesteps: 310205214

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.04052
Policy Entropy: 1.29146
Value Function Loss: 0.02171

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.11347
Value Function Update Magnitude: 0.19964

Collected Steps per Second: 10647.86358
Overall Steps per Second: 7364.49897

Timestep Collection Time: 4.70000
Timestep Consumption Time: 2.09543
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 6.79544

Cumulative Model Updates: 37164
Cumulative Timesteps: 310255259

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.02346
Policy Entropy: 1.29224
Value Function Loss: 0.02260

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.11527
Value Function Update Magnitude: 0.19478

Collected Steps per Second: 9864.15483
Overall Steps per Second: 7044.48860

Timestep Collection Time: 5.07220
Timestep Consumption Time: 2.03023
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 7.10243

Cumulative Model Updates: 37170
Cumulative Timesteps: 310305292

Timesteps Collected: 50033
--------END ITERATION REPORT--------


Saving checkpoint 310305292...
Checkpoint 310305292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.38579
Policy Entropy: 1.29446
Value Function Loss: 0.02174

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.11514
Value Function Update Magnitude: 0.19424

Collected Steps per Second: 9702.79061
Overall Steps per Second: 6939.48542

Timestep Collection Time: 5.15645
Timestep Consumption Time: 2.05330
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.20976

Cumulative Model Updates: 37176
Cumulative Timesteps: 310355324

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.50832
Policy Entropy: 1.29058
Value Function Loss: 0.02303

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.11904
Value Function Update Magnitude: 0.19120

Collected Steps per Second: 10376.25634
Overall Steps per Second: 7158.35159

Timestep Collection Time: 4.81869
Timestep Consumption Time: 2.16615
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 6.98485

Cumulative Model Updates: 37182
Cumulative Timesteps: 310405324

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.22546
Policy Entropy: 1.28967
Value Function Loss: 0.02253

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.11619
Value Function Update Magnitude: 0.18690

Collected Steps per Second: 9918.93316
Overall Steps per Second: 6980.99743

Timestep Collection Time: 5.04349
Timestep Consumption Time: 2.12254
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 7.16602

Cumulative Model Updates: 37188
Cumulative Timesteps: 310455350

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.23661
Policy Entropy: 1.28617
Value Function Loss: 0.02355

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.11844
Value Function Update Magnitude: 0.18824

Collected Steps per Second: 9688.29679
Overall Steps per Second: 6928.84734

Timestep Collection Time: 5.16396
Timestep Consumption Time: 2.05657
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 7.22054

Cumulative Model Updates: 37194
Cumulative Timesteps: 310505380

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.63106
Policy Entropy: 1.28310
Value Function Loss: 0.02390

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.11936
Value Function Update Magnitude: 0.19476

Collected Steps per Second: 10350.55658
Overall Steps per Second: 7174.79227

Timestep Collection Time: 4.83191
Timestep Consumption Time: 2.13874
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 6.97065

Cumulative Model Updates: 37200
Cumulative Timesteps: 310555393

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.96804
Policy Entropy: 1.28056
Value Function Loss: 0.02351

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.11938
Value Function Update Magnitude: 0.19407

Collected Steps per Second: 9838.93234
Overall Steps per Second: 5187.35142

Timestep Collection Time: 5.08419
Timestep Consumption Time: 4.55907
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 9.64326

Cumulative Model Updates: 37206
Cumulative Timesteps: 310605416

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.14975
Policy Entropy: 1.27508
Value Function Loss: 0.02384

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.11752
Value Function Update Magnitude: 0.20188

Collected Steps per Second: 9865.71610
Overall Steps per Second: 7032.51906

Timestep Collection Time: 5.06856
Timestep Consumption Time: 2.04198
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 7.11054

Cumulative Model Updates: 37212
Cumulative Timesteps: 310655421

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.07585
Policy Entropy: 1.28051
Value Function Loss: 0.02313

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.11830
Value Function Update Magnitude: 0.20398

Collected Steps per Second: 10494.09219
Overall Steps per Second: 7273.73726

Timestep Collection Time: 4.76706
Timestep Consumption Time: 2.11056
PPO Batch Consumption Time: 0.02902
Total Iteration Time: 6.87762

Cumulative Model Updates: 37218
Cumulative Timesteps: 310705447

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.63782
Policy Entropy: 1.28363
Value Function Loss: 0.02348

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.11964
Value Function Update Magnitude: 0.21002

Collected Steps per Second: 9785.93942
Overall Steps per Second: 7024.27769

Timestep Collection Time: 5.11142
Timestep Consumption Time: 2.00960
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.12102

Cumulative Model Updates: 37224
Cumulative Timesteps: 310755467

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.59702
Policy Entropy: 1.29000
Value Function Loss: 0.02325

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.11717
Value Function Update Magnitude: 0.20500

Collected Steps per Second: 9731.76774
Overall Steps per Second: 6979.16796

Timestep Collection Time: 5.13905
Timestep Consumption Time: 2.02685
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 7.16590

Cumulative Model Updates: 37230
Cumulative Timesteps: 310805479

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 310805479...
Checkpoint 310805479 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.95913
Policy Entropy: 1.29262
Value Function Loss: 0.02276

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.11650
Value Function Update Magnitude: 0.21074

Collected Steps per Second: 10578.34599
Overall Steps per Second: 7328.37492

Timestep Collection Time: 4.72891
Timestep Consumption Time: 2.09716
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 6.82607

Cumulative Model Updates: 37236
Cumulative Timesteps: 310855503

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.04720
Policy Entropy: 1.29138
Value Function Loss: 0.02323

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.11477
Value Function Update Magnitude: 0.21270

Collected Steps per Second: 10036.71413
Overall Steps per Second: 7158.89449

Timestep Collection Time: 4.98291
Timestep Consumption Time: 2.00309
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 6.98599

Cumulative Model Updates: 37242
Cumulative Timesteps: 310905515

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.87703
Policy Entropy: 1.28456
Value Function Loss: 0.02281

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.11695
Value Function Update Magnitude: 0.21506

Collected Steps per Second: 8886.58338
Overall Steps per Second: 6408.47568

Timestep Collection Time: 5.63051
Timestep Consumption Time: 2.17727
PPO Batch Consumption Time: 0.02995
Total Iteration Time: 7.80778

Cumulative Model Updates: 37248
Cumulative Timesteps: 310955551

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.33450
Policy Entropy: 1.28363
Value Function Loss: 0.02401

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.11762
Value Function Update Magnitude: 0.23267

Collected Steps per Second: 9761.56328
Overall Steps per Second: 6924.36724

Timestep Collection Time: 5.12541
Timestep Consumption Time: 2.10009
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.22550

Cumulative Model Updates: 37254
Cumulative Timesteps: 311005583

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.25887
Policy Entropy: 1.27881
Value Function Loss: 0.02327

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.11751
Value Function Update Magnitude: 0.23500

Collected Steps per Second: 9875.49101
Overall Steps per Second: 7014.09857

Timestep Collection Time: 5.06638
Timestep Consumption Time: 2.06682
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 7.13320

Cumulative Model Updates: 37260
Cumulative Timesteps: 311055616

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.44667
Policy Entropy: 1.28573
Value Function Loss: 0.02356

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.12079
Value Function Update Magnitude: 0.24741

Collected Steps per Second: 8942.79483
Overall Steps per Second: 6399.75741

Timestep Collection Time: 5.59143
Timestep Consumption Time: 2.22184
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.81326

Cumulative Model Updates: 37266
Cumulative Timesteps: 311105619

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.26873
Policy Entropy: 1.28602
Value Function Loss: 0.02229

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.11596
Value Function Update Magnitude: 0.24640

Collected Steps per Second: 9717.50597
Overall Steps per Second: 6807.41889

Timestep Collection Time: 5.14834
Timestep Consumption Time: 2.20085
PPO Batch Consumption Time: 0.03087
Total Iteration Time: 7.34919

Cumulative Model Updates: 37272
Cumulative Timesteps: 311155648

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.72525
Policy Entropy: 1.28289
Value Function Loss: 0.02272

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.11390
Value Function Update Magnitude: 0.23361

Collected Steps per Second: 9471.60635
Overall Steps per Second: 6665.10175

Timestep Collection Time: 5.28390
Timestep Consumption Time: 2.22491
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 7.50881

Cumulative Model Updates: 37278
Cumulative Timesteps: 311205695

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.09102
Policy Entropy: 1.27779
Value Function Loss: 0.02315

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.11388
Value Function Update Magnitude: 0.23566

Collected Steps per Second: 8932.38948
Overall Steps per Second: 6382.89613

Timestep Collection Time: 5.60096
Timestep Consumption Time: 2.23717
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 7.83813

Cumulative Model Updates: 37284
Cumulative Timesteps: 311255725

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.63903
Policy Entropy: 1.27511
Value Function Loss: 0.02313

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.11598
Value Function Update Magnitude: 0.22141

Collected Steps per Second: 10401.48133
Overall Steps per Second: 7100.58520

Timestep Collection Time: 4.80787
Timestep Consumption Time: 2.23507
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 7.04294

Cumulative Model Updates: 37290
Cumulative Timesteps: 311305734

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 311305734...
Checkpoint 311305734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.02773
Policy Entropy: 1.27781
Value Function Loss: 0.02342

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.11897
Value Function Update Magnitude: 0.22614

Collected Steps per Second: 10186.55372
Overall Steps per Second: 6893.96193

Timestep Collection Time: 4.91226
Timestep Consumption Time: 2.34612
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 7.25838

Cumulative Model Updates: 37296
Cumulative Timesteps: 311355773

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.63093
Policy Entropy: 1.28040
Value Function Loss: 0.02333

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.12088
Value Function Update Magnitude: 0.22772

Collected Steps per Second: 8963.84185
Overall Steps per Second: 6403.34054

Timestep Collection Time: 5.57808
Timestep Consumption Time: 2.23050
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 7.80858

Cumulative Model Updates: 37302
Cumulative Timesteps: 311405774

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.54371
Policy Entropy: 1.28116
Value Function Loss: 0.02252

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.11725
Value Function Update Magnitude: 0.22250

Collected Steps per Second: 10482.61701
Overall Steps per Second: 7134.26076

Timestep Collection Time: 4.77047
Timestep Consumption Time: 2.23895
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 7.00942

Cumulative Model Updates: 37308
Cumulative Timesteps: 311455781

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.36179
Policy Entropy: 1.28334
Value Function Loss: 0.02312

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.11626
Value Function Update Magnitude: 0.22126

Collected Steps per Second: 10614.16658
Overall Steps per Second: 7515.30142

Timestep Collection Time: 4.71248
Timestep Consumption Time: 1.94315
PPO Batch Consumption Time: 0.02351
Total Iteration Time: 6.65562

Cumulative Model Updates: 37314
Cumulative Timesteps: 311505800

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.58308
Policy Entropy: 1.28691
Value Function Loss: 0.02310

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.11523
Value Function Update Magnitude: 0.21965

Collected Steps per Second: 9939.32821
Overall Steps per Second: 7171.74446

Timestep Collection Time: 5.03444
Timestep Consumption Time: 1.94280
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 6.97724

Cumulative Model Updates: 37320
Cumulative Timesteps: 311555839

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.19836
Policy Entropy: 1.29067
Value Function Loss: 0.02447

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07222
Policy Update Magnitude: 0.11645
Value Function Update Magnitude: 0.22517

Collected Steps per Second: 10287.15644
Overall Steps per Second: 7260.30827

Timestep Collection Time: 4.86393
Timestep Consumption Time: 2.02779
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 6.89172

Cumulative Model Updates: 37326
Cumulative Timesteps: 311605875

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.89336
Policy Entropy: 1.28797
Value Function Loss: 0.02356

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.11482
Value Function Update Magnitude: 0.23582

Collected Steps per Second: 10283.45806
Overall Steps per Second: 7340.36917

Timestep Collection Time: 4.86539
Timestep Consumption Time: 1.95076
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 6.81614

Cumulative Model Updates: 37332
Cumulative Timesteps: 311655908

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.74439
Policy Entropy: 1.28665
Value Function Loss: 0.02301

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.11391
Value Function Update Magnitude: 0.24086

Collected Steps per Second: 9945.84769
Overall Steps per Second: 7172.64788

Timestep Collection Time: 5.02974
Timestep Consumption Time: 1.94467
PPO Batch Consumption Time: 0.02468
Total Iteration Time: 6.97441

Cumulative Model Updates: 37338
Cumulative Timesteps: 311705933

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.43883
Policy Entropy: 1.28368
Value Function Loss: 0.02263

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.11514
Value Function Update Magnitude: 0.23929

Collected Steps per Second: 10668.75810
Overall Steps per Second: 7518.88002

Timestep Collection Time: 4.68827
Timestep Consumption Time: 1.96405
PPO Batch Consumption Time: 0.02450
Total Iteration Time: 6.65232

Cumulative Model Updates: 37344
Cumulative Timesteps: 311755951

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.12686
Policy Entropy: 1.27728
Value Function Loss: 0.02306

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.11742
Value Function Update Magnitude: 0.23632

Collected Steps per Second: 9988.15978
Overall Steps per Second: 7172.43987

Timestep Collection Time: 5.00823
Timestep Consumption Time: 1.96611
PPO Batch Consumption Time: 0.02425
Total Iteration Time: 6.97434

Cumulative Model Updates: 37350
Cumulative Timesteps: 311805974

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 311805974...
Checkpoint 311805974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.53871
Policy Entropy: 1.27457
Value Function Loss: 0.02286

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.11940
Value Function Update Magnitude: 0.22154

Collected Steps per Second: 9877.26259
Overall Steps per Second: 7081.78258

Timestep Collection Time: 5.06476
Timestep Consumption Time: 1.99928
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 7.06404

Cumulative Model Updates: 37356
Cumulative Timesteps: 311856000

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.87641
Policy Entropy: 1.27151
Value Function Loss: 0.02282

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.12095
Value Function Update Magnitude: 0.21295

Collected Steps per Second: 10001.57730
Overall Steps per Second: 6953.35497

Timestep Collection Time: 5.00071
Timestep Consumption Time: 2.19222
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.19293

Cumulative Model Updates: 37362
Cumulative Timesteps: 311906015

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.00631
Policy Entropy: 1.27412
Value Function Loss: 0.02245

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.11760
Value Function Update Magnitude: 0.20907

Collected Steps per Second: 10208.13103
Overall Steps per Second: 6913.28968

Timestep Collection Time: 4.90080
Timestep Consumption Time: 2.33570
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 7.23650

Cumulative Model Updates: 37368
Cumulative Timesteps: 311956043

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.51727
Policy Entropy: 1.27345
Value Function Loss: 0.02375

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.12136
Value Function Update Magnitude: 0.20603

Collected Steps per Second: 9425.50449
Overall Steps per Second: 6880.72554

Timestep Collection Time: 5.30900
Timestep Consumption Time: 1.96349
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 7.27249

Cumulative Model Updates: 37374
Cumulative Timesteps: 312006083

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.91086
Policy Entropy: 1.27384
Value Function Loss: 0.02307

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.11884
Value Function Update Magnitude: 0.20806

Collected Steps per Second: 10352.97724
Overall Steps per Second: 7221.83799

Timestep Collection Time: 4.83407
Timestep Consumption Time: 2.09588
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 6.92995

Cumulative Model Updates: 37380
Cumulative Timesteps: 312056130

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.73008
Policy Entropy: 1.26961
Value Function Loss: 0.02334

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.12225
Value Function Update Magnitude: 0.20543

Collected Steps per Second: 9280.53928
Overall Steps per Second: 6690.89518

Timestep Collection Time: 5.39117
Timestep Consumption Time: 2.08660
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 7.47777

Cumulative Model Updates: 37386
Cumulative Timesteps: 312106163

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.59927
Policy Entropy: 1.26399
Value Function Loss: 0.02281

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.12076
Value Function Update Magnitude: 0.20742

Collected Steps per Second: 9332.38159
Overall Steps per Second: 6795.18152

Timestep Collection Time: 5.36198
Timestep Consumption Time: 2.00207
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.36404

Cumulative Model Updates: 37392
Cumulative Timesteps: 312156203

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.59636
Policy Entropy: 1.26308
Value Function Loss: 0.02388

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.12098
Value Function Update Magnitude: 0.21093

Collected Steps per Second: 9852.32823
Overall Steps per Second: 6876.38832

Timestep Collection Time: 5.07839
Timestep Consumption Time: 2.19781
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 7.27620

Cumulative Model Updates: 37398
Cumulative Timesteps: 312206237

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.40441
Policy Entropy: 1.25891
Value Function Loss: 0.02399

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.12116
Value Function Update Magnitude: 0.22199

Collected Steps per Second: 9439.81793
Overall Steps per Second: 6626.02473

Timestep Collection Time: 5.30106
Timestep Consumption Time: 2.25113
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 7.55219

Cumulative Model Updates: 37404
Cumulative Timesteps: 312256278

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.03346
Policy Entropy: 1.26048
Value Function Loss: 0.02483

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.12186
Value Function Update Magnitude: 0.23556

Collected Steps per Second: 9231.78346
Overall Steps per Second: 6715.78779

Timestep Collection Time: 5.41856
Timestep Consumption Time: 2.03000
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 7.44857

Cumulative Model Updates: 37410
Cumulative Timesteps: 312306301

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 312306301...
Checkpoint 312306301 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.41226
Policy Entropy: 1.26198
Value Function Loss: 0.02480

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.11903
Value Function Update Magnitude: 0.25441

Collected Steps per Second: 9823.43832
Overall Steps per Second: 7015.06599

Timestep Collection Time: 5.09262
Timestep Consumption Time: 2.03875
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 7.13137

Cumulative Model Updates: 37416
Cumulative Timesteps: 312356328

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.30594
Policy Entropy: 1.27463
Value Function Loss: 0.02447

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.12039
Value Function Update Magnitude: 0.25184

Collected Steps per Second: 8985.92687
Overall Steps per Second: 6491.23958

Timestep Collection Time: 5.56926
Timestep Consumption Time: 2.14036
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 7.70962

Cumulative Model Updates: 37422
Cumulative Timesteps: 312406373

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.43005
Policy Entropy: 1.27284
Value Function Loss: 0.02338

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.12158
Value Function Update Magnitude: 0.23245

Collected Steps per Second: 9397.26105
Overall Steps per Second: 6885.78629

Timestep Collection Time: 5.32517
Timestep Consumption Time: 1.94227
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 7.26743

Cumulative Model Updates: 37428
Cumulative Timesteps: 312456415

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.59633
Policy Entropy: 1.27578
Value Function Loss: 0.02346

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.12124
Value Function Update Magnitude: 0.22667

Collected Steps per Second: 10550.64424
Overall Steps per Second: 7429.76398

Timestep Collection Time: 4.74170
Timestep Consumption Time: 1.99176
PPO Batch Consumption Time: 0.02407
Total Iteration Time: 6.73346

Cumulative Model Updates: 37434
Cumulative Timesteps: 312506443

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.81057
Policy Entropy: 1.27222
Value Function Loss: 0.02393

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.12002
Value Function Update Magnitude: 0.22482

Collected Steps per Second: 9989.90497
Overall Steps per Second: 7232.92404

Timestep Collection Time: 5.00836
Timestep Consumption Time: 1.90904
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 6.91740

Cumulative Model Updates: 37440
Cumulative Timesteps: 312556476

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.64461
Policy Entropy: 1.27049
Value Function Loss: 0.02413

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.11955
Value Function Update Magnitude: 0.23127

Collected Steps per Second: 9949.70303
Overall Steps per Second: 7174.74404

Timestep Collection Time: 5.02940
Timestep Consumption Time: 1.94521
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 6.97460

Cumulative Model Updates: 37446
Cumulative Timesteps: 312606517

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.29798
Policy Entropy: 1.27156
Value Function Loss: 0.02382

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.11851
Value Function Update Magnitude: 0.22348

Collected Steps per Second: 9789.40641
Overall Steps per Second: 6834.11982

Timestep Collection Time: 5.11114
Timestep Consumption Time: 2.21022
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 7.32135

Cumulative Model Updates: 37452
Cumulative Timesteps: 312656552

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.30844
Policy Entropy: 1.27058
Value Function Loss: 0.02427

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.11855
Value Function Update Magnitude: 0.21995

Collected Steps per Second: 8886.38776
Overall Steps per Second: 6304.83414

Timestep Collection Time: 5.62940
Timestep Consumption Time: 2.30499
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.93439

Cumulative Model Updates: 37458
Cumulative Timesteps: 312706577

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.40844
Policy Entropy: 1.27280
Value Function Loss: 0.02380

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.11963
Value Function Update Magnitude: 0.22309

Collected Steps per Second: 9075.51263
Overall Steps per Second: 6609.76209

Timestep Collection Time: 5.50977
Timestep Consumption Time: 2.05540
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.56517

Cumulative Model Updates: 37464
Cumulative Timesteps: 312756581

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.28269
Policy Entropy: 1.26956
Value Function Loss: 0.02332

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.12066
Value Function Update Magnitude: 0.21473

Collected Steps per Second: 9747.18340
Overall Steps per Second: 6728.95686

Timestep Collection Time: 5.13205
Timestep Consumption Time: 2.30194
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 7.43399

Cumulative Model Updates: 37470
Cumulative Timesteps: 312806604

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 312806604...
Checkpoint 312806604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.87707
Policy Entropy: 1.27660
Value Function Loss: 0.02309

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.11980
Value Function Update Magnitude: 0.21154

Collected Steps per Second: 8863.35354
Overall Steps per Second: 6342.84086

Timestep Collection Time: 5.64256
Timestep Consumption Time: 2.24224
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.88480

Cumulative Model Updates: 37476
Cumulative Timesteps: 312856616

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.56343
Policy Entropy: 1.27889
Value Function Loss: 0.02260

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.12072
Value Function Update Magnitude: 0.21477

Collected Steps per Second: 9165.86897
Overall Steps per Second: 6580.51068

Timestep Collection Time: 5.45971
Timestep Consumption Time: 2.14502
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.60473

Cumulative Model Updates: 37482
Cumulative Timesteps: 312906659

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.03954
Policy Entropy: 1.26812
Value Function Loss: 0.02255

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.11843
Value Function Update Magnitude: 0.20610

Collected Steps per Second: 9264.51372
Overall Steps per Second: 6490.26181

Timestep Collection Time: 5.39845
Timestep Consumption Time: 2.30756
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 7.70601

Cumulative Model Updates: 37488
Cumulative Timesteps: 312956673

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.74525
Policy Entropy: 1.26802
Value Function Loss: 0.02207

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.11606
Value Function Update Magnitude: 0.20067

Collected Steps per Second: 9480.72783
Overall Steps per Second: 6781.32223

Timestep Collection Time: 5.27829
Timestep Consumption Time: 2.10110
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.37939

Cumulative Model Updates: 37494
Cumulative Timesteps: 313006715

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.33462
Policy Entropy: 1.26680
Value Function Loss: 0.02221

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.11838
Value Function Update Magnitude: 0.20559

Collected Steps per Second: 9521.92349
Overall Steps per Second: 6757.18795

Timestep Collection Time: 5.25545
Timestep Consumption Time: 2.15029
PPO Batch Consumption Time: 0.02948
Total Iteration Time: 7.40574

Cumulative Model Updates: 37500
Cumulative Timesteps: 313056757

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.52364
Policy Entropy: 1.27689
Value Function Loss: 0.02216

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.11882
Value Function Update Magnitude: 0.20980

Collected Steps per Second: 9499.43281
Overall Steps per Second: 6600.40193

Timestep Collection Time: 5.26505
Timestep Consumption Time: 2.31252
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.57757

Cumulative Model Updates: 37506
Cumulative Timesteps: 313106772

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.27745
Policy Entropy: 1.27242
Value Function Loss: 0.02371

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07248
Policy Update Magnitude: 0.11880
Value Function Update Magnitude: 0.21718

Collected Steps per Second: 9148.45886
Overall Steps per Second: 6556.54943

Timestep Collection Time: 5.47010
Timestep Consumption Time: 2.16242
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 7.63252

Cumulative Model Updates: 37512
Cumulative Timesteps: 313156815

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.74946
Policy Entropy: 1.27608
Value Function Loss: 0.02420

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.12415
Value Function Update Magnitude: 0.22461

Collected Steps per Second: 9549.86835
Overall Steps per Second: 6839.39415

Timestep Collection Time: 5.23651
Timestep Consumption Time: 2.07525
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 7.31176

Cumulative Model Updates: 37518
Cumulative Timesteps: 313206823

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.82729
Policy Entropy: 1.27348
Value Function Loss: 0.02449

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.12027
Value Function Update Magnitude: 0.22274

Collected Steps per Second: 10566.44135
Overall Steps per Second: 7289.02472

Timestep Collection Time: 4.73613
Timestep Consumption Time: 2.12954
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 6.86566

Cumulative Model Updates: 37524
Cumulative Timesteps: 313256867

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.30173
Policy Entropy: 1.27647
Value Function Loss: 0.02356

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.11709
Value Function Update Magnitude: 0.21030

Collected Steps per Second: 9898.17218
Overall Steps per Second: 7132.82361

Timestep Collection Time: 5.05225
Timestep Consumption Time: 1.95872
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.01097

Cumulative Model Updates: 37530
Cumulative Timesteps: 313306875

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 313306875...
Checkpoint 313306875 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.39195
Policy Entropy: 1.27351
Value Function Loss: 0.02357

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.11568
Value Function Update Magnitude: 0.20486

Collected Steps per Second: 10025.07965
Overall Steps per Second: 7177.52552

Timestep Collection Time: 4.99009
Timestep Consumption Time: 1.97973
PPO Batch Consumption Time: 0.02539
Total Iteration Time: 6.96981

Cumulative Model Updates: 37536
Cumulative Timesteps: 313356901

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.10191
Policy Entropy: 1.27584
Value Function Loss: 0.02326

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.11866
Value Function Update Magnitude: 0.21200

Collected Steps per Second: 10118.83229
Overall Steps per Second: 7171.50817

Timestep Collection Time: 4.94415
Timestep Consumption Time: 2.03193
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 6.97608

Cumulative Model Updates: 37542
Cumulative Timesteps: 313406930

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.36783
Policy Entropy: 1.27924
Value Function Loss: 0.02308

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.07712
Policy Update Magnitude: 0.11957
Value Function Update Magnitude: 0.20849

Collected Steps per Second: 9965.56230
Overall Steps per Second: 7198.99412

Timestep Collection Time: 5.01848
Timestep Consumption Time: 1.92860
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 6.94708

Cumulative Model Updates: 37548
Cumulative Timesteps: 313456942

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.83644
Policy Entropy: 1.28628
Value Function Loss: 0.02305

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.12106
Value Function Update Magnitude: 0.20243

Collected Steps per Second: 9694.55376
Overall Steps per Second: 6966.59003

Timestep Collection Time: 5.16125
Timestep Consumption Time: 2.02103
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.18228

Cumulative Model Updates: 37554
Cumulative Timesteps: 313506978

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.94361
Policy Entropy: 1.28956
Value Function Loss: 0.02314

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.06453
Policy Update Magnitude: 0.12023
Value Function Update Magnitude: 0.20172

Collected Steps per Second: 11127.46138
Overall Steps per Second: 7642.04334

Timestep Collection Time: 4.49590
Timestep Consumption Time: 2.05051
PPO Batch Consumption Time: 0.03490
Total Iteration Time: 6.54642

Cumulative Model Updates: 37560
Cumulative Timesteps: 313557006

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.21120
Policy Entropy: 1.29110
Value Function Loss: 0.02233

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.11902
Value Function Update Magnitude: 0.20447

Collected Steps per Second: 9698.09486
Overall Steps per Second: 6817.74837

Timestep Collection Time: 5.15936
Timestep Consumption Time: 2.17972
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 7.33908

Cumulative Model Updates: 37566
Cumulative Timesteps: 313607042

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.45488
Policy Entropy: 1.29613
Value Function Loss: 0.02170

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.11455
Value Function Update Magnitude: 0.20480

Collected Steps per Second: 9405.25769
Overall Steps per Second: 6807.20703

Timestep Collection Time: 5.32064
Timestep Consumption Time: 2.03069
PPO Batch Consumption Time: 0.02409
Total Iteration Time: 7.35133

Cumulative Model Updates: 37572
Cumulative Timesteps: 313657084

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.96085
Policy Entropy: 1.29327
Value Function Loss: 0.02197

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.11381
Value Function Update Magnitude: 0.19989

Collected Steps per Second: 10302.37948
Overall Steps per Second: 7122.49840

Timestep Collection Time: 4.85558
Timestep Consumption Time: 2.16780
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.02338

Cumulative Model Updates: 37578
Cumulative Timesteps: 313707108

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.99202
Policy Entropy: 1.29170
Value Function Loss: 0.02171

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.06830
Policy Update Magnitude: 0.11492
Value Function Update Magnitude: 0.19408

Collected Steps per Second: 9071.13815
Overall Steps per Second: 6436.22902

Timestep Collection Time: 5.51441
Timestep Consumption Time: 2.25753
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 7.77194

Cumulative Model Updates: 37584
Cumulative Timesteps: 313757130

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.94989
Policy Entropy: 1.28448
Value Function Loss: 0.02181

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.11374
Value Function Update Magnitude: 0.19986

Collected Steps per Second: 9289.12104
Overall Steps per Second: 6741.92053

Timestep Collection Time: 5.38522
Timestep Consumption Time: 2.03462
PPO Batch Consumption Time: 0.02386
Total Iteration Time: 7.41984

Cumulative Model Updates: 37590
Cumulative Timesteps: 313807154

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 313807154...
Checkpoint 313807154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.24511
Policy Entropy: 1.28133
Value Function Loss: 0.02219

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.11574
Value Function Update Magnitude: 0.20538

Collected Steps per Second: 10044.30666
Overall Steps per Second: 6866.42815

Timestep Collection Time: 4.97864
Timestep Consumption Time: 2.30418
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.28283

Cumulative Model Updates: 37596
Cumulative Timesteps: 313857161

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.61486
Policy Entropy: 1.27593
Value Function Loss: 0.02214

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.11793
Value Function Update Magnitude: 0.20678

Collected Steps per Second: 9151.10666
Overall Steps per Second: 6546.79903

Timestep Collection Time: 5.46699
Timestep Consumption Time: 2.17476
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.64175

Cumulative Model Updates: 37602
Cumulative Timesteps: 313907190

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.05755
Policy Entropy: 1.28006
Value Function Loss: 0.02250

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.11563
Value Function Update Magnitude: 0.20937

Collected Steps per Second: 9152.84244
Overall Steps per Second: 6647.59551

Timestep Collection Time: 5.46726
Timestep Consumption Time: 2.06042
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 7.52768

Cumulative Model Updates: 37608
Cumulative Timesteps: 313957231

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.41445
Policy Entropy: 1.28308
Value Function Loss: 0.02341

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.11827
Value Function Update Magnitude: 0.21581

Collected Steps per Second: 9722.23840
Overall Steps per Second: 6735.86075

Timestep Collection Time: 5.14614
Timestep Consumption Time: 2.28157
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.42771

Cumulative Model Updates: 37614
Cumulative Timesteps: 314007263

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.37198
Policy Entropy: 1.28650
Value Function Loss: 0.02339

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07478
Policy Update Magnitude: 0.12108
Value Function Update Magnitude: 0.22449

Collected Steps per Second: 9154.38342
Overall Steps per Second: 6489.54556

Timestep Collection Time: 5.46208
Timestep Consumption Time: 2.24293
PPO Batch Consumption Time: 0.02951
Total Iteration Time: 7.70501

Cumulative Model Updates: 37620
Cumulative Timesteps: 314057265

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.38845
Policy Entropy: 1.28311
Value Function Loss: 0.02236

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.11937
Value Function Update Magnitude: 0.22662

Collected Steps per Second: 9321.57483
Overall Steps per Second: 6651.49590

Timestep Collection Time: 5.36873
Timestep Consumption Time: 2.15514
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.52387

Cumulative Model Updates: 37626
Cumulative Timesteps: 314107310

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.47435
Policy Entropy: 1.28301
Value Function Loss: 0.02209

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.11827
Value Function Update Magnitude: 0.21927

Collected Steps per Second: 10100.30053
Overall Steps per Second: 6994.16437

Timestep Collection Time: 4.95055
Timestep Consumption Time: 2.19856
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.14910

Cumulative Model Updates: 37632
Cumulative Timesteps: 314157312

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.88742
Policy Entropy: 1.28396
Value Function Loss: 0.02208

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.11707
Value Function Update Magnitude: 0.22560

Collected Steps per Second: 9601.30319
Overall Steps per Second: 7011.25410

Timestep Collection Time: 5.21013
Timestep Consumption Time: 1.92469
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.13481

Cumulative Model Updates: 37638
Cumulative Timesteps: 314207336

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.99255
Policy Entropy: 1.28199
Value Function Loss: 0.02338

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.11765
Value Function Update Magnitude: 0.22483

Collected Steps per Second: 10033.02568
Overall Steps per Second: 7230.84666

Timestep Collection Time: 4.98673
Timestep Consumption Time: 1.93251
PPO Batch Consumption Time: 0.02583
Total Iteration Time: 6.91925

Cumulative Model Updates: 37644
Cumulative Timesteps: 314257368

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.83720
Policy Entropy: 1.28101
Value Function Loss: 0.02377

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.12189
Value Function Update Magnitude: 0.21468

Collected Steps per Second: 10745.61860
Overall Steps per Second: 7404.74611

Timestep Collection Time: 4.65604
Timestep Consumption Time: 2.10071
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 6.75675

Cumulative Model Updates: 37650
Cumulative Timesteps: 314307400

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 314307400...
Checkpoint 314307400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.61890
Policy Entropy: 1.28012
Value Function Loss: 0.02390

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.12194
Value Function Update Magnitude: 0.21347

Collected Steps per Second: 9518.41884
Overall Steps per Second: 6878.74561

Timestep Collection Time: 5.25623
Timestep Consumption Time: 2.01704
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.27327

Cumulative Model Updates: 37656
Cumulative Timesteps: 314357431

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.49422
Policy Entropy: 1.28367
Value Function Loss: 0.02305

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.12187
Value Function Update Magnitude: 0.21379

Collected Steps per Second: 9350.66135
Overall Steps per Second: 6872.98077

Timestep Collection Time: 5.34850
Timestep Consumption Time: 1.92811
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.27661

Cumulative Model Updates: 37662
Cumulative Timesteps: 314407443

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.13331
Policy Entropy: 1.28229
Value Function Loss: 0.02342

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.12214
Value Function Update Magnitude: 0.22182

Collected Steps per Second: 10105.19358
Overall Steps per Second: 7161.39161

Timestep Collection Time: 4.95181
Timestep Consumption Time: 2.03552
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.98733

Cumulative Model Updates: 37668
Cumulative Timesteps: 314457482

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.39006
Policy Entropy: 1.27814
Value Function Loss: 0.02442

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.12661
Value Function Update Magnitude: 0.22862

Collected Steps per Second: 9518.42802
Overall Steps per Second: 6711.79099

Timestep Collection Time: 5.25759
Timestep Consumption Time: 2.19854
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 7.45613

Cumulative Model Updates: 37674
Cumulative Timesteps: 314507526

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.85326
Policy Entropy: 1.27243
Value Function Loss: 0.02495

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.12293
Value Function Update Magnitude: 0.23717

Collected Steps per Second: 9220.57197
Overall Steps per Second: 6706.89734

Timestep Collection Time: 5.42352
Timestep Consumption Time: 2.03268
PPO Batch Consumption Time: 0.02428
Total Iteration Time: 7.45620

Cumulative Model Updates: 37680
Cumulative Timesteps: 314557534

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.96512
Policy Entropy: 1.28276
Value Function Loss: 0.02535

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.12314
Value Function Update Magnitude: 0.23336

Collected Steps per Second: 10325.04663
Overall Steps per Second: 7290.64160

Timestep Collection Time: 4.84560
Timestep Consumption Time: 2.01676
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 6.86236

Cumulative Model Updates: 37686
Cumulative Timesteps: 314607565

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.58340
Policy Entropy: 1.28165
Value Function Loss: 0.02529

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.12113
Value Function Update Magnitude: 0.23680

Collected Steps per Second: 9457.19101
Overall Steps per Second: 6593.56632

Timestep Collection Time: 5.29153
Timestep Consumption Time: 2.29814
PPO Batch Consumption Time: 0.02878
Total Iteration Time: 7.58967

Cumulative Model Updates: 37692
Cumulative Timesteps: 314657608

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.81147
Policy Entropy: 1.28408
Value Function Loss: 0.02511

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.12310
Value Function Update Magnitude: 0.23493

Collected Steps per Second: 9059.15271
Overall Steps per Second: 6611.47206

Timestep Collection Time: 5.52381
Timestep Consumption Time: 2.04501
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.56881

Cumulative Model Updates: 37698
Cumulative Timesteps: 314707649

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.97110
Policy Entropy: 1.28178
Value Function Loss: 0.02498

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.12267
Value Function Update Magnitude: 0.22145

Collected Steps per Second: 9944.39297
Overall Steps per Second: 6844.70670

Timestep Collection Time: 5.03067
Timestep Consumption Time: 2.27819
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 7.30886

Cumulative Model Updates: 37704
Cumulative Timesteps: 314757676

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.61792
Policy Entropy: 1.29159
Value Function Loss: 0.02333

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.12101
Value Function Update Magnitude: 0.21385

Collected Steps per Second: 9600.45574
Overall Steps per Second: 6708.72454

Timestep Collection Time: 5.20871
Timestep Consumption Time: 2.24516
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.45388

Cumulative Model Updates: 37710
Cumulative Timesteps: 314807682

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 314807682...
Checkpoint 314807682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.77660
Policy Entropy: 1.28694
Value Function Loss: 0.02341

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.11904
Value Function Update Magnitude: 0.21825

Collected Steps per Second: 9160.21612
Overall Steps per Second: 6499.97667

Timestep Collection Time: 5.46297
Timestep Consumption Time: 2.23583
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 7.69880

Cumulative Model Updates: 37716
Cumulative Timesteps: 314857724

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.97628
Policy Entropy: 1.29216
Value Function Loss: 0.02264

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.11959
Value Function Update Magnitude: 0.21926

Collected Steps per Second: 9621.44311
Overall Steps per Second: 6782.47493

Timestep Collection Time: 5.19745
Timestep Consumption Time: 2.17552
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 7.37297

Cumulative Model Updates: 37722
Cumulative Timesteps: 314907731

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.51429
Policy Entropy: 1.28766
Value Function Loss: 0.02297

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.12217
Value Function Update Magnitude: 0.21260

Collected Steps per Second: 10113.87274
Overall Steps per Second: 7204.36078

Timestep Collection Time: 4.94479
Timestep Consumption Time: 1.99698
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 6.94177

Cumulative Model Updates: 37728
Cumulative Timesteps: 314957742

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.41836
Policy Entropy: 1.29009
Value Function Loss: 0.02324

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.12229
Value Function Update Magnitude: 0.21808

Collected Steps per Second: 9818.70302
Overall Steps per Second: 7107.59813

Timestep Collection Time: 5.09283
Timestep Consumption Time: 1.94260
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 7.03543

Cumulative Model Updates: 37734
Cumulative Timesteps: 315007747

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.33843
Policy Entropy: 1.28564
Value Function Loss: 0.02263

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.12224
Value Function Update Magnitude: 0.21694

Collected Steps per Second: 9705.88538
Overall Steps per Second: 6862.78365

Timestep Collection Time: 5.15399
Timestep Consumption Time: 2.13518
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 7.28917

Cumulative Model Updates: 37740
Cumulative Timesteps: 315057771

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.57989
Policy Entropy: 1.28423
Value Function Loss: 0.02261

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.12122
Value Function Update Magnitude: 0.21191

Collected Steps per Second: 9535.91953
Overall Steps per Second: 6950.94904

Timestep Collection Time: 5.24501
Timestep Consumption Time: 1.95055
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.19556

Cumulative Model Updates: 37746
Cumulative Timesteps: 315107787

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.65228
Policy Entropy: 1.28897
Value Function Loss: 0.02165

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.11964
Value Function Update Magnitude: 0.20178

Collected Steps per Second: 9692.94748
Overall Steps per Second: 7053.98231

Timestep Collection Time: 5.16045
Timestep Consumption Time: 1.93058
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.09103

Cumulative Model Updates: 37752
Cumulative Timesteps: 315157807

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.16091
Policy Entropy: 1.29272
Value Function Loss: 0.02256

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07018
Policy Update Magnitude: 0.12060
Value Function Update Magnitude: 0.20417

Collected Steps per Second: 9749.55201
Overall Steps per Second: 6818.93481

Timestep Collection Time: 5.12967
Timestep Consumption Time: 2.20461
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 7.33428

Cumulative Model Updates: 37758
Cumulative Timesteps: 315207819

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.12124
Policy Entropy: 1.29580
Value Function Loss: 0.02264

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.12151
Value Function Update Magnitude: 0.20468

Collected Steps per Second: 9459.96177
Overall Steps per Second: 6753.41993

Timestep Collection Time: 5.28977
Timestep Consumption Time: 2.11996
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 7.40973

Cumulative Model Updates: 37764
Cumulative Timesteps: 315257860

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.14089
Policy Entropy: 1.29411
Value Function Loss: 0.02342

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.12327
Value Function Update Magnitude: 0.20381

Collected Steps per Second: 10037.98482
Overall Steps per Second: 7040.22193

Timestep Collection Time: 4.98427
Timestep Consumption Time: 2.12233
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.10659

Cumulative Model Updates: 37770
Cumulative Timesteps: 315307892

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 315307892...
Checkpoint 315307892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.78986
Policy Entropy: 1.30038
Value Function Loss: 0.02335

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.07211
Policy Update Magnitude: 0.12324
Value Function Update Magnitude: 0.20740

Collected Steps per Second: 10948.03496
Overall Steps per Second: 7336.66445

Timestep Collection Time: 4.56995
Timestep Consumption Time: 2.24950
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 6.81945

Cumulative Model Updates: 37776
Cumulative Timesteps: 315357924

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.92367
Policy Entropy: 1.30221
Value Function Loss: 0.02342

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.06690
Policy Update Magnitude: 0.12162
Value Function Update Magnitude: 0.20508

Collected Steps per Second: 9368.56376
Overall Steps per Second: 6824.77756

Timestep Collection Time: 5.33988
Timestep Consumption Time: 1.99032
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 7.33020

Cumulative Model Updates: 37782
Cumulative Timesteps: 315407951

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.82564
Policy Entropy: 1.30256
Value Function Loss: 0.02237

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.06666
Policy Update Magnitude: 0.11876
Value Function Update Magnitude: 0.20843

Collected Steps per Second: 9524.03904
Overall Steps per Second: 6964.73972

Timestep Collection Time: 5.25302
Timestep Consumption Time: 1.93030
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 7.18333

Cumulative Model Updates: 37788
Cumulative Timesteps: 315457981

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.81211
Policy Entropy: 1.30025
Value Function Loss: 0.02225

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.06387
Policy Update Magnitude: 0.11852
Value Function Update Magnitude: 0.20572

Collected Steps per Second: 9830.70362
Overall Steps per Second: 6887.57320

Timestep Collection Time: 5.08722
Timestep Consumption Time: 2.17382
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.26105

Cumulative Model Updates: 37794
Cumulative Timesteps: 315507992

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.40306
Policy Entropy: 1.29441
Value Function Loss: 0.02135

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.07267
Policy Update Magnitude: 0.11595
Value Function Update Magnitude: 0.19238

Collected Steps per Second: 8953.96689
Overall Steps per Second: 6345.73229

Timestep Collection Time: 5.58646
Timestep Consumption Time: 2.29616
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.88262

Cumulative Model Updates: 37800
Cumulative Timesteps: 315558013

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.28467
Policy Entropy: 1.28868
Value Function Loss: 0.02190

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.11435
Value Function Update Magnitude: 0.18521

Collected Steps per Second: 9714.67340
Overall Steps per Second: 6978.99260

Timestep Collection Time: 5.15004
Timestep Consumption Time: 2.01876
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.16880

Cumulative Model Updates: 37806
Cumulative Timesteps: 315608044

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.60974
Policy Entropy: 1.28188
Value Function Loss: 0.02139

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.11338
Value Function Update Magnitude: 0.18276

Collected Steps per Second: 9833.21890
Overall Steps per Second: 6716.19147

Timestep Collection Time: 5.08714
Timestep Consumption Time: 2.36098
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.44812

Cumulative Model Updates: 37812
Cumulative Timesteps: 315658067

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.67597
Policy Entropy: 1.28818
Value Function Loss: 0.02254

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.11429
Value Function Update Magnitude: 0.19225

Collected Steps per Second: 9115.30628
Overall Steps per Second: 6458.40144

Timestep Collection Time: 5.48572
Timestep Consumption Time: 2.25676
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 7.74247

Cumulative Model Updates: 37818
Cumulative Timesteps: 315708071

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.30816
Policy Entropy: 1.29019
Value Function Loss: 0.02376

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.11989
Value Function Update Magnitude: 0.20543

Collected Steps per Second: 9410.08358
Overall Steps per Second: 6717.54759

Timestep Collection Time: 5.31451
Timestep Consumption Time: 2.13017
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.44468

Cumulative Model Updates: 37824
Cumulative Timesteps: 315758081

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.91952
Policy Entropy: 1.29333
Value Function Loss: 0.02316

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.11873
Value Function Update Magnitude: 0.20974

Collected Steps per Second: 10037.77872
Overall Steps per Second: 7093.91063

Timestep Collection Time: 4.98198
Timestep Consumption Time: 2.06745
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.04943

Cumulative Model Updates: 37830
Cumulative Timesteps: 315808089

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 315808089...
Checkpoint 315808089 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.79776
Policy Entropy: 1.29054
Value Function Loss: 0.02276

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.19893

Collected Steps per Second: 8843.11707
Overall Steps per Second: 6153.51502

Timestep Collection Time: 5.65558
Timestep Consumption Time: 2.47196
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 8.12755

Cumulative Model Updates: 37836
Cumulative Timesteps: 315858102

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.34867
Policy Entropy: 1.29088
Value Function Loss: 0.02237

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.11960
Value Function Update Magnitude: 0.19298

Collected Steps per Second: 9492.67206
Overall Steps per Second: 6718.64353

Timestep Collection Time: 5.26775
Timestep Consumption Time: 2.17498
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 7.44272

Cumulative Model Updates: 37842
Cumulative Timesteps: 315908107

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.69991
Policy Entropy: 1.29199
Value Function Loss: 0.02233

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.11735
Value Function Update Magnitude: 0.20125

Collected Steps per Second: 10100.49635
Overall Steps per Second: 6964.30441

Timestep Collection Time: 4.95421
Timestep Consumption Time: 2.23100
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.18521

Cumulative Model Updates: 37848
Cumulative Timesteps: 315958147

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.85194
Policy Entropy: 1.28519
Value Function Loss: 0.02215

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.12256
Value Function Update Magnitude: 0.19857

Collected Steps per Second: 9427.95860
Overall Steps per Second: 6643.78719

Timestep Collection Time: 5.30518
Timestep Consumption Time: 2.22321
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 7.52839

Cumulative Model Updates: 37854
Cumulative Timesteps: 316008164

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.05955
Policy Entropy: 1.28327
Value Function Loss: 0.02204

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.12352
Value Function Update Magnitude: 0.19354

Collected Steps per Second: 9757.87796
Overall Steps per Second: 6998.94418

Timestep Collection Time: 5.12724
Timestep Consumption Time: 2.02112
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.14836

Cumulative Model Updates: 37860
Cumulative Timesteps: 316058195

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.98380
Policy Entropy: 1.27610
Value Function Loss: 0.02254

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.12010
Value Function Update Magnitude: 0.19796

Collected Steps per Second: 10450.22154
Overall Steps per Second: 7413.43164

Timestep Collection Time: 4.78507
Timestep Consumption Time: 1.96012
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.74519

Cumulative Model Updates: 37866
Cumulative Timesteps: 316108200

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.10126
Policy Entropy: 1.28299
Value Function Loss: 0.02476

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.12025
Value Function Update Magnitude: 0.20090

Collected Steps per Second: 10134.93716
Overall Steps per Second: 7204.70153

Timestep Collection Time: 4.93659
Timestep Consumption Time: 2.00777
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 6.94435

Cumulative Model Updates: 37872
Cumulative Timesteps: 316158232

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.19852
Policy Entropy: 1.28593
Value Function Loss: 0.02566

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.11864
Value Function Update Magnitude: 0.21093

Collected Steps per Second: 9696.46614
Overall Steps per Second: 7061.78081

Timestep Collection Time: 5.15806
Timestep Consumption Time: 1.92443
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.08249

Cumulative Model Updates: 37878
Cumulative Timesteps: 316208247

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.77962
Policy Entropy: 1.28865
Value Function Loss: 0.02551

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.12054
Value Function Update Magnitude: 0.21445

Collected Steps per Second: 10605.41070
Overall Steps per Second: 7436.88274

Timestep Collection Time: 4.71835
Timestep Consumption Time: 2.01028
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 6.72863

Cumulative Model Updates: 37884
Cumulative Timesteps: 316258287

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.37879
Policy Entropy: 1.28475
Value Function Loss: 0.02391

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.12255
Value Function Update Magnitude: 0.21612

Collected Steps per Second: 9823.65130
Overall Steps per Second: 7193.30066

Timestep Collection Time: 5.09434
Timestep Consumption Time: 1.86283
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.95717

Cumulative Model Updates: 37890
Cumulative Timesteps: 316308332

Timesteps Collected: 50045
--------END ITERATION REPORT--------


Saving checkpoint 316308332...
Checkpoint 316308332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.65874
Policy Entropy: 1.27522
Value Function Loss: 0.02388

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.11860
Value Function Update Magnitude: 0.20406

Collected Steps per Second: 9698.74260
Overall Steps per Second: 7045.84296

Timestep Collection Time: 5.15706
Timestep Consumption Time: 1.94174
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.09880

Cumulative Model Updates: 37896
Cumulative Timesteps: 316358349

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.68159
Policy Entropy: 1.27821
Value Function Loss: 0.02371

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.12073
Value Function Update Magnitude: 0.19715

Collected Steps per Second: 10155.95028
Overall Steps per Second: 6878.90752

Timestep Collection Time: 4.92470
Timestep Consumption Time: 2.34608
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 7.27078

Cumulative Model Updates: 37902
Cumulative Timesteps: 316408364

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.54153
Policy Entropy: 1.27970
Value Function Loss: 0.02365

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.12150
Value Function Update Magnitude: 0.19347

Collected Steps per Second: 9377.43608
Overall Steps per Second: 6709.65589

Timestep Collection Time: 5.33653
Timestep Consumption Time: 2.12182
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 7.45836

Cumulative Model Updates: 37908
Cumulative Timesteps: 316458407

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.00690
Policy Entropy: 1.28484
Value Function Loss: 0.02451

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.07480
Policy Update Magnitude: 0.12065
Value Function Update Magnitude: 0.19804

Collected Steps per Second: 10261.43606
Overall Steps per Second: 7208.18488

Timestep Collection Time: 4.87622
Timestep Consumption Time: 2.06547
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 6.94169

Cumulative Model Updates: 37914
Cumulative Timesteps: 316508444

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.08215
Policy Entropy: 1.28490
Value Function Loss: 0.02420

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.11971
Value Function Update Magnitude: 0.20592

Collected Steps per Second: 10121.10367
Overall Steps per Second: 6773.74019

Timestep Collection Time: 4.94264
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 7.38514

Cumulative Model Updates: 37920
Cumulative Timesteps: 316558469

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.73092
Policy Entropy: 1.29090
Value Function Loss: 0.02359

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.11948
Value Function Update Magnitude: 0.19820

Collected Steps per Second: 8702.72621
Overall Steps per Second: 6322.15137

Timestep Collection Time: 5.74716
Timestep Consumption Time: 2.16407
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.91123

Cumulative Model Updates: 37926
Cumulative Timesteps: 316608485

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.71349
Policy Entropy: 1.29009
Value Function Loss: 0.02272

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.11935
Value Function Update Magnitude: 0.20402

Collected Steps per Second: 9770.98326
Overall Steps per Second: 6893.38284

Timestep Collection Time: 5.12118
Timestep Consumption Time: 2.13781
PPO Batch Consumption Time: 0.02485
Total Iteration Time: 7.25899

Cumulative Model Updates: 37932
Cumulative Timesteps: 316658524

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.97985
Policy Entropy: 1.28872
Value Function Loss: 0.02279

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.11596
Value Function Update Magnitude: 0.20282

Collected Steps per Second: 9782.44197
Overall Steps per Second: 6794.77913

Timestep Collection Time: 5.11304
Timestep Consumption Time: 2.24820
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.36124

Cumulative Model Updates: 37938
Cumulative Timesteps: 316708542

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.06832
Policy Entropy: 1.28680
Value Function Loss: 0.02375

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.11875
Value Function Update Magnitude: 0.20641

Collected Steps per Second: 8840.62205
Overall Steps per Second: 6501.53250

Timestep Collection Time: 5.65888
Timestep Consumption Time: 2.03592
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.69480

Cumulative Model Updates: 37944
Cumulative Timesteps: 316758570

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.37942
Policy Entropy: 1.29032
Value Function Loss: 0.02226

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.11810
Value Function Update Magnitude: 0.20327

Collected Steps per Second: 10156.99619
Overall Steps per Second: 7028.23681

Timestep Collection Time: 4.92567
Timestep Consumption Time: 2.19276
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.11843

Cumulative Model Updates: 37950
Cumulative Timesteps: 316808600

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 316808600...
Checkpoint 316808600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.38907
Policy Entropy: 1.28896
Value Function Loss: 0.02312

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.11819
Value Function Update Magnitude: 0.19153

Collected Steps per Second: 10385.94992
Overall Steps per Second: 6993.70950

Timestep Collection Time: 4.81747
Timestep Consumption Time: 2.33667
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 7.15414

Cumulative Model Updates: 37956
Cumulative Timesteps: 316858634

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.15505
Policy Entropy: 1.29275
Value Function Loss: 0.02355

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.12091
Value Function Update Magnitude: 0.18661

Collected Steps per Second: 8996.59474
Overall Steps per Second: 6461.23741

Timestep Collection Time: 5.56255
Timestep Consumption Time: 2.18272
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 7.74527

Cumulative Model Updates: 37962
Cumulative Timesteps: 316908678

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.51182
Policy Entropy: 1.29431
Value Function Loss: 0.02410

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07123
Policy Update Magnitude: 0.12074
Value Function Update Magnitude: 0.19821

Collected Steps per Second: 10185.42231
Overall Steps per Second: 7081.56686

Timestep Collection Time: 4.90986
Timestep Consumption Time: 2.15199
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 7.06186

Cumulative Model Updates: 37968
Cumulative Timesteps: 316958687

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.16593
Policy Entropy: 1.29596
Value Function Loss: 0.02226

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.11898
Value Function Update Magnitude: 0.20399

Collected Steps per Second: 10423.83233
Overall Steps per Second: 7290.02653

Timestep Collection Time: 4.80102
Timestep Consumption Time: 2.06384
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 6.86486

Cumulative Model Updates: 37974
Cumulative Timesteps: 317008732

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.08657
Policy Entropy: 1.29417
Value Function Loss: 0.02058

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.11669
Value Function Update Magnitude: 0.19030

Collected Steps per Second: 9450.71876
Overall Steps per Second: 6814.69425

Timestep Collection Time: 5.29536
Timestep Consumption Time: 2.04833
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 7.34369

Cumulative Model Updates: 37980
Cumulative Timesteps: 317058777

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.03221
Policy Entropy: 1.29218
Value Function Loss: 0.02081

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.11429
Value Function Update Magnitude: 0.19124

Collected Steps per Second: 9702.78129
Overall Steps per Second: 6937.45211

Timestep Collection Time: 5.15368
Timestep Consumption Time: 2.05430
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 7.20798

Cumulative Model Updates: 37986
Cumulative Timesteps: 317108782

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.38682
Policy Entropy: 1.29821
Value Function Loss: 0.02105

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.11423
Value Function Update Magnitude: 0.19374

Collected Steps per Second: 10434.83198
Overall Steps per Second: 7409.97149

Timestep Collection Time: 4.79299
Timestep Consumption Time: 1.95657
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 6.74955

Cumulative Model Updates: 37992
Cumulative Timesteps: 317158796

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.93893
Policy Entropy: 1.29827
Value Function Loss: 0.02223

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.11574
Value Function Update Magnitude: 0.19464

Collected Steps per Second: 10113.91467
Overall Steps per Second: 7140.49137

Timestep Collection Time: 4.94606
Timestep Consumption Time: 2.05962
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.00568

Cumulative Model Updates: 37998
Cumulative Timesteps: 317208820

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.27417
Policy Entropy: 1.29801
Value Function Loss: 0.02169

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.11843
Value Function Update Magnitude: 0.19235

Collected Steps per Second: 9899.91487
Overall Steps per Second: 7184.04604

Timestep Collection Time: 5.05519
Timestep Consumption Time: 1.91107
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 6.96627

Cumulative Model Updates: 38004
Cumulative Timesteps: 317258866

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.42888
Policy Entropy: 1.29818
Value Function Loss: 0.02346

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.11837
Value Function Update Magnitude: 0.19083

Collected Steps per Second: 10496.33667
Overall Steps per Second: 7342.38327

Timestep Collection Time: 4.76414
Timestep Consumption Time: 2.04646
PPO Batch Consumption Time: 0.02452
Total Iteration Time: 6.81060

Cumulative Model Updates: 38010
Cumulative Timesteps: 317308872

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 317308872...
Checkpoint 317308872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.84280
Policy Entropy: 1.30141
Value Function Loss: 0.02256

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.11660
Value Function Update Magnitude: 0.20356

Collected Steps per Second: 9614.11886
Overall Steps per Second: 7018.66072

Timestep Collection Time: 5.20401
Timestep Consumption Time: 1.92441
PPO Batch Consumption Time: 0.02500
Total Iteration Time: 7.12843

Cumulative Model Updates: 38016
Cumulative Timesteps: 317358904

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.25422
Policy Entropy: 1.30116
Value Function Loss: 0.02349

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.11760
Value Function Update Magnitude: 0.20447

Collected Steps per Second: 9472.83894
Overall Steps per Second: 6611.58413

Timestep Collection Time: 5.28015
Timestep Consumption Time: 2.28506
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.56521

Cumulative Model Updates: 38022
Cumulative Timesteps: 317408922

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.22034
Policy Entropy: 1.29745
Value Function Loss: 0.02500

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.11979
Value Function Update Magnitude: 0.20317

Collected Steps per Second: 9526.87456
Overall Steps per Second: 6890.33534

Timestep Collection Time: 5.25240
Timestep Consumption Time: 2.00980
PPO Batch Consumption Time: 0.02474
Total Iteration Time: 7.26220

Cumulative Model Updates: 38028
Cumulative Timesteps: 317458961

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.12951
Policy Entropy: 1.29082
Value Function Loss: 0.02584

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.11911
Value Function Update Magnitude: 0.20617

Collected Steps per Second: 9651.74325
Overall Steps per Second: 6903.79983

Timestep Collection Time: 5.18321
Timestep Consumption Time: 2.06309
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 7.24630

Cumulative Model Updates: 38034
Cumulative Timesteps: 317508988

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.44179
Policy Entropy: 1.29263
Value Function Loss: 0.02495

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.12054
Value Function Update Magnitude: 0.20485

Collected Steps per Second: 9239.00140
Overall Steps per Second: 6510.52797

Timestep Collection Time: 5.41509
Timestep Consumption Time: 2.26939
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 7.68448

Cumulative Model Updates: 38040
Cumulative Timesteps: 317559018

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.95972
Policy Entropy: 1.29459
Value Function Loss: 0.02366

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.12034
Value Function Update Magnitude: 0.21295

Collected Steps per Second: 9310.56739
Overall Steps per Second: 6406.01210

Timestep Collection Time: 5.37099
Timestep Consumption Time: 2.43527
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 7.80626

Cumulative Model Updates: 38046
Cumulative Timesteps: 317609025

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.38675
Policy Entropy: 1.29694
Value Function Loss: 0.02244

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.11470
Value Function Update Magnitude: 0.22011

Collected Steps per Second: 9960.16942
Overall Steps per Second: 7025.26443

Timestep Collection Time: 5.02230
Timestep Consumption Time: 2.09814
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 7.12044

Cumulative Model Updates: 38052
Cumulative Timesteps: 317659048

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.95470
Policy Entropy: 1.28859
Value Function Loss: 0.02307

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.11570
Value Function Update Magnitude: 0.21292

Collected Steps per Second: 9993.59448
Overall Steps per Second: 6930.59236

Timestep Collection Time: 5.00701
Timestep Consumption Time: 2.21287
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 7.21987

Cumulative Model Updates: 38058
Cumulative Timesteps: 317709086

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.35005
Policy Entropy: 1.28357
Value Function Loss: 0.02272

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.11725
Value Function Update Magnitude: 0.21907

Collected Steps per Second: 9530.84704
Overall Steps per Second: 6696.64936

Timestep Collection Time: 5.25022
Timestep Consumption Time: 2.22203
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 7.47224

Cumulative Model Updates: 38064
Cumulative Timesteps: 317759125

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.05894
Policy Entropy: 1.28544
Value Function Loss: 0.02249

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.11616
Value Function Update Magnitude: 0.21960

Collected Steps per Second: 9289.26397
Overall Steps per Second: 6738.15545

Timestep Collection Time: 5.38665
Timestep Consumption Time: 2.03942
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 7.42607

Cumulative Model Updates: 38070
Cumulative Timesteps: 317809163

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 317809163...
Checkpoint 317809163 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.94890
Policy Entropy: 1.29310
Value Function Loss: 0.02118

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.11434
Value Function Update Magnitude: 0.20948

Collected Steps per Second: 8905.49686
Overall Steps per Second: 6397.85358

Timestep Collection Time: 5.61530
Timestep Consumption Time: 2.20092
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.81622

Cumulative Model Updates: 38076
Cumulative Timesteps: 317859170

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.64730
Policy Entropy: 1.29090
Value Function Loss: 0.02254

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.11739
Value Function Update Magnitude: 0.20871

Collected Steps per Second: 9702.03187
Overall Steps per Second: 6868.69799

Timestep Collection Time: 5.15675
Timestep Consumption Time: 2.12716
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.28391

Cumulative Model Updates: 38082
Cumulative Timesteps: 317909201

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.26142
Policy Entropy: 1.28920
Value Function Loss: 0.02297

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.12101
Value Function Update Magnitude: 0.21836

Collected Steps per Second: 9667.00452
Overall Steps per Second: 6937.63945

Timestep Collection Time: 5.17316
Timestep Consumption Time: 2.03520
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 7.20836

Cumulative Model Updates: 38088
Cumulative Timesteps: 317959210

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.05816
Policy Entropy: 1.28300
Value Function Loss: 0.02479

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.11784
Value Function Update Magnitude: 0.21794

Collected Steps per Second: 9806.00459
Overall Steps per Second: 7143.25233

Timestep Collection Time: 5.10055
Timestep Consumption Time: 1.90130
PPO Batch Consumption Time: 0.02404
Total Iteration Time: 7.00185

Cumulative Model Updates: 38094
Cumulative Timesteps: 318009226

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.54050
Policy Entropy: 1.28147
Value Function Loss: 0.02419

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.11842
Value Function Update Magnitude: 0.21201

Collected Steps per Second: 10454.90910
Overall Steps per Second: 7389.70946

Timestep Collection Time: 4.78407
Timestep Consumption Time: 1.98440
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 6.76847

Cumulative Model Updates: 38100
Cumulative Timesteps: 318059243

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.82449
Policy Entropy: 1.28426
Value Function Loss: 0.02374

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.11657
Value Function Update Magnitude: 0.21229

Collected Steps per Second: 9993.89612
Overall Steps per Second: 7039.76707

Timestep Collection Time: 5.00506
Timestep Consumption Time: 2.10029
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 7.10535

Cumulative Model Updates: 38106
Cumulative Timesteps: 318109263

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.88781
Policy Entropy: 1.28978
Value Function Loss: 0.02373

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.11865
Value Function Update Magnitude: 0.22214

Collected Steps per Second: 9124.35169
Overall Steps per Second: 6572.72301

Timestep Collection Time: 5.48488
Timestep Consumption Time: 2.12931
PPO Batch Consumption Time: 0.02483
Total Iteration Time: 7.61420

Cumulative Model Updates: 38112
Cumulative Timesteps: 318159309

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.73179
Policy Entropy: 1.28551
Value Function Loss: 0.02393

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.07639
Policy Update Magnitude: 0.11875
Value Function Update Magnitude: 0.22255

Collected Steps per Second: 10115.72536
Overall Steps per Second: 7015.54152

Timestep Collection Time: 4.94745
Timestep Consumption Time: 2.18629
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 7.13373

Cumulative Model Updates: 38118
Cumulative Timesteps: 318209356

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61778
Policy Entropy: 1.28617
Value Function Loss: 0.02386

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.11890
Value Function Update Magnitude: 0.23236

Collected Steps per Second: 9609.64659
Overall Steps per Second: 6773.85868

Timestep Collection Time: 5.20456
Timestep Consumption Time: 2.17882
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 7.38338

Cumulative Model Updates: 38124
Cumulative Timesteps: 318259370

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.02491
Policy Entropy: 1.28377
Value Function Loss: 0.02255

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.11793
Value Function Update Magnitude: 0.22689

Collected Steps per Second: 9244.26227
Overall Steps per Second: 6540.55233

Timestep Collection Time: 5.40952
Timestep Consumption Time: 2.23617
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 7.64568

Cumulative Model Updates: 38130
Cumulative Timesteps: 318309377

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 318309377...
Checkpoint 318309377 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.09342
Policy Entropy: 1.28250
Value Function Loss: 0.02323

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07655
Policy Update Magnitude: 0.11931
Value Function Update Magnitude: 0.21893

Collected Steps per Second: 9748.00185
Overall Steps per Second: 6627.97687

Timestep Collection Time: 5.12946
Timestep Consumption Time: 2.41462
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.54408

Cumulative Model Updates: 38136
Cumulative Timesteps: 318359379

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.60088
Policy Entropy: 1.27803
Value Function Loss: 0.02543

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.12291
Value Function Update Magnitude: 0.21913

Collected Steps per Second: 10128.65540
Overall Steps per Second: 7208.75056

Timestep Collection Time: 4.93649
Timestep Consumption Time: 1.99953
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 6.93601

Cumulative Model Updates: 38142
Cumulative Timesteps: 318409379

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.70478
Policy Entropy: 1.27849
Value Function Loss: 0.02546

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.09196
Policy Update Magnitude: 0.12628
Value Function Update Magnitude: 0.21425

Collected Steps per Second: 9075.79554
Overall Steps per Second: 6509.50484

Timestep Collection Time: 5.51070
Timestep Consumption Time: 2.17252
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.68323

Cumulative Model Updates: 38148
Cumulative Timesteps: 318459393

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.33379
Policy Entropy: 1.28875
Value Function Loss: 0.02476

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.12652
Value Function Update Magnitude: 0.20858

Collected Steps per Second: 9048.37100
Overall Steps per Second: 6571.22914

Timestep Collection Time: 5.52762
Timestep Consumption Time: 2.08374
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.61136

Cumulative Model Updates: 38154
Cumulative Timesteps: 318509409

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.64346
Policy Entropy: 1.29031
Value Function Loss: 0.02353

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.12642
Value Function Update Magnitude: 0.21237

Collected Steps per Second: 10019.85988
Overall Steps per Second: 7129.61112

Timestep Collection Time: 4.99378
Timestep Consumption Time: 2.02441
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.01819

Cumulative Model Updates: 38160
Cumulative Timesteps: 318559446

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.18498
Policy Entropy: 1.28552
Value Function Loss: 0.02295

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.11971
Value Function Update Magnitude: 0.20724

Collected Steps per Second: 9222.91451
Overall Steps per Second: 6573.73855

Timestep Collection Time: 5.42356
Timestep Consumption Time: 2.18566
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.60922

Cumulative Model Updates: 38166
Cumulative Timesteps: 318609467

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.11205
Policy Entropy: 1.28201
Value Function Loss: 0.02302

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07384
Policy Update Magnitude: 0.11604
Value Function Update Magnitude: 0.20040

Collected Steps per Second: 9231.62443
Overall Steps per Second: 6652.87647

Timestep Collection Time: 5.41963
Timestep Consumption Time: 2.10072
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.52036

Cumulative Model Updates: 38172
Cumulative Timesteps: 318659499

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.32307
Policy Entropy: 1.28915
Value Function Loss: 0.02226

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07171
Policy Update Magnitude: 0.11825
Value Function Update Magnitude: 0.19569

Collected Steps per Second: 9791.19057
Overall Steps per Second: 6995.94817

Timestep Collection Time: 5.11000
Timestep Consumption Time: 2.04171
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 7.15171

Cumulative Model Updates: 38178
Cumulative Timesteps: 318709532

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.04497
Policy Entropy: 1.29423
Value Function Loss: 0.02265

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06195
Policy Update Magnitude: 0.11769
Value Function Update Magnitude: 0.20516

Collected Steps per Second: 9308.74797
Overall Steps per Second: 6652.95032

Timestep Collection Time: 5.37387
Timestep Consumption Time: 2.14520
PPO Batch Consumption Time: 0.02435
Total Iteration Time: 7.51907

Cumulative Model Updates: 38184
Cumulative Timesteps: 318759556

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.93340
Policy Entropy: 1.29190
Value Function Loss: 0.02248

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06260
Policy Update Magnitude: 0.11951
Value Function Update Magnitude: 0.22893

Collected Steps per Second: 9677.29999
Overall Steps per Second: 6922.17487

Timestep Collection Time: 5.17159
Timestep Consumption Time: 2.05837
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.22995

Cumulative Model Updates: 38190
Cumulative Timesteps: 318809603

Timesteps Collected: 50047
--------END ITERATION REPORT--------


Saving checkpoint 318809603...
Checkpoint 318809603 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.43900
Policy Entropy: 1.28659
Value Function Loss: 0.02245

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.11797
Value Function Update Magnitude: 0.22761

Collected Steps per Second: 10125.02148
Overall Steps per Second: 7131.44152

Timestep Collection Time: 4.94122
Timestep Consumption Time: 2.07419
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 7.01541

Cumulative Model Updates: 38196
Cumulative Timesteps: 318859633

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.64864
Policy Entropy: 1.28845
Value Function Loss: 0.02249

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.11540
Value Function Update Magnitude: 0.21145

Collected Steps per Second: 9352.92793
Overall Steps per Second: 6775.21743

Timestep Collection Time: 5.34774
Timestep Consumption Time: 2.03461
PPO Batch Consumption Time: 0.02520
Total Iteration Time: 7.38235

Cumulative Model Updates: 38202
Cumulative Timesteps: 318909650

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.01645
Policy Entropy: 1.28896
Value Function Loss: 0.02232

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.11668
Value Function Update Magnitude: 0.20197

Collected Steps per Second: 9776.63666
Overall Steps per Second: 7005.42675

Timestep Collection Time: 5.11495
Timestep Consumption Time: 2.02337
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.13832

Cumulative Model Updates: 38208
Cumulative Timesteps: 318959657

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.33133
Policy Entropy: 1.29509
Value Function Loss: 0.02313

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.12053
Value Function Update Magnitude: 0.19659

Collected Steps per Second: 10694.46384
Overall Steps per Second: 7422.79881

Timestep Collection Time: 4.67588
Timestep Consumption Time: 2.06093
PPO Batch Consumption Time: 0.02498
Total Iteration Time: 6.73681

Cumulative Model Updates: 38214
Cumulative Timesteps: 319009663

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.76772
Policy Entropy: 1.29780
Value Function Loss: 0.02314

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.06632
Policy Update Magnitude: 0.11797
Value Function Update Magnitude: 0.19786

Collected Steps per Second: 10131.18115
Overall Steps per Second: 7240.35824

Timestep Collection Time: 4.93625
Timestep Consumption Time: 1.97087
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 6.90712

Cumulative Model Updates: 38220
Cumulative Timesteps: 319059673

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.81337
Policy Entropy: 1.29943
Value Function Loss: 0.02482

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06502
Policy Update Magnitude: 0.11918
Value Function Update Magnitude: 0.20575

Collected Steps per Second: 10062.25783
Overall Steps per Second: 7263.70263

Timestep Collection Time: 4.96916
Timestep Consumption Time: 1.91452
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 6.88368

Cumulative Model Updates: 38226
Cumulative Timesteps: 319109674

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.89742
Policy Entropy: 1.29442
Value Function Loss: 0.02460

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.12118
Value Function Update Magnitude: 0.21341

Collected Steps per Second: 9823.06593
Overall Steps per Second: 6745.46845

Timestep Collection Time: 5.09240
Timestep Consumption Time: 2.32339
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 7.41579

Cumulative Model Updates: 38232
Cumulative Timesteps: 319159697

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.93224
Policy Entropy: 1.28775
Value Function Loss: 0.02300

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.12080
Value Function Update Magnitude: 0.21204

Collected Steps per Second: 8832.97905
Overall Steps per Second: 6352.01375

Timestep Collection Time: 5.66106
Timestep Consumption Time: 2.21109
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.87215

Cumulative Model Updates: 38238
Cumulative Timesteps: 319209701

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.81866
Policy Entropy: 1.28946
Value Function Loss: 0.02183

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.11920
Value Function Update Magnitude: 0.20174

Collected Steps per Second: 9630.96744
Overall Steps per Second: 6895.71291

Timestep Collection Time: 5.19231
Timestep Consumption Time: 2.05958
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.25190

Cumulative Model Updates: 38244
Cumulative Timesteps: 319259708

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.32586
Policy Entropy: 1.29319
Value Function Loss: 0.02177

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.11676
Value Function Update Magnitude: 0.20684

Collected Steps per Second: 10059.08862
Overall Steps per Second: 7064.46752

Timestep Collection Time: 4.97451
Timestep Consumption Time: 2.10869
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 7.08319

Cumulative Model Updates: 38250
Cumulative Timesteps: 319309747

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 319309747...
Checkpoint 319309747 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.69529
Policy Entropy: 1.29391
Value Function Loss: 0.02212

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.12052
Value Function Update Magnitude: 0.21764

Collected Steps per Second: 8982.48003
Overall Steps per Second: 6312.76769

Timestep Collection Time: 5.56817
Timestep Consumption Time: 2.35482
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 7.92299

Cumulative Model Updates: 38256
Cumulative Timesteps: 319359763

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.41203
Policy Entropy: 1.28910
Value Function Loss: 0.02213

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.12085
Value Function Update Magnitude: 0.22669

Collected Steps per Second: 9622.66479
Overall Steps per Second: 6753.05006

Timestep Collection Time: 5.19752
Timestep Consumption Time: 2.20861
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 7.40613

Cumulative Model Updates: 38262
Cumulative Timesteps: 319409777

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.40317
Policy Entropy: 1.28421
Value Function Loss: 0.02287

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.12102
Value Function Update Magnitude: 0.22646

Collected Steps per Second: 10678.80971
Overall Steps per Second: 7143.19484

Timestep Collection Time: 4.68620
Timestep Consumption Time: 2.31949
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.00569

Cumulative Model Updates: 38268
Cumulative Timesteps: 319459820

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.57548
Policy Entropy: 1.28660
Value Function Loss: 0.02398

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.12240
Value Function Update Magnitude: 0.23782

Collected Steps per Second: 8936.63073
Overall Steps per Second: 6302.31893

Timestep Collection Time: 5.59741
Timestep Consumption Time: 2.33967
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.93708

Cumulative Model Updates: 38274
Cumulative Timesteps: 319509842

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.97795
Policy Entropy: 1.28912
Value Function Loss: 0.02502

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.12472
Value Function Update Magnitude: 0.26045

Collected Steps per Second: 9364.10507
Overall Steps per Second: 6737.97130

Timestep Collection Time: 5.34381
Timestep Consumption Time: 2.08276
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.42657

Cumulative Model Updates: 38280
Cumulative Timesteps: 319559882

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.51763
Policy Entropy: 1.28603
Value Function Loss: 0.02420

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.12098
Value Function Update Magnitude: 0.24774

Collected Steps per Second: 9325.92899
Overall Steps per Second: 6663.01098

Timestep Collection Time: 5.36472
Timestep Consumption Time: 2.14405
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.50877

Cumulative Model Updates: 38286
Cumulative Timesteps: 319609913

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.01955
Policy Entropy: 1.28414
Value Function Loss: 0.02422

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.11970
Value Function Update Magnitude: 0.24490

Collected Steps per Second: 9067.13346
Overall Steps per Second: 6527.83558

Timestep Collection Time: 5.51552
Timestep Consumption Time: 2.14551
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.66104

Cumulative Model Updates: 38292
Cumulative Timesteps: 319659923

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.79031
Policy Entropy: 1.28899
Value Function Loss: 0.02312

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.11824
Value Function Update Magnitude: 0.25626

Collected Steps per Second: 9710.96291
Overall Steps per Second: 7032.38223

Timestep Collection Time: 5.15129
Timestep Consumption Time: 1.96209
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 7.11338

Cumulative Model Updates: 38298
Cumulative Timesteps: 319709947

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.38888
Policy Entropy: 1.28920
Value Function Loss: 0.02451

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.12254
Value Function Update Magnitude: 0.25126

Collected Steps per Second: 10656.92765
Overall Steps per Second: 7435.00714

Timestep Collection Time: 4.69282
Timestep Consumption Time: 2.03361
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 6.72642

Cumulative Model Updates: 38304
Cumulative Timesteps: 319759958

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.05597
Policy Entropy: 1.28981
Value Function Loss: 0.02506

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.12820
Value Function Update Magnitude: 0.24431

Collected Steps per Second: 9992.94353
Overall Steps per Second: 7196.38604

Timestep Collection Time: 5.00523
Timestep Consumption Time: 1.94506
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 6.95029

Cumulative Model Updates: 38310
Cumulative Timesteps: 319809975

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 319809975...
Checkpoint 319809975 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.69698
Policy Entropy: 1.28248
Value Function Loss: 0.02391

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.13014
Value Function Update Magnitude: 0.23117

Collected Steps per Second: 9964.05793
Overall Steps per Second: 7158.47905

Timestep Collection Time: 5.01814
Timestep Consumption Time: 1.96673
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 6.98486

Cumulative Model Updates: 38316
Cumulative Timesteps: 319859976

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.97259
Policy Entropy: 1.28739
Value Function Loss: 0.02307

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.12689
Value Function Update Magnitude: 0.22755

Collected Steps per Second: 10163.54647
Overall Steps per Second: 6909.65289

Timestep Collection Time: 4.92348
Timestep Consumption Time: 2.31856
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 7.24204

Cumulative Model Updates: 38322
Cumulative Timesteps: 319910016

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.26024
Policy Entropy: 1.28517
Value Function Loss: 0.02263

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.12669
Value Function Update Magnitude: 0.21994

Collected Steps per Second: 9380.11570
Overall Steps per Second: 6727.22782

Timestep Collection Time: 5.33042
Timestep Consumption Time: 2.10206
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.43248

Cumulative Model Updates: 38328
Cumulative Timesteps: 319960016

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.90847
Policy Entropy: 1.28644
Value Function Loss: 0.02349

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.12594
Value Function Update Magnitude: 0.22494

Collected Steps per Second: 9586.01576
Overall Steps per Second: 6913.62886

Timestep Collection Time: 5.22000
Timestep Consumption Time: 2.01773
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 7.23773

Cumulative Model Updates: 38334
Cumulative Timesteps: 320010055

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.58956
Policy Entropy: 1.28162
Value Function Loss: 0.02405

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.12805
Value Function Update Magnitude: 0.22626

Collected Steps per Second: 10399.52169
Overall Steps per Second: 7128.67565

Timestep Collection Time: 4.80811
Timestep Consumption Time: 2.20610
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 7.01421

Cumulative Model Updates: 38340
Cumulative Timesteps: 320060057

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.92355
Policy Entropy: 1.28362
Value Function Loss: 0.02387

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.12628
Value Function Update Magnitude: 0.20973

Collected Steps per Second: 9026.36825
Overall Steps per Second: 6461.76563

Timestep Collection Time: 5.54132
Timestep Consumption Time: 2.19929
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 7.74061

Cumulative Model Updates: 38346
Cumulative Timesteps: 320110075

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.29352
Policy Entropy: 1.28135
Value Function Loss: 0.02381

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.12380
Value Function Update Magnitude: 0.20340

Collected Steps per Second: 9135.91673
Overall Steps per Second: 6639.90895

Timestep Collection Time: 5.47531
Timestep Consumption Time: 2.05822
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 7.53354

Cumulative Model Updates: 38352
Cumulative Timesteps: 320160097

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.56051
Policy Entropy: 1.28138
Value Function Loss: 0.02318

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.12079
Value Function Update Magnitude: 0.20182

Collected Steps per Second: 9601.17981
Overall Steps per Second: 6683.21580

Timestep Collection Time: 5.21196
Timestep Consumption Time: 2.27560
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.48756

Cumulative Model Updates: 38358
Cumulative Timesteps: 320210138

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.36641
Policy Entropy: 1.28032
Value Function Loss: 0.02421

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.12103
Value Function Update Magnitude: 0.20675

Collected Steps per Second: 9212.47779
Overall Steps per Second: 6509.73802

Timestep Collection Time: 5.43231
Timestep Consumption Time: 2.25541
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.68771

Cumulative Model Updates: 38364
Cumulative Timesteps: 320260183

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.61025
Policy Entropy: 1.27910
Value Function Loss: 0.02446

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.12290
Value Function Update Magnitude: 0.20947

Collected Steps per Second: 9276.97466
Overall Steps per Second: 6728.44989

Timestep Collection Time: 5.39098
Timestep Consumption Time: 2.04193
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 7.43292

Cumulative Model Updates: 38370
Cumulative Timesteps: 320310195

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 320310195...
Checkpoint 320310195 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.57887
Policy Entropy: 1.27931
Value Function Loss: 0.02426

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.12329
Value Function Update Magnitude: 0.21041

Collected Steps per Second: 9727.38813
Overall Steps per Second: 6692.59867

Timestep Collection Time: 5.14352
Timestep Consumption Time: 2.33235
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 7.47587

Cumulative Model Updates: 38376
Cumulative Timesteps: 320360228

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.18775
Policy Entropy: 1.28220
Value Function Loss: 0.02383

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.12172
Value Function Update Magnitude: 0.20713

Collected Steps per Second: 9321.67426
Overall Steps per Second: 6700.38296

Timestep Collection Time: 5.36674
Timestep Consumption Time: 2.09955
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.46629

Cumulative Model Updates: 38382
Cumulative Timesteps: 320410255

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.31109
Policy Entropy: 1.28487
Value Function Loss: 0.02367

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.12159
Value Function Update Magnitude: 0.20244

Collected Steps per Second: 9249.71769
Overall Steps per Second: 6468.25295

Timestep Collection Time: 5.40838
Timestep Consumption Time: 2.32570
PPO Batch Consumption Time: 0.02754
Total Iteration Time: 7.73408

Cumulative Model Updates: 38388
Cumulative Timesteps: 320460281

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.42804
Policy Entropy: 1.28709
Value Function Loss: 0.02309

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.12035
Value Function Update Magnitude: 0.19410

Collected Steps per Second: 9940.51533
Overall Steps per Second: 7052.84440

Timestep Collection Time: 5.03143
Timestep Consumption Time: 2.06004
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 7.09147

Cumulative Model Updates: 38394
Cumulative Timesteps: 320510296

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.41245
Policy Entropy: 1.28672
Value Function Loss: 0.02263

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.11828
Value Function Update Magnitude: 0.19304

Collected Steps per Second: 10101.59334
Overall Steps per Second: 7197.76403

Timestep Collection Time: 4.95377
Timestep Consumption Time: 1.99852
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 6.95230

Cumulative Model Updates: 38400
Cumulative Timesteps: 320560337

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.02076
Policy Entropy: 1.28172
Value Function Loss: 0.02342

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.11756
Value Function Update Magnitude: 0.19275

Collected Steps per Second: 9561.85160
Overall Steps per Second: 6730.87713

Timestep Collection Time: 5.23235
Timestep Consumption Time: 2.20070
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.43306

Cumulative Model Updates: 38406
Cumulative Timesteps: 320610368

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.83455
Policy Entropy: 1.27468
Value Function Loss: 0.02338

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.12011
Value Function Update Magnitude: 0.19649

Collected Steps per Second: 9579.83073
Overall Steps per Second: 6863.62151

Timestep Collection Time: 5.22118
Timestep Consumption Time: 2.06623
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 7.28741

Cumulative Model Updates: 38412
Cumulative Timesteps: 320660386

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.31095
Policy Entropy: 1.26941
Value Function Loss: 0.02426

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.12055
Value Function Update Magnitude: 0.19591

Collected Steps per Second: 9832.33581
Overall Steps per Second: 7022.73446

Timestep Collection Time: 5.08679
Timestep Consumption Time: 2.03508
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 7.12187

Cumulative Model Updates: 38418
Cumulative Timesteps: 320710401

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.68591
Policy Entropy: 1.26574
Value Function Loss: 0.02413

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.12456
Value Function Update Magnitude: 0.20485

Collected Steps per Second: 9961.75522
Overall Steps per Second: 7253.88307

Timestep Collection Time: 5.02331
Timestep Consumption Time: 1.87520
PPO Batch Consumption Time: 0.02509
Total Iteration Time: 6.89851

Cumulative Model Updates: 38424
Cumulative Timesteps: 320760442

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.90458
Policy Entropy: 1.26640
Value Function Loss: 0.02420

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.12846
Value Function Update Magnitude: 0.20708

Collected Steps per Second: 10564.24178
Overall Steps per Second: 7459.65323

Timestep Collection Time: 4.73437
Timestep Consumption Time: 1.97037
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 6.70474

Cumulative Model Updates: 38430
Cumulative Timesteps: 320810457

Timesteps Collected: 50015
--------END ITERATION REPORT--------


Saving checkpoint 320810457...
Checkpoint 320810457 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.62319
Policy Entropy: 1.26817
Value Function Loss: 0.02490

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.12948
Value Function Update Magnitude: 0.20769

Collected Steps per Second: 10008.09592
Overall Steps per Second: 7304.17651

Timestep Collection Time: 4.99665
Timestep Consumption Time: 1.84970
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 6.84636

Cumulative Model Updates: 38436
Cumulative Timesteps: 320860464

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.00032
Policy Entropy: 1.26255
Value Function Loss: 0.02438

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.12744
Value Function Update Magnitude: 0.20399

Collected Steps per Second: 9224.76738
Overall Steps per Second: 6566.07682

Timestep Collection Time: 5.42041
Timestep Consumption Time: 2.19479
PPO Batch Consumption Time: 0.02953
Total Iteration Time: 7.61520

Cumulative Model Updates: 38442
Cumulative Timesteps: 320910466

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.24766
Policy Entropy: 1.26161
Value Function Loss: 0.02420

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.12547
Value Function Update Magnitude: 0.20728

Collected Steps per Second: 9062.77175
Overall Steps per Second: 6547.54119

Timestep Collection Time: 5.51873
Timestep Consumption Time: 2.12001
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 7.63875

Cumulative Model Updates: 38448
Cumulative Timesteps: 320960481

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.05614
Policy Entropy: 1.26106
Value Function Loss: 0.02427

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.12422
Value Function Update Magnitude: 0.20422

Collected Steps per Second: 9974.21867
Overall Steps per Second: 7156.96204

Timestep Collection Time: 5.01533
Timestep Consumption Time: 1.97423
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 6.98956

Cumulative Model Updates: 38454
Cumulative Timesteps: 321010505

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.12062
Policy Entropy: 1.26883
Value Function Loss: 0.02424

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.12513
Value Function Update Magnitude: 0.20530

Collected Steps per Second: 9364.86398
Overall Steps per Second: 6431.97960

Timestep Collection Time: 5.34306
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 7.77941

Cumulative Model Updates: 38460
Cumulative Timesteps: 321060542

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.46520
Policy Entropy: 1.26645
Value Function Loss: 0.02603

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.07595
Policy Update Magnitude: 0.12655
Value Function Update Magnitude: 0.21262

Collected Steps per Second: 9666.36094
Overall Steps per Second: 6721.41808

Timestep Collection Time: 5.17558
Timestep Consumption Time: 2.26764
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.44322

Cumulative Model Updates: 38466
Cumulative Timesteps: 321110571

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.41833
Policy Entropy: 1.26686
Value Function Loss: 0.02539

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.12842
Value Function Update Magnitude: 0.21266

Collected Steps per Second: 9793.63942
Overall Steps per Second: 6986.25059

Timestep Collection Time: 5.10923
Timestep Consumption Time: 2.05312
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.16235

Cumulative Model Updates: 38472
Cumulative Timesteps: 321160609

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.17254
Policy Entropy: 1.26409
Value Function Loss: 0.02561

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.12614
Value Function Update Magnitude: 0.21322

Collected Steps per Second: 9212.87885
Overall Steps per Second: 6415.14799

Timestep Collection Time: 5.42957
Timestep Consumption Time: 2.36791
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.79748

Cumulative Model Updates: 38478
Cumulative Timesteps: 321210631

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.72204
Policy Entropy: 1.26579
Value Function Loss: 0.02448

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.12636
Value Function Update Magnitude: 0.21822

Collected Steps per Second: 9556.73343
Overall Steps per Second: 6766.17622

Timestep Collection Time: 5.23683
Timestep Consumption Time: 2.15981
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.39664

Cumulative Model Updates: 38484
Cumulative Timesteps: 321260678

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.52372
Policy Entropy: 1.26301
Value Function Loss: 0.02458

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.13038
Value Function Update Magnitude: 0.21474

Collected Steps per Second: 9615.60139
Overall Steps per Second: 6857.17735

Timestep Collection Time: 5.20186
Timestep Consumption Time: 2.09254
PPO Batch Consumption Time: 0.02450
Total Iteration Time: 7.29440

Cumulative Model Updates: 38490
Cumulative Timesteps: 321310697

Timesteps Collected: 50019
--------END ITERATION REPORT--------


Saving checkpoint 321310697...
Checkpoint 321310697 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.35871
Policy Entropy: 1.25662
Value Function Loss: 0.02430

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.12833
Value Function Update Magnitude: 0.20296

Collected Steps per Second: 8886.14716
Overall Steps per Second: 6287.65249

Timestep Collection Time: 5.63067
Timestep Consumption Time: 2.32699
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 7.95766

Cumulative Model Updates: 38496
Cumulative Timesteps: 321360732

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.78125
Policy Entropy: 1.25570
Value Function Loss: 0.02347

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.12808
Value Function Update Magnitude: 0.20017

Collected Steps per Second: 9626.41318
Overall Steps per Second: 6760.94088

Timestep Collection Time: 5.19778
Timestep Consumption Time: 2.20296
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.40075

Cumulative Model Updates: 38502
Cumulative Timesteps: 321410768

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.84815
Policy Entropy: 1.25751
Value Function Loss: 0.02276

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.12582
Value Function Update Magnitude: 0.20624

Collected Steps per Second: 10087.87712
Overall Steps per Second: 7089.78488

Timestep Collection Time: 4.95872
Timestep Consumption Time: 2.09692
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 7.05564

Cumulative Model Updates: 38508
Cumulative Timesteps: 321460791

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.10501
Policy Entropy: 1.26174
Value Function Loss: 0.02432

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.12770
Value Function Update Magnitude: 0.22762

Collected Steps per Second: 9953.59937
Overall Steps per Second: 7111.05558

Timestep Collection Time: 5.02492
Timestep Consumption Time: 2.00864
PPO Batch Consumption Time: 0.02533
Total Iteration Time: 7.03355

Cumulative Model Updates: 38514
Cumulative Timesteps: 321510807

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.61089
Policy Entropy: 1.26336
Value Function Loss: 0.02412

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.12690
Value Function Update Magnitude: 0.22204

Collected Steps per Second: 10506.76283
Overall Steps per Second: 7427.52107

Timestep Collection Time: 4.76312
Timestep Consumption Time: 1.97466
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 6.73778

Cumulative Model Updates: 38520
Cumulative Timesteps: 321560852

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.69264
Policy Entropy: 1.26530
Value Function Loss: 0.02378

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.12655
Value Function Update Magnitude: 0.21229

Collected Steps per Second: 10047.24315
Overall Steps per Second: 7021.39662

Timestep Collection Time: 4.97858
Timestep Consumption Time: 2.14550
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.12408

Cumulative Model Updates: 38526
Cumulative Timesteps: 321610873

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.00878
Policy Entropy: 1.26613
Value Function Loss: 0.02387

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.12770
Value Function Update Magnitude: 0.19746

Collected Steps per Second: 9766.74062
Overall Steps per Second: 7003.01160

Timestep Collection Time: 5.11952
Timestep Consumption Time: 2.02041
PPO Batch Consumption Time: 0.02870
Total Iteration Time: 7.13993

Cumulative Model Updates: 38532
Cumulative Timesteps: 321660874

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.95320
Policy Entropy: 1.26716
Value Function Loss: 0.02534

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.13190
Value Function Update Magnitude: 0.20017

Collected Steps per Second: 9527.56406
Overall Steps per Second: 6606.55807

Timestep Collection Time: 5.25045
Timestep Consumption Time: 2.32142
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.57187

Cumulative Model Updates: 38538
Cumulative Timesteps: 321710898

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.55104
Policy Entropy: 1.26350
Value Function Loss: 0.02628

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.13989
Value Function Update Magnitude: 0.20646

Collected Steps per Second: 10458.64370
Overall Steps per Second: 7332.19790

Timestep Collection Time: 4.78169
Timestep Consumption Time: 2.03891
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 6.82060

Cumulative Model Updates: 38544
Cumulative Timesteps: 321760908

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.53637
Policy Entropy: 1.26480
Value Function Loss: 0.02480

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.13230
Value Function Update Magnitude: 0.21533

Collected Steps per Second: 10478.67544
Overall Steps per Second: 7293.79266

Timestep Collection Time: 4.77312
Timestep Consumption Time: 2.08422
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 6.85734

Cumulative Model Updates: 38550
Cumulative Timesteps: 321810924

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 321810924...
Checkpoint 321810924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.26390
Policy Entropy: 1.27370
Value Function Loss: 0.02441

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.12949
Value Function Update Magnitude: 0.22143

Collected Steps per Second: 10027.82064
Overall Steps per Second: 7060.86119

Timestep Collection Time: 4.98842
Timestep Consumption Time: 2.09612
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 7.08455

Cumulative Model Updates: 38556
Cumulative Timesteps: 321860947

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.18868
Policy Entropy: 1.27057
Value Function Loss: 0.02306

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.12895
Value Function Update Magnitude: 0.21793

Collected Steps per Second: 9345.59582
Overall Steps per Second: 6544.75416

Timestep Collection Time: 5.35386
Timestep Consumption Time: 2.29120
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.64505

Cumulative Model Updates: 38562
Cumulative Timesteps: 321910982

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.34630
Policy Entropy: 1.27324
Value Function Loss: 0.02379

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.13103
Value Function Update Magnitude: 0.22415

Collected Steps per Second: 9606.66021
Overall Steps per Second: 6867.13007

Timestep Collection Time: 5.20732
Timestep Consumption Time: 2.07738
PPO Batch Consumption Time: 0.02417
Total Iteration Time: 7.28470

Cumulative Model Updates: 38568
Cumulative Timesteps: 321961007

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.50073
Policy Entropy: 1.26772
Value Function Loss: 0.02308

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.13400
Value Function Update Magnitude: 0.22531

Collected Steps per Second: 10408.94248
Overall Steps per Second: 7058.11421

Timestep Collection Time: 4.80616
Timestep Consumption Time: 2.28171
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 7.08787

Cumulative Model Updates: 38574
Cumulative Timesteps: 322011034

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.43815
Policy Entropy: 1.26880
Value Function Loss: 0.02376

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.13608
Value Function Update Magnitude: 0.22588

Collected Steps per Second: 9279.90872
Overall Steps per Second: 6511.23077

Timestep Collection Time: 5.38798
Timestep Consumption Time: 2.29106
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 7.67904

Cumulative Model Updates: 38580
Cumulative Timesteps: 322061034

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.18427
Policy Entropy: 1.27178
Value Function Loss: 0.02454

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.13110
Value Function Update Magnitude: 0.21809

Collected Steps per Second: 9202.82342
Overall Steps per Second: 6605.96366

Timestep Collection Time: 5.43583
Timestep Consumption Time: 2.13687
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 7.57270

Cumulative Model Updates: 38586
Cumulative Timesteps: 322111059

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.27159
Policy Entropy: 1.26672
Value Function Loss: 0.02451

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.13178
Value Function Update Magnitude: 0.21414

Collected Steps per Second: 10191.56985
Overall Steps per Second: 6814.00487

Timestep Collection Time: 4.90984
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 7.34355

Cumulative Model Updates: 38592
Cumulative Timesteps: 322161098

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.06299
Policy Entropy: 1.26397
Value Function Loss: 0.02462

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.12768
Value Function Update Magnitude: 0.21995

Collected Steps per Second: 9426.33355
Overall Steps per Second: 6529.91315

Timestep Collection Time: 5.30864
Timestep Consumption Time: 2.35471
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.66335

Cumulative Model Updates: 38598
Cumulative Timesteps: 322211139

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.30315
Policy Entropy: 1.26250
Value Function Loss: 0.02401

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.21501

Collected Steps per Second: 9537.94232
Overall Steps per Second: 6799.95507

Timestep Collection Time: 5.24358
Timestep Consumption Time: 2.11132
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 7.35490

Cumulative Model Updates: 38604
Cumulative Timesteps: 322261152

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.34688
Policy Entropy: 1.26196
Value Function Loss: 0.02550

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.13157
Value Function Update Magnitude: 0.22375

Collected Steps per Second: 10023.16894
Overall Steps per Second: 7237.63372

Timestep Collection Time: 4.99104
Timestep Consumption Time: 1.92089
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 6.91193

Cumulative Model Updates: 38610
Cumulative Timesteps: 322311178

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 322311178...
Checkpoint 322311178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.82642
Policy Entropy: 1.26762
Value Function Loss: 0.02592

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.13293
Value Function Update Magnitude: 0.22688

Collected Steps per Second: 9854.52278
Overall Steps per Second: 7001.22256

Timestep Collection Time: 5.07635
Timestep Consumption Time: 2.06883
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 7.14518

Cumulative Model Updates: 38616
Cumulative Timesteps: 322361203

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.08286
Policy Entropy: 1.27082
Value Function Loss: 0.02586

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.12953
Value Function Update Magnitude: 0.22472

Collected Steps per Second: 9172.08064
Overall Steps per Second: 6683.18196

Timestep Collection Time: 5.45460
Timestep Consumption Time: 2.03136
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 7.48596

Cumulative Model Updates: 38622
Cumulative Timesteps: 322411233

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.57789
Policy Entropy: 1.27906
Value Function Loss: 0.02567

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.13095
Value Function Update Magnitude: 0.20874

Collected Steps per Second: 9479.45963
Overall Steps per Second: 6834.94465

Timestep Collection Time: 5.27752
Timestep Consumption Time: 2.04193
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 7.31944

Cumulative Model Updates: 38628
Cumulative Timesteps: 322461261

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.59197
Policy Entropy: 1.27789
Value Function Loss: 0.02524

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.12815
Value Function Update Magnitude: 0.20712

Collected Steps per Second: 10575.25753
Overall Steps per Second: 7501.41527

Timestep Collection Time: 4.72877
Timestep Consumption Time: 1.93770
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 6.66648

Cumulative Model Updates: 38634
Cumulative Timesteps: 322511269

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.15167
Policy Entropy: 1.27665
Value Function Loss: 0.02457

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.12852
Value Function Update Magnitude: 0.23134

Collected Steps per Second: 9850.27723
Overall Steps per Second: 7194.32950

Timestep Collection Time: 5.07823
Timestep Consumption Time: 1.87474
PPO Batch Consumption Time: 0.02488
Total Iteration Time: 6.95298

Cumulative Model Updates: 38640
Cumulative Timesteps: 322561291

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.83449
Policy Entropy: 1.27252
Value Function Loss: 0.02456

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.12752
Value Function Update Magnitude: 0.23571

Collected Steps per Second: 9881.28645
Overall Steps per Second: 7192.36465

Timestep Collection Time: 5.06169
Timestep Consumption Time: 1.89235
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 6.95404

Cumulative Model Updates: 38646
Cumulative Timesteps: 322611307

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.14912
Policy Entropy: 1.27015
Value Function Loss: 0.02427

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.12759
Value Function Update Magnitude: 0.22687

Collected Steps per Second: 10878.85947
Overall Steps per Second: 7600.92447

Timestep Collection Time: 4.59874
Timestep Consumption Time: 1.98323
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 6.58196

Cumulative Model Updates: 38652
Cumulative Timesteps: 322661336

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.20589
Policy Entropy: 1.26506
Value Function Loss: 0.02428

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.12207
Value Function Update Magnitude: 0.20942

Collected Steps per Second: 9565.33245
Overall Steps per Second: 6829.28831

Timestep Collection Time: 5.23024
Timestep Consumption Time: 2.09541
PPO Batch Consumption Time: 0.02540
Total Iteration Time: 7.32565

Cumulative Model Updates: 38658
Cumulative Timesteps: 322711365

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.22948
Policy Entropy: 1.27383
Value Function Loss: 0.02448

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.12338
Value Function Update Magnitude: 0.20380

Collected Steps per Second: 9099.84942
Overall Steps per Second: 6611.46502

Timestep Collection Time: 5.49690
Timestep Consumption Time: 2.06889
PPO Batch Consumption Time: 0.02553
Total Iteration Time: 7.56580

Cumulative Model Updates: 38664
Cumulative Timesteps: 322761386

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.34822
Policy Entropy: 1.27704
Value Function Loss: 0.02442

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.12470
Value Function Update Magnitude: 0.21520

Collected Steps per Second: 10438.07734
Overall Steps per Second: 7252.70498

Timestep Collection Time: 4.79236
Timestep Consumption Time: 2.10479
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 6.89715

Cumulative Model Updates: 38670
Cumulative Timesteps: 322811409

Timesteps Collected: 50023
--------END ITERATION REPORT--------


Saving checkpoint 322811409...
Checkpoint 322811409 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.80716
Policy Entropy: 1.27649
Value Function Loss: 0.02435

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.12534
Value Function Update Magnitude: 0.23790

Collected Steps per Second: 10113.71247
Overall Steps per Second: 6898.41356

Timestep Collection Time: 4.94645
Timestep Consumption Time: 2.30550
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 7.25196

Cumulative Model Updates: 38676
Cumulative Timesteps: 322861436

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.06933
Policy Entropy: 1.26941
Value Function Loss: 0.02343

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.12261
Value Function Update Magnitude: 0.23498

Collected Steps per Second: 9080.12990
Overall Steps per Second: 6444.38572

Timestep Collection Time: 5.51149
Timestep Consumption Time: 2.25419
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 7.76567

Cumulative Model Updates: 38682
Cumulative Timesteps: 322911481

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.96262
Policy Entropy: 1.27301
Value Function Loss: 0.02430

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.12350
Value Function Update Magnitude: 0.24392

Collected Steps per Second: 9539.06681
Overall Steps per Second: 6706.99539

Timestep Collection Time: 5.24181
Timestep Consumption Time: 2.21339
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 7.45520

Cumulative Model Updates: 38688
Cumulative Timesteps: 322961483

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.54319
Policy Entropy: 1.27385
Value Function Loss: 0.02553

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.12693
Value Function Update Magnitude: 0.23437

Collected Steps per Second: 9308.33035
Overall Steps per Second: 6692.54659

Timestep Collection Time: 5.37422
Timestep Consumption Time: 2.10051
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 7.47473

Cumulative Model Updates: 38694
Cumulative Timesteps: 323011508

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.85925
Policy Entropy: 1.26618
Value Function Loss: 0.02595

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.12896
Value Function Update Magnitude: 0.23840

Collected Steps per Second: 9309.05134
Overall Steps per Second: 6674.29070

Timestep Collection Time: 5.37369
Timestep Consumption Time: 2.12133
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 7.49503

Cumulative Model Updates: 38700
Cumulative Timesteps: 323061532

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.81149
Policy Entropy: 1.26296
Value Function Loss: 0.02541

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.12660
Value Function Update Magnitude: 0.23813

Collected Steps per Second: 9637.77861
Overall Steps per Second: 6639.31712

Timestep Collection Time: 5.19207
Timestep Consumption Time: 2.34485
PPO Batch Consumption Time: 0.02517
Total Iteration Time: 7.53692

Cumulative Model Updates: 38706
Cumulative Timesteps: 323111572

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.95763
Policy Entropy: 1.26559
Value Function Loss: 0.02543

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.12718
Value Function Update Magnitude: 0.23457

Collected Steps per Second: 9313.99398
Overall Steps per Second: 6650.92140

Timestep Collection Time: 5.37020
Timestep Consumption Time: 2.15026
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.52046

Cumulative Model Updates: 38712
Cumulative Timesteps: 323161590

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.53284
Policy Entropy: 1.26799
Value Function Loss: 0.02459

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.12486
Value Function Update Magnitude: 0.23053

Collected Steps per Second: 9290.05693
Overall Steps per Second: 6785.54067

Timestep Collection Time: 5.38576
Timestep Consumption Time: 1.98786
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.37362

Cumulative Model Updates: 38718
Cumulative Timesteps: 323211624

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.93246
Policy Entropy: 1.27205
Value Function Loss: 0.02429

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.12320
Value Function Update Magnitude: 0.22260

Collected Steps per Second: 9554.22057
Overall Steps per Second: 6580.15965

Timestep Collection Time: 5.23789
Timestep Consumption Time: 2.36739
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 7.60529

Cumulative Model Updates: 38724
Cumulative Timesteps: 323261668

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.90073
Policy Entropy: 1.26589
Value Function Loss: 0.02372

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.12191
Value Function Update Magnitude: 0.22521

Collected Steps per Second: 9449.11224
Overall Steps per Second: 6803.19129

Timestep Collection Time: 5.29510
Timestep Consumption Time: 2.05939
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.35449

Cumulative Model Updates: 38730
Cumulative Timesteps: 323311702

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 323311702...
Checkpoint 323311702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.07841
Policy Entropy: 1.27125
Value Function Loss: 0.02532

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.12262
Value Function Update Magnitude: 0.22437

Collected Steps per Second: 9791.39446
Overall Steps per Second: 7096.28680

Timestep Collection Time: 5.10990
Timestep Consumption Time: 1.94069
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 7.05059

Cumulative Model Updates: 38736
Cumulative Timesteps: 323361735

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.38001
Policy Entropy: 1.27403
Value Function Loss: 0.02518

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.06795
Policy Update Magnitude: 0.12768
Value Function Update Magnitude: 0.23144

Collected Steps per Second: 9850.62699
Overall Steps per Second: 6863.25784

Timestep Collection Time: 5.07805
Timestep Consumption Time: 2.21032
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.28838

Cumulative Model Updates: 38742
Cumulative Timesteps: 323411757

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.84979
Policy Entropy: 1.27401
Value Function Loss: 0.02369

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.12550
Value Function Update Magnitude: 0.22611

Collected Steps per Second: 9029.07459
Overall Steps per Second: 6594.76893

Timestep Collection Time: 5.53877
Timestep Consumption Time: 2.04451
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 7.58328

Cumulative Model Updates: 38748
Cumulative Timesteps: 323461767

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.37453
Policy Entropy: 1.27767
Value Function Loss: 0.02304

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.12569
Value Function Update Magnitude: 0.22567

Collected Steps per Second: 10044.12441
Overall Steps per Second: 7044.19788

Timestep Collection Time: 4.97993
Timestep Consumption Time: 2.12081
PPO Batch Consumption Time: 0.02463
Total Iteration Time: 7.10074

Cumulative Model Updates: 38754
Cumulative Timesteps: 323511786

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.78726
Policy Entropy: 1.26786
Value Function Loss: 0.02471

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.12182
Value Function Update Magnitude: 0.21959

Collected Steps per Second: 10963.78297
Overall Steps per Second: 7688.46536

Timestep Collection Time: 4.56321
Timestep Consumption Time: 1.94394
PPO Batch Consumption Time: 0.02556
Total Iteration Time: 6.50715

Cumulative Model Updates: 38760
Cumulative Timesteps: 323561816

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.98107
Policy Entropy: 1.27156
Value Function Loss: 0.02614

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.12376
Value Function Update Magnitude: 0.22647

Collected Steps per Second: 10250.23686
Overall Steps per Second: 7218.57095

Timestep Collection Time: 4.87998
Timestep Consumption Time: 2.04950
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 6.92949

Cumulative Model Updates: 38766
Cumulative Timesteps: 323611837

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.03228
Policy Entropy: 1.26938
Value Function Loss: 0.02665

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.12657
Value Function Update Magnitude: 0.22873

Collected Steps per Second: 10087.32586
Overall Steps per Second: 7270.69760

Timestep Collection Time: 4.95672
Timestep Consumption Time: 1.92020
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 6.87692

Cumulative Model Updates: 38772
Cumulative Timesteps: 323661837

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.08035
Policy Entropy: 1.27464
Value Function Loss: 0.02562

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.12878
Value Function Update Magnitude: 0.22059

Collected Steps per Second: 10421.37939
Overall Steps per Second: 7370.36491

Timestep Collection Time: 4.79793
Timestep Consumption Time: 1.98613
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 6.78406

Cumulative Model Updates: 38778
Cumulative Timesteps: 323711838

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.85860
Policy Entropy: 1.27785
Value Function Loss: 0.02580

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.12946
Value Function Update Magnitude: 0.21740

Collected Steps per Second: 9444.70942
Overall Steps per Second: 6815.28000

Timestep Collection Time: 5.29482
Timestep Consumption Time: 2.04281
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 7.33763

Cumulative Model Updates: 38784
Cumulative Timesteps: 323761846

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.89350
Policy Entropy: 1.27629
Value Function Loss: 0.02609

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.12913
Value Function Update Magnitude: 0.22237

Collected Steps per Second: 8978.89720
Overall Steps per Second: 6560.88004

Timestep Collection Time: 5.56939
Timestep Consumption Time: 2.05260
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 7.62200

Cumulative Model Updates: 38790
Cumulative Timesteps: 323811853

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 323811853...
Checkpoint 323811853 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.87361
Policy Entropy: 1.27442
Value Function Loss: 0.02572

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07434
Policy Update Magnitude: 0.12567
Value Function Update Magnitude: 0.22517

Collected Steps per Second: 10583.76911
Overall Steps per Second: 7445.51080

Timestep Collection Time: 4.72488
Timestep Consumption Time: 1.99152
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 6.71640

Cumulative Model Updates: 38796
Cumulative Timesteps: 323861860

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.51697
Policy Entropy: 1.27308
Value Function Loss: 0.02513

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07018
Policy Update Magnitude: 0.12443
Value Function Update Magnitude: 0.22226

Collected Steps per Second: 10082.62075
Overall Steps per Second: 6979.29121

Timestep Collection Time: 4.95933
Timestep Consumption Time: 2.20516
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 7.16448

Cumulative Model Updates: 38802
Cumulative Timesteps: 323911863

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.31532
Policy Entropy: 1.27353
Value Function Loss: 0.02382

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.12748
Value Function Update Magnitude: 0.21457

Collected Steps per Second: 8938.26009
Overall Steps per Second: 6503.27755

Timestep Collection Time: 5.59818
Timestep Consumption Time: 2.09609
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 7.69427

Cumulative Model Updates: 38808
Cumulative Timesteps: 323961901

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.23573
Policy Entropy: 1.27488
Value Function Loss: 0.02320

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.12488
Value Function Update Magnitude: 0.20859

Collected Steps per Second: 10080.14740
Overall Steps per Second: 7161.32583

Timestep Collection Time: 4.96282
Timestep Consumption Time: 2.02275
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 6.98558

Cumulative Model Updates: 38814
Cumulative Timesteps: 324011927

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.06603
Policy Entropy: 1.26879
Value Function Loss: 0.02493

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.12633
Value Function Update Magnitude: 0.21076

Collected Steps per Second: 9074.96956
Overall Steps per Second: 6474.78941

Timestep Collection Time: 5.51208
Timestep Consumption Time: 2.21357
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.72566

Cumulative Model Updates: 38820
Cumulative Timesteps: 324061949

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.32141
Policy Entropy: 1.26869
Value Function Loss: 0.02569

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.12596
Value Function Update Magnitude: 0.21924

Collected Steps per Second: 8865.31926
Overall Steps per Second: 6359.82360

Timestep Collection Time: 5.64018
Timestep Consumption Time: 2.22199
PPO Batch Consumption Time: 0.02875
Total Iteration Time: 7.86217

Cumulative Model Updates: 38826
Cumulative Timesteps: 324111951

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.69504
Policy Entropy: 1.26719
Value Function Loss: 0.02610

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.12564
Value Function Update Magnitude: 0.21353

Collected Steps per Second: 9807.64512
Overall Steps per Second: 6820.84515

Timestep Collection Time: 5.09806
Timestep Consumption Time: 2.23241
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 7.33047

Cumulative Model Updates: 38832
Cumulative Timesteps: 324161951

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.55109
Policy Entropy: 1.27128
Value Function Loss: 0.02484

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.12056
Value Function Update Magnitude: 0.21707

Collected Steps per Second: 9228.96639
Overall Steps per Second: 6636.25183

Timestep Collection Time: 5.41935
Timestep Consumption Time: 2.11728
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 7.53663

Cumulative Model Updates: 38838
Cumulative Timesteps: 324211966

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.38229
Policy Entropy: 1.27365
Value Function Loss: 0.02348

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.11977
Value Function Update Magnitude: 0.21306

Collected Steps per Second: 9162.90069
Overall Steps per Second: 6468.27562

Timestep Collection Time: 5.45973
Timestep Consumption Time: 2.27448
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 7.73421

Cumulative Model Updates: 38844
Cumulative Timesteps: 324261993

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.46274
Policy Entropy: 1.27756
Value Function Loss: 0.02430

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.12072
Value Function Update Magnitude: 0.20803

Collected Steps per Second: 9811.31413
Overall Steps per Second: 6751.68501

Timestep Collection Time: 5.09738
Timestep Consumption Time: 2.30996
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 7.40734

Cumulative Model Updates: 38850
Cumulative Timesteps: 324312005

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 324312005...
Checkpoint 324312005 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.95614
Policy Entropy: 1.27620
Value Function Loss: 0.02385

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.12211
Value Function Update Magnitude: 0.21296

Collected Steps per Second: 9055.15230
Overall Steps per Second: 6599.77852

Timestep Collection Time: 5.52371
Timestep Consumption Time: 2.05503
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 7.57874

Cumulative Model Updates: 38856
Cumulative Timesteps: 324362023

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.13417
Policy Entropy: 1.27225
Value Function Loss: 0.02438

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.12154
Value Function Update Magnitude: 0.21208

Collected Steps per Second: 9851.80520
Overall Steps per Second: 7121.57388

Timestep Collection Time: 5.07876
Timestep Consumption Time: 1.94707
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 7.02583

Cumulative Model Updates: 38862
Cumulative Timesteps: 324412058

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.64077
Policy Entropy: 1.27506
Value Function Loss: 0.02325

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.12215
Value Function Update Magnitude: 0.20476

Collected Steps per Second: 10554.51645
Overall Steps per Second: 7426.45293

Timestep Collection Time: 4.73807
Timestep Consumption Time: 1.99570
PPO Batch Consumption Time: 0.02502
Total Iteration Time: 6.73377

Cumulative Model Updates: 38868
Cumulative Timesteps: 324462066

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.46238
Policy Entropy: 1.27546
Value Function Loss: 0.02272

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.11965
Value Function Update Magnitude: 0.19579

Collected Steps per Second: 9317.94745
Overall Steps per Second: 6408.61860

Timestep Collection Time: 5.37060
Timestep Consumption Time: 2.43810
PPO Batch Consumption Time: 0.02924
Total Iteration Time: 7.80870

Cumulative Model Updates: 38874
Cumulative Timesteps: 324512109

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.84562
Policy Entropy: 1.27880
Value Function Loss: 0.02202

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.08621
Policy Update Magnitude: 0.11538
Value Function Update Magnitude: 0.19310

Collected Steps per Second: 9108.45981
Overall Steps per Second: 6515.63786

Timestep Collection Time: 5.49116
Timestep Consumption Time: 2.18514
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 7.67630

Cumulative Model Updates: 38880
Cumulative Timesteps: 324562125

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.19580
Policy Entropy: 1.27178
Value Function Loss: 0.02199

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.11272
Value Function Update Magnitude: 0.19858

Collected Steps per Second: 10533.68669
Overall Steps per Second: 7258.39012

Timestep Collection Time: 4.75000
Timestep Consumption Time: 2.14340
PPO Batch Consumption Time: 0.02871
Total Iteration Time: 6.89340

Cumulative Model Updates: 38886
Cumulative Timesteps: 324612160

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.25372
Policy Entropy: 1.26523
Value Function Loss: 0.02324

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.11791
Value Function Update Magnitude: 0.20372

Collected Steps per Second: 9935.07651
Overall Steps per Second: 7015.78139

Timestep Collection Time: 5.03630
Timestep Consumption Time: 2.09562
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 7.13192

Cumulative Model Updates: 38892
Cumulative Timesteps: 324662196

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.67662
Policy Entropy: 1.26130
Value Function Loss: 0.02442

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.11912
Value Function Update Magnitude: 0.20823

Collected Steps per Second: 9502.40631
Overall Steps per Second: 6874.39799

Timestep Collection Time: 5.26498
Timestep Consumption Time: 2.01275
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 7.27773

Cumulative Model Updates: 38898
Cumulative Timesteps: 324712226

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.19515
Policy Entropy: 1.26756
Value Function Loss: 0.02417

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.12464
Value Function Update Magnitude: 0.21007

Collected Steps per Second: 10063.50869
Overall Steps per Second: 6744.90134

Timestep Collection Time: 4.97053
Timestep Consumption Time: 2.44559
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 7.41612

Cumulative Model Updates: 38904
Cumulative Timesteps: 324762247

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.30795
Policy Entropy: 1.26569
Value Function Loss: 0.02289

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.12156
Value Function Update Magnitude: 0.21803

Collected Steps per Second: 9707.36940
Overall Steps per Second: 6716.10314

Timestep Collection Time: 5.15392
Timestep Consumption Time: 2.29549
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 7.44941

Cumulative Model Updates: 38910
Cumulative Timesteps: 324812278

Timesteps Collected: 50031
--------END ITERATION REPORT--------


Saving checkpoint 324812278...
Checkpoint 324812278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.02063
Policy Entropy: 1.26574
Value Function Loss: 0.02202

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.11865
Value Function Update Magnitude: 0.21504

Collected Steps per Second: 9696.19446
Overall Steps per Second: 6876.79342

Timestep Collection Time: 5.16068
Timestep Consumption Time: 2.11582
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 7.27650

Cumulative Model Updates: 38916
Cumulative Timesteps: 324862317

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.57511
Policy Entropy: 1.26466
Value Function Loss: 0.02401

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.11827
Value Function Update Magnitude: 0.22734

Collected Steps per Second: 9546.83244
Overall Steps per Second: 6826.88562

Timestep Collection Time: 5.24174
Timestep Consumption Time: 2.08840
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.33014

Cumulative Model Updates: 38922
Cumulative Timesteps: 324912359

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.61363
Policy Entropy: 1.26982
Value Function Loss: 0.02473

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.12059
Value Function Update Magnitude: 0.24415

Collected Steps per Second: 9740.13250
Overall Steps per Second: 6855.49272

Timestep Collection Time: 5.13792
Timestep Consumption Time: 2.16192
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.29984

Cumulative Model Updates: 38928
Cumulative Timesteps: 324962403

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.80276
Policy Entropy: 1.26296
Value Function Loss: 0.02516

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.12303
Value Function Update Magnitude: 0.23228

Collected Steps per Second: 9128.62315
Overall Steps per Second: 6593.93944

Timestep Collection Time: 5.47881
Timestep Consumption Time: 2.10603
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 7.58484

Cumulative Model Updates: 38934
Cumulative Timesteps: 325012417

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.34749
Policy Entropy: 1.25526
Value Function Loss: 0.02283

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.12076
Value Function Update Magnitude: 0.21957

Collected Steps per Second: 9649.04301
Overall Steps per Second: 6945.85329

Timestep Collection Time: 5.18196
Timestep Consumption Time: 2.01672
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.19868

Cumulative Model Updates: 38940
Cumulative Timesteps: 325062418

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.82171
Policy Entropy: 1.25645
Value Function Loss: 0.02367

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.11899
Value Function Update Magnitude: 0.21884

Collected Steps per Second: 9847.75834
Overall Steps per Second: 6940.94815

Timestep Collection Time: 5.08156
Timestep Consumption Time: 2.12812
PPO Batch Consumption Time: 0.02451
Total Iteration Time: 7.20968

Cumulative Model Updates: 38946
Cumulative Timesteps: 325112460

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.92471
Policy Entropy: 1.25964
Value Function Loss: 0.02309

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.12028
Value Function Update Magnitude: 0.21838

Collected Steps per Second: 9138.48612
Overall Steps per Second: 6690.46081

Timestep Collection Time: 5.47268
Timestep Consumption Time: 2.00244
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.47512

Cumulative Model Updates: 38952
Cumulative Timesteps: 325162472

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.08587
Policy Entropy: 1.25806
Value Function Loss: 0.02501

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.12189
Value Function Update Magnitude: 0.22360

Collected Steps per Second: 10356.35750
Overall Steps per Second: 6990.02809

Timestep Collection Time: 4.83249
Timestep Consumption Time: 2.32728
PPO Batch Consumption Time: 0.02444
Total Iteration Time: 7.15977

Cumulative Model Updates: 38958
Cumulative Timesteps: 325212519

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.44466
Policy Entropy: 1.26155
Value Function Loss: 0.02360

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.11823
Value Function Update Magnitude: 0.22047

Collected Steps per Second: 10628.51600
Overall Steps per Second: 7108.36226

Timestep Collection Time: 4.70545
Timestep Consumption Time: 2.33020
PPO Batch Consumption Time: 0.02923
Total Iteration Time: 7.03566

Cumulative Model Updates: 38964
Cumulative Timesteps: 325262531

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.78752
Policy Entropy: 1.26867
Value Function Loss: 0.02539

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.12161
Value Function Update Magnitude: 0.22283

Collected Steps per Second: 9419.67183
Overall Steps per Second: 6765.71317

Timestep Collection Time: 5.31091
Timestep Consumption Time: 2.08329
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 7.39419

Cumulative Model Updates: 38970
Cumulative Timesteps: 325312558

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 325312558...
Checkpoint 325312558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.92317
Policy Entropy: 1.27326
Value Function Loss: 0.02496

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.12055
Value Function Update Magnitude: 0.22791

Collected Steps per Second: 10007.28327
Overall Steps per Second: 6748.13800

Timestep Collection Time: 4.99836
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.41242

Cumulative Model Updates: 38976
Cumulative Timesteps: 325362578

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.70860
Policy Entropy: 1.27340
Value Function Loss: 0.02685

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.12203
Value Function Update Magnitude: 0.23685

Collected Steps per Second: 9868.22935
Overall Steps per Second: 6780.44159

Timestep Collection Time: 5.06737
Timestep Consumption Time: 2.30766
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 7.37504

Cumulative Model Updates: 38982
Cumulative Timesteps: 325412584

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.37702
Policy Entropy: 1.26576
Value Function Loss: 0.02609

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.13101
Value Function Update Magnitude: 0.23552

Collected Steps per Second: 9527.79256
Overall Steps per Second: 6884.99052

Timestep Collection Time: 5.24791
Timestep Consumption Time: 2.01441
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 7.26232

Cumulative Model Updates: 38988
Cumulative Timesteps: 325462585

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.96528
Policy Entropy: 1.26606
Value Function Loss: 0.02541

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.12659
Value Function Update Magnitude: 0.22600

Collected Steps per Second: 9523.83893
Overall Steps per Second: 6861.35772

Timestep Collection Time: 5.25313
Timestep Consumption Time: 2.03843
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 7.29156

Cumulative Model Updates: 38994
Cumulative Timesteps: 325512615

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.55798
Policy Entropy: 1.26790
Value Function Loss: 0.02506

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.12393
Value Function Update Magnitude: 0.21504

Collected Steps per Second: 9713.19149
Overall Steps per Second: 6864.95959

Timestep Collection Time: 5.14990
Timestep Consumption Time: 2.13667
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 7.28657

Cumulative Model Updates: 39000
Cumulative Timesteps: 325562637

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.11982
Policy Entropy: 1.27347
Value Function Loss: 0.02485

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.12623
Value Function Update Magnitude: 0.21364

Collected Steps per Second: 9379.27496
Overall Steps per Second: 6752.43133

Timestep Collection Time: 5.33421
Timestep Consumption Time: 2.07512
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 7.40933

Cumulative Model Updates: 39006
Cumulative Timesteps: 325612668

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.72804
Policy Entropy: 1.27393
Value Function Loss: 0.02602

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.12449
Value Function Update Magnitude: 0.21840

Collected Steps per Second: 10390.44499
Overall Steps per Second: 7043.31551

Timestep Collection Time: 4.81298
Timestep Consumption Time: 2.28723
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 7.10021

Cumulative Model Updates: 39012
Cumulative Timesteps: 325662677

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.73855
Policy Entropy: 1.27606
Value Function Loss: 0.02484

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.12098
Value Function Update Magnitude: 0.21618

Collected Steps per Second: 10005.23147
Overall Steps per Second: 6937.15224

Timestep Collection Time: 4.99829
Timestep Consumption Time: 2.21058
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 7.20887

Cumulative Model Updates: 39018
Cumulative Timesteps: 325712686

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.96999
Policy Entropy: 1.27789
Value Function Loss: 0.02569

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.07710
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.22492

Collected Steps per Second: 9253.28415
Overall Steps per Second: 6687.40181

Timestep Collection Time: 5.40424
Timestep Consumption Time: 2.07355
PPO Batch Consumption Time: 0.02438
Total Iteration Time: 7.47779

Cumulative Model Updates: 39024
Cumulative Timesteps: 325762693

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.24254
Policy Entropy: 1.27874
Value Function Loss: 0.02590

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.12483
Value Function Update Magnitude: 0.22524

Collected Steps per Second: 9316.79491
Overall Steps per Second: 6616.14672

Timestep Collection Time: 5.37159
Timestep Consumption Time: 2.19263
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.56422

Cumulative Model Updates: 39030
Cumulative Timesteps: 325812739

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 325812739...
Checkpoint 325812739 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.21306
Policy Entropy: 1.27830
Value Function Loss: 0.02526

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.12262
Value Function Update Magnitude: 0.22298

Collected Steps per Second: 9917.32373
Overall Steps per Second: 6833.64097

Timestep Collection Time: 5.04531
Timestep Consumption Time: 2.27670
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 7.32201

Cumulative Model Updates: 39036
Cumulative Timesteps: 325862775

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.18775
Policy Entropy: 1.26959
Value Function Loss: 0.02394

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.12085
Value Function Update Magnitude: 0.22116

Collected Steps per Second: 9781.35499
Overall Steps per Second: 6974.24015

Timestep Collection Time: 5.11238
Timestep Consumption Time: 2.05772
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.17010

Cumulative Model Updates: 39042
Cumulative Timesteps: 325912781

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.64694
Policy Entropy: 1.27182
Value Function Loss: 0.02419

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.12176
Value Function Update Magnitude: 0.21939

Collected Steps per Second: 9834.63687
Overall Steps per Second: 6785.13536

Timestep Collection Time: 5.08661
Timestep Consumption Time: 2.28612
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 7.37273

Cumulative Model Updates: 39048
Cumulative Timesteps: 325962806

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.78888
Policy Entropy: 1.27084
Value Function Loss: 0.02499

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.12131
Value Function Update Magnitude: 0.22460

Collected Steps per Second: 9477.05854
Overall Steps per Second: 6739.67641

Timestep Collection Time: 5.27854
Timestep Consumption Time: 2.14393
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.42246

Cumulative Model Updates: 39054
Cumulative Timesteps: 326012831

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.97509
Policy Entropy: 1.27709
Value Function Loss: 0.02574

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.12319
Value Function Update Magnitude: 0.23213

Collected Steps per Second: 9969.76271
Overall Steps per Second: 7091.59318

Timestep Collection Time: 5.01807
Timestep Consumption Time: 2.03662
PPO Batch Consumption Time: 0.02519
Total Iteration Time: 7.05469

Cumulative Model Updates: 39060
Cumulative Timesteps: 326062860

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.22133
Policy Entropy: 1.27311
Value Function Loss: 0.02571

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.12252
Value Function Update Magnitude: 0.23016

Collected Steps per Second: 10117.78271
Overall Steps per Second: 7223.39490

Timestep Collection Time: 4.94268
Timestep Consumption Time: 1.98052
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 6.92320

Cumulative Model Updates: 39066
Cumulative Timesteps: 326112869

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.71952
Policy Entropy: 1.26716
Value Function Loss: 0.02419

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.11966
Value Function Update Magnitude: 0.21646

Collected Steps per Second: 9784.43442
Overall Steps per Second: 6893.35997

Timestep Collection Time: 5.11230
Timestep Consumption Time: 2.14410
PPO Batch Consumption Time: 0.02421
Total Iteration Time: 7.25640

Cumulative Model Updates: 39072
Cumulative Timesteps: 326162890

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.99538
Policy Entropy: 1.26183
Value Function Loss: 0.02447

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.12015
Value Function Update Magnitude: 0.20304

Collected Steps per Second: 9710.47970
Overall Steps per Second: 6971.80096

Timestep Collection Time: 5.15237
Timestep Consumption Time: 2.02397
PPO Batch Consumption Time: 0.02458
Total Iteration Time: 7.17634

Cumulative Model Updates: 39078
Cumulative Timesteps: 326212922

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.26989
Policy Entropy: 1.26342
Value Function Loss: 0.02461

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.11856
Value Function Update Magnitude: 0.20486

Collected Steps per Second: 10063.85915
Overall Steps per Second: 7136.84570

Timestep Collection Time: 4.96887
Timestep Consumption Time: 2.03787
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 7.00674

Cumulative Model Updates: 39084
Cumulative Timesteps: 326262928

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.25815
Policy Entropy: 1.26412
Value Function Loss: 0.02559

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.12076
Value Function Update Magnitude: 0.21059

Collected Steps per Second: 9909.22314
Overall Steps per Second: 6836.46368

Timestep Collection Time: 5.04853
Timestep Consumption Time: 2.26914
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 7.31767

Cumulative Model Updates: 39090
Cumulative Timesteps: 326312955

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 326312955...
Checkpoint 326312955 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.20742
Policy Entropy: 1.26489
Value Function Loss: 0.02571

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.12338
Value Function Update Magnitude: 0.21597

Collected Steps per Second: 10071.34442
Overall Steps per Second: 7229.13790

Timestep Collection Time: 4.96458
Timestep Consumption Time: 1.95187
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 6.91645

Cumulative Model Updates: 39096
Cumulative Timesteps: 326362955

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.44971
Policy Entropy: 1.26173
Value Function Loss: 0.02571

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.12635
Value Function Update Magnitude: 0.21748

Collected Steps per Second: 9452.02978
Overall Steps per Second: 6936.18263

Timestep Collection Time: 5.29008
Timestep Consumption Time: 1.91878
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 7.20886

Cumulative Model Updates: 39102
Cumulative Timesteps: 326412957

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.40241
Policy Entropy: 1.26337
Value Function Loss: 0.02568

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.12829
Value Function Update Magnitude: 0.21684

Collected Steps per Second: 10568.29805
Overall Steps per Second: 7434.61057

Timestep Collection Time: 4.73331
Timestep Consumption Time: 1.99509
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 6.72840

Cumulative Model Updates: 39108
Cumulative Timesteps: 326462980

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.81533
Policy Entropy: 1.26416
Value Function Loss: 0.02672

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.12634
Value Function Update Magnitude: 0.22138

Collected Steps per Second: 9559.38640
Overall Steps per Second: 6795.76409

Timestep Collection Time: 5.23391
Timestep Consumption Time: 2.12847
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.36238

Cumulative Model Updates: 39114
Cumulative Timesteps: 326513013

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.06981
Policy Entropy: 1.26377
Value Function Loss: 0.02627

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.12773
Value Function Update Magnitude: 0.22298

Collected Steps per Second: 9454.29439
Overall Steps per Second: 6722.52034

Timestep Collection Time: 5.28881
Timestep Consumption Time: 2.14917
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.43798

Cumulative Model Updates: 39120
Cumulative Timesteps: 326563015

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.33246
Policy Entropy: 1.26354
Value Function Loss: 0.02560

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.12669
Value Function Update Magnitude: 0.20933

Collected Steps per Second: 9307.04015
Overall Steps per Second: 6633.78350

Timestep Collection Time: 5.37432
Timestep Consumption Time: 2.16572
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.54004

Cumulative Model Updates: 39126
Cumulative Timesteps: 326613034

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.06694
Policy Entropy: 1.26134
Value Function Loss: 0.02481

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.12226
Value Function Update Magnitude: 0.20361

Collected Steps per Second: 9051.25176
Overall Steps per Second: 6561.88665

Timestep Collection Time: 5.52598
Timestep Consumption Time: 2.09637
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 7.62235

Cumulative Model Updates: 39132
Cumulative Timesteps: 326663051

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.62143
Policy Entropy: 1.26667
Value Function Loss: 0.02503

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.12095
Value Function Update Magnitude: 0.22298

Collected Steps per Second: 8907.61472
Overall Steps per Second: 6505.57867

Timestep Collection Time: 5.61699
Timestep Consumption Time: 2.07395
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 7.69094

Cumulative Model Updates: 39138
Cumulative Timesteps: 326713085

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.44737
Policy Entropy: 1.26424
Value Function Loss: 0.02587

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.23594

Collected Steps per Second: 9701.13386
Overall Steps per Second: 6708.33300

Timestep Collection Time: 5.15486
Timestep Consumption Time: 2.29975
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 7.45461

Cumulative Model Updates: 39144
Cumulative Timesteps: 326763093

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.86371
Policy Entropy: 1.26101
Value Function Loss: 0.02562

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.12523
Value Function Update Magnitude: 0.22182

Collected Steps per Second: 9594.25511
Overall Steps per Second: 6755.99241

Timestep Collection Time: 5.21531
Timestep Consumption Time: 2.19101
PPO Batch Consumption Time: 0.02849
Total Iteration Time: 7.40631

Cumulative Model Updates: 39150
Cumulative Timesteps: 326813130

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 326813130...
Checkpoint 326813130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.80042
Policy Entropy: 1.25253
Value Function Loss: 0.02510

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.12245
Value Function Update Magnitude: 0.21797

Collected Steps per Second: 9408.66521
Overall Steps per Second: 6698.82809

Timestep Collection Time: 5.31903
Timestep Consumption Time: 2.15168
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.47071

Cumulative Model Updates: 39156
Cumulative Timesteps: 326863175

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.87128
Policy Entropy: 1.24900
Value Function Loss: 0.02457

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.12290
Value Function Update Magnitude: 0.21605

Collected Steps per Second: 9548.74655
Overall Steps per Second: 6620.32679

Timestep Collection Time: 5.23912
Timestep Consumption Time: 2.31746
PPO Batch Consumption Time: 0.03088
Total Iteration Time: 7.55658

Cumulative Model Updates: 39162
Cumulative Timesteps: 326913202

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.09786
Policy Entropy: 1.25837
Value Function Loss: 0.02511

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.12256
Value Function Update Magnitude: 0.21369

Collected Steps per Second: 9154.51850
Overall Steps per Second: 6559.51254

Timestep Collection Time: 5.46473
Timestep Consumption Time: 2.16190
PPO Batch Consumption Time: 0.02415
Total Iteration Time: 7.62663

Cumulative Model Updates: 39168
Cumulative Timesteps: 326963229

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.64036
Policy Entropy: 1.26159
Value Function Loss: 0.02369

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.21355

Collected Steps per Second: 9005.61719
Overall Steps per Second: 6441.24275

Timestep Collection Time: 5.55353
Timestep Consumption Time: 2.21096
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 7.76450

Cumulative Model Updates: 39174
Cumulative Timesteps: 327013242

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.16771
Policy Entropy: 1.26072
Value Function Loss: 0.02288

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.12145
Value Function Update Magnitude: 0.19799

Collected Steps per Second: 10155.40737
Overall Steps per Second: 7077.06755

Timestep Collection Time: 4.92398
Timestep Consumption Time: 2.14180
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.06578

Cumulative Model Updates: 39180
Cumulative Timesteps: 327063247

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.26957
Policy Entropy: 1.25166
Value Function Loss: 0.02329

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.11883
Value Function Update Magnitude: 0.18953

Collected Steps per Second: 10246.98209
Overall Steps per Second: 7243.77513

Timestep Collection Time: 4.88027
Timestep Consumption Time: 2.02332
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 6.90358

Cumulative Model Updates: 39186
Cumulative Timesteps: 327113255

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.19718
Policy Entropy: 1.25266
Value Function Loss: 0.02430

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.12031
Value Function Update Magnitude: 0.19855

Collected Steps per Second: 10318.29348
Overall Steps per Second: 7402.82555

Timestep Collection Time: 4.84809
Timestep Consumption Time: 1.90933
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 6.75742

Cumulative Model Updates: 39192
Cumulative Timesteps: 327163279

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.38568
Policy Entropy: 1.25584
Value Function Loss: 0.02551

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.12174
Value Function Update Magnitude: 0.20923

Collected Steps per Second: 10179.84952
Overall Steps per Second: 7091.54633

Timestep Collection Time: 4.91530
Timestep Consumption Time: 2.14057
PPO Batch Consumption Time: 0.02442
Total Iteration Time: 7.05587

Cumulative Model Updates: 39198
Cumulative Timesteps: 327213316

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.07958
Policy Entropy: 1.26486
Value Function Loss: 0.02481

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.12105
Value Function Update Magnitude: 0.19791

Collected Steps per Second: 9304.85679
Overall Steps per Second: 6709.70018

Timestep Collection Time: 5.37655
Timestep Consumption Time: 2.07952
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 7.45607

Cumulative Model Updates: 39204
Cumulative Timesteps: 327263344

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.25737
Policy Entropy: 1.25986
Value Function Loss: 0.02477

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.12249
Value Function Update Magnitude: 0.19364

Collected Steps per Second: 9581.05516
Overall Steps per Second: 6852.31962

Timestep Collection Time: 5.21895
Timestep Consumption Time: 2.07829
PPO Batch Consumption Time: 0.02875
Total Iteration Time: 7.29724

Cumulative Model Updates: 39210
Cumulative Timesteps: 327313347

Timesteps Collected: 50003
--------END ITERATION REPORT--------


Saving checkpoint 327313347...
Checkpoint 327313347 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.26226
Policy Entropy: 1.26007
Value Function Loss: 0.02371

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.12116
Value Function Update Magnitude: 0.19492

Collected Steps per Second: 10284.51060
Overall Steps per Second: 7181.89558

Timestep Collection Time: 4.86246
Timestep Consumption Time: 2.10061
PPO Batch Consumption Time: 0.02497
Total Iteration Time: 6.96306

Cumulative Model Updates: 39216
Cumulative Timesteps: 327363355

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.48667
Policy Entropy: 1.25817
Value Function Loss: 0.02377

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.12346
Value Function Update Magnitude: 0.19364

Collected Steps per Second: 9349.27184
Overall Steps per Second: 6670.41366

Timestep Collection Time: 5.35090
Timestep Consumption Time: 2.14894
PPO Batch Consumption Time: 0.02396
Total Iteration Time: 7.49983

Cumulative Model Updates: 39222
Cumulative Timesteps: 327413382

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.62533
Policy Entropy: 1.26222
Value Function Loss: 0.02517

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.12564
Value Function Update Magnitude: 0.20056

Collected Steps per Second: 9781.26151
Overall Steps per Second: 6867.23932

Timestep Collection Time: 5.11304
Timestep Consumption Time: 2.16965
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 7.28269

Cumulative Model Updates: 39228
Cumulative Timesteps: 327463394

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.86101
Policy Entropy: 1.26318
Value Function Loss: 0.02513

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.12592
Value Function Update Magnitude: 0.21387

Collected Steps per Second: 10422.21144
Overall Steps per Second: 7138.04779

Timestep Collection Time: 4.80176
Timestep Consumption Time: 2.20926
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 7.01102

Cumulative Model Updates: 39234
Cumulative Timesteps: 327513439

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.83975
Policy Entropy: 1.26234
Value Function Loss: 0.02449

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.12367
Value Function Update Magnitude: 0.21315

Collected Steps per Second: 10473.55225
Overall Steps per Second: 7280.19160

Timestep Collection Time: 4.77765
Timestep Consumption Time: 2.09565
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 6.87331

Cumulative Model Updates: 39240
Cumulative Timesteps: 327563478

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.45690
Policy Entropy: 1.26383
Value Function Loss: 0.02328

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.12216
Value Function Update Magnitude: 0.20213

Collected Steps per Second: 10630.53097
Overall Steps per Second: 7289.51418

Timestep Collection Time: 4.70503
Timestep Consumption Time: 2.15647
PPO Batch Consumption Time: 0.02464
Total Iteration Time: 6.86150

Cumulative Model Updates: 39246
Cumulative Timesteps: 327613495

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.34987
Policy Entropy: 1.26110
Value Function Loss: 0.02429

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.12285
Value Function Update Magnitude: 0.20101

Collected Steps per Second: 10102.57269
Overall Steps per Second: 6969.63581

Timestep Collection Time: 4.95102
Timestep Consumption Time: 2.22554
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.17656

Cumulative Model Updates: 39252
Cumulative Timesteps: 327663513

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.89844
Policy Entropy: 1.25558
Value Function Loss: 0.02463

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.12372
Value Function Update Magnitude: 0.20719

Collected Steps per Second: 10002.99145
Overall Steps per Second: 6937.46617

Timestep Collection Time: 5.00270
Timestep Consumption Time: 2.21059
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 7.21330

Cumulative Model Updates: 39258
Cumulative Timesteps: 327713555

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.25561
Policy Entropy: 1.25431
Value Function Loss: 0.02526

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.12330
Value Function Update Magnitude: 0.20979

Collected Steps per Second: 9469.06619
Overall Steps per Second: 6643.14271

Timestep Collection Time: 5.28257
Timestep Consumption Time: 2.24715
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.52972

Cumulative Model Updates: 39264
Cumulative Timesteps: 327763576

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.76766
Policy Entropy: 1.25394
Value Function Loss: 0.02507

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.12325
Value Function Update Magnitude: 0.21870

Collected Steps per Second: 9886.96123
Overall Steps per Second: 6931.36020

Timestep Collection Time: 5.05969
Timestep Consumption Time: 2.15750
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.21720

Cumulative Model Updates: 39270
Cumulative Timesteps: 327813601

Timesteps Collected: 50025
--------END ITERATION REPORT--------


Saving checkpoint 327813601...
Checkpoint 327813601 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.21872
Policy Entropy: 1.25473
Value Function Loss: 0.02695

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.12185
Value Function Update Magnitude: 0.22611

Collected Steps per Second: 10101.08202
Overall Steps per Second: 7115.29274

Timestep Collection Time: 4.95175
Timestep Consumption Time: 2.07790
PPO Batch Consumption Time: 0.02525
Total Iteration Time: 7.02965

Cumulative Model Updates: 39276
Cumulative Timesteps: 327863619

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.65018
Policy Entropy: 1.25540
Value Function Loss: 0.02610

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.12547
Value Function Update Magnitude: 0.22753

Collected Steps per Second: 9195.10806
Overall Steps per Second: 6714.65082

Timestep Collection Time: 5.43767
Timestep Consumption Time: 2.00873
PPO Batch Consumption Time: 0.02495
Total Iteration Time: 7.44640

Cumulative Model Updates: 39282
Cumulative Timesteps: 327913619

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.98472
Policy Entropy: 1.26121
Value Function Loss: 0.02503

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.12600
Value Function Update Magnitude: 0.22661

Collected Steps per Second: 9734.71598
Overall Steps per Second: 6881.46897

Timestep Collection Time: 5.13687
Timestep Consumption Time: 2.12989
PPO Batch Consumption Time: 0.02444
Total Iteration Time: 7.26676

Cumulative Model Updates: 39288
Cumulative Timesteps: 327963625

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.67419
Policy Entropy: 1.26177
Value Function Loss: 0.02440

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.12476
Value Function Update Magnitude: 0.22128

Collected Steps per Second: 10211.41290
Overall Steps per Second: 7208.62343

Timestep Collection Time: 4.89922
Timestep Consumption Time: 2.04080
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 6.94002

Cumulative Model Updates: 39294
Cumulative Timesteps: 328013653

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.04679
Policy Entropy: 1.25740
Value Function Loss: 0.02528

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.12431
Value Function Update Magnitude: 0.23101

Collected Steps per Second: 9482.44493
Overall Steps per Second: 6839.48033

Timestep Collection Time: 5.27564
Timestep Consumption Time: 2.03865
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 7.31430

Cumulative Model Updates: 39300
Cumulative Timesteps: 328063679

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.28035
Policy Entropy: 1.25190
Value Function Loss: 0.02616

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.12827
Value Function Update Magnitude: 0.24007

Collected Steps per Second: 9798.45926
Overall Steps per Second: 6867.05792

Timestep Collection Time: 5.10325
Timestep Consumption Time: 2.17847
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 7.28172

Cumulative Model Updates: 39306
Cumulative Timesteps: 328113683

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.90097
Policy Entropy: 1.25510
Value Function Loss: 0.02540

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.12557
Value Function Update Magnitude: 0.22526

Collected Steps per Second: 9517.94943
Overall Steps per Second: 6739.55309

Timestep Collection Time: 5.25460
Timestep Consumption Time: 2.16622
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.42082

Cumulative Model Updates: 39312
Cumulative Timesteps: 328163696

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.51953
Policy Entropy: 1.26066
Value Function Loss: 0.02361

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.12315
Value Function Update Magnitude: 0.22595

Collected Steps per Second: 9881.79370
Overall Steps per Second: 7124.44923

Timestep Collection Time: 5.06163
Timestep Consumption Time: 1.95898
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.02061

Cumulative Model Updates: 39318
Cumulative Timesteps: 328213714

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.67854
Policy Entropy: 1.26352
Value Function Loss: 0.02348

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.12499
Value Function Update Magnitude: 0.23300

Collected Steps per Second: 9528.38168
Overall Steps per Second: 6725.55163

Timestep Collection Time: 5.25115
Timestep Consumption Time: 2.18838
PPO Batch Consumption Time: 0.02464
Total Iteration Time: 7.43954

Cumulative Model Updates: 39324
Cumulative Timesteps: 328263749

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.96325
Policy Entropy: 1.26479
Value Function Loss: 0.02427

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.12296
Value Function Update Magnitude: 0.23164

Collected Steps per Second: 9525.64787
Overall Steps per Second: 6830.66131

Timestep Collection Time: 5.25182
Timestep Consumption Time: 2.07207
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 7.32389

Cumulative Model Updates: 39330
Cumulative Timesteps: 328313776

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 328313776...
Checkpoint 328313776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.54809
Policy Entropy: 1.25968
Value Function Loss: 0.02602

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.12401
Value Function Update Magnitude: 0.22818

Collected Steps per Second: 9614.45955
Overall Steps per Second: 6979.21939

Timestep Collection Time: 5.20424
Timestep Consumption Time: 1.96504
PPO Batch Consumption Time: 0.02482
Total Iteration Time: 7.16928

Cumulative Model Updates: 39336
Cumulative Timesteps: 328363812

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.38297
Policy Entropy: 1.25712
Value Function Loss: 0.02593

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.12351
Value Function Update Magnitude: 0.22258

Collected Steps per Second: 10255.13677
Overall Steps per Second: 7189.54422

Timestep Collection Time: 4.87873
Timestep Consumption Time: 2.08027
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 6.95899

Cumulative Model Updates: 39342
Cumulative Timesteps: 328413844

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.85186
Policy Entropy: 1.25745
Value Function Loss: 0.02595

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.12752
Value Function Update Magnitude: 0.23135

Collected Steps per Second: 9669.82774
Overall Steps per Second: 6984.59038

Timestep Collection Time: 5.17362
Timestep Consumption Time: 1.98901
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.16262

Cumulative Model Updates: 39348
Cumulative Timesteps: 328463872

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.18505
Policy Entropy: 1.26052
Value Function Loss: 0.02642

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.12887
Value Function Update Magnitude: 0.24152

Collected Steps per Second: 10236.21120
Overall Steps per Second: 7216.33390

Timestep Collection Time: 4.88804
Timestep Consumption Time: 2.04554
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 6.93358

Cumulative Model Updates: 39354
Cumulative Timesteps: 328513907

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.43885
Policy Entropy: 1.26271
Value Function Loss: 0.02583

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.12661
Value Function Update Magnitude: 0.23224

Collected Steps per Second: 11025.66814
Overall Steps per Second: 7611.70589

Timestep Collection Time: 4.53859
Timestep Consumption Time: 2.03563
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 6.57422

Cumulative Model Updates: 39360
Cumulative Timesteps: 328563948

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.56427
Policy Entropy: 1.25876
Value Function Loss: 0.02555

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.12354
Value Function Update Magnitude: 0.23222

Collected Steps per Second: 9370.77500
Overall Steps per Second: 6717.16154

Timestep Collection Time: 5.33713
Timestep Consumption Time: 2.10843
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.44556

Cumulative Model Updates: 39366
Cumulative Timesteps: 328613961

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.97033
Policy Entropy: 1.26038
Value Function Loss: 0.02537

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.12220
Value Function Update Magnitude: 0.22991

Collected Steps per Second: 8882.55180
Overall Steps per Second: 6388.38308

Timestep Collection Time: 5.63408
Timestep Consumption Time: 2.19967
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 7.83375

Cumulative Model Updates: 39372
Cumulative Timesteps: 328664006

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.44890
Policy Entropy: 1.25377
Value Function Loss: 0.02511

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.12130
Value Function Update Magnitude: 0.22082

Collected Steps per Second: 9804.52101
Overall Steps per Second: 6759.45971

Timestep Collection Time: 5.10438
Timestep Consumption Time: 2.29947
PPO Batch Consumption Time: 0.02562
Total Iteration Time: 7.40385

Cumulative Model Updates: 39378
Cumulative Timesteps: 328714052

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.72794
Policy Entropy: 1.25393
Value Function Loss: 0.02591

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.12453
Value Function Update Magnitude: 0.21293

Collected Steps per Second: 9987.95436
Overall Steps per Second: 7135.85363

Timestep Collection Time: 5.00983
Timestep Consumption Time: 2.00236
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 7.01220

Cumulative Model Updates: 39384
Cumulative Timesteps: 328764090

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.74863
Policy Entropy: 1.24607
Value Function Loss: 0.02505

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.12184
Value Function Update Magnitude: 0.24670

Collected Steps per Second: 9387.68167
Overall Steps per Second: 6782.61579

Timestep Collection Time: 5.32794
Timestep Consumption Time: 2.04635
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 7.37429

Cumulative Model Updates: 39390
Cumulative Timesteps: 328814107

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 328814107...
Checkpoint 328814107 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.24232
Policy Entropy: 1.25064
Value Function Loss: 0.02502

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.12067
Value Function Update Magnitude: 0.25734

Collected Steps per Second: 9645.47533
Overall Steps per Second: 6623.83233

Timestep Collection Time: 5.18606
Timestep Consumption Time: 2.36576
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 7.55182

Cumulative Model Updates: 39396
Cumulative Timesteps: 328864129

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.44491
Policy Entropy: 1.24669
Value Function Loss: 0.02411

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.11975
Value Function Update Magnitude: 0.23934

Collected Steps per Second: 9283.36996
Overall Steps per Second: 6605.36490

Timestep Collection Time: 5.38641
Timestep Consumption Time: 2.18380
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.57021

Cumulative Model Updates: 39402
Cumulative Timesteps: 328914133

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.57437
Policy Entropy: 1.24843
Value Function Loss: 0.02520

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.11794
Value Function Update Magnitude: 0.24130

Collected Steps per Second: 9986.14915
Overall Steps per Second: 7090.97577

Timestep Collection Time: 5.00724
Timestep Consumption Time: 2.04440
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 7.05164

Cumulative Model Updates: 39408
Cumulative Timesteps: 328964136

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.63175
Policy Entropy: 1.25183
Value Function Loss: 0.02414

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.11813
Value Function Update Magnitude: 0.23844

Collected Steps per Second: 10447.94164
Overall Steps per Second: 7216.26886

Timestep Collection Time: 4.78879
Timestep Consumption Time: 2.14457
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 6.93336

Cumulative Model Updates: 39414
Cumulative Timesteps: 329014169

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.11290
Policy Entropy: 1.24898
Value Function Loss: 0.02351

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.11900
Value Function Update Magnitude: 0.23689

Collected Steps per Second: 9298.27916
Overall Steps per Second: 6765.93756

Timestep Collection Time: 5.37992
Timestep Consumption Time: 2.01359
PPO Batch Consumption Time: 0.02472
Total Iteration Time: 7.39351

Cumulative Model Updates: 39420
Cumulative Timesteps: 329064193

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.91984
Policy Entropy: 1.24346
Value Function Loss: 0.02286

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.11895
Value Function Update Magnitude: 0.22045

Collected Steps per Second: 9769.55251
Overall Steps per Second: 6997.61735

Timestep Collection Time: 5.12050
Timestep Consumption Time: 2.02836
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 7.14886

Cumulative Model Updates: 39426
Cumulative Timesteps: 329114218

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.97472
Policy Entropy: 1.24366
Value Function Loss: 0.02387

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.12054
Value Function Update Magnitude: 0.21274

Collected Steps per Second: 10096.34328
Overall Steps per Second: 6846.55199

Timestep Collection Time: 4.95595
Timestep Consumption Time: 2.35240
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 7.30835

Cumulative Model Updates: 39432
Cumulative Timesteps: 329164255

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.68637
Policy Entropy: 1.24898
Value Function Loss: 0.02406

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.12062
Value Function Update Magnitude: 0.21621

Collected Steps per Second: 9359.50736
Overall Steps per Second: 6769.51596

Timestep Collection Time: 5.34526
Timestep Consumption Time: 2.04508
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.39034

Cumulative Model Updates: 39438
Cumulative Timesteps: 329214284

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.48431
Policy Entropy: 1.25568
Value Function Loss: 0.02398

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.12106
Value Function Update Magnitude: 0.21368

Collected Steps per Second: 9599.76750
Overall Steps per Second: 6881.62354

Timestep Collection Time: 5.21002
Timestep Consumption Time: 2.05789
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 7.26791

Cumulative Model Updates: 39444
Cumulative Timesteps: 329264299

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.35689
Policy Entropy: 1.24929
Value Function Loss: 0.02391

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.11835
Value Function Update Magnitude: 0.19908

Collected Steps per Second: 10317.43102
Overall Steps per Second: 7345.35047

Timestep Collection Time: 4.84675
Timestep Consumption Time: 1.96109
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.80784

Cumulative Model Updates: 39450
Cumulative Timesteps: 329314305

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 329314305...
Checkpoint 329314305 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.75320
Policy Entropy: 1.24798
Value Function Loss: 0.02430

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.12031
Value Function Update Magnitude: 0.19852

Collected Steps per Second: 9972.80553
Overall Steps per Second: 7025.17535

Timestep Collection Time: 5.01795
Timestep Consumption Time: 2.10543
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 7.12338

Cumulative Model Updates: 39456
Cumulative Timesteps: 329364348

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.73151
Policy Entropy: 1.24176
Value Function Loss: 0.02415

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.12205
Value Function Update Magnitude: 0.20723

Collected Steps per Second: 9492.68875
Overall Steps per Second: 6780.49161

Timestep Collection Time: 5.27132
Timestep Consumption Time: 2.10853
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 7.37985

Cumulative Model Updates: 39462
Cumulative Timesteps: 329414387

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.34846
Policy Entropy: 1.24264
Value Function Loss: 0.02416

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.12583
Value Function Update Magnitude: 0.20876

Collected Steps per Second: 9572.14740
Overall Steps per Second: 6721.63551

Timestep Collection Time: 5.22359
Timestep Consumption Time: 2.21522
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.43881

Cumulative Model Updates: 39468
Cumulative Timesteps: 329464388

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.50330
Policy Entropy: 1.24113
Value Function Loss: 0.02380

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.20152

Collected Steps per Second: 9211.40561
Overall Steps per Second: 6695.88686

Timestep Collection Time: 5.43044
Timestep Consumption Time: 2.04011
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.47056

Cumulative Model Updates: 39474
Cumulative Timesteps: 329514410

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.25254
Policy Entropy: 1.24128
Value Function Loss: 0.02572

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.12493
Value Function Update Magnitude: 0.19605

Collected Steps per Second: 9367.99130
Overall Steps per Second: 6686.81195

Timestep Collection Time: 5.34095
Timestep Consumption Time: 2.14154
PPO Batch Consumption Time: 0.02432
Total Iteration Time: 7.48249

Cumulative Model Updates: 39480
Cumulative Timesteps: 329564444

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.54515
Policy Entropy: 1.23907
Value Function Loss: 0.02553

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.12530
Value Function Update Magnitude: 0.19659

Collected Steps per Second: 10080.58212
Overall Steps per Second: 6945.67564

Timestep Collection Time: 4.96112
Timestep Consumption Time: 2.23919
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 7.20031

Cumulative Model Updates: 39486
Cumulative Timesteps: 329614455

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.37029
Policy Entropy: 1.23549
Value Function Loss: 0.02644

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.12332
Value Function Update Magnitude: 0.19762

Collected Steps per Second: 9116.24402
Overall Steps per Second: 6503.86461

Timestep Collection Time: 5.48943
Timestep Consumption Time: 2.20492
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 7.69435

Cumulative Model Updates: 39492
Cumulative Timesteps: 329664498

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.18820
Policy Entropy: 1.23371
Value Function Loss: 0.02555

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.12661
Value Function Update Magnitude: 0.20056

Collected Steps per Second: 8981.17156
Overall Steps per Second: 6590.50779

Timestep Collection Time: 5.57154
Timestep Consumption Time: 2.02104
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 7.59259

Cumulative Model Updates: 39498
Cumulative Timesteps: 329714537

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.23343
Policy Entropy: 1.22951
Value Function Loss: 0.02569

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.12673
Value Function Update Magnitude: 0.19950

Collected Steps per Second: 9506.52155
Overall Steps per Second: 6640.96257

Timestep Collection Time: 5.26428
Timestep Consumption Time: 2.27152
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 7.53581

Cumulative Model Updates: 39504
Cumulative Timesteps: 329764582

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.65520
Policy Entropy: 1.23017
Value Function Loss: 0.02522

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.12451
Value Function Update Magnitude: 0.20491

Collected Steps per Second: 9244.21264
Overall Steps per Second: 6625.87008

Timestep Collection Time: 5.41301
Timestep Consumption Time: 2.13906
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.55206

Cumulative Model Updates: 39510
Cumulative Timesteps: 329814621

Timesteps Collected: 50039
--------END ITERATION REPORT--------


Saving checkpoint 329814621...
Checkpoint 329814621 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.86758
Policy Entropy: 1.23278
Value Function Loss: 0.02588

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.12651
Value Function Update Magnitude: 0.21241

Collected Steps per Second: 9075.10111
Overall Steps per Second: 6576.46579

Timestep Collection Time: 5.51046
Timestep Consumption Time: 2.09362
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 7.60408

Cumulative Model Updates: 39516
Cumulative Timesteps: 329864629

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.88500
Policy Entropy: 1.22924
Value Function Loss: 0.02593

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.12652
Value Function Update Magnitude: 0.22264

Collected Steps per Second: 9575.59038
Overall Steps per Second: 6769.69143

Timestep Collection Time: 5.22485
Timestep Consumption Time: 2.16559
PPO Batch Consumption Time: 0.02513
Total Iteration Time: 7.39044

Cumulative Model Updates: 39522
Cumulative Timesteps: 329914660

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.18698
Policy Entropy: 1.22930
Value Function Loss: 0.02556

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.12526
Value Function Update Magnitude: 0.21099

Collected Steps per Second: 9753.79091
Overall Steps per Second: 6957.14779

Timestep Collection Time: 5.13011
Timestep Consumption Time: 2.06221
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 7.19232

Cumulative Model Updates: 39528
Cumulative Timesteps: 329964698

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.66421
Policy Entropy: 1.22919
Value Function Loss: 0.02551

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.12338
Value Function Update Magnitude: 0.20439

Collected Steps per Second: 9817.90474
Overall Steps per Second: 7164.64574

Timestep Collection Time: 5.09365
Timestep Consumption Time: 1.88632
PPO Batch Consumption Time: 0.02478
Total Iteration Time: 6.97997

Cumulative Model Updates: 39534
Cumulative Timesteps: 330014707

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.98369
Policy Entropy: 1.23217
Value Function Loss: 0.02665

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.12515
Value Function Update Magnitude: 0.20749

Collected Steps per Second: 10550.82163
Overall Steps per Second: 7282.49915

Timestep Collection Time: 4.73944
Timestep Consumption Time: 2.12702
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 6.86646

Cumulative Model Updates: 39540
Cumulative Timesteps: 330064712

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.03953
Policy Entropy: 1.22786
Value Function Loss: 0.02766

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.12677
Value Function Update Magnitude: 0.21814

Collected Steps per Second: 9376.00935
Overall Steps per Second: 6818.45100

Timestep Collection Time: 5.33585
Timestep Consumption Time: 2.00144
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.33730

Cumulative Model Updates: 39546
Cumulative Timesteps: 330114741

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.91319
Policy Entropy: 1.22421
Value Function Loss: 0.02732

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.12840
Value Function Update Magnitude: 0.21523

Collected Steps per Second: 9579.30418
Overall Steps per Second: 6828.28747

Timestep Collection Time: 5.22251
Timestep Consumption Time: 2.10407
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 7.32658

Cumulative Model Updates: 39552
Cumulative Timesteps: 330164769

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.52366
Policy Entropy: 1.21958
Value Function Loss: 0.02659

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.12550
Value Function Update Magnitude: 0.20376

Collected Steps per Second: 10334.53174
Overall Steps per Second: 7317.46211

Timestep Collection Time: 4.84066
Timestep Consumption Time: 1.99586
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 6.83652

Cumulative Model Updates: 39558
Cumulative Timesteps: 330214795

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.08619
Policy Entropy: 1.22756
Value Function Loss: 0.02614

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.12568
Value Function Update Magnitude: 0.20452

Collected Steps per Second: 9761.42328
Overall Steps per Second: 6681.73844

Timestep Collection Time: 5.12599
Timestep Consumption Time: 2.36263
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 7.48862

Cumulative Model Updates: 39564
Cumulative Timesteps: 330264832

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.71118
Policy Entropy: 1.23197
Value Function Loss: 0.02520

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.12446
Value Function Update Magnitude: 0.20974

Collected Steps per Second: 9061.44490
Overall Steps per Second: 6603.10442

Timestep Collection Time: 5.52208
Timestep Consumption Time: 2.05587
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 7.57795

Cumulative Model Updates: 39570
Cumulative Timesteps: 330314870

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 330314870...
Checkpoint 330314870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.13879
Policy Entropy: 1.23716
Value Function Loss: 0.02549

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.12477
Value Function Update Magnitude: 0.21881

Collected Steps per Second: 9984.02661
Overall Steps per Second: 7039.97530

Timestep Collection Time: 5.01000
Timestep Consumption Time: 2.09514
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 7.10514

Cumulative Model Updates: 39576
Cumulative Timesteps: 330364890

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.82780
Policy Entropy: 1.22974
Value Function Loss: 0.02566

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.12579
Value Function Update Magnitude: 0.21235

Collected Steps per Second: 9725.63976
Overall Steps per Second: 6917.08619

Timestep Collection Time: 5.14239
Timestep Consumption Time: 2.08797
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.23036

Cumulative Model Updates: 39582
Cumulative Timesteps: 330414903

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.72573
Policy Entropy: 1.23066
Value Function Loss: 0.02668

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.12834
Value Function Update Magnitude: 0.21514

Collected Steps per Second: 8906.67981
Overall Steps per Second: 6343.59887

Timestep Collection Time: 5.61500
Timestep Consumption Time: 2.26870
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 7.88370

Cumulative Model Updates: 39588
Cumulative Timesteps: 330464914

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.95239
Policy Entropy: 1.23030
Value Function Loss: 0.02565

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.12714
Value Function Update Magnitude: 0.21724

Collected Steps per Second: 9577.52610
Overall Steps per Second: 6756.05011

Timestep Collection Time: 5.22223
Timestep Consumption Time: 2.18092
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 7.40314

Cumulative Model Updates: 39594
Cumulative Timesteps: 330514930

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.46794
Policy Entropy: 1.23068
Value Function Loss: 0.02579

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.12719
Value Function Update Magnitude: 0.21227

Collected Steps per Second: 9287.44412
Overall Steps per Second: 6636.85106

Timestep Collection Time: 5.38577
Timestep Consumption Time: 2.15094
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 7.53671

Cumulative Model Updates: 39600
Cumulative Timesteps: 330564950

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.21965
Policy Entropy: 1.22785
Value Function Loss: 0.02450

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.12580
Value Function Update Magnitude: 0.21123

Collected Steps per Second: 9190.75138
Overall Steps per Second: 6547.96724

Timestep Collection Time: 5.44069
Timestep Consumption Time: 2.19588
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 7.63657

Cumulative Model Updates: 39606
Cumulative Timesteps: 330614954

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.21396
Policy Entropy: 1.22785
Value Function Loss: 0.02466

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.12512
Value Function Update Magnitude: 0.21839

Collected Steps per Second: 9691.77436
Overall Steps per Second: 6801.05390

Timestep Collection Time: 5.15912
Timestep Consumption Time: 2.19283
PPO Batch Consumption Time: 0.02434
Total Iteration Time: 7.35195

Cumulative Model Updates: 39612
Cumulative Timesteps: 330664955

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.93470
Policy Entropy: 1.23030
Value Function Loss: 0.02373

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.12513
Value Function Update Magnitude: 0.21303

Collected Steps per Second: 10278.66944
Overall Steps per Second: 7164.18023

Timestep Collection Time: 4.86610
Timestep Consumption Time: 2.11544
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 6.98154

Cumulative Model Updates: 39618
Cumulative Timesteps: 330714972

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.10081
Policy Entropy: 1.22978
Value Function Loss: 0.02482

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.12833
Value Function Update Magnitude: 0.22128

Collected Steps per Second: 10122.58776
Overall Steps per Second: 7193.59055

Timestep Collection Time: 4.94291
Timestep Consumption Time: 2.01259
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 6.95550

Cumulative Model Updates: 39624
Cumulative Timesteps: 330765007

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.93083
Policy Entropy: 1.22829
Value Function Loss: 0.02520

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.12876
Value Function Update Magnitude: 0.22012

Collected Steps per Second: 9922.88979
Overall Steps per Second: 7009.06909

Timestep Collection Time: 5.04107
Timestep Consumption Time: 2.09568
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.13675

Cumulative Model Updates: 39630
Cumulative Timesteps: 330815029

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 330815029...
Checkpoint 330815029 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.97612
Policy Entropy: 1.22554
Value Function Loss: 0.02551

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.12485
Value Function Update Magnitude: 0.22061

Collected Steps per Second: 9317.63905
Overall Steps per Second: 6762.81068

Timestep Collection Time: 5.36885
Timestep Consumption Time: 2.02822
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 7.39707

Cumulative Model Updates: 39636
Cumulative Timesteps: 330865054

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.99118
Policy Entropy: 1.22771
Value Function Loss: 0.02553

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.12398
Value Function Update Magnitude: 0.22209

Collected Steps per Second: 10136.46964
Overall Steps per Second: 7233.97242

Timestep Collection Time: 4.93318
Timestep Consumption Time: 1.97935
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 6.91252

Cumulative Model Updates: 39642
Cumulative Timesteps: 330915059

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.99759
Policy Entropy: 1.23221
Value Function Loss: 0.02586

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.12625
Value Function Update Magnitude: 0.21994

Collected Steps per Second: 10350.13728
Overall Steps per Second: 7199.88428

Timestep Collection Time: 4.83211
Timestep Consumption Time: 2.11425
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 6.94636

Cumulative Model Updates: 39648
Cumulative Timesteps: 330965072

Timesteps Collected: 50013
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.82631
Policy Entropy: 1.23352
Value Function Loss: 0.02530

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.12561
Value Function Update Magnitude: 0.22135

Collected Steps per Second: 9418.04574
Overall Steps per Second: 6768.06542

Timestep Collection Time: 5.31097
Timestep Consumption Time: 2.07947
PPO Batch Consumption Time: 0.02375
Total Iteration Time: 7.39044

Cumulative Model Updates: 39654
Cumulative Timesteps: 331015091

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.21518
Policy Entropy: 1.23333
Value Function Loss: 0.02506

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.12740
Value Function Update Magnitude: 0.22529

Collected Steps per Second: 9884.32652
Overall Steps per Second: 7078.45232

Timestep Collection Time: 5.05932
Timestep Consumption Time: 2.00550
PPO Batch Consumption Time: 0.02455
Total Iteration Time: 7.06482

Cumulative Model Updates: 39660
Cumulative Timesteps: 331065099

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.12436
Policy Entropy: 1.23176
Value Function Loss: 0.02370

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.12429
Value Function Update Magnitude: 0.22664

Collected Steps per Second: 9671.64709
Overall Steps per Second: 6964.82294

Timestep Collection Time: 5.17016
Timestep Consumption Time: 2.00934
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 7.17951

Cumulative Model Updates: 39666
Cumulative Timesteps: 331115103

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.31860
Policy Entropy: 1.22923
Value Function Loss: 0.02395

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.12419
Value Function Update Magnitude: 0.21554

Collected Steps per Second: 9177.55960
Overall Steps per Second: 6596.01821

Timestep Collection Time: 5.44981
Timestep Consumption Time: 2.13294
PPO Batch Consumption Time: 0.02528
Total Iteration Time: 7.58276

Cumulative Model Updates: 39672
Cumulative Timesteps: 331165119

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.24041
Policy Entropy: 1.23219
Value Function Loss: 0.02385

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.12251
Value Function Update Magnitude: 0.20978

Collected Steps per Second: 9573.14815
Overall Steps per Second: 6810.42052

Timestep Collection Time: 5.22409
Timestep Consumption Time: 2.11921
PPO Batch Consumption Time: 0.02480
Total Iteration Time: 7.34331

Cumulative Model Updates: 39678
Cumulative Timesteps: 331215130

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.30647
Policy Entropy: 1.22628
Value Function Loss: 0.02364

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.12444
Value Function Update Magnitude: 0.20657

Collected Steps per Second: 10327.61050
Overall Steps per Second: 7184.90417

Timestep Collection Time: 4.84304
Timestep Consumption Time: 2.11836
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 6.96140

Cumulative Model Updates: 39684
Cumulative Timesteps: 331265147

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.57850
Policy Entropy: 1.22126
Value Function Loss: 0.02395

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.12418
Value Function Update Magnitude: 0.20731

Collected Steps per Second: 9459.80225
Overall Steps per Second: 6855.24904

Timestep Collection Time: 5.28721
Timestep Consumption Time: 2.00880
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 7.29602

Cumulative Model Updates: 39690
Cumulative Timesteps: 331315163

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 331315163...
Checkpoint 331315163 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.55364
Policy Entropy: 1.22230
Value Function Loss: 0.02411

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.12405
Value Function Update Magnitude: 0.20461

Collected Steps per Second: 9963.35348
Overall Steps per Second: 7024.21462

Timestep Collection Time: 5.01879
Timestep Consumption Time: 2.10001
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 7.11880

Cumulative Model Updates: 39696
Cumulative Timesteps: 331365167

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.99212
Policy Entropy: 1.23049
Value Function Loss: 0.02501

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.13117
Value Function Update Magnitude: 0.19937

Collected Steps per Second: 10067.17586
Overall Steps per Second: 7082.99833

Timestep Collection Time: 4.96972
Timestep Consumption Time: 2.09382
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.06353

Cumulative Model Updates: 39702
Cumulative Timesteps: 331415198

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.58918
Policy Entropy: 1.24094
Value Function Loss: 0.02619

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.12888
Value Function Update Magnitude: 0.20641

Collected Steps per Second: 9439.19828
Overall Steps per Second: 6706.80038

Timestep Collection Time: 5.30077
Timestep Consumption Time: 2.15957
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 7.46034

Cumulative Model Updates: 39708
Cumulative Timesteps: 331465233

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.98504
Policy Entropy: 1.23850
Value Function Loss: 0.02644

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.12911
Value Function Update Magnitude: 0.21205

Collected Steps per Second: 9004.06141
Overall Steps per Second: 6507.34585

Timestep Collection Time: 5.55660
Timestep Consumption Time: 2.13194
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 7.68854

Cumulative Model Updates: 39714
Cumulative Timesteps: 331515265

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.42057
Policy Entropy: 1.24606
Value Function Loss: 0.02652

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.13065
Value Function Update Magnitude: 0.21521

Collected Steps per Second: 9588.30804
Overall Steps per Second: 6719.77209

Timestep Collection Time: 5.21844
Timestep Consumption Time: 2.22765
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 7.44609

Cumulative Model Updates: 39720
Cumulative Timesteps: 331565301

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.62129
Policy Entropy: 1.24459
Value Function Loss: 0.02634

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.13092
Value Function Update Magnitude: 0.22109

Collected Steps per Second: 9248.03330
Overall Steps per Second: 6607.96740

Timestep Collection Time: 5.40666
Timestep Consumption Time: 2.16011
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 7.56677

Cumulative Model Updates: 39726
Cumulative Timesteps: 331615302

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.57779
Policy Entropy: 1.25108
Value Function Loss: 0.02655

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.13043
Value Function Update Magnitude: 0.22784

Collected Steps per Second: 9800.72393
Overall Steps per Second: 7014.59730

Timestep Collection Time: 5.10544
Timestep Consumption Time: 2.02783
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 7.13327

Cumulative Model Updates: 39732
Cumulative Timesteps: 331665339

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.01658
Policy Entropy: 1.24583
Value Function Loss: 0.02554

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.12847
Value Function Update Magnitude: 0.22423

Collected Steps per Second: 9728.52568
Overall Steps per Second: 6968.13983

Timestep Collection Time: 5.14138
Timestep Consumption Time: 2.03672
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 7.17810

Cumulative Model Updates: 39738
Cumulative Timesteps: 331715357

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.89744
Policy Entropy: 1.24339
Value Function Loss: 0.02517

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.12676
Value Function Update Magnitude: 0.22023

Collected Steps per Second: 10228.47176
Overall Steps per Second: 7360.83513

Timestep Collection Time: 4.88871
Timestep Consumption Time: 1.90454
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 6.79325

Cumulative Model Updates: 39744
Cumulative Timesteps: 331765361

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.41088
Policy Entropy: 1.24302
Value Function Loss: 0.02439

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.10723
Policy Update Magnitude: 0.12433
Value Function Update Magnitude: 0.22311

Collected Steps per Second: 9579.38800
Overall Steps per Second: 6825.41342

Timestep Collection Time: 5.22027
Timestep Consumption Time: 2.10632
PPO Batch Consumption Time: 0.02479
Total Iteration Time: 7.32659

Cumulative Model Updates: 39750
Cumulative Timesteps: 331815368

Timesteps Collected: 50007
--------END ITERATION REPORT--------


Saving checkpoint 331815368...
Checkpoint 331815368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.83854
Policy Entropy: 1.24390
Value Function Loss: 0.02627

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.12416
Value Function Update Magnitude: 0.22742

Collected Steps per Second: 9646.43655
Overall Steps per Second: 6584.42735

Timestep Collection Time: 5.18430
Timestep Consumption Time: 2.41090
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 7.59519

Cumulative Model Updates: 39756
Cumulative Timesteps: 331865378

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.48758
Policy Entropy: 1.24563
Value Function Loss: 0.02668

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.12946
Value Function Update Magnitude: 0.23673

Collected Steps per Second: 9143.10236
Overall Steps per Second: 6585.45982

Timestep Collection Time: 5.47363
Timestep Consumption Time: 2.12583
PPO Batch Consumption Time: 0.02414
Total Iteration Time: 7.59947

Cumulative Model Updates: 39762
Cumulative Timesteps: 331915424

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.73309
Policy Entropy: 1.24612
Value Function Loss: 0.02736

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.13940
Value Function Update Magnitude: 0.23454

Collected Steps per Second: 9086.42918
Overall Steps per Second: 6524.64912

Timestep Collection Time: 5.50535
Timestep Consumption Time: 2.16157
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 7.66693

Cumulative Model Updates: 39768
Cumulative Timesteps: 331965448

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.09838
Policy Entropy: 1.24740
Value Function Loss: 0.02577

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.13477
Value Function Update Magnitude: 0.22663

Collected Steps per Second: 9503.47299
Overall Steps per Second: 6620.98670

Timestep Collection Time: 5.26176
Timestep Consumption Time: 2.29074
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 7.55250

Cumulative Model Updates: 39774
Cumulative Timesteps: 332015453

Timesteps Collected: 50005
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.19834
Policy Entropy: 1.25078
Value Function Loss: 0.02614

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.13094
Value Function Update Magnitude: 0.22649

Collected Steps per Second: 9001.19572
Overall Steps per Second: 6537.53387

Timestep Collection Time: 5.55793
Timestep Consumption Time: 2.09450
PPO Batch Consumption Time: 0.02459
Total Iteration Time: 7.65243

Cumulative Model Updates: 39780
Cumulative Timesteps: 332065481

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.99540
Policy Entropy: 1.25698
Value Function Loss: 0.02627

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.12700
Value Function Update Magnitude: 0.23509

Collected Steps per Second: 9768.22910
Overall Steps per Second: 7134.29832

Timestep Collection Time: 5.11894
Timestep Consumption Time: 1.88988
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 7.00882

Cumulative Model Updates: 39786
Cumulative Timesteps: 332115484

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.34992
Policy Entropy: 1.25395
Value Function Loss: 0.02721

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.12603
Value Function Update Magnitude: 0.24564

Collected Steps per Second: 9961.91003
Overall Steps per Second: 6971.67980

Timestep Collection Time: 5.01922
Timestep Consumption Time: 2.15280
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.17202

Cumulative Model Updates: 39792
Cumulative Timesteps: 332165485

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.01718
Policy Entropy: 1.24847
Value Function Loss: 0.02670

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.12920
Value Function Update Magnitude: 0.24124

Collected Steps per Second: 9203.59537
Overall Steps per Second: 6570.79283

Timestep Collection Time: 5.43385
Timestep Consumption Time: 2.17725
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 7.61111

Cumulative Model Updates: 39798
Cumulative Timesteps: 332215496

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.56469
Policy Entropy: 1.24744
Value Function Loss: 0.02606

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.11620
Policy Update Magnitude: 0.12346
Value Function Update Magnitude: 0.23038

Collected Steps per Second: 8660.26427
Overall Steps per Second: 6269.09330

Timestep Collection Time: 5.77696
Timestep Consumption Time: 2.20346
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 7.98042

Cumulative Model Updates: 39804
Cumulative Timesteps: 332265526

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.62693
Policy Entropy: 1.25507
Value Function Loss: 0.02507

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.12385
Value Function Update Magnitude: 0.22057

Collected Steps per Second: 9752.00861
Overall Steps per Second: 6606.92533

Timestep Collection Time: 5.12828
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 7.56948

Cumulative Model Updates: 39810
Cumulative Timesteps: 332315537

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 332315537...
Checkpoint 332315537 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.45698
Policy Entropy: 1.25810
Value Function Loss: 0.02454

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.12463
Value Function Update Magnitude: 0.21628

Collected Steps per Second: 10917.93378
Overall Steps per Second: 7313.21211

Timestep Collection Time: 4.58017
Timestep Consumption Time: 2.25759
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 6.83776

Cumulative Model Updates: 39816
Cumulative Timesteps: 332365543

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.06005
Policy Entropy: 1.24919
Value Function Loss: 0.02496

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.12528
Value Function Update Magnitude: 0.22090

Collected Steps per Second: 9566.34196
Overall Steps per Second: 6871.42724

Timestep Collection Time: 5.22896
Timestep Consumption Time: 2.05075
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 7.27971

Cumulative Model Updates: 39822
Cumulative Timesteps: 332415565

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.37953
Policy Entropy: 1.24675
Value Function Loss: 0.02586

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.12497
Value Function Update Magnitude: 0.22462

Collected Steps per Second: 9363.29436
Overall Steps per Second: 6785.65972

Timestep Collection Time: 5.34032
Timestep Consumption Time: 2.02860
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 7.36892

Cumulative Model Updates: 39828
Cumulative Timesteps: 332465568

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.63314
Policy Entropy: 1.24205
Value Function Loss: 0.02557

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.12230
Value Function Update Magnitude: 0.23035

Collected Steps per Second: 10028.16098
Overall Steps per Second: 6991.99781

Timestep Collection Time: 4.98865
Timestep Consumption Time: 2.16624
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 7.15489

Cumulative Model Updates: 39834
Cumulative Timesteps: 332515595

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.70356
Policy Entropy: 1.24754
Value Function Loss: 0.02622

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.12725
Value Function Update Magnitude: 0.21777

Collected Steps per Second: 9268.56481
Overall Steps per Second: 6710.45132

Timestep Collection Time: 5.39577
Timestep Consumption Time: 2.05694
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.45270

Cumulative Model Updates: 39840
Cumulative Timesteps: 332565606

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.81912
Policy Entropy: 1.24521
Value Function Loss: 0.02521

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.12758
Value Function Update Magnitude: 0.21683

Collected Steps per Second: 9347.51330
Overall Steps per Second: 6740.35646

Timestep Collection Time: 5.35201
Timestep Consumption Time: 2.07015
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 7.42216

Cumulative Model Updates: 39846
Cumulative Timesteps: 332615634

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.48909
Policy Entropy: 1.24548
Value Function Loss: 0.02576

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.12632
Value Function Update Magnitude: 0.21322

Collected Steps per Second: 9942.63971
Overall Steps per Second: 7134.98397

Timestep Collection Time: 5.03035
Timestep Consumption Time: 1.97947
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.00983

Cumulative Model Updates: 39852
Cumulative Timesteps: 332665649

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.88844
Policy Entropy: 1.24541
Value Function Loss: 0.02401

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.12449
Value Function Update Magnitude: 0.21224

Collected Steps per Second: 9945.43145
Overall Steps per Second: 7082.03883

Timestep Collection Time: 5.02924
Timestep Consumption Time: 2.03341
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 7.06266

Cumulative Model Updates: 39858
Cumulative Timesteps: 332715667

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.97616
Policy Entropy: 1.24654
Value Function Loss: 0.02486

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.12393
Value Function Update Magnitude: 0.20746

Collected Steps per Second: 9526.22206
Overall Steps per Second: 6995.82876

Timestep Collection Time: 5.24962
Timestep Consumption Time: 1.89879
PPO Batch Consumption Time: 0.02530
Total Iteration Time: 7.14840

Cumulative Model Updates: 39864
Cumulative Timesteps: 332765676

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.54465
Policy Entropy: 1.25311
Value Function Loss: 0.02359

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.12343
Value Function Update Magnitude: 0.20659

Collected Steps per Second: 10282.95373
Overall Steps per Second: 7184.08932

Timestep Collection Time: 4.86582
Timestep Consumption Time: 2.09888
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 6.96470

Cumulative Model Updates: 39870
Cumulative Timesteps: 332815711

Timesteps Collected: 50035
--------END ITERATION REPORT--------


Saving checkpoint 332815711...
Checkpoint 332815711 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.80265
Policy Entropy: 1.25305
Value Function Loss: 0.02563

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.12310
Value Function Update Magnitude: 0.21241

Collected Steps per Second: 9206.86215
Overall Steps per Second: 6594.89974

Timestep Collection Time: 5.43225
Timestep Consumption Time: 2.15149
PPO Batch Consumption Time: 0.02426
Total Iteration Time: 7.58374

Cumulative Model Updates: 39876
Cumulative Timesteps: 332865725

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.16737
Policy Entropy: 1.25439
Value Function Loss: 0.02615

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.12401
Value Function Update Magnitude: 0.21362

Collected Steps per Second: 9102.82542
Overall Steps per Second: 6604.73583

Timestep Collection Time: 5.49379
Timestep Consumption Time: 2.07790
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 7.57169

Cumulative Model Updates: 39882
Cumulative Timesteps: 332915734

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.39533
Policy Entropy: 1.25378
Value Function Loss: 0.02744

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.12973
Value Function Update Magnitude: 0.22006

Collected Steps per Second: 10245.06665
Overall Steps per Second: 7287.28103

Timestep Collection Time: 4.88147
Timestep Consumption Time: 1.98131
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 6.86278

Cumulative Model Updates: 39888
Cumulative Timesteps: 332965745

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.14595
Policy Entropy: 1.24795
Value Function Loss: 0.02544

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.12833
Value Function Update Magnitude: 0.23639

Collected Steps per Second: 9413.09907
Overall Steps per Second: 6670.92249

Timestep Collection Time: 5.31377
Timestep Consumption Time: 2.18430
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 7.49806

Cumulative Model Updates: 39894
Cumulative Timesteps: 333015764

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.54024
Policy Entropy: 1.26298
Value Function Loss: 0.02401

Mean KL Divergence: 0.02321
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.11838
Value Function Update Magnitude: 0.22419

Collected Steps per Second: 9520.95983
Overall Steps per Second: 6845.98670

Timestep Collection Time: 5.25315
Timestep Consumption Time: 2.05259
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.30574

Cumulative Model Updates: 39900
Cumulative Timesteps: 333065779

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.49503
Policy Entropy: 1.25796
Value Function Loss: 0.02374

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.11684
Value Function Update Magnitude: 0.22527

Collected Steps per Second: 9803.14665
Overall Steps per Second: 6760.88048

Timestep Collection Time: 5.10397
Timestep Consumption Time: 2.29669
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 7.40066

Cumulative Model Updates: 39906
Cumulative Timesteps: 333115814

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.73056
Policy Entropy: 1.26975
Value Function Loss: 0.02468

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.11837
Value Function Update Magnitude: 0.22614

Collected Steps per Second: 8685.15190
Overall Steps per Second: 6304.09306

Timestep Collection Time: 5.75718
Timestep Consumption Time: 2.17449
PPO Batch Consumption Time: 0.02534
Total Iteration Time: 7.93167

Cumulative Model Updates: 39912
Cumulative Timesteps: 333165816

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.51097
Policy Entropy: 1.26301
Value Function Loss: 0.02483

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.11511
Value Function Update Magnitude: 0.21977

Collected Steps per Second: 9612.57160
Overall Steps per Second: 6806.70118

Timestep Collection Time: 5.20329
Timestep Consumption Time: 2.14491
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 7.34820

Cumulative Model Updates: 39918
Cumulative Timesteps: 333215833

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.85182
Policy Entropy: 1.26761
Value Function Loss: 0.02595

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.11572
Value Function Update Magnitude: 0.22084

Collected Steps per Second: 10000.13939
Overall Steps per Second: 6781.65141

Timestep Collection Time: 5.00463
Timestep Consumption Time: 2.37514
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 7.37977

Cumulative Model Updates: 39924
Cumulative Timesteps: 333265880

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.21289
Policy Entropy: 1.26217
Value Function Loss: 0.02538

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.12063
Value Function Update Magnitude: 0.22469

Collected Steps per Second: 8716.29433
Overall Steps per Second: 6263.12510

Timestep Collection Time: 5.73764
Timestep Consumption Time: 2.24735
PPO Batch Consumption Time: 0.02888
Total Iteration Time: 7.98499

Cumulative Model Updates: 39930
Cumulative Timesteps: 333315891

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 333315891...
Checkpoint 333315891 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.84969
Policy Entropy: 1.26575
Value Function Loss: 0.02544

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.12013
Value Function Update Magnitude: 0.22550

Collected Steps per Second: 9542.45878
Overall Steps per Second: 6781.68879

Timestep Collection Time: 5.24351
Timestep Consumption Time: 2.13459
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 7.37810

Cumulative Model Updates: 39936
Cumulative Timesteps: 333365927

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.02494
Policy Entropy: 1.26657
Value Function Loss: 0.02469

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.12174
Value Function Update Magnitude: 0.22020

Collected Steps per Second: 10114.35252
Overall Steps per Second: 7122.61849

Timestep Collection Time: 4.94525
Timestep Consumption Time: 2.07717
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 7.02242

Cumulative Model Updates: 39942
Cumulative Timesteps: 333415945

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.34510
Policy Entropy: 1.26620
Value Function Loss: 0.02547

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06885
Policy Update Magnitude: 0.12227
Value Function Update Magnitude: 0.21233

Collected Steps per Second: 9291.74968
Overall Steps per Second: 6832.21480

Timestep Collection Time: 5.38306
Timestep Consumption Time: 1.93785
PPO Batch Consumption Time: 0.02541
Total Iteration Time: 7.32091

Cumulative Model Updates: 39948
Cumulative Timesteps: 333465963

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.85655
Policy Entropy: 1.26560
Value Function Loss: 0.02522

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.12118
Value Function Update Magnitude: 0.20615

Collected Steps per Second: 9851.74132
Overall Steps per Second: 7154.87994

Timestep Collection Time: 5.07636
Timestep Consumption Time: 1.91341
PPO Batch Consumption Time: 0.02471
Total Iteration Time: 6.98977

Cumulative Model Updates: 39954
Cumulative Timesteps: 333515974

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.09199
Policy Entropy: 1.26643
Value Function Loss: 0.02528

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.11996
Value Function Update Magnitude: 0.21741

Collected Steps per Second: 9894.46099
Overall Steps per Second: 7052.20154

Timestep Collection Time: 5.05374
Timestep Consumption Time: 2.03682
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 7.09055

Cumulative Model Updates: 39960
Cumulative Timesteps: 333565978

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.55896
Policy Entropy: 1.25962
Value Function Loss: 0.02545

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.12060
Value Function Update Magnitude: 0.21130

Collected Steps per Second: 8835.04462
Overall Steps per Second: 6424.86289

Timestep Collection Time: 5.66188
Timestep Consumption Time: 2.12396
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 7.78585

Cumulative Model Updates: 39966
Cumulative Timesteps: 333616001

Timesteps Collected: 50023
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.65065
Policy Entropy: 1.25580
Value Function Loss: 0.02533

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.12030
Value Function Update Magnitude: 0.21001

Collected Steps per Second: 9195.14436
Overall Steps per Second: 6606.65208

Timestep Collection Time: 5.43787
Timestep Consumption Time: 2.13056
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 7.56843

Cumulative Model Updates: 39972
Cumulative Timesteps: 333666003

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.71867
Policy Entropy: 1.25516
Value Function Loss: 0.02476

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.12151
Value Function Update Magnitude: 0.20733

Collected Steps per Second: 9557.16496
Overall Steps per Second: 6839.79077

Timestep Collection Time: 5.23283
Timestep Consumption Time: 2.07895
PPO Batch Consumption Time: 0.02450
Total Iteration Time: 7.31177

Cumulative Model Updates: 39978
Cumulative Timesteps: 333716014

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.59871
Policy Entropy: 1.26234
Value Function Loss: 0.02446

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.12220
Value Function Update Magnitude: 0.20327

Collected Steps per Second: 9440.94367
Overall Steps per Second: 6711.05625

Timestep Collection Time: 5.30053
Timestep Consumption Time: 2.15612
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.45665

Cumulative Model Updates: 39984
Cumulative Timesteps: 333766056

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.29591
Policy Entropy: 1.26511
Value Function Loss: 0.02461

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.12177
Value Function Update Magnitude: 0.20212

Collected Steps per Second: 10687.99015
Overall Steps per Second: 7227.49009

Timestep Collection Time: 4.67918
Timestep Consumption Time: 2.24038
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 6.91955

Cumulative Model Updates: 39990
Cumulative Timesteps: 333816067

Timesteps Collected: 50011
--------END ITERATION REPORT--------


Saving checkpoint 333816067...
Checkpoint 333816067 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.29516
Policy Entropy: 1.26358
Value Function Loss: 0.02483

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.12437
Value Function Update Magnitude: 0.20158

Collected Steps per Second: 10105.42551
Overall Steps per Second: 7055.24101

Timestep Collection Time: 4.95249
Timestep Consumption Time: 2.14110
PPO Batch Consumption Time: 0.02473
Total Iteration Time: 7.09359

Cumulative Model Updates: 39996
Cumulative Timesteps: 333866114

Timesteps Collected: 50047
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.72224
Policy Entropy: 1.26119
Value Function Loss: 0.02532

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.12236
Value Function Update Magnitude: 0.20745

Collected Steps per Second: 9589.19399
Overall Steps per Second: 6923.62331

Timestep Collection Time: 5.21796
Timestep Consumption Time: 2.00890
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 7.22685

Cumulative Model Updates: 40002
Cumulative Timesteps: 333916150

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.71387
Policy Entropy: 1.26300
Value Function Loss: 0.02519

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.11872
Value Function Update Magnitude: 0.20711

Collected Steps per Second: 9185.21794
Overall Steps per Second: 6601.15742

Timestep Collection Time: 5.44375
Timestep Consumption Time: 2.13099
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 7.57473

Cumulative Model Updates: 40008
Cumulative Timesteps: 333966152

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.51996
Policy Entropy: 1.26986
Value Function Loss: 0.02566

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.12273
Value Function Update Magnitude: 0.20926

Collected Steps per Second: 9356.12452
Overall Steps per Second: 6516.50540

Timestep Collection Time: 5.34677
Timestep Consumption Time: 2.32990
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 7.67666

Cumulative Model Updates: 40014
Cumulative Timesteps: 334016177

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.54995
Policy Entropy: 1.26933
Value Function Loss: 0.02570

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.12610
Value Function Update Magnitude: 0.21796

Collected Steps per Second: 9637.23908
Overall Steps per Second: 6918.09294

Timestep Collection Time: 5.18935
Timestep Consumption Time: 2.03967
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 7.22902

Cumulative Model Updates: 40020
Cumulative Timesteps: 334066188

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.05366
Policy Entropy: 1.27138
Value Function Loss: 0.02625

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.11990
Value Function Update Magnitude: 0.20443

Collected Steps per Second: 9552.79300
Overall Steps per Second: 6917.65800

Timestep Collection Time: 5.23857
Timestep Consumption Time: 1.99552
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 7.23410

Cumulative Model Updates: 40026
Cumulative Timesteps: 334116231

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.07928
Policy Entropy: 1.26999
Value Function Loss: 0.02588

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.11986
Value Function Update Magnitude: 0.20474

Collected Steps per Second: 10215.44014
Overall Steps per Second: 7272.10379

Timestep Collection Time: 4.89690
Timestep Consumption Time: 1.98199
PPO Batch Consumption Time: 0.02462
Total Iteration Time: 6.87889

Cumulative Model Updates: 40032
Cumulative Timesteps: 334166255

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.90666
Policy Entropy: 1.27000
Value Function Loss: 0.02504

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.12085
Value Function Update Magnitude: 0.20430

Collected Steps per Second: 9824.89373
Overall Steps per Second: 6862.08295

Timestep Collection Time: 5.08932
Timestep Consumption Time: 2.19739
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 7.28671

Cumulative Model Updates: 40038
Cumulative Timesteps: 334216257

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.92986
Policy Entropy: 1.26238
Value Function Loss: 0.02450

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.12251
Value Function Update Magnitude: 0.19628

Collected Steps per Second: 9509.14525
Overall Steps per Second: 6866.82447

Timestep Collection Time: 5.26094
Timestep Consumption Time: 2.02438
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 7.28532

Cumulative Model Updates: 40044
Cumulative Timesteps: 334266284

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.62099
Policy Entropy: 1.26186
Value Function Loss: 0.02463

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.12003
Value Function Update Magnitude: 0.19668

Collected Steps per Second: 10472.47017
Overall Steps per Second: 7056.37890

Timestep Collection Time: 4.77700
Timestep Consumption Time: 2.31261
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 7.08961

Cumulative Model Updates: 40050
Cumulative Timesteps: 334316311

Timesteps Collected: 50027
--------END ITERATION REPORT--------


Saving checkpoint 334316311...
Checkpoint 334316311 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.40409
Policy Entropy: 1.25613
Value Function Loss: 0.02390

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.11908
Value Function Update Magnitude: 0.20859

Collected Steps per Second: 9986.34058
Overall Steps per Second: 7133.19464

Timestep Collection Time: 5.01034
Timestep Consumption Time: 2.00404
PPO Batch Consumption Time: 0.02476
Total Iteration Time: 7.01439

Cumulative Model Updates: 40056
Cumulative Timesteps: 334366346

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.89005
Policy Entropy: 1.25615
Value Function Loss: 0.02375

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.12189
Value Function Update Magnitude: 0.20664

Collected Steps per Second: 9513.75094
Overall Steps per Second: 6846.05765

Timestep Collection Time: 5.25681
Timestep Consumption Time: 2.04841
PPO Batch Consumption Time: 0.02477
Total Iteration Time: 7.30523

Cumulative Model Updates: 40062
Cumulative Timesteps: 334416358

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.87613
Policy Entropy: 1.25918
Value Function Loss: 0.02478

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.12418
Value Function Update Magnitude: 0.21691

Collected Steps per Second: 10337.62566
Overall Steps per Second: 7200.81931

Timestep Collection Time: 4.83805
Timestep Consumption Time: 2.10754
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 6.94560

Cumulative Model Updates: 40068
Cumulative Timesteps: 334466372

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.62691
Policy Entropy: 1.26018
Value Function Loss: 0.02489

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.12235
Value Function Update Magnitude: 0.20999

Collected Steps per Second: 10251.78586
Overall Steps per Second: 7249.48072

Timestep Collection Time: 4.88003
Timestep Consumption Time: 2.02102
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 6.90105

Cumulative Model Updates: 40074
Cumulative Timesteps: 334516401

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.97564
Policy Entropy: 1.26359
Value Function Loss: 0.02514

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.12117
Value Function Update Magnitude: 0.21027

Collected Steps per Second: 9681.83336
Overall Steps per Second: 6884.46295

Timestep Collection Time: 5.16472
Timestep Consumption Time: 2.09859
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 7.26331

Cumulative Model Updates: 40080
Cumulative Timesteps: 334566405

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.60104
Policy Entropy: 1.26086
Value Function Loss: 0.02395

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.12135
Value Function Update Magnitude: 0.21758

Collected Steps per Second: 9619.01302
Overall Steps per Second: 6898.76029

Timestep Collection Time: 5.20022
Timestep Consumption Time: 2.05050
PPO Batch Consumption Time: 0.02503
Total Iteration Time: 7.25072

Cumulative Model Updates: 40086
Cumulative Timesteps: 334616426

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.98539
Policy Entropy: 1.26661
Value Function Loss: 0.02408

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.12001
Value Function Update Magnitude: 0.22162

Collected Steps per Second: 9549.64355
Overall Steps per Second: 6866.27351

Timestep Collection Time: 5.24041
Timestep Consumption Time: 2.04797
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 7.28838

Cumulative Model Updates: 40092
Cumulative Timesteps: 334666470

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.79139
Policy Entropy: 1.26346
Value Function Loss: 0.02402

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.12072
Value Function Update Magnitude: 0.22022

Collected Steps per Second: 9440.08589
Overall Steps per Second: 6881.87639

Timestep Collection Time: 5.29783
Timestep Consumption Time: 1.96937
PPO Batch Consumption Time: 0.02470
Total Iteration Time: 7.26720

Cumulative Model Updates: 40098
Cumulative Timesteps: 334716482

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.23868
Policy Entropy: 1.26728
Value Function Loss: 0.02421

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.07994
Policy Update Magnitude: 0.12133
Value Function Update Magnitude: 0.20671

Collected Steps per Second: 9681.86009
Overall Steps per Second: 6836.91516

Timestep Collection Time: 5.16812
Timestep Consumption Time: 2.15053
PPO Batch Consumption Time: 0.02514
Total Iteration Time: 7.31865

Cumulative Model Updates: 40104
Cumulative Timesteps: 334766519

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.45686
Policy Entropy: 1.25976
Value Function Loss: 0.02433

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.11962
Value Function Update Magnitude: 0.19678

Collected Steps per Second: 9883.50885
Overall Steps per Second: 7115.58844

Timestep Collection Time: 5.06065
Timestep Consumption Time: 1.96856
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.02921

Cumulative Model Updates: 40110
Cumulative Timesteps: 334816536

Timesteps Collected: 50017
--------END ITERATION REPORT--------


Saving checkpoint 334816536...
Checkpoint 334816536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.96299
Policy Entropy: 1.26240
Value Function Loss: 0.02319

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.11871
Value Function Update Magnitude: 0.20133

Collected Steps per Second: 9377.83109
Overall Steps per Second: 6689.83388

Timestep Collection Time: 5.33439
Timestep Consumption Time: 2.14338
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 7.47776

Cumulative Model Updates: 40116
Cumulative Timesteps: 334866561

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.97921
Policy Entropy: 1.26418
Value Function Loss: 0.02489

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.11907
Value Function Update Magnitude: 0.21604

Collected Steps per Second: 9815.26007
Overall Steps per Second: 6958.39528

Timestep Collection Time: 5.09767
Timestep Consumption Time: 2.09292
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 7.19059

Cumulative Model Updates: 40122
Cumulative Timesteps: 334916596

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.70782
Policy Entropy: 1.26907
Value Function Loss: 0.02540

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.12352
Value Function Update Magnitude: 0.22232

Collected Steps per Second: 9813.09124
Overall Steps per Second: 7079.39505

Timestep Collection Time: 5.09595
Timestep Consumption Time: 1.96779
PPO Batch Consumption Time: 0.02904
Total Iteration Time: 7.06374

Cumulative Model Updates: 40128
Cumulative Timesteps: 334966603

Timesteps Collected: 50007
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.79580
Policy Entropy: 1.26543
Value Function Loss: 0.02626

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.12473
Value Function Update Magnitude: 0.21075

Collected Steps per Second: 9244.24803
Overall Steps per Second: 6543.19340

Timestep Collection Time: 5.41201
Timestep Consumption Time: 2.23410
PPO Batch Consumption Time: 0.02985
Total Iteration Time: 7.64611

Cumulative Model Updates: 40134
Cumulative Timesteps: 335016633

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.76754
Policy Entropy: 1.26904
Value Function Loss: 0.02570

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.12341
Value Function Update Magnitude: 0.20562

Collected Steps per Second: 9303.08881
Overall Steps per Second: 6734.18633

Timestep Collection Time: 5.37800
Timestep Consumption Time: 2.05156
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 7.42955

Cumulative Model Updates: 40140
Cumulative Timesteps: 335066665

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.87661
Policy Entropy: 1.25873
Value Function Loss: 0.02653

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.13533
Value Function Update Magnitude: 0.20931

Collected Steps per Second: 9870.08286
Overall Steps per Second: 7177.85038

Timestep Collection Time: 5.06733
Timestep Consumption Time: 1.90063
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 6.96796

Cumulative Model Updates: 40146
Cumulative Timesteps: 335116680

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.60275
Policy Entropy: 1.25785
Value Function Loss: 0.02574

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.12867
Value Function Update Magnitude: 0.20683

Collected Steps per Second: 9077.71169
Overall Steps per Second: 6715.73423

Timestep Collection Time: 5.50866
Timestep Consumption Time: 1.93744
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.44610

Cumulative Model Updates: 40152
Cumulative Timesteps: 335166686

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.67847
Policy Entropy: 1.25873
Value Function Loss: 0.02449

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.12378
Value Function Update Magnitude: 0.20381

Collected Steps per Second: 9824.15651
Overall Steps per Second: 7054.39185

Timestep Collection Time: 5.09123
Timestep Consumption Time: 1.99897
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 7.09019

Cumulative Model Updates: 40158
Cumulative Timesteps: 335216703

Timesteps Collected: 50017
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.70747
Policy Entropy: 1.26026
Value Function Loss: 0.02329

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.12444
Value Function Update Magnitude: 0.22065

Collected Steps per Second: 9891.39857
Overall Steps per Second: 7094.29333

Timestep Collection Time: 5.05672
Timestep Consumption Time: 1.99374
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.05046

Cumulative Model Updates: 40164
Cumulative Timesteps: 335266721

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.22978
Policy Entropy: 1.25563
Value Function Loss: 0.02391

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.12244
Value Function Update Magnitude: 0.23576

Collected Steps per Second: 9336.99384
Overall Steps per Second: 6686.09666

Timestep Collection Time: 5.35526
Timestep Consumption Time: 2.12325
PPO Batch Consumption Time: 0.02441
Total Iteration Time: 7.47850

Cumulative Model Updates: 40170
Cumulative Timesteps: 335316723

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 335316723...
Checkpoint 335316723 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.51591
Policy Entropy: 1.25580
Value Function Loss: 0.02518

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.12221
Value Function Update Magnitude: 0.23036

Collected Steps per Second: 9657.05799
Overall Steps per Second: 6741.33809

Timestep Collection Time: 5.18139
Timestep Consumption Time: 2.24102
PPO Batch Consumption Time: 0.02958
Total Iteration Time: 7.42241

Cumulative Model Updates: 40176
Cumulative Timesteps: 335366760

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.76894
Policy Entropy: 1.25663
Value Function Loss: 0.02422

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.12632
Value Function Update Magnitude: 0.22078

Collected Steps per Second: 9283.73154
Overall Steps per Second: 6505.93084

Timestep Collection Time: 5.38620
Timestep Consumption Time: 2.29971
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 7.68591

Cumulative Model Updates: 40182
Cumulative Timesteps: 335416764

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.76603
Policy Entropy: 1.25708
Value Function Loss: 0.02551

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.12678
Value Function Update Magnitude: 0.22008

Collected Steps per Second: 8958.83092
Overall Steps per Second: 6376.04244

Timestep Collection Time: 5.58242
Timestep Consumption Time: 2.26131
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.84374

Cumulative Model Updates: 40188
Cumulative Timesteps: 335466776

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.28733
Policy Entropy: 1.25276
Value Function Loss: 0.02563

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.12368
Value Function Update Magnitude: 0.22323

Collected Steps per Second: 9837.79913
Overall Steps per Second: 6962.06581

Timestep Collection Time: 5.08661
Timestep Consumption Time: 2.10106
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 7.18767

Cumulative Model Updates: 40194
Cumulative Timesteps: 335516817

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.64955
Policy Entropy: 1.25207
Value Function Loss: 0.02669

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.12710
Value Function Update Magnitude: 0.23612

Collected Steps per Second: 9411.82513
Overall Steps per Second: 6697.20683

Timestep Collection Time: 5.31629
Timestep Consumption Time: 2.15488
PPO Batch Consumption Time: 0.02507
Total Iteration Time: 7.47117

Cumulative Model Updates: 40200
Cumulative Timesteps: 335566853

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.55543
Policy Entropy: 1.25648
Value Function Loss: 0.02581

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.12107
Value Function Update Magnitude: 0.22689

Collected Steps per Second: 9482.44178
Overall Steps per Second: 6810.50340

Timestep Collection Time: 5.27417
Timestep Consumption Time: 2.06919
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 7.34336

Cumulative Model Updates: 40206
Cumulative Timesteps: 335616865

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.90447
Policy Entropy: 1.26025
Value Function Loss: 0.02567

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.11976
Value Function Update Magnitude: 0.21148

Collected Steps per Second: 9930.84390
Overall Steps per Second: 7117.51177

Timestep Collection Time: 5.03734
Timestep Consumption Time: 1.99110
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 7.02844

Cumulative Model Updates: 40212
Cumulative Timesteps: 335666890

Timesteps Collected: 50025
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.66114
Policy Entropy: 1.26391
Value Function Loss: 0.02567

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.12213
Value Function Update Magnitude: 0.21460

Collected Steps per Second: 9195.07362
Overall Steps per Second: 6649.68962

Timestep Collection Time: 5.44009
Timestep Consumption Time: 2.08237
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 7.52246

Cumulative Model Updates: 40218
Cumulative Timesteps: 335716912

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.63504
Policy Entropy: 1.25607
Value Function Loss: 0.02515

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.12173
Value Function Update Magnitude: 0.21075

Collected Steps per Second: 9408.15825
Overall Steps per Second: 6840.00821

Timestep Collection Time: 5.31815
Timestep Consumption Time: 1.99675
PPO Batch Consumption Time: 0.02522
Total Iteration Time: 7.31490

Cumulative Model Updates: 40224
Cumulative Timesteps: 335766946

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.13331
Policy Entropy: 1.25585
Value Function Loss: 0.02643

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.12311
Value Function Update Magnitude: 0.21191

Collected Steps per Second: 10366.42958
Overall Steps per Second: 7402.96308

Timestep Collection Time: 4.82683
Timestep Consumption Time: 1.93222
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 6.75905

Cumulative Model Updates: 40230
Cumulative Timesteps: 335816983

Timesteps Collected: 50037
--------END ITERATION REPORT--------


Saving checkpoint 335816983...
Checkpoint 335816983 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.78323
Policy Entropy: 1.25377
Value Function Loss: 0.02565

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.12129
Value Function Update Magnitude: 0.21902

Collected Steps per Second: 9791.19292
Overall Steps per Second: 6986.57777

Timestep Collection Time: 5.10724
Timestep Consumption Time: 2.05020
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 7.15744

Cumulative Model Updates: 40236
Cumulative Timesteps: 335866989

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.61488
Policy Entropy: 1.25534
Value Function Loss: 0.02639

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.12082
Value Function Update Magnitude: 0.22935

Collected Steps per Second: 9912.53084
Overall Steps per Second: 6976.49614

Timestep Collection Time: 5.04553
Timestep Consumption Time: 2.12340
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 7.16893

Cumulative Model Updates: 40242
Cumulative Timesteps: 335917003

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.02863
Policy Entropy: 1.25951
Value Function Loss: 0.02667

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.12495
Value Function Update Magnitude: 0.22015

Collected Steps per Second: 10438.01312
Overall Steps per Second: 7409.15868

Timestep Collection Time: 4.79373
Timestep Consumption Time: 1.95967
PPO Batch Consumption Time: 0.02467
Total Iteration Time: 6.75340

Cumulative Model Updates: 40248
Cumulative Timesteps: 335967040

Timesteps Collected: 50037
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.79378
Policy Entropy: 1.26340
Value Function Loss: 0.02746

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.12641
Value Function Update Magnitude: 0.23650

Collected Steps per Second: 9872.74517
Overall Steps per Second: 6905.71966

Timestep Collection Time: 5.06627
Timestep Consumption Time: 2.17671
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 7.24298

Cumulative Model Updates: 40254
Cumulative Timesteps: 336017058

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.50245
Policy Entropy: 1.26312
Value Function Loss: 0.02692

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.12278
Value Function Update Magnitude: 0.22853

Collected Steps per Second: 8973.45136
Overall Steps per Second: 6539.57194

Timestep Collection Time: 5.57556
Timestep Consumption Time: 2.07510
PPO Batch Consumption Time: 0.02489
Total Iteration Time: 7.65065

Cumulative Model Updates: 40260
Cumulative Timesteps: 336067090

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.13956
Policy Entropy: 1.26114
Value Function Loss: 0.02633

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07330
Policy Update Magnitude: 0.12627
Value Function Update Magnitude: 0.22746

Collected Steps per Second: 10018.15189
Overall Steps per Second: 7091.80151

Timestep Collection Time: 4.99284
Timestep Consumption Time: 2.06024
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 7.05307

Cumulative Model Updates: 40266
Cumulative Timesteps: 336117109

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.78044
Policy Entropy: 1.25464
Value Function Loss: 0.02616

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.12785
Value Function Update Magnitude: 0.22075

Collected Steps per Second: 9602.39183
Overall Steps per Second: 6907.08431

Timestep Collection Time: 5.20787
Timestep Consumption Time: 2.03223
PPO Batch Consumption Time: 0.02399
Total Iteration Time: 7.24010

Cumulative Model Updates: 40272
Cumulative Timesteps: 336167117

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.36395
Policy Entropy: 1.25195
Value Function Loss: 0.02643

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.12613
Value Function Update Magnitude: 0.21673

Collected Steps per Second: 9574.54623
Overall Steps per Second: 6874.21830

Timestep Collection Time: 5.22615
Timestep Consumption Time: 2.05293
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 7.27908

Cumulative Model Updates: 40278
Cumulative Timesteps: 336217155

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.69120
Policy Entropy: 1.25520
Value Function Loss: 0.02552

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.12274
Value Function Update Magnitude: 0.21306

Collected Steps per Second: 10205.36163
Overall Steps per Second: 7183.37227

Timestep Collection Time: 4.90379
Timestep Consumption Time: 2.06299
PPO Batch Consumption Time: 0.02584
Total Iteration Time: 6.96678

Cumulative Model Updates: 40284
Cumulative Timesteps: 336267200

Timesteps Collected: 50045
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.53750
Policy Entropy: 1.25647
Value Function Loss: 0.02552

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.12416
Value Function Update Magnitude: 0.20956

Collected Steps per Second: 9094.35863
Overall Steps per Second: 6474.32233

Timestep Collection Time: 5.50209
Timestep Consumption Time: 2.22659
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 7.72869

Cumulative Model Updates: 40290
Cumulative Timesteps: 336317238

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 336317238...
Checkpoint 336317238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.83428
Policy Entropy: 1.26191
Value Function Loss: 0.02455

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.12835
Value Function Update Magnitude: 0.20665

Collected Steps per Second: 8875.73591
Overall Steps per Second: 6412.39613

Timestep Collection Time: 5.63638
Timestep Consumption Time: 2.16523
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 7.80161

Cumulative Model Updates: 40296
Cumulative Timesteps: 336367265

Timesteps Collected: 50027
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.69723
Policy Entropy: 1.25893
Value Function Loss: 0.02529

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.12921
Value Function Update Magnitude: 0.19924

Collected Steps per Second: 9956.13976
Overall Steps per Second: 7003.28376

Timestep Collection Time: 5.02313
Timestep Consumption Time: 2.11795
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 7.14108

Cumulative Model Updates: 40302
Cumulative Timesteps: 336417276

Timesteps Collected: 50011
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.93833
Policy Entropy: 1.26097
Value Function Loss: 0.02564

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.13104
Value Function Update Magnitude: 0.20093

Collected Steps per Second: 9428.32921
Overall Steps per Second: 6664.14612

Timestep Collection Time: 5.30730
Timestep Consumption Time: 2.20139
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 7.50869

Cumulative Model Updates: 40308
Cumulative Timesteps: 336467315

Timesteps Collected: 50039
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.76125
Policy Entropy: 1.26183
Value Function Loss: 0.02650

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.12794
Value Function Update Magnitude: 0.21129

Collected Steps per Second: 9056.20363
Overall Steps per Second: 6521.44964

Timestep Collection Time: 5.52240
Timestep Consumption Time: 2.14644
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 7.66885

Cumulative Model Updates: 40314
Cumulative Timesteps: 336517327

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.43501
Policy Entropy: 1.25967
Value Function Loss: 0.02598

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.12603
Value Function Update Magnitude: 0.20822

Collected Steps per Second: 10091.49420
Overall Steps per Second: 7098.02184

Timestep Collection Time: 4.95615
Timestep Consumption Time: 2.09018
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 7.04633

Cumulative Model Updates: 40320
Cumulative Timesteps: 336567342

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.09007
Policy Entropy: 1.26092
Value Function Loss: 0.02581

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.12748
Value Function Update Magnitude: 0.21127

Collected Steps per Second: 9622.27926
Overall Steps per Second: 6792.25745

Timestep Collection Time: 5.19970
Timestep Consumption Time: 2.16648
PPO Batch Consumption Time: 0.02994
Total Iteration Time: 7.36618

Cumulative Model Updates: 40326
Cumulative Timesteps: 336617375

Timesteps Collected: 50033
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.51244
Policy Entropy: 1.25427
Value Function Loss: 0.02615

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.12960
Value Function Update Magnitude: 0.21165

Collected Steps per Second: 10311.04707
Overall Steps per Second: 7270.51169

Timestep Collection Time: 4.84946
Timestep Consumption Time: 2.02805
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 6.87751

Cumulative Model Updates: 40332
Cumulative Timesteps: 336667378

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.00009
Policy Entropy: 1.25601
Value Function Loss: 0.02631

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.12914
Value Function Update Magnitude: 0.21587

Collected Steps per Second: 10187.76992
Overall Steps per Second: 7043.00192

Timestep Collection Time: 4.90873
Timestep Consumption Time: 2.19179
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 7.10052

Cumulative Model Updates: 40338
Cumulative Timesteps: 336717387

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.97030
Policy Entropy: 1.25743
Value Function Loss: 0.02526

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.12753
Value Function Update Magnitude: 0.20923

Collected Steps per Second: 9345.39175
Overall Steps per Second: 6834.53502

Timestep Collection Time: 5.35430
Timestep Consumption Time: 1.96705
PPO Batch Consumption Time: 0.02440
Total Iteration Time: 7.32135

Cumulative Model Updates: 40344
Cumulative Timesteps: 336767425

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.08932
Policy Entropy: 1.25693
Value Function Loss: 0.02482

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.12718
Value Function Update Magnitude: 0.20718

Collected Steps per Second: 9804.25175
Overall Steps per Second: 7057.79852

Timestep Collection Time: 5.10411
Timestep Consumption Time: 1.98620
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.09031

Cumulative Model Updates: 40350
Cumulative Timesteps: 336817467

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 336817467...
Checkpoint 336817467 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.21359
Policy Entropy: 1.25870
Value Function Loss: 0.02518

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.12845
Value Function Update Magnitude: 0.20945

Collected Steps per Second: 10687.92125
Overall Steps per Second: 7545.09891

Timestep Collection Time: 4.67986
Timestep Consumption Time: 1.94934
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 6.62920

Cumulative Model Updates: 40356
Cumulative Timesteps: 336867485

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.17056
Policy Entropy: 1.25542
Value Function Loss: 0.02551

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.13137
Value Function Update Magnitude: 0.20565

Collected Steps per Second: 9975.21301
Overall Steps per Second: 7140.73603

Timestep Collection Time: 5.01553
Timestep Consumption Time: 1.99089
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 7.00642

Cumulative Model Updates: 40362
Cumulative Timesteps: 336917516

Timesteps Collected: 50031
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.23514
Policy Entropy: 1.26034
Value Function Loss: 0.02598

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.13010
Value Function Update Magnitude: 0.20792

Collected Steps per Second: 9745.30409
Overall Steps per Second: 7024.32960

Timestep Collection Time: 5.13283
Timestep Consumption Time: 1.98828
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 7.12111

Cumulative Model Updates: 40368
Cumulative Timesteps: 336967537

Timesteps Collected: 50021
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.17728
Policy Entropy: 1.25707
Value Function Loss: 0.02614

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.13594
Value Function Update Magnitude: 0.20614

Collected Steps per Second: 10243.08756
Overall Steps per Second: 7220.63266

Timestep Collection Time: 4.88222
Timestep Consumption Time: 2.04363
PPO Batch Consumption Time: 0.02538
Total Iteration Time: 6.92585

Cumulative Model Updates: 40374
Cumulative Timesteps: 337017546

Timesteps Collected: 50009
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.61041
Policy Entropy: 1.25043
Value Function Loss: 0.02704

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.13702
Value Function Update Magnitude: 0.21261

Collected Steps per Second: 10164.64526
Overall Steps per Second: 7160.31236

Timestep Collection Time: 4.91911
Timestep Consumption Time: 2.06397
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 6.98308

Cumulative Model Updates: 40380
Cumulative Timesteps: 337067547

Timesteps Collected: 50001
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.75336
Policy Entropy: 1.24874
Value Function Loss: 0.02634

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.13436
Value Function Update Magnitude: 0.21624

Collected Steps per Second: 8939.13419
Overall Steps per Second: 6555.17154

Timestep Collection Time: 5.59663
Timestep Consumption Time: 2.03536
PPO Batch Consumption Time: 0.02444
Total Iteration Time: 7.63199

Cumulative Model Updates: 40386
Cumulative Timesteps: 337117576

Timesteps Collected: 50029
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.33303
Policy Entropy: 1.24922
Value Function Loss: 0.02631

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.13198
Value Function Update Magnitude: 0.21093

Collected Steps per Second: 10067.25080
Overall Steps per Second: 7082.25593

Timestep Collection Time: 4.96809
Timestep Consumption Time: 2.09393
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 7.06202

Cumulative Model Updates: 40392
Cumulative Timesteps: 337167591

Timesteps Collected: 50015
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.34263
Policy Entropy: 1.25478
Value Function Loss: 0.02562

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.13057
Value Function Update Magnitude: 0.21141

Collected Steps per Second: 9575.87397
Overall Steps per Second: 6793.31398

Timestep Collection Time: 5.22177
Timestep Consumption Time: 2.13885
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 7.36062

Cumulative Model Updates: 40398
Cumulative Timesteps: 337217594

Timesteps Collected: 50003
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.85180
Policy Entropy: 1.25727
Value Function Loss: 0.02544

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.13035
Value Function Update Magnitude: 0.21524

Collected Steps per Second: 9155.99751
Overall Steps per Second: 6410.84695

Timestep Collection Time: 5.46298
Timestep Consumption Time: 2.33927
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 7.80225

Cumulative Model Updates: 40404
Cumulative Timesteps: 337267613

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.68800
Policy Entropy: 1.26015
Value Function Loss: 0.02515

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.12831
Value Function Update Magnitude: 0.21729

Collected Steps per Second: 9406.36969
Overall Steps per Second: 6647.49252

Timestep Collection Time: 5.31810
Timestep Consumption Time: 2.20715
PPO Batch Consumption Time: 0.02524
Total Iteration Time: 7.52524

Cumulative Model Updates: 40410
Cumulative Timesteps: 337317637

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 337317637...
Checkpoint 337317637 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.96972
Policy Entropy: 1.26043
Value Function Loss: 0.02515

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.13035
Value Function Update Magnitude: 0.21361

Collected Steps per Second: 9685.76356
Overall Steps per Second: 6924.20933

Timestep Collection Time: 5.16418
Timestep Consumption Time: 2.05961
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 7.22379

Cumulative Model Updates: 40416
Cumulative Timesteps: 337367656

Timesteps Collected: 50019
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.04193
Policy Entropy: 1.26401
Value Function Loss: 0.02572

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.13104
Value Function Update Magnitude: 0.21065

Collected Steps per Second: 9595.04151
Overall Steps per Second: 6692.40918

Timestep Collection Time: 5.21332
Timestep Consumption Time: 2.26112
PPO Batch Consumption Time: 0.02964
Total Iteration Time: 7.47444

Cumulative Model Updates: 40422
Cumulative Timesteps: 337417678

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.48305
Policy Entropy: 1.26688
Value Function Loss: 0.02615

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.13252
Value Function Update Magnitude: 0.20351

Collected Steps per Second: 9233.51361
Overall Steps per Second: 6596.94427

Timestep Collection Time: 5.41950
Timestep Consumption Time: 2.16598
PPO Batch Consumption Time: 0.02550
Total Iteration Time: 7.58548

Cumulative Model Updates: 40428
Cumulative Timesteps: 337467719

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.34645
Policy Entropy: 1.26299
Value Function Loss: 0.02618

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.13235
Value Function Update Magnitude: 0.20952

Collected Steps per Second: 9937.68116
Overall Steps per Second: 6823.10028

Timestep Collection Time: 5.03568
Timestep Consumption Time: 2.29867
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 7.33435

Cumulative Model Updates: 40434
Cumulative Timesteps: 337517762

Timesteps Collected: 50043
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.02878
Policy Entropy: 1.25762
Value Function Loss: 0.02580

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.13136
Value Function Update Magnitude: 0.20744

Collected Steps per Second: 9188.14810
Overall Steps per Second: 6533.02523

Timestep Collection Time: 5.44560
Timestep Consumption Time: 2.21318
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 7.65878

Cumulative Model Updates: 40440
Cumulative Timesteps: 337567797

Timesteps Collected: 50035
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.84657
Policy Entropy: 1.25984
Value Function Loss: 0.02540

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.13299
Value Function Update Magnitude: 0.20995

Collected Steps per Second: 9739.68365
Overall Steps per Second: 6742.21723

Timestep Collection Time: 5.13836
Timestep Consumption Time: 2.28442
PPO Batch Consumption Time: 0.02453
Total Iteration Time: 7.42278

Cumulative Model Updates: 40446
Cumulative Timesteps: 337617843

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.12949
Policy Entropy: 1.26101
Value Function Loss: 0.02479

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.13196
Value Function Update Magnitude: 0.20851

Collected Steps per Second: 10510.50029
Overall Steps per Second: 7217.49023

Timestep Collection Time: 4.75848
Timestep Consumption Time: 2.17108
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 6.92956

Cumulative Model Updates: 40452
Cumulative Timesteps: 337667857

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.93940
Policy Entropy: 1.26463
Value Function Loss: 0.02330

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.13229
Value Function Update Magnitude: 0.21047

Collected Steps per Second: 9988.07755
Overall Steps per Second: 6981.85849

Timestep Collection Time: 5.00697
Timestep Consumption Time: 2.15588
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 7.16285

Cumulative Model Updates: 40458
Cumulative Timesteps: 337717867

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.55109
Policy Entropy: 1.26508
Value Function Loss: 0.02457

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.12940
Value Function Update Magnitude: 0.19852

Collected Steps per Second: 9957.07064
Overall Steps per Second: 6947.51141

Timestep Collection Time: 5.02567
Timestep Consumption Time: 2.17705
PPO Batch Consumption Time: 0.02370
Total Iteration Time: 7.20272

Cumulative Model Updates: 40464
Cumulative Timesteps: 337767908

Timesteps Collected: 50041
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.66736
Policy Entropy: 1.26492
Value Function Loss: 0.02544

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.13084
Value Function Update Magnitude: 0.19279

Collected Steps per Second: 10235.29475
Overall Steps per Second: 7107.36829

Timestep Collection Time: 4.88594
Timestep Consumption Time: 2.15028
PPO Batch Consumption Time: 0.02564
Total Iteration Time: 7.03622

Cumulative Model Updates: 40470
Cumulative Timesteps: 337817917

Timesteps Collected: 50009
--------END ITERATION REPORT--------


Saving checkpoint 337817917...
Checkpoint 337817917 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.91305
Policy Entropy: 1.26449
Value Function Loss: 0.02711

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.13506
Value Function Update Magnitude: 0.18999

Collected Steps per Second: 10636.82389
Overall Steps per Second: 7570.62340

Timestep Collection Time: 4.70338
Timestep Consumption Time: 1.90493
PPO Batch Consumption Time: 0.02424
Total Iteration Time: 6.60831

Cumulative Model Updates: 40476
Cumulative Timesteps: 337867946

Timesteps Collected: 50029
--------END ITERATION REPORT--------


Saving checkpoint 337867946...
Checkpoint 337867946 saved!
