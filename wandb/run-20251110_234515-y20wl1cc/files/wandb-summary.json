{"PPO Batch Consumption Time":0.6468694607416788,"Total Iteration Time":24.743033199978527,"Timestep Collection Time":19.337170699960552,"z_vel":-22.26261714662019,"Policy Update Magnitude":0.05307423323392868,"Timestep Consumption Time":5.4058625000179745,"_wandb":{"runtime":3241},"_runtime":3241,"Value Function Loss":0.2905121644337972,"Cumulative Timesteps":12700565,"Timesteps Collected":50001,"Value Function Update Magnitude":0.02845350280404091,"y_vel":29.77607992209827,"_step":287,"Overall Steps per Second":2020.8112560768577,"Mean KL Divergence":0.005149736690024535,"_timestamp":1.762816903417686e+09,"Policy Entropy":0.2807304114103317,"x_vel":-35.22507521797473,"SB3 Clip Fraction":0.0590699998040994,"Policy Reward":270.6469777159682,"Collected Steps per Second":2585.74539035858,"Cumulative Model Updates":1480}