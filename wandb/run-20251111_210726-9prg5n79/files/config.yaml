_wandb:
    value:
        cli_version: 0.22.3
        e:
            s0n6y1srw9g3kxdxqt5mrbyc8uts202y:
                codePath: bot.py
                codePathLocal: bot.py
                cpu_count: 48
                cpu_count_logical: 96
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "26843545600"
                        used: "9290338304"
                email: cuteslenaa@gmail.com
                executable: /venv/main/bin/python
                git:
                    commit: 649ce3d9dd02f6118f3c1ce888f84748760431b9
                    remote: https://github.com/Gashrod1/Rl-ai.git
                gpu: NVIDIA GeForce RTX 4090
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-9edc6618-19b5-3d79-c635-621d872067f9
                host: 696541736f48
                memory:
                    total: "270084517888"
                os: Linux-6.8.0-79-generic-x86_64-with-glibc2.39
                program: /workspace/Rl-ai/bot.py
                python: CPython 3.12.3
                root: /workspace/Rl-ai
                startedAt: "2025-11-11T21:07:26.468916Z"
                writerId: s0n6y1srw9g3kxdxqt5mrbyc8uts202y
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 2
                - 5
                - 14
                - 16
                - 62
            "4": 3.12.3
            "5": 0.22.3
            "10":
                - 20
            "12": 0.22.3
            "13": linux-x86_64
critic_layer_sizes:
    value:
        - 512
        - 512
        - 256
critic_lr:
    value: 0.0002
exp_buffer_size:
    value: 150000
gae_gamma:
    value: 0.99
gae_lambda:
    value: 0.95
min_inference_size:
    value: 5
n_proc:
    value: 6
policy_layer_sizes:
    value:
        - 512
        - 512
        - 256
policy_lr:
    value: 0.0002
ppo_batch_size:
    value: 50000
ppo_clip_range:
    value: 0.2
ppo_ent_coef:
    value: 0.01
ppo_epochs:
    value: 2
ppo_minibatch_size:
    value: 50000
shm_buffer_size:
    value: 8192
standardize_obs:
    value: true
standardize_returns:
    value: true
timestep_limit:
    value: 1e+16
ts_per_iteration:
    value: 50000
