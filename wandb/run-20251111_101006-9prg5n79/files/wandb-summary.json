{"Total Iteration Time":49.45126419997541,"Mean KL Divergence":0.012732051933805147,"Timestep Consumption Time":15.733677099982742,"_runtime":27789,"Policy Entropy":0.3575005729993184,"_timestamp":1.7628526791268268e+09,"Cumulative Timesteps":56502460,"Cumulative Model Updates":6762,"Value Function Loss":0.22556995848814645,"Timestep Collection Time":33.71758709999267,"y_vel":4.263306245318798,"PPO Batch Consumption Time":2.2526501019795737,"z_vel":-19.494505080661266,"Timesteps Collected":50001,"Policy Update Magnitude":0.11317770183086395,"x_vel":18.41520172467023,"Collected Steps per Second":1482.9352958062314,"Overall Steps per Second":1011.1167188325362,"_wandb":{"runtime":27789},"_step":2259,"SB3 Clip Fraction":0.1501699984073639,"Policy Reward":406.8711847728613,"Value Function Update Magnitude":0.15862244367599487}